id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Ffuel-docs~master~Id6b23f8036a0b2faaf7f29e64bd7edb55b0ec166,openstack/fuel-docs,master,Id6b23f8036a0b2faaf7f29e64bd7edb55b0ec166,Multiple cluster networks,MERGED,2014-12-16 11:56:33.000000000,2014-12-24 02:39:28.000000000,2014-12-24 02:39:27.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8829}, {'_account_id': 8907}, {'_account_id': 8967}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-12-16 11:56:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/00165c130a39e43b3dc20d6951f0ee3db9dd2ca6', 'message': 'Multiple L2 networks\n\nplanning/4200-net-topology -- adds mention of multiple L2 networks\nfor Neutron GRE environments with xrefs for more information\n\nref-arch/6055-l2-multiple -- explains the implementation\n\noperations/3500-l2-multiple -- instructions for configuring\n\nterminology/node-group -- define term and xref other docs\n\nfile-ref/dnsmasq-template -- ref page for dnsmasq.template file\nthat defines the DHCP networks used\n\nChange-Id: Id6b23f8036a0b2faaf7f29e64bd7edb55b0ec166\nCloses-Bug: 1395638\n'}, {'number': 2, 'created': '2014-12-16 12:05:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/47620101d0e7041daee71cc674927ff401099809', 'message': 'Multiple L2 networks\n\nplanning/4200-net-topology -- adds mention of multiple L2 networks\nfor Neutron GRE environments with xrefs for more information\n\nref-arch/6055-l2-multiple -- explains the implementation\n\noperations/3500-l2-multiple -- instructions for configuring\n\nterminology/node-group -- define term and xref other docs\n\nfile-ref/dnsmasq-template -- ref page for dnsmasq.template file\nthat defines the DHCP networks used\n\nChange-Id: Id6b23f8036a0b2faaf7f29e64bd7edb55b0ec166\nCloses-Bug: 1395638\n'}, {'number': 3, 'created': '2014-12-16 19:43:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/15d46fce2407ce4cba8702106c480fe40e444064', 'message': 'Multiple L2 networks\n\nplanning/4200-net-topology -- adds mention of multiple L2 networks\nfor Neutron GRE environments with xrefs for more information\n\nref-arch/6055-l2-multiple -- explains the implementation\n\noperations/3500-l2-multiple -- instructions for configuring\n\nterminology/node-group -- define term and xref other docs\n\nfile-ref/dnsmasq-template -- ref page for dnsmasq.template file\nthat defines the DHCP networks used\n\nfile-ref/network-1-yaml -- ref page for network_1.yaml\n\nChange-Id: Id6b23f8036a0b2faaf7f29e64bd7edb55b0ec166\nCloses-Bug: 1395638\n'}, {'number': 4, 'created': '2014-12-17 10:03:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/c84b647f016fa61b914401847dcd0f4614882ff3', 'message': 'Multiple cluster networks\n\nplanning/4200-net-topology -- adds mention of multiple L2 networks\nfor Neutron GRE environments with xrefs for more information\n\nref-arch/6055-l2-multiple -- explains the implementation\n\noperations/3500-l2-multiple -- instructions for configuring\n\nterminology/node-group -- define term and xref other docs\nterminology/mcn -- basic info and xref docs\n\nfile-ref/dnsmasq-template -- ref page for dnsmasq.template file\nthat defines the DHCP networks used\n\nfile-ref/network-1-yaml -- ref page for network_1.yaml\n\nChange-Id: Id6b23f8036a0b2faaf7f29e64bd7edb55b0ec166\nCloses-Bug: 1395638\n'}, {'number': 5, 'created': '2014-12-18 21:44:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/28439726d18abea601319b69e2fa025c42274e0e', 'message': 'Multiple cluster networks\n\nplanning/4200-net-topology -- adds mention of multiple L2 networks\nfor Neutron GRE environments with xrefs for more information\n\nref-arch/6055-l2-multiple -- explains the implementation\n\noperations/3500-l2-multiple -- instructions for configuring\n\nterminology/node-group -- define term and xref other docs\nterminology/mcn -- basic info and xref docs\n\nfile-ref/dnsmasq-template -- ref page for dnsmasq.template file\nthat defines the DHCP networks used\n\nfile-ref/network-1-yaml -- ref page for network_1.yaml\n\nChange-Id: Id6b23f8036a0b2faaf7f29e64bd7edb55b0ec166\nCloses-Bug: 1395638\n'}, {'number': 6, 'created': '2014-12-19 15:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/01bae9f80784e0ce72813965b0d64a10669451b1', 'message': 'Multiple cluster networks\n\nplanning/4200-net-topology -- adds mention of multiple L2 networks\nfor Neutron GRE environments with xrefs for more information\n\nref-arch/network-concepts/6015-mcn.rst -- explains the implementation;\nit is located right after the section that discusses the Logical\nNetworks.\n\noperations/3500-mcn -- instructions for configuring\n\nterminology/node-group -- define term and xref other docs\nterminology/mcn -- basic info and xref docs\n\nfile-ref/dnsmasq-template -- ref page for dnsmasq.template file\nthat defines the DHCP networks used\n\nfile-ref/network-1-yaml -- ref page for network_1.yaml where the\nnetworks are configured\n\nrelease-notes/v6-0/new-features/mcn.rst is the ""New Features""\narticle for the Release Notes.\n\nChange-Id: Id6b23f8036a0b2faaf7f29e64bd7edb55b0ec166\nCloses-Bug: 1395638\n'}, {'number': 7, 'created': '2014-12-19 19:43:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/913be8a103c474797a16de66bc9b7291b3edbbd9', 'message': 'Multiple cluster networks\n\nplanning/4200-net-topology -- adds mention of multiple L2 networks\nfor Neutron GRE environments with xrefs for more information\n\nref-arch/network-concepts/6015-mcn.rst -- explains the implementation;\nit is located right after the section that discusses the Logical\nNetworks.\n\noperations/3500-mcn -- instructions for configuring\n\nterminology/node-group -- define term and xref other docs\nterminology/mcn -- basic info and xref docs\n\nfile-ref/dnsmasq-template -- ref page for dnsmasq.template file\nthat defines the DHCP networks used\n\nfile-ref/network-1-yaml -- ref page for network_1.yaml where the\nnetworks are configured\n\nrelease-notes/v6-0/new-features/mcn.rst is the ""New Features""\narticle for the Release Notes.\n\nChange-Id: Id6b23f8036a0b2faaf7f29e64bd7edb55b0ec166\nCloses-Bug: 1395638\n'}, {'number': 8, 'created': '2014-12-20 01:42:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a387f998a4758022ff0224713987b9a38badedb3', 'message': 'Multiple cluster networks\n\nplanning/4200-net-topology -- adds mention of multiple L2 networks\nfor Neutron GRE environments with xrefs for more information\n\nref-arch/network-concepts/6015-mcn.rst -- explains the implementation;\nit is located right after the section that discusses the Logical\nNetworks.\n\noperations/3500-mcn -- instructions for configuring\n\nterminology/node-group -- define term and xref other docs\nterminology/mcn -- basic info and xref docs\n\nfile-ref/dnsmasq-template -- ref page for dnsmasq.template file\nthat defines the DHCP networks used\n\nfile-ref/network-1-yaml -- ref page for network_1.yaml where the\nnetworks are configured\n\nrelease-notes/v6-0/new-features/mcn.rst is the ""New Features""\narticle for the Release Notes.\n\nChange-Id: Id6b23f8036a0b2faaf7f29e64bd7edb55b0ec166\nCloses-Bug: 1395638\n'}, {'number': 9, 'created': '2014-12-22 06:53:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/0bcdc20443c871b4fa7e0ba49871d04f900b71cb', 'message': 'Multiple cluster networks\n\nplanning/4200-net-topology -- adds mention of multiple L2 networks\nfor Neutron GRE environments with xrefs for more information\n\nref-arch/network-concepts/6015-mcn.rst -- explains the implementation;\nit is located right after the section that discusses the Logical\nNetworks.\nref-arch/6010-logical-networks -- I moved the definition of ""Internal\nnetwork"" to the end of the list so that the first four networks listed\ncorrespond to those discussed for MCN below.  No content changes were\nmade to that paragraph.\n\noperations/3500-mcn -- instructions for configuring\n\nterminology/node-group -- define term and xref other docs\nterminology/mcn -- basic info and xref docs\n\nfile-ref/dnsmasq-template -- ref page for dnsmasq.template file\nthat defines the DHCP networks used\n\nfile-ref/network-1-yaml -- ref page for network_1.yaml where the\nnetworks are configured\n\nrelease-notes/v6-0/new-features/mcn.rst is the ""New Features""\narticle for the Release Notes.\n\nChange-Id: Id6b23f8036a0b2faaf7f29e64bd7edb55b0ec166\nCloses-Bug: 1395638\n'}, {'number': 10, 'created': '2014-12-22 18:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a6a5e32071ca879fd303175d388f5555b3a1ab82', 'message': 'Multiple cluster networks\n\nplanning/4200-net-topology -- adds mention of multiple L2 networks\nfor Neutron GRE environments with xrefs for more information\n\nref-arch/network-concepts/6015-mcn.rst -- explains the implementation;\nit is located right after the section that discusses the Logical\nNetworks.\nref-arch/6010-logical-networks -- I moved the definition of ""Internal\nnetwork"" to the end of the list so that the first four networks listed\ncorrespond to those discussed for MCN below.  No content changes were\nmade to that paragraph.\n\noperations/3500-mcn -- instructions for configuring\n\nterminology/node-group -- define term and xref other docs\nterminology/mcn -- basic info and xref docs\n\nfile-ref/dnsmasq-template -- ref page for dnsmasq.template file\nthat defines the DHCP networks used\n\nfile-ref/network-1-yaml -- ref page for network_1.yaml where the\nnetworks are configured\n\nrelease-notes/v6-0/new-features/mcn.rst is the ""New Features""\narticle for the Release Notes.\n\nChange-Id: Id6b23f8036a0b2faaf7f29e64bd7edb55b0ec166\nCloses-Bug: 1395638\n'}, {'number': 11, 'created': '2014-12-23 19:34:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/760b8d62a15f2ecd223280f1898a9451599a29d6', 'message': 'Multiple cluster networks\n\nplanning/4200-net-topology -- adds mention of multiple L2 networks\nfor Neutron GRE environments with xrefs for more information\n\nref-arch/network-concepts/6015-mcn.rst -- explains the implementation;\nit is located right after the section that discusses the Logical\nNetworks.\nref-arch/6010-logical-networks -- I moved the definition of ""Internal\nnetwork"" to the end of the list so that the first four networks listed\ncorrespond to those discussed for MCN below.  No content changes were\nmade to that paragraph.\n\noperations/3500-mcn -- instructions for configuring\n\nterminology/node-group -- define term and xref other docs\nterminology/mcn -- basic info and xref docs\n\nfile-ref/dnsmasq-template -- ref page for dnsmasq.template file\nthat defines the DHCP networks used\n\nfile-ref/network-1-yaml -- ref page for network_1.yaml where the\nnetworks are configured\n\nrelease-notes/v6-0/new-features/mcn.rst is the ""New Features""\narticle for the Release Notes.\n\nChange-Id: Id6b23f8036a0b2faaf7f29e64bd7edb55b0ec166\nCloses-Bug: 1395638\n'}, {'number': 12, 'created': '2014-12-24 02:09:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/1fa70f80b31d9838e98034e122f0289d4dfb099e', 'message': 'Multiple cluster networks\n\nplanning/4200-net-topology -- adds mention of multiple L2 networks\nfor Neutron GRE environments with xrefs for more information\n\nref-arch/network-concepts/6015-mcn.rst -- explains the implementation;\nit is located right after the section that discusses the Logical\nNetworks.\nref-arch/6010-logical-networks -- I moved the definition of ""Internal\nnetwork"" to the end of the list so that the first four networks listed\ncorrespond to those discussed below.  No content changes were made to\nthat paragraph.\n\noperations/3500-mcn -- instructions for configuring\n\nterminology/node-group -- define term and xref other docs\n\nfile-ref/dnsmasq-template -- ref page for dnsmasq.template file\nthat defines the DHCP networks used\n\nfile-ref/network-1-yaml -- ref page for network_1.yaml where the\nnetworks are configured\n\nrelease-notes/v6-0/new-features/mcn.rst is the ""New Features""\narticle for the Release Notes.\n\nChange-Id: Id6b23f8036a0b2faaf7f29e64bd7edb55b0ec166\nCloses-Bug: 1395638\n'}, {'number': 13, 'created': '2014-12-24 02:20:12.000000000', 'files': ['pages/terminology/n/node-group.rst', 'pages/release-notes/v6-0/0020-new-features.rst', 'pages/terminology/allterms.rst', 'pages/operations/3500-mcn.rst', 'contents/contents-operations.rst', 'pages/planning-guide/4200-net-topology.rst', 'pages/reference-architecture/6000-network-architecture.rst', 'pages/release-notes/v6-0/new-features/mcn.rst', 'pages/file-ref/0000-intro.rst', 'pages/file-ref/network-1-yaml.rst', 'pages/file-ref/dnsmasq-template.rst', 'pages/reference-architecture/network-concepts/6010-logical-networks.rst', 'pages/release-notes/v6-0/new-features/l2-multiple.rst', 'pages/reference-architecture/network-concepts/6015-mcn.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/8aa8e181dc2e19f8bc17798c72e83e03f53daf2a', 'message': 'Multiple cluster networks\n\nplanning/4200-net-topology -- adds mention of multiple L2 networks\nfor Neutron GRE environments with xrefs for more information\n\nref-arch/network-concepts/6015-mcn.rst -- explains the implementation;\nit is located right after the section that discusses the Logical\nNetworks.\nref-arch/6010-logical-networks -- I moved the definition of ""Internal\nnetwork"" to the end of the list so that the first four networks listed\ncorrespond to those discussed below.  No content changes were made to\nthat paragraph.\n\noperations/3500-mcn -- instructions for configuring\n\nterminology/node-group -- define term and xref other docs\n\nfile-ref/dnsmasq-template -- ref page for dnsmasq.template file\nthat defines the DHCP networks used\n\nfile-ref/network-1-yaml -- ref page for network_1.yaml where the\nnetworks are configured\n\nrelease-notes/v6-0/new-features/mcn.rst is the ""New Features""\narticle for the Release Notes.\n\nChange-Id: Id6b23f8036a0b2faaf7f29e64bd7edb55b0ec166\nCloses-Bug: 1395638\n'}]",226,142082,8aa8e181dc2e19f8bc17798c72e83e03f53daf2a,93,11,13,10014,,,0,"Multiple cluster networks

planning/4200-net-topology -- adds mention of multiple L2 networks
for Neutron GRE environments with xrefs for more information

ref-arch/network-concepts/6015-mcn.rst -- explains the implementation;
it is located right after the section that discusses the Logical
Networks.
ref-arch/6010-logical-networks -- I moved the definition of ""Internal
network"" to the end of the list so that the first four networks listed
correspond to those discussed below.  No content changes were made to
that paragraph.

operations/3500-mcn -- instructions for configuring

terminology/node-group -- define term and xref other docs

file-ref/dnsmasq-template -- ref page for dnsmasq.template file
that defines the DHCP networks used

file-ref/network-1-yaml -- ref page for network_1.yaml where the
networks are configured

release-notes/v6-0/new-features/mcn.rst is the ""New Features""
article for the Release Notes.

Change-Id: Id6b23f8036a0b2faaf7f29e64bd7edb55b0ec166
Closes-Bug: 1395638
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/82/142082/3 && git format-patch -1 --stdout FETCH_HEAD,"['pages/terminology/n/node-group.rst', 'pages/reference-architecture/6055-l2-multiple.rst', 'pages/file-ref/0000-intro.rst', 'contents/contents-refarch.rst', 'pages/terminology/allterms.rst', 'pages/operations/3500-l2-multiple.rst', 'pages/file-ref/dnsmasq-template.rst', 'contents/contents-operations.rst', 'pages/planning-guide/4200-net-topology.rst']",9,00165c130a39e43b3dc20d6951f0ee3db9dd2ca6,bug/1395638, Neutron GRE supports multiple L2 networks in Mirantis OpenStack 6.0 and later. See :ref:`l2-multiple-ops` for instructions; :ref:`l2-multiple-arch` explains how this feature is implemented. ,,267,0
openstack%2Fmanila~master~I5760461c1ebf8cf53ccfae55606fe6036c915e02,openstack/manila,master,I5760461c1ebf8cf53ccfae55606fe6036c915e02,Make Tempest repo stable for Manila,MERGED,2014-12-23 12:36:09.000000000,2014-12-24 02:39:07.000000000,2014-12-24 02:39:05.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-12-23 12:36:09.000000000', 'files': ['contrib/ci/pre_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/manila/commit/be716c383a50e9e0aa81804974f74e5d6f1ac652', 'message': 'Make Tempest repo stable for Manila\n\nManila has Tempest plugin for mainstream Tempest.\nNow, our jobs run over latest Tempest.\nIt causes incompatibilities from time to time.\nFix it by checking out Tempest repo HEAD to some specific commit that is\ncompatible with Manila plugin.\n\nImplements blueprint stable-base-for-functional-tests\n\nChange-Id: I5760461c1ebf8cf53ccfae55606fe6036c915e02\n'}]",0,143662,be716c383a50e9e0aa81804974f74e5d6f1ac652,15,5,1,8851,,,0,"Make Tempest repo stable for Manila

Manila has Tempest plugin for mainstream Tempest.
Now, our jobs run over latest Tempest.
It causes incompatibilities from time to time.
Fix it by checking out Tempest repo HEAD to some specific commit that is
compatible with Manila plugin.

Implements blueprint stable-base-for-functional-tests

Change-Id: I5760461c1ebf8cf53ccfae55606fe6036c915e02
",git fetch https://review.opendev.org/openstack/manila refs/changes/62/143662/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/ci/pre_test_hook.sh'],1,be716c383a50e9e0aa81804974f74e5d6f1ac652,bp/stable-base-for-functional-tests,"# Go to Tempest dir and checkout stable commit to avoid possible # incompatibilities for plugin stored in Manila repo. TEMPEST_COMMIT=""128bbed7"" # 23 Dec, 2014 cd $BASE/new/tempest git checkout $TEMPEST_COMMIT # Print current Tempest status git status # Install Manila Tempest integration",# Install manila tempest integration,10,1
openstack%2Ffuel-docs~master~Ica825fcef96ab78a50ce847289ef2de1f39e2792,openstack/fuel-docs,master,Ica825fcef96ab78a50ce847289ef2de1f39e2792,Release Notes 6.0 -- New Partner Features and Pluggable Architecture,MERGED,2014-12-19 09:58:08.000000000,2014-12-24 02:38:47.000000000,2014-12-24 02:38:47.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8749}, {'_account_id': 8787}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 11427}, {'_account_id': 11577}, {'_account_id': 12139}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-12-19 09:58:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/ab04b93b3dbf31c76a88b8bbdd26b2e6948b0d2f', 'message': 'Release Notes 6.0 -- New Features\n\nThe following new features are covered within this CR:\n\n* NSX+vCenter\n\n* Ceilometer for vCenter\n\n* Pluggable Acrhitecture\n\n* Sahara for vCenter\n\n* Glance+VMDK\n\n* VLAN manager for vCenter hv\n\nChange-Id: Ica825fcef96ab78a50ce847289ef2de1f39e2792\n'}, {'number': 2, 'created': '2014-12-19 10:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/79da4e4faf2703b41f0c25cecc1f9e5e76a30455', 'message': 'Release Notes 6.0 -- New Partner Features and Pluggable Architecture\n\nThe following new features are covered within this CR:\n\n* NSX+vCenter\n\n* Ceilometer for vCenter\n\n* Pluggable Acrhitecture\n\n* Sahara for vCenter\n\n* Glance+VMDK\n\n* VLAN manager for vCenter hv\n\nChange-Id: Ica825fcef96ab78a50ce847289ef2de1f39e2792\n'}, {'number': 3, 'created': '2014-12-19 20:51:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4396ff6e32152a3e73f53ef22ea927300475ce22', 'message': 'Release Notes 6.0 -- New Partner Features and Pluggable Architecture\n\nThe following new features are covered within this CR:\n\n* NSX+vCenter\n\n* Ceilometer for vCenter\n\n* Pluggable Acrhitecture\n\n* Sahara for vCenter\n\n* Glance+VMDK\n\n* VLAN manager for vCenter hv\n\nChange-Id: Ica825fcef96ab78a50ce847289ef2de1f39e2792\n'}, {'number': 4, 'created': '2014-12-22 15:25:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/33a331690205bf00e4f87f47547abc9515927d3f', 'message': 'Release Notes 6.0 -- New Partner Features and Pluggable Architecture\n\nThe following new features are covered within this CR:\n\n* NSX+vCenter\n\n* Ceilometer for vCenter\n\n* Pluggable Acrhitecture\n\n* Sahara for vCenter\n\n* Glance+VMDK\n\n* VLAN manager for vCenter hv\n\nChange-Id: Ica825fcef96ab78a50ce847289ef2de1f39e2792\n'}, {'number': 5, 'created': '2014-12-23 17:55:23.000000000', 'files': ['pages/release-notes/v6-0/new-features/vlan-for-vcenter.rst', 'pages/user-guide/7300-vcenter.rst', 'pages/release-notes/v6-0/new-features/nsx.rst', 'pages/release-notes/v6-0/new-features/glance-vmdk.rst', 'pages/release-notes/v6-0/0020-new-features.rst', 'pages/release-notes/v6-0/new-features/ceilometer-vcenter.rst', 'pages/release-notes/v6-0/new-features/plugin-arch.rst', 'pages/release-notes/v6-0/new-features/1-1-instance-vsphere-map.rst', 'pages/release-notes/v6-0/new-features/sahara-vcenter.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/1f85d870a346863fce2aba32b4cb0119b33d93e7', 'message': 'Release Notes 6.0 -- New Partner Features and Pluggable Architecture\n\nThe following new features are covered within this CR:\n\n* NSX+vCenter\n\n* Ceilometer for vCenter\n\n* Pluggable Acrhitecture\n\n* Sahara for vCenter\n\n* Glance+VMDK\n\n* VLAN manager for vCenter hv\n\nChange-Id: Ica825fcef96ab78a50ce847289ef2de1f39e2792\n'}]",14,143025,1f85d870a346863fce2aba32b4cb0119b33d93e7,35,12,5,13082,,,0,"Release Notes 6.0 -- New Partner Features and Pluggable Architecture

The following new features are covered within this CR:

* NSX+vCenter

* Ceilometer for vCenter

* Pluggable Acrhitecture

* Sahara for vCenter

* Glance+VMDK

* VLAN manager for vCenter hv

Change-Id: Ica825fcef96ab78a50ce847289ef2de1f39e2792
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/25/143025/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/release-notes/v6-0/new-features/nsx.rst', 'pages/release-notes/v6-0/new-features/vlan-for-vcenter.rst', 'pages/user-guide/7300-vcenter.rst', 'pages/release-notes/v6-0/new-features/glance-vmdk.rst', 'pages/release-notes/v6-0/new-features/ceilometer-vcenter.rst', 'pages/release-notes/v6-0/new-features/plugin-arch.rst', 'pages/release-notes/v6-0/new-features/sahara-vcenter.rst']",7,ab04b93b3dbf31c76a88b8bbdd26b2e6948b0d2f,partner-new-features,"storage backend for HDFS file systems) have been implemented and tested. For instructions building and converting images for vCenter, see `Building Images for Vanilla Plugin <http://sahara.readthedocs.org/en/stable-juno/userdoc/diskimagebuilder.html>`_.",storage backend for HDFS file systems) have been implemented and tested. See the `Enable Sahara support in vCenter <https://bugs.launchpad.net/fuel/+bug/1370708>`_ blueprint for implementation details. ,35,48
openstack%2Fmanila~master~If49ca92b6665114de6782d056fa17985bd160426,openstack/manila,master,If49ca92b6665114de6782d056fa17985bd160426,Cleanup manila/utils.py,MERGED,2014-12-23 09:07:32.000000000,2014-12-24 02:34:08.000000000,2014-12-24 02:34:07.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-12-23 09:07:32.000000000', 'files': ['manila/tests/test_utils.py', 'manila/utils.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/1e54c232a93b8fc483ee4c2afb0bb1dc5858488c', 'message': 'Cleanup manila/utils.py\n\nThe file has a lot of unsed code. The following code was removed:\n\nvariables:\n * ISO_TIME_FORMAT\n * PERFECT_TIME_FORMAT\n * DEFAULT_PASSWORD_SYMBOLS\n * EASIER_PASSWORD_SYMBOLS\n\nfunctions:\n * find_config\n * fetchfile\n * create_channel\n * generate_uid\n * last_completed_audit_period\n * generate_password\n * generate_username\n * last_octet\n * get_my_linklocal\n * parse_mailmap\n * xhtml_escape\n * utf8\n * is_valid_boolstr\n * is_valid_ipv4\n * make_dev_path\n * sanitize_hostname\n * hash_file\n * temporary_mutation\n * generate_mac_address\n * strcmp_const_time\n * to_bytes\n\nclasses:\n * UndoManager\n\nChange-Id: If49ca92b6665114de6782d056fa17985bd160426\n'}]",0,143630,1e54c232a93b8fc483ee4c2afb0bb1dc5858488c,13,3,1,7102,,,0,"Cleanup manila/utils.py

The file has a lot of unsed code. The following code was removed:

variables:
 * ISO_TIME_FORMAT
 * PERFECT_TIME_FORMAT
 * DEFAULT_PASSWORD_SYMBOLS
 * EASIER_PASSWORD_SYMBOLS

functions:
 * find_config
 * fetchfile
 * create_channel
 * generate_uid
 * last_completed_audit_period
 * generate_password
 * generate_username
 * last_octet
 * get_my_linklocal
 * parse_mailmap
 * xhtml_escape
 * utf8
 * is_valid_boolstr
 * is_valid_ipv4
 * make_dev_path
 * sanitize_hostname
 * hash_file
 * temporary_mutation
 * generate_mac_address
 * strcmp_const_time
 * to_bytes

classes:
 * UndoManager

Change-Id: If49ca92b6665114de6782d056fa17985bd160426
",git fetch https://review.opendev.org/openstack/manila refs/changes/30/143630/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/test_utils.py', 'manila/utils.py']",2,1e54c232a93b8fc483ee4c2afb0bb1dc5858488c,,,"import datetimeimport hashlibimport random import refrom xml.sax import saxutilsfrom oslo.utils import excutilsISO_TIME_FORMAT = ""%Y-%m-%dT%H:%M:%S"" PERFECT_TIME_FORMAT = ""%Y-%m-%dT%H:%M:%S.%f""def find_config(config_path): """"""Find a configuration file using the given hint. :param config_path: Full or relative path to the config. :returns: Full path of the config, if it exists. :raises: `manila.exception.ConfigNotFound` """""" possible_locations = [ config_path, os.path.join(CONF.state_path, ""etc"", ""manila"", config_path), os.path.join(CONF.state_path, ""etc"", config_path), os.path.join(CONF.state_path, config_path), ""/etc/manila/%s"" % config_path, ] for path in possible_locations: if os.path.exists(path): return os.path.abspath(path) raise exception.ConfigNotFound(path=os.path.abspath(config_path)) def fetchfile(url, target): LOG.debug('Fetching %s', url) execute('curl', '--fail', url, '-o', target) def create_channel(client, width, height): """"""Invoke an interactive shell session on server."""""" channel = client.invoke_shell() channel.resize_pty(width, height) return channel def generate_uid(topic, size=8): characters = '01234567890abcdefghijklmnopqrstuvwxyz' choices = [random.choice(characters) for x in xrange(size)] return '%s-%s' % (topic, ''.join(choices)) # Default symbols to use for passwords. Avoids visually confusing characters. # ~6 bits per symbol DEFAULT_PASSWORD_SYMBOLS = ('23456789', # Removed: 0,1 'ABCDEFGHJKLMNPQRSTUVWXYZ', # Removed: I, O 'abcdefghijkmnopqrstuvwxyz') # Removed: l # ~5 bits per symbol EASIER_PASSWORD_SYMBOLS = ('23456789', # Removed: 0, 1 'ABCDEFGHJKLMNPQRSTUVWXYZ') # Removed: I, O def last_completed_audit_period(unit=None): """"""This method gives you the most recently *completed* audit period. arguments: units: string, one of 'hour', 'day', 'month', 'year' Periods normally begin at the beginning (UTC) of the period unit (So a 'day' period begins at midnight UTC, a 'month' unit on the 1st, a 'year' on Jan, 1) unit string may be appended with an optional offset like so: 'day@18' This will begin the period at 18:00 UTC. 'month@15' starts a monthly period on the 15th, and year@3 begins a yearly one on March 1st. returns: 2 tuple of datetimes (begin, end) The begin timestamp of this audit period is the same as the end of the previous. """""" if not unit: unit = CONF.volume_usage_audit_period offset = 0 if '@' in unit: unit, offset = unit.split(""@"", 1) offset = int(offset) rightnow = timeutils.utcnow() if unit not in ('month', 'day', 'year', 'hour'): raise ValueError('Time period must be hour, day, month or year') if unit == 'month': if offset == 0: offset = 1 end = datetime.datetime(day=offset, month=rightnow.month, year=rightnow.year) if end >= rightnow: year = rightnow.year if 1 >= rightnow.month: year -= 1 month = 12 + (rightnow.month - 1) else: month = rightnow.month - 1 end = datetime.datetime(day=offset, month=month, year=year) year = end.year if 1 >= end.month: year -= 1 month = 12 + (end.month - 1) else: month = end.month - 1 begin = datetime.datetime(day=offset, month=month, year=year) elif unit == 'year': if offset == 0: offset = 1 end = datetime.datetime(day=1, month=offset, year=rightnow.year) if end >= rightnow: end = datetime.datetime(day=1, month=offset, year=rightnow.year - 1) begin = datetime.datetime(day=1, month=offset, year=rightnow.year - 2) else: begin = datetime.datetime(day=1, month=offset, year=rightnow.year - 1) elif unit == 'day': end = datetime.datetime(hour=offset, day=rightnow.day, month=rightnow.month, year=rightnow.year) if end >= rightnow: end = end - datetime.timedelta(days=1) begin = end - datetime.timedelta(days=1) elif unit == 'hour': end = rightnow.replace(minute=offset, second=0, microsecond=0) if end >= rightnow: end = end - datetime.timedelta(hours=1) begin = end - datetime.timedelta(hours=1) return (begin, end) def generate_password(length=20, symbolgroups=DEFAULT_PASSWORD_SYMBOLS): """"""Generate a random password from the supplied symbol groups. At least one symbol from each group will be included. Unpredictable results if length is less than the number of symbol groups. Believed to be reasonably secure (with a reasonable password length!) """""" r = random.SystemRandom() # NOTE(jerdfelt): Some password policies require at least one character # from each group of symbols, so start off with one random character # from each symbol group password = [r.choice(s) for s in symbolgroups] # If length < len(symbolgroups), the leading characters will only # be from the first length groups. Try our best to not be predictable # by shuffling and then truncating. r.shuffle(password) password = password[:length] length -= len(password) # then fill with random characters from all symbol groups symbols = ''.join(symbolgroups) password.extend([r.choice(symbols) for _i in xrange(length)]) # finally shuffle to ensure first x characters aren't from a # predictable group r.shuffle(password) return ''.join(password) def generate_username(length=20, symbolgroups=DEFAULT_PASSWORD_SYMBOLS): # Use the same implementation as the password generation. return generate_password(length, symbolgroups) def last_octet(address): return int(address.split('.')[-1]) def get_my_linklocal(interface): try: if_str = execute('ip', '-f', 'inet6', '-o', 'addr', 'show', interface) condition = '\s+inet6\s+([0-9a-f:]+)/\d+\s+scope\s+link' links = [re.search(condition, x) for x in if_str[0].split('\n')] address = [w.group(1) for w in links if w is not None] if address[0] is not None: return address[0] else: raise exception.Error(_('Link Local address is not found.:%s') % if_str) except Exception as ex: raise exception.Error(_(""Couldn't get Link Local IP of %(interface)s"" "" :%(ex)s"") % {""interface"": interface, ""ex"": ex}) def parse_mailmap(mailmap='.mailmap'): mapping = {} if os.path.exists(mailmap): fp = open(mailmap, 'r') for l in fp: l = l.strip() if not l.startswith('#') and ' ' in l: canonical_email, alias = l.split(' ') mapping[alias.lower()] = canonical_email.lower() return mapping def xhtml_escape(value): """"""Escapes a string so it is valid within XML or XHTML. """""" return saxutils.escape(value, {'""': '&quot;', ""'"": '&apos;'}) def utf8(value): """"""Try to turn a string into utf-8 if possible. Code is directly from the utf8 function in http://github.com/facebook/tornado/blob/master/tornado/escape.py """""" if isinstance(value, unicode): return value.encode('utf-8') assert isinstance(value, str) return value def is_valid_boolstr(val): """"""Check if the provided string is a valid bool string or not."""""" val = str(val).lower() return (val == 'true' or val == 'false' or val == 'yes' or val == 'no' or val == 'y' or val == 'n' or val == '1' or val == '0') def is_valid_ipv4(address): """"""Validate IPv4 address. Valid the address strictly as per format xxx.xxx.xxx.xxx. where xxx is a value between 0 and 255. """""" parts = address.split(""."") if len(parts) != 4: return False for item in parts: try: if not 0 <= int(item) <= 255: return False except ValueError: return False return True def make_dev_path(dev, partition=None, base='/dev'): """"""Return a path to a particular device. >>> make_dev_path('xvdc') /dev/xvdc >>> make_dev_path('xvdc', 1) /dev/xvdc1 """""" path = os.path.join(base, dev) if partition: path += str(partition) return path def sanitize_hostname(hostname): """"""Return a hostname which conforms to RFC-952 and RFC-1123 specs."""""" if isinstance(hostname, unicode): hostname = hostname.encode('latin-1', 'ignore') hostname = re.sub('[ _]', '-', hostname) hostname = re.sub('[^\w.-]+', '', hostname) hostname = hostname.lower() hostname = hostname.strip('.-') return hostname def hash_file(file_like_object): """"""Generate a hash for the contents of a file."""""" checksum = hashlib.sha1() any(map(checksum.update, iter(lambda: file_like_object.read(32768), ''))) return checksum.hexdigest() @contextlib.contextmanager def temporary_mutation(obj, **kwargs): """"""Temporarily set the attr on a particular object. Temporarily set the attr on a particular object to a given value then revert when finished. One use of this is to temporarily set the read_deleted flag on a context object: with temporary_mutation(context, read_deleted=""yes""): do_something_that_needed_deleted_objects() """""" NOT_PRESENT = object() old_values = {} for attr, new_value in kwargs.items(): old_values[attr] = getattr(obj, attr, NOT_PRESENT) setattr(obj, attr, new_value) try: yield finally: for attr, old_value in old_values.items(): if old_value is NOT_PRESENT: del obj[attr] else: setattr(obj, attr, old_value) def generate_mac_address(): """"""Generate an Ethernet MAC address."""""" # NOTE(vish): We would prefer to use 0xfe here to ensure that linux # bridge mac addresses don't change, but it appears to # conflict with libvirt, so we use the next highest octet # that has the unicast and locally administered bits set # properly: 0xfa. # Discussion: https://bugs.launchpad.net/manila/+bug/921838 mac = [0xfa, 0x16, 0x3e, random.randint(0x00, 0x7f), random.randint(0x00, 0xff), random.randint(0x00, 0xff)] return ':'.join(map(lambda x: ""%02x"" % x, mac)) def strcmp_const_time(s1, s2): """"""Constant-time string comparison. :params s1: the first string :params s2: the second string :return: True if the strings are equal. This function takes two strings and compares them. It is intended to be used when doing a comparison for authentication purposes to help guard against timing attacks. """""" if len(s1) != len(s2): return False result = 0 for (a, b) in zip(s1, s2): result |= ord(a) ^ ord(b) return result == 0 class UndoManager(object): """"""Provides a mechanism to facilitate rolling back a series of actions. This can be used when an exception is raised. """""" def __init__(self): self.undo_stack = [] def undo_with(self, undo_func): self.undo_stack.append(undo_func) def _rollback(self): for undo_func in reversed(self.undo_stack): undo_func() def rollback_and_reraise(self, msg=None, **kwargs): """"""Rollback a series of actions then re-raise the exception. .. note:: (sirp) This should only be called within an exception handler. """""" with excutils.save_and_reraise_exception(): if msg: LOG.exception(msg, **kwargs) self._rollback() def to_bytes(text, default=0): """"""Try to turn a string into a number of bytes. Looks at the last characters of the text to determine what conversion is needed to turn the input text into a byte number. Supports: B/b, K/k, M/m, G/g, T/t (or the same with b/B on the end). """""" BYTE_MULTIPLIERS = { '': 1, 't': 1024 ** 4, 'g': 1024 ** 3, 'm': 1024 ** 2, 'k': 1024, } # Take off everything not number 'like' (which should leave # only the byte 'identifier' left) mult_key_org = text.lstrip('-1234567890') mult_key = mult_key_org.lower() mult_key_len = len(mult_key) if mult_key.endswith(""b""): mult_key = mult_key[0:-1] try: multiplier = BYTE_MULTIPLIERS[mult_key] if mult_key_len: # Empty cases shouldn't cause text[0:-0] text = text[0:-mult_key_len] return int(text) * multiplier except KeyError: msg = _('Unknown byte multiplier: %s') % mult_key_org raise TypeError(msg) except ValueError: return default ",0,623
openstack%2Ffuel-docs~master~I263b329532c95f0aeefba6365716223e74c73bc8,openstack/fuel-docs,master,I263b329532c95f0aeefba6365716223e74c73bc8,Add the actual tasks from HA blueprint,MERGED,2014-12-22 17:28:13.000000000,2014-12-24 02:34:01.000000000,2014-12-24 02:34:01.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9546}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-22 17:28:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/87d6e374252a998f231ccf5cf5d53624c30efbe1', 'message': 'Add the actual tasks from HA blueprint\n\nChange-Id: I263b329532c95f0aeefba6365716223e74c73bc8\n'}, {'number': 2, 'created': '2014-12-23 11:05:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/45b032eeb26f2299686fc51ec2672fa99bd042f9', 'message': 'Add the actual tasks from HA blueprint\n\nChange-Id: I263b329532c95f0aeefba6365716223e74c73bc8\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 3, 'created': '2014-12-23 15:23:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/c802c461304a4e6c1637a655f288d296b20ff4c9', 'message': 'Add the actual tasks from HA blueprint\n\nChange-Id: I263b329532c95f0aeefba6365716223e74c73bc8\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 4, 'created': '2014-12-24 02:24:37.000000000', 'files': ['pages/release-notes/v6-0/new-features/ha-improve.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/d231d9404589637bb652816853fe0b6d637b344f', 'message': 'Add the actual tasks from HA blueprint\n\nChange-Id: I263b329532c95f0aeefba6365716223e74c73bc8\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}]",2,143505,d231d9404589637bb652816853fe0b6d637b344f,24,8,4,11090,,,0,"Add the actual tasks from HA blueprint

Change-Id: I263b329532c95f0aeefba6365716223e74c73bc8
Signed-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/05/143505/4 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v6-0/new-features/ha-improve.rst'],1,87d6e374252a998f231ccf5cf5d53624c30efbe1,bp/Change-Id,* OCF scripts were improved to cover more complex HA scenarios.,* :ref:`Corosync<corosync-term>` cluster communication framework was updated to version 2.0. * Installation of Pacemaker and Corosync is now a discrete stage of deployment. * Monit is now used in conjunction with Pacemaker to monitor and automatically repair critical services on OpenStack Compute nodes.,1,7
openstack%2Fmanila~master~I698797326cacd4739bac44289529200d7ca32eb4,openstack/manila,master,I698797326cacd4739bac44289529200d7ca32eb4,Remove non-active host from host_state_map,MERGED,2014-12-22 08:23:43.000000000,2014-12-24 01:56:57.000000000,2014-12-24 01:56:56.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6116}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 11878}]","[{'number': 1, 'created': '2014-12-22 08:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/c2999ec17895942a2b6e29b2d858854e689296a8', 'message': 'Remove non-active host from host_state_map\n\nRemove non-active hosts from host_state_map every time when\nscheduler handles a new request.\n\nChange-Id: I698797326cacd4739bac44289529200d7ca32eb4\nCloses-Bug: #1404800\n'}, {'number': 2, 'created': '2014-12-22 11:53:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/1302b926892369f8de8a0a3756f9f21662fdfe1d', 'message': 'Remove non-active host from host_state_map\n\nRemove non-active hosts from host_state_map every time when\nscheduler handles a new request.\n\nChange-Id: I698797326cacd4739bac44289529200d7ca32eb4\nCloses-Bug: #1404800\n'}, {'number': 3, 'created': '2014-12-22 15:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/0138f94c4dd4c90a60df236297b5bf5c4ac38e87', 'message': 'Remove non-active host from host_state_map\n\nRemove non-active hosts from host_state_map every time when\nscheduler handles a new request.\n\nChange-Id: I698797326cacd4739bac44289529200d7ca32eb4\nCloses-Bug: #1404800\n'}, {'number': 4, 'created': '2014-12-24 00:57:06.000000000', 'files': ['manila/scheduler/host_manager.py', 'manila/tests/scheduler/test_host_manager.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/90260db681d47ae22445841764b2f12938c7bab4', 'message': 'Remove non-active host from host_state_map\n\nRemove non-active hosts from host_state_map every time when\nscheduler handles a new request.\n\nChange-Id: I698797326cacd4739bac44289529200d7ca32eb4\nCloses-Bug: #1404800\n'}]",12,143394,90260db681d47ae22445841764b2f12938c7bab4,28,7,4,6116,,,0,"Remove non-active host from host_state_map

Remove non-active hosts from host_state_map every time when
scheduler handles a new request.

Change-Id: I698797326cacd4739bac44289529200d7ca32eb4
Closes-Bug: #1404800
",git fetch https://review.opendev.org/openstack/manila refs/changes/94/143394/4 && git format-patch -1 --stdout FETCH_HEAD,"['manila/scheduler/host_manager.py', 'manila/tests/scheduler/test_host_manager.py']",2,c2999ec17895942a2b6e29b2d858854e689296a8,bug/1404800," # Second test: Now service is disabled on host4 ret_services[3]['disabled'] = True with mock.patch.object(db, 'service_get_all_by_topic', mock.Mock(return_value=ret_services)): # Disabled service self.host_manager.get_all_host_states_share(context) host_state_map = self.host_manager.host_state_map self.assertEqual(len(host_state_map), 3) # Check that service is up for i in xrange(3): share_node = fakes.SHARE_SERVICES[i] host = share_node['host'] self.assertEqual(host_state_map[host].service, share_node) db.service_get_all_by_topic.assert_called_once_with(context, topic) ",,27,0
openstack%2Fneutron~master~I008dda6abaf25094b11f3730b951e096dd3b7025,openstack/neutron,master,I008dda6abaf25094b11f3730b951e096dd3b7025,Add validation for the dvr router l3agent binding,MERGED,2014-09-02 23:31:37.000000000,2014-12-24 01:55:21.000000000,2014-12-24 01:55:19.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 4187}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 7016}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8213}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10624}, {'_account_id': 10692}, {'_account_id': 10971}, {'_account_id': 12040}, {'_account_id': 12737}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-09-02 23:31:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4cf30f88cbeed787fbe9c630a4fafabf8fb95ca4', 'message': 'Add validation for the dvr router l3agent binding\n\nValidates dvr router add/remove cases to the\nl3agents running in different dvr modes such\nas ""dvr_snat"" and ""dvr"" mode.\n\nIn the case of distributed virtual routers it\ndoes not make sense to move distributed routers\nfrom one ""dvr"" node to another ""dvr"" node.\n\nPrevent a legacy router to be added to a dvr\nagent and also prevent a dvr router to be added\nto a legacy agent.\n\nOnly allow moving a dvr router with snat\nenabled into a service node.\n\nAlso added some unit tests that addresses the\nvalidation.\n\nPartial-Bug: #1348309\n\nChange-Id: I008dda6abaf25094b11f3730b951e096dd3b7025\n'}, {'number': 2, 'created': '2014-09-03 07:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6736bdb65dee6d4c0026f4dcf7a6ab2889348959', 'message': 'Add validation for the dvr router l3agent binding\n\nValidates dvr router add/remove cases to the\nl3agents running in different dvr modes such\nas ""dvr_snat"" and ""dvr"" mode.\n\nIn the case of distributed virtual routers it\ndoes not make sense to move distributed routers\nfrom one ""dvr"" node to another ""dvr"" node.\n\nPrevent a legacy router to be added to a dvr\nagent and also prevent a dvr router to be added\nto a legacy agent.\n\nOnly allow moving a dvr router with snat\nenabled into a service node.\n\nAlso added some unit tests that addresses the\nvalidation.\n\nPartial-Bug: #1348309\n\nChange-Id: I008dda6abaf25094b11f3730b951e096dd3b7025\n'}, {'number': 3, 'created': '2014-09-15 06:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d736e3a62b2aa9c10ab0d559369fefd6271278c9', 'message': 'Add validation for the dvr router l3agent binding\n\nValidates dvr router add/remove cases to the\nl3agents running in different dvr modes such\nas ""dvr_snat"" and ""dvr"" mode.\n\nIn the case of distributed virtual routers it\ndoes not make sense to move distributed routers\nfrom one ""dvr"" node to another ""dvr"" node.\n\nPrevent a legacy router to be added to a dvr\nagent and also prevent a dvr router to be added\nto a legacy agent.\n\nOnly allow moving a dvr router with snat\nenabled into a service node.\n\nAlso added some unit tests that addresses the\nvalidation.\n\nPartial-Bug: #1348309\n\nChange-Id: I008dda6abaf25094b11f3730b951e096dd3b7025\n'}, {'number': 4, 'created': '2014-09-15 18:31:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/34ddbed4dbef37719d7fca632fe4f4c0e4a50c3c', 'message': 'Add validation for the dvr router l3agent binding\n\nValidates dvr router add/remove cases to the\nl3agents running in different dvr modes such\nas ""dvr_snat"" and ""dvr"" mode.\n\nIn the case of distributed virtual routers it\ndoes not make sense to move distributed routers\nfrom one ""dvr"" node to another ""dvr"" node.\n\nPrevent a legacy router to be added to a dvr\nagent and also prevent a dvr router to be added\nto a legacy agent.\n\nOnly allow moving a dvr router with snat\nenabled into a service node.\n\nAlso added some unit tests that addresses the\nvalidation.\n\nPartial-Bug: #1348309\n\nChange-Id: I008dda6abaf25094b11f3730b951e096dd3b7025\n'}, {'number': 5, 'created': '2014-09-16 05:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0bcab58b5d5ea3919b14b94addf4004bf3e99b0e', 'message': 'Add validation for the dvr router l3agent binding\n\nValidates dvr router add/remove cases to the\nl3agents running in different dvr modes such\nas ""dvr_snat"" and ""dvr"" mode.\n\nIn the case of distributed virtual routers it\ndoes not make sense to move distributed routers\nfrom one ""dvr"" node to another ""dvr"" node.\n\nOnly allow moving a dvr router with snat\nenabled into a service node.\n\nAlso added some unit tests that addresses the\nvalidation of legacy routers to dvr agent and\ndvr routers to legacy agent.\n\nChange-Id: I008dda6abaf25094b11f3730b951e096dd3b7025\n'}, {'number': 6, 'created': '2014-09-17 05:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1b98cfd9eefe6f95e628b5d9527d37da11dcdf99', 'message': 'Add validation for the dvr router l3agent binding\n\nValidates dvr router add/remove cases to the\nl3agents running in different dvr modes such\nas ""dvr_snat"" and ""dvr"" mode.\n\nIn the case of distributed virtual routers it\ndoes not make sense to move distributed routers\nfrom one ""dvr"" node to another ""dvr"" node.\n\nOnly allow moving a dvr router with snat\nenabled into a service node.\n\nAlso added some unit tests that addresses the\nvalidation of legacy routers to dvr agent and\ndvr routers to legacy agent.\n\nChange-Id: I008dda6abaf25094b11f3730b951e096dd3b7025\n'}, {'number': 7, 'created': '2014-09-26 17:02:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/32f8049c801a006230c26c6f355d7e7f060a1aa5', 'message': 'Add validation for the dvr router l3agent binding\n\nValidates dvr router add/remove cases to the\nl3agents running in different dvr modes such\nas ""dvr_snat"" and ""dvr"" mode.\n\nIn the case of distributed virtual routers it\ndoes not make sense to move distributed routers\nfrom one ""dvr"" node to another ""dvr"" node.\n\nOnly allow moving a dvr router with snat\nenabled into a service node.\n\nAlso added some unit tests that addresses the\nvalidation of legacy routers to dvr agent and\ndvr routers to legacy agent.\n\nPartial-Bug: #1369721\n\nChange-Id: I008dda6abaf25094b11f3730b951e096dd3b7025\n'}, {'number': 8, 'created': '2014-09-26 22:52:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/90e022a2baeddccb9e049a4cafe8244fe316baff', 'message': 'Add validation for the dvr router l3agent binding\n\nValidates dvr router add/remove cases to the\nl3agents running in different dvr modes such\nas ""dvr_snat"" and ""dvr"" mode.\n\nIn the case of distributed virtual routers it\ndoes not make sense to move distributed routers\nfrom one ""dvr"" node to another ""dvr"" node.\n\nOnly allow moving a dvr router with snat\nenabled into a service node.\n\nAlso added some unit tests that addresses the\nvalidation of legacy routers to dvr agent and\ndvr routers to legacy agent.\n\nPartial-Bug: #1369721\n\nChange-Id: I008dda6abaf25094b11f3730b951e096dd3b7025\n'}, {'number': 9, 'created': '2014-09-26 23:04:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2e7468759eb6999e61dd908c138e1cf467b18996', 'message': 'Add validation for the dvr router l3agent binding\n\nValidates dvr router add/remove cases to the\nl3agents running in different dvr modes such\nas ""dvr_snat"" and ""dvr"" mode.\n\nIn the case of distributed virtual routers it\ndoes not make sense to move distributed routers\nfrom one ""dvr"" node to another ""dvr"" node.\n\nOnly allow moving a dvr router with snat\nenabled into a service node.\n\nAlso added some unit tests that addresses the\nvalidation of legacy routers to dvr agent and\ndvr routers to legacy agent.\n\nPartial-Bug: #1369721\n\nChange-Id: I008dda6abaf25094b11f3730b951e096dd3b7025\n'}, {'number': 10, 'created': '2014-12-03 02:34:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/35b7f9106254a641aeecf0262cb2bc3048ca6438', 'message': 'Add validation for the dvr router l3agent binding\n\nValidates dvr router add/remove cases to the\nl3agents running in different dvr modes such\nas ""dvr_snat"" and ""dvr"" mode.\n\nIn the case of distributed virtual routers it\ndoes not make sense to move distributed routers\nfrom one ""dvr"" node to another ""dvr"" node.\n\nOnly allow moving a dvr router with snat\nenabled into a service node.\n\nAlso added some unit tests that addresses the\nvalidation of legacy routers to dvr agent and\ndvr routers to legacy agent.\n\nPartial-Bug: #1369721\n\nChange-Id: I008dda6abaf25094b11f3730b951e096dd3b7025\n'}, {'number': 11, 'created': '2014-12-04 21:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/52f796f980aac748fc62ccd9c181d6d9b1b636c2', 'message': 'Add validation for the dvr router l3agent binding\n\nValidates dvr router add/remove cases to the\nl3agents running in different dvr modes such\nas ""dvr_snat"" and ""dvr"" mode.\n\nIn the case of distributed virtual routers it\ndoes not make sense to move distributed routers\nfrom one ""dvr"" node to another ""dvr"" node.\n\nAlso added some unit tests that addresses the\nvalidation of legacy routers to dvr agent and\ndvr routers to legacy agent.\n\nPartial-Bug: #1369721\n\nChange-Id: I008dda6abaf25094b11f3730b951e096dd3b7025\n'}, {'number': 12, 'created': '2014-12-19 20:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0f46380554044ad164c93a1028e2a1c7cf162ffb', 'message': 'Add validation for the dvr router l3agent binding\n\nValidates dvr router add/remove cases to the\nl3agents running in different dvr modes such\nas ""dvr_snat"" and ""dvr"" mode.\n\nIn the case of distributed virtual routers it\ndoes not make sense to move distributed routers\nfrom one ""dvr"" node to another ""dvr"" node.\n\nAlso added some unit tests that addresses the\nvalidation of legacy routers to dvr agent and\ndvr routers to legacy agent.\n\nPartial-Bug: #1369721\n\nChange-Id: I008dda6abaf25094b11f3730b951e096dd3b7025\n'}, {'number': 13, 'created': '2014-12-19 22:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8db958eee9f80896642d2226fb8524a9bdc5a675', 'message': 'Add validation for the dvr router l3agent binding\n\nValidates dvr router add/remove cases to the\nl3agents running in different dvr modes such\nas ""dvr_snat"" and ""dvr"" mode.\n\nIn the case of distributed virtual routers it\ndoes not make sense to move distributed routers\nfrom one ""dvr"" node to another ""dvr"" node.\n\nAlso added some unit tests that addresses the\nvalidation of legacy routers to dvr agent and\ndvr routers to legacy agent.\n\nPartial-Bug: #1369721\n\nChange-Id: I008dda6abaf25094b11f3730b951e096dd3b7025\n'}, {'number': 14, 'created': '2014-12-23 19:40:22.000000000', 'files': ['neutron/tests/unit/test_l3_schedulers.py', 'neutron/extensions/l3agentscheduler.py', 'neutron/db/l3_agentschedulers_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7e65529923953c815e77d726b56f94635367532f', 'message': 'Add validation for the dvr router l3agent binding\n\nValidates dvr router add/remove cases to the\nl3agents running in different dvr modes such\nas ""dvr_snat"" and ""dvr"" mode.\n\nIn the case of distributed virtual routers it\ndoes not make sense to move distributed routers\nfrom one ""dvr"" node to another ""dvr"" node.\n\nAlso added some unit tests that addresses the\nvalidation of legacy routers to dvr agent and\ndvr routers to legacy agent.\n\nPartial-Bug: #1369721\n\nChange-Id: I008dda6abaf25094b11f3730b951e096dd3b7025\n'}]",62,118491,7e65529923953c815e77d726b56f94635367532f,403,39,14,7016,,,0,"Add validation for the dvr router l3agent binding

Validates dvr router add/remove cases to the
l3agents running in different dvr modes such
as ""dvr_snat"" and ""dvr"" mode.

In the case of distributed virtual routers it
does not make sense to move distributed routers
from one ""dvr"" node to another ""dvr"" node.

Also added some unit tests that addresses the
validation of legacy routers to dvr agent and
dvr routers to legacy agent.

Partial-Bug: #1369721

Change-Id: I008dda6abaf25094b11f3730b951e096dd3b7025
",git fetch https://review.opendev.org/openstack/neutron refs/changes/91/118491/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_l3_schedulers.py', 'neutron/extensions/l3agentscheduler.py', 'neutron/db/l3_agentschedulers_db.py']",3,4cf30f88cbeed787fbe9c630a4fafabf8fb95ca4,validate-migration," router_type = ('distributed' if is_distributed else 'centralized') if agent_mode == 'dvr' and is_distributed: raise l3agentscheduler.DVRL3AgentMoveNotAllowed( router_type=router_type, router_id=router['id'], agent_mode=agent_mode, agent_id=agent['id']) if (agent_mode == 'dvr_snat' and is_distributed and not router.get('external_gateway_info', None)): raise l3agentscheduler.DVRSnatMoveNotAllowed( router_type=router_type, router_id=router['id'], agent_mode=agent_mode, agent_id=agent['id']) ", router_type = ('distributed' if is_distributed else 'centralized'),169,9
openstack%2Frally~master~Ic18dc90820a518828344db8891744d26173a9855,openstack/rally,master,Ic18dc90820a518828344db8891744d26173a9855,Move files to common lib(Part 1),MERGED,2014-12-22 06:54:29.000000000,2014-12-24 01:40:33.000000000,2014-12-24 01:40:32.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 9545}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-22 06:54:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e2928760a539d4eac4dbe719ad84138c179dd99b', 'message': 'Move files to common lib(Part 1)\n\nMove broker.py, fileutils.py, sshutils.py and version.py to common\ndirectory.\n\nChange-Id: Ic18dc90820a518828344db8891744d26173a9855\n'}, {'number': 2, 'created': '2014-12-22 07:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/95583fe87215c9e5f6767e5221e02ec5cb001f39', 'message': 'Move files to common lib(Part 1)\n\nMove broker.py, fileutils.py, sshutils.py and version.py to common\ndirectory.\n\nChange-Id: Ic18dc90820a518828344db8891744d26173a9855\n'}, {'number': 3, 'created': '2014-12-24 00:26:13.000000000', 'files': ['rally/common/broker.py', 'rally/benchmark/scenarios/vm/utils.py', 'rally/common/fileutils.py', 'tests/unit/deploy/serverprovider/test_provider.py', 'tests/unit/test_utils.py', 'tests/unit/common/test_broker.py', 'rally/common/version.py', 'tests/unit/benchmark/scenarios/vm/test_utils.py', 'tests/unit/common/test_fileutils.py', 'rally/cmd/commands/use.py', 'tests/unit/common/__init__.py', 'rally/benchmark/context/cleanup/manager.py', 'rally/common/__init__.py', 'rally/common/sshutils.py', 'tests/unit/common/test_sshutils.py', 'rally/deploy/serverprovider/provider.py', 'rally/cmd/cliutils.py', 'rally/cmd/envutils.py', 'rally/benchmark/context/users.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/9aec997bf7e770c30e04d55adfab95d4df21139a', 'message': 'Move files to common lib(Part 1)\n\nMove broker.py, fileutils.py, sshutils.py and version.py to common\ndirectory.\n\nChange-Id: Ic18dc90820a518828344db8891744d26173a9855\n'}]",0,143376,9aec997bf7e770c30e04d55adfab95d4df21139a,49,6,3,4428,,,0,"Move files to common lib(Part 1)

Move broker.py, fileutils.py, sshutils.py and version.py to common
directory.

Change-Id: Ic18dc90820a518828344db8891744d26173a9855
",git fetch https://review.opendev.org/openstack/rally refs/changes/76/143376/2 && git format-patch -1 --stdout FETCH_HEAD,"['rally/common/broker.py', 'tests/unit/test_broker.py', 'rally/benchmark/scenarios/vm/utils.py', 'rally/common/fileutils.py', 'tests/unit/deploy/serverprovider/test_provider.py', 'rally/common/version.py', 'rally/cmd/commands/use.py', 'rally/benchmark/context/cleanup/manager.py', 'rally/common/__init__.py', 'rally/common/sshutils.py', 'rally/deploy/serverprovider/provider.py', 'tests/unit/test_sshutils.py', 'rally/cmd/cliutils.py', 'tests/unit/test_fileutils.py', 'rally/cmd/envutils.py', 'rally/benchmark/context/users.py']",16,e2928760a539d4eac4dbe719ad84138c179dd99b,common-lib,from rally.common import broker,from rally import broker,11,11
openstack%2Ftempest~master~I07eb4af34b20ae94a09b6fa90ffeb3bc19e14762,openstack/tempest,master,I07eb4af34b20ae94a09b6fa90ffeb3bc19e14762,Add ObjectStorageClient for cleanup,MERGED,2014-12-17 08:55:11.000000000,2014-12-24 01:33:27.000000000,2014-12-24 01:33:26.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 8859}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 08:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8e9140b700f6d2bc533539fc00608f8bdfa14c78', 'message': 'Add ObjectStorageClient for cleanup\n\nIn object storage clients, there is a lot of duplicated code for\nsetting CONF. This patch adds ObjectStorageClient for removing them.\n\nChange-Id: I07eb4af34b20ae94a09b6fa90ffeb3bc19e14762\n'}, {'number': 2, 'created': '2014-12-17 12:55:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2f9983de01fdccba02d13a6decab38b7194c64eb', 'message': 'Add ObjectStorageClient for cleanup\n\nIn object storage clients, there is a lot of duplicated code for\nsetting CONF. This patch adds ObjectStorageClient for removing them.\n\nChange-Id: I07eb4af34b20ae94a09b6fa90ffeb3bc19e14762\n'}, {'number': 3, 'created': '2014-12-17 12:59:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d1fa4be29c110d427bfbb1e9a27b2fa13eb7665c', 'message': 'Add ObjectStorageClient for cleanup\n\nIn object storage clients, there is a lot of duplicated code for\nsetting CONF. This patch adds ObjectStorageClient for removing them.\n\nChange-Id: I07eb4af34b20ae94a09b6fa90ffeb3bc19e14762\n'}, {'number': 4, 'created': '2014-12-17 13:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4e658302edb0c4a149d8d878c9d3a1e48ae2a725', 'message': 'Add ObjectStorageClient for cleanup\n\nIn object storage clients, there is a lot of duplicated code for\nsetting CONF. This patch adds ObjectStorageClient for removing them.\n\nChange-Id: I07eb4af34b20ae94a09b6fa90ffeb3bc19e14762\n'}, {'number': 5, 'created': '2014-12-18 00:09:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/be663a4d3c98aaa7b496692bad6859d547798fab', 'message': 'Add ObjectStorageClient for cleanup\n\nIn object storage clients, there is a lot of duplicated code for\nsetting CONF. This patch adds ObjectStorageClient for removing them.\n\nChange-Id: I07eb4af34b20ae94a09b6fa90ffeb3bc19e14762\n'}, {'number': 6, 'created': '2014-12-18 04:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d450de7ef6cfb2197b7c46b29e5a6979c2079c94', 'message': 'Add ObjectStorageClient for cleanup\n\nIn object storage clients, there is a lot of duplicated code for\nsetting CONF. This patch adds ObjectStorageClient for removing them.\n\nChange-Id: I07eb4af34b20ae94a09b6fa90ffeb3bc19e14762\n'}, {'number': 7, 'created': '2014-12-19 11:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/311e811fbfe8e9bc041d45539f8e3d538907f566', 'message': 'Add ObjectStorageClient for cleanup\n\nIn object storage clients, there is a lot of duplicated code for\nsetting CONF. This patch adds ObjectStorageClient for removing them.\n\nChange-Id: I07eb4af34b20ae94a09b6fa90ffeb3bc19e14762\n'}, {'number': 8, 'created': '2014-12-21 13:13:18.000000000', 'files': ['tempest/services/object_storage/account_client.py', 'tempest/services/object_storage/object_client.py', 'tempest/services/object_storage/container_client.py', 'tempest/services/object_storage/base.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/de398ac8b8660c31b42099cccf7994fd2f382ddd', 'message': 'Add ObjectStorageClient for cleanup\n\nIn object storage clients, there is a lot of duplicated code for\nsetting CONF. This patch adds ObjectStorageClient for removing them.\n\nChange-Id: I07eb4af34b20ae94a09b6fa90ffeb3bc19e14762\n'}]",2,142384,de398ac8b8660c31b42099cccf7994fd2f382ddd,33,7,8,6167,,,0,"Add ObjectStorageClient for cleanup

In object storage clients, there is a lot of duplicated code for
setting CONF. This patch adds ObjectStorageClient for removing them.

Change-Id: I07eb4af34b20ae94a09b6fa90ffeb3bc19e14762
",git fetch https://review.opendev.org/openstack/tempest refs/changes/84/142384/5 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/object_storage/account_client.py', 'tempest/services/object_storage/object_client.py', 'tempest/services/object_storage/container_client.py', 'tempest/services/object_storage/base.py']",4,8e9140b700f6d2bc533539fc00608f8bdfa14c78,rest-client,"# Copyright 2014 NEC Corporation. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.common import rest_client from tempest import config CONF = config.CONF class ObjectStorageClient(rest_client.RestClient): """""" Base object storage client class """""" def __init__(self, auth_provider): super(ObjectStorageClient, self).__init__(auth_provider) self.service = CONF.object_storage.catalog_type self.headers = {} self.format = 'json' ",,38,39
openstack%2Ftempest~master~I314cb514fda9cb3afd1e110048d527a392e7fa5c,openstack/tempest,master,I314cb514fda9cb3afd1e110048d527a392e7fa5c,Unskip test_create_delete_server_group_with_multiple_policies(),ABANDONED,2014-09-15 14:15:16.000000000,2014-12-24 01:19:19.000000000,,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-15 14:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b48c137878c4a49dbb856cc1ac9b3575c5f9b403', 'message': 'Unkip test_create_delete_server_group_with_multiple_policies()\n\ntest_create_delete_server_group_with_multiple_policies() was skipped\nbecause of bug 1324348 which is now in a state which should allow us\nto unskip it.\n\nChange-Id: I314cb514fda9cb3afd1e110048d527a392e7fa5c\nRelated-Bug: #1324348\n'}, {'number': 2, 'created': '2014-09-15 14:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/be16440fc3be9c61b2efc087feb0bb51f331192b', 'message': 'Unskip test_create_delete_server_group_with_multiple_policies()\n\ntest_create_delete_server_group_with_multiple_policies() was skipped\nbecause of bug 1324348 which is now in a state which should allow us\nto unskip it.\n\nChange-Id: I314cb514fda9cb3afd1e110048d527a392e7fa5c\nRelated-Bug: #1324348\n'}, {'number': 3, 'created': '2014-11-20 03:40:00.000000000', 'files': ['tempest/api/compute/servers/test_server_group.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/69ac80e9b052cfe804c47d5951b719d0d140de77', 'message': 'Unskip test_create_delete_server_group_with_multiple_policies()\n\ntest_create_delete_server_group_with_multiple_policies() was skipped\nbecause of bug 1324348 which is now in a state which should allow us\nto unskip it.\n\nChange-Id: I314cb514fda9cb3afd1e110048d527a392e7fa5c\nRelated-Bug: #1324348\n'}]",0,121574,69ac80e9b052cfe804c47d5951b719d0d140de77,11,4,3,5196,,,0,"Unskip test_create_delete_server_group_with_multiple_policies()

test_create_delete_server_group_with_multiple_policies() was skipped
because of bug 1324348 which is now in a state which should allow us
to unskip it.

Change-Id: I314cb514fda9cb3afd1e110048d527a392e7fa5c
Related-Bug: #1324348
",git fetch https://review.opendev.org/openstack/tempest refs/changes/74/121574/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_server_group.py'],1,b48c137878c4a49dbb856cc1ac9b3575c5f9b403,bug/1364166,," @test.skip_because(bug=""1324348"")",0,1
openstack%2Ffuel-docs~master~Id20a2a5a03a5f67e7e7619cf71fa9b088ed50490,openstack/fuel-docs,master,Id20a2a5a03a5f67e7e7619cf71fa9b088ed50490,Multiple L3 Agents,MERGED,2014-12-18 12:17:34.000000000,2014-12-24 01:12:43.000000000,2014-12-24 01:12:42.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8829}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-12-18 12:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/5e00cc828a4f40ce9f1198d356d1fa160fefc1f6', 'message': 'Multiple L3 Agents\n\nThe primary customer-facing change is the change from the\np_neutron-l3-agent resource to clone_p_neutron-l3-agent.\nThis substitution was made.\n\nWe do not currently document L3 agents in our docs so I put\nthe brief blurb about this feature in the intro to the\nCorosync/Pacemaker troubleshooting section, which is where\nalmost all the occurrences of the p_neutron-l3-agent occur.\n\nChange-Id: Id20a2a5a03a5f67e7e7619cf71fa9b088ed50490\n'}, {'number': 2, 'created': '2014-12-19 13:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/b243222542616f1fcb8648a29d7a916dc0b62ea7', 'message': 'Multiple L3 Agents\n\nAdded ""L3 Agents"" article to this commit to include some\nbackground information about this feature.\n\nAdded note to ops-guide/troubleshoot/9100-tshoot-corosync-pacemaker\nabout the clone_p_neutron-l3-agent resource\n\nAdded ""New Feature"" article to the Release Notes\n\nChange-Id: Id20a2a5a03a5f67e7e7619cf71fa9b088ed50490\n'}, {'number': 3, 'created': '2014-12-19 18:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/910c202261031eede91fc0b9ecac63ef351aa60a', 'message': 'Multiple L3 Agents\n\nAdded ""L3 Agents"" article to this commit to include some\nbackground information about this feature.\n\nAdded note to ops-guide/troubleshoot/9100-tshoot-corosync-pacemaker\nabout the clone_p_neutron-l3-agent resource\n\nAdded ""New Feature"" article to the Release Notes\n\nChange-Id: Id20a2a5a03a5f67e7e7619cf71fa9b088ed50490\n'}, {'number': 4, 'created': '2014-12-22 21:13:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/69f5e1de337a5f4be5a580148e997dc07ede4564', 'message': 'Multiple L3 Agents\n\nAdded ""L3 Agents"" article to this commit to include some\nbackground information about this feature.\n\nAdded note to ops-guide/troubleshoot/9100-tshoot-corosync-pacemaker\nabout the clone_p_neutron-l3-agent resource\n\nAdded ""New Feature"" article to the Release Notes\n\nChange-Id: Id20a2a5a03a5f67e7e7619cf71fa9b088ed50490\n'}, {'number': 5, 'created': '2014-12-22 21:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/6577babe312ca2d4d3396d5915d561c97701eb55', 'message': 'Multiple L3 Agents\n\nAdded ""L3 Agents"" article to this commit to include some\nbackground information about this feature.\n\nAdded note to ops-guide/troubleshoot/9100-tshoot-corosync-pacemaker\nabout the clone_p_neutron-l3-agent resource\n\nAdded ""New Feature"" article to the Release Notes\n\nChange-Id: Id20a2a5a03a5f67e7e7619cf71fa9b088ed50490\n'}, {'number': 6, 'created': '2014-12-23 20:22:24.000000000', 'files': ['pages/operations/troubleshoot/9100-tshoot-corosync-pacemaker.rst', 'pages/operations/troubleshoot/9105-crm-resources.rst', 'pages/reference-architecture/ha-notes/0130-how-fuel-deploys-ha.rst', 'pages/release-notes/v6-0/0020-new-features.rst', 'pages/release-notes/v6-0/new-features/l3-multiple-agents.rst', 'pages/terminology/allterms.rst', 'pages/operations/troubleshoot/9110-verify-neutron-ha-crm.rst', 'pages/terminology/l/l3-agent.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/6b13704f9804f459c775827963ca99a1456eee95', 'message': 'Multiple L3 Agents\n\nAdded ""L3 Agents"" article to this commit to include some\nbackground information about this feature.\n\nAdded note to ops-guide/troubleshoot/9100-tshoot-corosync-pacemaker\nabout the clone_p_neutron-l3-agent resource\n\nAdded ""New Feature"" article to the Release Notes\n\nChange-Id: Id20a2a5a03a5f67e7e7619cf71fa9b088ed50490\n'}]",54,142751,6b13704f9804f459c775827963ca99a1456eee95,43,9,6,10014,,,0,"Multiple L3 Agents

Added ""L3 Agents"" article to this commit to include some
background information about this feature.

Added note to ops-guide/troubleshoot/9100-tshoot-corosync-pacemaker
about the clone_p_neutron-l3-agent resource

Added ""New Feature"" article to the Release Notes

Change-Id: Id20a2a5a03a5f67e7e7619cf71fa9b088ed50490
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/51/142751/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/operations/troubleshoot/9100-tshoot-corosync-pacemaker.rst', 'pages/operations/ha-testing-scenarios-ops.rst', 'pages/operations/troubleshoot/9105-crm-resources.rst', 'pages/reference-architecture/ha-notes/0130-how-fuel-deploys-ha.rst', 'pages/operations/troubleshoot/9110-verify-neutron-ha-crm.rst']",5,5e00cc828a4f40ce9f1198d356d1fa160fefc1f6,l3, clone_p_neutron-plugin-openvswitch-agent (ocf::pacemaker:neutron-agent-ovs): Started fuel-controller-02 clone_p_neutron-dhcp-agent (ocf::pacemaker:neutron-agent-dhcp): Started fuel-controller-02 clone_p_neutron-l3-agent (ocf::pacemaker:neutron-agent-l3): Started fuel-controller-02, p_neutron-plugin-openvswitch-agent (ocf::pacemaker:neutron-agent-ovs): Started fuel-controller-02 p_neutron-dhcp-agent (ocf::pacemaker:neutron-agent-dhcp): Started fuel-controller-02 p_neutron-l3-agent (ocf::pacemaker:neutron-agent-l3): Started fuel-controller-02,40,26
openstack%2Ffuel-docs~master~Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870,openstack/fuel-docs,master,Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870,Describes NSX+vCenter support,MERGED,2014-10-30 12:49:55.000000000,2014-12-24 01:11:37.000000000,2014-12-23 19:05:34.000000000,"[{'_account_id': 3}, {'_account_id': 8074}, {'_account_id': 8787}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 11163}, {'_account_id': 11427}, {'_account_id': 12139}, {'_account_id': 12415}, {'_account_id': 13082}, {'_account_id': 13306}]","[{'number': 1, 'created': '2014-10-30 12:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/509a7c697a4f9f2a5dca2b6cb0f7742a8a6d435a', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 2, 'created': '2014-10-30 12:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/edbbc3b433efc0511999e66211009e889eb2e322', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 3, 'created': '2014-10-30 13:27:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/5c60bc6580f47ae0842e29aa56f5daf53febc48e', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 4, 'created': '2014-10-30 14:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/aa538ac5e28cde80522d9d0628d74037e52f90ff', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 5, 'created': '2014-10-30 14:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f3abe41570ec4261f58951db42610b3083e64476', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 6, 'created': '2014-10-30 15:10:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/c547824d8a5758ec0aa6a6ec9db53cd2679fa727', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 7, 'created': '2014-11-05 13:49:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/7edcf41155e6d4fc7739614ec06cf62ce3541550', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 8, 'created': '2014-11-06 07:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a32acaf39ed28e40256b1e5fbe66e92d8f45c885', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 9, 'created': '2014-11-11 11:21:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f700870678dceeaed041eb9c23e50afccfb1bba5', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 10, 'created': '2014-11-14 10:04:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/09286ba853a15147f8742504693c278d6c629698', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 11, 'created': '2014-11-18 07:55:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/fff46b01c74c1e09f4519425c5902b05fe70b134', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 12, 'created': '2014-11-27 09:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/aa77d70e2c67b39722a078c3665137f96d9ea61e', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 13, 'created': '2014-11-28 15:56:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/cdd69ff4804840a1e03ade1edbb0bcb0be109dac', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 14, 'created': '2014-12-01 07:51:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/90c170eb367d1d0b340dbfef98aa9fb901e52b25', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 15, 'created': '2014-12-01 11:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/78682788b116fbdfc72525419e7347d9739dbe2a', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 16, 'created': '2014-12-02 08:36:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/6e9616b6a9f9b0cc8783790c94ff222f7011e1e7', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 17, 'created': '2014-12-02 12:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/21f1d854766dfd9f17a04831f6c40efe012782e1', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 18, 'created': '2014-12-02 12:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/99993de2af144d478a2c1ffce533eed5336673fd', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 19, 'created': '2014-12-04 12:06:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/55aa7e7f88bae93420b3d9cbd9e2430761dfbbe1', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 20, 'created': '2014-12-08 13:43:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/cf1fecf2e3286d9a3e8d6d5cf05296f8900f3b7a', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 21, 'created': '2014-12-08 13:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/e6d3e1949a6d5992ad833509d845853a9495a0b5', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 22, 'created': '2014-12-12 07:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/3f645a992434d8711bf8b9c292813e874d8e313b', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 23, 'created': '2014-12-12 10:37:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/56a39e4e78bd615e137e7179192087bd908516ad', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 24, 'created': '2014-12-15 08:15:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/8af75eb778430dabd2e5dcdcdfc8819527b7823b', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 25, 'created': '2014-12-18 07:55:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/0f6ac1228419ad87532270361be80ac91cb34b6c', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 26, 'created': '2014-12-18 13:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/8e8dcd3549d5244c45820aa7bc241019270248fb', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 27, 'created': '2014-12-22 13:26:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/7daeb7329e572c440a0a45961ff6d65df7855f6a', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}, {'number': 28, 'created': '2014-12-23 06:48:13.000000000', 'files': ['_images/user_screen_shots/nsx-networking.png', '_images/nsx-vcenter-arch.png', '_images/nsx-vswitch11.png', '_images/nsx-vswitch5.png', '_images/nsx-vswitch2.png', 'pages/planning-guide/7000-nsx-plan.rst', 'pages/user-guide/7310-nsx.rst', '_images/nsx-vswitch3.png', '_images/nsx-vswitch12.png', '_images/nsx-vswitch7.png', '_images/nsx-vswitch9.png', 'pages/reference-architecture/neutron-intro/0270-nsx.rst', '_images/nsx-vswitch10.png', '_images/nsx-vswitch6.png', '_images/user_screen_shots/nsx-create-env.png', 'pages/terminology/e/experimental-features.rst', '_images/nsx-vswitch1.png', '_images/nsx-vswitch13.png', '_images/vcenter-nsx-settings.png', '_images/nsx-vswitch4.png', '_images/nsx-vswitch8.png'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f64eae9ba23dc75ec54791a4b91ca27762f2656c', 'message': 'Describes NSX+vCenter support\n\n* Add changes into Planning Guide\n* Add changes into User Guide (Fuel)\n* Add changes into Reference Architecture (Neutron+NSX)\n\nChange-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870\nImplements: blueprint vcenter-nsx-support\n'}]",87,132014,f64eae9ba23dc75ec54791a4b91ca27762f2656c,170,13,28,13082,,,0,"Describes NSX+vCenter support

* Add changes into Planning Guide
* Add changes into User Guide (Fuel)
* Add changes into Reference Architecture (Neutron+NSX)

Change-Id: Ic758dc3fad5250ec4fe0bae24d5e260a2fe9a870
Implements: blueprint vcenter-nsx-support
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/14/132014/1 && git format-patch -1 --stdout FETCH_HEAD,"['_images/nsx-vswitch11.png', '_images/nsx-vswitch5.png', '_images/nsx-vswitch2.png', 'pages/planning-guide/7000-nsx-plan.rst', '_images/nsx-vswitch3.png', '_images/nsx-vswitch12.png', '_images/nsx-vswitch7.png', '_images/nsx-vswitch9.png', '_images/nsx-vswitch10.png', '_images/nsx-vswitch6.png', '_images/nsx-vswitch1.png', '_images/nsx-vswitch13.png', '_images/nsx-vswitch4.png', '_images/nsx-vswitch8.png']",14,509a7c697a4f9f2a5dca2b6cb0f7742a8a6d435a,bp/vcenter-nsx-support,,,225,1
openstack%2Fcinder~master~I33adf99ca25a2d8f869de5bfa85b4ca8429be05e,openstack/cinder,master,I33adf99ca25a2d8f869de5bfa85b4ca8429be05e,Fix format errors in brick/iscsi LOG messages,MERGED,2014-12-19 19:29:08.000000000,2014-12-24 00:34:44.000000000,2014-12-23 08:07:35.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 6491}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 13900}, {'_account_id': 14206}]","[{'number': 1, 'created': '2014-12-19 19:29:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/26d9a16cf00bebd2412e196ff3f167116b56c75e', 'message': 'Fix format errors in brick/iscsi LOG messages\n\nCurrently in cinder.brick.iscsi.iscs:LioADM.create_iscsi_target\nThe Log message for the exception is:\n  LOG.error(""%s"" % e),\n\nThis rightfully results in:\n  *** UnicodeError: UnicodeError(u\'Message objects\n      do not support str() because they may contain\n      non-ascii characters. Please use unicode() or\n      translate() instead.\',)\n\nIn some cases this causes the Volume service to stop and\ndoesn\'t help a ton with debug. While looking at this also\nnoticed a number of other similar cases where invalid LOG\nmessages were set up.  Following the i8n guidelines here:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nWent ahead and cleaned the bulk of the LOG messages in this\nfile up to adhere to the guidelines as well as fixing the\nUnicodeError described in the bug.\n\nChange-Id: I33adf99ca25a2d8f869de5bfa85b4ca8429be05e\n'}, {'number': 2, 'created': '2014-12-21 18:23:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dbc669a3e1912b08ef332eb6fef8bcee4dc453b2', 'message': 'Fix format errors in brick/iscsi LOG messages\n\nCurrently in cinder.brick.iscsi.iscs:LioADM.create_iscsi_target\nThe Log message for the exception is:\n  LOG.error(""%s"" % e),\n\nThis rightfully results in:\n  *** UnicodeError: UnicodeError(u\'Message objects\n      do not support str() because they may contain\n      non-ascii characters. Please use unicode() or\n      translate() instead.\',)\n\nIn some cases this causes the Volume service to stop and\ndoesn\'t help a ton with debug. While looking at this also\nnoticed a number of other similar cases where invalid LOG\nmessages were set up.  Following the i8n guidelines here:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nWent ahead and cleaned the bulk of the LOG messages in this\nfile up to adhere to the guidelines as well as fixing the\nUnicodeError described in the bug.\n\nChange-Id: I33adf99ca25a2d8f869de5bfa85b4ca8429be05e\n'}, {'number': 3, 'created': '2014-12-22 21:24:13.000000000', 'files': ['cinder/brick/iscsi/iscsi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3e1ea2c99859d1304a1db2562d931e85dbfb9093', 'message': 'Fix format errors in brick/iscsi LOG messages\n\nCurrently in cinder.brick.iscsi.iscs:LioADM.create_iscsi_target\nThe Log message for the exception is:\n  LOG.error(""%s"" % e),\n\nThis rightfully results in:\n  *** UnicodeError: UnicodeError(u\'Message objects\n      do not support str() because they may contain\n      non-ascii characters. Please use unicode() or\n      translate() instead.\',)\n\nIn some cases this causes the Volume service to stop and\ndoesn\'t help a ton with debug. While looking at this also\nnoticed a number of other similar cases where invalid LOG\nmessages were set up.  Following the i8n guidelines here:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nWent ahead and cleaned the bulk of the LOG messages in this\nfile up to adhere to the guidelines as well as fixing the\nUnicodeError described in the bug.\n\nChange-Id: I33adf99ca25a2d8f869de5bfa85b4ca8429be05e\n'}]",17,143162,3e1ea2c99859d1304a1db2562d931e85dbfb9093,46,16,3,2243,,,0,"Fix format errors in brick/iscsi LOG messages

Currently in cinder.brick.iscsi.iscs:LioADM.create_iscsi_target
The Log message for the exception is:
  LOG.error(""%s"" % e),

This rightfully results in:
  *** UnicodeError: UnicodeError(u'Message objects
      do not support str() because they may contain
      non-ascii characters. Please use unicode() or
      translate() instead.',)

In some cases this causes the Volume service to stop and
doesn't help a ton with debug. While looking at this also
noticed a number of other similar cases where invalid LOG
messages were set up.  Following the i8n guidelines here:
http://docs.openstack.org/developer/oslo.i18n/guidelines.html

Went ahead and cleaned the bulk of the LOG messages in this
file up to adhere to the guidelines as well as fixing the
UnicodeError described in the bug.

Change-Id: I33adf99ca25a2d8f869de5bfa85b4ca8429be05e
",git fetch https://review.opendev.org/openstack/cinder refs/changes/62/143162/3 && git format-patch -1 --stdout FETCH_HEAD,['cinder/brick/iscsi/iscsi.py'],1,26d9a16cf00bebd2412e196ff3f167116b56c75e,bug/1402078," ""iscsi backing lun for Volume "" ""ID: %(vol_id)s: %(e)s"") % {'vol_id': vol_id, 'e': e}) LOG.debug('Failed to find CHAP auth from config for %s', vol_id) LOG.info(_LI('Creating iscsi_target for: %s'), vol_id) LOG.debug(""Targets after update: %s"", out) except putils.ProcessExecutionError as e: LOG.warning(_LW(""Failed to create iscsi target for Volume "" ""ID: %(vol_id)s: %(e)s"") LOG.error(_LE(""Failed to create iscsi target for Volume "" ""ID: %(vol_id)s. Ensure the tgtd config file "" LOG.info(_LI('Removing iscsi_target for: %s'), vol_id) 'nothing to remove.'), volume_path) LOG.error(_LE(""Failed to remove iscsi target for Volume "" ""ID: %(vol_id)s: %(e)s"") LOG.error(_LE(""Failed to remove iscsi target for Volume "" ""ID: %(vol_id)s: %(e)s"") 'of remove_iscsi_target.', volume_path) LOG.error(_LE(""Failed to create iscsi target for Volume "" ""ID: %(vol_id)s: %(e)s"") LOG.info(_LI('Removing iscsi_target for volume: %s'), vol_id) LOG.info(_LI('Creating iscsi_target for volume: %s'), vol_id) LOG.error(_LE(""Failed to create iscsi target for Volume "" ""ID: %(vol_id)s, Error: %(err)s."") % {'vol_id': vol_id, 'err': e.stderr}) LOG.error(_LE(""Failed to create iscsi target for Volume "" ""ID: %s.""), vol_id) LOG.info(_LI('Removing iscsi_target: %s'), vol_id) LOG.error(_LE(""Failed to remove iscsi target for Volume "" ""ID: %(vol_id)s, Error: %(err)s."") % {'vol_id': vol_id, 'err': e.stderr}) LOG.error(_LE(""Failed to add initiator iqn %s to target.""), LOG.error(_LE(""Failed to delete initiator iqn %s to target.""),","import six LOG.debug('StdOut from recreate backing lun: %s' % out) LOG.debug('StdErr from recreate backing lun: %s' % err) ""iscsi backing lun for volume "" ""id:%(vol_id)s: %(e)s"") % {'vol_id': vol_id, 'e': six.text_type(e)}) LOG.debug('Failed to find CHAP auth from config for %s' % vol_id) LOG.info(_LI('Creating iscsi_target for: %s') % vol_id) LOG.debug(""StdOut from tgt-admin --update: %s"", out) LOG.debug(""StdErr from tgt-admin --update: %s"", err) LOG.debug(""Targets after update: %s"" % out) except putils.ProcessExecutionError as e: LOG.warning(_LW(""Failed to create iscsi target for volume "" ""id:%(vol_id)s: %(e)s"") LOG.error(_LE(""Failed to create iscsi target for volume "" ""id:%(vol_id)s. Please ensure your tgtd config file "" LOG.info(_LI('Removing iscsi_target for: %s') % vol_id) 'nothing to remove.') % volume_path) LOG.error(_LE(""Failed to remove iscsi target for volume "" ""id:%(vol_id)s: %(e)s"") LOG.error(_LE(""Failed to remove iscsi target for volume "" ""id:%(vol_id)s: %(e)s"") 'of remove_iscsi_target.' % volume_path) LOG.error(_LE(""Failed to create iscsi target for volume "" ""id:%(vol_id)s: %(e)s"") LOG.info(_LI('Removing iscsi_target for volume: %s') % vol_id) LOG.info(_LI('Creating iscsi_target for volume: %s') % vol_id) LOG.error(_LE(""Failed to create iscsi target for volume "" ""id:%s."") % vol_id) LOG.error(""%s"" % e) LOG.error(_LE(""Failed to create iscsi target for volume "" ""id:%s."") % vol_id) LOG.info(_LI('Removing iscsi_target: %s') % vol_id) LOG.error(_LE(""Failed to remove iscsi target for volume "" ""id:%s."") % vol_id) LOG.error(""%s"" % e) LOG.error(_LE(""Failed to add initiator iqn %s to target."") % LOG.error(_LE(""Failed to delete initiator iqn %s to target."") %",32,37
openstack%2Foslo.log~master~I09442d824400041768dbcddfbce932b175c767ab,openstack/oslo.log,master,I09442d824400041768dbcddfbce932b175c767ab,Use RequestContext store in oslo_context,MERGED,2014-12-22 15:59:09.000000000,2014-12-24 00:26:42.000000000,2014-12-24 00:26:41.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-12-22 15:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/931d37daaed726ac3b6660d2308dfbd9728341a7', 'message': ""Use RequestContext store in oslo_context\n\nRemove the _local store as we don't need it anymore. We should\nfetch the context directly from oslo_context's context module\nusing the get_current() method. Use the fixture in oslo_context\nto adapt the test cases to work with the change outlined above.\n\nChange-Id: I09442d824400041768dbcddfbce932b175c767ab\n""}, {'number': 2, 'created': '2014-12-22 17:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/20d207b5373d1285d16b36d4ec2325e99d32e574', 'message': ""Use RequestContext store in oslo_context\n\nRemove the _local store as we don't need it anymore. We should\nfetch the context directly from oslo_context's context module\nusing the get_current() method. Use the fixture in oslo_context\nto adapt the test cases to work with the change outlined above.\n\nSince we are using RequestContext from oslo_context, adjust a\nbit of code to use resource_uuid in addition to instance_uuid\nas well.\n\nChange-Id: I09442d824400041768dbcddfbce932b175c767ab\n""}, {'number': 3, 'created': '2014-12-22 19:01:26.000000000', 'files': ['oslo_log/tests/unit/test_log.py', 'oslo_log/formatters.py', 'oslo_log/tests/unit/test_local.py', 'oslo_log/_local.py'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/480cfc8514026c82e062a1d9c6dbf67a37341545', 'message': ""Use RequestContext store in oslo_context\n\nRemove the _local store as we don't need it anymore. We should\nfetch the context directly from oslo_context's context module\nusing the get_current() method. Use the fixture in oslo_context\nto adapt the test cases to work with the change outlined above.\n\nSince we are using RequestContext from oslo_context, adjust a\nbit of code to use resource_uuid in addition to instance_uuid\nas well. Added a fixture in the base test case itself to make\nsure that the context thread local store is cleared in between\ntests\n\nChange-Id: I09442d824400041768dbcddfbce932b175c767ab\n""}]",2,143477,480cfc8514026c82e062a1d9c6dbf67a37341545,22,4,3,5638,,,0,"Use RequestContext store in oslo_context

Remove the _local store as we don't need it anymore. We should
fetch the context directly from oslo_context's context module
using the get_current() method. Use the fixture in oslo_context
to adapt the test cases to work with the change outlined above.

Since we are using RequestContext from oslo_context, adjust a
bit of code to use resource_uuid in addition to instance_uuid
as well. Added a fixture in the base test case itself to make
sure that the context thread local store is cleared in between
tests

Change-Id: I09442d824400041768dbcddfbce932b175c767ab
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/77/143477/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_log/formatters.py', 'oslo_log/tests/unit/test_log.py', 'oslo_log/tests/unit/test_local.py', 'oslo_log/_local.py']",4,931d37daaed726ac3b6660d2308dfbd9728341a7,,,"# Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Local storage of variables using weak references"""""" import threading import weakref class WeakLocal(threading.local): def __getattribute__(self, attr): rval = super(WeakLocal, self).__getattribute__(attr) if rval: # NOTE(mikal): this bit is confusing. What is stored is a weak # reference, not the value itself. We therefore need to lookup # the weak reference and return the inner value here. rval = rval() return rval def __setattr__(self, attr, value): value = weakref.ref(value) return super(WeakLocal, self).__setattr__(attr, value) # NOTE(mikal): the name ""store"" should be deprecated in the future store = WeakLocal() # A ""weak"" store uses weak references and allows an object to fall out of scope # when it falls out of scope in the code that uses the thread local storage. A # ""strong"" store will hold a reference to the object so that it never falls out # of scope. weak_store = WeakLocal() strong_store = threading.local() ",32,158
openstack%2Foslo.config~master~Ia610412433bb79c60f90cebf3dcdf36232fdab2a,openstack/oslo.config,master,Ia610412433bb79c60f90cebf3dcdf36232fdab2a,Set the version string,MERGED,2014-12-10 13:11:18.000000000,2014-12-24 00:08:17.000000000,2014-12-24 00:08:16.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-12-10 13:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/32a3802c95fa569be1423be2cfc310d01702cbdf', 'message': 'Set the version string\n\nChange-Id: Ia610412433bb79c60f90cebf3dcdf36232fdab2a\nCloses-Bug: #1398985\n'}, {'number': 2, 'created': '2014-12-18 21:21:49.000000000', 'files': ['oslo_config/generator.py'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/f0456811b412dd1bdb69a31311590e721dd6ac96', 'message': 'Set the version string\n\nChange-Id: Ia610412433bb79c60f90cebf3dcdf36232fdab2a\nCloses-Bug: #1398985\n'}]",0,140671,f0456811b412dd1bdb69a31311590e721dd6ac96,10,3,2,2472,,,0,"Set the version string

Change-Id: Ia610412433bb79c60f90cebf3dcdf36232fdab2a
Closes-Bug: #1398985
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/71/140671/2 && git format-patch -1 --stdout FETCH_HEAD,['oslo_config/generator.py'],1,32a3802c95fa569be1423be2cfc310d01702cbdf,bug/1398985,"import pkg_resources version = pkg_resources.get_distribution('oslo.config').version conf(args, version=version)", conf(args),4,1
openstack%2Ffuel-docs~master~Ie96a2c16b92bfb3ab488c0a2941655f07313107f,openstack/fuel-docs,master,Ie96a2c16b92bfb3ab488c0a2941655f07313107f,Add information about MTU size,MERGED,2014-12-16 14:20:32.000000000,2014-12-23 23:57:27.000000000,2014-12-23 23:57:27.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8829}, {'_account_id': 8971}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-12-16 14:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/28b6f1ecb061d14b1ef4a02c48a7aecb0ba460d2', 'message': 'Add information about MTU size\n\nDue to OVS behavior, we should add a note about\nsetting a reasonable MTU size.\n\nChange-Id: Ie96a2c16b92bfb3ab488c0a2941655f07313107f\nCloses-Bug: 1402735\n'}, {'number': 2, 'created': '2014-12-16 14:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/9280a95d874f821a5e976eff3c80bfa0880ea59a', 'message': 'Add information about MTU size\n\nDue to OVS behavior, we should add a note about\nsetting a reasonable MTU size.\n\nChange-Id: Ie96a2c16b92bfb3ab488c0a2941655f07313107f\nCloses-Bug: 1402734\n'}, {'number': 3, 'created': '2014-12-23 23:52:29.000000000', 'files': ['pages/reference-architecture/ovs/0000-ovs-intro.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/8f3cb86bec044345dd6918f0edeeb23c3bc63591', 'message': 'Add information about MTU size\n\nDue to OVS behavior, we should add a note about\nsetting a reasonable MTU size.\n\nChange-Id: Ie96a2c16b92bfb3ab488c0a2941655f07313107f\nCloses-Bug: 1402734\n'}]",2,142114,8f3cb86bec044345dd6918f0edeeb23c3bc63591,18,7,3,13082,,,0,"Add information about MTU size

Due to OVS behavior, we should add a note about
setting a reasonable MTU size.

Change-Id: Ie96a2c16b92bfb3ab488c0a2941655f07313107f
Closes-Bug: 1402734
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/14/142114/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/reference-architecture/ovs/0000-ovs-intro.rst'],1,28b6f1ecb061d14b1ef4a02c48a7aecb0ba460d2,bug/1402734,".. note:: Due to the way how OVS handles GRE tunnels, it tries to copy DF flag to wrap GRE packet header, thus making it impossible for packets of more than 1430 bytes size to be transfered through regular interfaces; this breaks almost all applications. In Mirantis OpenStack 6.0, Open vSwitch agent now sets *df_inherit* flag to this option for OVS versions that support *df_inherit* flag. To avoid performance issues, you should extend your MTU size to a reasonable one. See `the Official OpenStack documentation <http://docs.openstack.org/icehouse/install-guide/install/yum/content/neutron-ml2-network-node.html>`_ for more information and instructions. ",,13,0
openstack%2Foslo.db~master~I24ac192cbd8b4edf8f5a0ee2f9b3613d46899deb,openstack/oslo.db,master,I24ac192cbd8b4edf8f5a0ee2f9b3613d46899deb,Updated from global requirements,MERGED,2014-12-18 01:27:30.000000000,2014-12-23 23:57:02.000000000,2014-12-23 23:57:01.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 7249}, {'_account_id': 7491}]","[{'number': 1, 'created': '2014-12-18 01:27:30.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/4a57952d9f5a43c97b0125be39d1a85ba87ccc72', 'message': 'Updated from global requirements\n\nChange-Id: I24ac192cbd8b4edf8f5a0ee2f9b3613d46899deb\n'}]",0,142638,4a57952d9f5a43c97b0125be39d1a85ba87ccc72,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: I24ac192cbd8b4edf8f5a0ee2f9b3613d46899deb
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/38/142638/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,4a57952d9f5a43c97b0125be39d1a85ba87ccc72,openstack/requirements,alembic>=0.7.1,alembic>=0.6.4,1,1
openstack%2Fpuppet-glance~master~Id713d32d1dc34a15e93adb89c18d3471145e6ffe,openstack/puppet-glance,master,Id713d32d1dc34a15e93adb89c18d3471145e6ffe,Service Validation for Glance-API,MERGED,2014-11-21 16:32:48.000000000,2014-12-23 23:31:08.000000000,2014-12-23 03:37:34.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 7155}, {'_account_id': 7156}, {'_account_id': 7616}, {'_account_id': 8482}, {'_account_id': 9410}]","[{'number': 1, 'created': '2014-11-21 16:32:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/7a7122236e4544227c0e0a26b1b679c5febff8de', 'message': 'Service Validation for Glance-API\n\nAs an option, validate Glance API service with a default or custom\ncommand, and if the service is up and running, create a Puppet Anchor\n\nChange-Id: Id713d32d1dc34a15e93adb89c18d3471145e6ffe\n'}, {'number': 2, 'created': '2014-12-08 23:43:16.000000000', 'files': ['manifests/api.pp', 'spec/classes/glance_api_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/2fa0df1e3ba95511449800c6df6dbb1e1fb01d5e', 'message': 'Service Validation for Glance-API\n\nAs an option, validate Glance API service with a default or custom\ncommand, and if the service is up and running, create a Puppet Anchor\n\nChange-Id: Id713d32d1dc34a15e93adb89c18d3471145e6ffe\n'}]",0,136411,2fa0df1e3ba95511449800c6df6dbb1e1fb01d5e,12,7,2,3153,,,0,"Service Validation for Glance-API

As an option, validate Glance API service with a default or custom
command, and if the service is up and running, create a Puppet Anchor

Change-Id: Id713d32d1dc34a15e93adb89c18d3471145e6ffe
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/11/136411/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/api.pp', 'spec/classes/glance_api_spec.rb']",2,7a7122236e4544227c0e0a26b1b679c5febff8de,validate-api-service," it { should_not contain_exec('validate_nova_api') } describe 'while validating the service with default command' do let :params do default_params.merge({ :validate => true, }) end it { should contain_exec('execute glance-api validation').with( :path => '/usr/bin:/bin:/usr/sbin:/sbin', :provider => 'shell', :tries => '10', :try_sleep => '2', :command => 'glance --os-auth-url http://localhost:5000/v2.0 --os-tenant-name services --os-username glance --os-password ChangeMe image-list', )} it { should contain_anchor('create glance-api anchor').with( :require => 'Exec[execute glance-api validation]', )} end describe 'while validating the service with custom command' do let :params do default_params.merge({ :validate => true, :validation_options => { 'glance-api' => { 'command' => 'my-script' } } }) end it { should contain_exec('execute glance-api validation').with( :path => '/usr/bin:/bin:/usr/sbin:/sbin', :provider => 'shell', :tries => '10', :try_sleep => '2', :command => 'my-script', )} it { should contain_anchor('create glance-api anchor').with( :require => 'Exec[execute glance-api validation]', )} end ",,76,0
openstack%2Fdiskimage-builder~master~I4062eb1d62322c455dac5b83b856f454da211320,openstack/diskimage-builder,master,I4062eb1d62322c455dac5b83b856f454da211320,Fail helpfully if uuidgen is missing,MERGED,2014-12-15 23:39:53.000000000,2014-12-23 23:27:28.000000000,2014-12-23 23:27:26.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6488}, {'_account_id': 6928}, {'_account_id': 8399}]","[{'number': 1, 'created': '2014-12-15 23:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/d49937279a02fb252580df8bd0322360d1f07e4d', 'message': 'Fail helpfully if uuidgen is missing\n\nIf uuidgen is not installed we currently fail when performing tune2fs.\n\nChange-Id: I4062eb1d62322c455dac5b83b856f454da211320\n'}, {'number': 2, 'created': '2014-12-15 23:40:56.000000000', 'files': ['bin/disk-image-create'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c94880aa2f8152e9ad86c37f22b2cb4b6eebae3a', 'message': 'Fail helpfully if uuidgen is missing\n\nIf uuidgen is not installed we currently fail when performing tune2fs.\n\nChange-Id: I4062eb1d62322c455dac5b83b856f454da211320\n'}]",1,141940,c94880aa2f8152e9ad86c37f22b2cb4b6eebae3a,12,5,2,10035,,,0,"Fail helpfully if uuidgen is missing

If uuidgen is not installed we currently fail when performing tune2fs.

Change-Id: I4062eb1d62322c455dac5b83b856f454da211320
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/40/141940/2 && git format-patch -1 --stdout FETCH_HEAD,['bin/disk-image-create'],1,d49937279a02fb252580df8bd0322360d1f07e4d,fix/detect-missing-uuidgen,"if echo ""$FS_TYPE"" | grep -q ""^ext"" && [ -z ""${DIB_IMAGE_ROOT_FS_UUID}"" ]; then echo ""ext filesystem detected but no DIB_IMAGE_ROOT_FS_UUID found."" echo ""Is the uuidgen utility installed on your system?"" exit 1 fi if [ -z ""${DIB_IMAGE_ROOT_FS_UUID}"" ]; then fi",,8,0
openstack%2Foslo.messaging~master~I7cd1e53e2ced7ebf9c5942b7a0dbbeb991acab4d,openstack/oslo.messaging,master,I7cd1e53e2ced7ebf9c5942b7a0dbbeb991acab4d,safe_log Sanitize Passwords in List of Dicts,MERGED,2014-09-24 15:20:44.000000000,2014-12-23 23:27:06.000000000,2014-12-23 23:27:05.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 8415}, {'_account_id': 13290}, {'_account_id': 13777}]","[{'number': 1, 'created': '2014-09-24 15:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/3746b108924d868f4ff3d92f320188aab1dda318', 'message': 'safe_log Sanitize Passwords in List of Dicts\n\nSanitizes password fields found in lists of dicts for messages\nbefore logging.\n\nThis also copy the whole safe_log tests from oslo-incubator.\n\nChange-Id: I7cd1e53e2ced7ebf9c5942b7a0dbbeb991acab4d\nCloses-Bug: #1268459\n'}, {'number': 2, 'created': '2014-10-22 09:00:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/1b57b781ac04d6a2f710a96ddcf3c073f2221bc1', 'message': 'safe_log Sanitize Passwords in List of Dicts\n\nSanitizes password fields found in lists of dicts for messages\nbefore logging.\n\nThis also copy the whole safe_log tests from oslo-incubator.\n\nChange-Id: I7cd1e53e2ced7ebf9c5942b7a0dbbeb991acab4d\nCloses-Bug: #1268459\n'}, {'number': 3, 'created': '2014-10-28 15:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/54d1e14761f0650233d94efaccceb11bea79df5c', 'message': 'safe_log Sanitize Passwords in List of Dicts\n\nSanitizes password fields found in lists of dicts for messages\nbefore logging.\n\nThis also copy the whole safe_log tests from oslo-incubator.\n\nChange-Id: I7cd1e53e2ced7ebf9c5942b7a0dbbeb991acab4d\nCloses-Bug: #1268459\n'}, {'number': 4, 'created': '2014-10-29 11:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/20806bb1b3c7ebf2057de83c44393e5d312b065e', 'message': 'safe_log Sanitize Passwords in List of Dicts\n\nSanitizes password fields found in lists of dicts for messages\nbefore logging.\n\nThis also copy the whole safe_log tests from oslo-incubator.\n\nChange-Id: I7cd1e53e2ced7ebf9c5942b7a0dbbeb991acab4d\nCloses-Bug: #1268459\n'}, {'number': 5, 'created': '2014-11-18 13:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/5711f7c18aab6c26d9d83fbce921f16d4fa1a09b', 'message': 'safe_log Sanitize Passwords in List of Dicts\n\nSanitizes password fields found in lists of dicts for messages\nbefore logging.\n\nThis also copy the whole safe_log tests from oslo-incubator.\n\nChange-Id: I7cd1e53e2ced7ebf9c5942b7a0dbbeb991acab4d\nCloses-Bug: #1268459\n'}, {'number': 6, 'created': '2014-11-28 16:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/1ebb61de2b207f9f98fb1e909ae70314b137bf9e', 'message': 'safe_log Sanitize Passwords in List of Dicts\n\nSanitizes password fields found in lists of dicts for messages\nbefore logging.\n\nThis also copy the whole safe_log tests from oslo-incubator.\n\nChange-Id: I7cd1e53e2ced7ebf9c5942b7a0dbbeb991acab4d\nCloses-Bug: #1268459\n'}, {'number': 7, 'created': '2014-12-03 06:38:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/54869ef29f38d551768ff0c8583de859a30fffb0', 'message': 'safe_log Sanitize Passwords in List of Dicts\n\nSanitizes password fields found in lists of dicts for messages\nbefore logging.\n\nThis also copy the whole safe_log tests from oslo-incubator.\n\nChange-Id: I7cd1e53e2ced7ebf9c5942b7a0dbbeb991acab4d\nCloses-Bug: #1268459\n'}, {'number': 8, 'created': '2014-12-03 16:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/caa71d0ce4fe4622cfb124c783872dda241b9a57', 'message': 'safe_log Sanitize Passwords in List of Dicts\n\nSanitizes password fields found in lists of dicts for messages\nbefore logging.\n\nThis also copy the whole safe_log tests from oslo-incubator.\n\nChange-Id: I7cd1e53e2ced7ebf9c5942b7a0dbbeb991acab4d\nCloses-Bug: #1268459\n'}, {'number': 9, 'created': '2014-12-04 14:29:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/8b612324f19665d8988c1c7f8d709e2aeca60dd0', 'message': 'safe_log Sanitize Passwords in List of Dicts\n\nSanitizes password fields found in lists of dicts for messages\nbefore logging.\n\nThis also copy the whole safe_log tests from oslo-incubator.\n\nChange-Id: I7cd1e53e2ced7ebf9c5942b7a0dbbeb991acab4d\nCloses-Bug: #1268459\n'}, {'number': 10, 'created': '2014-12-04 15:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/2096d01c4e9130844a6fd32d814f1bcb4a342f90', 'message': 'safe_log Sanitize Passwords in List of Dicts\n\nSanitizes password fields found in lists of dicts for messages\nbefore logging.\n\nThis change uses oslo.utils.strutils.mask_password to do it.\n\nChange-Id: I7cd1e53e2ced7ebf9c5942b7a0dbbeb991acab4d\nCloses-Bug: #1268459\n'}, {'number': 11, 'created': '2014-12-09 09:09:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/df3dceae2265e89681a0ac26e6a065532d58ad7e', 'message': 'safe_log Sanitize Passwords in List of Dicts\n\nSanitizes password fields found in lists of dicts for messages\nbefore logging.\n\nThis change uses oslo.utils.strutils.mask_password to do it.\n\nChange-Id: I7cd1e53e2ced7ebf9c5942b7a0dbbeb991acab4d\nCloses-Bug: #1268459\n'}, {'number': 12, 'created': '2014-12-11 10:10:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/e8d146af19dc46ec5e6d10f64777a973cb292ed6', 'message': 'safe_log Sanitize Passwords in List of Dicts\n\nSanitizes password fields found in lists of dicts for messages\nbefore logging.\n\nThis change uses oslo.utils.strutils.mask_password to do it.\n\nChange-Id: I7cd1e53e2ced7ebf9c5942b7a0dbbeb991acab4d\nCloses-Bug: #1268459\n'}, {'number': 13, 'created': '2014-12-12 07:31:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/534569959804f39d1cf60392a2770f1d6b3dd559', 'message': 'safe_log Sanitize Passwords in List of Dicts\n\nSanitizes password fields found in lists of dicts for messages\nbefore logging.\n\nThis change uses oslo.utils.strutils.mask_password to do it.\n\nChange-Id: I7cd1e53e2ced7ebf9c5942b7a0dbbeb991acab4d\nCloses-Bug: #1268459\n'}, {'number': 14, 'created': '2014-12-16 16:17:46.000000000', 'files': ['oslo/messaging/_drivers/common.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/56a9c55a3f2919d0dcc93639c23df169aafc240a', 'message': 'safe_log Sanitize Passwords in List of Dicts\n\nSanitizes password fields found in lists of dicts for messages\nbefore logging.\n\nThis change uses oslo.utils.strutils.mask_password to do it.\n\nChange-Id: I7cd1e53e2ced7ebf9c5942b7a0dbbeb991acab4d\nCloses-Bug: #1268459\n'}]",8,123759,56a9c55a3f2919d0dcc93639c23df169aafc240a,85,9,14,2813,,,0,"safe_log Sanitize Passwords in List of Dicts

Sanitizes password fields found in lists of dicts for messages
before logging.

This change uses oslo.utils.strutils.mask_password to do it.

Change-Id: I7cd1e53e2ced7ebf9c5942b7a0dbbeb991acab4d
Closes-Bug: #1268459
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/59/123759/14 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_drivers/common.py', 'tests/drivers/test_drivers_common.py']",2,3746b108924d868f4ff3d92f320188aab1dda318,bug/1268459,"# Copyright 2013 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import testscenarios from oslo.messaging._drivers import common as driver_common from tests import utils as test_utils load_tests = testscenarios.load_tests_apply_scenarios class CommonDriversTestCase(test_utils.BaseTestCase): def test_safe_log_sanitizes_globals(self): def logger_method(msg, data): self.assertEqual('<SANITIZED>', data['_context_auth_token']) self.assertEqual('<SANITIZED>', data['auth_token']) data = {'_context_auth_token': 'banana', 'auth_token': 'cheese'} driver_common._safe_log(logger_method, 'foo', data) def test_safe_log_sanitizes_set_admin_password(self): def logger_method(msg, data): self.assertEqual('<SANITIZED>', data['args']['new_pass']) data = {'_context_auth_token': 'banana', 'auth_token': 'cheese', 'method': 'set_admin_password', 'args': {'new_pass': 'gerkin'}} driver_common._safe_log(logger_method, 'foo', data) def test_safe_log_sanitizes_run_instance(self): def logger_method(msg, data): self.assertEqual('<SANITIZED>', data['args']['admin_password']) data = {'_context_auth_token': 'banana', 'auth_token': 'cheese', 'method': 'run_instance', 'args': {'admin_password': 'gerkin'}} driver_common._safe_log(logger_method, 'foo', data) def test_safe_log_sanitizes_any_password_in_context(self): def logger_method(msg, data): self.assertEqual('<SANITIZED>', data['_context_password']) self.assertEqual('<SANITIZED>', data['password']) data = {'_context_auth_token': 'banana', 'auth_token': 'cheese', 'password': 'passw0rd', '_context_password': 'passw0rd' } driver_common._safe_log(logger_method, 'foo', data) def test_safe_log_sanitizes_cells_route_message(self): def logger_method(msg, data): vals = data['args']['message']['args']['method_info'] self.assertEqual('<SANITIZED>', vals['method_kwargs']['password']) meth_info = {'method_args': ['aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee'], 'method': 'set_admin_password', 'method_kwargs': {'password': 'this_password_is_visible'}} data = {'method': 'route_message', 'args': {'routing_path': 'a.fake.path', 'direction': 'down', 'message': {'args': {'is_broadcast': False, 'service_name': 'compute', 'method_info': meth_info}, 'method': 'run_service_api_method'}, 'dest_cell_name': 'cell!0001'}} driver_common._safe_log(logger_method, 'foo', data) def test_safe_log_sanitizes_any_password_in_list_of_dicts(self): def logger_method(msg, data): self.assertEqual('<SANITIZED>', data['users'][0]['_password']) self.assertEqual('<SANITIZED>', data['users'][1]['_password']) users = [{'_host': '%', '_password': 'passw0rd', '_name': 'mydb'}, {'_host': '%', '_password': 'secret', '_name': 'newdb'}] data = {'_request_id': 'req-44adf4ac-12bb-44c5-be3d-da2cc73b2e05', 'users': users} driver_common._safe_log(logger_method, 'foo', data) ",,96,1
openstack%2Foslo-incubator~master~I55f2942a787f780d81051c1b9faa0eb15c2443a1,openstack/oslo-incubator,master,I55f2942a787f780d81051c1b9faa0eb15c2443a1,Add a virtual sprint ML template/program,MERGED,2014-12-09 19:53:11.000000000,2014-12-23 23:24:13.000000000,2014-12-23 23:24:11.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-12-09 19:53:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/bd0185063a7d38c58c2ba5ce4ab8727b0b385101', 'message': 'Add a virtual sprint ML template/program\n\nThis program can be used to create a nicely formatted\nvirtual sprint email for the mailing list so that oslo\nsubprojects can use it to invite others to there virtual\nsprints.\n\nChange-Id: I55f2942a787f780d81051c1b9faa0eb15c2443a1\n'}, {'number': 2, 'created': '2014-12-09 19:59:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/2e67a12620d7fdc14712b5aba63301cd10ed44a0', 'message': 'Add a virtual sprint ML template/program\n\nThis program can be used to create a nicely formatted\nvirtual sprint email for the mailing list so that oslo\nsubprojects can use it to invite others to there virtual\nsprints.\n\nChange-Id: I55f2942a787f780d81051c1b9faa0eb15c2443a1\n'}, {'number': 3, 'created': '2014-12-09 20:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/721000df034f025a1cda445459dfbb0517764db2', 'message': 'Add a virtual sprint ML template/program\n\nThis program can be used to create a nicely formatted\nvirtual sprint email for the mailing list so that oslo\nsubprojects can use it to invite others to there virtual\nsprints.\n\nChange-Id: I55f2942a787f780d81051c1b9faa0eb15c2443a1\n'}, {'number': 4, 'created': '2014-12-09 21:28:01.000000000', 'files': ['tools/virtual_sprint.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/317ec9c72354160a64423de6eee862b6f0f595b7', 'message': 'Add a virtual sprint ML template/program\n\nThis program can be used to create a nicely formatted\nvirtual sprint email for the mailing list so that oslo\nsubprojects can use it to invite others to there virtual\nsprints.\n\nChange-Id: I55f2942a787f780d81051c1b9faa0eb15c2443a1\n'}]",1,140458,317ec9c72354160a64423de6eee862b6f0f595b7,12,4,4,1297,,,0,"Add a virtual sprint ML template/program

This program can be used to create a nicely formatted
virtual sprint email for the mailing list so that oslo
subprojects can use it to invite others to there virtual
sprints.

Change-Id: I55f2942a787f780d81051c1b9faa0eb15c2443a1
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/58/140458/4 && git format-patch -1 --stdout FETCH_HEAD,['tools/virtual_sprint.py'],1,bd0185063a7d38c58c2ba5ce4ab8727b0b385101,,"#!/usr/bin/env python # vi: ts=4 expandtab # # Copyright (C) 2014 Yahoo! Inc. # # This program is free software: you can redistribute it and/or modify # it under the terms of the GNU General Public License version 3, as # published by the Free Software Foundation. # # This program is distributed in the hope that it will be useful, # but WITHOUT ANY WARRANTY; without even the implied warranty of # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the # GNU General Public License for more details. # # You should have received a copy of the GNU General Public License # along with this program. If not, see <http://www.gnu.org/licenses/>. import sys import delorean import jinja2 import parawrap def expand_template(contents, params): if not params: params = {} tpl = jinja2.Template(source=str(contents), undefined=jinja2.StrictUndefined).render(**params) return tpl TPL = """""" Hi everyone, The OpenStack {{ team }} team will be hosting a virtual sprint in the Freenode IRC channel #{{ channel }} for the {{ for }} on {{ when }} starting at {{ starts_at }} and going for ~{{ duration }} hours. The goal of this sprint is to work on any open reviews, documentation or any other integration questions, development and so-on, so that we can help progress the {{ for }} forward at a good rate. Live version of the current documentation is available here: {{ docs }} The code itself lives in the openstack/{{ project }} respository. {{ git_tree }} Please feel free to join if interested, curious, or able. Much appreciated, {{ author }} """""" # Example: # # python tools/virtual_sprint.py ""taskflow"" ""next tuesday"" ""Joshua Harlow"" if len(sys.argv) != 4: print(""%s project when author"" % sys.argv[0]) sys.exit(1) # Something like 'next tuesday' is expected... d = delorean.Delorean() project = sys.argv[1] when = getattr(d, sys.argv[2].replace("" "", ""_"")) author = sys.argv[3] params = { 'team': 'oslo', 'project': project, 'channel': 'openstack-oslo', 'docs': 'http://docs.openstack.org/developer/%s/' % project, 'when': when().datetime.strftime('%A %m-%d-%Y'), 'starts_at': '16:00 UTC', 'duration': 8, 'author': author, 'git_tree': 'http://git.openstack.org/cgit/openstack/%s/tree' % project, } params['for'] = params['project'] + ' ' + 'subproject' for line in parawrap.wrap(expand_template(TPL.strip(), params)): print(line) ",,85,0
openstack%2Fpuppet-tempest~stable%2Fjuno~I5b954b2b3d1b300dc8f75dd2147fe0c811c1c2ab,openstack/puppet-tempest,stable/juno,I5b954b2b3d1b300dc8f75dd2147fe0c811c1c2ab,Allow to not manage Tempest code in Puppet,MERGED,2014-12-18 13:07:48.000000000,2014-12-23 23:17:34.000000000,2014-12-23 23:17:34.000000000,"[{'_account_id': 3}, {'_account_id': 7155}, {'_account_id': 8482}, {'_account_id': 9410}]","[{'number': 1, 'created': '2014-12-18 13:07:48.000000000', 'files': ['manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/f5e87cad5de119bd483006f06efcd22a34d8bdc4', 'message': 'Allow to not manage Tempest code in Puppet\n\nIn the case you are using a package, you may want the flexibility to not\nuse VCS to manage Tempest code and just use the Puppet module to\nconfigure Tempest itself.\n\nAdding a new parameter, true by default to keep backward compatibility.\n\n(cherry picked from commit 05fc037265964e16429639e26601d8fd6d28ec4c)\n\nChange-Id: I5b954b2b3d1b300dc8f75dd2147fe0c811c1c2ab\n'}]",0,142767,f5e87cad5de119bd483006f06efcd22a34d8bdc4,7,4,1,3153,,,0,"Allow to not manage Tempest code in Puppet

In the case you are using a package, you may want the flexibility to not
use VCS to manage Tempest code and just use the Puppet module to
configure Tempest itself.

Adding a new parameter, true by default to keep backward compatibility.

(cherry picked from commit 05fc037265964e16429639e26601d8fd6d28ec4c)

Change-Id: I5b954b2b3d1b300dc8f75dd2147fe0c811c1c2ab
",git fetch https://review.opendev.org/openstack/puppet-tempest refs/changes/67/142767/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/init.pp'],1,f5e87cad5de119bd483006f06efcd22a34d8bdc4,," $install_from_source = true, $tempest_config_file = '/var/lib/tempest/etc/tempest.conf', if $install_from_source { ensure_packages([ 'git', 'python-setuptools', ]) ensure_packages($tempest::params::dev_packages) exec { 'install-pip': command => '/usr/bin/easy_install pip', unless => '/usr/bin/which pip', require => Package['python-setuptools'], } exec { 'install-tox': command => ""${tempest::params::pip_bin_path}/pip install -U tox"", unless => '/usr/bin/which tox', require => Exec['install-pip'], } vcsrepo { $tempest_clone_path: ensure => 'present', source => $tempest_repo_uri, revision => $tempest_repo_revision, provider => 'git', require => Package['git'], user => $tempest_clone_owner, } if $setup_venv { # virtualenv will be installed along with tox exec { 'setup-venv': command => ""/usr/bin/python ${tempest_clone_path}/tools/install_venv.py"", cwd => $tempest_clone_path, unless => ""/usr/bin/test -d ${tempest_clone_path}/.venv"", require => [ Vcsrepo[$tempest_clone_path], Exec['install-tox'], Package[$tempest::params::dev_packages], ], } } $tempest_conf = ""${tempest_clone_path}/etc/tempest.conf"" file { $tempest_conf: replace => false, source => ""${tempest_conf}.sample"", require => Vcsrepo[$tempest_clone_path], owner => $tempest_clone_owner, } Tempest_config { path => $tempest_conf, require => File[$tempest_conf], } } else { Tempest_config { path => $tempest_config_file, }"," ensure_packages([ 'git', 'python-setuptools', ]) ensure_packages($tempest::params::dev_packages) exec { 'install-pip': command => '/usr/bin/easy_install pip', unless => '/usr/bin/which pip', require => Package['python-setuptools'], } exec { 'install-tox': command => ""${tempest::params::pip_bin_path}/pip install -U tox"", unless => '/usr/bin/which tox', require => Exec['install-pip'], } vcsrepo { $tempest_clone_path: ensure => 'present', source => $tempest_repo_uri, revision => $tempest_repo_revision, provider => 'git', require => Package['git'], user => $tempest_clone_owner, } if $setup_venv { # virtualenv will be installed along with tox exec { 'setup-venv': command => ""/usr/bin/python ${tempest_clone_path}/tools/install_venv.py"", cwd => $tempest_clone_path, unless => ""/usr/bin/test -d ${tempest_clone_path}/.venv"", require => [ Vcsrepo[$tempest_clone_path], Exec['install-tox'], Package[$tempest::params::dev_packages], ], } } $tempest_conf = ""${tempest_clone_path}/etc/tempest.conf"" file { $tempest_conf: replace => false, source => ""${tempest_conf}.sample"", require => Vcsrepo[$tempest_clone_path], owner => $tempest_clone_owner, } Tempest_config { path => $tempest_conf, require => File[$tempest_conf],",57,48
openstack%2Fpuppet-cinder~stable%2Fjuno~I602563420d915ce2b553c8bccca6f1260403d168,openstack/puppet-cinder,stable/juno,I602563420d915ce2b553c8bccca6f1260403d168,Service Validation for Cinder-API,MERGED,2014-12-17 16:13:13.000000000,2014-12-23 23:16:53.000000000,2014-12-23 23:16:53.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 7155}, {'_account_id': 8482}, {'_account_id': 9410}]","[{'number': 1, 'created': '2014-12-17 16:13:13.000000000', 'files': ['manifests/api.pp', 'spec/classes/cinder_api_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/f6af237764cca3319594e731b6b808a7c557cd4c', 'message': 'Service Validation for Cinder-API\n\nAs an option, validate Cinder API service with a default or custom\ncommand, and if the service is up and running, create a Puppet Anchor.\n\nChange-Id: I602563420d915ce2b553c8bccca6f1260403d168\n(cherry picked from commit 62823628ca092a2ee45faf3d40622a95f5483097)\n'}]",0,142477,f6af237764cca3319594e731b6b808a7c557cd4c,7,5,1,3153,,,0,"Service Validation for Cinder-API

As an option, validate Cinder API service with a default or custom
command, and if the service is up and running, create a Puppet Anchor.

Change-Id: I602563420d915ce2b553c8bccca6f1260403d168
(cherry picked from commit 62823628ca092a2ee45faf3d40622a95f5483097)
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/77/142477/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/api.pp', 'spec/classes/cinder_api_spec.rb']",2,f6af237764cca3319594e731b6b808a7c557cd4c,," describe 'while validating the service with default command' do let :params do req_params.merge({ :validate => true, }) end it { should contain_exec('execute cinder-api validation').with( :path => '/usr/bin:/bin:/usr/sbin:/sbin', :provider => 'shell', :tries => '10', :try_sleep => '2', :command => 'cinder --os-auth-url http://localhost:5000/ --os-tenant-name services --os-username cinder --os-password foo list', )} it { should contain_anchor('create cinder-api anchor').with( :require => 'Exec[execute cinder-api validation]', )} end describe 'while validating the service with custom command' do let :params do req_params.merge({ :validate => true, :validation_options => { 'cinder-api' => { 'command' => 'my-script' } } }) end it { should contain_exec('execute cinder-api validation').with( :path => '/usr/bin:/bin:/usr/sbin:/sbin', :provider => 'shell', :tries => '10', :try_sleep => '2', :command => 'my-script', )} it { should contain_anchor('create cinder-api anchor').with( :require => 'Exec[execute cinder-api validation]', )} end ",,76,3
openstack%2Fdiskimage-builder~master~I0cb7b96e24daab8ee73611936af72074c70ac1aa,openstack/diskimage-builder,master,I0cb7b96e24daab8ee73611936af72074c70ac1aa,Allow absolute path to image with ironic-agent,MERGED,2014-12-13 17:15:06.000000000,2014-12-23 23:08:51.000000000,2014-12-23 23:08:50.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6488}, {'_account_id': 6928}, {'_account_id': 7711}, {'_account_id': 12356}]","[{'number': 1, 'created': '2014-12-13 17:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/54b6d780c4e7304bd4238653b8e421bb2afc45e4', 'message': 'Allow absolute path to image with ironic-agent\n\nThe element was prepending the work directory forcibly, which will have\nproblems when the image name has an absolute path, which is allowed.\n\nChange-Id: I0cb7b96e24daab8ee73611936af72074c70ac1aa\nCloses-Bug: #1400405\n'}, {'number': 2, 'created': '2014-12-14 17:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/871f0206e169bf0e4145de945d1d9ac2e32b4862', 'message': 'Allow absolute path to image with ironic-agent\n\nThe element was prepending the work directory forcibly, which will have\nproblems when the image name has an absolute path, which is allowed.\n\nChange-Id: I0cb7b96e24daab8ee73611936af72074c70ac1aa\nCloses-Bug: #1400405\n'}, {'number': 3, 'created': '2014-12-16 00:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/7a5b1029d1a2bce3861357d85c0ddb3c5e91ea55', 'message': 'Allow absolute path to image with ironic-agent\n\nThe element was prepending the work directory forcibly, which will have\nproblems when the image name has an absolute path, which is allowed.\n\nChange-Id: I0cb7b96e24daab8ee73611936af72074c70ac1aa\nCloses-Bug: #1400405\n'}, {'number': 4, 'created': '2014-12-16 18:41:11.000000000', 'files': ['elements/ironic-agent/cleanup.d/99-ramdisk-create'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/4dceacd5ed96d570bd015ce2c01ce91d1463499e', 'message': 'Allow absolute path to image with ironic-agent\n\nThe element was prepending the work directory forcibly, which will have\nproblems when the image name has an absolute path, which is allowed.\n\nChange-Id: I0cb7b96e24daab8ee73611936af72074c70ac1aa\nCloses-Bug: #1400405\n'}]",5,141567,4dceacd5ed96d570bd015ce2c01ce91d1463499e,25,6,4,6488,,,0,"Allow absolute path to image with ironic-agent

The element was prepending the work directory forcibly, which will have
problems when the image name has an absolute path, which is allowed.

Change-Id: I0cb7b96e24daab8ee73611936af72074c70ac1aa
Closes-Bug: #1400405
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/67/141567/4 && git format-patch -1 --stdout FETCH_HEAD,['elements/ironic-agent/cleanup.d/99-ramdisk-create'],1,54b6d780c4e7304bd4238653b8e421bb2afc45e4,bug/1400405,pushd $WORKDIR sudo find . -path ./sys -prune -o -path ./proc -prune -o -print | sudo cpio -o -H newc | gzip > $IMAGE_NAME.initramfs popd,sudo find . -path ./sys -prune -o -path ./proc -prune -o -print | sudo cpio -o -H newc | gzip > $WORKDIR/$IMAGE_NAME.initramfs,3,1
openstack%2Ftripleo-image-elements~master~I18d280fbbdb64b4dabfc0ee1c0f61cd8294316f7,openstack/tripleo-image-elements,master,I18d280fbbdb64b4dabfc0ee1c0f61cd8294316f7,Grant privs to localhost and flush privs,MERGED,2014-12-08 12:21:40.000000000,2014-12-23 22:55:51.000000000,2014-12-23 22:55:51.000000000,"[{'_account_id': 3}, {'_account_id': 1706}, {'_account_id': 6449}, {'_account_id': 6928}, {'_account_id': 6969}, {'_account_id': 9453}, {'_account_id': 11650}]","[{'number': 1, 'created': '2014-12-08 12:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/443f670484d1b0e52e618d820e7186a49aecdce0', 'message': 'Grant privs to localhost and flush privs\n\nWhen creating new users privs should also be\ngranted to localhost and flushed.\n\nChange-Id: I18d280fbbdb64b4dabfc0ee1c0f61cd8294316f7\n'}, {'number': 2, 'created': '2014-12-08 15:00:48.000000000', 'files': ['elements/mysql-common/os-refresh-config/post-configure.d/50-mysql-users'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/14659ad1cc3b38488decf390381c72e2747bfd1d', 'message': 'Grant privs to localhost and flush privs\n\nWhen creating new users privs should also be\ngranted to localhost and flushed.\n\nChange-Id: I18d280fbbdb64b4dabfc0ee1c0f61cd8294316f7\n'}]",0,139984,14659ad1cc3b38488decf390381c72e2747bfd1d,15,7,2,1872,,,0,"Grant privs to localhost and flush privs

When creating new users privs should also be
granted to localhost and flushed.

Change-Id: I18d280fbbdb64b4dabfc0ee1c0f61cd8294316f7
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/84/139984/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/mysql-common/os-refresh-config/post-configure.d/50-mysql-users'],1,443f670484d1b0e52e618d820e7186a49aecdce0,," cmd_local = cmd + "" TO `%s`@'localhost' IDENTIFIED BY '%s'"" % (username, password) cmd_global = cmd + "" TO `%s`@'%%' IDENTIFIED BY '%s'"" % (username, password) print(""%s"" % (cmd_local)) print(""%s"" % (cmd_global)) cursor.execute(cmd_local) cursor.execute(cmd_global) cursor.execute(""FLUSH PRIVILEGES"");"," cmd += "" TO `%s`@'%%' IDENTIFIED BY '%s'"" % (username, password) print(""%s"" % (cmd)) cursor.execute(cmd)",7,3
openstack%2Foslo.i18n~master~If7fa8fd1915378bda3fc6e361049c2d90cdec8af,openstack/oslo.i18n,master,If7fa8fd1915378bda3fc6e361049c2d90cdec8af,Correct the translation domain for loading messages,MERGED,2014-12-22 16:28:35.000000000,2014-12-23 22:45:48.000000000,2014-12-23 22:45:47.000000000,"[{'_account_id': 3}, {'_account_id': 6601}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-12-22 16:28:35.000000000', 'files': ['oslo_i18n/_i18n.py'], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/582c7183cab87b449acee5775deb12677a0b0cee', 'message': 'Correct the translation domain for loading messages\n\nChange-Id: If7fa8fd1915378bda3fc6e361049c2d90cdec8af\n'}]",0,143483,582c7183cab87b449acee5775deb12677a0b0cee,9,3,1,2472,,,0,"Correct the translation domain for loading messages

Change-Id: If7fa8fd1915378bda3fc6e361049c2d90cdec8af
",git fetch https://review.opendev.org/openstack/oslo.i18n refs/changes/83/143483/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_i18n/_i18n.py'],1,582c7183cab87b449acee5775deb12677a0b0cee,fix-translation-domain,_translators = _factory.TranslatorFactory('oslo.i18n'),_translators = _factory.TranslatorFactory('oslo_i18n'),1,1
openstack%2Ftripleo-image-elements~master~I06056c0d3a4f26f7483980305898e4e2b1e08c6e,openstack/tripleo-image-elements,master,I06056c0d3a4f26f7483980305898e4e2b1e08c6e,Allow setting ca_certificate option for metadata api,MERGED,2014-12-05 10:23:33.000000000,2014-12-23 22:45:17.000000000,2014-12-23 22:45:16.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 8688}]","[{'number': 1, 'created': '2014-12-05 10:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/cbdc6e4cab8d1e3e8bac3ed29b2d8064a52f7e3a', 'message': ""Allow setting ca_certificate option for metadata api\n\nThis aligns os-c-c with the change to os-c-c to allow a ca_certificate being\npassed down into requests so that it doesn't fail to collect towarsd a SSL'd\nmetadata api.\n\nChange-Id: I06056c0d3a4f26f7483980305898e4e2b1e08c6e\n""}, {'number': 2, 'created': '2014-12-05 10:50:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/bf042226327efe14769f9f9ceb9fef339c806648', 'message': 'Allow setting ca_certificate option for metadata api\n\nThis allows os-collect-config to pass a ca_certificate when making requests to an SSL metadata server.\n\nChange-Id: I06056c0d3a4f26f7483980305898e4e2b1e08c6e\n'}, {'number': 3, 'created': '2014-12-05 11:01:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ff120bc6744dd46bd83be4386284a9ef7c17cbea', 'message': 'Allow setting ca_certificate option for metadata api\n\nThis allows os-collect-config to pass a ca_certificate when making\nrequests to an SSL metadata server.\n\nChange-Id: I06056c0d3a4f26f7483980305898e4e2b1e08c6e\n'}, {'number': 4, 'created': '2014-12-05 11:10:00.000000000', 'files': ['elements/os-collect-config/README.md', 'elements/os-collect-config/os-apply-config/etc/os-collect-config.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/71d9a26741adc4308583bad6bfbf95606605d71c', 'message': 'Allow setting ca_certificate option for metadata api\n\nThis allows os-collect-config to pass a ca_certificate when making\nrequests to an SSL metadata server.\n\nChange-Id: I06056c0d3a4f26f7483980305898e4e2b1e08c6e\n'}]",1,139594,71d9a26741adc4308583bad6bfbf95606605d71c,15,3,4,395,,,0,"Allow setting ca_certificate option for metadata api

This allows os-collect-config to pass a ca_certificate when making
requests to an SSL metadata server.

Change-Id: I06056c0d3a4f26f7483980305898e4e2b1e08c6e
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/94/139594/4 && git format-patch -1 --stdout FETCH_HEAD,['elements/os-collect-config/os-apply-config/etc/os-collect-config.conf'],1,cbdc6e4cab8d1e3e8bac3ed29b2d8064a52f7e3a,139594,{{#ca_certificate}} ca_certificate = {{.}} {{/ca_certificate}},,3,0
openstack%2Ffuel-docs~master~I0ba89d2d5c097984c21ec31cbf3771d21be62c26,openstack/fuel-docs,master,I0ba89d2d5c097984c21ec31cbf3771d21be62c26,less misleading diagram that describes vCenter HA,MERGED,2014-10-14 12:02:49.000000000,2014-12-23 22:37:48.000000000,2014-12-23 22:37:47.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 11163}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-10-14 12:02:49.000000000', 'files': ['_images/vcenter-reference-architecture.png', 'pages/reference-architecture/7000-vcenter.rst', '_images/vcenter-ha-architecture.png'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/6cf3ed65845b137c4ca6ef54b73c73f9cafc9f42', 'message': 'less misleading diagram that describes vCenter HA\n\n- current diagram has following misleading moment: it states that\n  nova-network and nova-compute has active and standby working modes,\n  which is not true\n- rename image file to vcenter-ha-reference.png, because it\n  describes HA architecture, which is a part of reference architecture\n\nChange-Id: I0ba89d2d5c097984c21ec31cbf3771d21be62c26\n'}]",0,128250,6cf3ed65845b137c4ca6ef54b73c73f9cafc9f42,11,8,1,11427,,,0,"less misleading diagram that describes vCenter HA

- current diagram has following misleading moment: it states that
  nova-network and nova-compute has active and standby working modes,
  which is not true
- rename image file to vcenter-ha-reference.png, because it
  describes HA architecture, which is a part of reference architecture

Change-Id: I0ba89d2d5c097984c21ec31cbf3771d21be62c26
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/50/128250/1 && git format-patch -1 --stdout FETCH_HEAD,"['_images/vcenter-reference-architecture.png', 'pages/reference-architecture/7000-vcenter.rst', '_images/vcenter-ha-architecture.png']",3,6cf3ed65845b137c4ca6ef54b73c73f9cafc9f42,vcenter-ha-diagram,,,1,1
openstack%2Fneutron~master~I1e0209ab293494942efab12baabd4858df40e3aa,openstack/neutron,master,I1e0209ab293494942efab12baabd4858df40e3aa,Fixes spelling error,MERGED,2014-12-19 20:24:08.000000000,2014-12-23 22:34:38.000000000,2014-12-23 21:46:52.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 4656}, {'_account_id': 5115}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 7743}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-19 20:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4e79a4d3cda7905d77a56d6bc97f59790d113d1f', 'message': 'Fixes spelling error\nCloses-Bug: #1404341\n\nChange-Id: I1e0209ab293494942efab12baabd4858df40e3aa\n'}, {'number': 2, 'created': '2014-12-23 19:37:00.000000000', 'files': ['neutron/api/rpc/agentnotifiers/l3_rpc_agent_api.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8504dedd9c8b3fe899c5806115a6f0367c30e27e', 'message': 'Fixes spelling error\n\nCloses-Bug: #1404341\n\nChange-Id: I1e0209ab293494942efab12baabd4858df40e3aa\n'}]",1,143179,8504dedd9c8b3fe899c5806115a6f0367c30e27e,58,24,2,5115,,,0,"Fixes spelling error

Closes-Bug: #1404341

Change-Id: I1e0209ab293494942efab12baabd4858df40e3aa
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/143179/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/api/rpc/agentnotifiers/l3_rpc_agent_api.py'],1,4e79a4d3cda7905d77a56d6bc97f59790d113d1f,143179, LOG.debug('Notify agent at %(host)s the message ', LOG.debug('Nofity agent at %(host)s the message ',1,1
openstack%2Ffuel-docs~master~Id0fd03e37c3f3cb62f48c930dde92aa38aa177e7,openstack/fuel-docs,master,Id0fd03e37c3f3cb62f48c930dde92aa38aa177e7,Updates screenshot for vCenter Storage Backend,MERGED,2014-12-11 14:35:00.000000000,2014-12-23 22:24:39.000000000,2014-12-23 22:24:39.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 10014}, {'_account_id': 11427}, {'_account_id': 12139}, {'_account_id': 12415}, {'_account_id': 14342}]","[{'number': 1, 'created': '2014-12-11 14:35:00.000000000', 'files': ['pages/user-guide/7300-vcenter.rst', '_images/user_screen_shots/vcenter-glance-backend.png'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/bd4ec60737900a9455ecd916b2a7d2d0e8d16f6b', 'message': 'Updates screenshot for vCenter Storage Backend\n\nParapraph on available option is reworked.\n\nChange-Id: Id0fd03e37c3f3cb62f48c930dde92aa38aa177e7\n'}]",0,141062,bd4ec60737900a9455ecd916b2a7d2d0e8d16f6b,13,9,1,13082,,,0,"Updates screenshot for vCenter Storage Backend

Parapraph on available option is reworked.

Change-Id: Id0fd03e37c3f3cb62f48c930dde92aa38aa177e7
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/62/141062/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/user-guide/7300-vcenter.rst', '_images/user_screen_shots/vcenter-glance-backend.png']",2,bd4ec60737900a9455ecd916b2a7d2d0e8d16f6b,storage-backend-glance-vdmk,,,5,13
openstack%2Fpython-openstackclient~master~Ice21fee85203a8a55417e0ead8b509b8fd6705c1,openstack/python-openstackclient,master,Ice21fee85203a8a55417e0ead8b509b8fd6705c1,add multi-delete support for compute/image/net/volume,MERGED,2014-12-10 03:56:31.000000000,2014-12-23 22:23:46.000000000,2014-12-23 22:23:45.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8736}, {'_account_id': 9101}]","[{'number': 1, 'created': '2014-12-10 03:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/40cb7d3f4f445ddae1420480c893d0ee49283631', 'message': 'add multi-delete support for compute/image/net/volume\n\nThis is part1, add support for these objects:\ncompute.server\nimagev1.image\nimagev2.image\nnetwork.network\nvolume.volume\nvolume.backup\nvolume.snapshot\n\nChange-Id: Ice21fee85203a8a55417e0ead8b509b8fd6705c1\n'}, {'number': 2, 'created': '2014-12-10 06:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e0129dfb327d7f07e3a9029ddd45af2546427970', 'message': 'add multi-delete support for compute/image/net/volume\n\nThis is part1, add support for these objects:\ncompute.server\nimagev1.image\nimagev2.image\nnetwork.network\nvolume.volume\nvolume.backup\nvolume.snapshot\n\nCloses-Bug: #1400597\nChange-Id: Ice21fee85203a8a55417e0ead8b509b8fd6705c1\n'}, {'number': 3, 'created': '2014-12-23 01:31:23.000000000', 'files': ['openstackclient/tests/image/v2/test_image.py', 'openstackclient/volume/v1/snapshot.py', 'openstackclient/image/v1/image.py', 'openstackclient/network/v2/network.py', 'openstackclient/compute/v2/server.py', 'doc/source/command-objects/server.rst', 'openstackclient/volume/v1/backup.py', 'openstackclient/tests/compute/v2/test_server.py', 'openstackclient/volume/v1/volume.py', 'openstackclient/image/v2/image.py', 'openstackclient/tests/image/v1/test_image.py', 'openstackclient/tests/network/v2/test_network.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/470b7e53a8d7e7ba088b934c49163412c8ee5ed9', 'message': 'add multi-delete support for compute/image/net/volume\n\nThis is part1, add support for these objects:\ncompute.server\nimagev1.image\nimagev2.image\nnetwork.network\nvolume.volume\nvolume.backup\nvolume.snapshot\n\nCloses-Bug: #1400597\nChange-Id: Ice21fee85203a8a55417e0ead8b509b8fd6705c1\n'}]",5,140567,470b7e53a8d7e7ba088b934c49163412c8ee5ed9,16,5,3,9101,,,0,"add multi-delete support for compute/image/net/volume

This is part1, add support for these objects:
compute.server
imagev1.image
imagev2.image
network.network
volume.volume
volume.backup
volume.snapshot

Closes-Bug: #1400597
Change-Id: Ice21fee85203a8a55417e0ead8b509b8fd6705c1
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/67/140567/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/image/v2/test_image.py', 'openstackclient/volume/v1/snapshot.py', 'openstackclient/volume/v1/backup.py', 'openstackclient/image/v1/image.py', 'openstackclient/network/v2/network.py', 'openstackclient/tests/compute/v2/test_server.py', 'openstackclient/volume/v1/volume.py', 'openstackclient/image/v2/image.py', 'openstackclient/tests/image/v1/test_image.py', 'openstackclient/tests/network/v2/test_network.py', 'openstackclient/compute/v2/server.py']",11,40cb7d3f4f445ddae1420480c893d0ee49283631,other_projects," """"""Delete server(s) command"""""" 'servers', nargs=""+"", help=_('Server(s) (name or ID)'), for server in parsed_args.servers: server_obj = utils.find_resource( compute_client.servers, server) compute_client.servers.delete(server_obj.id)"," """"""Delete server command"""""" 'server', help=_('Server (name or ID)'), server = utils.find_resource( compute_client.servers, parsed_args.server) compute_client.servers.delete(server.id)",67,54
openstack%2Fpython-openstackclient~master~I270434d657cf4ddc23c3aba2c704d6ef184b0dbc,openstack/python-openstackclient,master,I270434d657cf4ddc23c3aba2c704d6ef184b0dbc,add multi-delete support for identity,MERGED,2014-12-10 06:12:08.000000000,2014-12-23 22:23:33.000000000,2014-12-23 22:23:32.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 9101}]","[{'number': 1, 'created': '2014-12-10 06:12:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/0961fdb9e51a00a6f500572f6f30939ab25d2298', 'message': 'add multi-delete support for identify\n\nThis is part2. Add support for these objects:\nidentify.project(v2.0)\nidentify.role(v2.0)\nidentify.user(v2.0)\nidentify.project(v3)\nidentify.role(v3)\nidentify.user(v3)\nidentify.group(v3)\n\nChange-Id: I270434d657cf4ddc23c3aba2c704d6ef184b0dbc\n'}, {'number': 2, 'created': '2014-12-10 06:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/15de2ea4c262daeb4ba3a70279d9ae0bd922d516', 'message': 'add multi-delete support for identify\n\nThis is part2. Add support for these objects:\nidentify.project(v2.0)\nidentify.role(v2.0)\nidentify.user(v2.0)\nidentify.project(v3)\nidentify.role(v3)\nidentify.user(v3)\nidentify.group(v3)\n\nCloses-Bug: #1400597\nChange-Id: I270434d657cf4ddc23c3aba2c704d6ef184b0dbc\n'}, {'number': 3, 'created': '2014-12-10 07:20:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/cc6e0685a7fe0829f058f334e6063fd5daa044ef', 'message': 'add multi-delete support for identity\n\nThis is part2. Add support for these objects:\nidentity.project(v2.0)\nidentity.role(v2.0)\nidentity.user(v2.0)\nidentity.project(v3)\nidentity.role(v3)\nidentity.user(v3)\nidentity.group(v3)\n\nCloses-Bug: #1400597\nChange-Id: I270434d657cf4ddc23c3aba2c704d6ef184b0dbc\n'}, {'number': 4, 'created': '2014-12-23 01:37:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/66e272c8e5bb14d0698356c213f3f1a74935653c', 'message': 'add multi-delete support for identity\n\nThis is part2. Add support for these objects:\nidentity.project(v2.0)\nidentity.role(v2.0)\nidentity.user(v2.0)\nidentity.project(v3)\nidentity.role(v3)\nidentity.user(v3)\nidentity.group(v3)\n\nCloses-Bug: #1400597\nChange-Id: I270434d657cf4ddc23c3aba2c704d6ef184b0dbc\n'}, {'number': 5, 'created': '2014-12-23 01:39:40.000000000', 'files': ['openstackclient/identity/v2_0/role.py', 'openstackclient/identity/v2_0/user.py', 'openstackclient/tests/identity/v2_0/test_project.py', 'openstackclient/tests/identity/v3/test_user.py', 'openstackclient/identity/v3/project.py', 'openstackclient/tests/identity/v3/test_project.py', 'openstackclient/identity/v2_0/project.py', 'doc/source/command-objects/role.rst', 'openstackclient/tests/identity/v2_0/test_role.py', 'openstackclient/tests/identity/v3/test_role.py', 'doc/source/command-objects/project.rst', 'doc/source/command-objects/user.rst', 'openstackclient/identity/v3/role.py', 'openstackclient/identity/v3/group.py', 'openstackclient/tests/identity/v2_0/test_user.py', 'openstackclient/identity/v3/user.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d8f1cbd98461d4c2989384d29c7e2a99223468a9', 'message': 'add multi-delete support for identity\n\nThis is part2. Add support for these objects:\nidentity.project(v2.0)\nidentity.role(v2.0)\nidentity.user(v2.0)\nidentity.project(v3)\nidentity.role(v3)\nidentity.user(v3)\nidentity.group(v3)\n\nCloses-Bug: #1400597\nChange-Id: I270434d657cf4ddc23c3aba2c704d6ef184b0dbc\n'}]",5,140581,d8f1cbd98461d4c2989384d29c7e2a99223468a9,17,4,5,9101,,,0,"add multi-delete support for identity

This is part2. Add support for these objects:
identity.project(v2.0)
identity.role(v2.0)
identity.user(v2.0)
identity.project(v3)
identity.role(v3)
identity.user(v3)
identity.group(v3)

Closes-Bug: #1400597
Change-Id: I270434d657cf4ddc23c3aba2c704d6ef184b0dbc
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/81/140581/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/identity/v2_0/role.py', 'openstackclient/identity/v2_0/user.py', 'openstackclient/tests/identity/v2_0/test_project.py', 'openstackclient/tests/identity/v3/test_user.py', 'openstackclient/identity/v3/project.py', 'openstackclient/tests/identity/v3/test_project.py', 'openstackclient/identity/v2_0/project.py', 'openstackclient/tests/identity/v2_0/test_role.py', 'openstackclient/tests/identity/v3/test_role.py', 'openstackclient/identity/v3/role.py', 'openstackclient/identity/v3/group.py', 'openstackclient/tests/identity/v2_0/test_user.py', 'openstackclient/identity/v3/user.py']",13,0961fdb9e51a00a6f500572f6f30939ab25d2298,identity_project," """"""Delete user(s) command"""""" 'users', nargs=""+"", help='User(s) to delete (name or ID)', domain = None for user in parsed_args.users: if domain is not None: user_obj = utils.find_resource(identity_client.users, user, domain_id=domain.id) else: user_obj = utils.find_resource(identity_client.users, user) identity_client.users.delete(user_obj.id)"," """"""Delete user"""""" 'user', help='User to delete (name or ID)', user = utils.find_resource(identity_client.users, parsed_args.user, domain_id=domain.id) else: user = utils.find_resource(identity_client.users, parsed_args.user) identity_client.users.delete(user.id)",88,75
openstack%2Fcinder~master~I3d5cfeb2ee39ecb6af5b312dfa6c2a585cf8e0e3,openstack/cinder,master,I3d5cfeb2ee39ecb6af5b312dfa6c2a585cf8e0e3,Mock calls to rpm and dpkg from NetApp unit tests,MERGED,2014-12-19 16:17:50.000000000,2014-12-23 22:21:01.000000000,2014-12-23 14:42:43.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 7198}, {'_account_id': 9003}, {'_account_id': 9186}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11878}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 14206}]","[{'number': 1, 'created': '2014-12-19 16:17:50.000000000', 'files': ['cinder/volume/drivers/netapp/utils.py', 'cinder/tests/test_netapp_eseries_iscsi.py', 'cinder/tests/test_netapp_nfs.py', 'cinder/tests/test_netapp.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d555ca100aeb176bc021b8179d2a5cdfe10e168e', 'message': ""Mock calls to rpm and dpkg from NetApp unit tests\n\nThis patch fixes an issue wherein several NetApp unit tests ran\nOS rpm or dpkg commands because the callouts to these commands\nwere not mocked out during driver initialization.\n\nIt also replaces 'rpm -qa' with 'rpm -q' when that command is\ninvoked since the latter also works and is faster.\n\nCloses-Bug: 1393545\nChange-Id: I3d5cfeb2ee39ecb6af5b312dfa6c2a585cf8e0e3\n""}]",0,143127,d555ca100aeb176bc021b8179d2a5cdfe10e168e,32,15,1,9003,,,0,"Mock calls to rpm and dpkg from NetApp unit tests

This patch fixes an issue wherein several NetApp unit tests ran
OS rpm or dpkg commands because the callouts to these commands
were not mocked out during driver initialization.

It also replaces 'rpm -qa' with 'rpm -q' when that command is
invoked since the latter also works and is faster.

Closes-Bug: 1393545
Change-Id: I3d5cfeb2ee39ecb6af5b312dfa6c2a585cf8e0e3
",git fetch https://review.opendev.org/openstack/cinder refs/changes/27/143127/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/netapp/utils.py', 'cinder/tests/test_netapp_eseries_iscsi.py', 'cinder/tests/test_netapp_nfs.py', 'cinder/tests/test_netapp.py']",4,d555ca100aeb176bc021b8179d2a5cdfe10e168e,bug/1393545,"from cinder.volume.drivers.netapp import utils self.mock_object(utils, 'OpenStackInfo') self.mock_object(utils, 'OpenStackInfo') self.mock_object(utils, 'OpenStackInfo') self.mock_object(utils, 'OpenStackInfo') self.mock_object(utils, 'OpenStackInfo') self.mock_object(utils, 'OpenStackInfo') self.mock_object(client_base.Client, 'provide_ems') self.mock_object(utils, 'OpenStackInfo') self.mock_object(utils, 'OpenStackInfo') self.mock_object(utils, 'OpenStackInfo') self.mock_object(utils, 'OpenStackInfo') self.mock_object(utils, 'OpenStackInfo')",,20,1
openstack%2Fpuppet-openstack-specs~master~I8e37c06f188d1d061e4346a5af83d4f648ee26e7,openstack/puppet-openstack-specs,master,I8e37c06f188d1d061e4346a5af83d4f648ee26e7,Use OpenStackClient in Module Resources,MERGED,2014-11-20 23:59:16.000000000,2014-12-23 22:20:12.000000000,2014-12-23 22:20:12.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6554}, {'_account_id': 7155}, {'_account_id': 7156}, {'_account_id': 7616}, {'_account_id': 8482}, {'_account_id': 9060}, {'_account_id': 9146}, {'_account_id': 9983}]","[{'number': 1, 'created': '2014-11-20 23:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-specs/commit/0a25d1bfcef2e77888f6d12b5124a070fdb329b9', 'message': 'Use OpenStackClient in Module REsources\n\nChange-Id: I8e37c06f188d1d061e4346a5af83d4f648ee26e7\n'}, {'number': 2, 'created': '2014-11-20 23:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-specs/commit/097ee625a1fc4f0f262c78b774870dabf46c7ac0', 'message': 'Use OpenStackClient in Module Resources\n\nChange-Id: I8e37c06f188d1d061e4346a5af83d4f648ee26e7\n'}, {'number': 3, 'created': '2014-11-25 18:33:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-specs/commit/614465703be111ed5c05d4c4ffa37e438f55165e', 'message': 'Use OpenStackClient in Module Resources\n\nChange-Id: I8e37c06f188d1d061e4346a5af83d4f648ee26e7\n'}, {'number': 4, 'created': '2014-12-18 00:34:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-specs/commit/412788a817a75fa8cb08958fb1a2ef72b4172baa', 'message': 'Use OpenStackClient in Module Resources\n\nChange-Id: I8e37c06f188d1d061e4346a5af83d4f648ee26e7\n'}, {'number': 5, 'created': '2014-12-22 17:05:23.000000000', 'files': ['specs/use-openstackclient-in-aviator-resources.rst'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-specs/commit/83127b724f777dd71324e0f7d674828bc20f6d1d', 'message': 'Use OpenStackClient in Module Resources\n\nChange-Id: I8e37c06f188d1d061e4346a5af83d4f648ee26e7\n'}]",4,136186,83127b724f777dd71324e0f7d674828bc20f6d1d,28,10,5,8482,,,0,"Use OpenStackClient in Module Resources

Change-Id: I8e37c06f188d1d061e4346a5af83d4f648ee26e7
",git fetch https://review.opendev.org/openstack/puppet-openstack-specs refs/changes/86/136186/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/use-openstackclient-in-aviator-resources.rst'],1,0a25d1bfcef2e77888f6d12b5124a070fdb329b9,openstackclient,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================================= Use OpenstackClient in Module Resources ======================================= https://blueprints.launchpad.net/puppet-openstacklib/+spec/use-openstackclient-in-module-resources This spec proposes to alter the course proposed in blueprint: use-aviator-in-module-resources. The preferred solution to the problem description is to use the universal OpenStack command-line client. Problem description =================== The original problem is framed in the original Aviator blueprint. The problem that this spec proposes to solve is that using the API directly adds increased complexity which decreases maintainability. The providers must manage HTTP sessions themselves, which reinvents the wheel. Moreover, unit testing providers using the REST API is quite complex, since an entire HTTP session must be mocked using the VCR gem. Adding new tests becomes difficult since the new testwriter can't duplicate the original testwriter's environment, so parameters such as IP addresses will become inconsistent across tests. Aviator also does not appear to be actively keeping up with new changes in OpenStack, and it does not yet have support for the Neutron API. Proposed change =============== Work to use Aviator in the base provider in the openstacklib module has already been done. This work lays out the options that providers can use for authenticating against the REST APIs. The work to convert the providers to use the Aviator base provider has not been completed. The change would simply swap the calls to the Aviator library with calls to the openstack command. The base provider will no longer have to manage sessions itself, which means not having to differentiate between a password-authenticated session and using a token directly. Testing with the VCR gem will be dropped since responses from the openstack() command can be stubbed with mocha. OpenStackClient is actively keeping up with API changes and is rapidly developing, so we will monitor its progress and work with the developers to get features we need and fix bugs. Alternatives ------------ The alternative is to continue on the path with Aviator. Data model impact ----------------- None. Module API impact ----------------- The log_file parameter that puppet/util/aviator added to the puppet types would no longer be necessary since that was a requirement only for Aviator. The OpenStack client is bundled with other OpenStack services so it needs a manifest to install it explicitly. End user impact --------------------- There should be no end user impact. Performance Impact ------------------ OpenStackClient may not be as fast as using the API directly, but it is certainly not slower than using the individual command line clients. OpenStackClient plans to soon provide the ability to cache resources locally in order to speed up requests, so using that functionality should increase performance. Deployer impact --------------------- None. Developer impact ---------------- The parameters of the base provider's request() method can change slightly to better mirror how parameters will be passed to openstack(), but this is not a hard requirement as long as all the necessary information is passed to openstack(). Implementation ============== Assignee(s) ----------- Primary assignee: krinkle richm Work Items ---------- * Rewrite the base provider in openstacklib to reflect these changes. Work for this has already been started. * Rewrite the keystone providers to inherit from the new base provider and utilize its methods. * Rewrite providers for other modules Dependencies ============ None Testing ======= Unit tests will be updated to mock the openstack() command and we will remove all VCR fixtures. Documentation Impact ==================== None References ========== * Proofs of concept, still works in progress: - Base provider: https://review.openstack.org/#/c/134843/ - keystone_tenant rewritten: https://review.openstack.org/#/c/134844/ * Mailing list discussion: - https://groups.google.com/a/puppetlabs.com/forum/#!topic/puppet-openstack/GJwDHNAFVYw * IRC discussion: (starting at 14:36:50) - http://eavesdrop.openstack.org/meetings/puppet_openstack/2014/puppet_openstack.2014-11-17-14.01.log.html ",,146,0
openstack%2Fneutron~master~I60397b55354f9ee0877a2572133e7b28552ce8dc,openstack/neutron,master,I60397b55354f9ee0877a2572133e7b28552ce8dc,Fixes spelling error Closes-Bug: #1404341,ABANDONED,2014-12-23 19:05:19.000000000,2014-12-23 22:16:06.000000000,,"[{'_account_id': 3}, {'_account_id': 5115}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 12040}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-23 19:05:19.000000000', 'files': ['neutron/api/rpc/agentnotifiers/l3_rpc_agent_api.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ad113a005999d38b2bba27f90bc97b047523c339', 'message': 'Fixes spelling error\nCloses-Bug: #1404341\n\nChange-Id: I60397b55354f9ee0877a2572133e7b28552ce8dc\n'}]",0,143721,ad113a005999d38b2bba27f90bc97b047523c339,16,15,1,7448,,,0,"Fixes spelling error
Closes-Bug: #1404341

Change-Id: I60397b55354f9ee0877a2572133e7b28552ce8dc
",git fetch https://review.opendev.org/openstack/neutron refs/changes/21/143721/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/api/rpc/agentnotifiers/l3_rpc_agent_api.py'],1,ad113a005999d38b2bba27f90bc97b047523c339,143179, LOG.debug('Notify agent at %(host)s the message ', LOG.debug('Nofity agent at %(host)s the message ',1,1
openstack%2Ffuel-docs~master~I03590bb3ca561354dfdc4f2593511277d30c6791,openstack/fuel-docs,master,I03590bb3ca561354dfdc4f2593511277d30c6791,Replaces screenshot for network services,ABANDONED,2014-12-03 08:21:42.000000000,2014-12-23 22:16:06.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-12-03 08:21:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/56d24f574b2f19ae63e714a5f3e54cfe2832e80b', 'message': ""Replaces screenshot for network services\n\nSince UI is updated, let's replace the screenhot for network services.\n\nChange-Id: I03590bb3ca561354dfdc4f2593511277d30c6791\n""}, {'number': 2, 'created': '2014-12-11 14:02:02.000000000', 'files': ['_images/user_screen_shots/network-services.png'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/75ad698301a680774e050f88f9ccd919cee5f399', 'message': ""Replaces screenshot for network services\n\nSince UI is updated, let's replace the screenhot for network services.\n\nChange-Id: I03590bb3ca561354dfdc4f2593511277d30c6791\n""}]",0,138665,75ad698301a680774e050f88f9ccd919cee5f399,11,4,2,13082,,,0,"Replaces screenshot for network services

Since UI is updated, let's replace the screenhot for network services.

Change-Id: I03590bb3ca561354dfdc4f2593511277d30c6791
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/65/138665/1 && git format-patch -1 --stdout FETCH_HEAD,['_images/user_screen_shots/network-services.png'],1,56d24f574b2f19ae63e714a5f3e54cfe2832e80b,net-serv-screen,,,0,0
openstack%2Ffuel-docs~master~Id381726e8f1da89d4966545f8f7bc31974e33e8d,openstack/fuel-docs,master,Id381726e8f1da89d4966545f8f7bc31974e33e8d,6.0 Release Number,MERGED,2014-12-18 03:04:48.000000000,2014-12-23 22:12:37.000000000,2014-12-23 22:12:36.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}]","[{'number': 1, 'created': '2014-12-18 03:04:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/c92c1a54491f7c3fcf5b6b4fc5793785ef5f9887', 'message': '6.0 Release Number\n\nFixed the pdf/pdf* files that did not have 6.0\n\nUpdated the Release Notes preface date/release\nAlso fixed a typo in the include list to include update-upgrade issues\n\nChange-Id: Id381726e8f1da89d4966545f8f7bc31974e33e8d\n'}, {'number': 2, 'created': '2014-12-20 01:06:12.000000000', 'files': ['pdf/pdf_virtualbox.rst', 'pdf/pdf_operations.rst', 'pdf/pdf_reference.rst', 'pdf/pdf_terminology.rst', 'pdf/pdf_user.rst', 'pages/preface/preface.rst', 'pages/release-notes/v6-0-juno-full.rst', 'pdf/pdf_planning-guide.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/74b1f75254fb313af4ae7de71508ec2caf46d98e', 'message': '6.0 Release Number\n\nFixed the pdf/pdf* files that did not have 6.0\n\nUpdated the Release Notes preface date/release\nAlso fixed a typo in the include list to include update-upgrade issues\n\nChange-Id: Id381726e8f1da89d4966545f8f7bc31974e33e8d\n'}]",0,142653,74b1f75254fb313af4ae7de71508ec2caf46d98e,13,4,2,10014,,,0,"6.0 Release Number

Fixed the pdf/pdf* files that did not have 6.0

Updated the Release Notes preface date/release
Also fixed a typo in the include list to include update-upgrade issues

Change-Id: Id381726e8f1da89d4966545f8f7bc31974e33e8d
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/53/142653/1 && git format-patch -1 --stdout FETCH_HEAD,"['pdf/pdf_virtualbox.rst', 'pdf/pdf_operations.rst', 'pdf/pdf_reference.rst', 'pdf/pdf_terminology.rst', 'pdf/pdf_user.rst', 'pages/preface/preface.rst', 'pages/release-notes/v6-0-juno-full.rst', 'pdf/pdf_planning-guide.rst']",8,c92c1a54491f7c3fcf5b6b4fc5793785ef5f9887,fix-release-number, | Mirantis OpenStack v6.0 | .. cssclass:: right|, | Mirantis OpenStack v5.1 | .. cssclass:: right|,11,7
openstack%2Ffuel-docs~master~Ie64bb84295d3d818745bfeb0460785ee97bae70a,openstack/fuel-docs,master,Ie64bb84295d3d818745bfeb0460785ee97bae70a,Update Murano testing documentation,MERGED,2014-12-19 12:11:33.000000000,2014-12-23 22:07:32.000000000,2014-12-23 22:07:31.000000000,"[{'_account_id': 3}, {'_account_id': 7126}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7227}, {'_account_id': 7244}, {'_account_id': 7428}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 8592}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 12200}, {'_account_id': 13082}, {'_account_id': 13962}]","[{'number': 1, 'created': '2014-12-19 12:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/242666fe523dfef1f17c291943479aa3a2ef4f22', 'message': 'Update Murano testing documentation\n\nAdded link to image with Murano agent\n\nChange-Id: Ie64bb84295d3d818745bfeb0460785ee97bae70a\nPartially Closes-Bug: #1395666\n'}, {'number': 2, 'created': '2014-12-20 13:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/7d993538dd3603382be05be621dc0030f70fbcf6', 'message': 'Update Murano testing documentation\n\nAdded link to image with Murano agent\n\nChange-Id: Ie64bb84295d3d818745bfeb0460785ee97bae70a\nPartial-Bug: #1395666\n'}, {'number': 3, 'created': '2014-12-21 18:53:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/ef71224e5464b0e17df9b68f6dca9324a1ed4850', 'message': 'Update Murano testing documentation\n\nAdded link to image with Murano agent\n\nChange-Id: Ie64bb84295d3d818745bfeb0460785ee97bae70a\nPartial-Bug: #1395666\n'}, {'number': 4, 'created': '2014-12-21 21:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f0c621fca43c12fd9199854b6970f209073013ad', 'message': 'Update Murano testing documentation\n\nAdded link to image with Murano agent\n\nChange-Id: Ie64bb84295d3d818745bfeb0460785ee97bae70a\nPartial-Bug: #1395666\n'}, {'number': 5, 'created': '2014-12-22 09:09:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/5411b028537a8772f8fb1a67439f65984c96ead4', 'message': 'Update Murano testing documentation\n\nAdded link to image with Murano agent\n\nChange-Id: Ie64bb84295d3d818745bfeb0460785ee97bae70a\nPartial-Bug: #1395666\n'}, {'number': 6, 'created': '2014-12-22 10:28:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/dce65a030c04d1b40fa56a132e607cb643700689', 'message': 'Update Murano testing documentation\n\nAdded link to image with Murano agent\n\nChange-Id: Ie64bb84295d3d818745bfeb0460785ee97bae70a\nPartial-Bug: #1395666\n'}, {'number': 7, 'created': '2014-12-22 10:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/9c6a0df29f4e7a172ca1a3fee4e1446aa491d47b', 'message': 'Update Murano testing documentation\n\nAdded link to image with Murano agent\n\nChange-Id: Ie64bb84295d3d818745bfeb0460785ee97bae70a\nPartial-Bug: #1395666\n'}, {'number': 8, 'created': '2014-12-22 13:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/22cb2db23d2f995e79bc70fd3735b33811618734', 'message': 'Update Murano testing documentation\n\nAdded link to image with Murano agent\n\nChange-Id: Ie64bb84295d3d818745bfeb0460785ee97bae70a\nPartial-Bug: #1395666\n'}, {'number': 9, 'created': '2014-12-22 20:21:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/0ce34fd4037b00f7a55e888bc7becfd8c0a8d53a', 'message': 'Update Murano testing documentation\n\nAdded link to image with Murano agent\n\nChange-Id: Ie64bb84295d3d818745bfeb0460785ee97bae70a\nPartial-Bug: #1395666\n'}, {'number': 10, 'created': '2014-12-23 09:31:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a4f29ec2c3757c6274af8d069c2158b7fc5648a4', 'message': 'Update Murano testing documentation\n\nAdded link to image with Murano agent\n\nChange-Id: Ie64bb84295d3d818745bfeb0460785ee97bae70a\nPartial-Bug: #1395666\n'}, {'number': 11, 'created': '2014-12-23 09:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/360a94bee2595a4bd4b9f51755b65e4d5e7a673f', 'message': 'Update Murano testing documentation\n\nAdded link to image with Murano agent\n\nChange-Id: Ie64bb84295d3d818745bfeb0460785ee97bae70a\nPartial-Bug: #1395666\n'}, {'number': 12, 'created': '2014-12-23 20:04:50.000000000', 'files': ['pages/operations/murano/7482-test-prepare.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/05e329d8bc7538fa4cfbc23dc0405e8759eb46ed', 'message': 'Update Murano testing documentation\n\nAdded link to image with Murano agent\n\nChange-Id: Ie64bb84295d3d818745bfeb0460785ee97bae70a\nPartial-Bug: #1395666\n'}]",28,143064,05e329d8bc7538fa4cfbc23dc0405e8759eb46ed,90,17,12,13962,,,0,"Update Murano testing documentation

Added link to image with Murano agent

Change-Id: Ie64bb84295d3d818745bfeb0460785ee97bae70a
Partial-Bug: #1395666
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/64/143064/5 && git format-patch -1 --stdout FETCH_HEAD,['pages/operations/murano/7482-test-prepare.rst'],1,242666fe523dfef1f17c291943479aa3a2ef4f22,murano-test, Or you can download the following image: http://murano-files.mirantis.com/ubuntu_14_04-murano-agent_stable_juno.qcow2 ,,4,0
openstack%2Fbarbican~master~I8dea6ca2753538f6a74492916b46643e6237bc71,openstack/barbican,master,I8dea6ca2753538f6a74492916b46643e6237bc71,Fixes crypto enabled plugins configuration,MERGED,2014-12-23 06:03:49.000000000,2014-12-23 22:03:32.000000000,2014-12-23 22:03:31.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7244}, {'_account_id': 7262}, {'_account_id': 7687}, {'_account_id': 8004}]","[{'number': 1, 'created': '2014-12-23 06:03:49.000000000', 'files': ['requirements.txt', 'barbican/plugin/crypto/crypto.py', 'barbican/plugin/crypto/manager.py', 'barbican/plugin/store_crypto.py', 'barbican/tests/plugin/test_store_crypto.py', 'barbican/tests/plugin/crypto/test_manager.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/81a4dbfd0eecb299c492e33b227acc16b70f9c83', 'message': 'Fixes crypto enabled plugins configuration\n\nThis fix creates the singleton crypto plugin manager via a factory\nmethod rather than at module load time, allowing for configuration\noptions (such as enabled plugins) to be determined prior to creating\nthe singleton.\n\nChange-Id: I8dea6ca2753538f6a74492916b46643e6237bc71\n'}]",0,143601,81a4dbfd0eecb299c492e33b227acc16b70f9c83,21,6,1,7789,,,0,"Fixes crypto enabled plugins configuration

This fix creates the singleton crypto plugin manager via a factory
method rather than at module load time, allowing for configuration
options (such as enabled plugins) to be determined prior to creating
the singleton.

Change-Id: I8dea6ca2753538f6a74492916b46643e6237bc71
",git fetch https://review.opendev.org/openstack/barbican refs/changes/01/143601/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'barbican/plugin/crypto/crypto.py', 'barbican/plugin/crypto/manager.py', 'barbican/plugin/store_crypto.py', 'barbican/tests/plugin/test_store_crypto.py', 'barbican/tests/plugin/crypto/test_manager.py']",6,81a4dbfd0eecb299c492e33b227acc16b70f9c83,bug/1404978,"# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. from barbican.plugin.crypto import manager from barbican.tests import utils class WhenTestingManager(utils.BaseTestCase): def test_can_override_enabled_plugins(self): """"""Verify can override default configuration for plugin selection."""""" manager.CONF.set_override( ""enabled_crypto_plugins"", ['foo_plugin'], group='crypto') manager_to_test = manager.get_manager() self.assertIsInstance( manager_to_test, manager._CryptoPluginManager) self.assertListEqual(['foo_plugin'], manager_to_test._names) ",,68,27
openstack%2Fneutron-specs~master~I83d6e51cf1038dbf55e6026f0f7b595416f2f235,openstack/neutron-specs,master,I83d6e51cf1038dbf55e6026f0f7b595416f2f235,blueprint dhcp-network-scheduling-failover,ABANDONED,2014-11-19 11:55:21.000000000,2014-12-23 21:51:45.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 2592}, {'_account_id': 6072}]","[{'number': 1, 'created': '2014-11-19 11:55:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/a992c8112ec7a389f3367bc21f328dfe894775a2', 'message': 'blueprint dhcp-network-scheduling-failover\n\nAdd option to automatically remove and/or reschedule\nnetworks from dead DHCP agents.\n\nChange-Id: I83d6e51cf1038dbf55e6026f0f7b595416f2f235\n'}, {'number': 2, 'created': '2014-12-04 14:59:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8b4f6776bc1f2db71abe2e2d9727f4b24a7c9fc1', 'message': 'blueprint dhcp-network-scheduling-failover\n\nAdd option to automatically remove and/or reschedule\nnetworks from dead DHCP agents.\n\nChange-Id: I83d6e51cf1038dbf55e6026f0f7b595416f2f235\n'}, {'number': 3, 'created': '2014-12-04 15:24:28.000000000', 'files': ['specs/kilo/dhcp-scheduling-failover.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/50d6aa22ae076bcc66eaa76a45449b16ef761d21', 'message': 'blueprint dhcp-network-scheduling-failover\n\nAdd option to automatically remove and/or reschedule\nnetworks from dead DHCP agents.\n\nChange-Id: I83d6e51cf1038dbf55e6026f0f7b595416f2f235\n'}]",19,135575,50d6aa22ae076bcc66eaa76a45449b16ef761d21,15,4,3,6072,,,0,"blueprint dhcp-network-scheduling-failover

Add option to automatically remove and/or reschedule
networks from dead DHCP agents.

Change-Id: I83d6e51cf1038dbf55e6026f0f7b595416f2f235
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/75/135575/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/dhcp-scheduling-failover.rst'],1,a992c8112ec7a389f3367bc21f328dfe894775a2,bp/dhcp-network-scheduling-failover,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Title of your blueprint ========================================== DHCP network scheduling failover Problem Description =================== When neutron server considers one of DHCP agents dead, it should take care of networks which were hosted by the dead DHCP agent. Proposed Change =============== Introduce new configuration option allow_automatic_dhcp_failover so neutron server will remove dhcp-enabled networks from dead DHCP agents. In case network_auto_schedule is True, network is then rescheduled to an active DHCP agent. The goal is to allow neutron server or external monitoring system to manage network to agent bindings. Data Model Impact ----------------- None REST API Impact --------------- None Security Impact --------------- None Notifications Impact -------------------- None Other End User Impact --------------------- Users might be getting more reliable service in the environment with mutliple DHCP agents Performance Impact ------------------ None Other Deployer Impact --------------------- New option is introduced defaulting to True. In other words, by default, networks from dead DHCP agents will be rescheduled to alive DHCP agents. Developer Impact ---------------- None Community Impact ---------------- Community is happily endorsing the change :) Alternatives ------------ This functionality can be implemented via external tools that can add/remove networks from DHCP agents using REST API. The benefit of doing this in neutron server (beside that external tools are not needed) is proper scheduling. Implementation ============== Implementation is straightfowrard. Periodic agent liveleness check is added to DhcpAgentSchedulerDbMixin which is inherited by all core plugins. Core plugins start periodic check at the point their constructor is invoked. Periodic check detects dead agent using time thresholds and if it founds dead DHCP agent, it removes network-to-agent binding and reschedules the network if configured so. Assignee(s) ----------- enikanorov Work Items ---------- Dependencies ============ Testing ======= Proposed change is tested in HA environment on the cloud with 3 network controllers each having DHCP agent. Tempest Tests ------------- None Functional Tests ---------------- None API Tests --------- None Documentation Impact ==================== User Documentation ------------------ Note about new config option must be added to documentation Developer Documentation ----------------------- None References ========== 1. Implementation https://review.openstack.org/#/c/131150 ",,146,0
openstack%2Fneutron~master~Ie7c8518b92be46a4eea4e9345713fdeba844126d,openstack/neutron,master,Ie7c8518b92be46a4eea4e9345713fdeba844126d,get_binary_name should returns strings without spaces,MERGED,2014-12-19 15:14:14.000000000,2014-12-23 21:43:32.000000000,2014-12-23 21:43:30.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 1131}, {'_account_id': 2035}, {'_account_id': 2874}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 7293}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-19 15:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/99cd11aaacd1f3482b42c8e229cdb6c5d783f9ae', 'message': ""get_binary_name should returns strings without spaces\n\nIptables does not support chain names with spaces. It implies\nget_binary_name should return strings without spaces (they are used as\nchain name prefix). But currently 'python -m unittest $module' implies\nspaces in get_binary_name() result, it disallows to use it when $module\nis a functional test module. This change replaces spaces with\nunderscores in get_binary_name results.\n\nChange-Id: Ie7c8518b92be46a4eea4e9345713fdeba844126d\nCloses-Bug: #1404250\n""}, {'number': 2, 'created': '2014-12-23 15:34:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c8ff3f09b4cedce920febd9642ed9136118a7bb5', 'message': ""get_binary_name should returns strings without spaces\n\nIptables does not support chain names with spaces. It implies\nget_binary_name should return strings without spaces (they are used as\nchain name prefix). But currently 'python -m unittest $module' implies\nspaces in get_binary_name() result, it disallows to use it when $module\nis a functional test module. This change replaces spaces with\nunderscores in get_binary_name results.\n\nChange-Id: Ie7c8518b92be46a4eea4e9345713fdeba844126d\nCloses-Bug: #1404250\n""}, {'number': 3, 'created': '2014-12-23 18:50:08.000000000', 'files': ['neutron/tests/unit/test_iptables_manager.py', 'neutron/agent/linux/iptables_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0937dca14b1f60bdf3d4377ee305d41a1721f153', 'message': ""get_binary_name should returns strings without spaces\n\nIptables does not support chain names with spaces. It implies\nget_binary_name should return strings without spaces (they are used as\nchain name prefix). But currently 'python -m unittest $module' implies\nspaces in get_binary_name() result, it disallows to use it when $module\nis a functional test module. This change replaces spaces with\nunderscores in get_binary_name results.\n\nChange-Id: Ie7c8518b92be46a4eea4e9345713fdeba844126d\nCloses-Bug: #1404250\n""}]",5,143108,0937dca14b1f60bdf3d4377ee305d41a1721f153,86,28,3,8124,,,0,"get_binary_name should returns strings without spaces

Iptables does not support chain names with spaces. It implies
get_binary_name should return strings without spaces (they are used as
chain name prefix). But currently 'python -m unittest $module' implies
spaces in get_binary_name() result, it disallows to use it when $module
is a functional test module. This change replaces spaces with
underscores in get_binary_name results.

Change-Id: Ie7c8518b92be46a4eea4e9345713fdeba844126d
Closes-Bug: #1404250
",git fetch https://review.opendev.org/openstack/neutron refs/changes/08/143108/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_iptables_manager.py', 'neutron/agent/linux/iptables_manager.py']",2,99cd11aaacd1f3482b42c8e229cdb6c5d783f9ae,143108," return os.path.basename(sys.argv[0])[:16].replace(' ', '_')", return os.path.basename(sys.argv[0])[:16],10,1
openstack%2Fnova~master~Ic7fba3e750196dfb3296291cd4d4d21bc06d47c6,openstack/nova,master,Ic7fba3e750196dfb3296291cd4d4d21bc06d47c6,Cleanup log marker in neutronv2 api,MERGED,2014-08-19 12:32:41.000000000,2014-12-23 21:38:27.000000000,2014-12-23 21:38:24.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 642}, {'_account_id': 1561}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6282}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11531}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-08-19 12:32:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/66d37f5e8c7d3a7f7f9d651b23b897d3ed641238', 'message': 'Cleanup log marker in neutronv2 api\n\nCleanup log according to docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nChange-Id: Ic7fba3e750196dfb3296291cd4d4d21bc06d47c6\n'}, {'number': 2, 'created': '2014-08-20 08:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d1883db0558a2587bcac28917204d5a205aafe7b', 'message': 'Cleanup log marker in neutronv2 api\n\nCleanup log according to docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nChange-Id: Ic7fba3e750196dfb3296291cd4d4d21bc06d47c6\n'}, {'number': 3, 'created': '2014-08-20 14:15:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b7f0cb846f0d46cd6966e144c3fabbc84d610d09', 'message': 'Cleanup log marker in neutronv2 api\n\nCleanup log according to docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nChange-Id: Ic7fba3e750196dfb3296291cd4d4d21bc06d47c6\n'}, {'number': 4, 'created': '2014-08-21 00:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7ac2f52465eefddceb2512373aac39bb54ce506d', 'message': 'Cleanup log marker in neutronv2 api\n\nCleanup log according to docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nChange-Id: Ic7fba3e750196dfb3296291cd4d4d21bc06d47c6\n'}, {'number': 5, 'created': '2014-10-09 02:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e0a3326fd3faa1d3370aa0ab16c90d24178cbfe2', 'message': 'Cleanup log marker in neutronv2 api\n\nCleanup log according to docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nChange-Id: Ic7fba3e750196dfb3296291cd4d4d21bc06d47c6\n'}, {'number': 6, 'created': '2014-10-09 04:39:48.000000000', 'files': ['nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3567435e859fa18032b1674820979b6a71d3983e', 'message': 'Cleanup log marker in neutronv2 api\n\nCleanup log according to docs.openstack.org/developer/oslo.i18n/guidelines.html\nAdd LI marker for LOG.info.\nCorrect debug log information in _get_instance_nw_info function.\nand other log cleanup.\n\nChange-Id: Ic7fba3e750196dfb3296291cd4d4d21bc06d47c6\n'}]",17,115271,3567435e859fa18032b1674820979b6a71d3983e,62,16,6,12175,,,0,"Cleanup log marker in neutronv2 api

Cleanup log according to docs.openstack.org/developer/oslo.i18n/guidelines.html
Add LI marker for LOG.info.
Correct debug log information in _get_instance_nw_info function.
and other log cleanup.

Change-Id: Ic7fba3e750196dfb3296291cd4d4d21bc06d47c6
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/115271/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/neutronv2/api.py'],1,66d37f5e8c7d3a7f7f9d651b23b897d3ed641238,cleanup,"from nova.i18n import _, _LE, _LI, _LW msg = _(""Failed to update port %s"") msg = _(""Failed to delete port %s"") LOG.info(_LI('Unable to reset device ID for port %s'), port, LOG.exception(_(""Failed to delete neutron port %s""), LOG.debug('get_instance_nw_info()', instance=instance) LOG.debug('_get_instance_nw_info()', instance=instance) LOG.debug('validate_networks() for %s', requested_networks) LOG.exception(_(""Failed to access port %s""), LOG.info(_LI('re-assign floating IP %(address)s from ' LOG.exception(_('Unable to access floating IP %s'), id) LOG.exception(_('Unable to access floating IP %(fixed_ip)s ' 'for port %(port_id)s'), msg = _(""Unable to update host of port %s"")","from nova.i18n import _, _LE, _LW msg = _LE(""Failed to update port %s"") msg = _LE(""Failed to delete port %s"") LOG.info(_('Unable to reset device ID for port %s'), port, LOG.exception(_LE(""Failed to delete neutron port %s""), LOG.debug('get_instance_nw_info()', instance=instance) LOG.debug('validate_networks() for %s', requested_networks) LOG.exception(_LE(""Failed to access port %s""), LOG.info(_('re-assign floating IP %(address)s from ' LOG.exception(_LE('Unable to access floating IP %s'), id) LOG.exception(_LE('Unable to access floating IP %(fixed_ip)s ' 'for port %(port_id)s'), msg = _LE(""Unable to update host of port %s"")",14,14
openstack%2Ffuel-docs~master~I358ccdb5cdac3683efc0b82d4d1b942ba7a7ee3f,openstack/fuel-docs,master,I358ccdb5cdac3683efc0b82d4d1b942ba7a7ee3f,ML2 -- fixed release-specific mention,MERGED,2014-12-22 20:27:56.000000000,2014-12-23 21:33:54.000000000,2014-12-23 21:33:54.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8971}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-12-22 20:27:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/6fe58224dd97bc848ab1eb824e6c8597e1ca8a7c', 'message': 'ML2 -- deleted release-specific mention\n\nThis was first implemented in 5.1; no longer need to specify\nthe release number.\n\nChange-Id: I358ccdb5cdac3683efc0b82d4d1b942ba7a7ee3f\n'}, {'number': 2, 'created': '2014-12-23 19:15:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/2120bb05d331168c67f2e34374f2b3de141996d2', 'message': 'ML2 -- deleted release-specific mention\n\nThis was first implemented in 5.1; no longer need to specify\nthe release number.\n\nChange-Id: I358ccdb5cdac3683efc0b82d4d1b942ba7a7ee3f\n'}, {'number': 3, 'created': '2014-12-23 19:50:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/943b115cd550698c3d76210d48253a30f75ad92f', 'message': 'ML2 -- fixed release-specific mention\n\nThis was first implemented in 5.1, still relevant in more recent releases.\n\nExpanded the explanation of relation between ML2 and Mellanox features.\n\nChange-Id: I358ccdb5cdac3683efc0b82d4d1b942ba7a7ee3f\n'}, {'number': 4, 'created': '2014-12-23 21:14:06.000000000', 'files': ['pages/operations/3000-ml2-create.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/16ed16df29e21f2a83dd9c4ba5c40a3bbec38086', 'message': 'ML2 -- fixed release-specific mention\n\nThis was first implemented in 5.1, still relevant in more recent releases.\n\nExpanded the explanation of relation between ML2 and Mellanox features.\n\nChange-Id: I358ccdb5cdac3683efc0b82d4d1b942ba7a7ee3f\n'}]",6,143528,16ed16df29e21f2a83dd9c4ba5c40a3bbec38086,25,5,4,10014,,,0,"ML2 -- fixed release-specific mention

This was first implemented in 5.1, still relevant in more recent releases.

Expanded the explanation of relation between ML2 and Mellanox features.

Change-Id: I358ccdb5cdac3683efc0b82d4d1b942ba7a7ee3f
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/28/143528/4 && git format-patch -1 --stdout FETCH_HEAD,['pages/operations/3000-ml2-create.rst'],1,6fe58224dd97bc848ab1eb824e6c8597e1ca8a7c,ml2-tiny,Fuel supports :ref:`ml2-term` drivers,Fuel 5.1 supports :ref:`ml2-term` drivers,1,1
openstack%2Fproject-config~master~I3f46c9e20440f766db5e6b4a65d71a99651adf17,openstack/project-config,master,I3f46c9e20440f766db5e6b4a65d71a99651adf17,Use prepare_tempest_testrepository as part of devstack node script,ABANDONED,2014-12-19 00:04:46.000000000,2014-12-23 21:24:28.000000000,,"[{'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 4146}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-19 00:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/1d8eca3bb065d0f3866d37141a56cae9d90ae225', 'message': ""Use prepare_tempest_testrepository as part of devstack node script\n\nThis commit adds a call out to the new prepare_tempest_testrepository\nscript in order to pre-seed tempest's testrepository with data from\nthe subunit2sql DB. This will enable the testr scheduler to perform\nsome worker balance optimization based on the average run_times from\nall the previous gate runs.\n\nChange-Id: I3f46c9e20440f766db5e6b4a65d71a99651adf17\n""}, {'number': 2, 'created': '2014-12-23 17:43:04.000000000', 'files': ['nodepool/elements/cache-devstack/extra-data.d/51-cache-testrepository-db', 'nodepool/scripts/prepare_node_devstack.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/781da8b343eb500d36cda4e20f604625020dfc9f', 'message': ""Use prepare_tempest_testrepository as part of devstack node script\n\nThis commit adds a call out to the new prepare_tempest_testrepository\nscript in order to pre-seed tempest's testrepository with data from\nthe subunit2sql DB. This will enable the testr scheduler to perform\nsome worker balance optimization based on the average run_times from\nall the previous gate runs.\n\nChange-Id: I3f46c9e20440f766db5e6b4a65d71a99651adf17\n""}]",0,142940,781da8b343eb500d36cda4e20f604625020dfc9f,9,5,2,5196,,,0,"Use prepare_tempest_testrepository as part of devstack node script

This commit adds a call out to the new prepare_tempest_testrepository
script in order to pre-seed tempest's testrepository with data from
the subunit2sql DB. This will enable the testr scheduler to perform
some worker balance optimization based on the average run_times from
all the previous gate runs.

Change-Id: I3f46c9e20440f766db5e6b4a65d71a99651adf17
",git fetch https://review.opendev.org/openstack/project-config refs/changes/40/142940/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/scripts/prepare_node_devstack.sh'],1,1d8eca3bb065d0f3866d37141a56cae9d90ae225,136234,TEMPEST_DIR=${TEMPEST_DIR:-/opt/git/tempest}# Pre-seed tempest testrepository with data from subunit2sql sudo -i /opt/nodepool-scripts/prepare_tempest_testrepository.py $TEMPEST_DIR ,,4,0
openstack%2Ffuel-docs~master~Ifcee05c3175853fa060d449b939ee6748b04aa00,openstack/fuel-docs,master,Ifcee05c3175853fa060d449b939ee6748b04aa00,OpenStack logs info,ABANDONED,2014-12-21 19:43:27.000000000,2014-12-23 21:05:35.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-12-21 19:43:27.000000000', 'files': ['pages/operations/troubleshoot/1000-logs.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/ef620fa008f19702435dea1cbb991ece728aba92', 'message': 'OpenStack logs info\n\nAdds information about oslo logs for OpenStack services\nthat Nailgun cannot parse.\n\nPartial-Bug: 1401852\n\nChange-Id: Ifcee05c3175853fa060d449b939ee6748b04aa00\n'}]",5,143312,ef620fa008f19702435dea1cbb991ece728aba92,10,6,1,10014,,,0,"OpenStack logs info

Adds information about oslo logs for OpenStack services
that Nailgun cannot parse.

Partial-Bug: 1401852

Change-Id: Ifcee05c3175853fa060d449b939ee6748b04aa00
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/12/143312/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/operations/troubleshoot/1000-logs.rst'],1,ef620fa008f19702435dea1cbb991ece728aba92,bug/1401852,"Logging for OpenStack services ++++++++++++++++++++++++++++++config file under */etc* (for example, */etc/nova/nova.conf*) and modify the values of **debug** and **use_syslog** flags as follows::Disabling syslog protects the Fuel master node from being overloaded by aforget to revert both flags to the original values when you are done with Note that some OpenStack logs from the target nodes (such as *nova-api.log*) can not be displayed from the Fuel UI because they use a new Oslo format that was first introduced in Juno and that Nailgun cannot parse. The following OpenStack logs use a format that Nailgun can parse: heat-manage.log, heat-api-cfn.log, heat-api.log, heat-api-cloudwatch.log, glance-manage.log, glance-registry.log, glance-api.log, neutron-server.log, neutron-openvswitch-agent.log, neutron-l3-agent.log, neutron-netns-cleanup.log, neutron-metadata-agent.log. ", Enabling debug logging for OpenStack services +++++++++++++++++++++++++++++++++++++++++++++config file under */etc* (e.g. */etc/nova/nova.conf*) and revert the values of **debug** and **use_syslog** flags like this::Disabling syslog will protect the Fuel master node from being overloaded from aforget to revert both flags back to original values when done with,19,7
openstack%2Fhorizon~master~I5ef42067887e1f1f1f5ee3224df7b6391be0a375,openstack/horizon,master,I5ef42067887e1f1f1f5ee3224df7b6391be0a375,Support for resizing a trove instance,MERGED,2014-07-22 18:21:59.000000000,2014-12-23 20:44:22.000000000,2014-12-23 20:44:20.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5293}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 8871}, {'_account_id': 9659}, {'_account_id': 9749}, {'_account_id': 9750}, {'_account_id': 9981}, {'_account_id': 10295}, {'_account_id': 11997}, {'_account_id': 12355}, {'_account_id': 12857}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-07-22 18:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/acc000485fde748f760f84731f5fab204126ba56', 'message': 'Support for resizing a trove instance\n\nAdded menu item and dialog to allow the\nuser to select a new flavor for their\ntrove instance\n\nChange-Id: I5ef42067887e1f1f1f5ee3224df7b6391be0a375\nImplements: blueprint trove-resize-instance-dialog\n'}, {'number': 2, 'created': '2014-07-31 14:30:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b0d68d80e61a96fd70732427039e764b0b62bcf4', 'message': 'Support for resizing a trove instance\n\nAdded menu item and dialog to allow the\nuser to select a new flavor for their\ntrove instance\n\nChange-Id: I5ef42067887e1f1f1f5ee3224df7b6391be0a375\nImplements: blueprint trove-resize-instance-dialog\n'}, {'number': 3, 'created': '2014-09-03 13:35:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/89a88f6ec956d84e17f787e6afcda602704525ce', 'message': 'Support for resizing a trove instance\n\nAdded menu item and dialog to allow the\nuser to select a new flavor for their\ntrove instance\n\nChange-Id: I5ef42067887e1f1f1f5ee3224df7b6391be0a375\nImplements: blueprint trove-resize-instance-dialog\n'}, {'number': 4, 'created': '2014-09-14 14:11:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1197dad411972b43ef4bb9284e8f327b9ae30401', 'message': 'Support for resizing a trove instance\n\nAdded menu item and dialog to allow the\nuser to select a new flavor for their\ntrove instance\n\nChange-Id: I5ef42067887e1f1f1f5ee3224df7b6391be0a375\nImplements: blueprint trove-resize-instance-dialog\n'}, {'number': 5, 'created': '2014-10-28 17:34:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f4acc03fe2aefbf1a6be850228b918c9f00a2f95', 'message': 'Support for resizing a trove instance\n\nAdded menu item and dialog to allow the\nuser to select a new flavor for their\ntrove instance\n\nChange-Id: I5ef42067887e1f1f1f5ee3224df7b6391be0a375\nImplements: blueprint trove-resize-instance-dialog\n'}, {'number': 6, 'created': '2014-10-29 13:45:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6d73c8d2e6906c673ccc70ed83531659234b0dcf', 'message': 'Support for resizing a trove instance\n\nAdded menu item and dialog to allow the\nuser to select a new flavor for their\ntrove instance\n\nChange-Id: I5ef42067887e1f1f1f5ee3224df7b6391be0a375\nImplements: blueprint trove-resize-instance-dialog\n'}, {'number': 7, 'created': '2014-11-24 15:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/50a0cd9ac349716899837411cb96685ed2094d0d', 'message': 'Support for resizing a trove instance\n\nAdded menu item and dialog to allow the\nuser to select a new flavor for their\ntrove instance\n\nChange-Id: I5ef42067887e1f1f1f5ee3224df7b6391be0a375\nImplements: blueprint trove-resize-instance-dialog\n'}, {'number': 8, 'created': '2014-11-24 15:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c8b76afc993d271c134c00eac5d9aea1c8c1196a', 'message': 'Support for resizing a trove instance\n\nAdded menu item and dialog to allow the\nuser to select a new flavor for their\ntrove instance\n\nChange-Id: I5ef42067887e1f1f1f5ee3224df7b6391be0a375\nImplements: blueprint trove-resize-instance-dialog\n'}, {'number': 9, 'created': '2014-11-24 16:21:14.000000000', 'files': ['openstack_dashboard/dashboards/project/databases/views.py', 'openstack_dashboard/api/trove.py', 'openstack_dashboard/dashboards/project/databases/forms.py', 'openstack_dashboard/dashboards/project/databases/templates/databases/resize_instance.html', 'openstack_dashboard/test/test_data/trove_data.py', 'openstack_dashboard/dashboards/project/databases/templates/databases/_resize_instance.html', 'openstack_dashboard/dashboards/project/databases/tables.py', 'openstack_dashboard/dashboards/project/databases/tests.py', 'openstack_dashboard/dashboards/project/databases/urls.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/178f608c2be1b1bed832d90ea4f26e91fd19cbdf', 'message': 'Support for resizing a trove instance\n\nAdded menu item and dialog to allow the\nuser to select a new flavor for their\ntrove instance\n\nChange-Id: I5ef42067887e1f1f1f5ee3224df7b6391be0a375\nImplements: blueprint trove-resize-instance-dialog\n'}]",17,108793,178f608c2be1b1bed832d90ea4f26e91fd19cbdf,52,15,9,9750,,,0,"Support for resizing a trove instance

Added menu item and dialog to allow the
user to select a new flavor for their
trove instance

Change-Id: I5ef42067887e1f1f1f5ee3224df7b6391be0a375
Implements: blueprint trove-resize-instance-dialog
",git fetch https://review.opendev.org/openstack/horizon refs/changes/93/108793/9 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/databases/views.py', 'openstack_dashboard/api/trove.py', 'openstack_dashboard/dashboards/project/databases/forms.py', 'openstack_dashboard/dashboards/project/databases/templates/databases/resize_instance.html', 'openstack_dashboard/test/test_data/trove_data.py', 'openstack_dashboard/dashboards/project/databases/templates/databases/_resize_instance.html', 'openstack_dashboard/dashboards/project/databases/tables.py', 'openstack_dashboard/dashboards/project/databases/tests.py', 'openstack_dashboard/dashboards/project/databases/urls.py']",9,acc000485fde748f760f84731f5fab204126ba56,bp/trove-resize-instance-dialog," name='resize_volume'), url(INSTANCES % 'resize_instance', views.ResizeInstanceView.as_view(), name='resize_instance')", name='resize_volume'),248,2
openstack%2Fheat~master~I5f1dc6d1c1cfc7d0b795fe43fdb677969372bd0b,openstack/heat,master,I5f1dc6d1c1cfc7d0b795fe43fdb677969372bd0b,Fix NetworkInUse when deleting RS Cloud::Network,MERGED,2014-12-15 20:53:17.000000000,2014-12-23 20:43:07.000000000,2014-12-23 20:43:06.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4257}, {'_account_id': 6983}, {'_account_id': 7230}, {'_account_id': 7253}, {'_account_id': 7256}]","[{'number': 1, 'created': '2014-12-15 20:53:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/56d658924adb2d2b3006206cb9a3193e2ae5afcb', 'message': ""Fix NetworkInUse when deleting RS Cloud::Network\n\nAdds retry logic to the deletion of Rackspace::Cloud::Network so that it\ndoesn't throw NetworkInUse exceptions.\n\nCloses-Bug: bug/1402827\nChange-Id: I5f1dc6d1c1cfc7d0b795fe43fdb677969372bd0b\n""}, {'number': 2, 'created': '2014-12-15 20:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7a2c5c890af333addb24b3f0cba9b2d03bb24447', 'message': ""Fix NetworkInUse when deleting RS Cloud::Network\n\nAdds retry logic to the deletion of Rackspace::Cloud::Network so that it\ndoesn't throw NetworkInUse exceptions.\n\nCloses-Bug: 1402827\nChange-Id: I5f1dc6d1c1cfc7d0b795fe43fdb677969372bd0b\n""}, {'number': 3, 'created': '2014-12-18 16:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6b6ea7c0a271f875b48a27866ce9f67194b06108', 'message': ""Fix NetworkInUse when deleting RS Cloud::Network\n\nAdds retry logic to the deletion of Rackspace::Cloud::Network so that it\ndoesn't throw NetworkInUse exceptions.\n\nCloses-Bug: 1402827\nChange-Id: I5f1dc6d1c1cfc7d0b795fe43fdb677969372bd0b\n""}, {'number': 4, 'created': '2014-12-22 15:48:30.000000000', 'files': ['contrib/rackspace/rackspace/tests/test_cloudnetworks.py', 'contrib/rackspace/rackspace/resources/cloudnetworks.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/9ffe53bac05b6bd69b0c44c814b9e407982f04ee', 'message': ""Fix NetworkInUse when deleting RS Cloud::Network\n\nAdds retry logic to the deletion of Rackspace::Cloud::Network so that it\ndoesn't throw NetworkInUse exceptions.\n\nCloses-Bug: 1402827\nChange-Id: I5f1dc6d1c1cfc7d0b795fe43fdb677969372bd0b\n""}]",0,141902,9ffe53bac05b6bd69b0c44c814b9e407982f04ee,20,7,4,9189,,,0,"Fix NetworkInUse when deleting RS Cloud::Network

Adds retry logic to the deletion of Rackspace::Cloud::Network so that it
doesn't throw NetworkInUse exceptions.

Closes-Bug: 1402827
Change-Id: I5f1dc6d1c1cfc7d0b795fe43fdb677969372bd0b
",git fetch https://review.opendev.org/openstack/heat refs/changes/02/141902/1 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/rackspace/rackspace/tests/test_cloudnetworks.py', 'contrib/rackspace/rackspace/resources/cloudnetworks.py']",2,56d658924adb2d2b3006206cb9a3193e2ae5afcb,bug/1402827,"from heat.engine import scheduler from pyrax.exceptions import NetworkInUse # noqa class NetworkInUse(Exception): """"""Dummy pyrax exception - only used for testing."""""" """"""A resource for creating Rackspace Cloud Networks. def delete_network(network): while True: yield try: network.delete() break except NetworkInUse: LOG.warn(""Network '%s' still in use."" % network.id) while True: yield try: network.get() except NotFound: break task = None if self.network(): task = scheduler.TaskRunner(delete_network, self.network()) task.start() return task def check_delete_complete(self, task): if task and not task.step(): return False "," """""" A resource for creating Rackspace Cloud Networks. net = self.network() if net: net.delete() return net def check_delete_complete(self, network): if network: try: network.get() except NotFound: return True else: return False",48,16
openstack%2Fcinder~master~I0d68ba54617be550244969b7672e95158126f64a,openstack/cinder,master,I0d68ba54617be550244969b7672e95158126f64a,Sync periodic_task module from oslo-incubator,MERGED,2014-12-19 22:50:05.000000000,2014-12-23 20:42:53.000000000,2014-12-23 20:42:52.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 14206}]","[{'number': 1, 'created': '2014-12-19 22:50:05.000000000', 'files': ['cinder/openstack/common/periodic_task.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/41239fd65666e6dba2ca3012c8187d6c34dce9a0', 'message': ""Sync periodic_task module from oslo-incubator\n\nThe periodic_task module hasn't been sync'd since the middle of the\nJuno release cycle.  This patch brings it up to date with the\nlatest oslo-incubator code.\n\nCurrent HEAD in OSLO:\n---------------------\ncommit 36b0e8570b449129d6d474c03b02ceb62edb78df\nDate:   Thu Dec 11 11:27:08 2014 +0100\nWe shouldn't replace `oslo-incubator` in comments\n\nChanges merged with this patch:\n---------------------\n5d40e143 - Remove code that moved to oslo.i18n\na3220c51 - add list_opts to all modules with configuration options\n\nChange-Id: I0d68ba54617be550244969b7672e95158126f64a\n""}]",0,143213,41239fd65666e6dba2ca3012c8187d6c34dce9a0,15,11,1,7198,,,0,"Sync periodic_task module from oslo-incubator

The periodic_task module hasn't been sync'd since the middle of the
Juno release cycle.  This patch brings it up to date with the
latest oslo-incubator code.

Current HEAD in OSLO:
---------------------
commit 36b0e8570b449129d6d474c03b02ceb62edb78df
Date:   Thu Dec 11 11:27:08 2014 +0100
We shouldn't replace `oslo-incubator` in comments

Changes merged with this patch:
---------------------
5d40e143 - Remove code that moved to oslo.i18n
a3220c51 - add list_opts to all modules with configuration options

Change-Id: I0d68ba54617be550244969b7672e95158126f64a
",git fetch https://review.opendev.org/openstack/cinder refs/changes/13/143213/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/openstack/common/periodic_task.py'],1,41239fd65666e6dba2ca3012c8187d6c34dce9a0,sync_periodic_task,"import copyfrom cinder.openstack.common._i18n import _, _LE, _LIdef list_opts(): """"""Entry point for oslo.config-generator."""""" return [(None, copy.deepcopy(periodic_opts))] ","from cinder.openstack.common.gettextutils import _, _LE, _LI",7,1
openstack%2Fcinder~master~If15f311db093f05fc97568bdcc5f7ad8ea8abddf,openstack/cinder,master,If15f311db093f05fc97568bdcc5f7ad8ea8abddf,Sync latest imageutils from oslo-incubator,MERGED,2014-12-19 20:28:30.000000000,2014-12-23 20:41:32.000000000,2014-12-23 20:41:31.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 9003}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 14206}]","[{'number': 1, 'created': '2014-12-19 20:28:30.000000000', 'files': ['cinder/openstack/common/imageutils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6ef23f8b3d2a4e438ee661692a0a81c4ef5fa451', 'message': ""Sync latest imageutils from oslo-incubator\n\nPerforming a sync as imageutils has not been updated since late\nin the Icehouse release cycle.\n\nCurrent HEAD in OSLO:\n---------------------\ncommit 36b0e8570b449129d6d474c03b02ceb62edb78df\nDate:   Thu Dec 11 11:27:08 2014 +0100\nWe shouldn't replace `oslo-incubator` in comments\n\nChange being merged with this patch:\n---------------------\nb2d35eec - Use list.pop(0) to keep the code simpler\n\nChange-Id: If15f311db093f05fc97568bdcc5f7ad8ea8abddf\n""}]",0,143181,6ef23f8b3d2a4e438ee661692a0a81c4ef5fa451,19,15,1,7198,,,0,"Sync latest imageutils from oslo-incubator

Performing a sync as imageutils has not been updated since late
in the Icehouse release cycle.

Current HEAD in OSLO:
---------------------
commit 36b0e8570b449129d6d474c03b02ceb62edb78df
Date:   Thu Dec 11 11:27:08 2014 +0100
We shouldn't replace `oslo-incubator` in comments

Change being merged with this patch:
---------------------
b2d35eec - Use list.pop(0) to keep the code simpler

Change-Id: If15f311db093f05fc97568bdcc5f7ad8ea8abddf
",git fetch https://review.opendev.org/openstack/cinder refs/changes/81/143181/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/openstack/common/imageutils.py'],1,6ef23f8b3d2a4e438ee661692a0a81c4ef5fa451,update_imageutils,"from oslo.utils import strutils from cinder.openstack.common._i18n import _ # - i.e. for usage in kwargs and such... if not lines_after or not lines_after.pop(0).startswith(""ID""): lines_after.pop(0)","from cinder.openstack.common.gettextutils import _ from cinder.openstack.common import strutils # - ie for usage in kwargs and such... if not lines_after or not lines_after[0].startswith(""ID""): del lines_after[0] del lines_after[0]",6,6
openstack%2Fcinder~master~I572b4c186a8ba2f774ba840307b917f273c529ea,openstack/cinder,master,I572b4c186a8ba2f774ba840307b917f273c529ea,Sync the latest middleware module from oslo-incubator,MERGED,2014-12-19 21:27:38.000000000,2014-12-23 20:41:22.000000000,2014-12-23 20:41:19.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 5538}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 13636}, {'_account_id': 14206}]","[{'number': 1, 'created': '2014-12-19 21:27:38.000000000', 'files': ['cinder/openstack/common/middleware/catch_errors.py', 'cinder/openstack/common/middleware/request_id.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/30ec621dfd8d79be69e1789118210f04e2fbc2b6', 'message': ""Sync the latest middleware module from oslo-incubator\n\nMiddleware hasn't had a sync from oslo-incubator since the\nmiddle of the icehouse development cycle.  This sync\nbrings us up to date with the latest changes.\n\nCurrent HEAD in OSLO:\n---------------------\ncommit 36b0e8570b449129d6d474c03b02ceb62edb78df\nDate:   Thu Dec 11 11:27:08 2014 +0100\nWe shouldn't replace `oslo-incubator` in comments\n\nChanges being merged with this patch by file:\n---------------------\ncatch_errors.py\n- ce8f8fa4 - Add middleware.catch_errors shim for Kilo\n- 4504e4f4 - Remove middleware\n- 5d40e143 - Remove code that moved to oslo.i18n\n- 76183592 - add deprecation note to middleware\n- 463e6916 - remove oslo log from middleware\n- fcf517d7 - Update oslo log messages with translation domains\n- fdcae242 - Middleware to catch all error in WSGI pipeline\n\nrequest_id.py\n- 4ffc4c87 - Add middleware.request_id shim for Kilo\n- 4504e4f4 - Remove middleware\n- 76183592 - add deprecation note to middleware\n\nChange-Id: I572b4c186a8ba2f774ba840307b917f273c529ea\n""}]",0,143194,30ec621dfd8d79be69e1789118210f04e2fbc2b6,18,14,1,7198,,,0,"Sync the latest middleware module from oslo-incubator

Middleware hasn't had a sync from oslo-incubator since the
middle of the icehouse development cycle.  This sync
brings us up to date with the latest changes.

Current HEAD in OSLO:
---------------------
commit 36b0e8570b449129d6d474c03b02ceb62edb78df
Date:   Thu Dec 11 11:27:08 2014 +0100
We shouldn't replace `oslo-incubator` in comments

Changes being merged with this patch by file:
---------------------
catch_errors.py
- ce8f8fa4 - Add middleware.catch_errors shim for Kilo
- 4504e4f4 - Remove middleware
- 5d40e143 - Remove code that moved to oslo.i18n
- 76183592 - add deprecation note to middleware
- 463e6916 - remove oslo log from middleware
- fcf517d7 - Update oslo log messages with translation domains
- fdcae242 - Middleware to catch all error in WSGI pipeline

request_id.py
- 4ffc4c87 - Add middleware.request_id shim for Kilo
- 4504e4f4 - Remove middleware
- 76183592 - add deprecation note to middleware

Change-Id: I572b4c186a8ba2f774ba840307b917f273c529ea
",git fetch https://review.opendev.org/openstack/cinder refs/changes/94/143194/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/openstack/common/middleware/catch_errors.py', 'cinder/openstack/common/middleware/request_id.py']",2,30ec621dfd8d79be69e1789118210f04e2fbc2b6,sync_middleware,"""""""Compatibility shim for Kilo, while operators migrate to oslo.middleware."""""" from oslo.middleware import request_id from cinder.openstack.common import versionutils@versionutils.deprecated(as_of=versionutils.deprecated.KILO, in_favor_of='oslo.middleware.RequestId') class RequestIdMiddleware(request_id.RequestId): pass","# Copyright (c) 2013 NEC Corporation # All Rights Reserved. #""""""Middleware that ensures request ID. It ensures to assign request ID for each API request and set it to request environment. The request ID is also added to API response. """""" import webob.dec from cinder.openstack.common import context from cinder.openstack.common.middleware import baseclass RequestIdMiddleware(base.Middleware): @webob.dec.wsgify def __call__(self, req): req_id = context.generate_request_id() req.environ[ENV_REQUEST_ID] = req_id response = req.get_response(self.application) if HTTP_RESP_HEADER_REQUEST_ID not in response.headers: response.headers.add(HTTP_RESP_HEADER_REQUEST_ID, req_id) return response",30,21
openstack%2Fglance~stable%2Ficehouse~I653eef3fc4fd886c8485f26932fcb1b6a33effc6,openstack/glance,stable/icehouse,I653eef3fc4fd886c8485f26932fcb1b6a33effc6,Fixed store config error in sheepdog,ABANDONED,2014-10-16 20:28:26.000000000,2014-12-23 20:15:23.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 5202}, {'_account_id': 8127}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-10-16 20:28:26.000000000', 'files': ['glance/store/__init__.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/e78d7342d8c7a5b332bd64774d3ea19f2abfd633', 'message': 'Fixed store config error in sheepdog\n\nsheepdog error shows up even its not in list of unknown host.\nThe check should be made for only known host for storing configuration.\nUse of backend hosts is subjective so its better to deal with known hosts.\n\nChange-Id: I653eef3fc4fd886c8485f26932fcb1b6a33effc6\nCloses-Bug: #1350713\n'}]",0,129039,e78d7342d8c7a5b332bd64774d3ea19f2abfd633,7,5,1,12609,,,0,"Fixed store config error in sheepdog

sheepdog error shows up even its not in list of unknown host.
The check should be made for only known host for storing configuration.
Use of backend hosts is subjective so its better to deal with known hosts.

Change-Id: I653eef3fc4fd886c8485f26932fcb1b6a33effc6
Closes-Bug: #1350713
",git fetch https://review.opendev.org/openstack/glance refs/changes/39/129039/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/store/__init__.py'],1,e78d7342d8c7a5b332bd64774d3ea19f2abfd633,bug/1350713, for store_entry in set(CONF.known_stores):, for store_entry in set(CONF.known_stores + _ALL_STORES):,1,1
openstack%2Fzaqar~master~I768fcbc6266c737894ff2489049d3535df22e80e,openstack/zaqar,master,I768fcbc6266c737894ff2489049d3535df22e80e,Clean up the 'queues' package for tests,MERGED,2014-12-18 01:30:28.000000000,2014-12-23 20:14:18.000000000,2014-12-23 20:14:16.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}]","[{'number': 1, 'created': '2014-12-18 01:30:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/8c0ca18ffe066d71bd29b35dc36d75e56c5a0741', 'message': ""Clean up the 'queues' package for tests\n\nPartially-Implements blueprint: notifications\n\nChange-Id: I768fcbc6266c737894ff2489049d3535df22e80e\n""}, {'number': 2, 'created': '2014-12-19 03:11:37.000000000', 'files': ['tests/unit/transport/test_auth.py', 'zaqar/tests/unit/transport/__init__.py', 'tests/unit/queues/__init__.py', 'tests/unit/storage/test_impl_mongodb.py', 'zaqar/tests/unit/storage/__init__.py', 'tests/unit/storage/__init__.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_health.py', 'zaqar/tests/unit/transport/wsgi/v1/test_pools.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_claims.py', 'tests/unit/storage/test_pool_catalog.py', 'tests/unit/transport/wsgi/test_v1_1.py', 'zaqar/tests/unit/transport/wsgi/__init__.py', 'zaqar/tests/unit/transport/wsgi/v1/test_queue_lifecycle.py', 'zaqar/tests/unit/transport/wsgi/v1/test_default_limits.py', 'zaqar/tests/unit/transport/wsgi/v1/__init__.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_queue_lifecycle.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_messages.py', 'zaqar/tests/unit/transport/wsgi/v1/test_validation.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_flavors.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_media_type.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_auth.py', 'zaqar/tests/unit/transport/wsgi/v1/test_messages.py', 'tests/unit/transport/wsgi/__init__.py', 'zaqar/tests/unit/transport/wsgi/v1_1/__init__.py', 'zaqar/tests/unit/transport/wsgi/v1/test_home.py', 'tests/unit/storage/test_impl_sqlalchemy.py', 'tests/unit/transport/wsgi/test_v1_0.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_default_limits.py', 'zaqar/tests/unit/storage/base.py', 'tests/unit/storage/test_pool_queues.py', 'tests/unit/transport/wsgi/test_utils.py', 'zaqar/tests/unit/__init__.py', 'zaqar/tests/unit/transport/wsgi/v1/test_claims.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_validation.py', 'zaqar/tests/unit/transport/wsgi/v1/test_media_type.py', 'zaqar/tests/unit/transport/wsgi/base.py', 'zaqar/tests/unit/transport/wsgi/v1/test_auth.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_home.py', 'tests/unit/storage/test_impl_redis.py', 'tests/unit/transport/__init__.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_pools.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/e60e1ea81065b4180a950232d3677b1b1fc95e21', 'message': ""Clean up the 'queues' package for tests\n\nPartially-Implements blueprint: notifications\n\nChange-Id: I768fcbc6266c737894ff2489049d3535df22e80e\n""}]",0,142642,e60e1ea81065b4180a950232d3677b1b1fc95e21,13,3,2,6484,,,0,"Clean up the 'queues' package for tests

Partially-Implements blueprint: notifications

Change-Id: I768fcbc6266c737894ff2489049d3535df22e80e
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/42/142642/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/transport/test_auth.py', 'zaqar/tests/unit/transport/__init__.py', 'tests/unit/queues/__init__.py', 'tests/unit/storage/test_impl_mongodb.py', 'zaqar/tests/unit/storage/__init__.py', 'tests/unit/storage/__init__.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_health.py', 'zaqar/tests/unit/transport/wsgi/v1/test_pools.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_claims.py', 'tests/unit/storage/test_pool_catalog.py', 'tests/unit/transport/wsgi/test_v1_1.py', 'zaqar/tests/unit/transport/wsgi/__init__.py', 'zaqar/tests/unit/transport/wsgi/v1/test_queue_lifecycle.py', 'zaqar/tests/unit/transport/wsgi/v1/test_default_limits.py', 'zaqar/tests/unit/transport/wsgi/v1/__init__.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_queue_lifecycle.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_messages.py', 'zaqar/tests/unit/transport/wsgi/v1/test_validation.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_flavors.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_media_type.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_auth.py', 'zaqar/tests/unit/transport/wsgi/v1/test_messages.py', 'tests/unit/transport/wsgi/__init__.py', 'zaqar/tests/unit/transport/wsgi/v1_1/__init__.py', 'zaqar/tests/unit/transport/wsgi/v1/test_home.py', 'tests/unit/storage/test_impl_sqlalchemy.py', 'tests/unit/transport/wsgi/test_v1_0.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_default_limits.py', 'zaqar/tests/unit/storage/base.py', 'tests/unit/storage/test_pool_queues.py', 'tests/unit/transport/wsgi/test_utils.py', 'zaqar/tests/unit/__init__.py', 'zaqar/tests/unit/transport/wsgi/v1/test_claims.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_validation.py', 'zaqar/tests/unit/transport/wsgi/v1/test_media_type.py', 'zaqar/tests/unit/transport/wsgi/base.py', 'zaqar/tests/unit/transport/wsgi/v1/test_auth.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_home.py', 'tests/unit/storage/test_impl_redis.py', 'tests/unit/transport/__init__.py', 'zaqar/tests/unit/transport/wsgi/v1_1/test_pools.py']",41,8c0ca18ffe066d71bd29b35dc36d75e56c5a0741,bp/notifications,from zaqar.tests.unit.transport.wsgi import base,from zaqar.tests.queues.transport.wsgi import base,48,48
openstack%2Fdjango_openstack_auth~master~Idcda852a7497a72b96aed75d344ea9c1154dfc48,openstack/django_openstack_auth,master,Idcda852a7497a72b96aed75d344ea9c1154dfc48,Use standard test loading features,MERGED,2014-12-09 02:11:00.000000000,2014-12-23 20:14:06.000000000,2014-12-23 20:14:05.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 14124}]","[{'number': 1, 'created': '2014-12-09 02:11:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/c726681094255ff68226e5273e0c1a6efbeb9543', 'message': 'Use standard test loading features\n\nUse the standard testscenarios library that we use throughout OpenStack\nto do multiple similar test runs rather than use a custom metaclass\nbased mechanism.\n\nChange-Id: Idcda852a7497a72b96aed75d344ea9c1154dfc48\n'}, {'number': 2, 'created': '2014-12-09 11:58:09.000000000', 'files': ['openstack_auth/tests/tests.py', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/9704b6f36eaf1f324e59864e29b92b69c112e62c', 'message': 'Use standard test loading features\n\nUse the standard testscenarios library that we use throughout OpenStack\nto do multiple similar test runs rather than use a custom metaclass\nbased mechanism.\n\nChange-Id: Idcda852a7497a72b96aed75d344ea9c1154dfc48\n'}]",0,140200,9704b6f36eaf1f324e59864e29b92b69c112e62c,10,4,2,7191,,,0,"Use standard test loading features

Use the standard testscenarios library that we use throughout OpenStack
to do multiple similar test runs rather than use a custom metaclass
based mechanism.

Change-Id: Idcda852a7497a72b96aed75d344ea9c1154dfc48
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/00/140200/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_auth/tests/tests.py', 'test-requirements.txt']",2,c726681094255ff68226e5273e0c1a6efbeb9543,authplugin,testscenarios>=0.4,,23,58
openstack%2Frally~master~I2c3719dfb3030f5a386486db09cfb61316242ada,openstack/rally,master,I2c3719dfb3030f5a386486db09cfb61316242ada,Fix docstring checker,MERGED,2014-12-23 16:04:58.000000000,2014-12-23 19:51:37.000000000,2014-12-23 19:51:36.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 9545}, {'_account_id': 10475}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-23 16:04:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d155bce7b653ab3293cec4a02f426442c00642ae', 'message': 'Fix docstring checker\n\nWe should add tests for all plugins. Otherwise results of tests\nwill depend on order of run.\n\nChange-Id: I2c3719dfb3030f5a386486db09cfb61316242ada\n'}, {'number': 2, 'created': '2014-12-23 16:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0ca0e0348b0b55955d7b678aeb01b88e5b0d8cfa', 'message': ""Fix docstring checker\n\nWe shouldn't test docstrings of plugins described in tests.*\n\nChange-Id: I2c3719dfb3030f5a386486db09cfb61316242ada\n""}, {'number': 3, 'created': '2014-12-23 17:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ec9a086e7ecfb0f5ae8c9524f212e474a4b174a1', 'message': 'Fix docstring checker\n\nWe should test docstrings only for plugins that are described in rally.*\n\nChange-Id: I2c3719dfb3030f5a386486db09cfb61316242ada\n'}, {'number': 4, 'created': '2014-12-23 17:04:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ecaeeec85431236743ebdae2d09c8186157c5b52', 'message': 'Fix docstring checker\n\nWe should test docstrings only for plugins that are described in rally.*\n\nChange-Id: I2c3719dfb3030f5a386486db09cfb61316242ada\n'}, {'number': 5, 'created': '2014-12-23 17:53:52.000000000', 'files': ['tests/unit/fakes.py', 'tests/unit/test_docstrings.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/31851cb0dc8775006bdca8e27a09c132dcce0631', 'message': 'Fix docstring checker\n\nWe should test docstrings only for plugins that are described in rally.*\n\nChange-Id: I2c3719dfb3030f5a386486db09cfb61316242ada\n'}]",1,143687,31851cb0dc8775006bdca8e27a09c132dcce0631,24,7,5,6172,,,0,"Fix docstring checker

We should test docstrings only for plugins that are described in rally.*

Change-Id: I2c3719dfb3030f5a386486db09cfb61316242ada
",git fetch https://review.opendev.org/openstack/rally refs/changes/87/143687/5 && git format-patch -1 --stdout FETCH_HEAD,['tests/unit/benchmark/scenarios/test_base.py'],1,d155bce7b653ab3293cec4a02f426442c00642ae,fix_the_world2," """"""Fake scenario."""""" """"""Fake scenario."""""" """"""Fake scenario.""""""",,3,0
openstack%2Ffuel-main~stable%2F6.0~I6ed3677ee70525aa38b63d51cdf7a6b02f189c6d,openstack/fuel-main,stable/6.0,I6ed3677ee70525aa38b63d51cdf7a6b02f189c6d,Fix backup/restore master node system tests,MERGED,2014-12-20 01:07:48.000000000,2014-12-23 19:33:01.000000000,2014-12-23 19:33:01.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-12-20 01:07:48.000000000', 'files': ['fuelweb_test/tests/test_ha.py', 'fuelweb_test/tests/test_simple.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c29dc5db734524d99904e1d54c24b8220f25c6d8', 'message': 'Fix backup/restore master node system tests\n\nUse auth credentials when connect to reverted environment where\nthese credentials was changed from default.\n\nChange-Id: I6ed3677ee70525aa38b63d51cdf7a6b02f189c6d\nCloses-Bug: #1404423\n'}]",0,143233,c29dc5db734524d99904e1d54c24b8220f25c6d8,9,6,1,11969,,,0,"Fix backup/restore master node system tests

Use auth credentials when connect to reverted environment where
these credentials was changed from default.

Change-Id: I6ed3677ee70525aa38b63d51cdf7a6b02f189c6d
Closes-Bug: #1404423
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/33/143233/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/test_ha.py', 'fuelweb_test/tests/test_simple.py']",2,c29dc5db734524d99904e1d54c24b8220f25c6d8,," self.fuel_web.get_nailgun_node_by_name('slave-01')['ip'], 'novaSimpleFlat', 'novaSimpleFlat', 'novaSimpleFlat')", self.fuel_web.get_nailgun_node_by_name('slave-01')['ip']),4,2
openstack%2Ffuel-main~master~I6ed3677ee70525aa38b63d51cdf7a6b02f189c6d,openstack/fuel-main,master,I6ed3677ee70525aa38b63d51cdf7a6b02f189c6d,Fix backup/restore master node system tests,MERGED,2014-12-20 01:02:24.000000000,2014-12-23 19:32:17.000000000,2014-12-23 19:32:16.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-12-20 01:02:24.000000000', 'files': ['fuelweb_test/tests/test_ha.py', 'fuelweb_test/tests/test_simple.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2b6d57b7cf3ca9f0fa9ded4b31d52bdb4fcf63f9', 'message': 'Fix backup/restore master node system tests\n\nUse auth credentials when connect to reverted environment where\nthese credentials was changed from default.\n\nChange-Id: I6ed3677ee70525aa38b63d51cdf7a6b02f189c6d\nCloses-Bug: #1404423\n'}]",0,143232,2b6d57b7cf3ca9f0fa9ded4b31d52bdb4fcf63f9,11,6,1,11969,,,0,"Fix backup/restore master node system tests

Use auth credentials when connect to reverted environment where
these credentials was changed from default.

Change-Id: I6ed3677ee70525aa38b63d51cdf7a6b02f189c6d
Closes-Bug: #1404423
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/32/143232/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/test_ha.py', 'fuelweb_test/tests/test_simple.py']",2,2b6d57b7cf3ca9f0fa9ded4b31d52bdb4fcf63f9,bug/1404423," self.fuel_web.get_nailgun_node_by_name('slave-01')['ip'], 'novaSimpleFlat', 'novaSimpleFlat', 'novaSimpleFlat')", self.fuel_web.get_nailgun_node_by_name('slave-01')['ip']),4,2
openstack%2Ffuel-main~stable%2F5.1~I28a84f8e2a304e18cf54eb7d08b24f0ef67503f5,openstack/fuel-main,stable/5.1,I28a84f8e2a304e18cf54eb7d08b24f0ef67503f5,Wait for Keystone start after master node reset,MERGED,2014-12-20 11:48:01.000000000,2014-12-23 19:31:37.000000000,2014-12-23 19:31:37.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-12-20 11:48:01.000000000', 'files': ['fuelweb_test/models/environment.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/bb837820f27c00cf54620e65934184d65f7a898a', 'message': 'Wait for Keystone start after master node reset\n\nUse protected Nailgun API URL to check that Keystone\nis up and works fine before running tests.\n\nChange-Id: I28a84f8e2a304e18cf54eb7d08b24f0ef67503f5\nCloses-bug: #1401692\n(cherry picked from commit 4a00e4565b879f110ff56a3c941c0bd81efa7086)\n'}]",0,143264,bb837820f27c00cf54620e65934184d65f7a898a,9,6,1,11969,,,0,"Wait for Keystone start after master node reset

Use protected Nailgun API URL to check that Keystone
is up and works fine before running tests.

Change-Id: I28a84f8e2a304e18cf54eb7d08b24f0ef67503f5
Closes-bug: #1401692
(cherry picked from commit 4a00e4565b879f110ff56a3c941c0bd81efa7086)
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/64/143264/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/environment.py'],1,bb837820f27c00cf54620e65934184d65f7a898a,," _wait(self._fuel_web.client.get_releases, timeout=120)"," _wait(self._fuel_web.get_nailgun_version, timeout=120)",1,1
openstack%2Ffuel-main~master~I987ca924f3336b5956707624e00dd1d0238e5d6f,openstack/fuel-main,master,I987ca924f3336b5956707624e00dd1d0238e5d6f,Fix regex for checking private data in statistics,MERGED,2014-12-18 16:19:53.000000000,2014-12-23 19:23:05.000000000,2014-12-23 19:23:05.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 10959}, {'_account_id': 11969}]","[{'number': 1, 'created': '2014-12-18 16:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9cbff9cce70f9331d638683e729a8141aded7bbf', 'message': ""Fix regex for checking private data in statistics\n\nChange regexp for matching data types which can contain\nsome network information (e.g. public IP network address).\nCurrently it also matches allowed types of info - used\nfor deployments 'predefined_networks', 'network_type',\n'network_scheme'.\n\nChange-Id: I987ca924f3336b5956707624e00dd1d0238e5d6f\nImplements: blueprint fuel-stats-test\n""}, {'number': 2, 'created': '2014-12-19 06:51:54.000000000', 'files': ['fuelweb_test/helpers/checkers.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/034bb48f08d19e6e7c545df081e68766fa810958', 'message': ""Fix regex for checking private data in statistics\n\nChange regexp for matching data types which can contain\nsome network information (e.g. public IP network address).\nCurrently it also matches allowed types of info - used\nfor deployments 'predefined_networks', 'network_type',\n'network_scheme'.\n\nChange-Id: I987ca924f3336b5956707624e00dd1d0238e5d6f\nImplements: blueprint fuel-stats-test\n""}]",0,142827,034bb48f08d19e6e7c545df081e68766fa810958,15,7,2,11081,,,0,"Fix regex for checking private data in statistics

Change regexp for matching data types which can contain
some network information (e.g. public IP network address).
Currently it also matches allowed types of info - used
for deployments 'predefined_networks', 'network_type',
'network_scheme'.

Change-Id: I987ca924f3336b5956707624e00dd1d0238e5d6f
Implements: blueprint fuel-stats-test
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/27/142827/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/helpers/checkers.py'],1,9cbff9cce70f9331d638683e729a8141aded7bbf,bp/fuel-stats-test," 'some_network': 'network\b',"," 'some_network': 'network(?!_assignment)',",1,1
openstack%2Ffuel-main~master~I4250fd455b7149b2ef227e79b44170aef07f29ae,openstack/fuel-main,master,I4250fd455b7149b2ef227e79b44170aef07f29ae,Add var to tests which enables stats checking,MERGED,2014-12-17 20:57:40.000000000,2014-12-23 19:22:22.000000000,2014-12-23 19:22:22.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}]","[{'number': 1, 'created': '2014-12-17 20:57:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1cdae522498d822b5a4b4f06b2000ca79fe03cfe', 'message': 'Add var to tests which enables stats checking\n\nAdd an additional variable FUEL_STATS_CHECK to\nsystem tests settings which enables checking of\ngathered usage statistics after performing tests\n(currently only few tests support that). Existing\nvar FUEL_STATS_ENABLED is used for enabling stats\ncollecting in Nailgun settings.\n\nChange-Id: I4250fd455b7149b2ef227e79b44170aef07f29ae\nImplements: blueprint fuel-stats-test\n'}, {'number': 2, 'created': '2014-12-18 07:16:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/62853247e46c82e5a96f0c850c0b2f06ae395032', 'message': 'Add var to tests which enables stats checking\n\nAdd an additional variable FUEL_STATS_CHECK to\nsystem tests settings which enables checking of\ngathered usage statistics after performing tests\n(currently only few tests support that). Existing\nvar FUEL_STATS_ENABLED is used for enabling stats\ncollecting in Nailgun settings.\n\nChange-Id: I4250fd455b7149b2ef227e79b44170aef07f29ae\nImplements: blueprint fuel-stats-test\n'}, {'number': 3, 'created': '2014-12-19 06:51:54.000000000', 'files': ['fuelweb_test/helpers/decorators.py', 'fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/404bb584100789fe9975b3f7df3a4eb7a663988e', 'message': 'Add var to tests which enables stats checking\n\nAdd an additional variable FUEL_STATS_CHECK to\nsystem tests settings which enables checking of\ngathered usage statistics after performing tests\n(currently only few tests support that). Existing\nvar FUEL_STATS_ENABLED is used for enabling stats\ncollecting in Nailgun settings.\n\nChange-Id: I4250fd455b7149b2ef227e79b44170aef07f29ae\nImplements: blueprint fuel-stats-test\n'}]",0,142576,404bb584100789fe9975b3f7df3a4eb7a663988e,19,6,3,11081,,,0,"Add var to tests which enables stats checking

Add an additional variable FUEL_STATS_CHECK to
system tests settings which enables checking of
gathered usage statistics after performing tests
(currently only few tests support that). Existing
var FUEL_STATS_ENABLED is used for enabling stats
collecting in Nailgun settings.

Change-Id: I4250fd455b7149b2ef227e79b44170aef07f29ae
Implements: blueprint fuel-stats-test
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/76/142576/3 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/helpers/decorators.py', 'fuelweb_test/settings.py']",2,1cdae522498d822b5a4b4f06b2000ca79fe03cfe,bp/fuel-stats-test,"FUEL_STATS_CHECK = os.environ.get('FUEL_STATS_CHECK', 'false') == 'true'",,3,0
openstack%2Fcinder~master~I56c11c317e6eb63ce10e85e920ca36351080270b,openstack/cinder,master,I56c11c317e6eb63ce10e85e920ca36351080270b,Remove unused import rbd,ABANDONED,2014-12-23 19:12:44.000000000,2014-12-23 19:21:59.000000000,,[{'_account_id': 13900}],"[{'number': 1, 'created': '2014-12-23 19:12:44.000000000', 'files': ['cinder/volume/drivers/rbd.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/80bf7041fa9c208f24351459c8cca0aa86c0af8e', 'message': 'Remove unused import rbd\n\nThe imported rbd module is not being used. Remove it.\n\nChange-Id: I56c11c317e6eb63ce10e85e920ca36351080270b\n'}]",0,143723,80bf7041fa9c208f24351459c8cca0aa86c0af8e,3,1,1,13900,,,0,"Remove unused import rbd

The imported rbd module is not being used. Remove it.

Change-Id: I56c11c317e6eb63ce10e85e920ca36351080270b
",git fetch https://review.opendev.org/openstack/cinder refs/changes/23/143723/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/rbd.py'],1,80bf7041fa9c208f24351459c8cca0aa86c0af8e,remove-unused-import-rbd,, import rbd rbd = None,0,2
openstack%2Ffuel-main~master~I90d3c6f77f303629e2eeaf6d12b82da0f2510140,openstack/fuel-main,master,I90d3c6f77f303629e2eeaf6d12b82da0f2510140,Check stats collecting after tests,MERGED,2014-12-15 10:23:36.000000000,2014-12-23 19:21:17.000000000,2014-12-23 19:21:16.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8392}, {'_account_id': 8882}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 10959}, {'_account_id': 11081}, {'_account_id': 11969}]","[{'number': 1, 'created': '2014-12-15 10:23:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a82f7539726ee5ff180f22c2c269b6719767e772', 'message': 'WIP Check stats collecting after tests\n\nCheck that usage stats are sent (if enabled)\nor not sent (if disabled) after the following\ntests:\n - deploy_simple_flat\n - multiple_cluster_net_neutron_gre_ha\n\nChange-Id: I90d3c6f77f303629e2eeaf6d12b82da0f2510140\nImplements: blueprint fuel-stats-test\n'}, {'number': 2, 'created': '2014-12-17 20:40:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9f548b5ead628960836eb38239fd6dad0d1fbea4', 'message': ""Check stats collecting after tests\n\nCheck that usage stats are sent (if sending enabled)\nor not sent (if sending disabled) after the following\ntests:\n\n - deploy_neutron_gre_ha_nodegroups\n - deploy_reset_on_ready\n - multiple_cluster_net_neutron_gre_ha\n\nAlso, improve 'get_ssh_to_remote_by_key' method,\nso it can get SSH keys from SSH-Agent (usefull\non Jenkins) and fail test if Fuel master node is\nunavailable via SSH after resuming environment.\n\nChange-Id: I90d3c6f77f303629e2eeaf6d12b82da0f2510140\nImplements: blueprint fuel-stats-test\n""}, {'number': 3, 'created': '2014-12-18 07:16:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/bef5657e4f0b183651ce936d2fefde77906480f0', 'message': ""Check stats collecting after tests\n\nCheck that usage stats are sent (if sending enabled)\nor not sent (if sending disabled) after the following\ntests:\n\n - deploy_neutron_gre_ha_nodegroups\n - deploy_reset_on_ready\n - multiple_cluster_net_neutron_gre_ha\n\nAlso, improve 'get_ssh_to_remote_by_key' method,\nso it can get SSH keys from SSH-Agent (usefull\non Jenkins) and fail test if Fuel master node is\nunavailable via SSH after resuming environment.\n\nChange-Id: I90d3c6f77f303629e2eeaf6d12b82da0f2510140\nImplements: blueprint fuel-stats-test\n""}, {'number': 4, 'created': '2014-12-19 06:51:54.000000000', 'files': ['fuelweb_test/helpers/decorators.py', 'fuelweb_test/models/environment.py', 'fuelweb_test/tests/test_multiple_networks.py', 'fuelweb_test/tests/test_environment_action.py', 'fuelweb_test/helpers/checkers.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f007d9f6655bb657534710905be007b5787f4385', 'message': ""Check stats collecting after tests\n\nCheck that usage stats are sent (if sending enabled)\nor not sent (if sending disabled) after the following\ntests:\n\n - deploy_flat_stop_reset_on_deploying\n - deploy_reset_on_ready\n - multiple_cluster_net_neutron_gre_ha\n\nIn system tests we can use one environment (with the\nsame master node uuid) in several different tests,\nso the count of sent to collector logs can be greater\nthan we expect in particular test.\n\nAlso, improve 'get_ssh_to_remote_by_key' method,\nso it can get SSH keys from SSH-Agent (usefull\non Jenkins) and fail test if Fuel master node is\nunavailable via SSH after resuming environment.\n\nChange-Id: I90d3c6f77f303629e2eeaf6d12b82da0f2510140\nImplements: blueprint fuel-stats-test\n""}]",0,141763,f007d9f6655bb657534710905be007b5787f4385,25,10,4,11081,,,0,"Check stats collecting after tests

Check that usage stats are sent (if sending enabled)
or not sent (if sending disabled) after the following
tests:

 - deploy_flat_stop_reset_on_deploying
 - deploy_reset_on_ready
 - multiple_cluster_net_neutron_gre_ha

In system tests we can use one environment (with the
same master node uuid) in several different tests,
so the count of sent to collector logs can be greater
than we expect in particular test.

Also, improve 'get_ssh_to_remote_by_key' method,
so it can get SSH keys from SSH-Agent (usefull
on Jenkins) and fail test if Fuel master node is
unavailable via SSH after resuming environment.

Change-Id: I90d3c6f77f303629e2eeaf6d12b82da0f2510140
Implements: blueprint fuel-stats-test
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/63/141763/3 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/test_multiple_networks.py', 'fuelweb_test/tests/test_simple.py']",2,a82f7539726ee5ff180f22c2c269b6719767e772,bp/fuel-stats-test,from fuelweb_test.helpers.decorators import check_fuel_statistics @check_fuel_statistics,,4,0
openstack%2Fneutron~master~I1d548b9a0a04c8855ada42206c2a333597c2c85b,openstack/neutron,master,I1d548b9a0a04c8855ada42206c2a333597c2c85b,validate L3 HA min/max _l3_agents_per_router,MERGED,2014-12-09 14:20:54.000000000,2014-12-23 19:18:29.000000000,2014-12-23 19:18:27.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 7141}, {'_account_id': 8124}, {'_account_id': 8576}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10267}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12683}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-09 14:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3cdc2eb84e95093c9ba70f08c6713565b361fe94', 'message': 'validate min/max _l3_agents_per_router\n\nneutron manager should validate L3 HA config options\npreset in neutron.conf. Only validation required is\nmax_l3_agents_per_router < min_l3_agents_per_router\n\nCloses-bug: #1400311\nChange-Id: I1d548b9a0a04c8855ada42206c2a333597c2c85b\n'}, {'number': 2, 'created': '2014-12-09 14:36:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1bbd306c9abde7253f43e5c4a785ba91c8506c57', 'message': 'validate min/max _l3_agents_per_router\n\nneutron manager should validate L3 HA config options\npreset in neutron.conf. Only validation required is\nmax_l3_agents_per_router < min_l3_agents_per_router\n\nCloses-bug: #1400311\nChange-Id: I1d548b9a0a04c8855ada42206c2a333597c2c85b\n'}, {'number': 3, 'created': '2014-12-09 16:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9db7470adc8e6228b3e16c9c82ca25deadd0d548', 'message': 'validate L3 HA min/max _l3_agents_per_router\n\nThe below missing validation is added to L3 HA\nmax_l3_agents_per_router < min_l3_agents_per_router\n\nCloses-bug: #1400311\nChange-Id: I1d548b9a0a04c8855ada42206c2a333597c2c85b\n'}, {'number': 4, 'created': '2014-12-11 09:00:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b887b09d7c89046252756526bdbbdcc976d1f42d', 'message': 'validate L3 HA min/max _l3_agents_per_router\n\nThe below missing validation is added to L3 HA\nmax_l3_agents_per_router < min_l3_agents_per_router\n\nCloses-bug: #1400311\nChange-Id: I1d548b9a0a04c8855ada42206c2a333597c2c85b\n'}, {'number': 5, 'created': '2014-12-12 06:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7194ac0b5a34c70cfff3eb439a1aec33ebef6f49', 'message': 'validate L3 HA min/max _l3_agents_per_router\n\nThe below missing validation is added to L3 HA\nmax_l3_agents_per_router < min_l3_agents_per_router\n\nCloses-bug: #1400311\nChange-Id: I1d548b9a0a04c8855ada42206c2a333597c2c85b\n'}, {'number': 6, 'created': '2014-12-12 07:00:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d8991d3cc282632a09d9d7d3b25b27441e88bfdd', 'message': 'validate L3 HA min/max _l3_agents_per_router\n\nThe below missing validation is added to L3 HA\nmax_l3_agents_per_router < min_l3_agents_per_router\n\nCloses-bug: #1400311\nChange-Id: I1d548b9a0a04c8855ada42206c2a333597c2c85b\n'}, {'number': 7, 'created': '2014-12-15 15:06:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d25534e8264d9dd68c3c17bfff49f501b319da14', 'message': 'validate L3 HA min/max _l3_agents_per_router\n\nThe below missing validation is added to L3 HA\nmax_l3_agents_per_router < min_l3_agents_per_router\n\nCloses-bug: #1400311\nChange-Id: I1d548b9a0a04c8855ada42206c2a333597c2c85b\n'}, {'number': 8, 'created': '2014-12-15 15:10:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8a98b6ab78bd9ab4b80693cdd45ac436f9f6c996', 'message': 'validate L3 HA min/max _l3_agents_per_router\n\nThe below missing validation is added to L3 HA\nmax_l3_agents_per_router < min_l3_agents_per_router\n\nCloses-bug: #1400311\nChange-Id: I1d548b9a0a04c8855ada42206c2a333597c2c85b\n'}, {'number': 9, 'created': '2014-12-19 05:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c25e08fb152515f314f2d2f7bbd0ed6a83ee035e', 'message': 'validate L3 HA min/max _l3_agents_per_router\n\nThe below missing validation is added to L3 HA\nmax_l3_agents_per_router < min_l3_agents_per_router\n\nCloses-bug: #1400311\nChange-Id: I1d548b9a0a04c8855ada42206c2a333597c2c85b\n'}, {'number': 10, 'created': '2014-12-19 05:49:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3dc2c94ee351b8bc7bd8a216f96ac2609b6631ef', 'message': 'validate L3 HA min/max _l3_agents_per_router\n\nThe below missing validation is added to L3 HA\nmax_l3_agents_per_router >= min_l3_agents_per_router\n\nCloses-bug: #1400311\nChange-Id: I1d548b9a0a04c8855ada42206c2a333597c2c85b\n'}, {'number': 11, 'created': '2014-12-19 06:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/040506ea12f17ce4cf63d3ccf9ae2678ca4e73a7', 'message': 'validate L3 HA min/max _l3_agents_per_router\n\nThe below missing validation is added for L3 HA\nmax_l3_agents_per_router >= min_l3_agents_per_router\n\nCloses-bug: #1400311\nChange-Id: I1d548b9a0a04c8855ada42206c2a333597c2c85b\n'}, {'number': 12, 'created': '2014-12-23 11:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ba855ec3372434ae4a52d1077e44b9b761582d54', 'message': 'validate L3 HA min/max _l3_agents_per_router\n\nThe below missing validation is added for L3 HA\nmax_l3_agents_per_router >= min_l3_agents_per_router\n\nCloses-bug: #1400311\nChange-Id: I1d548b9a0a04c8855ada42206c2a333597c2c85b\n'}, {'number': 13, 'created': '2014-12-23 11:07:08.000000000', 'files': ['neutron/db/l3_hamode_db.py', 'neutron/tests/unit/db/test_l3_ha_db.py', 'neutron/extensions/l3_ext_ha_mode.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7da314434e445ce3a6f3642c784954ef61154b7f', 'message': 'validate L3 HA min/max _l3_agents_per_router\n\nThe below missing validation is added for L3 HA\nmax_l3_agents_per_router >= min_l3_agents_per_router\n\nCloses-bug: #1400311\nChange-Id: I1d548b9a0a04c8855ada42206c2a333597c2c85b\n'}]",8,140340,7da314434e445ce3a6f3642c784954ef61154b7f,245,33,13,10267,,,0,"validate L3 HA min/max _l3_agents_per_router

The below missing validation is added for L3 HA
max_l3_agents_per_router >= min_l3_agents_per_router

Closes-bug: #1400311
Change-Id: I1d548b9a0a04c8855ada42206c2a333597c2c85b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/140340/12 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/manager.py', 'neutron/tests/unit/test_neutron_manager.py']",2,3cdc2eb84e95093c9ba70f08c6713565b361fe94,bug/1400311," def test_post_service_plugin_validation(self): cfg.CONF.import_opt('l3_ha', 'neutron.db.l3_hamode_db') cfg.CONF.import_opt('max_l3_agents_per_router', 'neutron.db.l3_hamode_db') cfg.CONF.import_opt('min_l3_agents_per_router', 'neutron.db.l3_hamode_db') self.assertIsNone(manager.validate_post_service_plugin_load( constants.DUMMY)) plugin_type = constants.L3_ROUTER_NAT self.assertIsNone(manager.validate_post_service_plugin_load( plugin_type)) cfg.CONF.set_override('l3_ha', True) self.assertIsNone(manager.validate_post_service_plugin_load( plugin_type)) cfg.CONF.set_override('l3_ha', True) cfg.CONF.set_override('max_l3_agents_per_router', 4) cfg.CONF.set_override('min_l3_agents_per_router', 3) self.assertIsNone(manager.validate_post_service_plugin_load( plugin_type)) cfg.CONF.set_override('l3_ha', True) cfg.CONF.set_override('max_l3_agents_per_router', 3) cfg.CONF.set_override('min_l3_agents_per_router', 3) self.assertIsNone(manager.validate_post_service_plugin_load( plugin_type)) cfg.CONF.set_override('max_l3_agents_per_router', 3) cfg.CONF.set_override('min_l3_agents_per_router', 4) self.assertIsNotNone(manager.validate_post_service_plugin_load( plugin_type)) ",,56,0
openstack%2Fproject-config~master~Iefb8ae4e82dcd31306d03befdc9766f2c1291571,openstack/project-config,master,Iefb8ae4e82dcd31306d03befdc9766f2c1291571,We want to run freese in venv not with tox target,MERGED,2014-12-23 18:44:11.000000000,2014-12-23 19:09:43.000000000,2014-12-23 19:09:43.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-12-23 18:44:11.000000000', 'files': ['jenkins/scripts/run-tox.sh', 'jenkins/scripts/run-cover.sh', 'jenkins/scripts/run-pep8.sh', 'jenkins/scripts/run-docs.sh', 'jenkins/scripts/run-selenium.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/25541f1ec593d51779f9742221a63e76590e95c6', 'message': ""We want to run freese in venv not with tox target\n\nRunning the freeze command as posargs to tox targets is unreliable as\nthose commands may be interpreted as arguments to other commands rather\nthan as commands themselves. For example `tox -epy26 -- pbr freeze` is\nlikely pass 'pbr freeze' as test name filters to the py26 test runner.\n\nInstead what we want is to run pbr/pip freeze directly out of the venv\nin question.\n\nChange-Id: Iefb8ae4e82dcd31306d03befdc9766f2c1291571\n""}]",0,143717,25541f1ec593d51779f9742221a63e76590e95c6,9,4,1,4146,,,0,"We want to run freese in venv not with tox target

Running the freeze command as posargs to tox targets is unreliable as
those commands may be interpreted as arguments to other commands rather
than as commands themselves. For example `tox -epy26 -- pbr freeze` is
likely pass 'pbr freeze' as test name filters to the py26 test runner.

Instead what we want is to run pbr/pip freeze directly out of the venv
in question.

Change-Id: Iefb8ae4e82dcd31306d03befdc9766f2c1291571
",git fetch https://review.opendev.org/openstack/project-config refs/changes/17/143717/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/scripts/run-tox.sh', 'jenkins/scripts/run-cover.sh', 'jenkins/scripts/run-pep8.sh', 'jenkins/scripts/run-docs.sh', 'jenkins/scripts/run-selenium.sh']",5,25541f1ec593d51779f9742221a63e76590e95c6,fix-pbr-freeze,.tox/${venv}/bin/${freezecmd} freeze,tox -e$venv -- $freezecmd freeze,5,5
openstack%2Fopenstack-manuals~stable%2Fjuno~I3032c8e867d3e367004907da8d8479dc61beca66,openstack/openstack-manuals,stable/juno,I3032c8e867d3e367004907da8d8479dc61beca66,Allow guest remote access to rabbitmq,MERGED,2014-12-23 18:06:23.000000000,2014-12-23 19:06:05.000000000,2014-12-23 19:06:04.000000000,"[{'_account_id': 3}, {'_account_id': 6772}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-12-23 18:06:23.000000000', 'files': ['doc/install-guide/section_basics-queue.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d785cb2bce4e99d07da0600534a90d40f60f366b', 'message': 'Allow guest remote access to rabbitmq\n\nSince RabbitMQ version 3.3.0, the guest user has no remote access,\ndocument how to enable it for SUSE distros.\n\nBackport: juno\nChange-Id: I3032c8e867d3e367004907da8d8479dc61beca66\nCloses-Bug: #1390419\n(cherry picked from commit 69c9c65daeda311b7ccf28f8cce480e9fc63f723)\n'}]",0,143706,d785cb2bce4e99d07da0600534a90d40f60f366b,8,3,1,6547,,,0,"Allow guest remote access to rabbitmq

Since RabbitMQ version 3.3.0, the guest user has no remote access,
document how to enable it for SUSE distros.

Backport: juno
Change-Id: I3032c8e867d3e367004907da8d8479dc61beca66
Closes-Bug: #1390419
(cherry picked from commit 69c9c65daeda311b7ccf28f8cce480e9fc63f723)
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/06/143706/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_basics-queue.xml'],1,d785cb2bce4e99d07da0600534a90d40f60f366b,bug/1390419," <step os=""opensuse;sles""> <para> If you are running RabbitMQ version 3.3.0 or higher, you need to allow remote connection of the guest user as well. Edit <filename>/etc/rabbitmq/rabbitmq.config</filename> and add or uncomment this line: <programlisting>{loopback_users, []}</programlisting> </para> </step>",,9,0
openstack%2Fironic~master~I85b75f26051170c0d306ef38b517cc1657e47a99,openstack/ironic,master,I85b75f26051170c0d306ef38b517cc1657e47a99,Use get_my_ipv4 from oslo.utils,MERGED,2014-12-23 08:26:20.000000000,2014-12-23 18:37:04.000000000,2014-12-23 18:37:03.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-12-23 08:26:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6d9331414346234e851a8037048c63a839f7b02e', 'message': ""Use get_my_ipv4 from oslo.utils\n\nRemove _get_my_ip from ironic and replace it's usages\nby usages of get_my_ipv4 from netutils, because this methods\nimplements the same functionality.\n\nChange-Id: I85b75f26051170c0d306ef38b517cc1657e47a99\n""}, {'number': 2, 'created': '2014-12-23 13:27:43.000000000', 'files': ['ironic/netconf.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/46d24b51de16a8d743cbf505a6aebd0072aecaa6', 'message': ""Use get_my_ipv4 from oslo.utils\n\nRemove _get_my_ip from ironic and replace it's usages\nby usages of get_my_ipv4 from netutils, because this methods\nimplements the same functionality.\n\nChange-Id: I85b75f26051170c0d306ef38b517cc1657e47a99\n""}]",1,143621,46d24b51de16a8d743cbf505a6aebd0072aecaa6,18,5,2,9796,,,0,"Use get_my_ipv4 from oslo.utils

Remove _get_my_ip from ironic and replace it's usages
by usages of get_my_ipv4 from netutils, because this methods
implements the same functionality.

Change-Id: I85b75f26051170c0d306ef38b517cc1657e47a99
",git fetch https://review.opendev.org/openstack/ironic refs/changes/21/143621/2 && git format-patch -1 --stdout FETCH_HEAD,['ironic/netconf.py'],1,6d9331414346234e851a8037048c63a839f7b02e,get_my_ipv4,"from oslo.utils import netutils default=netutils.get_my_ipv4(),"," def _get_my_ip(): """"""Returns the actual ip of the local machine. This code figures out what source address would be used if some traffic were to be sent out to some well known address on the Internet. In this case, a Google DNS server is used, but the specific address does not matter much. No traffic is actually sent. """""" try: csock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) csock.connect(('8.8.8.8', 80)) (addr, port) = csock.getsockname() csock.close() return addr except socket.error: return ""127.0.0.1"" default=_get_my_ip(),",2,20
openstack%2Fironic~master~I5f2b50718f2d6ae2258a14055ddd77fc40d8a344,openstack/ironic,master,I5f2b50718f2d6ae2258a14055ddd77fc40d8a344,Reuse methods from netutils,MERGED,2014-12-23 08:58:37.000000000,2014-12-23 18:36:42.000000000,2014-12-23 18:36:41.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 9315}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-12-23 08:58:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f933f212254b84b7e47f1f26369176a78ae120ea', 'message': 'Reuse methods from netutils\n\nReplace usages of is_valid_ipv4, is_valid_ipv6 from Ironic,\nby usages of this methods from oslo.utils and remove these\nmethods from Ironic code.\n\nChange-Id: I5f2b50718f2d6ae2258a14055ddd77fc40d8a344\n'}, {'number': 2, 'created': '2014-12-23 13:32:38.000000000', 'files': ['ironic/tests/test_utils.py', 'ironic/dhcp/neutron.py', 'ironic/drivers/modules/console_utils.py', 'ironic/common/utils.py', 'ironic/tests/drivers/test_console_utils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/72b871e176c4ec493c555e8fd28a3ad49ea799dd', 'message': 'Reuse methods from netutils\n\nReplace usages of is_valid_ipv4, is_valid_ipv6 from Ironic,\nby usages of this methods from oslo.utils and remove these\nmethods from Ironic code.\n\nChange-Id: I5f2b50718f2d6ae2258a14055ddd77fc40d8a344\n'}]",1,143629,72b871e176c4ec493c555e8fd28a3ad49ea799dd,18,6,2,9796,,,0,"Reuse methods from netutils

Replace usages of is_valid_ipv4, is_valid_ipv6 from Ironic,
by usages of this methods from oslo.utils and remove these
methods from Ironic code.

Change-Id: I5f2b50718f2d6ae2258a14055ddd77fc40d8a344
",git fetch https://review.opendev.org/openstack/ironic refs/changes/29/143629/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/test_utils.py', 'ironic/dhcp/neutron.py', 'ironic/drivers/modules/console_utils.py', 'ironic/common/utils.py', 'ironic/tests/drivers/test_console_utils.py']",5,f933f212254b84b7e47f1f26369176a78ae120ea,reuse_netutils,from oslo.utils import netutils if netutils.is_valid_ipv6(console_host):, if utils.is_valid_ipv6(console_host):,6,36
openstack%2Fopenstack-manuals~master~I67804d2e7bfbd53e8f453adc251a102c6f0e39ff,openstack/openstack-manuals,master,I67804d2e7bfbd53e8f453adc251a102c6f0e39ff,Clarify heat roles,MERGED,2014-12-23 15:23:30.000000000,2014-12-23 18:31:18.000000000,2014-12-23 18:31:16.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-23 15:23:30.000000000', 'files': ['doc/install-guide/section_heat-install.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/01a4e4060b300c1fc0b1b1634f106115e79aef2b', 'message': 'Clarify heat roles\n\nBuilding on an earlier patch, I further clarified the purpose\nof the heat_stack_owner and heat_stack_user roles.\n\nChange-Id: I67804d2e7bfbd53e8f453adc251a102c6f0e39ff\nCloses-Bug: #1401668\nbackport: juno\n'}]",0,143680,01a4e4060b300c1fc0b1b1634f106115e79aef2b,7,4,1,9515,,,0,"Clarify heat roles

Building on an earlier patch, I further clarified the purpose
of the heat_stack_owner and heat_stack_user roles.

Change-Id: I67804d2e7bfbd53e8f453adc251a102c6f0e39ff
Closes-Bug: #1401668
backport: juno
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/80/143680/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_heat-install.xml'],1,01a4e4060b300c1fc0b1b1634f106115e79aef2b,bug/1401668," <para>Create the <literal>heat_stack_owner</literal> role:</para> <screen><prompt>$</prompt> <userinput>keystone role-create --name heat_stack_owner</userinput></screen> </step> <step> <para>Add the <literal>heat_stack_owner</literal> role to the <literal>demo</literal> tenant and user:</para> <screen><prompt>$</prompt> <userinput>keystone user-role-add --user demo --tenant demo --role heat_stack_owner</userinput></screen> <note> <para>You must add the <literal>heat_stack_owner</literal> role to users that manage stacks.</para> </note> </step> <step> <para>Create the <literal>heat_stack_user</literal> role:</para> <screen><prompt>$</prompt> <userinput>keystone role-create --name heat_stack_user</userinput></screen> <note> <para>The Orchestration service automatically assigns the <literal>heat_stack_user</literal> role to users that it creates during stack deployment. By default, this role restricts <glossterm>API</glossterm> operations. To avoid conflicts, do not add this role to users with the <literal>heat_stack_owner</literal> role.</para> </note>"," <para>Create the <literal>heat_stack_user</literal> and <literal>heat_stack_owner</literal> roles:</para> <screen><prompt>$</prompt> <userinput>keystone role-create --name heat_stack_user</userinput> <prompt>$</prompt> <userinput>keystone role-create --name heat_stack_owner</userinput></screen> <para>By default, users created by Orchestration use the <literal>heat_stack_user</literal> role.</para> <para>The <literal>heat_stack_user</literal> role is for users created by heat, and is restricted to specific API actions. The <literal>heat_stack_owner</literal> role is assigned to users who create heat stacks.</para> <warning><para>Because the <literal>heat_stack_owner</literal> role has limited operational access to heat, you must never assign this role to a user with a <literal>heat_stack_user</literal> role.</para></warning>",23,14
openstack%2Fproject-config~master~I9e290822ce08fb3621f513f47a19c79bf634fde3,openstack/project-config,master,I9e290822ce08fb3621f513f47a19c79bf634fde3,Remove icehouse compat checks from glance/keystoneclient,MERGED,2014-12-22 23:33:45.000000000,2014-12-23 18:08:24.000000000,2014-12-23 18:08:23.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 5196}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 7069}, {'_account_id': 7191}]","[{'number': 1, 'created': '2014-12-22 23:33:45.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/240567ede9f36529b1c523a1eacad980fc9ed27c', 'message': ""Remove icehouse compat checks from glance/keystoneclient\n\nBoth of these clients' version in master is beyond their corresponding\nicehouse requirements version caps.  These jobs should be disabled since\nthose version constraints prevent icehouse from ever running with\nthe newest versions.\n\nChange-Id: I9e290822ce08fb3621f513f47a19c79bf634fde3\nCloses-bug: #1404083\nCloses-bug: #1404081\n""}]",0,143566,240567ede9f36529b1c523a1eacad980fc9ed27c,11,13,1,1420,,,0,"Remove icehouse compat checks from glance/keystoneclient

Both of these clients' version in master is beyond their corresponding
icehouse requirements version caps.  These jobs should be disabled since
those version constraints prevent icehouse from ever running with
the newest versions.

Change-Id: I9e290822ce08fb3621f513f47a19c79bf634fde3
Closes-bug: #1404083
Closes-bug: #1404081
",git fetch https://review.opendev.org/openstack/project-config refs/changes/66/143566/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,240567ede9f36529b1c523a1eacad980fc9ed27c,drop_stable_client_jobs, - name: stable-compat-jobs-one-release - name: stable-compat-jobs-one-release, - name: stable-compat-jobs - name: stable-compat-jobs,2,2
openstack%2Fheat-translator~master~I84b2df606db17209706d12f6f6a03e7812210d53,openstack/heat-translator,master,I84b2df606db17209706d12f6f6a03e7812210d53,Add a debug env for tox,MERGED,2014-12-19 22:21:50.000000000,2014-12-23 18:03:31.000000000,2014-12-23 18:03:30.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 7193}]","[{'number': 1, 'created': '2014-12-19 22:21:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/e24f0e2888084348b80c56b4bc55d3d22aa4fe95', 'message': ""Add a debug env for tox\nRunning a test with the pdb debugger was difficult because\ntox captures output and causes the pdb prompt to quit.\n\nTips for how to run with debug are provided here:\n https://wiki.openstack.org/wiki/Testr#Debugging_.28pdb.29_Tests\n\nThis change puts these commands into a debug env in tox.ini so\nyou can do a command like\n\ntox -e debug\n\nand when it hits your breakpoint you'll get the debug prompt.\n\nChange-Id: I84b2df606db17209706d12f6f6a03e7812210d53\n""}, {'number': 2, 'created': '2014-12-19 22:23:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/03f2a44746f52fcb06aef094ab0591d49263dd24', 'message': ""Add a debug env for tox\nRunning a test with the pdb debugger was difficult because\ntox captures output and causes the pdb prompt to quit.\n\nTips for how to run with debug are provided here:\nhttps://wiki.openstack.org/wiki/Testr#Debugging_.28pdb.29_Tests\n\nThis change puts these commands into a debug env in tox.ini so\nyou can do a command like\n\ntox -e debug\n\nand when it hits your breakpoint you'll get the debug prompt.\n\nChange-Id: I84b2df606db17209706d12f6f6a03e7812210d53\n""}, {'number': 3, 'created': '2014-12-19 22:24:52.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/4e39b5729f09078d43775893b81f4c9964209c0c', 'message': ""Add a debug env for tox\n\nRunning a test with the pdb debugger was difficult because\ntox captures output and causes the pdb prompt to quit.\n\nTips for how to run with debug are provided here:\nhttps://wiki.openstack.org/wiki/Testr#Debugging_.28pdb.29_Tests\n\nThis change puts these commands into a debug env in tox.ini so\nyou can do a command like\n\ntox -e debug\n\nand when it hits your breakpoint you'll get the debug prompt.\n\nChange-Id: I84b2df606db17209706d12f6f6a03e7812210d53\n""}]",0,143206,4e39b5729f09078d43775893b81f4c9964209c0c,12,3,3,6460,,,0,"Add a debug env for tox

Running a test with the pdb debugger was difficult because
tox captures output and causes the pdb prompt to quit.

Tips for how to run with debug are provided here:
https://wiki.openstack.org/wiki/Testr#Debugging_.28pdb.29_Tests

This change puts these commands into a debug env in tox.ini so
you can do a command like

tox -e debug

and when it hits your breakpoint you'll get the debug prompt.

Change-Id: I84b2df606db17209706d12f6f6a03e7812210d53
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/06/143206/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,e24f0e2888084348b80c56b4bc55d3d22aa4fe95,debugForTox,[testenv:debug] commands = oslo_debug_helper -t translator/tests {posargs} ,,4,0
openstack%2Frally~master~Ibb1fc8130f3621e2cfefd90d0b52d8b5afa9fe1e,openstack/rally,master,Ibb1fc8130f3621e2cfefd90d0b52d8b5afa9fe1e,Add docstrings to scenario classes defined inside tests,ABANDONED,2014-12-23 12:24:25.000000000,2014-12-23 17:53:18.000000000,,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-23 12:24:25.000000000', 'files': ['tests/unit/benchmark/scenarios/test_base.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/61f949dece124d285c66bdc84ad11a53960806d6', 'message': 'Add docstrings to scenario classes defined inside tests\n\nNo docstrings there potentially leads to races.\n\nChange-Id: Ibb1fc8130f3621e2cfefd90d0b52d8b5afa9fe1e\n'}]",0,143660,61f949dece124d285c66bdc84ad11a53960806d6,7,4,1,8507,,,0,"Add docstrings to scenario classes defined inside tests

No docstrings there potentially leads to races.

Change-Id: Ibb1fc8130f3621e2cfefd90d0b52d8b5afa9fe1e
",git fetch https://review.opendev.org/openstack/rally refs/changes/60/143660/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/unit/benchmark/scenarios/test_base.py'],1,61f949dece124d285c66bdc84ad11a53960806d6,docstrings," """"""Fake Scenario class."""""" """"""Fake Scenario class."""""" """"""Fake Scenario class."""""" """"""Fake Scenario class."""""" """"""Fake Scenario class.""""""", pass pass pass pass pass,5,5
openstack%2Fmanila~master~Ic115a4c5dfc4f0a7fb3d4dc83405280e35458535,openstack/manila,master,Ic115a4c5dfc4f0a7fb3d4dc83405280e35458535,Lower concurrency for CI,ABANDONED,2014-12-18 19:40:31.000000000,2014-12-23 17:49:48.000000000,,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 8851}, {'_account_id': 11878}]","[{'number': 1, 'created': '2014-12-18 19:40:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ca0b805856db66d3b152646644d00a1c675c93de', 'message': 'Test lower concurrency for CI\n\nChange-Id: Ic115a4c5dfc4f0a7fb3d4dc83405280e35458535\n'}, {'number': 2, 'created': '2014-12-19 16:02:54.000000000', 'files': ['contrib/ci/post_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/manila/commit/2997c5c9cd722ed4c85f05adf3b62e5948ea9a0c', 'message': 'Lower concurrency for CI\n\nWe still have check jobs failing somewhat regularly, and lower\nconcurrency should reduce that chance. Testing shows that the\ncheck job does not take noticeably longer with concurrency set\nto 3 rather than 6.\n\nChange-Id: Ic115a4c5dfc4f0a7fb3d4dc83405280e35458535\n'}]",0,142890,2997c5c9cd722ed4c85f05adf3b62e5948ea9a0c,12,4,2,2417,,,0,"Lower concurrency for CI

We still have check jobs failing somewhat regularly, and lower
concurrency should reduce that chance. Testing shows that the
check job does not take noticeably longer with concurrency set
to 3 rather than 6.

Change-Id: Ic115a4c5dfc4f0a7fb3d4dc83405280e35458535
",git fetch https://review.opendev.org/openstack/manila refs/changes/90/142890/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/ci/post_test_hook.sh'],1,ca0b805856db66d3b152646644d00a1c675c93de,,export TEMPEST_CONCURRENCY=3,export TEMPEST_CONCURRENCY=6,1,1
openstack%2Fneutron~master~Ife1fc2a8f8fe284605ad77cee4ffa307e6d5360c,openstack/neutron,master,Ife1fc2a8f8fe284605ad77cee4ffa307e6d5360c,ML2 UT: Fix incorrect mock return value,MERGED,2014-12-22 16:43:49.000000000,2014-12-23 17:44:12.000000000,2014-12-23 17:44:10.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6698}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}]","[{'number': 1, 'created': '2014-12-22 16:43:49.000000000', 'files': ['neutron/tests/unit/ml2/drivers/cisco/nexus/test_cisco_mech.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c948e4318665492cd9a46bfc9ec47250b8cc9692', 'message': 'ML2 UT: Fix incorrect mock return value\n\nIn the UT for ML2 Cisco Nexus MD,\nin the function test_ncclient_version_detect()\nThe value being passed into the mock is incorrect\nto mock the ncclient connect object.\n\nChange-Id: Ife1fc2a8f8fe284605ad77cee4ffa307e6d5360c\nCloses-Bug: #1404927\n'}]",0,143489,c948e4318665492cd9a46bfc9ec47250b8cc9692,33,19,1,6698,,,0,"ML2 UT: Fix incorrect mock return value

In the UT for ML2 Cisco Nexus MD,
in the function test_ncclient_version_detect()
The value being passed into the mock is incorrect
to mock the ncclient connect object.

Change-Id: Ife1fc2a8f8fe284605ad77cee4ffa307e6d5360c
Closes-Bug: #1404927
",git fetch https://review.opendev.org/openstack/neutron refs/changes/89/143489/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/ml2/drivers/cisco/nexus/test_cisco_mech.py'],1,c948e4318665492cd9a46bfc9ec47250b8cc9692,bug/1404927," orig_connect_return_val = self.mock_ncclient.connect.return_value [TypeError, orig_connect_return_val]):"," connect = self.mock_ncclient.connect [TypeError, connect]):",2,2
openstack%2Fheat~master~I94b117bf2d142ff1a67affec503d9cfdb8a558cc,openstack/heat,master,I94b117bf2d142ff1a67affec503d9cfdb8a558cc,Abstract rpc 'create_stack' call mock method,MERGED,2014-12-08 04:28:56.000000000,2014-12-23 17:43:33.000000000,2014-12-23 17:43:32.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 3098}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 6983}, {'_account_id': 7256}, {'_account_id': 9542}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-08 04:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e94628d1188f36042fef07d25ab75b3974bd257d', 'message': ""Abstract rpc 'create_stack' call mock method\n\nAbstract 'create_stack' rpc call mock method.\n\nChange-Id: I94b117bf2d142ff1a67affec503d9cfdb8a558cc\n""}, {'number': 2, 'created': '2014-12-08 04:30:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e017ace0e0a5b99ef27b08774b4ccb9a057caa81', 'message': ""Abstract rpc 'create_stack' call mock method\n\nAbstract 'create_stack' rpc call mock method for \ntest_api_cfn_v1.py.\n\nChange-Id: I94b117bf2d142ff1a67affec503d9cfdb8a558cc\n""}, {'number': 3, 'created': '2014-12-11 02:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/35633ded08d7928d07c394376737702ddb1d1aac', 'message': ""Abstract rpc 'create_stack' call mock method\n\nAbstract 'create_stack' rpc call mock method for \ntest_api_cfn_v1.py.\n\nChange-Id: I94b117bf2d142ff1a67affec503d9cfdb8a558cc\n""}, {'number': 4, 'created': '2014-12-22 08:52:41.000000000', 'files': ['heat/tests/test_api_cfn_v1.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/2798d2762f5b8b623e8c80fb41fb0ce9afa4562c', 'message': ""Abstract rpc 'create_stack' call mock method\n\nAbstract 'create_stack' rpc call mock method for \ntest_api_cfn_v1.py.\n\nChange-Id: I94b117bf2d142ff1a67affec503d9cfdb8a558cc\n""}]",0,139902,2798d2762f5b8b623e8c80fb41fb0ce9afa4562c,18,9,4,8289,,,0,"Abstract rpc 'create_stack' call mock method

Abstract 'create_stack' rpc call mock method for 
test_api_cfn_v1.py.

Change-Id: I94b117bf2d142ff1a67affec503d9cfdb8a558cc
",git fetch https://review.opendev.org/openstack/heat refs/changes/02/139902/4 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_api_cfn_v1.py'],1,e94628d1188f36042fef07d25ab75b3974bd257d,abstract-rpc-client-calls," def _stub_rpc_create_stack_call_failure(self, req_context, stack_name, engine_parms, engine_args, failure, need_stub=True): if need_stub: self.m.StubOutWithMock(policy.Enforcer, 'enforce') self.m.StubOutWithMock(rpc_client.EngineClient, 'call') policy.Enforcer.enforce(req_context, 'CreateStack').AndReturn(True) # Insert an engine RPC error and ensure we map correctly to the # heat exception type rpc_client.EngineClient.call( req_context, ('create_stack', {'stack_name': stack_name, 'template': self.template, 'params': engine_parms, 'files': {}, 'args': engine_args, 'owner_id': None, 'nested_depth': 0, 'user_creds_id': None, 'stack_user_project_id': None}), version='1.2' ).AndRaise(failure) def _stub_rpc_create_stack_call_success(self, stack_name, engine_parms, engine_args, parameters): dummy_req = self._dummy_GET_request(parameters) return dummy_req def test_create(self): # Format a dummy request stack_name = ""wordpress"" json_template = json.dumps(self.template) params = {'Action': 'CreateStack', 'StackName': stack_name, 'TemplateBody': '%s' % json_template, 'TimeoutInMinutes': 30, 'DisableRollback': 'true', 'Parameters.member.1.ParameterKey': 'InstanceType', 'Parameters.member.1.ParameterValue': 'm1.xlarge'} engine_parms = {u'InstanceType': u'm1.xlarge'} engine_args = {'timeout_mins': u'30', 'disable_rollback': 'true'} dummy_req = self._stub_rpc_create_stack_call_success(stack_name, engine_parms, engine_args, params) dummy_req = self._stub_rpc_create_stack_call_success(stack_name, engine_parms, engine_args, params) dummy_req = self._stub_rpc_create_stack_call_success(stack_name, engine_parms, engine_args, params) dummy_req = self._stub_rpc_create_stack_call_success(stack_name, engine_parms, engine_args, params) dummy_req = self._stub_rpc_create_stack_call_success(stack_name, engine_parms, engine_args, params) self._stub_rpc_create_stack_call_failure(dummy_req.context, stack_name, engine_parms, engine_args, AttributeError()) failure = heat_exception.UnknownUserParameter(key='test') self._stub_rpc_create_stack_call_failure(dummy_req.context, stack_name, engine_parms, engine_args, failure, False) failure = heat_exception.UserParameterMissing(key='test') self._stub_rpc_create_stack_call_failure(dummy_req.context, stack_name, engine_parms, engine_args, failure, False) failure = heat_exception.StackExists(stack_name='test') self._stub_rpc_create_stack_call_failure(dummy_req.context, stack_name, engine_parms, engine_args, failure) failure = heat_exception.StackValidationFailed( message='Something went wrong') self._stub_rpc_create_stack_call_failure(dummy_req.context, stack_name, engine_parms, engine_args, failure)"," def test_create(self): # Format a dummy request stack_name = ""wordpress"" json_template = json.dumps(self.template) params = {'Action': 'CreateStack', 'StackName': stack_name, 'TemplateBody': '%s' % json_template, 'TimeoutInMinutes': 30, 'DisableRollback': 'true', 'Parameters.member.1.ParameterKey': 'InstanceType', 'Parameters.member.1.ParameterValue': 'm1.xlarge'} engine_parms = {u'InstanceType': u'm1.xlarge'} engine_args = {'timeout_mins': u'30', 'disable_rollback': 'true'} dummy_req = self._dummy_GET_request(params) dummy_req = self._dummy_GET_request(params) self._stub_enforce(dummy_req, 'CreateStack') # Stub out the RPC call to the engine with a pre-canned response engine_resp = {u'tenant': u't', u'stack_name': u'wordpress', u'stack_id': u'1', u'path': u''} self.m.StubOutWithMock(rpc_client.EngineClient, 'call') rpc_client.EngineClient.call( dummy_req.context, ('create_stack', {'stack_name': stack_name, 'template': self.template, 'params': engine_parms, 'files': {}, 'args': engine_args, 'owner_id': None, 'nested_depth': 0, 'user_creds_id': None, 'stack_user_project_id': None}), version='1.2' ).AndReturn(engine_resp) self.m.ReplayAll() dummy_req = self._dummy_GET_request(params) self._stub_enforce(dummy_req, 'CreateStack') # Stub out the RPC call to the engine with a pre-canned response engine_resp = {u'tenant': u't', u'stack_name': u'wordpress', u'stack_id': u'1', u'path': u''} self.m.StubOutWithMock(rpc_client.EngineClient, 'call') rpc_client.EngineClient.call( dummy_req.context, ('create_stack', {'stack_name': stack_name, 'template': self.template, 'params': engine_parms, 'files': {}, 'args': engine_args, 'owner_id': None, 'nested_depth': 0, 'user_creds_id': None, 'stack_user_project_id': None}), version='1.2' ).AndReturn(engine_resp) self.m.ReplayAll() dummy_req = self._dummy_GET_request(params) self._stub_enforce(dummy_req, 'CreateStack') # Stub out the RPC call to the engine with a pre-canned response engine_resp = {u'tenant': u't', u'stack_name': u'wordpress', u'stack_id': u'1', u'path': u''} self.m.StubOutWithMock(rpc_client.EngineClient, 'call') rpc_client.EngineClient.call( dummy_req.context, ('create_stack', {'stack_name': stack_name, 'template': self.template, 'params': engine_parms, 'files': {}, 'args': engine_args, 'owner_id': None, 'nested_depth': 0, 'user_creds_id': None, 'stack_user_project_id': None}), version='1.2' ).AndReturn(engine_resp) self.m.ReplayAll() dummy_req = self._dummy_GET_request(params) self._stub_enforce(dummy_req, 'CreateStack') # Stub out the RPC call to the engine with a pre-canned response engine_resp = {u'tenant': u't', u'stack_name': u'wordpress', u'stack_id': u'1', u'path': u''} self.m.StubOutWithMock(rpc_client.EngineClient, 'call') rpc_client.EngineClient.call( dummy_req.context, ('create_stack', {'stack_name': stack_name, 'template': self.template, 'params': engine_parms, 'files': {}, 'args': engine_args, 'owner_id': None, 'nested_depth': 0, 'user_creds_id': None, 'stack_user_project_id': None}), version='1.2' ).AndReturn(engine_resp) self.m.ReplayAll() self.m.StubOutWithMock(policy.Enforcer, 'enforce') # Insert an engine RPC error and ensure we map correctly to the # heat exception type self.m.StubOutWithMock(rpc_client.EngineClient, 'call') policy.Enforcer.enforce(dummy_req.context, 'CreateStack' ).AndReturn(True) rpc_client.EngineClient.call( dummy_req.context, ('create_stack', {'stack_name': stack_name, 'template': self.template, 'params': engine_parms, 'files': {}, 'args': engine_args, 'owner_id': None, 'nested_depth': 0, 'user_creds_id': None, 'stack_user_project_id': None}), version='1.2' ).AndRaise(AttributeError()) policy.Enforcer.enforce(dummy_req.context, 'CreateStack' ).AndReturn(True) rpc_client.EngineClient.call( dummy_req.context, ('create_stack', {'stack_name': stack_name, 'template': self.template, 'params': engine_parms, 'files': {}, 'args': engine_args, 'owner_id': None, 'nested_depth': 0, 'user_creds_id': None, 'stack_user_project_id': None}), version='1.2' ).AndRaise(heat_exception.UnknownUserParameter(key='test')) policy.Enforcer.enforce(dummy_req.context, 'CreateStack' ).AndReturn(True) rpc_client.EngineClient.call( dummy_req.context, ('create_stack', {'stack_name': stack_name, 'template': self.template, 'params': engine_parms, 'files': {}, 'args': engine_args, 'owner_id': None, 'nested_depth': 0, 'user_creds_id': None, 'stack_user_project_id': None}), version='1.2' ).AndRaise(heat_exception.UserParameterMissing(key='test')) self._stub_enforce(dummy_req, 'CreateStack') # Insert an engine RPC error and ensure we map correctly to the # heat exception type self.m.StubOutWithMock(rpc_client.EngineClient, 'call') rpc_client.EngineClient.call( dummy_req.context, ('create_stack', {'stack_name': stack_name, 'template': self.template, 'params': engine_parms, 'files': {}, 'args': engine_args, 'owner_id': None, 'nested_depth': 0, 'user_creds_id': None, 'stack_user_project_id': None}), version='1.2' ).AndRaise(heat_exception.StackExists(stack_name='test')) self._stub_enforce(dummy_req, 'CreateStack') # Stub out the RPC call to the engine with a pre-canned response self.m.StubOutWithMock(rpc_client.EngineClient, 'call') rpc_client.EngineClient.call( dummy_req.context, ('create_stack', {'stack_name': stack_name, 'template': self.template, 'params': engine_parms, 'files': {}, 'args': engine_args, 'owner_id': None, 'nested_depth': 0, 'user_creds_id': None, 'stack_user_project_id': None}), version='1.2' ).AndRaise(heat_exception.StackValidationFailed( message='Something went wrong')) ",94,218
openstack%2Ftripleo-image-elements~master~If4f650719828cf8b506cdce21ee8095757844965,openstack/tripleo-image-elements,master,If4f650719828cf8b506cdce21ee8095757844965,Add iptables rule for nova and mysql,MERGED,2014-12-12 00:02:05.000000000,2014-12-23 17:32:13.000000000,2014-12-23 17:32:11.000000000,"[{'_account_id': 3}, {'_account_id': 1872}, {'_account_id': 1926}, {'_account_id': 7144}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-12-12 00:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a303c293d8446be35d2a6cc8b236d9c1a90155b4', 'message': 'Add iptables rule for glance, nova, mysql\n\nOur testing shows that the following ports need to be\nopened in iptables in order for proper behavior when\nthe firewall is enabled:\n\n1) Glance port #9191\n2) Mysql port #4444 and #4568 (needed for Galera clustering)\n3) Nova\tport #8773 for EC2 apis\n\nChange-Id: If4f650719828cf8b506cdce21ee8095757844965\n'}, {'number': 2, 'created': '2014-12-12 17:09:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a10c39befc48f80249d94279cb9e0f9c70060227', 'message': 'Add iptables rule for glance, nova, mysql\n\nOur testing shows that the following ports need to be\nopened in iptables in order for proper behavior when\nthe firewall is enabled:\n\n1) Mysql port #4444 and #4568 (needed for Galera clustering)\n2) Nova\tport #8773 for EC2 apis\n\nChange-Id: If4f650719828cf8b506cdce21ee8095757844965\n'}, {'number': 3, 'created': '2014-12-16 19:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/58a53814f239a31ee8f02501e60bb53163d1403c', 'message': 'Add iptables rule for nova and mysql\n\nOur testing shows that the following ports need to be\nopened in iptables in order for proper behavior when\nthe firewall is enabled:\n\n1) Mysql port #4444 and #4568 (needed for Galera clustering)\n2) Nova\tport #8773 for EC2 apis\n\nChange-Id: If4f650719828cf8b506cdce21ee8095757844965\n'}, {'number': 4, 'created': '2014-12-17 22:37:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/fdfa89e7bb2947a466f97330e9443a0fdf9e5b34', 'message': 'Add iptables rule for nova and mysql\n\nOur testing shows that the following ports need to be\nopened in iptables in order for proper behavior when\nthe firewall is enabled:\n\n1) Mysql port #4444 and #4568 (needed for Galera clustering)\naccording to Percona documentation at:\nhttp://www.percona.com/doc/percona-xtradb-cluster/5.5/howtos/3nodesec2.html\n\n2) Nova\tport #8773 for EC2 apis according to Red Hat documentation:\nhttps://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux_OpenStack_Platform/2/html/Getting_Started_Guide/chap-Deploying_Compute_Services.html\n\nChange-Id: If4f650719828cf8b506cdce21ee8095757844965\n'}, {'number': 5, 'created': '2014-12-18 14:13:19.000000000', 'files': ['elements/nova-api/os-refresh-config/pre-configure.d/97-nova-api-fedora-iptables', 'elements/mysql-common/os-refresh-config/pre-configure.d/97-mysql-galera-iptables'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/285150277e7c76fe87ecc954a0dba20eec7c8678', 'message': 'Add iptables rule for nova and mysql\n\nOur testing shows that the following ports need to be\nopened in iptables in order for proper behavior when\nthe firewall is enabled:\n\n1) Mysql port #4444 and #4568 (needed for Galera clustering)\naccording to Percona documentation at:\nhttp://www.percona.com/doc/percona-xtradb-cluster/5.5/howtos/3nodesec2.html\n\n2) Nova port #8773 for EC2 apis according to Red Hat documentation:\nhttps://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux_OpenStack_Platform/2/html/Getting_Started_Guide/chap-Deploying_Compute_Services.html\n\nChange-Id: If4f650719828cf8b506cdce21ee8095757844965\n'}]",3,141221,285150277e7c76fe87ecc954a0dba20eec7c8678,31,7,5,10290,,,0,"Add iptables rule for nova and mysql

Our testing shows that the following ports need to be
opened in iptables in order for proper behavior when
the firewall is enabled:

1) Mysql port #4444 and #4568 (needed for Galera clustering)
according to Percona documentation at:
http://www.percona.com/doc/percona-xtradb-cluster/5.5/howtos/3nodesec2.html

2) Nova port #8773 for EC2 apis according to Red Hat documentation:
https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux_OpenStack_Platform/2/html/Getting_Started_Guide/chap-Deploying_Compute_Services.html

Change-Id: If4f650719828cf8b506cdce21ee8095757844965
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/21/141221/4 && git format-patch -1 --stdout FETCH_HEAD,"['elements/nova-api/os-refresh-config/pre-configure.d/97-nova-api-fedora-iptables', 'elements/mysql-common/os-refresh-config/pre-configure.d/97-mysql-galera-iptables']",2,a303c293d8446be35d2a6cc8b236d9c1a90155b4,(detached,add-rule INPUT -p tcp --dport 4568 -j ACCEPT # galera add-rule INPUT -p tcp --dport 4444 -j ACCEPT # mysql cluster,,3,0
openstack%2Ftripleo-heat-templates~master~I0691f43bd2ce85bec0d68ab979136414f0610c61,openstack/tripleo-heat-templates,master,I0691f43bd2ce85bec0d68ab979136414f0610c61,Don't store Neutron DB credentials on compute node,MERGED,2014-11-25 20:17:23.000000000,2014-12-23 17:30:45.000000000,2014-12-23 17:30:45.000000000,"[{'_account_id': 3}, {'_account_id': 4220}, {'_account_id': 4328}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-11-25 20:17:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e7620c821bdaee692f1034105445f0e7ac0872b2', 'message': ""Compute nodes don't need neutron_dsn\n\nThis patch removes all references to the Neutron DSN parameter\nin the overcloud compute templates.\n\nChange-Id: I0691f43bd2ce85bec0d68ab979136414f0610c61\n""}, {'number': 2, 'created': '2014-12-07 20:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/017704000d241970948104031ce084a2663685a4', 'message': ""Don't store Neutron DB credentials on compute node\n\nThis patch removes all references to the Neutron DSN parameter\nin the overcloud compute templates. These credentials\nare not required in order to run the required Neutron\nservices.\n\nChange-Id: I0691f43bd2ce85bec0d68ab979136414f0610c61\n""}, {'number': 3, 'created': '2014-12-08 13:35:38.000000000', 'files': ['overcloud-without-mergepy.yaml', 'nova-compute-config.yaml', 'nova-compute-instance.yaml', 'compute.yaml', 'overcloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2c403d89fa3af67c36ff0e37f9dfafbf7dc5103f', 'message': ""Don't store Neutron DB credentials on compute node\n\nThis patch removes all references to the Neutron DSN parameter\nin the overcloud compute templates. These credentials\nare not required in order to run the required Neutron\nservices.\n\nChange-Id: I0691f43bd2ce85bec0d68ab979136414f0610c61\n""}]",0,137192,2c403d89fa3af67c36ff0e37f9dfafbf7dc5103f,19,6,3,360,,,0,"Don't store Neutron DB credentials on compute node

This patch removes all references to the Neutron DSN parameter
in the overcloud compute templates. These credentials
are not required in order to run the required Neutron
services.

Change-Id: I0691f43bd2ce85bec0d68ab979136414f0610c61
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/92/137192/2 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-without-mergepy.yaml', 'nova-compute-config.yaml', 'nova-compute-instance.yaml', 'compute.yaml', 'compute-config.yaml', 'overcloud-source.yaml']",6,e7620c821bdaee692f1034105445f0e7ac0872b2,no_compute_dsn,, NeutronDSN: Fn::Join: - '' - - mysql://neutron:unset@ - *compute_database_host - /ovs_neutron,0,18
openstack%2Ftripleo-heat-templates~master~If75f480489b84002dd061c183dbee3572a8b63f1,openstack/tripleo-heat-templates,master,If75f480489b84002dd061c183dbee3572a8b63f1,Don't store Nova DB credentials on compute nodes,MERGED,2014-11-25 20:03:34.000000000,2014-12-23 17:30:28.000000000,2014-12-23 17:30:28.000000000,"[{'_account_id': 3}, {'_account_id': 4220}, {'_account_id': 4328}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 9369}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-11-25 20:03:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b65eebf6770b49019a2a601f0c794c43f6a47af0', 'message': ""Compute nodes don't need nova_dsn\n\nWhen using the Conductor the Nova compute service\ndoes not need access to the database. This patch\nremoves all references to the Nova DSN in the overcloud\ncompute templates.\n\nChange-Id: If75f480489b84002dd061c183dbee3572a8b63f1\n""}, {'number': 2, 'created': '2014-11-25 20:17:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b373e8f9e493180dcbefbc67627db8c53ec6335c', 'message': ""Compute nodes don't need nova_dsn\n\nWhen using the Conductor the Nova compute service\ndoes not need access to the database. This patch\nremoves all references to the Nova DSN in the overcloud\ncompute templates.\n\nChange-Id: If75f480489b84002dd061c183dbee3572a8b63f1\n""}, {'number': 3, 'created': '2014-12-07 20:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1735c1c1dff5d9c88d94cd09db399a943d90a6de', 'message': ""Don't store Nova DB credentials on compute nodes\n\nRemove NovaDSN from overcloud compute.\n\nWhen using the Conductor the Nova compute service\ndoes not need access to the database. This patch\nremoves all references to the Nova DSN in the overcloud\ncompute templates.\n\nChange-Id: If75f480489b84002dd061c183dbee3572a8b63f1\n""}, {'number': 4, 'created': '2014-12-08 13:35:38.000000000', 'files': ['overcloud-without-mergepy.yaml', 'nova-compute-config.yaml', 'nova-compute-instance.yaml', 'compute.yaml', 'compute-config.yaml', 'overcloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dfec68afbe99d7bba43b62304b220d8a238a8730', 'message': ""Don't store Nova DB credentials on compute nodes\n\nRemove NovaDSN from overcloud compute.\n\nWhen using the Conductor the Nova compute service\ndoes not need access to the database. This patch\nremoves all references to the Nova DSN in the overcloud\ncompute templates.\n\nChange-Id: If75f480489b84002dd061c183dbee3572a8b63f1\n""}]",0,137183,dfec68afbe99d7bba43b62304b220d8a238a8730,21,7,4,360,,,0,"Don't store Nova DB credentials on compute nodes

Remove NovaDSN from overcloud compute.

When using the Conductor the Nova compute service
does not need access to the database. This patch
removes all references to the Nova DSN in the overcloud
compute templates.

Change-Id: If75f480489b84002dd061c183dbee3572a8b63f1
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/83/137183/1 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-without-mergepy.yaml', 'nova-compute-config.yaml', 'nova-compute-instance.yaml', 'compute.yaml', 'compute-config.yaml']",5,b65eebf6770b49019a2a601f0c794c43f6a47af0,no_compute_dsn,, db: {get_input: nova_dsn},1,15
openstack%2Fcinder~master~I5c8653a17250063660ca8aa369c537cc340bc4e9,openstack/cinder,master,I5c8653a17250063660ca8aa369c537cc340bc4e9,Set iet_conf to nonexistent file in unit test,MERGED,2014-12-20 00:47:49.000000000,2014-12-23 17:26:24.000000000,2014-12-22 16:25:10.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 7198}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 13900}, {'_account_id': 14206}]","[{'number': 1, 'created': '2014-12-20 00:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/77b8c622e41c68716448c0733c91ad9633e3c899', 'message': ""Set iet_conf to nonexistent file in unit test\n\nThe Iet test in test_iscsi isn't setup to deal with\nan actual iet.conf file.  The result is that if you happen\nto be on a system that has an iet.conf file the test will fail\nwhen it gets to the os.stat check.\n\nThis patch just uses a tempdir with a bogus file name that is\nset as the iet_conf option to make sure the test never runs into\na situation where the file is actually there.\n\nChange-Id: I5c8653a17250063660ca8aa369c537cc340bc4e9\nCloses-Bug: #1400780\n""}, {'number': 2, 'created': '2014-12-21 17:55:39.000000000', 'files': ['cinder/tests/test_iscsi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/80bc025da4ee2b90f7ac9add5f5769c7cdd52bb2', 'message': ""Set iet_conf to nonexistent file in unit test\n\nThe Iet test in test_iscsi isn't setup to deal with\nan actual iet.conf file.  The result is that if you happen\nto be on a system that has an iet.conf file the test will fail\nwhen it gets to the os.stat check.\n\nThis patch just uses a tempdir with a bogus file name that is\nset as the iet_conf option to make sure the test never runs into\na situation where the file is actually there.\n\nChange-Id: I5c8653a17250063660ca8aa369c537cc340bc4e9\nCloses-Bug: #1400780\n""}]",1,143229,80bc025da4ee2b90f7ac9add5f5769c7cdd52bb2,22,13,2,2243,,,0,"Set iet_conf to nonexistent file in unit test

The Iet test in test_iscsi isn't setup to deal with
an actual iet.conf file.  The result is that if you happen
to be on a system that has an iet.conf file the test will fail
when it gets to the os.stat check.

This patch just uses a tempdir with a bogus file name that is
set as the iet_conf option to make sure the test never runs into
a situation where the file is actually there.

Change-Id: I5c8653a17250063660ca8aa369c537cc340bc4e9
Closes-Bug: #1400780
",git fetch https://review.opendev.org/openstack/cinder refs/changes/29/143229/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/test_iscsi.py'],1,77b8c622e41c68716448c0733c91ad9633e3c899,bug/1400780, tempdir = tempfile.mkdtemp() self.iet_conffile = str(tempdir)+'/bogus-file' self.flags(iet_conf=self.iet_conffile) tempdir = tempfile.mkdtemp() self.iet_conffile = str(tempdir)+'/bogus-file' self.flags(iet_conf=self.iet_conffile) tempdir = tempfile.mkdtemp() self.iet_conffile = str(tempdir)+'/bogus-file' self.flags(iet_conf=self.iet_conffile) self.iet_conffile = 'this-bogus-conf-file-dne' self.flags(iet_conf=self.iet_conffile),,19,0
openstack%2Fproject-config~master~I3ad1260b3886e05a5157eb8decfdd5e51cbff22e,openstack/project-config,master,I3ad1260b3886e05a5157eb8decfdd5e51cbff22e,Add more publications branches to gerritbot,MERGED,2014-12-19 21:36:36.000000000,2014-12-23 17:22:10.000000000,2014-12-23 17:22:09.000000000,"[{'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6609}]","[{'number': 1, 'created': '2014-12-19 21:36:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/6d4eae5942fb22872d93f3e6354eb073666b426f', 'message': ""Add more publications branches to gerritbot\n\nOf the publications considered current, four of the publications branches\nweren't sending notifications to channel, adding them to gerritbot so we see\nthem.\n\nChange-Id: I3ad1260b3886e05a5157eb8decfdd5e51cbff22e\n""}, {'number': 2, 'created': '2014-12-22 19:07:02.000000000', 'files': ['gerritbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/715a83afde70a609b876701b210bb361dc4b1284', 'message': ""Add more publications branches to gerritbot\n\nOf the publications considered current, five of the publications branches\nweren't sending notifications to channel, adding them to gerritbot so we see\nthem. Also, reorganize list so it's alphabetized and has a section specific\nto publications.\n\nChange-Id: I3ad1260b3886e05a5157eb8decfdd5e51cbff22e\n""}]",6,143197,715a83afde70a609b876701b210bb361dc4b1284,18,5,2,6609,,,0,"Add more publications branches to gerritbot

Of the publications considered current, five of the publications branches
weren't sending notifications to channel, adding them to gerritbot so we see
them. Also, reorganize list so it's alphabetized and has a section specific
to publications.

Change-Id: I3ad1260b3886e05a5157eb8decfdd5e51cbff22e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/97/143197/1 && git format-patch -1 --stdout FETCH_HEAD,['gerritbot/channels.yaml'],1,6d4eae5942fb22872d93f3e6354eb073666b426f,add/pubbranches, - devstack-tutorial - processing-ci-log-events - stackforge - using-your-own,,4,0
openstack%2Ftripleo-image-elements~master~I8757019e9731bad91173cbc545ef09d0dbb2e29c,openstack/tripleo-image-elements,master,I8757019e9731bad91173cbc545ef09d0dbb2e29c,Only configure Ceilo DB connection if it is set,MERGED,2014-12-07 20:14:10.000000000,2014-12-23 17:21:00.000000000,2014-12-23 17:21:00.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-12-07 20:14:10.000000000', 'files': ['elements/ceilometer/os-apply-config/etc/ceilometer/ceilometer.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/d80116c25e5ab4f4e3e248169202c7239887dff4', 'message': 'Only configure Ceilo DB connection if it is set\n\nThe Ceilometer compute agent does not require DB access.\nThis patch avoids configuring the database/connection setting\nif no metadata is present.\n\nChange-Id: I8757019e9731bad91173cbc545ef09d0dbb2e29c\n'}]",0,139877,d80116c25e5ab4f4e3e248169202c7239887dff4,14,4,1,360,,,0,"Only configure Ceilo DB connection if it is set

The Ceilometer compute agent does not require DB access.
This patch avoids configuring the database/connection setting
if no metadata is present.

Change-Id: I8757019e9731bad91173cbc545ef09d0dbb2e29c
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/77/139877/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/ceilometer/os-apply-config/etc/ceilometer/ceilometer.conf'],1,d80116c25e5ab4f4e3e248169202c7239887dff4,ceilometer_db,{{#ceilometer.db}}{{/ceilometer.db}},,2,0
openstack%2Fproject-config~master~Ie2be50f842b4220d4e7f9d8e830d3df3262a6353,openstack/project-config,master,Ie2be50f842b4220d4e7f9d8e830d3df3262a6353,XenServer: Enable injection of XVA and ISO urls,MERGED,2014-11-24 07:48:52.000000000,2014-12-23 17:17:25.000000000,2014-12-23 17:17:25.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 5044}, {'_account_id': 6133}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6554}, {'_account_id': 6735}]","[{'number': 1, 'created': '2014-11-24 07:48:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/535236e8e5c7391947c5d0d4a60a059600e2ac5c', 'message': ""XenServer: Use nodepool to inject XVA and ISO url\n\nThis will enable the flexible configuration of the XVA and the URL\nthrough nodepool, thus it's not needed to push an infra change for\nchanging those values.\n\nChange-Id: Ie2be50f842b4220d4e7f9d8e830d3df3262a6353\n""}, {'number': 2, 'created': '2014-12-18 17:08:14.000000000', 'files': ['nodepool/scripts/convert_node_to_xenserver.sh', 'nodepool/scripts/install_xenserver.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c7c3d68468eee3c85bf5a052353e90bdee791693', 'message': ""XenServer: Enable injection of XVA and ISO urls\n\nThis will enable the flexible configuration of the XVA and the URL\nthrough nodepool, thus it's not needed to push an infra change for\nchanging those values. Also if you do not have those values configured,\nsensible defaults are provided.\n\nChange-Id: Ie2be50f842b4220d4e7f9d8e830d3df3262a6353\n""}]",1,136700,c7c3d68468eee3c85bf5a052353e90bdee791693,19,9,2,5044,,,0,"XenServer: Enable injection of XVA and ISO urls

This will enable the flexible configuration of the XVA and the URL
through nodepool, thus it's not needed to push an infra change for
changing those values. Also if you do not have those values configured,
sensible defaults are provided.

Change-Id: Ie2be50f842b4220d4e7f9d8e830d3df3262a6353
",git fetch https://review.opendev.org/openstack/project-config refs/changes/00/136700/2 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/scripts/convert_node_to_xenserver.sh', 'nodepool/scripts/install_xenserver.sh']",2,535236e8e5c7391947c5d0d4a60a059600e2ac5c,addparams," ""$NODEPOOL_XENSERVER_XVA_URL"" \ devstack \ ""$NODEPOOL_XENSERVER_ISO_URL""", http://downloads.vmd.citrix.com/OpenStack/xenapi-in-the-cloud-appliances/1.1.4.xva \ devstack,4,3
openstack%2Fheat~master~Ia5abf6da88eb2f701978bcc637a417706831ed0f,openstack/heat,master,Ia5abf6da88eb2f701978bcc637a417706831ed0f,Add Nova flavor constraint for SaharaNodeGroupTemplate,MERGED,2014-12-12 02:16:36.000000000,2014-12-23 17:13:59.000000000,2014-12-23 17:13:57.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 6983}, {'_account_id': 9542}, {'_account_id': 13009}, {'_account_id': 13323}]","[{'number': 1, 'created': '2014-12-12 02:16:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a2752843212ae83a86e3e3b1fbf6b71298d80d48', 'message': ""Add Nova flavor constraint for SaharaNodeGroupTemplate\n\nAdd nova.flavor custom constraint for\nSaharaNodeGroupTemplate resource, to validate\nthe flavor's existence.\n\nChange-Id: Ia5abf6da88eb2f701978bcc637a417706831ed0f\n""}, {'number': 2, 'created': '2014-12-17 14:29:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f8ab4d1f07adeaffbd7e4bd1287fcedfbd4d2ae9', 'message': ""Add Nova flavor constraint for SaharaNodeGroupTemplate\n\nAdd nova.flavor custom constraint for\nSaharaNodeGroupTemplate resource, to validate\nthe flavor's existence.\n\nChange-Id: Ia5abf6da88eb2f701978bcc637a417706831ed0f\n""}, {'number': 3, 'created': '2014-12-22 03:56:04.000000000', 'files': ['heat/tests/test_sahara_templates.py', 'heat/engine/resources/sahara_templates.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/3f20aa88cfcd601e2418c279d4d5383260d325ac', 'message': ""Add Nova flavor constraint for SaharaNodeGroupTemplate\n\nAdd nova.flavor custom constraint for\nSaharaNodeGroupTemplate resource, to validate\nthe flavor's existence.\n\nChange-Id: Ia5abf6da88eb2f701978bcc637a417706831ed0f\n""}]",0,141246,3f20aa88cfcd601e2418c279d4d5383260d325ac,22,10,3,8289,,,0,"Add Nova flavor constraint for SaharaNodeGroupTemplate

Add nova.flavor custom constraint for
SaharaNodeGroupTemplate resource, to validate
the flavor's existence.

Change-Id: Ia5abf6da88eb2f701978bcc637a417706831ed0f
",git fetch https://review.opendev.org/openstack/heat refs/changes/46/141246/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_sahara_templates.py', 'heat/engine/resources/sahara_templates.py']",2,a2752843212ae83a86e3e3b1fbf6b71298d80d48,sahara-template-add-flavor-constraint, constraints=[ constraints.CustomConstraint('nova.flavor') ],,14,0
openstack%2Fnova~master~Iea29950f3991a8051f48263f43c7b9b861d9e640,openstack/nova,master,Iea29950f3991a8051f48263f43c7b9b861d9e640,libvirt: introduce new helper for getting libvirt domain,MERGED,2014-12-10 15:06:18.000000000,2014-12-23 17:13:41.000000000,2014-12-23 17:13:38.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 15:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a08de1c672a2fb078eeb1647fc8289f9859714e5', 'message': 'libvirt: introduce new helper for getting libvirt domain\n\nIntroduce a get_domain() method to obtain a libvirt domain\nfrom a Nova instance object. This slightly simplifies the\ncallers, avoiding the need for them to know that the lookup\nis done based on the name (as opposed to ID or UUID).\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Iea29950f3991a8051f48263f43c7b9b861d9e640\n'}, {'number': 2, 'created': '2014-12-10 16:19:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c9cf21fa7bbc1ccbd58f8dc4f7c4f0409c07a74c', 'message': 'libvirt: introduce new helper for getting libvirt domain\n\nIntroduce a get_domain() method to obtain a libvirt domain\nfrom a Nova instance object. This slightly simplifies the\ncallers, avoiding the need for them to know that the lookup\nis done based on the name (as opposed to ID or UUID).\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Iea29950f3991a8051f48263f43c7b9b861d9e640\n'}, {'number': 3, 'created': '2014-12-10 17:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/74dbe965de93fa0eab7c4ccd0211b5c05fe02780', 'message': 'libvirt: introduce new helper for getting libvirt domain\n\nIntroduce a get_domain() method to obtain a libvirt domain\nfrom a Nova instance object. This slightly simplifies the\ncallers, avoiding the need for them to know that the lookup\nis done based on the name (as opposed to ID or UUID).\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Iea29950f3991a8051f48263f43c7b9b861d9e640\n'}, {'number': 4, 'created': '2014-12-16 12:07:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2ea4082122fde85c140dd13f0a701eaeb31c5258', 'message': 'libvirt: introduce new helper for getting libvirt domain\n\nIntroduce a get_domain() method to obtain a libvirt domain\nfrom a Nova instance object. This slightly simplifies the\ncallers, avoiding the need for them to know that the lookup\nis done based on the name (as opposed to ID or UUID).\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Iea29950f3991a8051f48263f43c7b9b861d9e640\n'}, {'number': 5, 'created': '2014-12-17 11:08:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0329978d1c2c7a28de65fece0186e412118aec71', 'message': 'libvirt: introduce new helper for getting libvirt domain\n\nIntroduce a get_domain() method to obtain a libvirt domain\nfrom a Nova instance object. This slightly simplifies the\ncallers, avoiding the need for them to know that the lookup\nis done based on the name (as opposed to ID or UUID).\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Iea29950f3991a8051f48263f43c7b9b861d9e640\n'}, {'number': 6, 'created': '2014-12-18 14:18:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/297c0007a8bd33d586a767c6a61d0851c8b62e43', 'message': 'libvirt: introduce new helper for getting libvirt domain\n\nIntroduce a get_domain() method to obtain a libvirt domain\nfrom a Nova instance object. This slightly simplifies the\ncallers, avoiding the need for them to know that the lookup\nis done based on the name (as opposed to ID or UUID).\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Iea29950f3991a8051f48263f43c7b9b861d9e640\n'}, {'number': 7, 'created': '2014-12-19 11:33:21.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/81a336eb7a77daa59d044cecda92c46a0cb2daf6', 'message': 'libvirt: introduce new helper for getting libvirt domain\n\nIntroduce a get_domain() method to obtain a libvirt domain\nfrom a Nova instance object. This slightly simplifies the\ncallers, avoiding the need for them to know that the lookup\nis done based on the name (as opposed to ID or UUID).\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Iea29950f3991a8051f48263f43c7b9b861d9e640\n'}]",4,140720,81a336eb7a77daa59d044cecda92c46a0cb2daf6,58,10,7,1779,,,0,"libvirt: introduce new helper for getting libvirt domain

Introduce a get_domain() method to obtain a libvirt domain
from a Nova instance object. This slightly simplifies the
callers, avoiding the need for them to know that the lookup
is done based on the name (as opposed to ID or UUID).

Blueprint: libvirt-driver-class-refactor
Change-Id: Iea29950f3991a8051f48263f43c7b9b861d9e640
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/140720/7 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,a08de1c672a2fb078eeb1647fc8289f9859714e5,libvirt-driver-refactor-3," self._get_domain(instance) virt_dom = self._get_domain(instance) virt_dom = self._get_domain(instance) virt_dom = self._get_domain(instance) virt_dom = self._get_domain(instance) virt_dom = self._get_domain(instance) virt_dom = self._get_domain(instance) virt_dom = self._get_domain(instance) virt_dom = self._get_domain(instance) virt_dom = self._get_domain(instance) virt_dom = self._get_domain(instance) domain = self._get_domain(instance) virt_dom = self._get_domain(instance) virt_dom = self._get_domain(instance) dom = self._get_domain(instance) dom = self._get_domain(instance) dom = self._get_domain(instance) dom = self._get_domain(instance) dom = self._get_domain(instance) dom = self._get_domain(instance) dom = self._get_domain(instance) domain = self._get_domain(instance) virt_dom = self._get_domain(instance) virt_dom = self._get_domain(instance) virt_dom = self._get_domain(instance) virt_dom = self._get_domain(instance) def _get_domain(self, instance): """"""Retrieve libvirt domain object for an instance. :param instance: an nova.objects.Instance object Attempt to lookup the libvirt domain objects corresponding to the Nova instance, based on its name. If not found it will raise an exception.InstanceNotFound exception. On other errors, it will raise a exception.NovaException exception. :returns: a libvirt.Domain object """""" return self._lookup_by_name(instance.name) virt_dom = self._get_domain(instance) domain = self._get_domain(instance) dom = self._get_domain(instance) dom = self._get_domain(instance) domain = self._get_domain(instance) domain = self._get_domain(instance)"," self._lookup_by_name(instance.name) virt_dom = self._lookup_by_name(instance['name']) virt_dom = self._lookup_by_name(instance['name']) virt_dom = self._lookup_by_name(instance['name']) instance_name = instance.name virt_dom = self._lookup_by_name(instance_name) instance_name = instance['name'] virt_dom = self._lookup_by_name(instance_name) virt_dom = self._lookup_by_name(instance['name']) instance_name = instance.name virt_dom = self._lookup_by_name(instance_name) virt_dom = self._lookup_by_name(instance['name']) virt_dom = self._lookup_by_name(instance['name']) virt_dom = self._lookup_by_name(instance['name']) domain = self._lookup_by_name(instance['name']) virt_dom = self._lookup_by_name(instance.name) virt_dom = self._lookup_by_name(instance.name) dom = self._lookup_by_name(instance[""name""]) dom = self._lookup_by_name(instance[""name""]) dom = self._lookup_by_name(instance['name']) dom = self._lookup_by_name(instance['name']) dom = self._lookup_by_name(instance[""name""]) dom = self._lookup_by_name(instance[""name""]) dom = self._lookup_by_name(instance.name) domain = self._lookup_by_name(instance.name) virt_dom = self._lookup_by_name(instance.name) virt_dom = self._lookup_by_name(instance.name) virt_dom = self._lookup_by_name(instance_name) virt_dom = self._lookup_by_name(instance_name) virt_dom = self._lookup_by_name(instance['name']) domain = self._lookup_by_name(instance.name) dom = self._lookup_by_name(instance[""name""]) dom = self._lookup_by_name(instance.name) domain = self._lookup_by_name(instance['name']) domain = self._lookup_by_name(instance['name'])",49,35
openstack%2Fnova~master~Ibe0e5836a94295378f2208b220e452b61545c1c9,openstack/nova,master,Ibe0e5836a94295378f2208b220e452b61545c1c9,libvirt: remove pointless _get_host_uuid method,MERGED,2014-12-10 15:06:18.000000000,2014-12-23 17:13:20.000000000,2014-12-23 17:13:17.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 15:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/573b68e1ae1f3f02033e9d30e9871da7a8c3bd74', 'message': 'libvirt: remove pointless _get_host_uuid method\n\nThe _get_host_uuid method only had one caller these days, so it\nis a pretty pointless helper API.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Ibe0e5836a94295378f2208b220e452b61545c1c9\n'}, {'number': 2, 'created': '2014-12-10 16:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7d1d0cc9319b24f68c6de596f885ee2202465a6', 'message': 'libvirt: remove pointless _get_host_uuid method\n\nThe _get_host_uuid method only had one caller these days, so it\nis a pretty pointless helper API.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Ibe0e5836a94295378f2208b220e452b61545c1c9\n'}, {'number': 3, 'created': '2014-12-10 17:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/92c32971ba24d65e6a0929bb0a91d567fc7f52bd', 'message': 'libvirt: remove pointless _get_host_uuid method\n\nThe _get_host_uuid method only had one caller these days, so it\nis a pretty pointless helper API.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Ibe0e5836a94295378f2208b220e452b61545c1c9\n'}, {'number': 4, 'created': '2014-12-16 12:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a9c3bfc370bfa204f08ee56bc95cbd5dd8eb0f16', 'message': 'libvirt: remove pointless _get_host_uuid method\n\nThe _get_host_uuid method only had one caller these days, so it\nis a pretty pointless helper API.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Ibe0e5836a94295378f2208b220e452b61545c1c9\n'}, {'number': 5, 'created': '2014-12-17 11:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f7c28cdb1696b934d28de76956e908947c44b5c', 'message': 'libvirt: remove pointless _get_host_uuid method\n\nThe _get_host_uuid method only had one caller these days, so it\nis a pretty pointless helper API.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Ibe0e5836a94295378f2208b220e452b61545c1c9\n'}, {'number': 6, 'created': '2014-12-18 14:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/77999ed48ccc65ac2db20d8ad6b107a4977af7b1', 'message': 'libvirt: remove pointless _get_host_uuid method\n\nThe _get_host_uuid method only had one caller these days, so it\nis a pretty pointless helper API.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Ibe0e5836a94295378f2208b220e452b61545c1c9\n'}, {'number': 7, 'created': '2014-12-19 11:33:23.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e6a5bbd545425235ca6c182b3f1100e26637a03f', 'message': 'libvirt: remove pointless _get_host_uuid method\n\nThe _get_host_uuid method only had one caller these days, so it\nis a pretty pointless helper API.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Ibe0e5836a94295378f2208b220e452b61545c1c9\n'}]",0,140719,e6a5bbd545425235ca6c182b3f1100e26637a03f,55,13,7,1779,,,0,"libvirt: remove pointless _get_host_uuid method

The _get_host_uuid method only had one caller these days, so it
is a pretty pointless helper API.

Blueprint: libvirt-driver-class-refactor
Change-Id: Ibe0e5836a94295378f2208b220e452b61545c1c9
",git fetch https://review.opendev.org/openstack/nova refs/changes/19/140719/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,573b68e1ae1f3f02033e9d30e9871da7a8c3bd74,libvirt-driver-refactor-3," @mock.patch.object(libvirt_driver.LibvirtDriver, ""_get_host_sysinfo_serial_hardware"") ""_get_host_sysinfo_serial_hardware"") @mock.patch.object(libvirt_driver.LibvirtDriver, ""_get_host_sysinfo_serial_hardware"",) def _check_xml_and_uri(self, instance, mock_flavor, mock_serial, self.flags(sysinfo_serial=""hardware"", group=""libvirt"") mock_serial.return_value = ""cef19ce0-0ca2-11df-855d-b19fbce37686"""," # Force libvirt to return a host UUID that matches the serial in # nova.tests.unit.fakelibvirt. This is necessary because the host UUID # returned by libvirt becomes the serial whose value is checked for in # test_xml_and_uri_* below. self.useFixture(fixtures.MonkeyPatch( 'nova.virt.libvirt.driver.LibvirtDriver._get_host_uuid', lambda _: 'cef19ce0-0ca2-11df-855d-b19fbce37686')) # Prevent test suite trying to find /etc/machine-id # which isn't guaranteed to exist. Instead it will use # the host UUID from libvirt which we mock above self.flags(sysinfo_serial=""hardware"", group=""libvirt"") @mock.patch.object(libvirt_driver.LibvirtDriver, ""_get_host_uuid"") ""_get_host_uuid"") def _check_xml_and_uri(self, instance, mock_flavor,",11,20
openstack%2Fheat-specs~master~Id023bc83118ee3e53797456b075c59f8e979f4e4,openstack/heat-specs,master,Id023bc83118ee3e53797456b075c59f8e979f4e4,Apply neutron custom constraints,MERGED,2014-11-18 03:47:56.000000000,2014-12-23 17:10:26.000000000,2014-12-23 17:10:24.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 7385}, {'_account_id': 8246}]","[{'number': 1, 'created': '2014-11-18 03:47:56.000000000', 'files': ['specs/kilo/apply-neutron-custom-constraints.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/6a84501d4f52518931d203c4bea9ad9930525b75', 'message': 'Apply neutron custom constraints\n\nTo apply neutron network/subnet/port/router custom constraints\nfor resources.\n\nSpecification blueprint apply-neutron-constraints\n\nChange-Id: Id023bc83118ee3e53797456b075c59f8e979f4e4\n'}]",0,135157,6a84501d4f52518931d203c4bea9ad9930525b75,9,11,1,8289,,,0,"Apply neutron custom constraints

To apply neutron network/subnet/port/router custom constraints
for resources.

Specification blueprint apply-neutron-constraints

Change-Id: Id023bc83118ee3e53797456b075c59f8e979f4e4
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/57/135157/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/apply-neutron-custom-constraints.rst'],1,6a84501d4f52518931d203c4bea9ad9930525b75,bp/apply-neutron-constraints,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/heat/+spec/awesome-thing should be named awesome-thing.rst . Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ================================== Apply Neutron Custom Constraints ================================== https://blueprints.launchpad.net/heat/+spec/apply-neutron-constraints Apply neutron port/subnet/network/router custom constraints. Problem description =================== 1. Neutron port/subnet/router custom constraints are defined, but not to apply. 2. Neutron network custom constraint only apply to OS::Sahara::* resources, should apply to other related resources. Proposed change =============== 1. Apply neutron subnet constraint. 2. Apply neutron port constraint. 3. Apply neutron router constraint. 4. Apply neutron network constraint. Alternatives ------------ None Implementation ============== Assignee(s) ----------- Primary assignee: huangtianhua@huawei.com Milestones ---------- Target Milestone for completion: Kilo-1 Work Items ---------- 1. Apply neutron subnet constraint. 2. Apply neutron port constraint. 3. Apply neutron router constraint. 4. Apply neutron network constraint. 5. Add UT/Tempest tests for changes. Dependencies ============ None ",,74,0
openstack%2Fmurano-agent~master~Ie83194c3f604c3f4c90b14609081421a832dd83a,openstack/murano-agent,master,Ie83194c3f604c3f4c90b14609081421a832dd83a,DIB: Added systemd startup script and override of install variables,ABANDONED,2014-12-23 07:19:07.000000000,2014-12-23 17:06:27.000000000,,"[{'_account_id': 3}, {'_account_id': 7562}, {'_account_id': 7821}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-12-23 07:19:07.000000000', 'files': ['contrib/elements/murano-agent/install.d/74-murano-agent', 'contrib/elements/murano-agent/install.d/murano-agent.service'], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/80e8f02242ff8b5704db9cc83e3d1004e2c18284', 'message': 'DIB: Added systemd startup script and override of install variables\n\nChange-Id: Ie83194c3f604c3f4c90b14609081421a832dd83a\n'}]",0,143610,80e8f02242ff8b5704db9cc83e3d1004e2c18284,6,4,1,13752,,,0,"DIB: Added systemd startup script and override of install variables

Change-Id: Ie83194c3f604c3f4c90b14609081421a832dd83a
",git fetch https://review.opendev.org/openstack/murano-agent refs/changes/10/143610/1 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/elements/murano-agent/install.d/74-murano-agent', 'contrib/elements/murano-agent/install.d/murano-agent.service']",2,80e8f02242ff8b5704db9cc83e3d1004e2c18284,,[Unit] Description=OpenStack Murano Agent [Service] Type=simple ExecStart=/opt/stack/venvs/murano-agent/bin/muranoagent --config-dir /etc/murano 2>&1 | logger -t murano-agent Restart=on-failure [Install] WantedBy=multi-user.target ,,21,7
openstack%2Fproject-config~master~Id4860ce82fe82214b06b0936c0274cee2b159e22,openstack/project-config,master,Id4860ce82fe82214b06b0936c0274cee2b159e22,ec2-driver: Added gate checks,MERGED,2014-12-18 21:28:25.000000000,2014-12-23 17:01:06.000000000,2014-12-23 17:01:05.000000000,"[{'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 14222}]","[{'number': 1, 'created': '2014-12-18 21:28:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ac553db3f7dd01c6ca69a4c0358d25e6a1f9eb50', 'message': 'ec2-driver: Added gate checks\n\nChange-Id: Id4860ce82fe82214b06b0936c0274cee2b159e22\n'}, {'number': 2, 'created': '2014-12-19 16:50:19.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4bf921ce828f58621393b1069d9e3aeb3c45bf75', 'message': 'ec2-driver: Added gate checks\n\nChange-Id: Id4860ce82fe82214b06b0936c0274cee2b159e22\n'}]",0,142908,4bf921ce828f58621393b1069d9e3aeb3c45bf75,12,5,2,14219,,,0,"ec2-driver: Added gate checks

Change-Id: Id4860ce82fe82214b06b0936c0274cee2b159e22
",git fetch https://review.opendev.org/openstack/project-config refs/changes/08/142908/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/projects.yaml'],1,ac553db3f7dd01c6ca69a4c0358d25e6a1f9eb50,, name: ec2-driver node: 'bare-precise || bare-trusty' tarball-site: tarballs.openstack.org jobs: - python-jobs - project:,,8,0
openstack%2Ffuel-main~master~Iae459e7a032bb2171b22ebc0f8c7ab630d284146,openstack/fuel-main,master,Iae459e7a032bb2171b22ebc0f8c7ab630d284146,Add a System test vCenter + VLanManager HA-mode,MERGED,2014-12-23 09:29:35.000000000,2014-12-23 16:53:37.000000000,2014-12-23 16:53:34.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12139}, {'_account_id': 12141}, {'_account_id': 12415}, {'_account_id': 13306}]","[{'number': 1, 'created': '2014-12-23 09:29:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/fbbd1368759d1663c65d27859cd932c4cba834a9', 'message': 'Add a System test vCenter + VLanManager HA-mode\n\nChange-Id: Iae459e7a032bb2171b22ebc0f8c7ab630d284146\n'}, {'number': 2, 'created': '2014-12-23 09:38:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5854f073f70d4c21c58acc179502bc53532b04dc', 'message': 'Add a System test vCenter + VLanManager HA-mode\n\nChange-Id: Iae459e7a032bb2171b22ebc0f8c7ab630d284146\n'}, {'number': 3, 'created': '2014-12-23 10:39:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/85068b4141d89ce639d09857ea2d9044698e0527', 'message': 'Add a System test vCenter + VLanManager HA-mode\n\nChange-Id: Iae459e7a032bb2171b22ebc0f8c7ab630d284146\n'}, {'number': 4, 'created': '2014-12-23 11:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c0a578333ae29e12797c9dc97c6fb72c372c1029', 'message': 'Add a System test vCenter + VLanManager HA-mode\nImplements blueprint: VLAN manager support for vCenter\n\nChange-Id: Iae459e7a032bb2171b22ebc0f8c7ab630d284146\n'}, {'number': 5, 'created': '2014-12-23 11:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a65404bd7896a012353b23cb21e9a02b59db815e', 'message': 'Add a System test vCenter + VLanManager HA-mode\nImplements blueprint: ""VLAN manager support for vCenter""\n\nChange-Id: Iae459e7a032bb2171b22ebc0f8c7ab630d284146\n'}, {'number': 6, 'created': '2014-12-23 11:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8399b0b86e3fd0c26bbecb3ef4436393027b2ee0', 'message': 'Add a System test vCenter + VLanManager HA-mode\nImplements blueprint: VLAN_manager_support_for_vCenter\n\nChange-Id: Iae459e7a032bb2171b22ebc0f8c7ab630d284146\n'}, {'number': 7, 'created': '2014-12-23 11:56:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/42b71a75298ca2bfe2112f718708fbfed0e4c558', 'message': 'Add a System test vCenter + VLanManager HA-mode\nImplements blueprint: VLAN-manager-support-for-vCenter\n\nChange-Id: Iae459e7a032bb2171b22ebc0f8c7ab630d284146\n'}, {'number': 8, 'created': '2014-12-23 12:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8592763d2765ff4368d94c02607b42781e3104fd', 'message': 'Add a System test vCenter + VLanManager HA-mode\nImplements blueprint: vcenter-vlan-manager\nChange-Id: Iae459e7a032bb2171b22ebc0f8c7ab630d284146\n'}, {'number': 9, 'created': '2014-12-23 12:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7dddd8ca4fc1377b832266399a81c5221d6c6f79', 'message': 'Add a System test vCenter + VLanManager HA-mode\nhttps://blueprints.launchpad.net/fuel/+spec/vcenter-vlan-manager\nChange-Id: Iae459e7a032bb2171b22ebc0f8c7ab630d284146\n'}, {'number': 10, 'created': '2014-12-23 12:38:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/578978330c85a1cffa76b4954b877a724cebec2c', 'message': 'Add a System test vCenter + VLanManager HA-mode\n\nhttps://blueprints.launchpad.net/fuel/+spec/vcenter-vlan-manager\nChange-Id: Iae459e7a032bb2171b22ebc0f8c7ab630d284146\n'}, {'number': 11, 'created': '2014-12-23 16:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/727b2e1b2935d804132b717c8751073a3fb6c1c0', 'message': 'Add a System test vCenter + VLanManager HA-mode\n\nhttps://blueprints.launchpad.net/fuel/+spec/vcenter-vlan-manager\nImplements: blueprint vcenter-vlan-manager\nChange-Id: Iae459e7a032bb2171b22ebc0f8c7ab630d284146\n'}, {'number': 12, 'created': '2014-12-23 16:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/af1f9484dc61152d60e869e677c01149e6e3b8b8', 'message': 'Add a System test vCenter + VLanManager HA-mode\n\n\nImplements: blueprint vcenter-vlan-manager\nChange-Id: Iae459e7a032bb2171b22ebc0f8c7ab630d284146\n'}, {'number': 13, 'created': '2014-12-23 16:14:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/415e0a51a6aefe5d3e827c9555f7a4d66612f898', 'message': 'Add a System test vCenter + VLanManager HA-mode\n\n\nImplements: vcenter-vlan-manager\nChange-Id: Iae459e7a032bb2171b22ebc0f8c7ab630d284146\n'}, {'number': 14, 'created': '2014-12-23 16:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7df7c330e0fbfd33d7bcb478574f481f1d7edbb0', 'message': 'Add a System test vCenter + VLanManager HA-mode\n\n\nRelated: blueprint vcenter-vlan-manager\nChange-Id: Iae459e7a032bb2171b22ebc0f8c7ab630d284146\n'}, {'number': 15, 'created': '2014-12-23 16:48:16.000000000', 'files': ['fuelweb_test/tests/test_vcenter.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d050ca18f03cc2d7b7ac2bd18c1e8be6e32e6eec', 'message': 'Add a System test vCenter + VLanManager HA-mode\n\n- implement following testing scenario:\n  * create HA cluster\n  * add 2 controllers and 1 controller+cinder node\n  * configure Nova VLanManager\n  * deploy aforementioned nodes in one go\n  * run network test\n  * run OSTF\n\nRelated: blueprint vcenter-vlan-manager\nChange-Id: Iae459e7a032bb2171b22ebc0f8c7ab630d284146\n'}]",4,143633,d050ca18f03cc2d7b7ac2bd18c1e8be6e32e6eec,76,12,15,13306,,,0,"Add a System test vCenter + VLanManager HA-mode

- implement following testing scenario:
  * create HA cluster
  * add 2 controllers and 1 controller+cinder node
  * configure Nova VLanManager
  * deploy aforementioned nodes in one go
  * run network test
  * run OSTF

Related: blueprint vcenter-vlan-manager
Change-Id: Iae459e7a032bb2171b22ebc0f8c7ab630d284146
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/33/143633/11 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_vcenter.py'],1,fbbd1368759d1663c65d27859cd932c4cba834a9,," @test(depends_on=[SetupEnvironment.prepare_slaves_3], groups=[""vcenter_vlan_ha"", ""vcenter_vlan""]) @log_snapshot_on_error def vcenter_vlan_ha(self): """"""Deploy a cluster in HA mode with 2 controller node, 1 controller + cinder node, vCenter and VlanManager enabled. Verify that it works. Scenario: 1. Create a Simple cluster with vCenter as a hypervisor 2. Add 2 node with controller and 1 node with controller + cinder roles 3. Set Nova-Network VlanManager as a network backend 4. Deploy the cluster 5. Run network verification 6. Run OSTF """""" self.env.revert_snapshot(""ready_with_3_slaves"") # Configure a cluster. cluster_id = self.fuel_web.create_cluster( name=self.__class__.__name__, mode=settings.DEPLOYMENT_MODE_HA, settings={ 'use_vcenter': True, 'volumes_vmdk': True, 'volumes_lvm': False, 'host_ip': settings.VCENTER_IP, 'vc_user': settings.VCENTER_USERNAME, 'vc_password': settings.VCENTER_PASSWORD, 'cluster': settings.VCENTER_CLUSTERS, 'tenant': 'vcenter', 'user': 'vcenter', 'password': 'vcenter' } ) logger.info(""cluster is {0}"".format(cluster_id)) # Assign roles to nodes. self.fuel_web.update_nodes( cluster_id, {'slave-01': ['controller'], 'slave-02': ['controller'], 'slave-03': ['controller', 'cinder'], } ) # Configure network interfaces. # Public and Fixed networks are on the same interface # because Nova will use the same vSwitch for PortGroups creating # as a ESXi' management interface is located in. interfaces = { 'eth0': [""fuelweb_admin""], 'eth1': [""public"", ""fixed""], 'eth2': [""management"", ], 'eth3': [], 'eth4': [""storage""], } slave_nodes = self.fuel_web.client.list_cluster_nodes(cluster_id) for node in slave_nodes: self.fuel_web.update_node_networks(node['id'], interfaces) # Configure Nova-Network VLanManager. self.fuel_web.update_vlan_network_fixed( cluster_id, amount=8, network_size=32) # Deploy the cluster. self.fuel_web.deploy_cluster_wait(cluster_id) # Run tests. self.fuel_web.verify_network(cluster_id) self.fuel_web.run_ostf( cluster_id=cluster_id, test_sets=['ha', 'smoke', 'sanity'],)",,74,0
openstack%2Ftripleo-heat-templates~master~I30f325b1751caaef5624537e63ee27c2e418d5c8,openstack/tripleo-heat-templates,master,I30f325b1751caaef5624537e63ee27c2e418d5c8,Compute: drive NW configuration via software conf,MERGED,2014-10-23 19:23:10.000000000,2014-12-23 16:44:56.000000000,2014-12-23 16:44:56.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 6488}, {'_account_id': 7144}, {'_account_id': 7585}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-10-23 19:23:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dfb7e29705d5d966e76017d260642a9133764044', 'message': 'Drive network configuration via software config\n\nThis example extends the compute software configuration\nso that heat metadata is used to model the os-net-config\nYAML (ultimately JSON) directly. The existing\nos-net-config element already supports this format.\n\nConfiguring the physical network layer in this manner\nwould supplant the ever growing list of Heat parameters\nthat we have and is something that could be automatically\ngenerated via tuskar?\n\nIn order to prevent duplicate commands from being executed\nvia neutron-openvswitch-agent we also want to land this\nfirst: https://review.openstack.org/#/c/130573/\n\nChange-Id: I30f325b1751caaef5624537e63ee27c2e418d5c8\n'}, {'number': 2, 'created': '2014-10-23 19:30:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2cc0d9cd09725e11beed58c1baf5a4ad616e0f9c', 'message': 'Drive network configuration via software config\n\nThis example extends the compute software configuration\nso that heat metadata is used to model the os-net-config\nYAML (ultimately JSON) directly. The existing\nos-net-config element already supports this format.\n\nConfiguring the physical network layer in this manner\nwould supplant the ever growing list of Heat parameters\nthat we have and is something that could be automatically\ngenerated via tuskar?\n\nIn order to prevent duplicate commands from being executed\nvia neutron-openvswitch-agent we also want to land this\nfirst: https://review.openstack.org/#/c/130573/\n\nChange-Id: I30f325b1751caaef5624537e63ee27c2e418d5c8\n'}, {'number': 3, 'created': '2014-10-28 13:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9f3840179e3737e4077771b0aab516fd1ec9b8b4', 'message': 'Drive network configuration via software config\n\nThis example extends the compute software configuration\nso that heat metadata is used to model the os-net-config\nYAML (ultimately JSON) directly. The existing\nos-net-config element already supports this format.\n\nConfiguring the physical network layer in this manner\nwould supplant the ever growing list of Heat parameters\nthat we have and is something that could be automatically\ngenerated via tuskar?\n\nIn order to prevent duplicate commands from being executed\nvia neutron-openvswitch-agent we also want to land this\nfirst: https://review.openstack.org/#/c/130573/\n\nChange-Id: I30f325b1751caaef5624537e63ee27c2e418d5c8\n'}, {'number': 4, 'created': '2014-10-28 13:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e58d3a49cbff7260d05b20b85661b331f6167def', 'message': 'Drive network configuration via software config\n\nThis example extends the compute software configuration\nso that heat metadata is used to model the os-net-config\nYAML (ultimately JSON) directly. The existing\nos-net-config element already supports this format.\n\nConfiguring the physical network layer in this manner\nwould supplant the ever growing list of Heat parameters\nthat we have and is something that could be automatically\ngenerated (via tuskar?).\n\nIn order to prevent duplicate commands from being executed\nvia neutron-openvswitch-agent we also want to land this\nfirst: https://review.openstack.org/#/c/130573/\n\nChange-Id: I30f325b1751caaef5624537e63ee27c2e418d5c8\n'}, {'number': 5, 'created': '2014-11-14 17:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9895e8f18dae444636a1fb7c8e930a3e793cea77', 'message': 'Drive network configuration via software config\n\nThis example extends the compute software configuration\nso that heat metadata is used to model the os-net-config\nYAML (ultimately JSON) directly. The existing\nos-net-config element already supports this format.\n\nConfiguring the physical network layer in this manner\nwould supplant the ever growing list of Heat parameters\nthat we have and is something that could be automatically\ngenerated (via tuskar?).\n\nChange-Id: I30f325b1751caaef5624537e63ee27c2e418d5c8\n'}, {'number': 6, 'created': '2014-11-25 18:09:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3dc6b1b657f04204d0b08f76b1b4eb7faae54592', 'message': 'Drive network configuration via software config\n\nThis example extends the compute software configuration\nso that heat metadata is used to model the os-net-config\nYAML (ultimately JSON) directly. The existing\nos-net-config element already supports this format.\n\nConfiguring the physical network layer in this manner\nwould supplant the ever growing list of Heat parameters\nthat we have and is something that could be automatically\ngenerated (via tuskar?).\n\nChange-Id: I30f325b1751caaef5624537e63ee27c2e418d5c8\n'}, {'number': 7, 'created': '2014-12-06 00:24:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1ed858ddbc014ba7e28c5eef7a4f8d7cd104e5d7', 'message': 'Drive network configuration via software config\n\nThis example extends the compute software configuration\nso that heat metadata is used to model the os-net-config\nYAML (ultimately JSON) directly. The existing\nos-net-config element already supports this format.\n\nConfiguring the physical network layer in this manner\nwould supplant the ever growing list of Heat parameters\nthat we have and is something that could be automatically\ngenerated via tuskar.\n\nThe default is to use net-config-noop.yaml which\nwill pass no config metadata into the os-net-config\nelement which will essentially disable it in favor\nof using parameters w/ init-neutron-ovs.\n\nChange-Id: I30f325b1751caaef5624537e63ee27c2e418d5c8\n'}, {'number': 8, 'created': '2014-12-06 02:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/13bedd9f8b5ee9bb63dec8a0f91baca99e41bce8', 'message': 'Drive network configuration via software config\n\nThis example extends the compute software configuration\nso that heat metadata is used to model the os-net-config\nYAML (ultimately JSON) directly. The existing\nos-net-config element already supports this format.\n\nConfiguring the physical network layer in this manner\nwould supplant the ever growing list of Heat parameters\nthat we have and is something that could be automatically\ngenerated via tuskar.\n\nThe default is to use net-config-noop.yaml which\nwill pass no config metadata into the os-net-config\nelement which will essentially disable it in favor\nof using parameters w/ init-neutron-ovs.\n\nChange-Id: I30f325b1751caaef5624537e63ee27c2e418d5c8\n'}, {'number': 9, 'created': '2014-12-10 14:15:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c327bba2f05e939cc97231733e9958c5cb9b0a3f', 'message': 'Drive network configuration via software config\n\nThis example extends the compute software configuration\nso that heat metadata is used to model the os-net-config\nYAML (ultimately JSON) directly. The existing\nos-net-config element already supports this format.\n\nConfiguring the physical network layer in this manner\nwould supplant the ever growing list of Heat parameters\nthat we have and is something that could be automatically\ngenerated via tuskar.\n\nThe default is to use net-config-noop.yaml which\nwill pass no config metadata into the os-net-config\nelement which will essentially disable it in favor\nof using parameters w/ init-neutron-ovs.\n\nChange-Id: I30f325b1751caaef5624537e63ee27c2e418d5c8\n'}, {'number': 10, 'created': '2014-12-20 02:53:43.000000000', 'files': ['net-config-bond.yaml', 'overcloud-resource-registry.yaml', 'net-config-noop.yaml', 'compute.yaml', 'net-config-bridge.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9df1991a80724f3179475cb9d561bfadb749822e', 'message': 'Compute: drive NW configuration via software conf\n\nThis example extends the compute software configuration\nso that heat metadata is used to model the os-net-config\nYAML (ultimately JSON) directly. The existing\nos-net-config element already supports this format.\n\nConfiguring the physical network layer in this manner\nwould supplant the ever growing list of Heat parameters\nthat we have and is something that could be automatically\ngenerated via tuskar.\n\nThe default is to use net-config-noop.yaml which\nwill pass no config metadata into the os-net-config\nelement which will essentially disable it in favor\nof using parameters w/ init-neutron-ovs.\n\nChange-Id: I30f325b1751caaef5624537e63ee27c2e418d5c8\n'}]",9,130624,9df1991a80724f3179475cb9d561bfadb749822e,56,9,10,360,,,0,"Compute: drive NW configuration via software conf

This example extends the compute software configuration
so that heat metadata is used to model the os-net-config
YAML (ultimately JSON) directly. The existing
os-net-config element already supports this format.

Configuring the physical network layer in this manner
would supplant the ever growing list of Heat parameters
that we have and is something that could be automatically
generated via tuskar.

The default is to use net-config-noop.yaml which
will pass no config metadata into the os-net-config
element which will essentially disable it in favor
of using parameters w/ init-neutron-ovs.

Change-Id: I30f325b1751caaef5624537e63ee27c2e418d5c8
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/24/130624/2 && git format-patch -1 --stdout FETCH_HEAD,"['net-config-bond.yaml', 'overcloud-resource-registry.yaml', 'compute.yaml', 'net-config-bridge.yaml']",4,dfb7e29705d5d966e76017d260642a9133764044,puppet,heat_template_version: 2014-10-16 description: > Software Config to drive os-net-config for a simple bridge. resources: OsNetConfigImpl: type: OS::Heat::StructuredConfig properties: group: os-apply-config config: os_net_config: network_config: - type: ovs_bridge name: {get_input: bridge_name} use_dhcp: true # Can't do this yet: https://bugs.launchpad.net/heat/+bug/1344284 #ovs_extra: # - list_join: # - ' ' # - - br-set-external-id # - {get_input: bridge_name} # - bridge-id # - {get_input: bridge_name} members: - type: interface name: {get_input: interface_name} # force the MAC address of the bridge to this interface primary: true outputs: config_id: description: The ID of the OsNetConfigImpl resource. value: {get_resource: OsNetConfigImpl} ,,96,0
openstack%2Fsahara~master~I4c6c285775f5443818ec82dc5a4dc6eafc7c30c4,openstack/sahara,master,I4c6c285775f5443818ec82dc5a4dc6eafc7c30c4,Updated from global requirements,MERGED,2014-12-18 01:28:22.000000000,2014-12-23 16:34:42.000000000,2014-12-23 16:03:46.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-12-18 01:28:22.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/sahara/commit/d066b6af12554d273a65e44a792cd41fa580ff3b', 'message': 'Updated from global requirements\n\nChange-Id: I4c6c285775f5443818ec82dc5a4dc6eafc7c30c4\n'}]",0,142639,d066b6af12554d273a65e44a792cd41fa580ff3b,25,7,1,11131,,,0,"Updated from global requirements

Change-Id: I4c6c285775f5443818ec82dc5a4dc6eafc7c30c4
",git fetch https://review.opendev.org/openstack/sahara refs/changes/39/142639/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,d066b6af12554d273a65e44a792cd41fa580ff3b,openstack/requirements,alembic>=0.7.1,alembic>=0.6.4,1,1
openstack%2Fopenstack-manuals~stable%2Fjuno~I036ae43b73c8ca469e04e8090e197d57a7a5f5d0,openstack/openstack-manuals,stable/juno,I036ae43b73c8ca469e04e8090e197d57a7a5f5d0,Fix additional issue with _member_ role creation,MERGED,2014-12-23 15:25:35.000000000,2014-12-23 16:32:11.000000000,2014-12-23 16:32:11.000000000,"[{'_account_id': 3}, {'_account_id': 6772}, {'_account_id': 9382}]","[{'number': 1, 'created': '2014-12-23 15:25:35.000000000', 'files': ['doc/install-guide/section_keystone-users.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cdee7ddb42b1a7b6e42f51ce95a7f6a7b30a5e51', 'message': ""Fix additional issue with _member_ role creation\n\nI removed the '--tenant' option from the admin user/tenant\ncreation step because the latter needs only the admin role.\nAlso, I provided an explanation about automatic assignment\nand/or creation of the _member_ role.\n\nChange-Id: I036ae43b73c8ca469e04e8090e197d57a7a5f5d0\nCloses-Bug: #1403136\nbackport: juno\n(cherry picked from commit 549be4ba1d84ba749ea79c7a0d1e8953ef9d4cfd)\n""}]",0,143682,cdee7ddb42b1a7b6e42f51ce95a7f6a7b30a5e51,7,3,1,9515,,,0,"Fix additional issue with _member_ role creation

I removed the '--tenant' option from the admin user/tenant
creation step because the latter needs only the admin role.
Also, I provided an explanation about automatic assignment
and/or creation of the _member_ role.

Change-Id: I036ae43b73c8ca469e04e8090e197d57a7a5f5d0
Closes-Bug: #1403136
backport: juno
(cherry picked from commit 549be4ba1d84ba749ea79c7a0d1e8953ef9d4cfd)
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/82/143682/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_keystone-users.xml'],1,cdee7ddb42b1a7b6e42f51ce95a7f6a7b30a5e51,juno/backport/143519, <para>Create the <literal>admin</literal> user:</para> <screen><prompt>$</prompt> <userinput>keystone user-create --name admin --pass <replaceable>ADMIN_PASS</replaceable> --email <replaceable>EMAIL_ADDRESS</replaceable></userinput> <note> <para>Using the <literal>--tenant</literal> option automatically assigns the <literal>_member_</literal> role to a user. This option will also create the <literal>_member_</literal> role if it does not exist.</para> </note>, <para>Create the <literal>admin</literal> user under the <literal>admin</literal> tenant:</para> <screen><prompt>$</prompt> <userinput>keystone user-create --name admin --tenant admin --pass <replaceable>ADMIN_PASS</replaceable> --email <replaceable>EMAIL_ADDRESS</replaceable></userinput>| tenantId | 6f4c1e4cbfef4d5a8a1345882fbca110 |,8,4
openstack%2Ffuel-ostf~master~I95a226db48dda30abd86bdff0204a3bed68d17ef,openstack/fuel-ostf,master,I95a226db48dda30abd86bdff0204a3bed68d17ef,Update OSTF Murano platform tests,MERGED,2014-12-09 14:47:12.000000000,2014-12-23 16:29:35.000000000,2014-12-23 16:29:35.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7126}, {'_account_id': 7225}, {'_account_id': 7227}, {'_account_id': 7428}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 8592}, {'_account_id': 8971}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-12-09 14:47:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/a5c64df07581d3e4007b63c79f17b079d93241a1', 'message': 'Added Murano documentation to OSTF\n\nThis pacth update documentation for OSTF tests that using Murano.\nDocumentation contains steps to download/create image with\nMurano-agent and marking this image with Murano tag.\n\nChange-Id: I95a226db48dda30abd86bdff0204a3bed68d17ef\nCloses-Bug: #1395666\n'}, {'number': 2, 'created': '2014-12-10 15:57:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/51a8be94768471abd0f3eb1916590204d90e030b', 'message': 'Added Murano documentation to OSTF\n\nThis pacth update documentation for OSTF tests that using Murano.\nDocumentation contains steps to download/create image with\nMurano-agent and marking this image with Murano tag.\n\nAlso patch contains update for error message, when OSTF fails\nof non-existing Murano-image.\n\nChange-Id: I95a226db48dda30abd86bdff0204a3bed68d17ef\nCloses-Bug: #1395666\n'}, {'number': 3, 'created': '2014-12-10 16:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/f10a878247f5dd2afb24a17c8eff81a98403f8cd', 'message': 'Added Murano documentation to OSTF\n\nThis pacth update documentation for OSTF tests that using Murano.\nDocumentation contains steps to download/create image with\nMurano-agent and marking this image with Murano tag.\n\nAlso patch contains update for error message, when OSTF fails\nof non-existing Murano-image.\n\nChange-Id: I95a226db48dda30abd86bdff0204a3bed68d17ef\nCloses-Bug: #1395666\n'}, {'number': 4, 'created': '2014-12-10 17:44:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/0c2ab6cb18093e77bd651a0375a9f52cc69b8a78', 'message': 'Added Murano documentation to OSTF\n\nThis pacth update documentation for OSTF tests that using Murano.\nDocumentation contains steps to download/create image with\nMurano-agent and marking this image with Murano tag.\n\nAlso patch contains update for error message, when OSTF fails\nof non-existing Murano-image.\n\nChange-Id: I95a226db48dda30abd86bdff0204a3bed68d17ef\nCloses-Bug: #1395666\n'}, {'number': 5, 'created': '2014-12-11 10:57:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/a1b7ed6d21d569f1c1add508a1c874cce07179d4', 'message': 'Added Murano documentation to OSTF\n\nThis pacth update documentation for OSTF tests that using Murano.\nDocumentation contains steps to download/create image with\nMurano-agent and marking this image with Murano tag.\n\nAlso patch contains update for error message, when OSTF fails\nof non-existing Murano-image.\n\nChange-Id: I95a226db48dda30abd86bdff0204a3bed68d17ef\nCloses-Bug: #1395666\n'}, {'number': 6, 'created': '2014-12-19 12:49:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/01f5d92059fdd391641384f46fcee606a25fd048', 'message': 'Added Murano documentation to OSTF\n\nThis pacth update documentation for OSTF tests that using Murano.\nDocumentation contains steps to download/create image with\nMurano-agent and marking this image with Murano tag.\n\nAlso patch contains update for error message, when OSTF fails\nof non-existing Murano-image.\n\nChange-Id: I95a226db48dda30abd86bdff0204a3bed68d17ef\nCloses-Bug: #1395666\n'}, {'number': 7, 'created': '2014-12-19 13:09:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/c2c29202e68bfd78a6933ba0ec55c93a9eae0acc', 'message': 'Update OSTF Murano platform tests\n\nAdded link to documentation, when OSTF fails\n\nChange-Id: I95a226db48dda30abd86bdff0204a3bed68d17ef\nCloses-Bug: #1395666\n'}, {'number': 8, 'created': '2014-12-22 10:46:57.000000000', 'files': ['fuel_health/tests/platform_tests/test_platform_murano_linux.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/fa2a92aafdd6de38c6f7b71c51a0ecd6c612d440', 'message': 'Update OSTF Murano platform tests\n\nAdded link to documentation, when OSTF fails\n\nChange-Id: I95a226db48dda30abd86bdff0204a3bed68d17ef\nCloses-Bug: #1395666\n'}]",4,140349,fa2a92aafdd6de38c6f7b71c51a0ecd6c612d440,49,11,8,13962,,,0,"Update OSTF Murano platform tests

Added link to documentation, when OSTF fails

Change-Id: I95a226db48dda30abd86bdff0204a3bed68d17ef
Closes-Bug: #1395666
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/49/140349/8 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,a5c64df07581d3e4007b63c79f17b079d93241a1,bug/1395666,"OSTF with Murano ---------------- If you want to test Murano with OSTF, you need to prepare your environment. To run tests you will need an image, which contains murano-agent. You can download the image here: http://murano-files.mirantis.com/ubuntu_14_04-murano-agent_stable_juno.qcow2 Or you can create your own using this diskimage-builder: git clone https://git.openstack.org/openstack/diskimage-builder.git git clone https://git.openstack.org/stackforge/murano-agent.git export ELEMENTS_PATH=murano-agent/contrib/elements diskimage-builder/bin/disk-image-create vm ubuntu murano-agent -o ubuntu-murano-agent.qcow2 After these steps, you will need import your image into your environment via glance or using Horizon Dashboard. If you want to use glance from console: 1. SCP your image to node, where located OS controller. 2. SSH to node. 3. Use these commands: . openrc glance image-create --disk-format qcow2 --container-format bare --name ubuntu-murano < ubuntu-murano.qcow2 If you want to use Horizon Dashboard: 1. Login into Horizon Dashboard 2. Navigate to Project-Compute-Images 3. Click ""Create image"" 4. Specify parameters and select image source. Then you should navigate to Murano-Manage-Images and mark your uploaded image with murano tag. Now, you can start OSTF tests that using Murano component.",,37,0
openstack%2Ffuel-main~master~If0a7dfa3388f42928959c365a0175ac6270516c8,openstack/fuel-main,master,If0a7dfa3388f42928959c365a0175ac6270516c8,Custom master manifests - add deploy possibility,MERGED,2014-12-22 13:39:46.000000000,2014-12-23 16:28:12.000000000,2014-12-23 16:28:11.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7195}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 12867}]","[{'number': 1, 'created': '2014-12-22 13:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/80b6bd3df38e16e9436d91335f5bd788bbd5215a', 'message': 'Add deploy step on test master custom manifests\n\nAfter setup master with custrom manifests\ndeploy simple cluster.\n\nChange-Id: If0a7dfa3388f42928959c365a0175ac6270516c8\nblueprint: fuel-master-ci-tests\n'}, {'number': 2, 'created': '2014-12-22 17:47:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5981aeb87119ade06ca8a461a975f9e90deeeac9', 'message': 'Add deploy step on test master custom manifests\n\nAfter setup master with custom manifests\ndeploy simple cluster.\n\nChange-Id: If0a7dfa3388f42928959c365a0175ac6270516c8\nblueprint: fuel-master-ci-tests\n'}, {'number': 3, 'created': '2014-12-23 11:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/691711cc1fb255501658cddfb55df1e84c119e64', 'message': 'Add deploy step on test master custom manifests\n\nAfter setup master with custom manifests\ndeploy simple cluster.\n\nChange-Id: If0a7dfa3388f42928959c365a0175ac6270516c8\nblueprint: fuel-master-ci-tests\n'}, {'number': 4, 'created': '2014-12-23 12:29:29.000000000', 'files': ['fuelweb_test/helpers/decorators.py', 'fuelweb_test/models/environment.py', 'fuelweb_test/tests/test_admin_node.py', 'fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/54ba60dca1c62618336cf6facf497d88d12132f1', 'message': 'Custom master manifests - add deploy possibility\n\nAdd possibility to deploy any test\nwith custom master manifests\n\nChange-Id: If0a7dfa3388f42928959c365a0175ac6270516c8\nblueprint: fuel-master-ci-tests\n'}]",6,143441,54ba60dca1c62618336cf6facf497d88d12132f1,29,9,4,9439,,,0,"Custom master manifests - add deploy possibility

Add possibility to deploy any test
with custom master manifests

Change-Id: If0a7dfa3388f42928959c365a0175ac6270516c8
blueprint: fuel-master-ci-tests
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/41/143441/4 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/helpers/decorators.py', 'fuelweb_test/tests/test_simple.py']",2,80b6bd3df38e16e9436d91335f5bd788bbd5215a,bp/fuel-master-ci-tests,"from fuelweb_test.tests.test_admin_node import TestAdminNodeCustomManifests @test(groups=[""deploy_with_custom_master_manifests""]) class SimpleEnvCustomMasterManifests(TestBasic): @test(depends_on=[TestAdminNodeCustomManifests. setup_with_custom_manifests], groups=[""deploy_simple_master_custom_manifests""]) @log_snapshot_on_error def deploy_simple_master_custom_manifests(self): """"""Deploy environment with custom master manifests Scenario: 1. Setup master with custom manifests 2. Deploy environment 3. Run network verification 4. Run OSTF """""" self.env.bootstrap_nodes(self.env.nodes().slaves[:3]) cluster_id = self.fuel_web.create_cluster( name=self.__class__.__name__, mode=DEPLOYMENT_MODE_SIMPLE ) self.fuel_web.update_nodes( cluster_id, { 'slave-01': ['controller'], 'slave-02': ['compute'], 'slave-03': ['cinder'] } ) self.fuel_web.deploy_cluster_wait(cluster_id) os_conn = os_actions.OpenStackActions( self.fuel_web.get_nailgun_node_by_name('slave-01')['ip']) self.fuel_web.assert_cluster_ready( os_conn, smiles_count=6, networks_count=1, timeout=300) self.fuel_web.verify_network(cluster_id) self.fuel_web.run_ostf(cluster_id=cluster_id)",,47,1
openstack%2Ffuel-main~master~I31ba48b62dc6114e290d7cce7acfbeeb9aa2e93a,openstack/fuel-main,master,I31ba48b62dc6114e290d7cce7acfbeeb9aa2e93a,Update Heat system tests,MERGED,2014-12-19 13:44:01.000000000,2014-12-23 16:27:16.000000000,2014-12-23 16:27:16.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7126}, {'_account_id': 7227}, {'_account_id': 7428}, {'_account_id': 8592}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 13962}]","[{'number': 1, 'created': '2014-12-19 13:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1235c96ad32cf80b60b3f66c606dea528bc0dd9a', 'message': ""Update Heat system tests\n\n- Added Ceilometer install option to enviroments\n(test autoscaling now needed Ceilometer)\n- Remove import of Heat image, now tests use TestVM image\n- Added running of new test 'test_update'\n\nCloses-Bug: #1404233\nChange-Id: I31ba48b62dc6114e290d7cce7acfbeeb9aa2e93a\n""}, {'number': 2, 'created': '2014-12-19 13:51:27.000000000', 'files': ['fuelweb_test/tests/test_services.py', 'fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0f8e53d2ac9401113a24e40d3bc53de1dbf9c8c7', 'message': ""Update Heat system tests\n\n- Added Ceilometer install option to enviroments\n(test autoscaling now needed Ceilometer)\n- Remove import of Heat image, now tests use TestVM image\n- Added running of new test 'test_update'\n\nCloses-Bug: #1404233\nChange-Id: I31ba48b62dc6114e290d7cce7acfbeeb9aa2e93a\n""}]",0,143086,0f8e53d2ac9401113a24e40d3bc53de1dbf9c8c7,16,9,2,8592,,,0,"Update Heat system tests

- Added Ceilometer install option to enviroments
(test autoscaling now needed Ceilometer)
- Remove import of Heat image, now tests use TestVM image
- Added running of new test 'test_update'

Closes-Bug: #1404233
Change-Id: I31ba48b62dc6114e290d7cce7acfbeeb9aa2e93a
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/86/143086/2 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/test_services.py', 'fuelweb_test/settings.py']",2,1235c96ad32cf80b60b3f66c606dea528bc0dd9a,,,"SERVTEST_HEAT_SERVER_URL = (""http://fedorapeople.org/groups/"" ""heat/prebuilt-jeos-images/"") SERVTEST_HEAT_IMAGE = ""F17-x86_64-cfntools.qcow2"" SERVTEST_HEAT_IMAGE_NAME = 'F17-x86_64-cfntools' SERVTEST_HEAT_IMAGE_MD5 = 'afab0f79bac770d61d24b4d0560b5f70' SERVTEST_HEAT_IMAGE_META = { 'heat_image_info': '{""type"": ""fedora"", ""title"": ""heat""}'} ",41,76
openstack%2Ffuel-ostf~master~If4e245e1b5d4dea96ded60dc18294cc3fcffac62,openstack/fuel-ostf,master,If4e245e1b5d4dea96ded60dc18294cc3fcffac62,Added OSTF tests for WordPress,MERGED,2014-12-08 10:55:25.000000000,2014-12-23 16:25:30.000000000,2014-12-23 16:25:29.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7126}, {'_account_id': 7227}, {'_account_id': 7428}, {'_account_id': 8592}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 13962}]","[{'number': 1, 'created': '2014-12-08 10:55:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/22741ea2fcee80e10af7c5628875afb19910fd72', 'message': 'Added OSTF tests for WordPress\n\nIn MOS 6.0 we will have new Murano application. This patch provide\na test for this application.\n\nChange-Id: If4e245e1b5d4dea96ded60dc18294cc3fcffac62\n'}, {'number': 2, 'created': '2014-12-08 10:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/df1c1dc119cfccd616a37236930ee86b82303bbc', 'message': 'Added OSTF tests for WordPress\n\nIn MOS 6.0 we will have new Murano application. This patch provide\na test for this application.\n\nChange-Id: If4e245e1b5d4dea96ded60dc18294cc3fcffac62\n'}, {'number': 3, 'created': '2014-12-08 11:05:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/dc4fcf1d274bebf759a51a64eabc6b6980c6224d', 'message': 'Added OSTF tests for WordPress\n\nIn MOS 6.0 we will have new Murano application. This patch provide\na test for this application.\n\nChange-Id: If4e245e1b5d4dea96ded60dc18294cc3fcffac62\n'}, {'number': 4, 'created': '2014-12-08 11:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/d9f97df82a3578abdb0328954d32f06a453e9b9d', 'message': 'Added OSTF tests for WordPress\n\nIn MOS 6.0 we will have new Murano application. This patch provide\na test for this application.\n\nChange-Id: If4e245e1b5d4dea96ded60dc18294cc3fcffac62\n'}, {'number': 5, 'created': '2014-12-08 11:46:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/1004bebe3289a1cb7a3501e1b014b2b2ba37cfe4', 'message': 'Added OSTF tests for WordPress\n\nIn MOS 6.0 we will have new Murano application. This patch provide\na test for this application.\n\nChange-Id: If4e245e1b5d4dea96ded60dc18294cc3fcffac62\n'}, {'number': 6, 'created': '2014-12-08 12:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/e555a06751ea8f7e650fcfc9b5ec08e41352ea69', 'message': 'Added OSTF tests for WordPress\n\nIn MOS 6.0 we will have new Murano application. This patch provide\na test for this application.\n\nChange-Id: If4e245e1b5d4dea96ded60dc18294cc3fcffac62\n'}, {'number': 7, 'created': '2014-12-08 12:11:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/cd770d15e0baaa3e6301c0c4ca046ee0d621fe23', 'message': 'Added OSTF tests for WordPress\n\nIn MOS 6.0 we will have new Murano application. This patch provide\na test for this application.\n\nChange-Id: If4e245e1b5d4dea96ded60dc18294cc3fcffac62\n'}, {'number': 8, 'created': '2014-12-10 15:32:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/3727d28e18a41ed77289d088758865a048a9f455', 'message': 'Added OSTF tests for WordPress\n\nIn MOS 6.0 we will have new Murano application. This patch provide\na test for this application.\n\nChange-Id: If4e245e1b5d4dea96ded60dc18294cc3fcffac62\nCloses-Bug: #1401151\n'}, {'number': 9, 'created': '2014-12-16 10:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/8a3453dcfa5375537e10d5af72e5550633364bf0', 'message': 'Added OSTF tests for WordPress\n\nIn MOS 6.0 we will have new Murano application. This patch provide\na test for this application.\n\nChange-Id: If4e245e1b5d4dea96ded60dc18294cc3fcffac62\nCloses-Bug: #1401151\n'}, {'number': 10, 'created': '2014-12-16 10:57:01.000000000', 'files': ['fuel_health/tests/platform_tests/test_platform_murano_linux.py', 'fuel_health/murano.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/59141e7943710ac69648598d45b348cfaa9d0f7e', 'message': 'Added OSTF tests for WordPress\n\nIn MOS 6.0 we will have new Murano application. This patch provide\na test for this application.\n\nChange-Id: If4e245e1b5d4dea96ded60dc18294cc3fcffac62\nCloses-Bug: #1401151\n'}]",4,139968,59141e7943710ac69648598d45b348cfaa9d0f7e,55,9,10,13962,,,0,"Added OSTF tests for WordPress

In MOS 6.0 we will have new Murano application. This patch provide
a test for this application.

Change-Id: If4e245e1b5d4dea96ded60dc18294cc3fcffac62
Closes-Bug: #1401151
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/68/139968/4 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_health/tests/platform_tests/test_platform_murano_linux.py', 'fuel_health/murano.py']",2,22741ea2fcee80e10af7c5628875afb19910fd72,bug/1401151,"# not use this file except in compliance with the License. You may obtaindis def check_route(self, environment, route): check_ip = environment['services'][0]['instance']['floatingIpAddress'] resp = requests.get('http://' + '%s/%s' % (check_ip, str(route))) self.assertEqual(200, resp.status_code)",# not use this file except in compliance with the License. You may obtain,139,1
openstack%2Fkeystone~master~I17756fb5f27cb6a950c647590e2a9e0a83c336ca,openstack/keystone,master,I17756fb5f27cb6a950c647590e2a9e0a83c336ca,Memcache connection pool excess check,MERGED,2014-12-10 13:42:28.000000000,2014-12-23 16:03:02.000000000,2014-12-23 16:03:00.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 13055}]","[{'number': 1, 'created': '2014-12-10 13:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4d284c1f8c4196160ed32774db936d93edad21f1', 'message': 'Memcache connection pool excess check\n\nWhen memcache pool depletes exceeding connections are created.\nThen they are pushed back the to pool via a blocking operation ``put``.\nAs a result thread, attempting to release connection, blocks.\n\nThis patch adds a check preventing pushung the excess back to the pool,\nclosing released connection instead.\n\nChange-Id: I17756fb5f27cb6a950c647590e2a9e0a83c336ca\nCloses-Bug: #1401108\nCloses-Bug: #1400326\n'}, {'number': 2, 'created': '2014-12-10 13:44:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/895be281530d3745265c7cb25f07e85597caf350', 'message': 'Memcache connection pool excess check\n\nWhen memcache pool depletes exceeding connections are created.\nThen they are pushed back the to pool via a blocking operation ``put``.\nAs a result thread, attempting to release connection, blocks.\n\nThis patch adds a check preventing pushung the excess back to the pool,\nclosing released connection instead.\n\nChange-Id: I17756fb5f27cb6a950c647590e2a9e0a83c336ca\nCloses-Bug: #1401108\nCloses-Bug: #1400326\n'}, {'number': 3, 'created': '2014-12-10 15:04:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/461a18d32e5c23a9b31e3fc18ad8c0f67a8cec7a', 'message': 'Memcache connection pool excess check\n\nWhen memcache pool depletes exceeding connections are created.\nThen they are pushed back the to pool via a blocking operation ``put``.\nAs a result thread, attempting to release connection, blocks.\n\nThis patch adds a check preventing pushung the excess back to the pool,\nclosing released connection instead.\n\nChange-Id: I17756fb5f27cb6a950c647590e2a9e0a83c336ca\nCloses-Bug: #1401108\nCloses-Bug: #1400326\n'}, {'number': 4, 'created': '2014-12-18 15:00:18.000000000', 'files': ['keystone/common/cache/_memcache_pool.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/66b37af4728d6eab29632c95e3d7e406990359fd', 'message': 'Memcache connection pool excess check\n\nWhen memcache pool depletes exceeding connections are created.\nThen they are pushed back the to pool via a blocking operation ``put``.\nAs a result thread, attempting to release connection, blocks.\n\nThis patch adds a check preventing pushung the excess back to the pool,\nclosing released connection instead.\n\nChange-Id: I17756fb5f27cb6a950c647590e2a9e0a83c336ca\nCloses-Bug: #1401108\nCloses-Bug: #1400326\n'}]",0,140681,66b37af4728d6eab29632c95e3d7e406990359fd,26,4,4,13055,,,0,"Memcache connection pool excess check

When memcache pool depletes exceeding connections are created.
Then they are pushed back the to pool via a blocking operation ``put``.
As a result thread, attempting to release connection, blocks.

This patch adds a check preventing pushung the excess back to the pool,
closing released connection instead.

Change-Id: I17756fb5f27cb6a950c647590e2a9e0a83c336ca
Closes-Bug: #1401108
Closes-Bug: #1400326
",git fetch https://review.opendev.org/openstack/keystone refs/changes/81/140681/4 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/cache/_memcache_pool.py'],1,4d284c1f8c4196160ed32774db936d93edad21f1,bug/1401108," if self.maxsize: return self.maxsize - self._acquired else: # A value indicating there is always a free connection # if maxsize is None or 0 return 1 def _drop_expired_connections(self): def put(self, conn): self._drop_expired_connections() try: super(ConnectionPool, self).put(conn, block=False) except queue.Full: self._debug_logger('Reaping exceeding connection %s', id(conn)) self._destroy_connection(conn) "," return self.maxsize - self._acquired def _drop_expired_connections(self, conn): self._drop_expired_connections(conn)",15,3
openstack%2Fceilometer~master~Iac63815b13a81554e69d3fe2933615a6c3789419,openstack/ceilometer,master,Iac63815b13a81554e69d3fe2933615a6c3789419,Manual update from global requirements,MERGED,2014-12-23 01:15:09.000000000,2014-12-23 15:53:39.000000000,2014-12-23 15:53:38.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 10987}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-12-23 01:15:09.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9b220aaa6f79c12f923a3260c64bfb14f6ae25a9', 'message': 'Manual update from global requirements\n\nThe automated update seems to have been lost or fallen behind.\n\nChange-Id: Iac63815b13a81554e69d3fe2933615a6c3789419\n'}]",0,143580,9b220aaa6f79c12f923a3260c64bfb14f6ae25a9,15,5,1,11564,,,0,"Manual update from global requirements

The automated update seems to have been lost or fallen behind.

Change-Id: Iac63815b13a81554e69d3fe2933615a6c3789419
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/80/143580/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,9b220aaa6f79c12f923a3260c64bfb14f6ae25a9,manual-requirements,"alembic>=0.7.1oslo.utils>=1.1.0 # Apache-2.0python-glanceclient>=0.15.0pytz>=2013.6SQLAlchemy>=0.9.7,<=0.9.99","alembic>=0.6.4oslo.utils>=1.0.0 # Apache-2.0python-glanceclient>=0.14.0pytzSQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99",12,12
openstack%2Fpbr~master~I8eee890e579c40b00a4a9b504584c307772f9cbf,openstack/pbr,master,I8eee890e579c40b00a4a9b504584c307772f9cbf,Merge tag '0.10.6' into master,MERGED,2014-12-21 22:24:26.000000000,2014-12-23 15:53:31.000000000,2014-12-23 15:53:31.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-21 22:24:26.000000000', 'files': ['tools/integration.sh', 'pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/a4228942c8d117c622d0b71aaed6335fcd2848eb', 'message': ""Merge tag '0.10.6' into master\n\ntag 0.10.6\n\nChange-Id: I8eee890e579c40b00a4a9b504584c307772f9cbf\n""}]",0,143328,a4228942c8d117c622d0b71aaed6335fcd2848eb,11,4,1,5263,,,0,"Merge tag '0.10.6' into master

tag 0.10.6

Change-Id: I8eee890e579c40b00a4a9b504584c307772f9cbf
",git fetch https://review.opendev.org/openstack/pbr refs/changes/28/143328/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/integration.sh', 'pbr/packaging.py']",2,a4228942c8d117c622d0b71aaed6335fcd2848eb,setuptools-8,,"<<<<<<< HEAD (316121 Merge tag '0.10.5' into master)======= if pre_version: try: return git._run_git_command( ['describe', '--exact-match'], git_dir, throw_on_error=True).replace('-', '.') except Exception: return ""%s.dev%s"" % (pre_version, _get_revno_and_last_tag(git_dir)[0]) else: # git describe always is going to return one of three things # - a short-sha if there are no tags # - a tag, if there's one on the current revision # - a string of the form $last_tag-$revs_since_last_tag-g$short_sha raw_version = git._run_git_command(['describe', '--always'], git_dir) # First, if there are no -'s or .'s, then it's just a short sha. # Create a synthetic version for it. if '-' not in raw_version and '.' not in raw_version: return ""0.0.0.post%s"" % _get_revno_and_last_tag(git_dir) # Now, we want to strip the short-sha prefix stripped_version = raw_version.split('-g')[0] # Finally, if we convert - to .post, which will turn the remaining # - which separates the version from the revcount into a PEP440 # post string return stripped_version.replace('-', '.post') >>>>>>> BRANCH (cd7da2 Integration test PBR commits)",0,37
openstack%2Fpbr~master~I2c7c4ffdf853c352101b804447d7e4ba69f74ee0,openstack/pbr,master,I2c7c4ffdf853c352101b804447d7e4ba69f74ee0,Merge tag '0.10.5' into master,MERGED,2014-12-21 22:24:26.000000000,2014-12-23 15:53:29.000000000,2014-12-23 15:53:29.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 5638}, {'_account_id': 7369}]","[{'number': 1, 'created': '2014-12-21 22:24:26.000000000', 'files': ['pbr/tests/test_setup.py', 'pbr/packaging.py', 'pbr/tests/test_packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/316121b4363eb7b3dc697e9facf4545682f4a48d', 'message': ""Merge tag '0.10.5' into master\n\ntag 0.10.5\n\nChange-Id: I2c7c4ffdf853c352101b804447d7e4ba69f74ee0\n""}]",0,143327,316121b4363eb7b3dc697e9facf4545682f4a48d,12,5,1,5263,,,0,"Merge tag '0.10.5' into master

tag 0.10.5

Change-Id: I2c7c4ffdf853c352101b804447d7e4ba69f74ee0
",git fetch https://review.opendev.org/openstack/pbr refs/changes/27/143327/1 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/tests/test_setup.py', 'pbr/packaging.py', 'pbr/tests/test_packaging.py']",3,316121b4363eb7b3dc697e9facf4545682f4a48d,setuptools-8,,"<<<<<<< HEAD (a89b90 Merge tag '0.10.4' into master)======= with mock.patch.object(git, '_run_shell_command') as _command: >>>>>>> BRANCH (0acee4 Move write_pbr_json to avoid issues with nose)<<<<<<< HEAD (a89b90 Merge tag '0.10.4' into master)======= with mock.patch.object(git, '_run_shell_command') as _command: >>>>>>> BRANCH (0acee4 Move write_pbr_json to avoid issues with nose)",0,87
openstack%2Fpbr~master~I048cd25bf21eacd39883801ab79c4b91832fb395,openstack/pbr,master,I048cd25bf21eacd39883801ab79c4b91832fb395,Merge tag '0.10.4' into master,MERGED,2014-12-21 22:24:26.000000000,2014-12-23 15:53:25.000000000,2014-12-23 15:53:24.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 5638}, {'_account_id': 7369}]","[{'number': 1, 'created': '2014-12-21 22:24:26.000000000', 'files': ['pbr/packaging.py', 'pbr/builddoc.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/pbr/commit/a89b90e37ebd2132cb8947f974f535ada824516b', 'message': ""Merge tag '0.10.4' into master\n\nReleasing 0.10.4\n\nChange-Id: I048cd25bf21eacd39883801ab79c4b91832fb395\n""}]",0,143326,a89b90e37ebd2132cb8947f974f535ada824516b,12,5,1,5263,,,0,"Merge tag '0.10.4' into master

Releasing 0.10.4

Change-Id: I048cd25bf21eacd39883801ab79c4b91832fb395
",git fetch https://review.opendev.org/openstack/pbr refs/changes/26/143326/1 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/packaging.py', 'pbr/builddoc.py', 'tox.ini']",3,a89b90e37ebd2132cb8947f974f535ada824516b,setuptools-8,,"<<<<<<< HEAD (c29a1c Merge tag '0.10.3' into master)======= envlist = py33,py34,py26,py27,pypy,pep8 >>>>>>> BRANCH (e7d282 Properly check for git before getting git dir)<<<<<<< HEAD (c29a1c Merge tag '0.10.3' into master) ======= # NOTE(dhellmann): List ourself as a dependency first to ensure that # the source being tested is used to install all of the other # dependencies that want to use pbr for installation. >>>>>>> BRANCH (e7d282 Properly check for git before getting git dir)",0,395
openstack%2Fironic~master~I81c5deaa4c578c29c32788bd248f9db7166975e3,openstack/ironic,master,I81c5deaa4c578c29c32788bd248f9db7166975e3,Rename parameters for ilo driver,ABANDONED,2014-11-25 11:32:47.000000000,2014-12-23 15:52:03.000000000,,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 9315}, {'_account_id': 12081}, {'_account_id': 13362}]","[{'number': 1, 'created': '2014-11-25 11:32:47.000000000', 'files': ['ironic/tests/drivers/ilo/test_common.py', 'ironic/tests/conductor/test_manager.py', 'ironic/drivers/modules/ilo/common.py', 'ironic/drivers/modules/ilo/deploy.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/1a9e315d0ffaf033a037805b18e9c3753a437349', 'message': ""Rename parameters for ilo driver\n\nDrivers parameters names should use prefixes for avoiding conflicts.\nThese parameters were renamed for ilo driver:\n  'client_port' -> 'ilo_client_port'\n  'client_timeout' -> 'ilo_client_timeout'\n  'console_port' -> 'ilo_console_port'\n\nDocImpact\nChange-Id: I81c5deaa4c578c29c32788bd248f9db7166975e3\n""}]",0,137022,1a9e315d0ffaf033a037805b18e9c3753a437349,12,8,1,7711,,,0,"Rename parameters for ilo driver

Drivers parameters names should use prefixes for avoiding conflicts.
These parameters were renamed for ilo driver:
  'client_port' -> 'ilo_client_port'
  'client_timeout' -> 'ilo_client_timeout'
  'console_port' -> 'ilo_console_port'

DocImpact
Change-Id: I81c5deaa4c578c29c32788bd248f9db7166975e3
",git fetch https://review.opendev.org/openstack/ironic refs/changes/22/137022/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/conductor/test_manager.py', 'ironic/tests/drivers/ilo/test_common.py', 'ironic/drivers/modules/ilo/common.py', 'ironic/drivers/modules/ilo/deploy.py']",4,1a9e315d0ffaf033a037805b18e9c3753a437349,ilo-parameters-names," if 'ilo_console_port' in info: info['ipmi_terminal_port'] = info['ilo_console_port'] if 'ilo_console_port' not in driver_info: ""Missing 'ilo_console_port' parameter in node's driver_info.""))"," if 'console_port' in info: info['ipmi_terminal_port'] = info['console_port'] if 'console_port' not in driver_info: ""Missing 'console_port' parameter in node's driver_info.""))",55,63
openstack%2Fpbr~master~If8dd160585172a09064413305123eb2d1079d5b6,openstack/pbr,master,If8dd160585172a09064413305123eb2d1079d5b6,Merge tag '0.10.3' into master,MERGED,2014-12-21 22:24:26.000000000,2014-12-23 15:31:23.000000000,2014-12-23 15:31:22.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 5638}, {'_account_id': 7369}]","[{'number': 1, 'created': '2014-12-21 22:24:26.000000000', 'files': ['pbr/packaging.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/pbr/commit/c29a1c672c57ccf9c0ccf33103cdb890ba1591af', 'message': ""Merge tag '0.10.3' into master\n\nReleasing 0.10.3\n\nChange-Id: If8dd160585172a09064413305123eb2d1079d5b6\n""}]",0,143325,c29a1c672c57ccf9c0ccf33103cdb890ba1591af,14,5,1,5263,,,0,"Merge tag '0.10.3' into master

Releasing 0.10.3

Change-Id: If8dd160585172a09064413305123eb2d1079d5b6
",git fetch https://review.opendev.org/openstack/pbr refs/changes/25/143325/1 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/packaging.py', 'setup.cfg']",2,c29a1c672c57ccf9c0ccf33103cdb890ba1591af,setuptools-8,,<<<<<<< HEAD (3ec9f0 Move write_pbr_json to avoid issues with nose)======= pbr.json = pbr.packaging:write_pbr_json >>>>>>> BRANCH (e73e67 Stop including git sha in version strings),0,98
openstack%2Fneutron~stable%2Ficehouse~I0fba9c9623898ee52590207ebbb728503bb59a5b,openstack/neutron,stable/icehouse,I0fba9c9623898ee52590207ebbb728503bb59a5b,Only fetch port_id from SG binding table,ABANDONED,2014-11-14 06:27:10.000000000,2014-12-23 15:10:12.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-11-14 06:27:10.000000000', 'files': ['neutron/db/securitygroups_rpc_base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9d25b83b122e71155e346042e8ed1b271c7b0b5c', 'message': 'Only fetch port_id from SG binding table\n\nChange a query to only retrieve the port_id instead of\nevery column from the row of security group binding info.\n\nConflicts:\n    neutron/db/securitygroups_rpc_base.py\n\nPartial-Bug: #1373851\n(cherry picked from commit 6acadab5eb8b7b627e097a638d8486bef59a7f30)\n\nChange-Id: I0fba9c9623898ee52590207ebbb728503bb59a5b\n'}]",0,134449,9d25b83b122e71155e346042e8ed1b271c7b0b5c,14,12,1,1313,,,0,"Only fetch port_id from SG binding table

Change a query to only retrieve the port_id instead of
every column from the row of security group binding info.

Conflicts:
    neutron/db/securitygroups_rpc_base.py

Partial-Bug: #1373851
(cherry picked from commit 6acadab5eb8b7b627e097a638d8486bef59a7f30)

Change-Id: I0fba9c9623898ee52590207ebbb728503bb59a5b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/49/134449/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/securitygroups_rpc_base.py'],1,9d25b83b122e71155e346042e8ed1b271c7b0b5c,," query = context.session.query(sg_binding_port, for (port_id, rule_in_db) in rules_in_db:"," query = context.session.query(sg_db.SecurityGroupPortBinding, for (binding, rule_in_db) in rules_in_db: port_id = binding['port_id']",2,3
openstack%2Fneutron~stable%2Ficehouse~I12899413004838d2d22b691f1e2f3b18f7ec2c27,openstack/neutron,stable/icehouse,I12899413004838d2d22b691f1e2f3b18f7ec2c27,Improve performance of security group DB query,ABANDONED,2014-11-14 05:51:46.000000000,2014-12-23 15:10:05.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 1313}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-11-14 05:51:46.000000000', 'files': ['neutron/db/securitygroups_rpc_base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e66cfbc753c2c9c60e6869aba3c7481ef444b4ac', 'message': 'Improve performance of security group DB query\n\nThe _select_ips_for_remote_group method was joining the\nIP allocation, port, allowed address pair, and security group tables\ntogether in a single query. Additionally, it was loading all of\nthe port columns and using none of them. This resulted in a\nvery expensive query with no benefit.\n\nThis patch eliminates the unnecessary use of the port table by joining\nthe IP allocation table directly to the security groups and allowed\naddress pairs tables. In local testing of the method, this sped it up\nby an order of magnitude.\n\nCloses-Bug: #1373851\nChange-Id: I12899413004838d2d22b691f1e2f3b18f7ec2c27\n(cherry picked from commit 04df85b6e5a098f8f55bb82f04d9769763beb487)\n'}]",0,134442,e66cfbc753c2c9c60e6869aba3c7481ef444b4ac,28,13,1,1313,,,0,"Improve performance of security group DB query

The _select_ips_for_remote_group method was joining the
IP allocation, port, allowed address pair, and security group tables
together in a single query. Additionally, it was loading all of
the port columns and using none of them. This resulted in a
very expensive query with no benefit.

This patch eliminates the unnecessary use of the port table by joining
the IP allocation table directly to the security groups and allowed
address pairs tables. In local testing of the method, this sped it up
by an order of magnitude.

Closes-Bug: #1373851
Change-Id: I12899413004838d2d22b691f1e2f3b18f7ec2c27
(cherry picked from commit 04df85b6e5a098f8f55bb82f04d9769763beb487)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/42/134442/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/securitygroups_rpc_base.py'],1,e66cfbc753c2c9c60e6869aba3c7481ef444b4ac,,"from neutron.db import allowedaddresspairs_db as addr_pair ips_by_group[remote_group_id] = set() # Join the security group binding table directly to the IP allocation # table instead of via the Port table skip an unnecessary intermediary models_v2.IPAllocation.ip_address, addr_pair.AllowedAddressPair.ip_address) # Outerjoin because address pairs may be null and we still want the # IP for the port. query = query.outerjoin( addr_pair.AllowedAddressPair, sg_binding_port == addr_pair.AllowedAddressPair.port_id) # Each allowed address pair IP record for a port beyond the 1st # will have a duplicate regular IP in the query response since # the relationship is 1-to-many. Dedup with a set for security_group_id, ip_address, allowed_addr_ip in query: ips_by_group[security_group_id].add(ip_address) if allowed_addr_ip: ips_by_group[security_group_id].add(allowed_addr_ip)"," ips_by_group[remote_group_id] = [] models_v2.Port, models_v2.IPAllocation.ip_address) query = query.join(models_v2.Port, ip_port == models_v2.Port.id) for security_group_id, port, ip_address in query: ips_by_group[security_group_id].append(ip_address) # if there are allowed_address_pairs add them if getattr(port, 'allowed_address_pairs', None): for address_pair in port.allowed_address_pairs: ips_by_group[security_group_id].append( address_pair['ip_address'])",18,12
openstack%2Fneutron-specs~master~I4d126a313017ef01308d565b6792e104a5d1a935,openstack/neutron-specs,master,I4d126a313017ef01308d565b6792e104a5d1a935,Service group and Service Object for firewall as a service,MERGED,2014-10-28 22:44:03.000000000,2014-12-23 15:09:29.000000000,2014-12-23 15:09:28.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 333}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 2592}, {'_account_id': 6995}, {'_account_id': 7249}, {'_account_id': 8645}, {'_account_id': 10041}, {'_account_id': 10182}, {'_account_id': 10511}, {'_account_id': 10980}, {'_account_id': 11753}, {'_account_id': 12483}, {'_account_id': 12525}]","[{'number': 1, 'created': '2014-10-28 22:44:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d551a57cfc2f715d35dc78cea81997e98d258535', 'message': 'Service group and Service Object for firewall as a service\n\nIn the traditional firewall design a service is used to define type of traffic\nin firewall. This blueprint creates an extension that allows the firewall\nadministrators to create customized service objects. The customized service\nobjects can be grouped together to form a service group object. The policy\nrule of FWaaS can reference more than one type of traffic by referencing to\nservice group objects.\nImplements: blueprint fwaas-customized-service for customized service\nChange-Id: I4d126a313017ef01308d565b6792e104a5d1a935\nAuthored-by: badveli vishnuvardhan <badveli_vishnuus@yahoo.com>\n'}, {'number': 2, 'created': '2014-10-30 02:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5b03739f3f4a92ec941bd037f8a2093095dc03bb', 'message': 'Service group and Service Object for firewall as a service\n\nIn the traditional firewall design a service is used to define type of traffic\nin firewall. This blueprint creates an extension that allows the firewall\nadministrators to create customized service objects. The customized service\nobjects can be grouped together to form a service group object. The policy\nrule of FWaaS can reference more than one type of traffic by referencing to\nservice group objects.\nImplements: blueprint fwaas-customized-service for customized service\nChange-Id: I4d126a313017ef01308d565b6792e104a5d1a935\nAuthored-by: badveli vishnuvardhan <badveli_vishnuus@yahoo.com>\n'}, {'number': 3, 'created': '2014-11-12 22:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b5af768ab59809ec6a499497f39ea6466673b3c4', 'message': 'Service group and Service Object for firewall as a service\n\nIn the traditional firewall design a service is used to define type of traffic\nin firewall. This blueprint creates an extension that allows the firewall\nadministrators to create customized service objects. The customized service\nobjects can be grouped together to form a service group object. The policy\nrule of FWaaS can reference more than one type of traffic by referencing to\nservice group objects.\nImplements: blueprint fwaas-customized-service for customized service\nChange-Id: I4d126a313017ef01308d565b6792e104a5d1a935\nAuthored-by: badveli vishnuvardhan <badveli_vishnuus@yahoo.com>\n'}, {'number': 4, 'created': '2014-11-18 03:41:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/4c881403ef50e8ea6092d9742df1ffacebc1072e', 'message': 'Service group and Service Object for firewall as a service\n\nIn the traditional firewall design a service is used to define type of traffic\nin firewall. This blueprint creates an extension that allows the firewall\nadministrators to create customized service objects. The customized service\nobjects can be grouped together to form a service group object. The policy\nrule of FWaaS can reference more than one type of traffic by referencing to\nservice group objects.\nImplements: blueprint fwaas-customized-service for customized service\nChange-Id: I4d126a313017ef01308d565b6792e104a5d1a935\nAuthored-by: badveli vishnuvardhan <badveli_vishnuus@yahoo.com>\n'}, {'number': 5, 'created': '2014-11-21 07:21:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/da96055f2c295e77f8d5001488f50b22cfb58ded', 'message': 'Service group and Service Object for firewall as a service\n\nIn the traditional firewall design a service is used to define type of traffic\nin firewall. This blueprint creates an extension that allows the firewall\nadministrators to create customized service objects. The customized service\nobjects can be grouped together to form a service group object. The policy\nrule of FWaaS can reference more than one type of traffic by referencing to\nservice group objects.\nImplements: blueprint fwaas-customized-service for customized service\nChange-Id: I4d126a313017ef01308d565b6792e104a5d1a935\nAuthored-by: badveli vishnuvardhan <badveli_vishnuus@yahoo.com>\n'}, {'number': 6, 'created': '2014-12-04 03:11:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8f5e83f1fa8ff2aad7299a3352972bf32d30fef6', 'message': 'Service group and Service Object for firewall as a service\n\nIn the traditional firewall design a service is used to define type of traffic\nin firewall. This blueprint creates an extension that allows the firewall\nadministrators to create customized service objects. The customized service\nobjects can be grouped together to form a service group object. The policy\nrule of FWaaS can reference more than one type of traffic by referencing to\nservice group objects.\nImplements: blueprint fwaas-customized-service for customized service\nChange-Id: I4d126a313017ef01308d565b6792e104a5d1a935\nAuthored-by: badveli vishnuvardhan <badveli_vishnuus@yahoo.com>\n'}, {'number': 7, 'created': '2014-12-04 04:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ee7752208e88c51eb4de2fdaf1fa25a013a8b174', 'message': 'Service group and Service Object for firewall as a service\n\nIn the traditional firewall design a service is used to define type of traffic\nin firewall. This blueprint creates an extension that allows the firewall\nadministrators to create customized service objects. The customized service\nobjects can be grouped together to form a service group object. The policy\nrule of FWaaS can reference more than one type of traffic by referencing to\nservice group objects.\nImplements: blueprint fwaas-customized-service for customized service\nChange-Id: I4d126a313017ef01308d565b6792e104a5d1a935\nAuthored-by: badveli vishnuvardhan <badveli_vishnuus@yahoo.com>\n'}, {'number': 8, 'created': '2014-12-05 20:48:48.000000000', 'files': ['specs/kilo/service-group.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b4ca374a968dfa18a0f9524ef80bbef52c6da4cb', 'message': 'Service group and Service Object for firewall as a service\n\nIn the traditional firewall design a service is used to define type of traffic\nin firewall. This blueprint creates an extension that allows the firewall\nadministrators to create customized service objects. The customized service\nobjects can be grouped together to form a service group object. The policy\nrule of FWaaS can reference more than one type of traffic by referencing to\nservice group objects.\nImplements: blueprint fwaas-customized-service for customized service\nChange-Id: I4d126a313017ef01308d565b6792e104a5d1a935\nAuthored-by: badveli vishnuvardhan <badveli_vishnuus@yahoo.com>\n'}]",148,131596,b4ca374a968dfa18a0f9524ef80bbef52c6da4cb,63,17,8,11753,,,0,"Service group and Service Object for firewall as a service

In the traditional firewall design a service is used to define type of traffic
in firewall. This blueprint creates an extension that allows the firewall
administrators to create customized service objects. The customized service
objects can be grouped together to form a service group object. The policy
rule of FWaaS can reference more than one type of traffic by referencing to
service group objects.
Implements: blueprint fwaas-customized-service for customized service
Change-Id: I4d126a313017ef01308d565b6792e104a5d1a935
Authored-by: badveli vishnuvardhan <badveli_vishnuus@yahoo.com>
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/96/131596/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/service-group.rst'],1,d551a57cfc2f715d35dc78cea81997e98d258535,bp/creates,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================================== Service Group and Service Object support ======================================== https://blueprints.launchpad.net/neutron/+spec/fwaas-customized-service In the traditional firewall design a service is used to define type of traffic in firewall,This blueprint creates an extension that allows the firewall administrators to create customized service objects. The customized service objects can be grouped together to form a service group object. Problem Description ======================= 1. In FWaaS, administrator can use port range and protocol inside firewall rules to define traffic type. But we don't have a flexible way to allow user to specify more than one type of traffic in the same rule.To support different traffic type, with the same source, destination address and action, different rules need to be created. This makes the process of defining firewall rules un-scalable. 2. Most of vendors' (eg. PAN, Juniper) security policy is implemented based on service and do not configure protocol and port on the policy directly, We should support the same in the firewall rule for the easy integration. 3. Some vendors also support special attributes for different traffic type, one of the usage is to allow session idle timeout values for different traffic type. We can not support this today Proposed Change ================== We propose to add a new extension with two resources. One is called service group and one is called service object. Administrator can use service object to define a special type of traffic. The service objects is grouped into service group that can be referenced from other openstack modules (eg. firewall rule). Each service object can be defined with a timeout value that can be used to overwrite default session idle timeout value. When being used with firewall rules, the service groups are allowed to be reused among different firewall rules in the same tenant. To simplify the initial implementation, following features are not supported in the first implementation: 1. support of sharing the service object among service groups. 2. support of the case where the cloud provider administrator creates service group for tenant to use. We should be able to add these two features later with backward compatible APIs. The service group can only be deleted if there are no other object is referencing it and in the current case, the referencing object will be firewall rules. A service object can only be deleted if there are no other service groups are referencing it. Since most of the firewall vendors support only using service group or service object to configure firewall policy and do not allow user to configure the protocol and port on the security policy directly, we should deprecate the protocol and port options from the firewall rule resources. But we will delay this decision until later releases. Even current document is targeting firewall rule as the user of the service group, the service group could also be useful when configure security group or group policy. In the developer session of Hong Kong openstack summit, some of developers suggested to make service group as global resource. Based on this suggestion, we will make the service group and service object global resources. Here is an example for using service group in firewall rule: Assuming a tenant has two servers that provide certain type of web services on port 8080, 80 and 8000.We can create two firewall rules to permit traffic from any source ip address to these two servers.The service provided from 8000 port has very short idle timeout (10 seconds), the services provided on port 8080 and 80 have default idle timeout neutron service-group-create http-services This will create a service group named as http-services neutron service-object-create --protcol tcp --destination-port 8080 http_object_8080 \ --service-group http-services This creates a service object named http_object_8080 in the http-service group neutron service-object-create --protcol tcp --destination-port 80 http_object_80 \ --service-group http-services This creates a service object named http_object_80 in http-service group neutron service-object-create --protcol tcp --destination-port 8000 --timeout 10 \ http_object_8000 --service-group http-services This creates a service object names http_object_8000 in http-service group, The service idle timeout for this object is 10 seconds. It implies the firewall session that created by this type of traffic has idle timeout as 10 seconds (comparing the default timeout 1800 seconds) neutron firewall-rule-create --destination-ip-address 10.0.2.1 --service-group \ tcp-http-service action permit neutron firewall-rule-create --destination-ip-address 11.0.2.1 --service-group \ tcp-http-service action permit These two rules permit traffics from any IP address to service 10.0.2.1 and 11.0.2.1 that match any service defined in the service group http-services In the current reference design, when the firewall rules get pushed to the firewall agent, the agent checks if the rule is referencing service groups (by the service group id), if it is, then the agent queries the service group content from plugin and expend the firewal rule based on the content of the service group into the iptable rules. Since the firewall policy is pushed with all the rules together, it would be better to have agent to query the service group contents so that the policy push message will not be too big. When deleting rules, the agent will do the same so that it can recover the original iptable rules and delete them. Note: 1. firewall rule can also be configured with protocol and port range, for current reference design, we will not allow service-group, protocol and port range to be configured together 2. Later, we can used IPset to implement firewall reference design, in that way, it will be much easier for us to apply service group. Data Model Impact ----------------- Firewall rules: +-------------------+------------+-----------------+-----------+------+-------------------------+ | Attribute name | Type | Default Value | Required | CRUD | Description | +-------------------+------------+-----------------+-----------+------+-------------------------+ | service_groups | List | empty | N | CRU | List of service groups | +-------------------+------------+-----------------+-----------+------+-------------------------+ Service group: +-------------------+------------+-----------------+-----------+------+-------------------------+ | Attribute name | Type | Default Value | Required | CRUD | Description | +-------------------+------------+-----------------+-----------+------+-------------------------+ | id | uuid | generated | Y | R | | +-------------------+------------+-----------------+-----------+------+-------------------------+ | name | String | empty | N | CRU |Name of service group | +-------------------+------------+-----------------+-----------+------+-------------------------+ | description | String | empty | N | CRU | | +-------------------+------------+-----------------+-----------+------+-------------------------+ | tenant id | uuid | empty | Y | R |Id of tenant that creates| | | | | | |service group | +-------------------+------------+-----------------+-----------+------+-------------------------+ | service objects | list | empty list | N | CRU |List of service objects | +-------------------+------------+-----------------+-----------+------+-------------------------+ Service object: +----------------------+----------------+-----------------------------+------+--------------------------+ | Attribute name | Type | Default Value | Required | CRUD |Description | +----------------------+----------------+-----------------+-----------+------+--------------------------+ | id | uuid | generated | Y | R | | +----------------------+----------------+-----------------+-----------+------+--------------------------+ | name | String | empty | N | CRU |Service object name | +----------------------+----------------+-----------------+-----------+------+--------------------------+ | service group id | uuid | empty | N | CRU |Foreign key to service grp| +----------------------+----------------+-----------------+-----------+------+--------------------------+ | protocol | string | empty | Y | CRU |'tcp','udp','icmp','any' | | | | | | | or protocol id (0-255) | +----------------------+----------------+-----------------+-----------+------+--------------------------+ | source_port | integer or str | empty | N | CRU |This could be either a | | | | | | |single port (integer or | | | | | | |string) or a range(string)| | | | | | |in the form ""p1:p2"" | | | | | | |where(0<=p1<=p2 <=65535) | +----------------------+----------------+-----------------+-----------+------+--------------------------+ | destination_port |integer or str | empty | N | CRU | Same as source_port | +----------------------+----------------+-----------------+-----------+------+--------------------------+ | icmp_code | char | empty | N | CRU | | +----------------------+----------------+-----------------+-----------+------+--------------------------+ | icmp_type | char | empty | N | CRU | | +----------------------+----------------+-----------------+-----------+------+--------------------------+ | timeout | short | empty | N | CRU | | +----------------------+----------------+-----------------+-----------+------+--------------------------+ | tenant_id | uuid | empty | Y | R | | +----------------------+----------------+-----------------+-----------+------+--------------------------+ New CLIs: service-group-create service-group-delete service-group-list service-group-show service-group-update service-object-create service-object-delete service-object-list service-object-show REST API Impact --------------- The new resources: .. code-block:: python RESOURCE_ATTRIBUTE_MAP = { 'service_groups': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'primary_key': True}, 'name': {'allow_post': True, 'allow_put': True, 'is_visible': True, 'default': '', 'validate': {'type:name_not_default': None}}, 'description': {'allow_post': True, 'allow_put': True, 'is_visible': True, 'default': ''}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'required_by_policy': True, 'is_visible': True}, 'service_objects': {'allow_post': False, 'allow_put': False, 'convert_to': attr.convert_none_to_empty_list, 'is_visible': True}, } 'service_objects': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'primary_key': True}, 'name': {'allow_post': True, 'allow_put': True, 'is_visible': True, 'default': '', 'validate': {'type:name_not_default': None}}, 'service_group_id': {'allow_post': True, 'allow_put': False, 'is_visible': True, 'required_by_policy': True}, 'protocol': {'allow_post': True, 'allow_put': False, 'is_visible': True, 'default': None, 'convert_to': _convert_protocol}, 'source_port': {'allow_post': True, 'allow_put': False, 'validate': {'type:service_port_range': None}, 'convert_to': _convert_port_to_string, 'default': None, 'is_visible': True}, 'destination_port': {'allow_post': True, 'allow_put': False, 'validate': {'type:service_port_range': None}, 'convert_to': _convert_port_to_string, 'default': None, 'is_visible': True}, 'icmp_code': {'allow_post': True, 'allow_put': False, 'validate': {'type:icmp_code': None}, 'convert_to': _convert_icmp_code, 'default': None, 'is_visible': True}, 'icmp_type': {'allow_post': True, 'allow_put': False, 'validate': {'type:icmp_type': None}, 'convert_to': _convert_icmp_type, 'default': None, 'is_visible': True}, 'timeout': {'allow_post': True, 'allow_put': False, 'validate': {'type:range': [0, 65535]}, 'convert_to': attr.convert_to_int, 'default': 0, 'is_visible': True}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'required_by_policy': True, 'is_visible': True}, } } RESOURCE_ATTRIBUTE_MAP = { 'firewall_rules': { 'service_groups': {'allow_post': True, 'allow_put': True, 'convert_to': attr.convert_none_to_empty_list, 'default': None, 'is_visible': True}, } } +---------------+----------------------------+----------------------+ |Object |URI |Type | +---------------+----------------------------+----------------------+ |service group |/service-groups |GET | +---------------+----------------------------+----------------------+ |service group |/service-groups |POST | +---------------+----------------------------+----------------------+ |service group |/service-groups/{id} |GET | +---------------+----------------------------+----------------------+ |service group |/service-groups/{id} |PUT | +---------------+----------------------------+----------------------+ |service group |/service-group/s{id} |DELETE | +---------------+----------------------------+----------------------+ |service object |/service-objects |GET | +---------------+----------------------------+----------------------+ |service object |/service-objects |POST | +---------------+----------------------------+----------------------+ |service object |/service-objects/{id} |GET | +---------------+----------------------------+----------------------+ |service object |/service-objects/{id} |PUT | +---------------+----------------------------+----------------------+ |service object |/service-objects/{id} |DELETE | +---------------+----------------------------+----------------------+ Security Impact --------------- * Does this change touch sensitive data such as tokens, keys, or user data? No * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? No * Does this change involve cryptography or hashing? No * Does this change require the use of sudo or any elevated privileges? No * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. Yes * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. Notifications Impact -------------------- None Other End User Impact --------------------- None Performance Impact ------------------ None Other Deployer Impact --------------------- None Developer Impact ---------------- None Community Impact ---------------- This model and framework could be utilized by various modules as it provides the correct data modeling and reduce code bloat. Alternatives ------------ Without service group, administrator can create separate rule for each type of traffic. The issue with this method is high overheads, it may create way too many rules with the duplicated resource defined in it. Also, the most of firewall vendors have service group like concept in their policy definition. Adding the notion of the service group in the firewall rule simplifies integration path for firewall vendors Implementation ============== Assignee(s) ----------- Primary assignee: badveli_vishnuus@yahoo.com beyounn@gmail.com Work Items ------------ * API and database * Reference implementation * python-neutronclient Dependencies ============ None Testing ======= Both Tempest and Functional tests will be used. Tempest Tests ------------- Complete API coverage is included. https://review.openstack.org/#/c/113409/ Complete unit test coverage of the code is included. https://review.openstack.org/#/c/106274/ Functional Tests ---------------- Complete test coverage of the code is included. https://review.openstack.org/#/c/106274/ API Tests --------- Not applicable. Documentation Impact ==================== User Documentation ------------------ Documentation for both administrators and end users will have to be contemplated. Administrators will need to know how to configure the service group by using the service group API and python-neutronclient. Developer Documentation ----------------------- None needed beyond documentation changes listed above. References ========== None ",,419,0
openstack%2Fzaqar~master~I3068b6fffde2d4d88a6009ca2ed703b38b791273,openstack/zaqar,master,I3068b6fffde2d4d88a6009ca2ed703b38b791273,Slighty refactoring for the cross api spec,MERGED,2014-12-11 05:01:03.000000000,2014-12-23 15:01:46.000000000,2014-12-23 15:01:44.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6484}]","[{'number': 1, 'created': '2014-12-11 05:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/f3d7a5d9bd3b1ff0967c9b5640f972fc6c4056fa', 'message': 'Slighty refactoring for the cross api spec\n\nAn API package has been created in common to store the API base class,\nrequest and response classes, API validation and schemas.\n\nThe processing of the requests and responses will be added in a follow\nup patch.\n\nChange-Id: I3068b6fffde2d4d88a6009ca2ed703b38b791273\nPartial-Implements: blueprint cross-transport-api-spec\n'}, {'number': 2, 'created': '2014-12-11 05:03:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/4b4bafb1e58cbc23170381e46ca555febc07b360', 'message': 'Slighty refactoring for the cross api spec\n\nAn API package has been created in common to store the API base class,\nrequest and response classes, API validation and schemas.\n\nThe processing of the requests and responses will be added in a follow\nup patch.\n\nChange-Id: I3068b6fffde2d4d88a6009ca2ed703b38b791273\nPartial-Implements: blueprint cross-transport-api-spec\n'}, {'number': 3, 'created': '2014-12-11 05:10:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/e0277db567fd850a4fe1d2cf21cbf9fb422e8844', 'message': 'Slighty refactoring for the cross api spec\n\nAn API package has been created in common to store the API base class,\nrequest and response classes, API validation and schemas.\n\nThe processing of the requests and responses will be added in a follow\nup patch.\n\nChange-Id: I3068b6fffde2d4d88a6009ca2ed703b38b791273\nPartial-Implements: blueprint cross-transport-api-spec\n'}, {'number': 4, 'created': '2014-12-11 05:44:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/e62a1219465f8f22aa3fb405627190662902645b', 'message': 'Slighty refactoring for the cross api spec\n\nAn API package has been created in common to store the API base class,\nrequest and response classes, API validation and schemas.\n\nThe processing of the requests and responses will be added in a follow\nup patch.\n\nChange-Id: I3068b6fffde2d4d88a6009ca2ed703b38b791273\nPartial-Implements: blueprint cross-transport-api-spec\n'}, {'number': 5, 'created': '2014-12-11 05:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/bb7582da1db72506d443224f566474b0521aa43b', 'message': 'Slighty refactoring for the cross api spec\n\nAn API package has been created in common to store the API base class,\nrequest and response classes, API validation and schemas.\n\nThe processing of the requests and responses will be added in a follow\nup patch.\n\nChange-Id: I3068b6fffde2d4d88a6009ca2ed703b38b791273\nPartial-Implements: blueprint cross-transport-api-spec\n'}, {'number': 6, 'created': '2014-12-11 05:54:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/9e609c5b42c0d6fa98b648380036890494e25935', 'message': 'Slighty refactoring for the cross api spec\n\nAn API package has been created in common to store the API base class,\nrequest and response classes, API validation and schemas.\n\nThe processing of the requests and responses will be added in a follow\nup patch.\n\nChange-Id: I3068b6fffde2d4d88a6009ca2ed703b38b791273\nPartial-Implements: blueprint cross-transport-api-spec\n'}, {'number': 7, 'created': '2014-12-13 03:22:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/a4bd344a23a54be8ddd27c56fe9e604f1f559875', 'message': 'Slighty refactoring for the cross api spec\n\nAn API package has been created in common to store the API base class,\nrequest and response classes, API validation and schemas.\n\nThe processing of the requests and responses will be added in a follow\nup patch.\n\nChange-Id: I3068b6fffde2d4d88a6009ca2ed703b38b791273\nPartial-Implements: blueprint cross-transport-api-spec\n'}, {'number': 8, 'created': '2014-12-13 03:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/b10753a3fe1bc3fea0bfd8763b83866b72dd612b', 'message': 'Slighty refactoring for the cross api spec\n\nAn API package has been created in common to store the API base class,\nrequest and response classes, API validation and schemas.\n\nThe processing of the requests and responses will be added in a follow\nup patch.\n\nChange-Id: I3068b6fffde2d4d88a6009ca2ed703b38b791273\nPartial-Implements: blueprint cross-transport-api-spec\n'}, {'number': 9, 'created': '2014-12-14 04:36:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/a4a37af75ec0a2693bb22eec27263a409bde183a', 'message': 'Slighty refactoring for the cross api spec\n\nAn API package has been created in common to store the API base class,\nrequest and response classes, API validation and schemas.\n\nThe processing of the requests and responses will be added in a follow\nup patch.\n\nChange-Id: I3068b6fffde2d4d88a6009ca2ed703b38b791273\nPartial-Implements: blueprint cross-transport-api-spec\n'}, {'number': 10, 'created': '2014-12-15 13:53:24.000000000', 'files': ['doc/source/api/zaqar.common.request.rst', 'doc/source/api/zaqar.common.schemas.flavors.rst', 'zaqar/api/v1_1/response.py', 'zaqar/common/api/request.py', 'doc/source/api/autoindex.rst', 'doc/source/api/zaqar.common.response.rst', 'zaqar/transport/wsgi/v1_1/flavors.py', 'zaqar/api/v1/response.py', 'doc/source/api/zaqar.common.schemas.pools.rst', 'zaqar/common/api/__init__.py', 'zaqar/common/api/api.py', 'zaqar/transport/wsgi/v1_1/pools.py', 'tests/unit/common/test_api.py', 'tests/unit/common/test_request.py', 'zaqar/common/api/schemas/flavors.py', 'zaqar/common/api/schemas/pools.py', 'doc/source/api/zaqar.common.api.api.rst', 'doc/source/api/zaqar.common.api.rst', 'doc/source/api/zaqar.common.api.schemas.flavors.rst', 'doc/source/api/zaqar.common.api.response.rst', 'zaqar/transport/wsgi/v1_0/pools.py', 'zaqar/common/api/response.py', 'doc/source/api/zaqar.common.api.schemas.pools.rst', 'zaqar/common/api/schemas/__init__.py', 'zaqar/api/v1/request.py', 'doc/source/api/zaqar.common.api.request.rst', 'zaqar/api/v1_1/request.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/fb48b07011c6bccb051b2f34cb36e29afe498800', 'message': 'Slighty refactoring for the cross api spec\n\nAn API package has been created in common to store the API base class,\nrequest and response classes, API validation and schemas.\n\nThe processing of the requests and responses will be added in a follow\nup patch.\n\nChange-Id: I3068b6fffde2d4d88a6009ca2ed703b38b791273\nPartial-Implements: blueprint cross-transport-api-spec\n'}]",1,140919,fb48b07011c6bccb051b2f34cb36e29afe498800,33,4,10,6413,,,0,"Slighty refactoring for the cross api spec

An API package has been created in common to store the API base class,
request and response classes, API validation and schemas.

The processing of the requests and responses will be added in a follow
up patch.

Change-Id: I3068b6fffde2d4d88a6009ca2ed703b38b791273
Partial-Implements: blueprint cross-transport-api-spec
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/19/140919/6 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/queues/api/v1_1/request.py', 'tests/unit/common/test_request.py', 'zaqar/queues/transport/wsgi/v1_1/flavors.py', 'zaqar/common/api/request.py', 'zaqar/common/api/schemas/flavors.py', 'zaqar/common/api/schemas/pools.py', 'zaqar/queues/transport/wsgi/v1_0/pools.py', 'zaqar/queues/api/v1_1/response.py', 'zaqar/queues/api/v1/response.py', 'zaqar/queues/api/v1/request.py', 'zaqar/common/api/response.py', 'zaqar/queues/transport/wsgi/v1_1/pools.py', 'zaqar/common/api/schemas/__init__.py', 'zaqar/common/api/__init__.py', 'zaqar/common/api/api.py']",15,f3d7a5d9bd3b1ff0967c9b5640f972fc6c4056fa,bp/cross-transport-api-spec,,,9,8
openstack%2Ffuel-library~master~Ia82af254e8b6903cc3837b14fef281f09d03a106,openstack/fuel-library,master,Ia82af254e8b6903cc3837b14fef281f09d03a106,Added parameters for availability zones configuration for cinder,MERGED,2014-12-22 16:56:05.000000000,2014-12-23 14:59:29.000000000,2014-12-23 14:59:28.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 12139}]","[{'number': 1, 'created': '2014-12-22 16:56:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/75714d144ca81639600a837176ce48ae6a47a6d5', 'message': 'Added parameters for availability zones configuration\n\nBackported from upstraem.\n\nChange-Id: Ia82af254e8b6903cc3837b14fef281f09d03a106\nImplements: blueprint availability-zones\n'}, {'number': 2, 'created': '2014-12-22 16:57:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/60788c4624ce58a00b8a69e9b83d84f129a5b703', 'message': 'Added parameters for availability zones configuration\n\nBackported from upstream manifests.\n\nChange-Id: Ia82af254e8b6903cc3837b14fef281f09d03a106\nImplements: blueprint availability-zones\n'}, {'number': 3, 'created': '2014-12-23 13:42:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4f736c395fd501033ac3bf33a5dc333fbac57362', 'message': 'Added parameters for availability zones configuration for cinder\n\nBackported from pupppet-cinder upstream manifests.\n\nChange-Id: Ia82af254e8b6903cc3837b14fef281f09d03a106\nImplements: blueprint availability-zones\n'}, {'number': 4, 'created': '2014-12-23 13:43:42.000000000', 'files': ['deployment/puppet/cinder/manifests/init.pp', 'deployment/puppet/cinder/spec/classes/cinder_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7ce66e29eb21d7debfb9923b9e3f34906450f6bf', 'message': 'Added parameters for availability zones configuration for cinder\n\nBackported from puppet-cinder upstream manifests.\n\nChange-Id: Ia82af254e8b6903cc3837b14fef281f09d03a106\nImplements: blueprint availability-zones\n'}]",0,143497,7ce66e29eb21d7debfb9923b9e3f34906450f6bf,31,8,4,12139,,,0,"Added parameters for availability zones configuration for cinder

Backported from puppet-cinder upstream manifests.

Change-Id: Ia82af254e8b6903cc3837b14fef281f09d03a106
Implements: blueprint availability-zones
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/97/143497/4 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/cinder/manifests/init.pp', 'deployment/puppet/cinder/spec/classes/cinder_spec.rb']",2,75714d144ca81639600a837176ce48ae6a47a6d5,bp/availability-zones, should contain_cinder_config('DEFAULT/storage_availability_zone').with( :value => 'nova' ) should contain_cinder_config('DEFAULT/default_availability_zone').with( :value => 'nova' ),,16,0
openstack%2Fec2-api~master~Id9ccac0869555fb2ea977a9e878d41386550f336,openstack/ec2-api,master,Id9ccac0869555fb2ea977a9e878d41386550f336,EC2 classic mode unit tests for addresses,MERGED,2014-12-23 10:05:43.000000000,2014-12-23 14:47:23.000000000,2014-12-23 14:47:21.000000000,"[{'_account_id': 3}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-12-23 10:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/28625503c35560cdbebb98f2cb8860330139d239', 'message': 'EC2 classic mode unit tests for addresses\n\nChange-Id: Id9ccac0869555fb2ea977a9e878d41386550f336\n'}, {'number': 2, 'created': '2014-12-23 13:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/c7cbc6af1cddc23b560be5b709c8b6990e08a2c3', 'message': 'EC2 classic mode unit tests for addresses\n\nChange-Id: Id9ccac0869555fb2ea977a9e878d41386550f336\n'}, {'number': 3, 'created': '2014-12-23 14:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/a5621417e4ca9482a29fdd0fe2533364156482a4', 'message': 'EC2 classic mode unit tests for addresses\n\nChange-Id: Id9ccac0869555fb2ea977a9e878d41386550f336\n'}, {'number': 4, 'created': '2014-12-23 14:28:23.000000000', 'files': ['ec2api/tests/test_address.py', 'ec2api/tests/fakes.py', 'ec2api/api/address.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/13cf3bfecd3d6af1e3b512da7dbf8787344d9911', 'message': 'EC2 classic mode unit tests for addresses\n\nChange-Id: Id9ccac0869555fb2ea977a9e878d41386550f336\n'}]",0,143641,13cf3bfecd3d6af1e3b512da7dbf8787344d9911,12,3,4,9312,,,0,"EC2 classic mode unit tests for addresses

Change-Id: Id9ccac0869555fb2ea977a9e878d41386550f336
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/41/143641/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/tests/test_address.py', 'ec2api/tests/fakes.py', 'ec2api/api/address.py']",3,28625503c35560cdbebb98f2cb8860330139d239,," if os_instance_id: nova.servers.remove_floating_ip(os_instance_id, public_ip)"," nova.servers.remove_floating_ip(os_instance_id, public_ip)",83,3
openstack%2Ftempest~master~Ib17d1e92d5491aa49a58717ba158f339a1c5f366,openstack/tempest,master,Ib17d1e92d5491aa49a58717ba158f339a1c5f366,Fix dhcpv6-stateful tempest test to validate only valid use-case,MERGED,2014-12-19 08:31:35.000000000,2014-12-23 14:43:50.000000000,2014-12-23 14:43:49.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 6524}, {'_account_id': 7350}, {'_account_id': 10385}, {'_account_id': 10969}]","[{'number': 1, 'created': '2014-12-19 08:31:35.000000000', 'files': ['tempest/api/network/test_dhcp_ipv6.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/ba3aee5a9c9df7c2b471da4e6d1d48a60a97ab9d', 'message': 'Fix dhcpv6-stateful tempest test to validate only valid use-case\n\nAccording to IPv6 Radvd implementation[1], when ipv6_ra_mode is not set\nand ipv6_address_mode is set to dhcpv6-stateful, Neutron would be using\nan external router for Router Advertisements. Such subnets are not\nsupposed to be associated with Neutron Router as they are meant to be\nused with external router.\n\nA recent commit I0a063e543e320ea625a5411547bce7fa2ad66b7d is causing\nfailure of the Neutron patch[2] in gate. This patch modifies the tempest\ncode to remove this invalid use-case and validate only the valid\nuse-cases.\n\n[1] - Neutron ipv6-radvd-ra blueprint\n[2] - https://review.openstack.org/#/c/136733/6\n\nCloses-Bug: #1404139\nChange-Id: Ib17d1e92d5491aa49a58717ba158f339a1c5f366\n'}]",0,143014,ba3aee5a9c9df7c2b471da4e6d1d48a60a97ab9d,11,8,1,10257,,,0,"Fix dhcpv6-stateful tempest test to validate only valid use-case

According to IPv6 Radvd implementation[1], when ipv6_ra_mode is not set
and ipv6_address_mode is set to dhcpv6-stateful, Neutron would be using
an external router for Router Advertisements. Such subnets are not
supposed to be associated with Neutron Router as they are meant to be
used with external router.

A recent commit I0a063e543e320ea625a5411547bce7fa2ad66b7d is causing
failure of the Neutron patch[2] in gate. This patch modifies the tempest
code to remove this invalid use-case and validate only the valid
use-cases.

[1] - Neutron ipv6-radvd-ra blueprint
[2] - https://review.openstack.org/#/c/136733/6

Closes-Bug: #1404139
Change-Id: Ib17d1e92d5491aa49a58717ba158f339a1c5f366
",git fetch https://review.opendev.org/openstack/tempest refs/changes/14/143014/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/test_dhcp_ipv6.py'],1,ba3aee5a9c9df7c2b471da4e6d1d48a60a97ab9d,bug/1404139,," (None, 'dhcpv6-stateful'),",0,1
openstack%2Fec2-api~master~I620e3d497123513c35ebfaed94de93aed82758b8,openstack/ec2-api,master,I620e3d497123513c35ebfaed94de93aed82758b8,Add tags to describe output,MERGED,2014-12-22 12:59:38.000000000,2014-12-23 14:38:29.000000000,2014-12-23 14:38:28.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-12-22 12:59:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/f5be8db2147409f0d2e58f6a40a971a44ff81e02', 'message': 'Add tags to describe output\n\nChange-Id: I620e3d497123513c35ebfaed94de93aed82758b8\n'}, {'number': 2, 'created': '2014-12-22 13:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/60dbcb0cb625f6d113833368e5d12f6b6ab2077d', 'message': 'Add tags to describe output\n\nChange-Id: I620e3d497123513c35ebfaed94de93aed82758b8\n'}, {'number': 3, 'created': '2014-12-22 16:57:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/e765e9f444f33b744d7087f78500cfcf212f0168', 'message': 'Add tags to describe output\n\nChange-Id: I620e3d497123513c35ebfaed94de93aed82758b8\n'}, {'number': 4, 'created': '2014-12-22 17:56:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/1a4cb6b326482358bc30410d26dac0788f7593af', 'message': 'Add tags to describe output\n\nChange-Id: I620e3d497123513c35ebfaed94de93aed82758b8\n'}, {'number': 5, 'created': '2014-12-23 14:17:20.000000000', 'files': ['ec2api/api/snapshot.py', 'ec2api/api/network_interface.py', 'ec2api/api/dhcp_options.py', 'ec2api/api/internet_gateway.py', 'ec2api/api/route_table.py', 'ec2api/api/address.py', 'ec2api/api/image.py', 'ec2api/api/instance.py', 'ec2api/api/volume.py', 'ec2api/db/api.py', 'ec2api/db/sqlalchemy/api.py', 'ec2api/tests/fakes.py', 'ec2api/api/subnet.py', 'ec2api/api/common.py', 'ec2api/api/vpc.py', 'ec2api/api/security_group.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/6ec5a6002306eecc60ceb42ce7295d9726f52afa', 'message': 'Add tags to describe output\n\nChange-Id: I620e3d497123513c35ebfaed94de93aed82758b8\n'}]",0,143436,6ec5a6002306eecc60ceb42ce7295d9726f52afa,14,3,5,10224,,,0,"Add tags to describe output

Change-Id: I620e3d497123513c35ebfaed94de93aed82758b8
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/36/143436/4 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/tag.py', 'ec2api/api/instance.py', 'ec2api/api/network_interface.py', 'ec2api/db/api.py', 'ec2api/db/sqlalchemy/api.py', 'ec2api/tests/fakes.py', 'ec2api/api/common.py', 'ec2api/api/ec2utils.py', 'ec2api/api/route_table.py']",9,f5be8db2147409f0d2e58f6a40a971a44ff81e02,master," 'routeSet': [], 'tagSet': []}", 'routeSet': []},56,24
openstack%2Fec2-api~master~Iaa170b87c9035167cb1377f5c54d8fb9619d1f37,openstack/ec2-api,master,Iaa170b87c9035167cb1377f5c54d8fb9619d1f37,Availability_zones unit tests,MERGED,2014-12-23 07:58:39.000000000,2014-12-23 14:15:17.000000000,2014-12-23 14:15:17.000000000,"[{'_account_id': 3}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-12-23 07:58:39.000000000', 'files': ['ec2api/tests/test_availability_zone.py', 'ec2api/tests/test_key_pair.py', 'ec2api/tests/base.py', 'ec2api/tests/fakes.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/0c426c84f98c5022cf42b22a9c2889f0612081d7', 'message': 'Availability_zones unit tests\n\nChange-Id: Iaa170b87c9035167cb1377f5c54d8fb9619d1f37\n'}]",0,143613,0c426c84f98c5022cf42b22a9c2889f0612081d7,6,3,1,9312,,,0,"Availability_zones unit tests

Change-Id: Iaa170b87c9035167cb1377f5c54d8fb9619d1f37
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/13/143613/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/tests/test_availability_zone.py', 'ec2api/tests/test_key_pair.py', 'ec2api/tests/base.py', 'ec2api/tests/fakes.py']",4,0c426c84f98c5022cf42b22a9c2889f0612081d7,,"# availability zone objects class NovaAvailabilityZone(object): def __init__(self, nova_availability_zone_dict): self.zoneName = nova_availability_zone_dict['zoneName'] self.zoneState = {'available': nova_availability_zone_dict['zoneState'] == 'available'} self.hosts = nova_availability_zone_dict['hosts'] OS_AVAILABILITY_ZONE = {'zoneName': 'nova', 'zoneState': 'available', 'hosts': {'host1': {'service1': { 'active': 'True', 'available': 'True', 'updated_at': 'now'}, 'service2': { 'active': 'False', 'available': 'False', 'updated_at': 'now'}}, 'host2': {'service1': { 'active': 'True', 'available': 'True', 'updated_at': 'now'}} }} OS_AVAILABILITY_ZONE_INTERNAL = {'zoneName': 'internal', 'zoneState': 'available', 'hosts': {}} EC2_AVAILABILITY_ZONE = {'zoneName': 'nova', 'zoneState': 'available'} ",,83,2
openstack%2Fmagnum~master~I690745c90887d8f2dfcfcacbced7c102200916a3,openstack/magnum,master,I690745c90887d8f2dfcfcacbced7c102200916a3,Remove pod_list and service_list from kube.py and kubecli.py,ABANDONED,2014-12-22 06:50:29.000000000,2014-12-23 14:07:42.000000000,,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6924}, {'_account_id': 7494}]","[{'number': 1, 'created': '2014-12-22 06:50:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/99f0ae950a4dc1ac265ec00a01760718d75e6445', 'message': 'Remove pod_list and service_list from kube.py and kubecli.py\n\nNo one wil call those two APIs, since pod and service information\nwill be get from magnum db.\n\nChange-Id: I690745c90887d8f2dfcfcacbced7c102200916a3\n'}, {'number': 2, 'created': '2014-12-22 07:27:33.000000000', 'files': ['magnum/conductor/kubecli.py', 'magnum/conductor/handlers/kube.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/9a7a82d3d81c9a33cc29c5e18e208a4810d01416', 'message': 'Remove pod_list and service_list from kube.py and kubecli.py\n\nNo one wil call those two APIs, since pod and service information\nwill be get from magnum db.\n\nChange-Id: I690745c90887d8f2dfcfcacbced7c102200916a3\n'}]",0,143375,9a7a82d3d81c9a33cc29c5e18e208a4810d01416,11,4,2,7494,,,0,"Remove pod_list and service_list from kube.py and kubecli.py

No one wil call those two APIs, since pod and service information
will be get from magnum db.

Change-Id: I690745c90887d8f2dfcfcacbced7c102200916a3
",git fetch https://review.opendev.org/openstack/magnum refs/changes/75/143375/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/conductor/handlers/kube.py', 'magnum/conductor/kubecli.py']",2,99f0ae950a4dc1ac265ec00a01760718d75e6445,143366,," def service_list(): LOG.debug(""service_list"") try: out = utils.execute('kubectl', 'get', 'services') pod_data = [s.split() for s in out.split('\n')] return pod_data except Exception as e: LOG.error(""Couldn't get list of services due to error %s"" % e) return None @staticmethod def pod_list(): LOG.debug(""pod_list"") try: out = utils.execute('kubectl', 'get', 'pods') pod_data = [s.split() for s in out.split('\n')] return pod_data except Exception as e: LOG.error(""Couldn't get list of pods due to error %s"" % e) return None @staticmethod",0,30
openstack%2Fzaqar~master~I2f2f9b378acdafb63940fcda2dec86572df679b0,openstack/zaqar,master,I2f2f9b378acdafb63940fcda2dec86572df679b0,Use keystoneclient auth and register required options,MERGED,2014-12-19 11:02:21.000000000,2014-12-23 14:07:31.000000000,2014-12-23 14:07:30.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6484}, {'_account_id': 7488}]","[{'number': 1, 'created': '2014-12-19 11:02:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/e37828d0a686b1f63e20ba0ffc58ef1d1a2e15c5', 'message': ""Use keystoneclient auth and register required options\n\nThis patch will import keystoneclient auth and use it to register\noptions. Without this fix, zaqar's test will fail due to the\nchange in keystonemiddleware 1.3.0.\n\nCloses-Bug: #1404177\n\nChange-Id: I2f2f9b378acdafb63940fcda2dec86572df679b0\n""}, {'number': 2, 'created': '2014-12-19 12:10:40.000000000', 'files': ['zaqar/transport/auth.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/93c7da99f5f4da62fb2120a667712660084e99ea', 'message': ""Use keystoneclient auth and register required options\n\nThis patch will import keystoneclient auth and use it to register\noptions. Without this fix, zaqar's test will fail due to the\nchange in keystonemiddleware 1.3.0.\n\nCloses-Bug: #1404177\n\nChange-Id: I2f2f9b378acdafb63940fcda2dec86572df679b0\n""}]",0,143038,93c7da99f5f4da62fb2120a667712660084e99ea,19,5,2,6484,,,0,"Use keystoneclient auth and register required options

This patch will import keystoneclient auth and use it to register
options. Without this fix, zaqar's test will fail due to the
change in keystonemiddleware 1.3.0.

Closes-Bug: #1404177

Change-Id: I2f2f9b378acdafb63940fcda2dec86572df679b0
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/38/143038/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/etc/keystone_auth.conf', 'zaqar/transport/auth.py']",2,e37828d0a686b1f63e20ba0ffc58ef1d1a2e15c5,bug/1404177,"from keystoneclient import auth auth.register_conf_options(conf, cls.OPT_GROUP_NAME)",,11,0
openstack%2Fnova~master~If27674f2acbb8fab7d15caeb91d0f08ba811f6db,openstack/nova,master,If27674f2acbb8fab7d15caeb91d0f08ba811f6db,Nullify empty key_name on instance create,ABANDONED,2014-12-18 12:27:04.000000000,2014-12-23 14:04:37.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11061}]","[{'number': 1, 'created': '2014-12-18 12:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6bddcf76abebb772be29e716ddb9661b7e56d327', 'message': 'Nullify empty key_name on instance create\n\nEmpty ("""") key_name is treated as None, but gest written to database.\nHorizon does not like this and gives error when renreging instance\ndetails.\n\nChange-Id: If27674f2acbb8fab7d15caeb91d0f08ba811f6db\nCloses-Bug: #1403544\n'}, {'number': 2, 'created': '2014-12-18 13:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d8107e400dfcc7b5b327d8143893ee383407de5', 'message': 'Nullify empty key_name on instance create\n\nEmpty ("""") key_name is treated as None, but gest written to database.\nHorizon does not like this and gives error when renreging instance\ndetails.\n\nChange-Id: If27674f2acbb8fab7d15caeb91d0f08ba811f6db\nCloses-Bug: #1403544\n'}, {'number': 3, 'created': '2014-12-18 14:17:49.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_servers.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/663873052b65617d12cf8af48cc2a94666da960c', 'message': 'Nullify empty key_name on instance create\n\nEmpty ("""") key_name is treated as None, but gest written to database.\nHorizon does not like this and gives error when renreging instance\ndetails.\n\nChange-Id: If27674f2acbb8fab7d15caeb91d0f08ba811f6db\nCloses-Bug: #1403544\n'}]",0,142755,663873052b65617d12cf8af48cc2a94666da960c,15,6,3,11061,,,0,"Nullify empty key_name on instance create

Empty ("""") key_name is treated as None, but gest written to database.
Horizon does not like this and gives error when renreging instance
details.

Change-Id: If27674f2acbb8fab7d15caeb91d0f08ba811f6db
Closes-Bug: #1403544
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/142755/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_servers.py', 'nova/compute/api.py']",2,6bddcf76abebb772be29e716ddb9661b7e56d327,bug/1403544, else: key_name = None,,11,0
openstack%2Fglance~master~Ib7a6aeb2df3bc5d23fe8e070290b5bfcab00c0f5,openstack/glance,master,Ib7a6aeb2df3bc5d23fe8e070290b5bfcab00c0f5,Adds the ability to sort images with multiple keys,MERGED,2014-09-11 09:12:10.000000000,2014-12-23 13:48:08.000000000,2014-12-23 13:48:06.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 8127}, {'_account_id': 8158}, {'_account_id': 8443}, {'_account_id': 9096}, {'_account_id': 9303}, {'_account_id': 10068}, {'_account_id': 11356}, {'_account_id': 11391}, {'_account_id': 12395}, {'_account_id': 12807}, {'_account_id': 13717}]","[{'number': 1, 'created': '2014-09-11 09:12:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4fb80012f510ee8e417d3f9aae01e7146be7885a', 'message': 'Adds the ability to sort images with multiple keys\n\nExtend rest api v1/v2 with comma separated sort keys.\nExample:\n/v1/images/detail?sort_key=name,id\nChanged database api which now takes sort_key param as a list instead of string\npython-glanceclient support will be added in separate commit\n\nChange-Id: Ib7a6aeb2df3bc5d23fe8e070290b5bfcab00c0f5\nPartial-Bug: 1221274\n'}, {'number': 2, 'created': '2014-09-11 09:37:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/745aa61bf34ecc75da092186d3be1184acd0d861', 'message': 'Adds the ability to sort images with multiple keys\n\nExtend rest api v1/v2 with comma separated sort keys.\nExample:\n/v1/images/detail?sort_key=name,id\nChanged database api which now takes sort_key param as a list instead of string\npython-glanceclient support will be added in separate commit\n\nChange-Id: Ib7a6aeb2df3bc5d23fe8e070290b5bfcab00c0f5\nPartial-Bug: 1221274\n'}, {'number': 3, 'created': '2014-09-11 12:02:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/dc795a03990bf5828cc1b20d7ffc8dca9409a7b2', 'message': 'Adds the ability to sort images with multiple keys\n\nExtend rest api v1/v2 with comma separated sort keys.\nExample:\n/v1/images/detail?sort_key=name,id\nChanged database api which now takes sort_key param as a list instead of string\npython-glanceclient support will be added in separate commit\n\nChange-Id: Ib7a6aeb2df3bc5d23fe8e070290b5bfcab00c0f5\nPartial-Bug: 1221274\n'}, {'number': 4, 'created': '2014-09-11 13:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/23a22e1c818ee78501454f7168298fe4e09a51ce', 'message': 'Adds the ability to sort images with multiple keys\n\nExtend rest api v1/v2 with comma separated sort keys.\nExample:\n/v1/images/detail?sort_key=name,id\nChanged database api which now takes sort_key param as a list instead of string\npython-glanceclient support will be added in separate commit\n\nChange-Id: Ib7a6aeb2df3bc5d23fe8e070290b5bfcab00c0f5\nPartial-Bug: 1221274\n'}, {'number': 5, 'created': '2014-09-15 08:28:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/24b08e3b30832c53522c5a020eccc3d589b5926c', 'message': 'Adds the ability to sort images with multiple keys\n\nExtend rest api v1/v2 with comma separated sort keys.\nExample:\n/v1/images/detail?sort_key=name,id\nChanged database api which now takes sort_key param as a list instead of string\npython-glanceclient support will be added in separate commit\n\nChange-Id: Ib7a6aeb2df3bc5d23fe8e070290b5bfcab00c0f5\nDocImpact\nPartial-Bug: 1221274\n'}, {'number': 6, 'created': '2014-09-19 11:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/748c42994046440d21ce1ef4fb586bf899fcaed9', 'message': 'Adds the ability to sort images with multiple keys\n\nExtend rest api v1/v2 with comma separated sort keys.\nExample:\n/v1/images/detail?sort_key=name,id\nChanged database api which now takes sort_key param as a list instead of string\npython-glanceclient support will be added in separate commit\n\nChange-Id: Ib7a6aeb2df3bc5d23fe8e070290b5bfcab00c0f5\nDocImpact\nPartial-Bug: 1221274\n'}, {'number': 7, 'created': '2014-09-19 12:06:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/bcf966e7a9fab9c330b6abc5ef4a07bedd5c22ec', 'message': 'Adds the ability to sort images with multiple keys\n\nExtend rest api v1/v2 with comma separated sort keys.\nExample:\n/v1/images/detail?sort_key=name,id\nChanged database api which now takes sort_key param as a list instead of string\npython-glanceclient support will be added in separate commit\n\nChange-Id: Ib7a6aeb2df3bc5d23fe8e070290b5bfcab00c0f5\nDocImpact\nPartial-Bug: 1221274\n'}, {'number': 8, 'created': '2014-09-22 09:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/aabd33f90c02a8e39975b0ee098385a020d1373d', 'message': 'Adds the ability to sort images with multiple keys\n\nExtend rest api v2 with comma separated sort keys.\nExample:\n/v2/images/detail?sort_key=name,id\nChanged database api which now takes sort_key param as a list instead of string\npython-glanceclient support will be added in separate commit\n\nChange-Id: Ib7a6aeb2df3bc5d23fe8e070290b5bfcab00c0f5\nDocImpact\nPartial-Bug: 1221274\n'}, {'number': 9, 'created': '2014-09-22 10:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/141049899c5d5307cbc3495203fcdec5724fb3ab', 'message': 'Adds the ability to sort images with multiple keys\n\nExtend rest api v2 with comma separated sort keys.\nExample:\n/v2/images/detail?sort_key=name,id\nChanged database api which now takes sort_key param as a list instead of string\npython-glanceclient support will be added in separate commit\n\nChange-Id: Ib7a6aeb2df3bc5d23fe8e070290b5bfcab00c0f5\nDocImpact\nPartial-Bug: 1221274\n'}, {'number': 10, 'created': '2014-12-04 15:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b9cf9b072678003034c11580c57f92dddf29c1ed', 'message': 'Adds the ability to sort images with multiple keys\n\nExtend rest api v2 with comma separated sort keys.\nExample:\n/v2/images/detail?sort_key=name,id\nChanged database api which now takes sort_key param as a list instead of string\npython-glanceclient support will be added in separate commit\n\nChange-Id: Ib7a6aeb2df3bc5d23fe8e070290b5bfcab00c0f5\nDocImpact\nPartial-Bug: 1221274\n'}, {'number': 11, 'created': '2014-12-04 15:24:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/498ac0fd31f2e53245bff0d104b519d4844421de', 'message': 'Adds the ability to sort images with multiple keys\n\nExtend rest api v2 with comma separated sort keys.\nExample:\n/v2/images/detail?sort_key=name,id\nChanged database api which now takes sort_key param as a list instead of string\npython-glanceclient support will be added in separate commit\n\nChange-Id: Ib7a6aeb2df3bc5d23fe8e070290b5bfcab00c0f5\nDocImpact\nPartial-Bug: 1221274\n'}, {'number': 12, 'created': '2014-12-08 17:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8d6aca75c3c4416a220310ba49354464c91da2d2', 'message': 'Adds the ability to sort images with multiple keys\n\nExtend rest api v2 with multiple sort keys support.\nExample:\n/v2/images/detail?sort_key=name&sort_key=size\nChanged database api which now takes sort_key param as a list instead of string\npython-glanceclient support will be added in separate commit\n\nChange-Id: Ib7a6aeb2df3bc5d23fe8e070290b5bfcab00c0f5\nDocImpact\nPartial-Bug: 1221274\n'}, {'number': 13, 'created': '2014-12-08 17:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c424a0b56a34355469bf62bf98e71c7094d094a4', 'message': 'Adds the ability to sort images with multiple keys\n\nExtend rest api v2 with multiple sort keys support.\nExample:\n/v2/images/detail?sort_key=name&sort_key=size\nChanged database api which now takes sort_key param as a list instead of string\npython-glanceclient support will be added in separate commit\n\nChange-Id: Ib7a6aeb2df3bc5d23fe8e070290b5bfcab00c0f5\nDocImpact\nPartial-Bug: 1221274\n'}, {'number': 14, 'created': '2014-12-22 11:14:38.000000000', 'files': ['glance/registry/api/v1/images.py', 'glance/tests/functional/db/base.py', 'glance/db/simple/api.py', 'glance/tests/unit/v2/test_registry_client.py', 'glance/db/__init__.py', 'glance/db/sqlalchemy/api.py', 'glance/tests/unit/v2/test_images_resource.py', 'glance/tests/unit/v2/test_registry_api.py', 'glance/tests/unit/test_db.py', 'glance/api/v2/images.py', 'glance/tests/functional/db/test_sqlalchemy.py', 'glance/db/registry/api.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/2c3e3656b02a6f26c9fe98e95be103fe48015ae7', 'message': 'Adds the ability to sort images with multiple keys\n\nExtend rest api v2 with multiple sort keys support.\nExample:\n/v2/images/detail?sort_key=name&sort_key=size\nChanged database api which now takes sort_key param as a list instead of string\npython-glanceclient support will be added in separate commit\n\nChange-Id: Ib7a6aeb2df3bc5d23fe8e070290b5bfcab00c0f5\nDocImpact\nPartial-Bug: 1221274\n'}]",29,120727,2c3e3656b02a6f26c9fe98e95be103fe48015ae7,65,17,14,11391,,,0,"Adds the ability to sort images with multiple keys

Extend rest api v2 with multiple sort keys support.
Example:
/v2/images/detail?sort_key=name&sort_key=size
Changed database api which now takes sort_key param as a list instead of string
python-glanceclient support will be added in separate commit

Change-Id: Ib7a6aeb2df3bc5d23fe8e070290b5bfcab00c0f5
DocImpact
Partial-Bug: 1221274
",git fetch https://review.opendev.org/openstack/glance refs/changes/27/120727/12 && git format-patch -1 --stdout FETCH_HEAD,"['glance/registry/api/v1/images.py', 'glance/tests/functional/db/base.py', 'glance/tests/unit/v1/test_registry_api.py', 'glance/db/simple/api.py', 'glance/tests/unit/v2/test_registry_client.py', 'glance/tests/unit/v1/test_api.py', 'glance/db/__init__.py', 'glance/db/sqlalchemy/api.py', 'glance/tests/unit/v2/test_images_resource.py', 'glance/tests/unit/v2/test_registry_api.py', 'glance/tests/unit/v1/test_registry_client.py', 'glance/tests/unit/test_db.py', 'glance/api/v2/images.py', 'glance/tests/functional/db/test_sqlalchemy.py', 'glance/db/registry/api.py']",15,4fb80012f510ee8e417d3f9aae01e7146be7885a,bug/1221274," sort_key=['created_at'], sort_dir='desc',"," sort_key='created_at', sort_dir='desc',",354,57
openstack%2Ffuel-web~master~I4d82e29f93214eeb8c09e9b57b7653377fdf8903,openstack/fuel-web,master,I4d82e29f93214eeb8c09e9b57b7653377fdf8903,Code testing policy,MERGED,2014-12-16 08:26:09.000000000,2014-12-23 13:42:16.000000000,2014-12-23 13:42:16.000000000,"[{'_account_id': 3}, {'_account_id': 8053}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11082}, {'_account_id': 11577}, {'_account_id': 12200}, {'_account_id': 13082}, {'_account_id': 13445}, {'_account_id': 14342}]","[{'number': 1, 'created': '2014-12-16 08:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e43c4ca29c8b954bf986b9bcee1c283045ac8a37', 'message': 'Code testing policy\n\n  The rules must be followed by developers when summitting the unit\n  and integration tests\n\nChange-Id: I4d82e29f93214eeb8c09e9b57b7653377fdf8903\nImplements: bp/nailgun-code-testing-improvements\n'}, {'number': 2, 'created': '2014-12-16 08:30:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9320b927ecbf77e8ebb42e68c9b449da44b40854', 'message': 'Code testing policy\n\n  The rules must be followed by developers when summitting unit\n  and integration tests\n\nChange-Id: I4d82e29f93214eeb8c09e9b57b7653377fdf8903\nImplements: bp/nailgun-code-testing-improvements\n'}, {'number': 3, 'created': '2014-12-17 09:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7bad2e6282ec1e699fac6210442424736ccbbc96', 'message': 'Code testing policy\n\n  The rules must be followed by developers when summitting unit\n  and integration tests\n\nChange-Id: I4d82e29f93214eeb8c09e9b57b7653377fdf8903\nImplements: blueprint nailgun-code-testing-improvements\n'}, {'number': 4, 'created': '2014-12-17 13:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/aa3c5f1169e372f0be2c4893d5322e3f5231712f', 'message': 'Code testing policy\n\n  The rules must be followed by developers when summitting unit\n  and integration tests\n\nChange-Id: I4d82e29f93214eeb8c09e9b57b7653377fdf8903\nImplements: blueprint nailgun-code-testing-improvements\n'}, {'number': 5, 'created': '2014-12-17 21:33:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d33d9bcbe91667ce067836800d3d42f1901bfd72', 'message': 'Code testing policy\n\n  The rules must be followed by developers when summitting unit\n  and integration tests\n\nChange-Id: I4d82e29f93214eeb8c09e9b57b7653377fdf8903\nImplements: blueprint nailgun-code-testing-improvements\n'}, {'number': 6, 'created': '2014-12-17 21:42:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/aff54fe0f1b631f41c21fd2dd1846cf09289217d', 'message': 'Code testing policy\n\n  The rules must be followed by developers when summitting unit\n  and integration tests\n\nChange-Id: I4d82e29f93214eeb8c09e9b57b7653377fdf8903\nImplements: blueprint nailgun-code-testing-improvements\n'}, {'number': 7, 'created': '2014-12-19 14:40:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9937c0795408c164d0368002b291906ed0da5fab', 'message': 'Code testing policy\n\n  The rules must be followed by developers when submitting unit\n  and integration tests\n\nChange-Id: I4d82e29f93214eeb8c09e9b57b7653377fdf8903\nImplements: blueprint nailgun-code-testing-improvements\n'}, {'number': 8, 'created': '2014-12-19 14:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/61963c1f7c36b7b660ffc28a2e75cc0efa3663e3', 'message': 'Code testing policy\n\n  The rules must be followed by developers when submitting unit\n  and integration tests\n\nChange-Id: I4d82e29f93214eeb8c09e9b57b7653377fdf8903\nImplements: blueprint nailgun-code-testing-improvements\n'}, {'number': 9, 'created': '2014-12-19 16:23:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e166ddf9081ab4e1a00712974ea05b89fd50bc08', 'message': 'Code testing policy\n\n  The rules must be followed by developers when submitting unit\n  and integration tests\n\nChange-Id: I4d82e29f93214eeb8c09e9b57b7653377fdf8903\nImplements: blueprint nailgun-code-testing-improvements\n'}, {'number': 10, 'created': '2014-12-19 16:52:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/89f120fe4810c649d3168700cd97110d91aab5b1', 'message': 'Code testing policy\n\n  The rules must be followed by developers when submitting unit\n  and integration tests\n\nChange-Id: I4d82e29f93214eeb8c09e9b57b7653377fdf8903\nImplements: blueprint nailgun-code-testing-improvements\n'}, {'number': 11, 'created': '2014-12-22 12:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d36bdb5897b5eded0355c82fbf76a16f92d41543', 'message': 'Code testing policy\n\n  The rules must be followed by developers when submitting unit\n  and integration tests\n\nChange-Id: I4d82e29f93214eeb8c09e9b57b7653377fdf8903\nImplements: blueprint nailgun-code-testing-improvements\n'}, {'number': 12, 'created': '2014-12-22 13:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/de6d078884dcc0dbc7ae28014d45977d4ae0bedd', 'message': 'Code testing policy\n\n  The rules must be followed by developers when submitting unit\n  and integration tests\n\nChange-Id: I4d82e29f93214eeb8c09e9b57b7653377fdf8903\nImplements: blueprint nailgun-code-testing-improvements\n'}, {'number': 13, 'created': '2014-12-22 14:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b5f8172ff1f13377ef1dd3db07fe04d09cb39b55', 'message': 'Code testing policy\n\n  The rules must be followed by developers when submitting unit\n  and integration tests\n\nChange-Id: I4d82e29f93214eeb8c09e9b57b7653377fdf8903\nImplements: blueprint nailgun-code-testing-improvements\n'}, {'number': 14, 'created': '2014-12-23 10:15:11.000000000', 'files': ['docs/develop/nailgun/tree.rst', 'docs/develop/nailgun/development/code_testing.rst', 'nailgun/nailgun/db/api.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f9ebcd8d94cee06d34888f2af408b5d78bcefff3', 'message': 'Code testing policy\n\n  The rules must be followed by developers when submitting unit\n  and integration tests\n\nChange-Id: I4d82e29f93214eeb8c09e9b57b7653377fdf8903\nImplements: blueprint nailgun-code-testing-improvements\n'}]",61,142023,f9ebcd8d94cee06d34888f2af408b5d78bcefff3,112,16,14,11577,,,0,"Code testing policy

  The rules must be followed by developers when submitting unit
  and integration tests

Change-Id: I4d82e29f93214eeb8c09e9b57b7653377fdf8903
Implements: blueprint nailgun-code-testing-improvements
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/23/142023/4 && git format-patch -1 --stdout FETCH_HEAD,"['docs/develop/nailgun/tree.rst', 'docs/develop/nailgun/development/code_testing.rst', 'nailgun/nailgun/db/api.py']",3,e43c4ca29c8b954bf986b9bcee1c283045ac8a37,bp/nailgun-code-testing-improvements,,"# -*- coding: utf-8 -*- # Copyright 2013 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. ",97,16
openstack%2Ffuel-main~stable%2F6.0~If1edfeb774d6ef19f59651010d0dc696f3b8d59f,openstack/fuel-main,stable/6.0,If1edfeb774d6ef19f59651010d0dc696f3b8d59f,Update Murano testing settings,MERGED,2014-12-22 16:51:27.000000000,2014-12-23 13:25:10.000000000,2014-12-23 13:25:09.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 6719}, {'_account_id': 7227}, {'_account_id': 8782}, {'_account_id': 8882}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-22 16:51:27.000000000', 'files': ['fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/27b37934cc0ba29c49d244c840ed1db1769ebfce', 'message': 'Update Murano testing settings\n\nFixed incorrect Murano image name and md5 sum in settings.\n\nChange-Id: If1edfeb774d6ef19f59651010d0dc696f3b8d59f\nCloses-bug: #1404915\n'}]",0,143494,27b37934cc0ba29c49d244c840ed1db1769ebfce,9,7,1,13962,,,0,"Update Murano testing settings

Fixed incorrect Murano image name and md5 sum in settings.

Change-Id: If1edfeb774d6ef19f59651010d0dc696f3b8d59f
Closes-bug: #1404915
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/94/143494/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/settings.py'],1,27b37934cc0ba29c49d244c840ed1db1769ebfce,bug/1404915,"SERVTEST_MURANO_IMAGE = ""ubuntu_14_04-murano-agent_stable_juno.qcow2"" SERVTEST_MURANO_IMAGE_MD5 = '9f562f3f577dc32698c11a99d3f15070'","SERVTEST_MURANO_IMAGE = ""cloud-fedora.qcow2"" SERVTEST_MURANO_IMAGE_MD5 = '6e5e2f149c54b898b3c272f11ae31125'",2,2
openstack%2Ffuel-main~master~I59186e5deb34dda01f04dba13330824a547b820d,openstack/fuel-main,master,I59186e5deb34dda01f04dba13330824a547b820d,Update Murano testing settings,MERGED,2014-12-22 16:27:12.000000000,2014-12-23 13:24:02.000000000,2014-12-23 13:24:01.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 6719}, {'_account_id': 7227}, {'_account_id': 8782}, {'_account_id': 8882}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-22 16:27:12.000000000', 'files': ['fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/31e2304462837caff47b58d972eadbbd0f821ddf', 'message': 'Update Murano testing settings\n\nFixed incorrect Murano image name and md5 sum in settings.\n\nChange-Id: I59186e5deb34dda01f04dba13330824a547b820d\nPartial-bug: #1404915\n'}]",0,143481,31e2304462837caff47b58d972eadbbd0f821ddf,9,7,1,13962,,,0,"Update Murano testing settings

Fixed incorrect Murano image name and md5 sum in settings.

Change-Id: I59186e5deb34dda01f04dba13330824a547b820d
Partial-bug: #1404915
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/81/143481/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/settings.py'],1,31e2304462837caff47b58d972eadbbd0f821ddf,bug/1404915,"SERVTEST_MURANO_IMAGE = ""ubuntu_14_04-murano-agent_stable_juno.qcow2"" SERVTEST_MURANO_IMAGE_MD5 = '9f562f3f577dc32698c11a99d3f15070'","SERVTEST_MURANO_IMAGE = ""cloud-fedora.qcow2"" SERVTEST_MURANO_IMAGE_MD5 = '6e5e2f149c54b898b3c272f11ae31125'",2,2
openstack%2Fopenstack-manuals~master~I3032c8e867d3e367004907da8d8479dc61beca66,openstack/openstack-manuals,master,I3032c8e867d3e367004907da8d8479dc61beca66,Allow guest remote access to rabbitmq,MERGED,2014-12-19 07:51:30.000000000,2014-12-23 13:03:54.000000000,2014-12-23 13:03:52.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 4460}, {'_account_id': 6547}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-12-19 07:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/90afd423cff999066e9d04c193fe87342bb547b0', 'message': 'Allow guest remote access to rabbitmq\n\nSince RabbitMQ version 3.3.0, the guest user has no remote access,\nenable it.\n\nChange-Id: I3032c8e867d3e367004907da8d8479dc61beca66\nCloses-Bug: #1390419\n'}, {'number': 2, 'created': '2014-12-23 07:28:48.000000000', 'files': ['doc/install-guide/section_basics-queue.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/69c9c65daeda311b7ccf28f8cce480e9fc63f723', 'message': 'Allow guest remote access to rabbitmq\n\nSince RabbitMQ version 3.3.0, the guest user has no remote access,\ndocument how to enable it for SUSE distros.\n\nBackport: juno\nChange-Id: I3032c8e867d3e367004907da8d8479dc61beca66\nCloses-Bug: #1390419\n'}]",0,143006,69c9c65daeda311b7ccf28f8cce480e9fc63f723,17,5,2,6547,,,0,"Allow guest remote access to rabbitmq

Since RabbitMQ version 3.3.0, the guest user has no remote access,
document how to enable it for SUSE distros.

Backport: juno
Change-Id: I3032c8e867d3e367004907da8d8479dc61beca66
Closes-Bug: #1390419
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/06/143006/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_basics-queue.xml'],1,90afd423cff999066e9d04c193fe87342bb547b0,bug/1390419," <step> <para> If you are running RabbitMQ version 3.3.0 or higher, you need to allow remote connection of the guest user as well. Edit <filename>/etc/rabbitmq/rabbitmq.config</filename> and add or uncomment this line: <programlisting>{loopback_users, []}</programlisting> </para> </step>",,9,0
openstack%2Ffuel-library~master~I67d045e751c8d39df6237bcaeb315f7af12a1894,openstack/fuel-library,master,I67d045e751c8d39df6237bcaeb315f7af12a1894,Added parameters for availability zones configuration,MERGED,2014-12-22 16:45:04.000000000,2014-12-23 12:39:49.000000000,2014-12-23 12:39:48.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 11427}, {'_account_id': 12139}]","[{'number': 1, 'created': '2014-12-22 16:45:04.000000000', 'files': ['deployment/puppet/nova/manifests/compute.pp', 'deployment/puppet/nova/spec/classes/nova_compute_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5c2d436459d59ffb123cb3f34858cb3f606012ad', 'message': 'Added parameters for availability zones configuration\n\nFor configuration availability zones for nova-compute\nthe corresponding options have been added.\n\nUpstream patch id: I284ebd9db3b5b7c5e9218621b516cf045e5d1375\nImplements: blueprint availability-zones\n\nChange-Id: I67d045e751c8d39df6237bcaeb315f7af12a1894\n'}]",0,143490,5c2d436459d59ffb123cb3f34858cb3f606012ad,15,9,1,12139,,,0,"Added parameters for availability zones configuration

For configuration availability zones for nova-compute
the corresponding options have been added.

Upstream patch id: I284ebd9db3b5b7c5e9218621b516cf045e5d1375
Implements: blueprint availability-zones

Change-Id: I67d045e751c8d39df6237bcaeb315f7af12a1894
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/90/143490/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/nova/manifests/compute.pp', 'deployment/puppet/nova/spec/classes/nova_compute_spec.rb']",2,5c2d436459d59ffb123cb3f34858cb3f606012ad,bp/availability-zones," { :enabled => true, :ensure_package => '2012.1-2', :vncproxy_host => '127.0.0.1', :network_device_mtu => 9999, :default_availability_zone => 'az1', :default_schedule_zone => 'az2', :internal_service_availability_zone => 'az_int1', } it 'configures availability zones' do should contain_nova_config('DEFAULT/default_availability_zone').with_value('az1') should contain_nova_config('DEFAULT/default_schedule_zone').with_value('az2') should contain_nova_config('DEFAULT/internal_service_availability_zone').with_value('az_int1') end"," { :enabled => true, :ensure_package => '2012.1-2', :vncproxy_host => '127.0.0.1', :network_device_mtu => 9999 }",62,19
openstack%2Fglance~master~I0cf58ad198375a2f6f58bd7820cbb9d86003247a,openstack/glance,master,I0cf58ad198375a2f6f58bd7820cbb9d86003247a,Add sort key validation in v2 api,MERGED,2014-12-08 13:26:50.000000000,2014-12-23 12:07:50.000000000,2014-12-23 12:07:49.000000000,"[{'_account_id': 3}, {'_account_id': 6484}, {'_account_id': 8127}, {'_account_id': 8158}, {'_account_id': 11391}]","[{'number': 1, 'created': '2014-12-08 13:26:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/121e15e80b0bb8a7394c0c99919667a5d44a1deb', 'message': ""Add sort key validation in v2 api\n\nSince v2 api has no sort key validation it was possible to request\nsomething like /images?sort_key=blah and it was fine.\nThis code validates input parameters and raises an exception if\nparameter's not correct.\n\nChange-Id: I0cf58ad198375a2f6f58bd7820cbb9d86003247a\n""}, {'number': 2, 'created': '2014-12-08 15:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/03ab5afa83cf4137ad9f94c4725c220f924ad293', 'message': ""Add sort key validation in v2 api\n\nSince v2 api has no sort key validation it was possible to request\nsomething like /images?sort_key=checksum, which is api violation,\nsince it's deprecated to sort by private fields.\n\nThis code validates input parameters and raises an exception if\nparameter's not correct.\n\nCloses-bug:1400366\n\nChange-Id: I0cf58ad198375a2f6f58bd7820cbb9d86003247a\n""}, {'number': 3, 'created': '2014-12-08 15:53:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f1df764a1ee3d89d39fc811352facc2f6284cd66', 'message': ""Add sort key validation in v2 api\n\nSince v2 api has no sort key validation it's possible to request\nsomething like /images?sort_key=checksum, which is api violation,\nsince it's deprecated to sort by private fields.\n\nThis code validates input parameters and raises an exception if\nparameter's not correct.\n\nCloses-bug:1400366\n\nChange-Id: I0cf58ad198375a2f6f58bd7820cbb9d86003247a\n""}, {'number': 4, 'created': '2014-12-08 17:55:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/55726fa3abb5f93a117ab5db6217425e59556b61', 'message': ""Add sort key validation in v2 api\n\nSince v2 api has no sort key validation it's possible to request\nsomething like /images?sort_key=checksum, which is api violation,\nsince it's deprecated to sort by private fields.\n\nThis code validates input parameters and raises an exception if\nparameter's not correct.\n\nCloses-bug: 1400366\n\nChange-Id: I0cf58ad198375a2f6f58bd7820cbb9d86003247a\n""}, {'number': 5, 'created': '2014-12-18 13:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/54d695bce02e0a0d2daf9d261bc48a4f65459ef2', 'message': ""Add sort key validation in v2 api\n\nSince v2 api has no sort key validation and the default \npagination check is used it's possible to request something\nlike /images?sort_key=_sa_class_manager, which causes an \ninner SQL exception with 500 response code from the server.\n\nThis code validates input sort key and raises an exception\nif the parameter is out of the supported keys list.\n\nCloses-bug: 1400366\n\nChange-Id: I0cf58ad198375a2f6f58bd7820cbb9d86003247a\n""}, {'number': 6, 'created': '2014-12-22 10:49:56.000000000', 'files': ['glance/api/v2/images.py', 'glance/tests/unit/v2/test_images_resource.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/f9820a25d38584fdcc9ffde44de6ec146b6de4fb', 'message': ""Add sort key validation in v2 api\n\nSince v2 api has no sort key validation and the default\npagination check is used it's possible to request something\nlike /images?sort_key=_sa_class_manager, which causes an\ninner SQL exception with 500 response code from the server.\n\nThis code validates input sort key and raises an exception\nif the parameter is out of the supported keys list.\n\nCloses-bug: 1400366\n\nChange-Id: I0cf58ad198375a2f6f58bd7820cbb9d86003247a\n""}]",17,139996,f9820a25d38584fdcc9ffde44de6ec146b6de4fb,37,5,6,11391,,,0,"Add sort key validation in v2 api

Since v2 api has no sort key validation and the default
pagination check is used it's possible to request something
like /images?sort_key=_sa_class_manager, which causes an
inner SQL exception with 500 response code from the server.

This code validates input sort key and raises an exception
if the parameter is out of the supported keys list.

Closes-bug: 1400366

Change-Id: I0cf58ad198375a2f6f58bd7820cbb9d86003247a
",git fetch https://review.opendev.org/openstack/glance refs/changes/96/139996/3 && git format-patch -1 --stdout FETCH_HEAD,"['glance/api/v2/images.py', 'glance/tests/unit/v2/test_images_resource.py']",2,121e15e80b0bb8a7394c0c99919667a5d44a1deb,bug/1400366," def test_index_sort_key_bad_value(self): request = unit_test_utils.get_fake_request('/images?sort_key=blah') self.assertRaises(webob.exc.HTTPBadRequest, self.deserializer.index, request) ",,16,1
openstack%2Fglance~master~Idbf8779cdfc41ca1424bebcd101096bec482872f,openstack/glance,master,Idbf8779cdfc41ca1424bebcd101096bec482872f,"Replace '_' with '_LI', '_LE', '_LW', '_LC'",MERGED,2014-12-16 10:49:30.000000000,2014-12-23 12:07:04.000000000,2014-12-23 12:07:02.000000000,"[{'_account_id': 3}, {'_account_id': 5202}, {'_account_id': 8127}, {'_account_id': 8158}, {'_account_id': 9382}, {'_account_id': 10300}, {'_account_id': 11391}, {'_account_id': 12807}, {'_account_id': 14082}]","[{'number': 1, 'created': '2014-12-16 10:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d89c3fcb311493a206afdff11811975d62aadf78', 'message': 'Replace \'_\' with \'_LI\', \'_LE\', \'_LW\', \'_LC\'\n\noslo.i18n uses different marker functions to separate the\ntranslatable messages into different catalogs, which the translation\nteams can prioritize translating. For details, please refer to:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html#guidelines-for-use-in-openstack\n\nAdded hacking rules for warning, info, critical, error and exception\nabout checking translation for log messages and fixed for below cases only,\n1. LOG.error(_(""""))\n2. LOG.info(_(""""))\n3. LOG.exception(_(""""))\n4. LOG.critical(_(""""))\n5. LOG.warning(_(""""))\n\nBelow scenario is not handled in this patch,\nIf message is passed to LOG call using separate variable,\nex.\n    msg = (_("""")\n    LOG.error(msg)\n\nChange-Id: Idbf8779cdfc41ca1424bebcd101096bec482872f\n'}, {'number': 2, 'created': '2014-12-19 10:44:15.000000000', 'files': ['glance/common/location_strategy/__init__.py', 'glance/common/wsgi.py', 'glance/common/swift_store_utils.py', 'tools/migrate_image_owners.py', 'glance/common/property_utils.py', 'glance/hacking/checks.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/glance/commit/6eebebc80b2c67e7ae7450233d407fd4f9047ca2', 'message': 'Replace \'_\' with \'_LI\', \'_LE\', \'_LW\', \'_LC\'\n\noslo.i18n uses different marker functions to separate the\ntranslatable messages into different catalogs, which the translation\nteams can prioritize translating. For details, please refer to:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html#guidelines-for-use-in-openstack\n\nAdded hacking rules for warning, info, critical, error and exception\nabout checking translation for log messages and fixed for below cases only,\n1. LOG.error(_(""""))\n2. LOG.info(_(""""))\n3. LOG.exception(_(""""))\n4. LOG.critical(_(""""))\n5. LOG.warning(_(""""))\n\nBelow scenario is not handled in this patch,\nIf message is passed to LOG call using separate variable,\nex.\n    msg = (_("""")\n    LOG.error(msg)\n\nChange-Id: Idbf8779cdfc41ca1424bebcd101096bec482872f\n'}]",12,142059,6eebebc80b2c67e7ae7450233d407fd4f9047ca2,22,9,2,10300,,,0,"Replace '_' with '_LI', '_LE', '_LW', '_LC'

oslo.i18n uses different marker functions to separate the
translatable messages into different catalogs, which the translation
teams can prioritize translating. For details, please refer to:
http://docs.openstack.org/developer/oslo.i18n/guidelines.html#guidelines-for-use-in-openstack

Added hacking rules for warning, info, critical, error and exception
about checking translation for log messages and fixed for below cases only,
1. LOG.error(_(""""))
2. LOG.info(_(""""))
3. LOG.exception(_(""""))
4. LOG.critical(_(""""))
5. LOG.warning(_(""""))

Below scenario is not handled in this patch,
If message is passed to LOG call using separate variable,
ex.
    msg = (_("""")
    LOG.error(msg)

Change-Id: Idbf8779cdfc41ca1424bebcd101096bec482872f
",git fetch https://review.opendev.org/openstack/glance refs/changes/59/142059/2 && git format-patch -1 --stdout FETCH_HEAD,"['glance/common/location_strategy/__init__.py', 'glance/common/wsgi.py', 'glance/common/swift_store_utils.py', 'tools/migrate_image_owners.py', 'glance/common/property_utils.py', 'glance/hacking/checks.py', 'HACKING.rst']",7,d89c3fcb311493a206afdff11811975d62aadf78,Log_Translation,"- [G321] Validate that LOG messages, except debug ones, have translations - [G322] Validate that LOG.info messages use _LI. - [G323] Validate that LOG.exception messages use _LE. - [G324] Validate that LOG.error messages use _LE. - [G325] Validate that LOG.critical messages use _LC. - [G326] Validate that LOG.warning messages use _LW.",,76,19
openstack%2Frequirements~stable%2Ficehouse~Icfb2b7373a90a76874e8e8eab7c2591f41146689,openstack/requirements,stable/icehouse,Icfb2b7373a90a76874e8e8eab7c2591f41146689,Remove ironic-python-agent from icehouse projects,MERGED,2014-12-19 03:52:34.000000000,2014-12-23 12:06:32.000000000,2014-12-23 12:06:31.000000000,"[{'_account_id': 3}, {'_account_id': 24}, {'_account_id': 308}, {'_account_id': 979}, {'_account_id': 1420}, {'_account_id': 1561}, {'_account_id': 1955}, {'_account_id': 2750}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-12-19 03:52:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/9507d2a088a4f387c7af479e772ee94dc85c06d6', 'message': 'Add oslo.concurrency to icehouse dependencies\n\nThe check job for the icehouse requirements integration test installs\nironic-python-agent which depends upon oslo.concurrency. This is not\navailable in the icehouse requirements and therefore the check job\nfails.\n\nChange-Id: Icfb2b7373a90a76874e8e8eab7c2591f41146689\n'}, {'number': 2, 'created': '2014-12-22 22:58:26.000000000', 'files': ['projects.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/fc58ba4ec656de25453a16bec6406a97c980cc93', 'message': ""Remove ironic-python-agent from icehouse projects\n\nIronic-python-agent wasn't available during the icehouse cycle. As it\ndoes not have a icehouse branch the newest version is being retrieved\nwhich has dependencies not present in the icehouse requirements list and\nso the integration jobs are failing.\n\nChange-Id: Icfb2b7373a90a76874e8e8eab7c2591f41146689\n""}]",0,142974,fc58ba4ec656de25453a16bec6406a97c980cc93,10,9,2,7191,,,0,"Remove ironic-python-agent from icehouse projects

Ironic-python-agent wasn't available during the icehouse cycle. As it
does not have a icehouse branch the newest version is being retrieved
which has dependencies not present in the icehouse requirements list and
so the integration jobs are failing.

Change-Id: Icfb2b7373a90a76874e8e8eab7c2591f41146689
",git fetch https://review.opendev.org/openstack/requirements refs/changes/74/142974/2 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,9507d2a088a4f387c7af479e772ee94dc85c06d6,concurrency,oslo.concurrency>=0.3.0 # Apache-2.0,,1,0
openstack%2Fheat-translator~master~I12892b72f6b05b9b26ee1694c8d144e6beade524,openstack/heat-translator,master,I12892b72f6b05b9b26ee1694c8d144e6beade524,Rename TOSCA node property relationship to relationships,MERGED,2014-12-21 04:03:59.000000000,2014-12-23 11:26:56.000000000,2014-12-23 11:26:55.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 6460}, {'_account_id': 7193}, {'_account_id': 11355}]","[{'number': 1, 'created': '2014-12-21 04:03:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/88af1ad1f41751b8d27c639dc20d1b16ae663cbb', 'message': 'Rename TOSCA node property relationship to relationships\n\nTOSCA node template can have multiple relationships so property name\nproviding relationship should be plural.\n\nChange-Id: I12892b72f6b05b9b26ee1694c8d144e6beade524\nclose-Bug: #1404109\n'}, {'number': 2, 'created': '2014-12-21 04:06:13.000000000', 'files': ['translator/toscalib/nodetemplate.py', 'translator/hot/translate_node_templates.py', 'translator/toscalib/tpl_relationship_graph.py', 'translator/toscalib/tests/test_toscatpl.py'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/2933ff038e4524b7d2a49487f4b6d826ab73f6a5', 'message': 'Rename TOSCA node property relationship to relationships\n\nTOSCA node template can have multiple relationships so property name\nproviding relationship should be plural.\n\nCloses-Bug: #1404109\n\nChange-Id: I12892b72f6b05b9b26ee1694c8d144e6beade524\n'}]",0,143286,2933ff038e4524b7d2a49487f4b6d826ab73f6a5,12,5,2,6456,,,0,"Rename TOSCA node property relationship to relationships

TOSCA node template can have multiple relationships so property name
providing relationship should be plural.

Closes-Bug: #1404109

Change-Id: I12892b72f6b05b9b26ee1694c8d144e6beade524
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/86/143286/2 && git format-patch -1 --stdout FETCH_HEAD,"['translator/toscalib/nodetemplate.py', 'translator/hot/translate_node_templates.py', 'translator/toscalib/tpl_relationship_graph.py', 'translator/toscalib/tests/test_toscatpl.py']",4,88af1ad1f41751b8d27c639dc20d1b16ae663cbb,bug1404109," [x.type for x in tpl.relationships.keys()]) [y.name for y in tpl.relationships.values()]) relation = node_tpl.relationships relation, node in node_tpl.relationships.items()]) node in node_tpl.relationships.items()]) node in node_tpl.relationships.items()]) lambda: NodeTemplate(tpl_name, nodetemplates).relationships)"," [x.type for x in tpl.relationship.keys()]) [y.name for y in tpl.relationship.values()]) relation = node_tpl.relationship relation, node in node_tpl.relationship.items()]) node in node_tpl.relationship.items()]) node in node_tpl.relationship.items()]) lambda: NodeTemplate(tpl_name, nodetemplates).relationship)",11,11
openstack%2Fneutron~master~I414c7b4497f59927d8b6ec5f057dca19aa4ef122,openstack/neutron,master,I414c7b4497f59927d8b6ec5f057dca19aa4ef122,ml2: remove superfluous %s in LOG.debug() format,MERGED,2014-12-22 03:53:51.000000000,2014-12-23 10:53:56.000000000,2014-12-23 10:53:55.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1653}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10980}, {'_account_id': 11822}, {'_account_id': 12040}, {'_account_id': 12860}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-22 03:53:51.000000000', 'files': ['neutron/plugins/ml2/db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e3492286ca247c2f910d073044dd2b9c5387d150', 'message': 'ml2: remove superfluous %s in LOG.debug() format\n\nml2.db.get_dynamic_segment() includes this line:\n\n   LOG.debug(""No dynamic segment %s found for ""\n\t     ""Network:%(network_id)s, ""\n\t     ""Physical network:%(physnet)s, ""\n\t     ""segmentation_id:%(segmentation_id)s"",\n\t     {\'network_id\': network_id,\n\t      \'physnet\': physical_network,\n\t      \'segmentation_id\': segmentation_id})\n\nNote the superfluous %s in the format string.  At run-time, %s prints\nthe args hash again and doesn\'t cause an error, but this is clearly\nunintended.\n\nSince there doesn\'t seem to be any value that was meant to be used\ninstead, this change simply removes the %s.\n\nChange-Id: I414c7b4497f59927d8b6ec5f057dca19aa4ef122\nCloses-Bug: #1404782\n'}]",0,143352,e3492286ca247c2f910d073044dd2b9c5387d150,39,26,1,11279,,,0,"ml2: remove superfluous %s in LOG.debug() format

ml2.db.get_dynamic_segment() includes this line:

   LOG.debug(""No dynamic segment %s found for ""
	     ""Network:%(network_id)s, ""
	     ""Physical network:%(physnet)s, ""
	     ""segmentation_id:%(segmentation_id)s"",
	     {'network_id': network_id,
	      'physnet': physical_network,
	      'segmentation_id': segmentation_id})

Note the superfluous %s in the format string.  At run-time, %s prints
the args hash again and doesn't cause an error, but this is clearly
unintended.

Since there doesn't seem to be any value that was meant to be used
instead, this change simply removes the %s.

Change-Id: I414c7b4497f59927d8b6ec5f057dca19aa4ef122
Closes-Bug: #1404782
",git fetch https://review.opendev.org/openstack/neutron refs/changes/52/143352/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/db.py'],1,e3492286ca247c2f910d073044dd2b9c5387d150,bug/1404782," LOG.debug(""No dynamic segment found for """," LOG.debug(""No dynamic segment %s found for """,1,1
openstack%2Ftrove~master~I2a7d4c41ce77d6375fa08033514baa815a087016,openstack/trove,master,I2a7d4c41ce77d6375fa08033514baa815a087016,Obsolete oslo-incubator modules - jsonutils (now oslo.serialization),MERGED,2014-10-20 16:37:27.000000000,2014-12-23 10:51:36.000000000,2014-12-23 10:51:35.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 1925}, {'_account_id': 4240}, {'_account_id': 4463}, {'_account_id': 5293}, {'_account_id': 6159}, {'_account_id': 6268}, {'_account_id': 6413}, {'_account_id': 6610}, {'_account_id': 7092}, {'_account_id': 7796}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 9683}, {'_account_id': 9746}, {'_account_id': 9782}, {'_account_id': 10215}, {'_account_id': 10266}, {'_account_id': 10295}, {'_account_id': 10725}, {'_account_id': 12673}, {'_account_id': 13355}]","[{'number': 1, 'created': '2014-10-20 16:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/c2682d7c1b5815777296cecdfb2ae29db3287202', 'message': 'Obsolete oslo-incubator modules - jsonutils (now oslo.serialization)\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This commit handles the jsonutils module which\nis now oslo.serialization.jsonutils. The change here is to remove it\nfrom openstack-common.conf and point all people who used to use that\nat oslo.serialization. requirements.txt has been updated to point to\nthis dependency.\n\nChange-Id: I2a7d4c41ce77d6375fa08033514baa815a087016\nPartial-Bug: #1380789\nblueprint: retire-unused-trove-modules\n'}, {'number': 2, 'created': '2014-10-20 17:09:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/afa890aead4d0af69b0b3c36be0f578aec0edbfa', 'message': 'Obsolete oslo-incubator modules - jsonutils (now oslo.serialization)\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This commit handles the jsonutils module which\nis now oslo.serialization.jsonutils. The change here is to remove it\nfrom openstack-common.conf and point all people who used to use that\nat oslo.serialization. requirements.txt has been updated to point to\nthis dependency.\n\nChange-Id: I2a7d4c41ce77d6375fa08033514baa815a087016\nPartial-Bug: #1380789\nblueprint: retire-unused-trove-modules\n'}, {'number': 3, 'created': '2014-10-20 21:35:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8c5711dc8c7334d0a4aaec48be5317b0b4fc1717', 'message': 'Obsolete oslo-incubator modules - jsonutils (now oslo.serialization)\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This commit handles the jsonutils module which\nis now oslo.serialization.jsonutils. The change here is to remove it\nfrom openstack-common.conf and point all people who used to use that\nat oslo.serialization. requirements.txt has been updated to point to\nthis dependency.\n\nChange-Id: I2a7d4c41ce77d6375fa08033514baa815a087016\nPartial-Bug: #1380789\nblueprint: retire-unused-trove-modules\n'}, {'number': 4, 'created': '2014-10-21 01:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/bf721bce32a8ce34cf5f1094b8c2ed40cccb6933', 'message': 'Obsolete oslo-incubator modules - jsonutils (now oslo.serialization)\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This commit handles the jsonutils module which\nis now oslo.serialization.jsonutils. The change here is to remove it\nfrom openstack-common.conf and point all people who used to use that\nat oslo.serialization. requirements.txt has been updated to point to\nthis dependency.\n\nChange-Id: I2a7d4c41ce77d6375fa08033514baa815a087016\nPartial-Bug: #1380789\nblueprint: retire-unused-trove-modules\n'}, {'number': 5, 'created': '2014-10-21 16:40:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/93fa1c0bbc97017360ab3e5385a80625fff9dc94', 'message': 'Obsolete oslo-incubator modules - jsonutils (now oslo.serialization)\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This commit handles the jsonutils module which\nis now oslo.serialization.jsonutils. The change here is to remove it\nfrom openstack-common.conf and point all people who used to use that\nat oslo.serialization. requirements.txt has been updated to point to\nthis dependency.\n\nChange-Id: I2a7d4c41ce77d6375fa08033514baa815a087016\nPartial-Bug: #1380789\nblueprint: retire-unused-trove-modules\n'}, {'number': 6, 'created': '2014-11-05 15:54:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a89d12c1d0354638f704768a4b0c8142976ab287', 'message': 'Obsolete oslo-incubator modules - jsonutils (now oslo.serialization)\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This commit handles the jsonutils module which\nis now oslo.serialization.jsonutils. The change here is to remove it\nfrom openstack-common.conf and point all people who used to use that\nat oslo.serialization. requirements.txt has been updated to point to\nthis dependency.\n\nChange-Id: I2a7d4c41ce77d6375fa08033514baa815a087016\nPartial-Bug: #1380789\nblueprint: retire-unused-trove-modules\n'}, {'number': 7, 'created': '2014-11-07 20:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/08d8ba0d8bf8649341130e36eb7b3a24b42aad7b', 'message': 'Obsolete oslo-incubator modules - jsonutils (now oslo.serialization)\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This commit handles the jsonutils module which\nis now oslo.serialization.jsonutils. The change here is to remove it\nfrom openstack-common.conf and point all people who used to use that\nat oslo.serialization. requirements.txt has been updated to point to\nthis dependency.\n\nThe file jsonutils.py is not being deleted because of dependencies in\noslo-incubator.\n\nChange-Id: I2a7d4c41ce77d6375fa08033514baa815a087016\nPartial-Bug: #1380789\nblueprint: retire-unused-trove-modules\n'}, {'number': 8, 'created': '2014-11-10 12:41:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a4a8b6b61ce128498e213651cf8d4f44f450704b', 'message': 'Obsolete oslo-incubator modules - jsonutils (now oslo.serialization)\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This commit handles the jsonutils module which\nis now oslo.serialization.jsonutils. The change here is to remove it\nfrom openstack-common.conf and point all people who used to use that\nat oslo.serialization. requirements.txt has been updated to point to\nthis dependency.\n\nThe file jsonutils.py is not being deleted because of dependencies in\noslo-incubator.\n\nChange-Id: I2a7d4c41ce77d6375fa08033514baa815a087016\nPartial-Bug: #1380789\nblueprint: retire-unused-trove-modules\n'}, {'number': 9, 'created': '2014-11-10 12:45:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ed2954a1c1a10b859381a792b61ee26460801c75', 'message': 'Obsolete oslo-incubator modules - jsonutils (now oslo.serialization)\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This commit handles the jsonutils module which\nis now oslo.serialization.jsonutils. The change here is to remove it\nfrom openstack-common.conf and point all people who used to use that\nat oslo.serialization. requirements.txt has been updated to point to\nthis dependency.\n\nThe file jsonutils.py is not being deleted because of dependencies in\noslo-incubator.\n\nChange-Id: I2a7d4c41ce77d6375fa08033514baa815a087016\nPartial-Bug: #1380789\nblueprint: retire-unused-oslo-incubator-modules'}, {'number': 10, 'created': '2014-12-04 16:14:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/60957e1b7a6b5cdcda0d74c5cfb965f67bd705d4', 'message': 'Obsolete oslo-incubator modules - jsonutils (now oslo.serialization)\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This commit handles the jsonutils module which\nis now oslo.serialization.jsonutils. The change here is to remove it\nfrom openstack-common.conf and point all people who used to use that\nat oslo.serialization. requirements.txt has been updated to point to\nthis dependency.\n\nThe file jsonutils.py is not being deleted because of dependencies in\noslo-incubator.\n\nChange-Id: I2a7d4c41ce77d6375fa08033514baa815a087016\nPartial-Bug: #1380789\nblueprint: retire-unused-oslo-incubator-modules'}, {'number': 11, 'created': '2014-12-10 18:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/25ab0707bcb4704ecf19c67baf3761eaaecabd5b', 'message': 'Obsolete oslo-incubator modules - jsonutils (now oslo.serialization)\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This commit handles the jsonutils module which\nis now oslo.serialization.jsonutils. The change here is to remove it\nfrom openstack-common.conf and point all people who used to use that\nat oslo.serialization. requirements.txt has been updated to point to\nthis dependency.\n\nThe file jsonutils.py is not being deleted because of dependencies in\noslo-incubator.\n\nChange has been rebased on https://review.openstack.org/#/c/129294/\n\nChange-Id: I2a7d4c41ce77d6375fa08033514baa815a087016\nPartial-Bug: #1380789\nblueprint: retire-unused-oslo-incubator-modules\n'}, {'number': 12, 'created': '2014-12-11 20:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/b26ab3ab6585fc8df00ba28772973dfc9b116335', 'message': 'Obsolete oslo-incubator modules - jsonutils (now oslo.serialization)\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This commit handles the jsonutils module which\nis now oslo.serialization.jsonutils. The change here is to remove it\nfrom openstack-common.conf and point all people who used to use that\nat oslo.serialization. requirements.txt has been updated to point to\nthis dependency.\n\nThe file jsonutils.py is not being deleted because of dependencies in\noslo-incubator.\n\nChange has been rebased on https://review.openstack.org/#/c/129294/\n\nChange-Id: I2a7d4c41ce77d6375fa08033514baa815a087016\nPartial-Bug: #1380789\nblueprint: retire-unused-oslo-incubator-modules\n'}, {'number': 13, 'created': '2014-12-11 21:46:52.000000000', 'files': ['trove/common/limits.py', 'trove/common/wsgi.py', 'requirements.txt', 'openstack-common.conf', 'trove/tests/unittests/api/common/test_limits.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/a52f7cf5866d6850d357fabffb59958c8d56d0c5', 'message': 'Obsolete oslo-incubator modules - jsonutils (now oslo.serialization)\n\nThis change is part of a multi-part change set to handle obsolete and\ngraduated oslo modules. This commit handles the jsonutils module which\nis now oslo.serialization.jsonutils. The change here is to remove it\nfrom openstack-common.conf and point all people who used to use that\nat oslo.serialization. requirements.txt has been updated to point to\nthis dependency.\n\nThe file jsonutils.py is not being deleted because of dependencies in\noslo-incubator.\n\nChange has been rebased on https://review.openstack.org/#/c/129294/\n\nChange-Id: I2a7d4c41ce77d6375fa08033514baa815a087016\nPartial-Bug: #1380789\nblueprint: retire-unused-oslo-incubator-modules\n'}]",1,129668,a52f7cf5866d6850d357fabffb59958c8d56d0c5,64,24,13,9664,,,0,"Obsolete oslo-incubator modules - jsonutils (now oslo.serialization)

This change is part of a multi-part change set to handle obsolete and
graduated oslo modules. This commit handles the jsonutils module which
is now oslo.serialization.jsonutils. The change here is to remove it
from openstack-common.conf and point all people who used to use that
at oslo.serialization. requirements.txt has been updated to point to
this dependency.

The file jsonutils.py is not being deleted because of dependencies in
oslo-incubator.

Change has been rebased on https://review.openstack.org/#/c/129294/

Change-Id: I2a7d4c41ce77d6375fa08033514baa815a087016
Partial-Bug: #1380789
blueprint: retire-unused-oslo-incubator-modules
",git fetch https://review.opendev.org/openstack/trove refs/changes/68/129668/10 && git format-patch -1 --stdout FETCH_HEAD,"['trove/common/wsgi.py', 'trove/openstack/common/rpc/common.py', 'trove/openstack/common/wsgi.py', 'trove/openstack/common/log.py', 'trove/openstack/common/rpc/impl_zmq.py', 'trove/tests/unittests/api/common/test_limits.py', 'trove/openstack/common/notifier/log_notifier.py', 'trove/common/limits.py', 'requirements.txt', 'trove/openstack/common/policy.py', 'trove/openstack/common/rpc/securemessage.py', 'trove/openstack/common/rpc/impl_qpid.py', 'openstack-common.conf', 'trove/openstack/common/notifier/api.py']",14,c2682d7c1b5815777296cecdfb2ae29db3287202,bugs/bug-1380789-jsonutils,from oslo.serialization import jsonutils,from trove.openstack.common import jsonutils,13,13
openstack%2Ftempest~master~I8130d16b6d30498f77dc23368ab4b5a9eff60b7c,openstack/tempest,master,I8130d16b6d30498f77dc23368ab4b5a9eff60b7c,EC2: do not assume order in dictionary,MERGED,2014-12-18 11:13:49.000000000,2014-12-23 10:51:04.000000000,2014-12-23 10:51:03.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5538}, {'_account_id': 10385}, {'_account_id': 11224}]","[{'number': 1, 'created': '2014-12-18 11:13:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8d1489ebf0e7701cbb0390ae09dae05df7bde6a8', 'message': ""EC2: do not assume order in dictionary\n\nInstance tags dictionary used to be empty, so to assert addition\nof a new tag, fetching the first entry from that dict worked fine.\n\nBut now, even if no tags are created, the tag dict will contain\nan entry with tag name 'readonly'. Now we can't just take the\n'first' entry from the dict. We'll need to do 'assertIn' on the\ndict.\n\nChange-Id: I8130d16b6d30498f77dc23368ab4b5a9eff60b7c\n""}, {'number': 2, 'created': '2014-12-18 12:54:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/64c590fb9e73d9aea33deef750fb2f7c918bf910', 'message': ""EC2: do not assume order in dictionary\n\nInstance tags dictionary used to be empty, so to assert addition\nof a new tag, fetching the first entry from that dict worked fine.\n\nBut now, even if no tags are created, the tag dict will contain\nan entry with tag name 'readonly'. Now we can't just take the\n'first' entry from the dict. We'll need to do 'assertIn' on the\ndict.\n\nChange-Id: I8130d16b6d30498f77dc23368ab4b5a9eff60b7c\n""}, {'number': 3, 'created': '2014-12-22 15:18:33.000000000', 'files': ['tempest/thirdparty/boto/test_ec2_instance_run.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/2b6e67cfb5e50d078e36e6cd21df1394d29d80b8', 'message': ""EC2: do not assume order in dictionary\n\nInstance tags dictionary used to be empty, so to assert addition\nof a new tag, fetching the first entry from that dict worked fine.\n\nBut it doesn't work when there are more than one entries are\npresent. This patch fixes this.\n\nChange-Id: I8130d16b6d30498f77dc23368ab4b5a9eff60b7c\n""}]",10,142732,2b6e67cfb5e50d078e36e6cd21df1394d29d80b8,26,6,3,5538,,,0,"EC2: do not assume order in dictionary

Instance tags dictionary used to be empty, so to assert addition
of a new tag, fetching the first entry from that dict worked fine.

But it doesn't work when there are more than one entries are
present. This patch fixes this.

Change-Id: I8130d16b6d30498f77dc23368ab4b5a9eff60b7c
",git fetch https://review.opendev.org/openstack/tempest refs/changes/32/142732/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/thirdparty/boto/test_ec2_instance_run.py'],1,8d1489ebf0e7701cbb0390ae09dae05df7bde6a8,fixtags," def _get_tag_dict(tags): d = {} for tag in tags: d[tag.name] = tag.value return d self.assertIn('key1', _get_tag_dict(tags)) self.assertEqual('value1', _get_tag_dict(tags)['key1']) self.assertIn('key1', _get_tag_dict(tags)) self.assertEqual('value1', _get_tag_dict(tags)['key1']) self.assertIn('key1', _get_tag_dict(tags)) self.assertEqual('value1', _get_tag_dict(tags)['key1']) self.assertNotIn('key1', _get_tag_dict(tags))"," self.assertEqual(tags[0].name, 'key1') self.assertEqual(tags[0].value, 'value1') self.assertEqual(tags[0].name, 'key1') self.assertEqual(tags[0].value, 'value1') self.assertEqual(tags[0].name, 'key1') self.assertEqual(tags[0].value, 'value1') self.assertEqual(len(tags), 0, str(tags))",14,7
openstack%2Fhorizon~master~I795c04672a3c625be074c8af78eb169436ac3895,openstack/horizon,master,I795c04672a3c625be074c8af78eb169436ac3895,Creating a new user with an existing user name,MERGED,2014-12-20 04:09:46.000000000,2014-12-23 10:50:53.000000000,2014-12-23 10:50:52.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2874}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 6763}, {'_account_id': 8411}, {'_account_id': 10068}, {'_account_id': 13785}]","[{'number': 1, 'created': '2014-12-20 04:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ae37914eb3ff2722a3d626b36d15f635e36af2bd', 'message': 'Creating a new user with an existing user name\n\nChange error message when we create a new user\nwith an existing user name.\n\nChange-Id: I795c04672a3c625be074c8af78eb169436ac3895\nCloses-Bug: #1404432\n'}, {'number': 2, 'created': '2014-12-20 06:55:14.000000000', 'files': ['openstack_dashboard/dashboards/identity/users/forms.py', 'openstack_dashboard/api/keystone.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0dc91bed5ce176330ee20f63be68a4076c534fa5', 'message': 'Creating a new user with an existing user name\n\nChange error message when we create a new user\nwith an existing user name.\n\nChange-Id: I795c04672a3c625be074c8af78eb169436ac3895\nCloses-Bug: #1404432\n'}]",3,143252,0dc91bed5ce176330ee20f63be68a4076c534fa5,20,9,2,13086,,,0,"Creating a new user with an existing user name

Change error message when we create a new user
with an existing user name.

Change-Id: I795c04672a3c625be074c8af78eb169436ac3895
Closes-Bug: #1404432
",git fetch https://review.opendev.org/openstack/horizon refs/changes/52/143252/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/identity/users/forms.py', 'openstack_dashboard/api/keystone.py']",2,ae37914eb3ff2722a3d626b36d15f635e36af2bd,bug/1404432," try: if VERSIONS.active < 3: user = manager.create(name, password, email, project, enabled) return VERSIONS.upgrade_v2_user(user) else: return manager.create(name, password=password, email=email, project=project, enabled=enabled, domain=domain) except keystone_exceptions.Conflict: raise exceptions.Conflict()"," if VERSIONS.active < 3: user = manager.create(name, password, email, project, enabled) return VERSIONS.upgrade_v2_user(user) else: return manager.create(name, password=password, email=email, project=project, enabled=enabled, domain=domain)",14,6
openstack%2Ftricircle~master~I477d453526941be8caa3ee89ee20c575067c416b,openstack/tricircle,master,I477d453526941be8caa3ee89ee20c575067c416b,Modify the installation script of nova and glance,MERGED,2014-12-23 10:31:04.000000000,2014-12-23 10:31:51.000000000,2014-12-23 10:31:51.000000000,"[{'_account_id': 3}, {'_account_id': 9684}]","[{'number': 1, 'created': '2014-12-23 10:31:04.000000000', 'files': ['glancesync/README.md', 'juno-patches/glance_store/glance_store_patch/installation/install.sh', 'glancesync/installation/install.sh', 'novaproxy/README.md', 'novaproxy/installation/install.sh', 'envrc', 'juno-patches/glance/glance_location_patch/installation/install.sh'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/4886a8a2469ca10551fa7c66de5e328a8c8baa23', 'message': 'Modify the installation script of nova and glance\n\nModify the installation script of nova and glance, include the README files.\n\nChange-Id: I477d453526941be8caa3ee89ee20c575067c416b\n'}]",0,143646,4886a8a2469ca10551fa7c66de5e328a8c8baa23,6,2,1,9684,,,0,"Modify the installation script of nova and glance

Modify the installation script of nova and glance, include the README files.

Change-Id: I477d453526941be8caa3ee89ee20c575067c416b
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/46/143646/1 && git format-patch -1 --stdout FETCH_HEAD,"['glancesync/README.md', 'juno-patches/glance_store/glance_store_patch/installation/install.sh', 'glancesync/installation/install.sh', 'novaproxy/README.md', 'novaproxy/installation/install.sh', 'envrc', 'juno-patches/glance/glance_location_patch/installation/install.sh']",7,4886a8a2469ca10551fa7c66de5e328a8c8baa23,,"_PYTHON_INSTALL_DIR=${OPENSTACK_INSTALL_DIR} if [ ! -n ${_PYTHON_INSTALL_DIR} ];then _PYTHON_INSTALL_DIR=""/usr/lib/python2.7/dist-packages"" fifunction process_stop { PID=`ps -efw|grep ""$1""|grep -v grep|awk '{print $2}'` echo ""PID is: $PID"">>$_SCRIPT_LOGFILE if [ ""x${PID}"" != ""x"" ]; then for kill_id in $PID do kill -9 ${kill_id} if [ $? -ne 0 ]; then echo ""[[stop glance-sync]]$1 stop failed."">>$_SCRIPT_LOGFILE exit 1 fi done echo ""[[stop glance-sync]]$1 stop ok."">>$_SCRIPT_LOGFILE fi } function restart_services { log ""restarting glance ..."" service glance-api restart service glance-registry restart process_stop ""glance-sync"" python /usr/bin/glance-sync --config-file=/etc/glance/glance-sync.conf & } #restart services restart_services if [ $? -ne 0 ] ; then log ""There was an error in restarting the service, please restart glance manually."" exit 1 fi ","_GLANCE_CONF_DIR=""/etc/glance"" _GLANCE_API_CONF_FILE=""glance-api.conf"" _PYTHON_INSTALL_DIR=""/usr/lib64/python2.6/site-packages""_CODE_DIR=""${CURPATH}/../glance"" _CONF_DIR=""${CURPATH}/../etc""log ""checking installation directories..."" if [ ! -d ""${_GLANCE_DIR}"" ] ; then log ""Could not find the glance installation. Please check the variables in the beginning of the script."" log ""aborted."" exit 1 fi if [ ! -f ""${_GLANCE_CONF_DIR}/${_GLANCE_API_CONF_FILE}"" ] ; then log ""Could not find glance-api config file. Please check the variables in the beginning of the script."" log ""aborted."" exit 1 fi cp -rf ""${_GLANCE_CONF_DIR}/${_GLANCE_API_CONF_FILE}"" ""${_BACKUP_DIR}/etc/glance/""",180,110
openstack%2Fnova~master~Icb6ce23bc44e1043f62eaa5c1f8804692fd15a84,openstack/nova,master,Icb6ce23bc44e1043f62eaa5c1f8804692fd15a84,Save compute node after host field updated,ABANDONED,2014-12-23 08:19:02.000000000,2014-12-23 09:17:14.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-23 08:19:02.000000000', 'files': ['nova/objects/compute_node.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8a21a7e7d8786238380d83df29f33d0b41d61ad7', 'message': ""Save compute node after host field updated\n\nWe plan to detach compute-node from service, and we add data migration\ncode into object. The compute-node obj will update the new host fileds\nin compute-node table. But the current code didn't save the change.\n\nChange-Id: Icb6ce23bc44e1043f62eaa5c1f8804692fd15a84\n""}]",0,143618,8a21a7e7d8786238380d83df29f33d0b41d61ad7,8,6,1,5754,,,0,"Save compute node after host field updated

We plan to detach compute-node from service, and we add data migration
code into object. The compute-node obj will update the new host fileds
in compute-node table. But the current code didn't save the change.

Change-Id: Icb6ce23bc44e1043f62eaa5c1f8804692fd15a84
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/143618/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/objects/compute_node.py'],1,8a21a7e7d8786238380d83df29f33d0b41d61ad7,save_compute_host, compute.save(),,1,1
openstack%2Fmanila~master~I3bef5f2633f05462f2655245e3392e9b7fa96fc8,openstack/manila,master,I3bef5f2633f05462f2655245e3392e9b7fa96fc8,Remove unused function sanitize_hostname(),ABANDONED,2014-12-23 08:26:10.000000000,2014-12-23 09:08:07.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-23 08:26:10.000000000', 'files': ['manila/tests/test_utils.py', 'manila/utils.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/e54f202b479e5c964a98150865a02bb0b5587921', 'message': 'Remove unused function sanitize_hostname()\n\nThe function from manila/utils.py is never used so remove it.\n\nChange-Id: I3bef5f2633f05462f2655245e3392e9b7fa96fc8\n'}]",0,143620,e54f202b479e5c964a98150865a02bb0b5587921,3,1,1,7102,,,0,"Remove unused function sanitize_hostname()

The function from manila/utils.py is never used so remove it.

Change-Id: I3bef5f2633f05462f2655245e3392e9b7fa96fc8
",git fetch https://review.opendev.org/openstack/manila refs/changes/20/143620/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/test_utils.py', 'manila/utils.py']",2,e54f202b479e5c964a98150865a02bb0b5587921,,,"def sanitize_hostname(hostname): """"""Return a hostname which conforms to RFC-952 and RFC-1123 specs."""""" if isinstance(hostname, unicode): hostname = hostname.encode('latin-1', 'ignore') hostname = re.sub('[ _]', '-', hostname) hostname = re.sub('[^\w.-]+', '', hostname) hostname = hostname.lower() hostname = hostname.strip('.-') return hostname ",0,37
openstack%2Fkeystonemiddleware~master~Icc072b723f20711739cb90de65b4800233c649d1,openstack/keystonemiddleware,master,Icc072b723f20711739cb90de65b4800233c649d1,Use oslo.utils to validate boolean string,ABANDONED,2014-12-22 16:39:15.000000000,2014-12-23 08:42:56.000000000,,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 9101}, {'_account_id': 13478}]","[{'number': 1, 'created': '2014-12-22 16:39:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/35ee5323c65d1f62948d5851dd44c37362093887', 'message': 'Use oslo.utils to validate boolean string\n\nChange-Id: Icc072b723f20711739cb90de65b4800233c649d1\n'}, {'number': 2, 'created': '2014-12-22 16:50:30.000000000', 'files': ['keystonemiddleware/auth_token.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/2f755f46813977938de9b398bdf80cf87aff867e', 'message': 'Use oslo.utils to validate boolean string\n\nChange-Id: Icc072b723f20711739cb90de65b4800233c649d1\n'}]",0,143488,2f755f46813977938de9b398bdf80cf87aff867e,8,4,2,1669,,,0,"Use oslo.utils to validate boolean string

Change-Id: Icc072b723f20711739cb90de65b4800233c649d1
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/88/143488/2 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/auth_token.py'],1,35ee5323c65d1f62948d5851dd44c37362093887,jd/utils-bool,from oslo.utils import strutils self._delay_auth_decision = strutils.bool_from_string( self._conf_get('delay_auth_decision'))," self._delay_auth_decision = (self._conf_get('delay_auth_decision') in (True, 'true', 't', '1', 'on', 'yes', 'y') )",3,3
openstack%2Fnova~master~If94799fabef30ad1d5f16c63cf1c7ffdb2b57301,openstack/nova,master,If94799fabef30ad1d5f16c63cf1c7ffdb2b57301,Lower complexity of Controller.create (v2 API),ABANDONED,2014-12-18 13:27:22.000000000,2014-12-23 08:28:46.000000000,,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 5170}, {'_account_id': 7770}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10173}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-18 13:27:22.000000000', 'files': ['nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/744749cf2d0a2b36cb46a19c65ca08717def6b06', 'message': 'Lower complexity of Controller.create (v2 API)\n\nThe method Controller.create in nova/api/openstack/compute/servers.py\nhas a complexity of 46 that is the most complex in Nova code and it is\nequal to the limit specified in tox.ini. This cause a pep8 error if\nsomeone tries to add a new api for server create action.\nThis fail is unavoidable if one wants to keep consistency with the way\nother extensions are loaded, so a refactoring is necessary to lower\nthe complexity.\nWith this patch the complexity of Controller.create is lowered to 22.\n\nChange-Id: If94799fabef30ad1d5f16c63cf1c7ffdb2b57301\nCloses-Bug: 1403586\n'}]",0,142777,744749cf2d0a2b36cb46a19c65ca08717def6b06,9,9,1,13071,,,0,"Lower complexity of Controller.create (v2 API)

The method Controller.create in nova/api/openstack/compute/servers.py
has a complexity of 46 that is the most complex in Nova code and it is
equal to the limit specified in tox.ini. This cause a pep8 error if
someone tries to add a new api for server create action.
This fail is unavoidable if one wants to keep consistency with the way
other extensions are loaded, so a refactoring is necessary to lower
the complexity.
With this patch the complexity of Controller.create is lowered to 22.

Change-Id: If94799fabef30ad1d5f16c63cf1c7ffdb2b57301
Closes-Bug: 1403586
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/142777/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/servers.py'],1,744749cf2d0a2b36cb46a19c65ca08717def6b06,bug/1403586," def _get_config_drive(self, server_dict): return config_drive def _get_sg_names(self, server_dict): return sg_names def _get_req_networks(self, server_dict): return requested_networks def _get_key_name(self, server_dict): return key_name def _get_user_data(self, server_dict): return user_data def _get_availability_zone(self, server_dict): return availability_zone def _get_block_device_mapping(self, server_dict): return (block_device_mapping, legacy_bdm) def _get_multiple_create(self, server_dict): return (ret_resv_id, min_count, max_count) def _get_auto_disk_config(self, server_dict): return auto_disk_config def _get_scheduler_hints(self, server_dict): return scheduler_hints def _get_check_server_group_quota(self, server_dict): return check_server_group_quota @wsgi.serializers(xml=ServerTemplate) def show(self, req, id): """"""Returns server details by server id."""""" context = req.environ['nova.context'] instance = self._get_server(context, req, id) return self._view_builder.show(req, instance) @wsgi.response(202) @wsgi.serializers(xml=FullServerTemplate) @wsgi.deserializers(xml=CreateDeserializer) def create(self, req, body): """"""Creates a new server for a given user."""""" if not self.is_valid_body(body, 'server'): raise exc.HTTPUnprocessableEntity() context = req.environ['nova.context'] server_dict = body['server'] password = self._get_server_admin_password(server_dict) if 'name' not in server_dict: msg = _(""Server name is not defined"") raise exc.HTTPBadRequest(explanation=msg) name = server_dict['name'] self._validate_server_name(name) name = name.strip() image_uuid = self._image_from_req_data(body) personality = server_dict.get('personality') config_drive = self._get_config_drive(server_dict) injected_files = [] if personality: injected_files = self._get_injected_files(personality) sg_names = self._get_sg_names(server_dict) requested_networks = self._get_req_networks(server_dict) (access_ip_v4, ) = server_dict.get('accessIPv4'), if access_ip_v4 is not None: self._validate_access_ipv4(access_ip_v4) (access_ip_v6, ) = server_dict.get('accessIPv6'), if access_ip_v6 is not None: self._validate_access_ipv6(access_ip_v6) try: flavor_id = self._flavor_id_from_req_data(body) except ValueError as error: msg = _(""Invalid flavorRef provided."") raise exc.HTTPBadRequest(explanation=msg) # optional openstack extensions: key_name = self._get_key_name(server_dict) user_data = self._get_user_data(server_dict) availability_zone = self._get_availability_zone(server_dict) (block_device_mapping, legacy_bdm) = self._get_block_device_mapping(server_dict) (ret_resv_id, min_count, max_count) = self._get_multiple_create(server_dict) auto_disk_config = self._get_auto_disk_config(server_dict) scheduler_hints = self._get_scheduler_hints(server_dict) check_server_group_quota = \ self._get_check_server_group_quota(server_dict)"," @wsgi.serializers(xml=ServerTemplate) def show(self, req, id): """"""Returns server details by server id."""""" context = req.environ['nova.context'] instance = self._get_server(context, req, id) return self._view_builder.show(req, instance) @wsgi.response(202) @wsgi.serializers(xml=FullServerTemplate) @wsgi.deserializers(xml=CreateDeserializer) def create(self, req, body): """"""Creates a new server for a given user."""""" if not self.is_valid_body(body, 'server'): raise exc.HTTPUnprocessableEntity() context = req.environ['nova.context'] server_dict = body['server'] password = self._get_server_admin_password(server_dict) if 'name' not in server_dict: msg = _(""Server name is not defined"") raise exc.HTTPBadRequest(explanation=msg) name = server_dict['name'] self._validate_server_name(name) name = name.strip() image_uuid = self._image_from_req_data(body) personality = server_dict.get('personality') injected_files = [] if personality: injected_files = self._get_injected_files(personality) (access_ip_v4, ) = server_dict.get('accessIPv4'), if access_ip_v4 is not None: self._validate_access_ipv4(access_ip_v4) (access_ip_v6, ) = server_dict.get('accessIPv6'), if access_ip_v6 is not None: self._validate_access_ipv6(access_ip_v6) try: flavor_id = self._flavor_id_from_req_data(body) except ValueError as error: msg = _(""Invalid flavorRef provided."") raise exc.HTTPBadRequest(explanation=msg) # optional openstack extensions:",96,50
openstack%2Ffuel-docs~master~I462c62742344f42a7557c1004264c49c7ade0935,openstack/fuel-docs,master,I462c62742344f42a7557c1004264c49c7ade0935,Release Notes 6.0 -- OpenStack issues,ABANDONED,2014-12-22 13:23:51.000000000,2014-12-23 08:16:41.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-12-22 13:23:51.000000000', 'files': ['pages/release-notes/v6-0/1060-openstack.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/ea051f25f1953bf096b1ee83cdca927cfa1004b9', 'message': 'Release Notes 6.0 -- OpenStack issues\n\nUpdated the known & fixed issues.\n\nChange-Id: I462c62742344f42a7557c1004264c49c7ade0935\n'}]",0,143439,ea051f25f1953bf096b1ee83cdca927cfa1004b9,5,3,1,14342,,,0,"Release Notes 6.0 -- OpenStack issues

Updated the known & fixed issues.

Change-Id: I462c62742344f42a7557c1004264c49c7ade0935
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/39/143439/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v6-0/1060-openstack.rst'],1,ea051f25f1953bf096b1ee83cdca927cfa1004b9,rn-6.0-openstack,"New Features and Resolved Issues in Mirantis OpenStack 6.0 ---------------------------------------------------------- *_Nova floating range now waits for both Keystone backends. See `LP1381982 <https://bugs.launchpad.net/bugs/1381982>`_. *_Previously, default Neutron networks were created with admin tenant name, even if a custom name was applied in the cluster settings. This problem is now fixed. See `LP1376515 <https://bugs.launchpad.net/bugs/1376515>`_. *_File injection no longer fails when an instance launches See `LP1335697 <https://bugs.launchpad.net/bugs/1335697>`_. *_Rsyslogd restart no longer causes services to hang. See `LP1363102 <https://bugs.launchpad.net/bugs/1363102>`_. *_Applying iptables rules during large scale deployments now does not take an inappropriately long time. See `LP1399168 <https://bugs.launchpad.net/bugs/1399168>`_. Enabled Murano prevents the controller from redeployment ++++++++++++++++++++++++++++++++++++++++++++++++++++++++ When Murano is deployed at CentOS, redeployment of the controller might fail. To work around this issue around, follow these steps: #. Deploy the Fuel Master node. #. Log into the Fuel Master node as root. #. Install patch package: :: yum install patch -y #. Download the patch from `LP1401503 <https://bugs.launchpad.net/bugs/1401503>`_. and apply it: :: patch --verbose -p0 < apps-upload-check.patch ","File injection fails when an instance launches ++++++++++++++++++++++++++++++++++++++++++++++ Instances with file injection cannot be launched after the OpenStack environment is launched. Instances that do not require file injection can be launched. As a workaround, execute the **update-guestfs-appliance** command on each Compute node. See `LP1335697 <https://bugs.launchpad.net/bugs/1335697>`_.",37,8
openstack%2Fhorizon~master~I3a6a78cc5747c1f0f7dd1cd9d6a311705e6ad964,openstack/horizon,master,I3a6a78cc5747c1f0f7dd1cd9d6a311705e6ad964,Imported Translations from Transifex,MERGED,2014-12-23 06:07:32.000000000,2014-12-23 08:08:13.000000000,2014-12-23 08:08:12.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}]","[{'number': 1, 'created': '2014-12-23 06:07:32.000000000', 'files': ['openstack_dashboard/locale/ja/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ffba1b6fb13a553c659f85f79d5b11a6b98eb520', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I3a6a78cc5747c1f0f7dd1cd9d6a311705e6ad964\n'}]",0,143602,ffba1b6fb13a553c659f85f79d5b11a6b98eb520,7,3,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I3a6a78cc5747c1f0f7dd1cd9d6a311705e6ad964
",git fetch https://review.opendev.org/openstack/horizon refs/changes/02/143602/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/locale/ja/LC_MESSAGES/django.po'],1,ffba1b6fb13a553c659f85f79d5b11a6b98eb520,transifex/translations,"""POT-Creation-Date: 2014-12-20 01:30-0600\n"" ""PO-Revision-Date: 2014-12-22 14:51+0000\n"" ""Last-Translator: Akihiro Motoki <amotoki@gmail.com>\n""msgstr ""メタデータ定義""msgstr ""ネットワークの詳細: %(network_name)s""msgstr ""サブネットの詳細""msgstr ""ポートの詳細""msgstr ""どこかがおかしくなりました！""","""POT-Creation-Date: 2014-12-19 15:20-0600\n"" ""PO-Revision-Date: 2014-12-19 21:20+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr ""問題が発生しました""",8,8
openstack%2Fcinder~master~Id0e6b1d3c3cd1e51745e97f99eef88a15e285526,openstack/cinder,master,Id0e6b1d3c3cd1e51745e97f99eef88a15e285526,Add error handling to _connect function in PureISCSIDriver,MERGED,2014-12-18 02:36:18.000000000,2014-12-23 08:08:04.000000000,2014-12-23 08:08:03.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 4355}, {'_account_id': 7198}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 12780}, {'_account_id': 12924}, {'_account_id': 13868}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-12-18 02:36:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/49037b156766bc5a9773720a62e93fbb482200c7', 'message': 'Add error handling to _connect function in PureISCSIDriver\n\nThe driver was throwing an exception when trying to connect a volume\nto a host when they were already connected.  This change catches the\nexception and looks up the existing connection information to use as\na return value.\n\nChange-Id: Id0e6b1d3c3cd1e51745e97f99eef88a15e285526\nCloses-Bug:  1403631\n'}, {'number': 2, 'created': '2014-12-18 19:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/48cd118e3da6b662a6c25bbc3868e137e024fcbf', 'message': 'Add error handling to _connect function in PureISCSIDriver\n\nThe driver was throwing an exception when trying to connect a volume\nto a host when they were already connected.  This change catches the\nexception and looks up the existing connection information to use as\na return value.\n\nChange-Id: Id0e6b1d3c3cd1e51745e97f99eef88a15e285526\nCloses-Bug:  1403631\n'}, {'number': 3, 'created': '2014-12-19 05:12:12.000000000', 'files': ['cinder/volume/drivers/pure.py', 'cinder/tests/test_pure.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4da33ea23319b16b8e81ee0413b0c251a444d669', 'message': 'Add error handling to _connect function in PureISCSIDriver\n\nThe driver was throwing an exception when trying to connect a volume\nto a host when they were already connected.  This change catches the\nexception and looks up the existing connection information to use as\na return value.\n\nChange-Id: Id0e6b1d3c3cd1e51745e97f99eef88a15e285526\nCloses-Bug:  1403631\n'}]",6,142648,4da33ea23319b16b8e81ee0413b0c251a444d669,38,17,3,13868,,,0,"Add error handling to _connect function in PureISCSIDriver

The driver was throwing an exception when trying to connect a volume
to a host when they were already connected.  This change catches the
exception and looks up the existing connection information to use as
a return value.

Change-Id: Id0e6b1d3c3cd1e51745e97f99eef88a15e285526
Closes-Bug:  1403631
",git fetch https://review.opendev.org/openstack/cinder refs/changes/48/142648/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/pure.py', 'cinder/tests/test_pure.py']",2,49037b156766bc5a9773720a62e93fbb482200c7,bug/1403631," @mock.patch(DRIVER_OBJ + ""._get_host"", autospec=True) def test_connect_already_connected(self, mock_host): mock_host.return_value = PURE_HOST expected = {""host"": PURE_HOST_NAME, ""lun"": 1} self.array.list_volume_hosts.return_value = \ [expected, {""host"": ""extra"", ""lun"": 2}] self.array.connect_host.side_effect = exception.PureAPIException( code=400, reason=""Connection already exists"") actual = self.driver._connect(VOLUME, CONNECTOR) self.assertEqual(expected, actual) self.assertTrue(self.array.connect_host.called) self.assertTrue(self.array.list_volume_hosts) @mock.patch(DRIVER_OBJ + ""._get_host"", autospec=True) def test_connect_already_connected_list_hosts_empty(self, mock_host): mock_host.return_value = PURE_HOST self.array.list_volume_hosts.return_value = [] self.array.connect_host.side_effect = exception.PureAPIException( code=400, reason=""Connection already exists"") self.assertRaises(exception.PureDriverException, lambda: self.driver._connect(VOLUME, CONNECTOR)) self.assertTrue(self.array.connect_host.called) self.assertTrue(self.array.list_volume_hosts) @mock.patch(DRIVER_OBJ + ""._get_host"", autospec=True) def test_connect_already_connected_list_hosts_exception(self, mock_host): mock_host.return_value = PURE_HOST self.array.list_volume_hosts.side_effect = \ exception.PureAPIException(code=400, reason="""") self.array.connect_host.side_effect = exception.PureAPIException( code=400, reason=""Connection already exists"") self.assertRaises(exception.PureAPIException, lambda: self.driver._connect(VOLUME, CONNECTOR)) self.assertTrue(self.array.connect_host.called) self.assertTrue(self.array.list_volume_hosts) ",,57,1
openstack%2Fpbr~master~I1c420fed609bc60bbfdf78eb219e067ccab1a61e,openstack/pbr,master,I1c420fed609bc60bbfdf78eb219e067ccab1a61e,Move write_pbr_json to avoid issues with nose,MERGED,2014-12-19 17:47:05.000000000,2014-12-23 08:07:32.000000000,2014-12-23 08:07:32.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 5638}, {'_account_id': 7687}]","[{'number': 1, 'created': '2014-12-19 17:47:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/555db4fcce37380963ddc564e3f96fdf1ca589dd', 'message': 'Move write_pbr_json to avoid issues with nose\n\nPut write_pbr_json in pbr.pbr_json so that you do not need to import\npbr.packaging to use it. This avoids python3 errors with nose where nose\nis imported by pbr before it is converted to python3 by 2to3 under\npython3.\n\nNote that a noop packaging.write_pbr_json is added to make older pbr\nentrypoints that expect that path happy when running pbr in pbr itself.\nNote this should only affect pbr and not any other package.\n\nChange-Id: I1c420fed609bc60bbfdf78eb219e067ccab1a61e\n'}, {'number': 2, 'created': '2014-12-19 17:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/795631c3eef5c67a4269d55a4868a863f2cc6910', 'message': 'Move write_pbr_json to avoid issues with nose\n\nPut write_pbr_json in pbr.pbr_json so that you do not need to import\npbr.packaging to use it. This avoids python3 errors with nose where nose\nis imported by pbr before it is converted to python3 by 2to3 under\npython3.\n\nChange-Id: I1c420fed609bc60bbfdf78eb219e067ccab1a61e\n'}, {'number': 3, 'created': '2014-12-19 18:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/3550e89db42002e226ea70b1d0314a319b2ecd10', 'message': 'Move write_pbr_json to avoid issues with nose\n\nPut write_pbr_json in pbr.pbr_json so that you do not need to import\npbr.packaging to use it. This avoids python3 errors with nose where nose\nis imported by pbr before it is converted to python3 by 2to3 under\npython3.\n\nChange-Id: I1c420fed609bc60bbfdf78eb219e067ccab1a61e\n'}, {'number': 4, 'created': '2014-12-21 22:24:26.000000000', 'files': ['pbr/pbr_json.py', 'pbr/packaging.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/pbr/commit/3ec9f0e809f8588fd9110f2b0426a495a44e7a2f', 'message': 'Move write_pbr_json to avoid issues with nose\n\nPut write_pbr_json in pbr.pbr_json so that you do not need to import\npbr.packaging to use it. This avoids python3 errors with nose where nose\nis imported by pbr before it is converted to python3 by 2to3 under\npython3.\n\nChange-Id: I1c420fed609bc60bbfdf78eb219e067ccab1a61e\n'}]",2,143146,3ec9f0e809f8588fd9110f2b0426a495a44e7a2f,26,5,4,4146,,,0,"Move write_pbr_json to avoid issues with nose

Put write_pbr_json in pbr.pbr_json so that you do not need to import
pbr.packaging to use it. This avoids python3 errors with nose where nose
is imported by pbr before it is converted to python3 by 2to3 under
python3.

Change-Id: I1c420fed609bc60bbfdf78eb219e067ccab1a61e
",git fetch https://review.opendev.org/openstack/pbr refs/changes/46/143146/4 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/pbr_json.py', 'pbr/packaging.py', 'setup.cfg']",3,555db4fcce37380963ddc564e3f96fdf1ca589dd,setuptools-8,egg_info.writers = pbr.json = pbr.pbr_json:write_pbr_json,,42,14
openstack%2Fpbr~master~Ic8e0c74a779b23842369a8cf01fcbf37885202ef,openstack/pbr,master,Ic8e0c74a779b23842369a8cf01fcbf37885202ef,Properly check for git before getting git dir,MERGED,2014-12-18 16:46:19.000000000,2014-12-23 08:07:00.000000000,2014-12-23 08:06:59.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-18 16:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/92f9642802230dc95011afe1f4b0b808b91d51e1', 'message': 'Properly check for git before getting git dir\n\nWe cannot get the git dir if git is not installed. Check that git is\ninstalled before querying for the git dir. Return None if the git dir\ncannot be found or if git is not installed.\n\nChange-Id: Ic8e0c74a779b23842369a8cf01fcbf37885202ef\nFixes-bug: 1326682\n(cherry picked from commit e7d2825d39fce2111d0d413e63e553603a0e56fb)\n'}, {'number': 2, 'created': '2014-12-18 21:24:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/04f2d1aa4f346e651f3d6d4e74269ad86892a6ef', 'message': 'Properly check for git before getting git dir\n\nWe cannot get the git dir if git is not installed. Check that git is\ninstalled before querying for the git dir. Return None if the git dir\ncannot be found or if git is not installed.\n\nChange-Id: Ic8e0c74a779b23842369a8cf01fcbf37885202ef\nFixes-bug: 1326682\n(cherry picked from commit e7d2825d39fce2111d0d413e63e553603a0e56fb)\n'}, {'number': 3, 'created': '2014-12-18 21:36:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/5e722caaf7a6bcc0a3326ef7afc1bbc517e5109a', 'message': 'Properly check for git before getting git dir\n\nWe cannot get the git dir if git is not installed. Check that git is\ninstalled before querying for the git dir. Return None if the git dir\ncannot be found or if git is not installed.\n\nChange-Id: Ic8e0c74a779b23842369a8cf01fcbf37885202ef\nFixes-bug: 1326682\n(cherry picked from commit e7d2825d39fce2111d0d413e63e553603a0e56fb)\n'}, {'number': 4, 'created': '2014-12-18 23:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/0c6ffe8643140e94d40b1f72af072c255cc2eede', 'message': 'Properly check for git before getting git dir\n\nWe cannot get the git dir if git is not installed. Check that git is\ninstalled before querying for the git dir. Return None if the git dir\ncannot be found or if git is not installed.\n\nChange-Id: Ic8e0c74a779b23842369a8cf01fcbf37885202ef\nFixes-bug: 1326682\n(cherry picked from commit e7d2825d39fce2111d0d413e63e553603a0e56fb)\n'}, {'number': 5, 'created': '2014-12-19 01:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/3f606f5400dfe3c329a2e38e2c63c4a80d028463', 'message': 'Properly check for git before getting git dir\n\nWe cannot get the git dir if git is not installed. Check that git is\ninstalled before querying for the git dir. Return None if the git dir\ncannot be found or if git is not installed.\n\nChange-Id: Ic8e0c74a779b23842369a8cf01fcbf37885202ef\nFixes-bug: 1326682\n(cherry picked from commit e7d2825d39fce2111d0d413e63e553603a0e56fb)\n'}, {'number': 6, 'created': '2014-12-19 01:37:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/d11679df07d8a9b4723ae502eac6c40d252073ab', 'message': 'Properly check for git before getting git dir\n\nWe cannot get the git dir if git is not installed. Check that git is\ninstalled before querying for the git dir. Return None if the git dir\ncannot be found or if git is not installed.\n\nChange-Id: Ic8e0c74a779b23842369a8cf01fcbf37885202ef\nFixes-bug: 1326682\n(cherry picked from commit e7d2825d39fce2111d0d413e63e553603a0e56fb)\n'}, {'number': 7, 'created': '2014-12-19 18:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/d980d84c5978dff1509b61dcd01485b8cd8b8571', 'message': 'Properly check for git before getting git dir\n\nWe cannot get the git dir if git is not installed. Check that git is\ninstalled before querying for the git dir. Return None if the git dir\ncannot be found or if git is not installed.\n\nChange-Id: Ic8e0c74a779b23842369a8cf01fcbf37885202ef\nFixes-bug: 1326682\n(cherry picked from commit e7d2825d39fce2111d0d413e63e553603a0e56fb)\n'}, {'number': 8, 'created': '2014-12-21 22:24:26.000000000', 'files': ['pbr/packaging.py', 'pbr/git.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/50a43a18d14f4c2acebbd3fb221400224eb56781', 'message': 'Properly check for git before getting git dir\n\nWe cannot get the git dir if git is not installed. Check that git is\ninstalled before querying for the git dir. Return None if the git dir\ncannot be found or if git is not installed.\n\nChange-Id: Ic8e0c74a779b23842369a8cf01fcbf37885202ef\nFixes-bug: 1326682\n(cherry picked from commit e7d2825d39fce2111d0d413e63e553603a0e56fb)\n'}]",0,142841,50a43a18d14f4c2acebbd3fb221400224eb56781,31,6,8,4146,,,0,"Properly check for git before getting git dir

We cannot get the git dir if git is not installed. Check that git is
installed before querying for the git dir. Return None if the git dir
cannot be found or if git is not installed.

Change-Id: Ic8e0c74a779b23842369a8cf01fcbf37885202ef
Fixes-bug: 1326682
(cherry picked from commit e7d2825d39fce2111d0d413e63e553603a0e56fb)
",git fetch https://review.opendev.org/openstack/pbr refs/changes/41/142841/8 && git format-patch -1 --stdout FETCH_HEAD,['pbr/packaging.py'],1,92f9642802230dc95011afe1f4b0b808b91d51e1,setuptools-8, git_dir = _run_git_functions() git_dir = _run_git_functions() git_dir = _run_git_functions() git_dir = None if _git_is_installed(): git_dir = _get_git_directory() return git_dir or None, git_dir = _get_git_directory() git_dir = _get_git_directory() git_dir = _get_git_directory() git_dir = _get_git_directory() if git_dir and _git_is_installed(): return git_dir return None,7,7
openstack%2Fpbr~master~Ie121e795be2eef30822daaa5fe8ab1c2315577ae,openstack/pbr,master,Ie121e795be2eef30822daaa5fe8ab1c2315577ae,Port in git sha changes from 0.10 line,MERGED,2014-12-18 23:17:30.000000000,2014-12-23 07:50:55.000000000,2014-12-23 07:50:55.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 2472}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-18 23:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/74f72dd5d69e28b7930719f37377bbd37515624f', 'message': 'Port in git sha changes from 0.10 line\n\nStop including git sha in version strings\n\nWe include it in pbr.json now. Including it is contentious in the world\nof python, and it\'s up for debate as to whether or not it provides value.\n\nWrite and read more complex git sha info\n\nInstead of encoding the git sha into the version string, add it to\na metadata file. This will allow us to get out of the business of\narguing with pip and setuptools about version info. In order to make\nthis really nice, provide a command line utility called ""pbr"" that has\nsubcommands to print out the metadata that we\'re now including in the\negg-info dir.\n\nChange-Id: Ie121e795be2eef30822daaa5fe8ab1c2315577ae\n'}, {'number': 2, 'created': '2014-12-19 01:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/77077695a040c10dfd6520e13578e50036d60523', 'message': 'Port in git sha changes from 0.10 line\n\nStop including git sha in version strings\n\nWe include it in pbr.json now. Including it is contentious in the world\nof python, and it\'s up for debate as to whether or not it provides value.\n\nWrite and read more complex git sha info\n\nInstead of encoding the git sha into the version string, add it to\na metadata file. This will allow us to get out of the business of\narguing with pip and setuptools about version info. In order to make\nthis really nice, provide a command line utility called ""pbr"" that has\nsubcommands to print out the metadata that we\'re now including in the\negg-info dir.\n\nChange-Id: Ie121e795be2eef30822daaa5fe8ab1c2315577ae\n'}, {'number': 3, 'created': '2014-12-19 01:37:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/f4aeccd51093a9731e01fd19cd6ac3ff52393447', 'message': 'Port in git sha changes from 0.10 line\n\nStop including git sha in version strings\n\nWe include it in pbr.json now. Including it is contentious in the world\nof python, and it\'s up for debate as to whether or not it provides value.\n\nWrite and read more complex git sha info\n\nInstead of encoding the git sha into the version string, add it to\na metadata file. This will allow us to get out of the business of\narguing with pip and setuptools about version info. In order to make\nthis really nice, provide a command line utility called ""pbr"" that has\nsubcommands to print out the metadata that we\'re now including in the\negg-info dir.\n\nChange-Id: Ie121e795be2eef30822daaa5fe8ab1c2315577ae\nCo-Authored-By: Jeremy Stanley <fungi@yuggoth.org>\n'}, {'number': 4, 'created': '2014-12-19 18:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/76b4a69fafc0b569433a8271f1c632cc37297766', 'message': 'Port in git sha changes from 0.10 line\n\nStop including git sha in version strings\n\nWe include it in pbr.json now. Including it is contentious in the world\nof python, and it\'s up for debate as to whether or not it provides value.\n\nWrite and read more complex git sha info\n\nInstead of encoding the git sha into the version string, add it to\na metadata file. This will allow us to get out of the business of\narguing with pip and setuptools about version info. In order to make\nthis really nice, provide a command line utility called ""pbr"" that has\nsubcommands to print out the metadata that we\'re now including in the\negg-info dir.\n\nChange-Id: Ie121e795be2eef30822daaa5fe8ab1c2315577ae\nCo-Authored-By: Jeremy Stanley <fungi@yuggoth.org>\n'}, {'number': 5, 'created': '2014-12-21 22:24:26.000000000', 'files': ['pbr/tests/test_version.py', 'pbr/packaging.py', 'pbr/tests/base.py', 'pbr/tests/test_packaging.py', 'pbr/util.py', 'pbr/git.py', 'pbr/hooks/commands.py', 'tools/integration.sh', 'pbr/tests/test_setup.py', 'pbr/cmd/main.py', 'pbr/builddoc.py', 'setup.cfg', 'pbr/options.py', 'tox.ini', 'pbr/cmd/__init__.py', 'pbr/version.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/c01b8dae1e5ad91d30756140d9b591818444db2d', 'message': 'Port in git sha changes from 0.10 line\n\nStop including git sha in version strings\n\nWe include it in pbr.json now. Including it is contentious in the world\nof python, and it\'s up for debate as to whether or not it provides value.\n\nWrite and read more complex git sha info\n\nInstead of encoding the git sha into the version string, add it to\na metadata file. This will allow us to get out of the business of\narguing with pip and setuptools about version info. In order to make\nthis really nice, provide a command line utility called ""pbr"" that has\nsubcommands to print out the metadata that we\'re now including in the\negg-info dir.\n\nOnly import sphinx during hook processing\n\nWhen pbr is imported to handle writing the egg_info file because of\nthe entry point, it\'s causing sphinx to get imported. This has a\ncascading effect once docutils is trying to be installed on a system\nwith pbr installed. If some of the imports fail along the way, allow\npbr to continue usefully but without the Sphinx extensions\navailable. Eventually, when everything is installed, those\nextensions will work again when the commands for build_sphinx, etc.\nare run separately.\n\nAlso slip in a change to reorder the default list of environments\nrun by tox so the testr database is created using a dbm format\navailable to all python versions.\n\nIntegration test PBR commits\n\nMake sure that if a PBR commit is being tested then we install and\nuse that source rather than the latest PBR release.\n\nChange-Id: Ie121e795be2eef30822daaa5fe8ab1c2315577ae\n(cherry picked from commit 65f4fafd907a16ea1952ab7072676db2e9e0c51d)\n(cherry picked from commit cd7da23937b66fea3ec42fa2f5a128f363a97e7e)\nCloses-Bug: #1403510\nCo-Authored-By: Clark Boylan <clark.boylan@gmail.com>\nCo-Authored-By: Doug Hellmann <doug@doughellmann.com>\nCo-Authored-By: Jeremy Stanley <fungi@yuggoth.org>\n'}]",0,142931,c01b8dae1e5ad91d30756140d9b591818444db2d,33,6,5,2,,,0,"Port in git sha changes from 0.10 line

Stop including git sha in version strings

We include it in pbr.json now. Including it is contentious in the world
of python, and it's up for debate as to whether or not it provides value.

Write and read more complex git sha info

Instead of encoding the git sha into the version string, add it to
a metadata file. This will allow us to get out of the business of
arguing with pip and setuptools about version info. In order to make
this really nice, provide a command line utility called ""pbr"" that has
subcommands to print out the metadata that we're now including in the
egg-info dir.

Only import sphinx during hook processing

When pbr is imported to handle writing the egg_info file because of
the entry point, it's causing sphinx to get imported. This has a
cascading effect once docutils is trying to be installed on a system
with pbr installed. If some of the imports fail along the way, allow
pbr to continue usefully but without the Sphinx extensions
available. Eventually, when everything is installed, those
extensions will work again when the commands for build_sphinx, etc.
are run separately.

Also slip in a change to reorder the default list of environments
run by tox so the testr database is created using a dbm format
available to all python versions.

Integration test PBR commits

Make sure that if a PBR commit is being tested then we install and
use that source rather than the latest PBR release.

Change-Id: Ie121e795be2eef30822daaa5fe8ab1c2315577ae
(cherry picked from commit 65f4fafd907a16ea1952ab7072676db2e9e0c51d)
(cherry picked from commit cd7da23937b66fea3ec42fa2f5a128f363a97e7e)
Closes-Bug: #1403510
Co-Authored-By: Clark Boylan <clark.boylan@gmail.com>
Co-Authored-By: Doug Hellmann <doug@doughellmann.com>
Co-Authored-By: Jeremy Stanley <fungi@yuggoth.org>
",git fetch https://review.opendev.org/openstack/pbr refs/changes/31/142931/1 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/tests/test_version.py', 'pbr/packaging.py', 'pbr/version.py']",3,74f72dd5d69e28b7930719f37377bbd37515624f,setuptools-8," def __init__( self, major, minor=0, patch=0, prerelease_type=None, prerelease=None, dev_count=None): :raises: ValueError if both a prerelease version and dev_count is supplied. This is because semver (see the pbr semver documentation) does not permit both a prerelease version and a dev marker at the same time. else: prerelease=prerelease, dev_count=dev_count) return self._long_version(""~"") def _long_version(self, pre_separator, rc_marker=""""): return self._long_version(""."", ""0"") return self._long_version(None) def to_dev(self, dev_count): self._major, self._minor, self._patch, dev_count=dev_count)"," def __init__(self, major, minor=0, patch=0, prerelease_type=None, prerelease=None, dev_count=None, githash=None): :param githash: What tree hash is this version for. :raises: ValueError if both a prerelease version and dev_count or githash are supplied. This is because semver (see the pbr semver documentation) does not permit both a prerelease version and a dev marker at the same time. self._githash = githash elif self._dev_count > other._dev_count: elif self._githash == other._githash: # == it not < return False raise TypeError( ""same version with different hash has no defined order"") githash = None elif component.startswith('g'): # git hash - so use a dev_count of 1 as we have to have one dev_count = 1 githash = component[1:] if len(remainder) > 1: githash = remainder[1][1:] prerelease=prerelease, dev_count=dev_count, githash=githash) return self._long_version(""~"", ""+g"") def _long_version(self, pre_separator, hash_separator, rc_marker=""""): :param hash_separator: What separator to use to append the git hash. if self._githash: segments.append(hash_separator) segments.append(self._githash) return self._long_version(""."", "".g"", ""0"") return self._long_version(None, ""+g"") def to_dev(self, dev_count, githash): :param githash: The git hash of the tree with this version. self._major, self._minor, self._patch, dev_count=dev_count, githash=githash)",76,90
openstack%2Ftraining-guides~master~I970e994d9eba07635dca109f2292f33c29100a25,openstack/training-guides,master,I970e994d9eba07635dca109f2292f33c29100a25,Imported Translations from Transifex,MERGED,2014-12-23 06:00:58.000000000,2014-12-23 07:17:55.000000000,2014-12-23 07:17:55.000000000,"[{'_account_id': 3}, {'_account_id': 11109}]","[{'number': 1, 'created': '2014-12-23 06:00:58.000000000', 'files': ['doc/training-guides/locale/training-guides.pot', 'doc/training-guides/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/d12eddf265dd9cc2b868975cda5e4ee8710d0e0b', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I970e994d9eba07635dca109f2292f33c29100a25\n'}]",0,143600,d12eddf265dd9cc2b868975cda5e4ee8710d0e0b,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I970e994d9eba07635dca109f2292f33c29100a25
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/00/143600/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/training-guides/locale/training-guides.pot', 'doc/training-guides/locale/ja.po']",2,d12eddf265dd9cc2b868975cda5e4ee8710d0e0b,transifex/translations,"""POT-Creation-Date: 2014-12-22 18:26+0000\n"" ""PO-Revision-Date: 2014-12-22 18:26+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""#: ./doc/training-guides/st-training-guides.xml14(titleabbrev) #: ./doc/training-guides/st-training-guides.xml21(productname)#: ./doc/training-guides/st-training-guides.xml17(year)#: ./doc/training-guides/st-training-guides.xml18(year)#: ./doc/training-guides/st-training-guides.xml19(holder)#: ./doc/training-guides/st-training-guides.xml25(remark) #: ./doc/training-guides/st-training-guides.xml31(remark)#: ./doc/training-guides/st-training-guides.xml36(para)#: ./doc/training-guides/st-training-guides.xml43(date) msgid ""2014-12-17"" msgstr """" #: ./doc/training-guides/st-training-guides.xml47(para) msgid ""Icehouse released, adds support for automated labs installation."" msgstr """" #: ./doc/training-guides/st-training-guides.xml54(date)#: ./doc/training-guides/st-training-guides.xml58(para)#: ./doc/training-guides/st-training-guides.xml65(date)#: ./doc/training-guides/st-training-guides.xml69(para)#: ./doc/training-guides/st-training-guides.xml75(date)#: ./doc/training-guides/st-training-guides.xml79(para)#: ./doc/training-guides/st-training-guides.xml86(date)#: ./doc/training-guides/st-training-guides.xml90(para)#: ./doc/training-guides/st-training-guides.xml97(date)#: ./doc/training-guides/st-training-guides.xml101(para)#: ./doc/training-guides/st-training-guides.xml107(date)#: ./doc/training-guides/st-training-guides.xml111(para)","""POT-Creation-Date: 2014-12-14 22:48+0000\n"" ""PO-Revision-Date: 2014-12-18 11:11+0000\n"" ""Last-Translator: Tomoyuki KATO <tomo@dream.daynight.jp>\n""#: ./doc/training-guides/st-training-guides.xml9(titleabbrev) #: ./doc/training-guides/st-training-guides.xml16(productname)#: ./doc/training-guides/st-training-guides.xml12(year)#: ./doc/training-guides/st-training-guides.xml13(year)#: ./doc/training-guides/st-training-guides.xml14(holder)#: ./doc/training-guides/st-training-guides.xml20(remark) #: ./doc/training-guides/st-training-guides.xml26(remark)#: ./doc/training-guides/st-training-guides.xml31(para)#: ./doc/training-guides/st-training-guides.xml38(date)#: ./doc/training-guides/st-training-guides.xml42(para)#: ./doc/training-guides/st-training-guides.xml49(date)#: ./doc/training-guides/st-training-guides.xml53(para)#: ./doc/training-guides/st-training-guides.xml59(date)#: ./doc/training-guides/st-training-guides.xml63(para)#: ./doc/training-guides/st-training-guides.xml70(date)#: ./doc/training-guides/st-training-guides.xml74(para)#: ./doc/training-guides/st-training-guides.xml81(date)#: ./doc/training-guides/st-training-guides.xml85(para)#: ./doc/training-guides/st-training-guides.xml91(date)#: ./doc/training-guides/st-training-guides.xml95(para)",58,42
openstack%2Fnova~master~I4e5651631f5c9a3c6015ab603789fb155848448c,openstack/nova,master,I4e5651631f5c9a3c6015ab603789fb155848448c,Cleanup in test_availability_zone not to use wsgi_app,MERGED,2014-12-22 04:52:59.000000000,2014-12-23 07:13:21.000000000,2014-12-23 06:23:39.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-22 04:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2241b00c8e0b0bc7e05eabc7847d2c78ae206c11', 'message': 'Cleanup in test_availability_zone not to use wsgi_app\n\nIn API unit testing, making call through WSGI is little bit overhead,\nwherever applicable, unit tests can make direct call to controller\nmethods.\nSome unit tests needs WSGI call to tests more than one plugin together.\n\nThis patch makes above cleanup in test_availability_zone.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I4e5651631f5c9a3c6015ab603789fb155848448c\n'}, {'number': 2, 'created': '2014-12-22 08:47:12.000000000', 'files': ['nova/tests/unit/api/openstack/compute/contrib/test_availability_zone.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e792a061149a8f5b455416ee574493d4394aa2d4', 'message': 'Cleanup in test_availability_zone not to use wsgi_app\n\nIn API unit testing, making call through WSGI is little bit overhead,\nwherever applicable, unit tests can make direct call to controller\nmethods.\nSome unit tests need WSGI call to tests more than one plugin together.\n\nThis patch makes above cleanup in test_availability_zone.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I4e5651631f5c9a3c6015ab603789fb155848448c\n'}]",3,143360,e792a061149a8f5b455416ee574493d4394aa2d4,29,10,2,8556,,,0,"Cleanup in test_availability_zone not to use wsgi_app

In API unit testing, making call through WSGI is little bit overhead,
wherever applicable, unit tests can make direct call to controller
methods.
Some unit tests need WSGI call to tests more than one plugin together.

This patch makes above cleanup in test_availability_zone.

Partially implements blueprint v2-on-v3-api

Change-Id: I4e5651631f5c9a3c6015ab603789fb155848448c
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/143360/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/api/openstack/compute/contrib/test_availability_zone.py'],1,2241b00c8e0b0bc7e05eabc7847d2c78ae206c11,bp/v2-on-v3-api," self.controller = self.availability_zone.AvailabilityZoneController() result = self.controller._get_filtered_availability_zones(zones, True) result = self.controller._get_filtered_availability_zones(zones, False) req = webob.Request.blank('') req.environ['nova.context'] = context.get_admin_context() resp_dict = self.controller.index(req) req = webob.Request.blank('') resp_dict = self.controller.detail(req) req = webob.Request.blank('') resp_dict = self.controller.detail(req)"," def _get_wsgi_instance(self): return fakes.wsgi_app_v21(init_only=('os-availability-zone', 'servers')) az = self.availability_zone.AvailabilityZoneController() result = az._get_filtered_availability_zones(zones, True) result = az._get_filtered_availability_zones(zones, False) req = webob.Request.blank(self.url) resp = req.get_response(self._get_wsgi_instance()) self.assertEqual(resp.status_int, 200) resp_dict = jsonutils.loads(resp.body) availabilityZone = self.availability_zone.AvailabilityZoneController() req_url = self.url + '/detail' req = webob.Request.blank(req_url) req.method = 'GET' resp_dict = availabilityZone.detail(req) availabilityZone = self.availability_zone.AvailabilityZoneController() req_url = self.url + '/detail' req = webob.Request.blank(req_url) req.method = 'GET' resp_dict = availabilityZone.detail(req) def _get_wsgi_instance(self): return fakes.wsgi_app() ",11,25
openstack%2Fapi-site~master~Ife3fb0101ab14aac7bddae1c4c3342cd64c72cd0,openstack/api-site,master,Ife3fb0101ab14aac7bddae1c4c3342cd64c72cd0,Changes ID to tenantId for POST to create user with Identity v2.0 API,MERGED,2014-12-22 21:23:13.000000000,2014-12-23 07:03:52.000000000,2014-12-23 07:03:51.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-22 21:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/413d8e3fe4eda9cdcbdf1b01792bab1cead1811b', 'message': 'Changes ID to tenantId for POST to create user with Identity v2.0 API\n\nChange-Id: Ife3fb0101ab14aac7bddae1c4c3342cd64c72cd0\nCloses-bug: 1385781\n'}, {'number': 2, 'created': '2014-12-22 22:17:48.000000000', 'files': ['api-ref/src/wadls/identity-api/src/v2.0/wadl/identity-admin.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/0848e201ccc6dbf66f8eccba08e60b4f305def4b', 'message': 'Changes ID to tenantId for POST to create user with Identity v2.0 API\n\nChange-Id: Ife3fb0101ab14aac7bddae1c4c3342cd64c72cd0\nCloses-bug: 1385781\n'}]",0,143545,0848e201ccc6dbf66f8eccba08e60b4f305def4b,9,3,2,964,,,0,"Changes ID to tenantId for POST to create user with Identity v2.0 API

Change-Id: Ife3fb0101ab14aac7bddae1c4c3342cd64c72cd0
Closes-bug: 1385781
",git fetch https://review.opendev.org/openstack/api-site refs/changes/45/143545/2 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/identity-api/src/v2.0/wadl/identity-admin.wadl'],1,413d8e3fe4eda9cdcbdf1b01792bab1cead1811b,bug/1385781," <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""tenantId"" style=""plain"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN"">The tenant ID.</wadl:doc>"," <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""id"" style=""plain"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN"">The user ID.</wadl:doc>",4,3
openstack%2Fnova~master~Ie3dd4a3b3008af377a46ccc4dcadb6409101bc2d,openstack/nova,master,Ie3dd4a3b3008af377a46ccc4dcadb6409101bc2d,Remove unused db.api.aggregate_host_get_by_metadata_key,MERGED,2014-11-13 16:00:43.000000000,2014-12-23 07:01:49.000000000,2014-12-23 06:20:16.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-13 16:00:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f8e5fcffe74dc8b2e1e9050a76a38f1f94dfdafc', 'message': 'Remove unused db.api.aggregate_host_get_by_metadata_key\n\nChange-Id: Ie3dd4a3b3008af377a46ccc4dcadb6409101bc2d\n'}, {'number': 2, 'created': '2014-12-17 20:43:39.000000000', 'files': ['nova/db/api.py', 'nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/84bb4d210032e775d2c615ab351a2af160547494', 'message': 'Remove unused db.api.aggregate_host_get_by_metadata_key\n\nThe last use was removed in change\nI2ec7373f063ed728dde2af3b7c8259f4391885bc:\n\nobject-ify availability_zones\n\nChange-Id: Ie3dd4a3b3008af377a46ccc4dcadb6409101bc2d\n'}]",0,134265,84bb4d210032e775d2c615ab351a2af160547494,27,10,2,9555,,,0,"Remove unused db.api.aggregate_host_get_by_metadata_key

The last use was removed in change
I2ec7373f063ed728dde2af3b7c8259f4391885bc:

object-ify availability_zones

Change-Id: Ie3dd4a3b3008af377a46ccc4dcadb6409101bc2d
",git fetch https://review.opendev.org/openstack/nova refs/changes/65/134265/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/api.py', 'nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",3,f8e5fcffe74dc8b2e1e9050a76a38f1f94dfdafc,db/prune_api,,"def aggregate_host_get_by_metadata_key(context, key): rows = aggregate_get_by_metadata_key(context, key) metadata = collections.defaultdict(set) for agg in rows: for agghost in agg._hosts: metadata[agghost.host].add(agg._metadata[0]['value']) return dict(metadata) ",0,40
openstack%2Fmagnetodb~master~I52c6856e5e67cab5ec29f6fcdc0186ab45629327,openstack/magnetodb,master,I52c6856e5e67cab5ec29f6fcdc0186ab45629327,Add cassandra driver implementation with custom lsi support,MERGED,2014-07-16 21:09:40.000000000,2014-12-23 06:49:40.000000000,2014-12-23 06:49:38.000000000,"[{'_account_id': 3}, {'_account_id': 5538}, {'_account_id': 8188}, {'_account_id': 8491}, {'_account_id': 8601}, {'_account_id': 8863}, {'_account_id': 10676}, {'_account_id': 10829}]","[{'number': 1, 'created': '2014-07-16 21:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/2837bc3e3a8ecc2b268b076c8ef2e6972719a255', 'message': 'Add cassandra custom secondary index to code base\n\nChange-Id: I52c6856e5e67cab5ec29f6fcdc0186ab45629327\n'}, {'number': 2, 'created': '2014-07-17 09:15:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/12aa2a2c9482f35bab2e5be2ff09062384685ce9', 'message': 'Add cassandra custom secondary index to code base\n\nChange-Id: I52c6856e5e67cab5ec29f6fcdc0186ab45629327\n'}, {'number': 3, 'created': '2014-07-17 14:42:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/75e487c303db39aeeea08fcc604983ed3667a8c2', 'message': 'Add cassandra custom secondary index to code base\n\nChange-Id: I52c6856e5e67cab5ec29f6fcdc0186ab45629327\n'}, {'number': 4, 'created': '2014-08-14 13:44:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/f8715c0a4d88c84d48f15861c6140d2e71fc5476', 'message': '(DRAFT)Add cassandra custom secondary index to code base\n\nChange-Id: I52c6856e5e67cab5ec29f6fcdc0186ab45629327\n'}, {'number': 5, 'created': '2014-10-17 11:26:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/41990ff686913b792fbaa0e400799d99ca4a6fc7', 'message': '(DRAFT)Add cassandra custom secondary index to code base\n\nPartially implements: bp cassandra-backend-implementation-redesign\nChange-Id: I52c6856e5e67cab5ec29f6fcdc0186ab45629327\n'}, {'number': 6, 'created': '2014-11-20 12:02:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/696225f15a4b9de561ced0afd6563167d28a975e', 'message': '(DRAFT)Add cassandra custom secondary index to code base\n\nPartially implements: bp cassandra-backend-implementation-redesign\nChange-Id: I52c6856e5e67cab5ec29f6fcdc0186ab45629327\n'}, {'number': 7, 'created': '2014-11-26 13:44:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/8365af4c110219b8d43efc73d57105b4a1faada4', 'message': '(DRAFT)Add cassandra custom secondary index to code base\n\nPartially implements: bp cassandra-backend-implementation-redesign\nChange-Id: I52c6856e5e67cab5ec29f6fcdc0186ab45629327\n'}, {'number': 8, 'created': '2014-12-05 18:39:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/fcfa4cd7989fa02dfae6651b0d25779928068151', 'message': '(DRAFT)Add cassandra custom secondary index to code base\n\nAdd devstack support of cassandra custom index.\n\nCo-Authored-By: Alexei Vinogradov <alexei_vinogradov@symantec.com>\nPartially implements: bp cassandra-backend-implementation-redesign\nChange-Id: I52c6856e5e67cab5ec29f6fcdc0186ab45629327\n'}, {'number': 9, 'created': '2014-12-08 13:48:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/0eb0f18bbe8334608ef1190a066d601c17eacd09', 'message': '(DRAFT)Add cassandra custom secondary index to code base\n\nAdd devstack support of cassandra custom index.\n\nCo-Authored-By: Alexei Vinogradov <alexei_vinogradov@symantec.com>\nPartially implements: bp cassandra-backend-implementation-redesign\nChange-Id: I52c6856e5e67cab5ec29f6fcdc0186ab45629327\n'}, {'number': 10, 'created': '2014-12-16 14:41:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/177d6711f5296561ed017bb1f9f1c1c9cfbdc6d1', 'message': 'Add cassandra driver implementation with custom lsi support\n\nImplements: bp cassandra-backend-implementation-redesign\nChange-Id: I52c6856e5e67cab5ec29f6fcdc0186ab45629327\n'}, {'number': 11, 'created': '2014-12-17 11:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/2a790c21a4c2c5b25428bf2a03cf375eaf810c7b', 'message': 'Add cassandra driver implementation with custom lsi support\n\nImplements: bp cassandra-backend-implementation-redesign\nChange-Id: I52c6856e5e67cab5ec29f6fcdc0186ab45629327\n'}, {'number': 12, 'created': '2014-12-17 13:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/cf026abff074bf94221dfef79ce7a82ebaf6260b', 'message': 'Add cassandra driver implementation with custom lsi support\n\nImplements: bp cassandra-backend-implementation-redesign\nChange-Id: I52c6856e5e67cab5ec29f6fcdc0186ab45629327\n'}, {'number': 13, 'created': '2014-12-17 17:25:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/207f487a05e6e0485d021d31d9c83072a1bda3eb', 'message': 'Add cassandra driver implementation with custom lsi support\n\nImplements: bp cassandra-backend-implementation-redesign\nChange-Id: I52c6856e5e67cab5ec29f6fcdc0186ab45629327\n'}, {'number': 14, 'created': '2014-12-19 12:33:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/da63fa52a8996d840bdf6e0f473c027d32fac531', 'message': 'Add cassandra driver implementation with custom lsi support\n\nImplements: bp cassandra-backend-implementation-redesign\nChange-Id: I52c6856e5e67cab5ec29f6fcdc0186ab45629327\n'}, {'number': 15, 'created': '2014-12-19 12:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/b25abc9011e1abb7e6d8b074644139f52bfde3f0', 'message': 'Add cassandra driver implementation with custom lsi support\n\nImplements: bp cassandra-backend-implementation-redesign\nChange-Id: I52c6856e5e67cab5ec29f6fcdc0186ab45629327\n'}, {'number': 16, 'created': '2014-12-19 15:07:15.000000000', 'files': ['contrib/cassandra/magnetodb-cassandra-custom-indices/src/main/java/com/mirantis/magnetodb/cassandra/db/index/MagnetoDBLocalSecondaryIndex.java', 'magnetodb/api/openstack/v1/data/query.py', 'magnetodb/tests/storage/test_cassandra_impl.py', 'contrib/cassandra/magnetodb-cassandra-custom-indices/build.gradle', 'etc/magnetodb-async-task-executor.conf', 'contrib/cassandra/magnetodb-cassandra-custom-indices/src/main/java/com/mirantis/magnetodb/cassandra/db/index/MagnetoDBIndexSearcher.java', 'etc/magnetodb-api.conf', 'magnetodb/tests/storage/test_cassandra_with_custom_lsi_impl.py', 'contrib/devstack/lib/magnetodb', 'magnetodb/common/cassandra/cluster_handler.py', 'magnetodb/storage/driver/cassandra/cassandra_with_custom_lsi_impl.py', 'tools/install_cassandra_ccm.sh', 'etc/magnetodb-streaming-api.conf'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/751ed239399ad42acfe755628c58c670e1f27084', 'message': 'Add cassandra driver implementation with custom lsi support\n\nIn this patch added:\n 1) java library with custom LSI implementation\n 2) new storage driver for working with custom LSI\n 3) storage tests for this driver\n 4) fixes for our gate jobs - deployment of new java library with\n    Cassandra instalation\n\n\nImplements: bp cassandra-backend-implementation-redesign\nChange-Id: I52c6856e5e67cab5ec29f6fcdc0186ab45629327\n'}]",1,107500,751ed239399ad42acfe755628c58c670e1f27084,54,8,16,8601,,,0,"Add cassandra driver implementation with custom lsi support

In this patch added:
 1) java library with custom LSI implementation
 2) new storage driver for working with custom LSI
 3) storage tests for this driver
 4) fixes for our gate jobs - deployment of new java library with
    Cassandra instalation


Implements: bp cassandra-backend-implementation-redesign
Change-Id: I52c6856e5e67cab5ec29f6fcdc0186ab45629327
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/00/107500/1 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/cassandra/magnetodb-cassandra-custom-indeсes/src/main/java/com/mirantis/magnetodb/cassandra/db/index/MagnetoDBIndexSearcher.java', 'contrib/cassandra/magnetodb-cassandra-custom-indeсes/src/main/java/com/mirantis/magnetodb/cassandra/db/index/MagnetoDBLocalSecondaryIndex.java', 'contrib/cassandra/magnetodb-cassandra-custom-indeсes/build.gradle']",3,2837bc3e3a8ecc2b268b076c8ef2e6972719a255,bp/cassandra-backend-implementation-redesign,"apply plugin: 'java' apply plugin: 'maven' version = '0.0.1' sourceCompatibility = 1.7 targetCompatibility = 1.7 repositories { mavenCentral() mavenLocal() } dependencies { //provided dependencies compile group: 'org.apache.cassandra', name: 'cassandra-all', version: '2.0.8' } install { repositories.mavenInstaller { pom.version = '0.0.1' pom.groupId = 'com.mirantis.magnetodb' pom.artifactId = 'cassandra-custom-indeсes' } } ",,620,0
openstack%2Fopenstack-manuals~master~Icd548b17eb43536d8b1eddf55ca10921725d6cd6,openstack/openstack-manuals,master,Icd548b17eb43536d8b1eddf55ca10921725d6cd6,Imported Translations from Transifex,MERGED,2014-12-23 06:14:34.000000000,2014-12-23 06:49:19.000000000,2014-12-23 06:49:19.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-23 06:14:34.000000000', 'files': ['doc/install-guide/locale/install-guide.pot', 'doc/install-guide/locale/pt_BR.po', 'doc/config-reference/locale/config-reference.pot', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/common/locale/common.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/glossary/locale/ko_KR.po', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/common/locale/fr.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1d9bb9155a38e9b2372437142287c64d17a9fb72', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Icd548b17eb43536d8b1eddf55ca10921725d6cd6\n'}]",0,143604,1d9bb9155a38e9b2372437142287c64d17a9fb72,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Icd548b17eb43536d8b1eddf55ca10921725d6cd6
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/04/143604/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/install-guide.pot', 'doc/install-guide/locale/pt_BR.po', 'doc/config-reference/locale/config-reference.pot', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/common/locale/common.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/glossary/locale/ko_KR.po', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/common/locale/fr.po']",10,1d9bb9155a38e9b2372437142287c64d17a9fb72,transifex/translations,"""POT-Creation-Date: 2014-12-23 02:43+0000\n"" ""PO-Revision-Date: 2014-12-22 12:30+0000\n""","""POT-Creation-Date: 2014-12-22 02:28+0000\n"" ""PO-Revision-Date: 2014-12-22 02:28+0000\n""#: ./doc/common/tables/neutron-ml2_mlnx.xml13(th)#: ./doc/common/tables/neutron-mlnx.xml13(th)#: ./doc/common/tables/neutron-ml2_mlnx.xml12(th)#: ./doc/common/tables/neutron-mlnx.xml12(th)#: ./doc/common/tables/neutron-ml2_mlnx.xml18(th) #: ./doc/common/tables/neutron-mlnx.xml18(th)#: ./doc/common/tables/neutron-mlnx.xml30(td)#: ./doc/common/tables/neutron-mlnx.xml41(td)#: ./doc/common/tables/neutron-mlnx.xml29(td)#: ./doc/common/tables/neutron-mlnx.xml53(td)#: ./doc/common/tables/neutron-ml2_mlnx.xml7(caption) msgid ""Description of Mellanox ML2 mechanism driver configuration options"" msgstr """" #: ./doc/common/tables/neutron-ml2_mlnx.xml21(td) msgid ""vnic_type = mlnx_direct"" msgstr """" #: ./doc/common/tables/neutron-ml2_mlnx.xml22(td) msgid ""(StrOpt) Type of VM network interface: mlnx_direct or hostdev"" msgstr """" #: ./doc/common/tables/neutron-mlnx.xml7(caption) msgid ""Description of Mellanox configuration options"" msgstr """" #: ./doc/common/tables/neutron-mlnx.xml21(td) msgid ""backoff_rate = 2"" msgstr ""backoff_rate = 2"" #: ./doc/common/tables/neutron-mlnx.xml22(td) msgid """" ""(IntOpt) backoff rate multiplier for waiting period between retries for "" ""request to daemon, i.e. value of 2 will double the request timeout each "" ""retry"" msgstr """" #: ./doc/common/tables/neutron-mlnx.xml25(td) msgid ""daemon_endpoint = tcp://127.0.0.1:60001"" msgstr ""daemon_endpoint = tcp://127.0.0.1:60001"" #: ./doc/common/tables/neutron-mlnx.xml26(td) msgid ""(StrOpt) eswitch daemon end point"" msgstr """" #: ./doc/common/tables/neutron-mlnx.xml33(td) msgid ""request_timeout = 3000"" msgstr ""request_timeout = 3000"" #: ./doc/common/tables/neutron-mlnx.xml34(td) msgid """" ""(IntOpt) The number of milliseconds the agent will wait for response on "" ""request to daemon."" msgstr """" #: ./doc/common/tables/neutron-mlnx.xml37(th) msgid ""[MLNX]"" msgstr """" #: ./doc/common/tables/neutron-mlnx.xml40(td) msgid ""network_vlan_ranges = default:1:1000"" msgstr """" #: ./doc/common/tables/neutron-mlnx.xml44(td) msgid ""physical_network_type = eth"" msgstr """" #: ./doc/common/tables/neutron-mlnx.xml45(td) msgid ""(StrOpt) Physical network type for provider network (eth or ib)"" msgstr """" #: ./doc/common/tables/neutron-mlnx.xml48(td) msgid ""physical_network_type_mappings ="" msgstr """" #: ./doc/common/tables/neutron-mlnx.xml49(td) msgid """" ""(ListOpt) List of &lt;physical_network&gt;:&lt;physical_network_type&gt; "" ""with physical_network_type is either eth or ib"" msgstr """" #: ./doc/common/tables/neutron-mlnx.xml52(td) msgid ""tenant_network_type = vlan"" msgstr """" ",235,455
openstack%2Fnova~master~I8af9a5a2ba4f87ef221b9276df7d08395e44f021,openstack/nova,master,I8af9a5a2ba4f87ef221b9276df7d08395e44f021,libvirt: pass Host object into firewall class,MERGED,2014-12-10 15:06:18.000000000,2014-12-23 06:39:08.000000000,2014-12-23 06:39:05.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 15:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7657d272f17b2dd9b087bfac14c511249ec91ff', 'message': 'libvirt: pass Host object into firewall class\n\nInstead of passing in a get_connection callback function,\ngive the firewall class impls direct access to the new Host\nobject instead. Make use of the fakelibvirt fixture to\navoid needing to mock out the libvirt APIs directly.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I8af9a5a2ba4f87ef221b9276df7d08395e44f021\n'}, {'number': 2, 'created': '2014-12-10 17:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f931580a9d2cab9593b3d1a44341e285b456d94b', 'message': 'libvirt: pass Host object into firewall class\n\nInstead of passing in a get_connection callback function,\ngive the firewall class impls direct access to the new Host\nobject instead. Make use of the fakelibvirt fixture to\navoid needing to mock out the libvirt APIs directly.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I8af9a5a2ba4f87ef221b9276df7d08395e44f021\n'}, {'number': 3, 'created': '2014-12-16 12:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/95f38158c872c1796d148bf87fff47b97b9f7015', 'message': 'libvirt: pass Host object into firewall class\n\nInstead of passing in a get_connection callback function,\ngive the firewall class impls direct access to the new Host\nobject instead. Make use of the fakelibvirt fixture to\navoid needing to mock out the libvirt APIs directly.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I8af9a5a2ba4f87ef221b9276df7d08395e44f021\n'}, {'number': 4, 'created': '2014-12-17 11:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/80ebfcf86e0a9701fec63c62d02983e51e808830', 'message': 'libvirt: pass Host object into firewall class\n\nInstead of passing in a get_connection callback function,\ngive the firewall class impls direct access to the new Host\nobject instead. Make use of the fakelibvirt fixture to\navoid needing to mock out the libvirt APIs directly.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I8af9a5a2ba4f87ef221b9276df7d08395e44f021\n'}, {'number': 5, 'created': '2014-12-18 14:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/586085d4b06e2fa2b5d1b9a1f3293f0a3c1b7b5a', 'message': 'libvirt: pass Host object into firewall class\n\nInstead of passing in a get_connection callback function,\ngive the firewall class impls direct access to the new Host\nobject instead. Make use of the fakelibvirt fixture to\navoid needing to mock out the libvirt APIs directly.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I8af9a5a2ba4f87ef221b9276df7d08395e44f021\n'}, {'number': 6, 'created': '2014-12-19 11:33:23.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_firewall.py', 'nova/virt/libvirt/driver.py', 'nova/virt/libvirt/firewall.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cae7a6626cdb2fc8985bf4a8b7fadf0bcecc6645', 'message': 'libvirt: pass Host object into firewall class\n\nInstead of passing in a get_connection callback function,\ngive the firewall class impls direct access to the new Host\nobject instead. Make use of the fakelibvirt fixture to\navoid needing to mock out the libvirt APIs directly.\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I8af9a5a2ba4f87ef221b9276df7d08395e44f021\n'}]",5,140718,cae7a6626cdb2fc8985bf4a8b7fadf0bcecc6645,54,13,6,1779,,,0,"libvirt: pass Host object into firewall class

Instead of passing in a get_connection callback function,
give the firewall class impls direct access to the new Host
object instead. Make use of the fakelibvirt fixture to
avoid needing to mock out the libvirt APIs directly.

Blueprint: libvirt-driver-class-refactor
Change-Id: I8af9a5a2ba4f87ef221b9276df7d08395e44f021
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/140718/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/libvirt/test_firewall.py', 'nova/virt/libvirt/driver.py', 'nova/virt/libvirt/firewall.py']",3,e7657d272f17b2dd9b087bfac14c511249ec91ff,libvirt-driver-refactor-3," def __init__(self, virtapi, host, **kwargs): self._host = host return self._host.get_connection() self.nwfilter = NWFilterFirewall(virtapi, kwargs['host'])"," def __init__(self, virtapi, get_connection, **kwargs): self._libvirt_get_connection = get_connection return self._libvirt_get_connection() self.nwfilter = NWFilterFirewall(virtapi, kwargs['get_connection'])",42,34
openstack%2Fnova~master~Ic01956a0fc1ef641dd1b9a28caa40debdc8c114c,openstack/nova,master,Ic01956a0fc1ef641dd1b9a28caa40debdc8c114c,Fix get_all API to pass search option filter to cinder api,MERGED,2014-11-19 09:03:08.000000000,2014-12-23 06:21:16.000000000,2014-12-23 06:21:13.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 7191}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12410}]","[{'number': 1, 'created': '2014-11-19 09:03:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/18de225762075e1ef2f3fb8b85096637a40390ca', 'message': 'Fix api to pass the search option filter to cinder api\n\nChange-Id: Ic01956a0fc1ef641dd1b9a28caa40debdc8c114c\nCloses-Bug: #1391748\n'}, {'number': 2, 'created': '2014-11-19 09:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0bae3e09cf045fbaf79e4127d7fc2f1f28b31121', 'message': 'Fix get_all API to pass the search option filter to cinder API\n\nChange-Id: Ic01956a0fc1ef641dd1b9a28caa40debdc8c114c\nCloses-Bug: #1391748\n'}, {'number': 3, 'created': '2014-11-20 08:45:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ec6c8c167d92bd2f783d8d37f730b8f8a2b3c1d2', 'message': 'Fix get_all API to pass search option filter to cinder api\n\nChange-Id: Ic01956a0fc1ef641dd1b9a28caa40debdc8c114c\nCloses-Bug: #1391748\n'}, {'number': 4, 'created': '2014-11-20 16:44:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/60b419b0b7c27c10fe7ad3757624b4be824ec57d', 'message': 'Fix get_all API to pass search option filter to cinder api\n\nChange-Id: Ic01956a0fc1ef641dd1b9a28caa40debdc8c114c\nCloses-Bug: #1391748\n'}, {'number': 5, 'created': '2014-11-25 05:13:50.000000000', 'files': ['nova/tests/unit/volume/test_cinder.py', 'nova/volume/cinder.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1054a906481245597e989e20741445bddca6668f', 'message': 'Fix get_all API to pass search option filter to cinder api\n\nChange-Id: Ic01956a0fc1ef641dd1b9a28caa40debdc8c114c\nCloses-Bug: #1391748\n'}]",3,135537,1054a906481245597e989e20741445bddca6668f,49,12,5,12410,,,0,"Fix get_all API to pass search option filter to cinder api

Change-Id: Ic01956a0fc1ef641dd1b9a28caa40debdc8c114c
Closes-Bug: #1391748
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/135537/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/volume/cinder.py'],1,18de225762075e1ef2f3fb8b85096637a40390ca,bug/1391748," items = cinderclient(context).volumes.list(detailed=True, search_opts=search_opts)", items = cinderclient(context).volumes.list(detailed=True),2,1
openstack%2Fnova~master~Ibe336eb29c8263765f79124175aac2029d0d68ce,openstack/nova,master,Ibe336eb29c8263765f79124175aac2029d0d68ce,Remove unused db.api.dnsdomain_list,MERGED,2014-11-13 16:01:24.000000000,2014-12-23 06:20:56.000000000,2014-12-23 06:20:53.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-13 16:01:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/98856d47b5537349b5f6a8775ca800dadf525efe', 'message': 'Remove unused db.api.dnsdomain_list\n\nChange-Id: Ibe336eb29c8263765f79124175aac2029d0d68ce\n'}, {'number': 2, 'created': '2014-12-08 16:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84e510071f1e4db55b9325b34097219ba50d5e9d', 'message': 'Remove unused db.api.dnsdomain_list\n\nChange-Id: Ibe336eb29c8263765f79124175aac2029d0d68ce\n'}, {'number': 3, 'created': '2014-12-17 20:59:00.000000000', 'files': ['nova/db/api.py', 'nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6672595344579576310f7af323f55ac9c88ce25e', 'message': 'Remove unused db.api.dnsdomain_list\n\nThe last use was removed in change\nI4b682affbbe988638c0c834b12a121e6a871080a:\n\nUpdate nova.network to use DNSDomain object\n\nChange-Id: Ibe336eb29c8263765f79124175aac2029d0d68ce\n'}]",0,134272,6672595344579576310f7af323f55ac9c88ce25e,41,13,3,9555,,,0,"Remove unused db.api.dnsdomain_list

The last use was removed in change
I4b682affbbe988638c0c834b12a121e6a871080a:

Update nova.network to use DNSDomain object

Change-Id: Ibe336eb29c8263765f79124175aac2029d0d68ce
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/134272/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/api.py', 'nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",3,98856d47b5537349b5f6a8775ca800dadf525efe,db/prune_api,,"@require_context def dnsdomain_list(context): query = model_query(context, models.DNSDomain, read_deleted=""no"") return [row.domain for row in query.all()] ",0,18
openstack%2Fnova~master~Ifb684ed73ec5e7ad08eb297e3b043053d3456829,openstack/nova,master,Ifb684ed73ec5e7ad08eb297e3b043053d3456829,Resource tracker: use brackets for line wrap,MERGED,2014-10-06 13:08:58.000000000,2014-12-23 06:14:45.000000000,2014-12-23 06:04:41.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5367}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 9708}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-06 13:08:58.000000000', 'files': ['nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6d7a105afa98d6585461dcffcf410d6364dbc7aa', 'message': 'Resource tracker: use brackets for line wrap\n\nUse () instead of \\ for a line wrap.\n\nTrivialFix\n\nChange-Id: Ifb684ed73ec5e7ad08eb297e3b043053d3456829\n'}]",0,126288,6d7a105afa98d6585461dcffcf410d6364dbc7aa,20,12,1,1653,,,0,"Resource tracker: use brackets for line wrap

Use () instead of \ for a line wrap.

TrivialFix

Change-Id: Ifb684ed73ec5e7ad08eb297e3b043053d3456829
",git fetch https://review.opendev.org/openstack/nova refs/changes/88/126288/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/resource_tracker.py'],1,6d7a105afa98d6585461dcffcf410d6364dbc7aa,remove-dash, if ('pci_passthrough_devices' in resources and resources['pci_passthrough_devices']):, if 'pci_passthrough_devices' in resources and \ resources['pci_passthrough_devices']:,2,2
openstack%2Fnova~master~Id50c9af365c0f812862f44288a84f8da46dd007c,openstack/nova,master,Id50c9af365c0f812862f44288a84f8da46dd007c,Remove unused db.api.get_ec2_instance_id_by_uuid,MERGED,2014-11-13 16:00:38.000000000,2014-12-23 06:13:29.000000000,2014-12-23 06:13:26.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-13 16:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d466db20c0d5eb12e24fa83c7b124f36dc0fe6df', 'message': 'Remove unused db.api.get_ec2_instance_id_by_uuid\n\nChange-Id: Id50c9af365c0f812862f44288a84f8da46dd007c\n'}, {'number': 2, 'created': '2014-12-17 20:24:49.000000000', 'files': ['nova/db/api.py', 'nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3b01ca29ac65f592a9011fb126d8b57ee5246835', 'message': 'Remove unused db.api.get_ec2_instance_id_by_uuid\n\nThe last use was removed in change\nI66d60a29f0d909edd381e8492a4754bdd0eb8e52:\n\nec2: Convert to use EC2InstanceMapping object\n\nChange-Id: Id50c9af365c0f812862f44288a84f8da46dd007c\n'}]",0,134263,3b01ca29ac65f592a9011fb126d8b57ee5246835,26,10,2,9555,,,0,"Remove unused db.api.get_ec2_instance_id_by_uuid

The last use was removed in change
I66d60a29f0d909edd381e8492a4754bdd0eb8e52:

ec2: Convert to use EC2InstanceMapping object

Change-Id: Id50c9af365c0f812862f44288a84f8da46dd007c
",git fetch https://review.opendev.org/openstack/nova refs/changes/63/134263/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/api.py', 'nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",3,d466db20c0d5eb12e24fa83c7b124f36dc0fe6df,db/prune_api,,"def get_ec2_instance_id_by_uuid(context, instance_id): result = ec2_instance_get_by_uuid(context, instance_id) return result['id'] @require_context",0,22
openstack%2Fneutron~master~I0d308127081bb2fa4ff7d7e0ed2f1b6e915163c9,openstack/neutron,master,I0d308127081bb2fa4ff7d7e0ed2f1b6e915163c9,Prevent symlinks to be added to the tree,MERGED,2014-12-21 04:58:25.000000000,2014-12-23 06:08:10.000000000,2014-12-23 06:08:08.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 8279}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 14208}]","[{'number': 1, 'created': '2014-12-21 04:58:25.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3bf7e4574267eca9b013d5485477458baf7a2891', 'message': 'Prevent symlinks to be added to the tree\n\nSymlinks cannot be allowed because they are not supported by distutils.\nAdding them results into package build failures.\n\nThis patch add a check that verifies that no symlinks can slip in.\n\nCloses-bug: #1404605\n\nChange-Id: I0d308127081bb2fa4ff7d7e0ed2f1b6e915163c9\n'}]",3,143288,3bf7e4574267eca9b013d5485477458baf7a2891,31,18,1,748,,,0,"Prevent symlinks to be added to the tree

Symlinks cannot be allowed because they are not supported by distutils.
Adding them results into package build failures.

This patch add a check that verifies that no symlinks can slip in.

Closes-bug: #1404605

Change-Id: I0d308127081bb2fa4ff7d7e0ed2f1b6e915163c9
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/143288/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,3bf7e4574267eca9b013d5485477458baf7a2891,bug/1404605," sh -c ""if [ $(find . -type l ! -path '*.tox*' | wc -l) -ge 1 ]; then echo 'Symlinks are not allowed!' && exit 1; fi""",,1,0
openstack%2Ftempest~master~If5e3fc52ab3617486900af91d90c1d8d24367151,openstack/tempest,master,If5e3fc52ab3617486900af91d90c1d8d24367151,Unskip test_get_server_diagnostics_by_admin(),ABANDONED,2014-09-15 14:15:16.000000000,2014-12-23 06:00:05.000000000,,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-15 14:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9bb3c038b06af0812115e4bac178f387de80ac07', 'message': 'Unskip test_get_server_diagnostics_by_admin()\n\ntest_get_server_diagnostics_by_admin() was skipped because of bug\n1240043 which is now in a state which should allow us to unskip it.\n\nChange-Id: If5e3fc52ab3617486900af91d90c1d8d24367151\nRelated-Bug: #1240043\n'}, {'number': 2, 'created': '2014-09-15 19:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cbdfb8799bd234dc10e5ee18b602cfbc499d3ef6', 'message': 'Unskip test_get_server_diagnostics_by_admin()\n\ntest_get_server_diagnostics_by_admin() was skipped because of bug\n1240043 which is now in a state which should allow us to unskip it.\n\nChange-Id: If5e3fc52ab3617486900af91d90c1d8d24367151\nRelated-Bug: #1240043\n'}, {'number': 3, 'created': '2014-11-20 03:39:48.000000000', 'files': ['tempest/api/compute/v3/admin/test_servers.py', 'tempest/api/compute/admin/test_servers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/868a6fc64359fb9d01764ca3b8d6a22c1c822214', 'message': 'Unskip test_get_server_diagnostics_by_admin()\n\ntest_get_server_diagnostics_by_admin() was skipped because of bug\n1240043 which is now in a state which should allow us to unskip it.\n\nChange-Id: If5e3fc52ab3617486900af91d90c1d8d24367151\nRelated-Bug: #1240043\n'}]",0,121572,868a6fc64359fb9d01764ca3b8d6a22c1c822214,12,3,3,5196,,,0,"Unskip test_get_server_diagnostics_by_admin()

test_get_server_diagnostics_by_admin() was skipped because of bug
1240043 which is now in a state which should allow us to unskip it.

Change-Id: If5e3fc52ab3617486900af91d90c1d8d24367151
Related-Bug: #1240043
",git fetch https://review.opendev.org/openstack/tempest refs/changes/72/121572/3 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/v3/admin/test_servers.py', 'tempest/api/compute/admin/test_servers.py']",2,9bb3c038b06af0812115e4bac178f387de80ac07,bug/1240043,," @test.skip_because(bug=""1240043"")",0,2
openstack%2Fdevstack~master~I8ee31bd12c59f68ad2d06f098f402c3c2fba44c9,openstack/devstack,master,I8ee31bd12c59f68ad2d06f098f402c3c2fba44c9,Specify DIB image cache location when creating ramdisk,ABANDONED,2014-12-23 00:20:24.000000000,2014-12-23 05:44:32.000000000,,"[{'_account_id': 3}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-23 00:20:24.000000000', 'files': ['lib/ironic'], 'web_link': 'https://opendev.org/openstack/devstack/commit/bcecb6afa7f813fa8239d21acca0b4c54bbd41a9', 'message': ""Specify DIB image cache location when creating ramdisk\n\nEnsure DIB's cache is specified when creating baremetal deploy\nramdisks.  Long term, we will be migrating ramdisk creation to\nuse lib/dib, which already specifies this.\n\nChange-Id: I8ee31bd12c59f68ad2d06f098f402c3c2fba44c9\n""}]",0,143573,bcecb6afa7f813fa8239d21acca0b4c54bbd41a9,4,2,1,1420,,,0,"Specify DIB image cache location when creating ramdisk

Ensure DIB's cache is specified when creating baremetal deploy
ramdisks.  Long term, we will be migrating ramdisk creation to
use lib/dib, which already specifies this.

Change-Id: I8ee31bd12c59f68ad2d06f098f402c3c2fba44c9
",git fetch https://review.opendev.org/openstack/devstack refs/changes/73/143573/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/ironic'],1,bcecb6afa7f813fa8239d21acca0b4c54bbd41a9,, ramdisk-image-create --image-cache $DATA_DIR/diskimage-builder/image-create \ $IRONIC_DEPLOY_FLAVOR \, ramdisk-image-create $IRONIC_DEPLOY_FLAVOR \,2,1
openstack%2Fnova~master~I5f9b715b2f358d5b7db1a36f7bf9922d461771be,openstack/nova,master,I5f9b715b2f358d5b7db1a36f7bf9922d461771be,Config bindings: remove redundant brackets,MERGED,2014-11-10 09:52:31.000000000,2014-12-23 05:42:44.000000000,2014-12-23 05:42:41.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 7133}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-10 09:52:31.000000000', 'files': ['nova/api/auth.py', 'nova/virt/ironic/driver.py', 'nova/console/serial.py', 'nova/api/openstack/compute/contrib/os_tenant_networks.py', 'nova/network/linux_net.py', 'nova/api/metadata/base.py', 'nova/quota.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bc411531a03725aaa317453b5e5a0d910af8ea2f', 'message': 'Config bindings: remove redundant brackets\n\nThere were cases where the help text had redundant brackets. This\nwas removed.\n\nTrivialFix\n\nChange-Id: I5f9b715b2f358d5b7db1a36f7bf9922d461771be\n'}]",0,133418,bc411531a03725aaa317453b5e5a0d910af8ea2f,13,9,1,1653,,,0,"Config bindings: remove redundant brackets

There were cases where the help text had redundant brackets. This
was removed.

TrivialFix

Change-Id: I5f9b715b2f358d5b7db1a36f7bf9922d461771be
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/133418/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/auth.py', 'nova/virt/ironic/driver.py', 'nova/console/serial.py', 'nova/api/openstack/compute/contrib/os_tenant_networks.py', 'nova/network/linux_net.py', 'nova/api/metadata/base.py', 'nova/quota.py', 'nova/compute/manager.py']",8,bc411531a03725aaa317453b5e5a0d910af8ea2f,help-brackets," help='Interval in seconds for retrying failed instance file ' 'deletes. Set to -1 to disable. ' 'Setting this to 0 will run at the default rate.'), help='The number of times to attempt to reap an instance\'s ' 'files.'),"," help=('Interval in seconds for retrying failed instance file ' 'deletes. Set to -1 to disable. ' 'Setting this to 0 will run at the default rate.')), help=('The number of times to attempt to reap an instance\'s ' 'files.')),",26,26
openstack%2Fnova~master~If70b6b63caf6a167ae8b158fd76c98ac7197a524,openstack/nova,master,If70b6b63caf6a167ae8b158fd76c98ac7197a524,Make direct call to controller in test_console_auth_tokens,MERGED,2014-12-19 06:18:35.000000000,2014-12-23 05:42:22.000000000,2014-12-23 05:42:19.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-19 06:18:35.000000000', 'files': ['nova/tests/unit/api/openstack/compute/contrib/test_console_auth_tokens.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b127d03b9feb6a047cccf224c39417faaabc980c', 'message': 'Make direct call to controller in test_console_auth_tokens\n\nIn API unit testing, making call through WSGI is little bit overhead,\nwherever applicable, unit tests can make direct call to controller\nmethods.\n\nSome unit tests needs WSGI call to tests more than one plugin together.\n\nThis patch makes above cleanup in test_console_auth_tokens.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: If70b6b63caf6a167ae8b158fd76c98ac7197a524\n'}]",0,142993,b127d03b9feb6a047cccf224c39417faaabc980c,15,9,1,8556,,,0,"Make direct call to controller in test_console_auth_tokens

In API unit testing, making call through WSGI is little bit overhead,
wherever applicable, unit tests can make direct call to controller
methods.

Some unit tests needs WSGI call to tests more than one plugin together.

This patch makes above cleanup in test_console_auth_tokens.

Partially implements blueprint v2-on-v3-api

Change-Id: If70b6b63caf6a167ae8b158fd76c98ac7197a524
",git fetch https://review.opendev.org/openstack/nova refs/changes/93/142993/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/api/openstack/compute/contrib/test_console_auth_tokens.py'],1,b127d03b9feb6a047cccf224c39417faaabc980c,bp/v2-on-v3-api,"from nova.api.openstack.compute.contrib import console_auth_tokens \ as console_auth_tokens_v2 from nova.api.openstack.compute.plugins.v3 import console_auth_tokens \ as console_auth_tokens_v21 controller_class = console_auth_tokens_v21 self.controller = self.controller_class.ConsoleAuthTokensController() req = fakes.HTTPRequest.blank('', use_admin_context=True) output = self.controller.show(req, fakes.FAKE_UUID) req = fakes.HTTPRequest.blank('', use_admin_context=True) self.assertRaises(webob.exc.HTTPNotFound, self.controller.show, req, fakes.FAKE_UUID) req = fakes.HTTPRequest.blank('', use_admin_context=True) self.assertRaises(webob.exc.HTTPUnauthorized, self.controller.show, req, fakes.FAKE_UUID) controller_class = console_auth_tokens_v2","from oslo.serialization import jsonutilsfrom nova import contextCONF.import_opt('osapi_compute_ext_list', 'nova.api.openstack.compute.contrib') _FAKE_URL = '/v2/fake/os-console-auth-tokens/1' self._set_up_wsgi_app() def _set_up_wsgi_app(self): self.app = fakes.wsgi_app_v21( init_only=('os-console-auth-tokens'), fake_auth_context=self._get_admin_context()) def _get_admin_context(self): ctxt = context.get_admin_context() ctxt.user_id = 'fake' ctxt.project_id = 'fake' return ctxt def _create_request(self): req = webob.Request.blank(self._FAKE_URL) req.method = ""GET"" req.headers[""content-type""] = ""application/json"" return req req = self._create_request() res = req.get_response(self.app) self.assertEqual(200, res.status_int) output = jsonutils.loads(res.body) req = self._create_request() res = req.get_response(self.app) self.assertEqual(404, res.status_int) req = self._create_request() res = req.get_response(self.app) self.assertEqual(401, res.status_int) def _set_up_wsgi_app(self): self.flags( osapi_compute_extension=[ 'nova.api.openstack.compute.contrib.select_extensions'], osapi_compute_ext_list=['Console_auth_tokens']) self.app = fakes.wsgi_app(init_only=('os-console-auth-tokens',), fake_auth_context=self._get_admin_context())",15,41
openstack%2Fnova~master~I6e915da3e8847065dab227bf8c961f690a6db98a,openstack/nova,master,I6e915da3e8847065dab227bf8c961f690a6db98a,Call controller methods directly in test_console_output,MERGED,2014-12-19 06:33:23.000000000,2014-12-23 05:42:01.000000000,2014-12-23 05:41:58.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-19 06:33:23.000000000', 'files': ['nova/tests/unit/api/openstack/compute/contrib/test_console_output.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b2f0d2d348ddb80bf73c6e367c7b3d3cdd736c04', 'message': 'Call controller methods directly in test_console_output\n\nIn API unit testing, making call through WSGI is little bit overhead,\nwherever applicable, unit tests can make direct call to controller\nmethods.\n\nSome unit tests needs WSGI call to tests more than one plugin together.\n\nThis patch makes above cleanup in test_console_output.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I6e915da3e8847065dab227bf8c961f690a6db98a\n'}]",0,142995,b2f0d2d348ddb80bf73c6e367c7b3d3cdd736c04,19,10,1,8556,,,0,"Call controller methods directly in test_console_output

In API unit testing, making call through WSGI is little bit overhead,
wherever applicable, unit tests can make direct call to controller
methods.

Some unit tests needs WSGI call to tests more than one plugin together.

This patch makes above cleanup in test_console_output.

Partially implements blueprint v2-on-v3-api

Change-Id: I6e915da3e8847065dab227bf8c961f690a6db98a
",git fetch https://review.opendev.org/openstack/nova refs/changes/95/142995/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/api/openstack/compute/contrib/test_console_output.py'],1,b2f0d2d348ddb80bf73c6e367c7b3d3cdd736c04,bp/v2-on-v3-api,"import webob from nova.api.openstack.compute.contrib import console_output \ as console_output_v2 from nova.api.openstack.compute.plugins.v3 import console_output \ as console_output_v21 controller_class = console_output_v21 validation_error = exception.ValidationError self.controller = self.controller_class.ConsoleOutputController() def _get_console_output(self, length_dict=None): req = fakes.HTTPRequest.blank('') return self.controller.get_console_output(req, fakes.FAKE_UUID, body=body) def _check_console_output_failure(self, exception, body): req = fakes.HTTPRequest.blank('') self.assertRaises(exception, self.controller.get_console_output, req, fakes.FAKE_UUID, body=body) output = self._get_console_output() output = self._get_console_output(length_dict={'length': 3}) output = self._get_console_output(length_dict={'length': None}) output = self._get_console_output(length_dict={'length': '3'}) output = self._get_console_output() body = {'os-getConsoleOutput': {}} self._check_console_output_failure(webob.exc.HTTPNotFound, body) body = {'os-getConsoleOutput': {}} self._check_console_output_failure(webob.exc.HTTPNotFound, body) self._check_console_output_failure(self.validation_error, body) self._check_console_output_failure(self.validation_error, body) self._check_console_output_failure(self.validation_error, body) body = {'os-getConsoleOutput': {}} self._check_console_output_failure(webob.exc.HTTPConflict, body) body = {'os-getConsoleOutput': {}} self._check_console_output_failure(webob.exc.HTTPNotImplemented, body) body = {'os-getConsoleOutput': {'length': True}} self._check_console_output_failure(self.validation_error, body) controller_class = console_output_v2 validation_error = webob.exc.HTTPBadRequest","from oslo.serialization import jsonutils application_type = ""application/json"" action_url = '/v2/fake/servers/1/action' self.app = self._get_app() def _get_app(self): return fakes.wsgi_app_v21(init_only=('servers', 'os-console-output')) def _get_response(self, length_dict=None): req = fakes.HTTPRequest.blank(self.action_url) req.method = ""POST"" req.body = jsonutils.dumps(body) req.headers[""content-type""] = self.application_type res = req.get_response(self.app) return res res = self._get_response() output = jsonutils.loads(res.body) self.assertEqual(200, res.status_int) res = self._get_response(length_dict={'length': 3}) output = jsonutils.loads(res.body) self.assertEqual(200, res.status_int) res = self._get_response(length_dict={'length': None}) output = jsonutils.loads(res.body) self.assertEqual(200, res.status_int) res = self._get_response(length_dict={'length': '3'}) output = jsonutils.loads(res.body) self.assertEqual(200, res.status_int) res = self._get_response() output = jsonutils.loads(res.body) self.assertEqual(200, res.status_int) res = self._get_response() self.assertEqual(404, res.status_int) res = self._get_response() self.assertEqual(404, res.status_int) def _get_console_output_bad_request_case(self, body): req = fakes.HTTPRequest.blank(self.action_url) req.method = ""POST"" req.body = jsonutils.dumps(body) req.headers[""content-type""] = ""application/json"" res = req.get_response(self.app) self.assertEqual(400, res.status_int) self._get_console_output_bad_request_case(body) self._get_console_output_bad_request_case(body) self._get_console_output_bad_request_case(body) res = self._get_response(length_dict={'length': 3}) self.assertEqual(409, res.status_int) res = self._get_response() self.assertEqual(501, res.status_int) res = self._get_response(length_dict={'length': True}) self.assertEqual(400, res.status_int) need_osapi_compute_extension = True def _get_app(self): self.flags(osapi_compute_extension=[ 'nova.api.openstack.compute.contrib.select_extensions'], osapi_compute_ext_list=['Console_output']) return fakes.wsgi_app(init_only=('servers',))",38,58
openstack%2Fnova~master~Ibeb69afc5183c22191b77d45c73dcc8b0ef6d1f5,openstack/nova,master,Ibeb69afc5183c22191b77d45c73dcc8b0ef6d1f5,VMware: Use datastore_regex for disk stats,MERGED,2014-12-20 21:29:28.000000000,2014-12-23 05:38:51.000000000,2014-12-23 05:38:49.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 8247}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-20 21:29:28.000000000', 'files': ['nova/virt/vmwareapi/driver.py', 'nova/tests/unit/virt/vmwareapi/test_driver_api.py', 'nova/virt/vmwareapi/host.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c517f4b257ffe5b4b3a976554f7fe248aca33476', 'message': 'VMware: Use datastore_regex for disk stats\n\nVMware driver does not use datastore_regex when reporting disk\nstats, while it is used when spawning instances.  As a result,\nthe available disk_free reported periodically can be different\nfrom what is available when spawning.\n\nChange-Id: Ibeb69afc5183c22191b77d45c73dcc8b0ef6d1f5\nCloses-Bug: #1309753\nCo-Authored-By: Sabari Kumar Murugesan <smurugesan@vmware.com>\nCo-Authored-By: Davanum Srinivas <dims@linux.vnet.ibm.com>\n'}]",0,143280,c517f4b257ffe5b4b3a976554f7fe248aca33476,15,9,1,8247,,,0,"VMware: Use datastore_regex for disk stats

VMware driver does not use datastore_regex when reporting disk
stats, while it is used when spawning instances.  As a result,
the available disk_free reported periodically can be different
from what is available when spawning.

Change-Id: Ibeb69afc5183c22191b77d45c73dcc8b0ef6d1f5
Closes-Bug: #1309753
Co-Authored-By: Sabari Kumar Murugesan <smurugesan@vmware.com>
Co-Authored-By: Davanum Srinivas <dims@linux.vnet.ibm.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/143280/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/driver.py', 'nova/tests/unit/virt/vmwareapi/test_driver_api.py', 'nova/virt/vmwareapi/host.py']",3,c517f4b257ffe5b4b3a976554f7fe248aca33476,bug/1309753,"def _get_ds_capacity_and_freespace(session, cluster=None, datastore_regex=None): try: ds = ds_util.get_datastore(session, cluster, datastore_regex) def __init__(self, session, host_name, cluster, datastore_regex): self._datastore_regex = datastore_regex self._cluster, self._datastore_regex)","def _get_ds_capacity_and_freespace(session, cluster=None): try: ds = ds_util.get_datastore(session, cluster) def __init__(self, session, host_name, cluster): self._cluster)",20,5
openstack%2Fmanila~master~Iae849cb64ca36448eb5fa28a2075de614fea475c,openstack/manila,master,Iae849cb64ca36448eb5fa28a2075de614fea475c,Fix tempest test with share server listing with no filters,MERGED,2014-12-20 11:49:21.000000000,2014-12-23 05:36:29.000000000,2014-12-23 05:36:28.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 11878}]","[{'number': 1, 'created': '2014-12-20 11:49:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/7acc1115400218ad38ebdb77e2ff66a509684ed3', 'message': ""Fix tempest test with share server listing with no filters\n\nWe have test in tempest plugin that gets list of share servers\nand verifies presense there one of used servers, but also verifies\nthat all share servers have some specific states. It is incorrect\nbecause share servers from whole cluster are taken. And these 'all'\nshare servers are not related to test.\n\nChange-Id: Iae849cb64ca36448eb5fa28a2075de614fea475c\n""}, {'number': 2, 'created': '2014-12-20 11:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/81863ab52514f9f2cb7def5bdbb8e4519995940e', 'message': ""Fix tempest test with share server listing with no filters\n\nWe have test in tempest plugin that gets list of share servers\nand verifies presense there one of used servers, but also verifies\nthat all share servers have some specific states. It is incorrect\nbecause share servers from whole cluster are taken. And these 'all'\nshare servers are not related to test.\n\nChange-Id: Iae849cb64ca36448eb5fa28a2075de614fea475c\n""}, {'number': 3, 'created': '2014-12-20 12:44:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/dc64f22864a26ec55d2b3697a50cb3d6de61bda0', 'message': ""Fix tempest test with share server listing with no filters\n\nWe have test in tempest plugin that gets list of share servers\nand verifies presense there one of used servers, but also verifies\nthat all share servers have some specific states. It is incorrect\nbecause share servers from whole cluster are taken. And these 'all'\nshare servers are not related to test.\n\nChange-Id: Iae849cb64ca36448eb5fa28a2075de614fea475c\n""}, {'number': 4, 'created': '2014-12-21 16:17:26.000000000', 'files': ['contrib/tempest/tempest/api/share/admin/test_share_servers.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/b0e4b260a10836adb2135219a1b4d22157e01b83', 'message': ""Fix tempest test with share server listing with no filters\n\nWe have test in tempest plugin that gets list of share servers\nand verifies server being used is present, but also verifies\nthat all share servers have some specific states. It is incorrect\nbecause share servers from whole cluster are taken. And these 'all'\nshare servers are not related to test.\n\nChange-Id: Iae849cb64ca36448eb5fa28a2075de614fea475c\n""}]",2,143265,b0e4b260a10836adb2135219a1b4d22157e01b83,21,6,4,8851,,,0,"Fix tempest test with share server listing with no filters

We have test in tempest plugin that gets list of share servers
and verifies server being used is present, but also verifies
that all share servers have some specific states. It is incorrect
because share servers from whole cluster are taken. And these 'all'
share servers are not related to test.

Change-Id: Iae849cb64ca36448eb5fa28a2075de614fea475c
",git fetch https://review.opendev.org/openstack/manila refs/changes/65/143265/3 && git format-patch -1 --stdout FETCH_HEAD,['contrib/tempest/tempest/api/share/admin/test_share_servers.py'],1,7acc1115400218ad38ebdb77e2ff66a509684ed3,tempest," # Do not verify statuses because we get all share servers from whole # cluster and here can be servers with any state. any(self.assertIn(s[""share_network_name""], self.sn_name_and_id) for s in servers)"," # Use 'allowed_statuses' to cover possible statuses of share servers # in general, because we get info for whole cluster. allowed_statuses = [""active"", ""creating"", ""deleting""] any((s[""share_network_name""] in self.sn_name_and_id and self.assertIn(s[""status""].lower(), allowed_statuses)) for s in servers)",3,6
openstack%2Fmanila~master~I33f06b6b7192ac2f249b90f19a6c5b045ae55c9c,openstack/manila,master,I33f06b6b7192ac2f249b90f19a6c5b045ae55c9c,Improve tempest share server filtering,MERGED,2014-12-20 10:59:42.000000000,2014-12-23 05:31:59.000000000,2014-12-23 05:31:58.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}]","[{'number': 1, 'created': '2014-12-20 10:59:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/59d9720261f02f5848cf1990461c03e6d96c7b65', 'message': 'Improve tempest test with share server filtering\n\nImprove tempest test with share server filtering by share-network name.\nTest that does it does not verify whether used share-network has name or not.\nMake name verification and set name if absent,\nbecause sometimes share-network does not have name indeed.\n\nChange-Id: I33f06b6b7192ac2f249b90f19a6c5b045ae55c9c\n'}, {'number': 2, 'created': '2014-12-20 11:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/eccb4d307a4b7eaaa44ad185016a0b1a5b56eb8a', 'message': 'Improve tempest test with share server filtering\n\nImprove tempest test with share server filtering by share-network name.\nTest that does it does not verify whether used share-network has name or not.\nMake name verification and set name if absent,\nbecause sometimes share-network does not have name indeed.\n\nChange-Id: I33f06b6b7192ac2f249b90f19a6c5b045ae55c9c\n'}, {'number': 3, 'created': '2014-12-20 12:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/8a45ced6c27e5c910595000c15926b01bb8a9836', 'message': 'Improve tempest share server filtering\n\nMake sure that test_share_servers test suite uses share_network with name,\nbecause test suite depends on it and it is not set always.\n\nChange-Id: I33f06b6b7192ac2f249b90f19a6c5b045ae55c9c\n'}, {'number': 4, 'created': '2014-12-20 12:54:54.000000000', 'files': ['contrib/tempest/tempest/api/share/admin/test_share_servers.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/bc2a0bccf5168a3ebb37bb48752be269a19a7719', 'message': 'Improve tempest share server filtering\n\nMake sure that test_share_servers test suite uses share_network with name,\nbecause test suite depends on it and it is not set always.\n\nChange-Id: I33f06b6b7192ac2f249b90f19a6c5b045ae55c9c\n'}]",0,143262,bc2a0bccf5168a3ebb37bb48752be269a19a7719,16,3,4,8851,,,0,"Improve tempest share server filtering

Make sure that test_share_servers test suite uses share_network with name,
because test suite depends on it and it is not set always.

Change-Id: I33f06b6b7192ac2f249b90f19a6c5b045ae55c9c
",git fetch https://review.opendev.org/openstack/manila refs/changes/62/143262/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/tempest/tempest/api/share/admin/test_share_servers.py'],1,59d9720261f02f5848cf1990461c03e6d96c7b65,tempest," sn_id = self.share_network[""id""] if not self.share_network[""name""]: # Make sure used share network has name. __, sn = self.shares_client.update_share_network( self.share_network[""id""], name=""sn_%s"" % sn_id) sn_name = sn[""name""] search_opts = {""share_network"": sn_name} self.assertEqual(server[""share_network_name""], sn_name)"," search_opts = {""share_network"": self.share_network[""name""]} self.assertEqual(server[""share_network_name""], self.share_network[""name""])",10,3
openstack%2Ffuel-docs~master~Iad350bb588ea284010687bc3418030f3134a8ec6,openstack/fuel-docs,master,Iad350bb588ea284010687bc3418030f3134a8ec6,Minor fixes to Docker troubleshooting,ABANDONED,2014-12-03 10:29:15.000000000,2014-12-23 05:24:16.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-03 10:29:15.000000000', 'files': ['pages/operations/troubleshoot/2000-docker-disk-full.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/1a7db626c94646aa0fcced5a917041820e33336d', 'message': 'Minor fixes to Docker troubleshooting\n\nChange-Id: Iad350bb588ea284010687bc3418030f3134a8ec6\n'}]",0,138680,1a7db626c94646aa0fcced5a917041820e33336d,5,2,1,10014,,,0,"Minor fixes to Docker troubleshooting

Change-Id: Iad350bb588ea284010687bc3418030f3134a8ec6
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/80/138680/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/operations/troubleshoot/2000-docker-disk-full.rst'],1,1a7db626c94646aa0fcced5a917041820e33336d,docker-fix,if the disk fills up and gives solutions for resolving them.,if the disk fills up and gives solutions for resolving them.,1,2
openstack%2Fmanila~master~Ic7473c94eeb2b45533c028352b56e4027cd7eead,openstack/manila,master,Ic7473c94eeb2b45533c028352b56e4027cd7eead,Increase quotas and number of threads for tempest,MERGED,2014-12-20 11:27:52.000000000,2014-12-23 04:59:46.000000000,2014-12-23 04:59:44.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 11878}]","[{'number': 1, 'created': '2014-12-20 11:27:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/612680e06414e9e755df989d687d6c10c663a843', 'message': 'Increate quotas and number of threads for tempest\n\nIncrease quotas for Cinder (Generic driver case) and Manila.\nIncrease number of threads for tempest run to simulate concurrency and\nhave test run in shorter time slot.\n\nChange-Id: Ic7473c94eeb2b45533c028352b56e4027cd7eead\n'}, {'number': 2, 'created': '2014-12-20 11:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/4abbd88b5b684b0c34cdf1b9f434b6106b61dd23', 'message': 'Increase quotas and number of threads for tempest\n\nIncrease quotas for Cinder (Generic driver case) and Manila.\nIncrease number of threads for tempest run to simulate concurrency and\nhave test run in shorter time slot.\n\nChange-Id: Ic7473c94eeb2b45533c028352b56e4027cd7eead\n'}, {'number': 3, 'created': '2014-12-20 11:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/623250f44470d342d8dd98b3065266ca52421aa9', 'message': 'Increase quotas and number of threads for tempest\n\nIncrease quotas for Cinder (Generic driver case) and Manila.\nIncrease number of threads for tempest run to simulate concurrency and\nhave test run in shorter time slot.\n\nChange-Id: Ic7473c94eeb2b45533c028352b56e4027cd7eead\n'}, {'number': 4, 'created': '2014-12-20 12:23:51.000000000', 'files': ['contrib/devstack/extras.d/70-manila.sh', 'contrib/ci/post_test_hook.sh', 'manila/quota.py', 'contrib/devstack/lib/manila'], 'web_link': 'https://opendev.org/openstack/manila/commit/1bffbf0a7abe12563eee6583eae3132c9e81ceef', 'message': 'Increase quotas and number of threads for tempest\n\nIncrease quotas for Cinder (Generic driver case) and Manila.\nIncrease number of threads for tempest run to simulate concurrency and\nhave test run in shorter time slot.\n\nChange-Id: Ic7473c94eeb2b45533c028352b56e4027cd7eead\n'}]",0,143263,1bffbf0a7abe12563eee6583eae3132c9e81ceef,28,5,4,8851,,,0,"Increase quotas and number of threads for tempest

Increase quotas for Cinder (Generic driver case) and Manila.
Increase number of threads for tempest run to simulate concurrency and
have test run in shorter time slot.

Change-Id: Ic7473c94eeb2b45533c028352b56e4027cd7eead
",git fetch https://review.opendev.org/openstack/manila refs/changes/63/143263/4 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/devstack/extras.d/70-manila.sh', 'contrib/ci/post_test_hook.sh', 'manila/quota.py', 'contrib/devstack/lib/manila']",4,612680e06414e9e755df989d687d6c10c663a843,devstack,"function set_cinder_quotas { # Update Cinder configuration to make sure default quotas are enough # for Manila using Generic driver with parallel testing. if is_service_enabled cinder; then if [[ -n ""$CINDER_CONF"" ]]; then CINDER_CONF=/etc/cinder/cinder.conf fi iniset $CINDER_CONF quota_volumes 50 iniset $CINDER_CONF quota_snapshots 50 iniset $CINDER_CONF quota_gigabytes 1000 fi } ",,17,3
openstack%2Fpuppet-openstack_extras~master~I5b18f393999d6f70757a2dfd9b12da049d6b64e1,openstack/puppet-openstack_extras,master,I5b18f393999d6f70757a2dfd9b12da049d6b64e1,Add hash based repository management,MERGED,2014-08-13 15:07:43.000000000,2014-12-23 04:45:35.000000000,2014-12-23 04:45:35.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6554}, {'_account_id': 6994}, {'_account_id': 8482}, {'_account_id': 9410}]","[{'number': 1, 'created': '2014-08-13 15:07:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/6b629396120f0d19345301870b93abadfbf3bc60', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 2, 'created': '2014-08-13 15:58:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/177c2a05eb681a3d5a03c89e6e22da9273d38406', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 3, 'created': '2014-08-14 02:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/afaf43db0196a4960bf5c872019d2f5a468c34cc', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 4, 'created': '2014-08-14 03:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/d9b3e2fbd900174775cb234a681cd138b931f44e', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 5, 'created': '2014-08-14 03:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/3e7a3915232c8c9f958f88ebfcf82ae06a4819ed', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 6, 'created': '2014-08-14 04:58:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/b26c407b83d19c0c363ba2cad8e442e8743968d8', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 7, 'created': '2014-08-14 05:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/bd2fda9500890a793ed4222058b1fdcdda499113', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 8, 'created': '2014-08-14 05:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/c87f673e03645e3f7620d9dee97337faa3436a0c', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 9, 'created': '2014-08-14 05:13:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/186478a3d0c99808409c4e7640a9a5ef0026e5fe', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 10, 'created': '2014-08-14 05:18:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/7f3343c7fca333c4b9cd3a46645f118b013e072e', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 11, 'created': '2014-08-14 08:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/8b401364949f3d58a0da15276bf023ffa1501bd2', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 12, 'created': '2014-08-14 09:52:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/a4703fa3a403ec2ac263a7854825137646f4c463', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 13, 'created': '2014-08-14 10:20:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/e44637294b9ce675d7d58c4064296831b56707e6', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 14, 'created': '2014-08-14 15:19:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/3611abb5288e082f4af9d773918db6a4b87766ef', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 15, 'created': '2014-08-14 16:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/2918b275837b4efa0f03bb148170d947abcbdcfd', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 16, 'created': '2014-08-26 03:28:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/f3f32e272fa83105c4ecbefa90ebbd74ec57a6c0', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 17, 'created': '2014-08-26 04:03:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/5cd07f50401057a4af713fecb852e0b7c8a1829b', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 18, 'created': '2014-08-26 05:11:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/c0acc7de87b2f6f2ef8732c58e5bb6f1e648ec35', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 19, 'created': '2014-09-12 06:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/7029a14fcf964bbdae6cff82529213f3f3f29f02', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 20, 'created': '2014-09-25 03:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/72fa017eb60af8152d1f5684960ee10b8197e327', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 21, 'created': '2014-10-22 12:32:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/8555eae99101d04f58c94669d95727e3114d2ca1', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 22, 'created': '2014-11-22 15:13:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/fe04c324da4a49c3aa969f2609f96e58ebc2bac6', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 23, 'created': '2014-11-27 11:11:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/1d2688007cca0b80c12b9a2034fc97923ea2b0b7', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}, {'number': 24, 'created': '2014-11-27 11:12:34.000000000', 'files': ['lib/puppet/parser/functions/validate_yum_hash.rb', 'examples/redhat_repo.yaml', '.fixtures.yml', 'files/RPM-GPG-KEY-RDO-Havana', 'spec/classes/openstack_extras_repo_debian_ubuntu_spec.rb', 'manifests/repo/debian/ubuntu.pp', 'files/RPM-GPG-KEY-EPEL-7', 'manifests/repo/debian/debian.pp', 'files/RPM-GPG-KEY-EPEL-6', 'files/RPM-GPG-KEY-RDO-Juno', 'manifests/repo/redhat/params.pp', 'manifests/repo/redhat/redhat.pp', 'Rakefile', 'spec/classes/openstack_extras_repo_debian_debian_spec.rb', 'manifests/repo/debian/params.pp', 'spec/classes/openstack_extras_repo_redhat_redhat_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/0fc013377b07b4ffb4195243d36911438c5b9b4d', 'message': 'Add hash based repository management\n\nThis patch adds support for managing repos\nfor major distros, separated by osfamily at\nthe top level and operatingsystem below that.\n\nSince redhat, fedora and centos can all install\nfrom rdo, which is the only current option, the\nfedora and centos classes simply wrap around the\nredhat one. This may change in the future if any\nof them change (for example if RHOS support is\nadded and redhat is now different to fedora)\n\nChange-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1\n'}]",8,113922,0fc013377b07b4ffb4195243d36911438c5b9b4d,85,6,24,6994,,,0,"Add hash based repository management

This patch adds support for managing repos
for major distros, separated by osfamily at
the top level and operatingsystem below that.

Since redhat, fedora and centos can all install
from rdo, which is the only current option, the
fedora and centos classes simply wrap around the
redhat one. This may change in the future if any
of them change (for example if RHOS support is
added and redhat is now different to fedora)

Change-Id: I5b18f393999d6f70757a2dfd9b12da049d6b64e1
",git fetch https://review.opendev.org/openstack/puppet-openstack_extras refs/changes/22/113922/10 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/repo/redhat/redhat.pp', 'manifests/repo/redhat/fedora.pp', 'manifests/repo/debian/ubuntu.pp', 'manifests/repo/debian/debian.pp', 'manifests/repo/redhat/centos.pp']",5,6b629396120f0d19345301870b93abadfbf3bc60,repo_mgmt,"# == Class: openstack_extras::repo::redhat::centos # # This repo sets up yum repos for use with the RedHat # osfamily and CentOS operatingsystem. Currently a thin # wrapper around the redhat class, as there are no differences. # # === Parameters: # # [*release*] # (optional) The openstack release to use if managing rdo # Defaults to 'icehouse' # # [*manage_rdo*] # (optional) Whether to create a predefined yumrepo resource # for the RDO OpenStack repository provided by RedHat # Defaults to true # # [*repo_hash*] # (optional) A hash of yumrepo resources that will be passed to # create_resource. See examples folder for some useful examples. # Defaults to {} # # [*repo_defaults*] # (optional) The defaults for the yumrepo resources that will be # created using create_resource. # Defaults to # { 'enabled' => '1', # 'gpgcheck' => '1', # 'notify' => ""Exec['yum_refresh']"", # 'mirrorlist' => 'absent', # 'require' => ""Anchor['openstack_extras_redhat']"" } # # [*gpgkey_hash*] # (optional) A hash of file resources that will be passed to # create_resource. See examples folder for some useful examples. # Defaults to {} # # [*gpgkey_default*] # (optional) The default resource attributes to # create gpgkeys with. # Defaults to # { 'owner' => 'root', # 'group' => 'root', # 'mode' => '0644', # 'before' => ""Anchor['openstack_extras_redhat']"" } # # [*purge_unmanaged*] # (optional) Purge the yum.repos.d directory of # all repositories not managed by Puppet # Defaults to false # # [*package_require*] # (optional) Set all packages to require all # yumrepos be set. # Defaults to false # class openstack_extras::repo::redhat::centos( $release = 'icehouse', $manage_rdo = true, $repo_hash = {}, $repo_defaults = { 'enabled' => '1', 'gpgcheck' => '1', 'notify' => ""Exec['yum_refresh']"", 'mirrorlist' => 'absent', 'require' => ""Anchor['openstack_extras_redhat']"" }, $gpgkey_hash = {}, $gpgkey_default = { 'owner' => 'root', 'group' => 'root', 'mode' => '0644', 'before' => ""Anchor['openstack_extras_redhat']"" }, $purge_unamanaged = false, $package_require = false ) { class { 'openstack_extras::repo::redhat::redhat': release => $release, manage_rdo => $manage_rdo, repo_hash => $repo_hash, repo_defaults => $repo_defaults, gpgkey_hash => $gpgkey_hash, gegkey_default => $gpgkey_default, purge_unmanaged => $purge_unmanaged, package_require => $package_require } ",,402,0
openstack%2Fpython-magnumclient~master~I01a784609c00ffd4764925a7930793d9a1d86b05,openstack/python-magnumclient,master,I01a784609c00ffd4764925a7930793d9a1d86b05,Implement client for service operations,ABANDONED,2014-12-23 03:17:13.000000000,2014-12-23 04:13:04.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-23 03:17:13.000000000', 'files': ['magnumclient/api/shell.py'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/3086f8e5cc354ad5dc53f49d3ccde0523a14fc34', 'message': 'Implement client for service operations\n\nChange-Id: I01a784609c00ffd4764925a7930793d9a1d86b05\n'}]",0,143590,3086f8e5cc354ad5dc53f49d3ccde0523a14fc34,3,1,1,7494,,,0,"Implement client for service operations

Change-Id: I01a784609c00ffd4764925a7930793d9a1d86b05
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/90/143590/1 && git format-patch -1 --stdout FETCH_HEAD,['magnumclient/api/shell.py'],1,3086f8e5cc354ad5dc53f49d3ccde0523a14fc34,master,"def _show_service(service): utils.print_dict(service._info) """"""Print a list of services."""""" services = cs.services.list() columns = ('uuid', 'name', 'bay_uuid') utils.print_list(pods, columns, {'versions': _print_list_field('versions')}) @utils.arg('--name', metavar='<name>', help='Name of service to create.') @utils.arg('--service-file', metavar='<service-file>', help='Name of the serivce file to use for creating services.') def do_service_create(cs, args): """"""Create a service."""""" opts = {} opts['name'] = args.name opts['service_data'] = open(args.service_file).read() service = cs.services.create(**opts) _show_service(service) @utils.arg('--id', metavar='<service_id>', help='ID of the service to delete.') def do_service_delete(cs, args): """"""Delete a service."""""" cs.services.delete(args.id) @utils.arg('--id', metavar='<service_id>', help='ID of the service to show.') def do_service_show(cs, args): service = cs.services.get(args.id) _show_service(service)"," pass def do_service_create(cs, args): pass def do_service_delete(cs, args): pass def do_service_show(cs, args): pass",31,4
openstack%2Fdevstack~master~Id61cfbde2cef3a5d31cbf30e635f7c4fdc253b60,openstack/devstack,master,Id61cfbde2cef3a5d31cbf30e635f7c4fdc253b60,Fixes prettytable version issue,ABANDONED,2014-12-23 00:39:36.000000000,2014-12-23 04:10:38.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-23 00:39:36.000000000', 'files': ['tools/fixup_stuff.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/f15d7f933e80be73c191b11a7cf010c4461e6525', 'message': 'Fixes prettytable version issue\n\nChange-Id: Id61cfbde2cef3a5d31cbf30e635f7c4fdc253b60\nCloses-Bug: #1405019\n'}]",0,143574,f15d7f933e80be73c191b11a7cf010c4461e6525,5,4,1,13664,,,0,"Fixes prettytable version issue

Change-Id: Id61cfbde2cef3a5d31cbf30e635f7c4fdc253b60
Closes-Bug: #1405019
",git fetch https://review.opendev.org/openstack/devstack refs/changes/74/143574/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/fixup_stuff.sh'],1,f15d7f933e80be73c191b11a7cf010c4461e6525,,pip_install 'prettytable>=0.7',pip_install 'prettytable>0.7',1,1
openstack%2Fneutron~master~Ib14666f60b16584f225b1e0c4fed82ef7e941aac,openstack/neutron,master,Ib14666f60b16584f225b1e0c4fed82ef7e941aac,Correct arguments to logging function,MERGED,2014-12-17 04:09:50.000000000,2014-12-23 03:47:23.000000000,2014-12-17 11:27:58.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7249}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10237}, {'_account_id': 11279}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-17 04:09:50.000000000', 'files': ['neutron/cmd/sanity/checks.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/79f89db7fef191e22f0494b468a099edd6f0d611', 'message': 'Correct arguments to logging function\n\nofctl_arg_supported contains a bad call to LOG.debug in an exception\npath.\n\n    LOG.debug(""...%s. Exception: %s"", (full_args, e))\n\nThis throws ""TypeError: not enough arguments for format string"" and\nshould be:\n\n    LOG.debug(""...%s. Exception: %s"", full_args, e)\n\n(Found via pylint)\n\nChange-Id: Ib14666f60b16584f225b1e0c4fed82ef7e941aac\nCloses-Bug: #1403296\n'}]",0,142336,79f89db7fef191e22f0494b468a099edd6f0d611,24,19,1,11279,,,0,"Correct arguments to logging function

ofctl_arg_supported contains a bad call to LOG.debug in an exception
path.

    LOG.debug(""...%s. Exception: %s"", (full_args, e))

This throws ""TypeError: not enough arguments for format string"" and
should be:

    LOG.debug(""...%s. Exception: %s"", full_args, e)

(Found via pylint)

Change-Id: Ib14666f60b16584f225b1e0c4fed82ef7e941aac
Closes-Bug: #1403296
",git fetch https://review.opendev.org/openstack/neutron refs/changes/36/142336/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/cmd/sanity/checks.py'],1,79f89db7fef191e22f0494b468a099edd6f0d611,bug/1403296," ""command %s. Exception: %s"", full_args, e)"," ""command %s. Exception: %s"", (full_args, e))",1,1
openstack%2Ftricircle~master~Ieb2903c9f76d5ff1052f28baf88d8dbfd0f33223,openstack/tricircle,master,Ieb2903c9f76d5ff1052f28baf88d8dbfd0f33223,add README file for neutron cascaded_l3_patch and timestamp_cascaded_patch,MERGED,2014-12-23 03:17:06.000000000,2014-12-23 03:46:27.000000000,2014-12-23 03:46:27.000000000,"[{'_account_id': 3}, {'_account_id': 9778}]","[{'number': 1, 'created': '2014-12-23 03:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/b5385b95b73e77d7d869e7a6fdd5b5fde179704e', 'message': 'add README file for neutron cascaded_l3_patch and timestamp_cascaded_patch\n\nChange-Id: Ieb2903c9f76d5ff1052f28baf88d8dbfd0f33223\n'}, {'number': 2, 'created': '2014-12-23 03:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/3595afa5d2818db79532113fb4f9c2cc6e424000', 'message': 'add README file for neutron cascaded_l3_patch and timestamp_cascaded_patch\n\nChange-Id: Ieb2903c9f76d5ff1052f28baf88d8dbfd0f33223\n'}, {'number': 3, 'created': '2014-12-23 03:35:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/0d6b6d2e059a26c21db4dae86cc4c6262017df60', 'message': 'add README file for neutron cascaded_l3_patch and timestamp_cascaded_patch\n\nChange-Id: Ieb2903c9f76d5ff1052f28baf88d8dbfd0f33223\n'}, {'number': 4, 'created': '2014-12-23 03:44:51.000000000', 'files': ['juno-patches/neutron/neutron_cascaded_l3_patch/README.md', 'juno-patches/neutron/neutron_timestamp_cascaded_patch/README.md'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/995258ecf836d1afb6156c66c3290d48407a8649', 'message': 'add README file for neutron cascaded_l3_patch and timestamp_cascaded_patch\n\nChange-Id: Ieb2903c9f76d5ff1052f28baf88d8dbfd0f33223\n'}]",0,143589,995258ecf836d1afb6156c66c3290d48407a8649,12,2,4,9778,,,0,"add README file for neutron cascaded_l3_patch and timestamp_cascaded_patch

Change-Id: Ieb2903c9f76d5ff1052f28baf88d8dbfd0f33223
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/89/143589/4 && git format-patch -1 --stdout FETCH_HEAD,"['juno-patches/neutron/neutron_timestamp_cascaded_patch/README.txt', 'juno-patches/neutron/neutron_cascaded_l3_patch/README.txt']",2,b5385b95b73e77d7d869e7a6fdd5b5fde179704e,,"Openstack Neutron cascaded_l3_patch =============================== Neutron cascaded_l3_patch is mainly used to achieve L3 communications crossing OpenStack. To solve the problem, we add 'onlink' field for extra route of router based on the ip range in neutron-server, and add GRE Tunnel in l3-agent. This patch should be made to the Cascaded Neutron nodes. Key modules ----------- * We add GRE Tunnel in l3-agent by modifying some files: neutron/agent/linux/ip_lib.py neutron/agent/l3_agent.py * We add 'onlink' field for extra route of router based on the ip range in neutron-server by modifying some files: neutron/common/config.py neutron/db/extraroute_db.py Requirements ------------ * openstack neutron-2014.2 has been installed. Installation ------------ We provide two ways to install the Neutron cascaded_l3_patch. In this section, we will guide you through installing the Neutron cascaded_l3_patch with modifying the configuration. * **Note:** - Make sure you have an existing installation of **Openstack Neutron of Juno Version**. - We recommend that you Do backup at least the following files before installation, because they are to be overwritten or modified: $NEUTRON_PARENT_DIR/neutron (replace the $... with actual directory names.) * **Manual Installation** - Navigate to the local repository and copy the contents in 'neutron' sub-directory to the corresponding places in existing neutron, e.g. ```cp -r $LOCAL_REPOSITORY_DIR/neutron $NEUTRON_PARENT_DIR``` (replace the $... with actual directory name.) ``` - you can modify neutron config file $CONFIG_FILE_PATH/plugins/ml2/ml2_conf.ini Modify the value of firewall_driver option as: [securitygroup] firewall_driver=neutron.agent.firewall.NoopFirewallDriver $CONFIG_FILE_PATH/l3_agent.ini Modify the value of agent_mode option as: [DEFAULT] agent_mode=dvr_snat $CONFIG_FILE_PATH/neutron.conf, you can also don't modify Default value of 3gw_extern_net_ip_range option in config file, is l3gw_extern_net_ip_range=100.64.0.0/16 - Restart the neutron-server and neutron-l3-agent. ```service neutron-server restart``` ```service neutron-l3-agent restart``` - Done. * **Automatic Installation** - Navigate to the installation directory and run installation script. ``` cd $LOCAL_REPOSITORY_DIR/installation sudo bash ./install.sh ``` (replace the $... with actual directory name.) - Done. The installation script will automatically modify the neutron code and the configurations. * **Troubleshooting** In case the automatic installation process is not complete, please check the followings: - Make sure your OpenStack version is Juno. - Check the variables in the beginning of the install.sh scripts. Your installation directories may be different from the default values we provide. - The installation code will automatically modify the related codes to $NEUTRON_PARENT_DIR/neutron and the related configuration. - In case the automatic installation does not work, try to install manually. ",,152,0
openstack%2Fnova~master~Id94b6f678fc7ec7e7e3366982cf70a27e8fd0877,openstack/nova,master,Id94b6f678fc7ec7e7e3366982cf70a27e8fd0877,Glance:refactor glance.get_remote_image_service,ABANDONED,2014-11-06 09:05:11.000000000,2014-12-23 03:11:58.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6159}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-11-06 09:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d64978ec06ca2614e925443b2efc6606e0ca7f9e', 'message': 'Glance:refactor glance.get_remote_image_service\n\nIn image/api, _get_session returns a default image service, which\nthe context is not even used in the session.\n\nthis patch refactors glance.get_remote_image_service,\nwe can pass a context to glance.get_remote_image_service instead of\nget_default_image_service in _get_session.\n\nglance.get_default_image_service will be removed in another patch\nand we need change the name of glance.get_remote_image_service\njust as glance.get_image_service in followed patches\n\nChange-Id: Id94b6f678fc7ec7e7e3366982cf70a27e8fd0877\n'}, {'number': 2, 'created': '2014-11-06 13:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28bfc11413f58315b35eea5ba344d5afad760b38', 'message': 'Glance:refactor glance.get_remote_image_service\n\nIn image/api, _get_session returns a default image service, which\nthe context is not even used in the session.\n\nthis patch refactors glance.get_remote_image_service,\nwe can pass a context to glance.get_remote_image_service instead of\nget_default_image_service in _get_session.\n\nglance.get_default_image_service will be removed in another patch\nand we need change the name of glance.get_remote_image_service\njust as glance.get_image_service in followed patches\n\nChange-Id: Id94b6f678fc7ec7e7e3366982cf70a27e8fd0877\n'}, {'number': 3, 'created': '2014-11-17 03:14:00.000000000', 'files': ['nova/image/glance.py', 'nova/image/api.py', 'nova/tests/unit/image/test_glance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2ce7f4c0204cf298c6a792fdfe8ec34d10474991', 'message': 'Glance:refactor glance.get_remote_image_service\n\nIn image/api, _get_session returns a default image service, which\nthe context is not even used in the session.\n\nthis patch refactors glance.get_remote_image_service,\nwe can pass a context to glance.get_remote_image_service instead of\nget_default_image_service in _get_session.\n\nglance.get_default_image_service will be removed in another patch\nand we need change the name of glance.get_remote_image_service\njust as glance.get_image_service in followed patches\n\nChange-Id: Id94b6f678fc7ec7e7e3366982cf70a27e8fd0877\n'}]",2,132972,2ce7f4c0204cf298c6a792fdfe8ec34d10474991,33,12,3,12175,,,0,"Glance:refactor glance.get_remote_image_service

In image/api, _get_session returns a default image service, which
the context is not even used in the session.

this patch refactors glance.get_remote_image_service,
we can pass a context to glance.get_remote_image_service instead of
get_default_image_service in _get_session.

glance.get_default_image_service will be removed in another patch
and we need change the name of glance.get_remote_image_service
just as glance.get_image_service in followed patches

Change-Id: Id94b6f678fc7ec7e7e3366982cf70a27e8fd0877
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/132972/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/image/glance.py', 'nova/image/api.py', 'nova/tests/image/test_glance.py']",3,d64978ec06ca2614e925443b2efc6606e0ca7f9e,refactor_glance," gcwi_mocked.assert_called_once_with(context=mock.sentinel.ctx) @mock.patch.object(glance.GlanceClientWrapper, '__init__', return_value=None) def test_get_remote_service_by_default(self, gcwi_mocked): _ignored, image_id = glance.get_remote_image_service( mock.sentinel.ctx) self.assertEqual(None, image_id) gcwi_mocked.assert_called_once_with(context=mock.sentinel.ctx) ", gcwi_mocked.assert_called_once_with(),25,19
openstack%2Ffuel-docs~master~Ie8613e770056dc234e249e17fce02ae9bc39c332,openstack/fuel-docs,master,Ie8613e770056dc234e249e17fce02ae9bc39c332,Proof-of-concept: Comprehensive Network Guide,ABANDONED,2014-12-06 00:19:20.000000000,2014-12-23 03:10:24.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-12-06 00:19:20.000000000', 'files': ['pages/reference-architecture/9000-network-all.rst', 'contents/contents-refarch.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/d8b0b351657133e21a5819024bb3cc1ca08be587', 'message': ""Proof-of-concept: Comprehensive Network Guide\n\nBOGUS COMMIT!!!  DO NOT MERGE!!!\n\nThis is an attempt to build a comprenhensive guide to Fuel Networking\nby ..include'ing all the sections in the doc related to Networking,\nto see if it can be done.\n\nThis commit does not build -- we have duplicate tags because all the\nsource files are included into the docs twice.\n\nChange-Id: Ie8613e770056dc234e249e17fce02ae9bc39c332\n""}]",0,139768,d8b0b351657133e21a5819024bb3cc1ca08be587,6,3,1,10014,,,0,"Proof-of-concept: Comprehensive Network Guide

BOGUS COMMIT!!!  DO NOT MERGE!!!

This is an attempt to build a comprenhensive guide to Fuel Networking
by ..include'ing all the sections in the doc related to Networking,
to see if it can be done.

This commit does not build -- we have duplicate tags because all the
source files are included into the docs twice.

Change-Id: Ie8613e770056dc234e249e17fce02ae9bc39c332
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/68/139768/1 && git format-patch -1 --stdout FETCH_HEAD,"['contents/contents-refarch.rst', 'pages/reference-architecture/9000-network-all.rst']",2,d8b0b351657133e21a5819024bb3cc1ca08be587,bogus-network, Comprehensive guide to Fuel Networking ====================================== .. include:: /pages/planning-guide/4200-net-topology.rst .. include:: /pages/planning-guide/4200-net-topology.rst .. include:: /pages/planning-guide/0010-prerequisites/0600-network-hardware-sizing.rst .. include:: /pages/user-guide/initialize-fuel/0400-pxe-config.rst .. include:: /pages/user-guide/create-environment/3000-choose-network.rst .. include:: /pages/user-guide/config-environment/1400-network-settings.rst .. include:: /pages/user-guide/config-environment/3000-nic-bonding-ui.rst .. include:: /pages/user-guide/config-environment/0220-map-logical-to-physical-nic.rst .. include:: /pages/user-guide/config-environment/3400-verify-networks.rst .. include:: /pages/operations/troubleshoot/9110-verify-neutron-ha-crm.rst .. include:: /pages/reference-architecture/6000-network-architecture.rst .. include:: /pages/reference-architecture/6050-neutron-topologies.rst .. include:: /pages/reference-architecture/6070-nova-topologies.rst .. include:: /pages/reference-architecture/0100-openvswitch.rst .. include:: /pages/reference-architecture/0110-bonding.rst Terminology articles related to networking ========================================== .. include:: /pages/terminology/b/bonding.rst .. include:: /pages/terminology/n/neutron.rst .. include:: /pages/terminology/n/nic-rst .. include:: /pages/terminology/n/nova-network.rst .. include:: /pages/terminology/n/nsx.rst .. include:: /pages/terminology/o/ovs.rst .. include:: /pages/terminology/p/pxe.rst ,,36,0
openstack%2Fopenstack-manuals~master~Id4696ff3bb11d591c195e30ab07253df7bdbda53,openstack/openstack-manuals,master,Id4696ff3bb11d591c195e30ab07253df7bdbda53,change to section_architecture_network_focus,MERGED,2014-12-22 20:08:39.000000000,2014-12-23 02:38:11.000000000,2014-12-23 02:38:10.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-22 20:08:39.000000000', 'files': ['doc/arch-design/network_focus/section_architecture_network_focus.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/194646a4a93eb0edadfaa8e545aa522162a1ea17', 'message': 'change to section_architecture_network_focus\n\nshould be are a number of\nmoved a and as\nhave should be has\nadded space between autoconfiguration\n\nChange-Id: Id4696ff3bb11d591c195e30ab07253df7bdbda53\n'}]",0,143522,194646a4a93eb0edadfaa8e545aa522162a1ea17,7,3,1,9382,,,0,"change to section_architecture_network_focus

should be are a number of
moved a and as
have should be has
added space between autoconfiguration

Change-Id: Id4696ff3bb11d591c195e30ab07253df7bdbda53
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/22/143522/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/arch-design/network_focus/section_architecture_network_focus.xml'],1,194646a4a93eb0edadfaa8e545aa522162a1ea17,, are a number of very specific considerations to keep in mind when <para>Networks exist to serve as a medium of transporting data has inter-dependencies with non-network portions of OpenStack stateless address auto configuration but work is in, a number of very specific considerations to keep in mind when <para>Networks exist to serve a as medium of transporting data have inter-dependencies with non-network portions of OpenStack stateless address autoconfiguration but work is in,4,4
openstack%2Fopenstack-manuals~master~I9f2d9c352d92e46c58125ad384222eb2fbfd2dd2,openstack/openstack-manuals,master,I9f2d9c352d92e46c58125ad384222eb2fbfd2dd2,change to section_architecture_general_purpose,MERGED,2014-12-22 20:54:36.000000000,2014-12-23 02:38:04.000000000,2014-12-23 02:38:03.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-22 20:54:36.000000000', 'files': ['doc/arch-design/generalpurpose/section_architecture_general_purpose.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/06ee449093f33c89a0e574465c07c0a299f3750b', 'message': 'change to section_architecture_general_purpose\n\nchanged sevices to services (typo)\ntechnicalrequirements - added space\nloggin changed to logging\nLogstach should be Logstash\n\nChange-Id: I9f2d9c352d92e46c58125ad384222eb2fbfd2dd2\n'}]",0,143534,06ee449093f33c89a0e574465c07c0a299f3750b,8,4,1,9382,,,0,"change to section_architecture_general_purpose

changed sevices to services (typo)
technicalrequirements - added space
loggin changed to logging
Logstach should be Logstash

Change-Id: I9f2d9c352d92e46c58125ad384222eb2fbfd2dd2
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/34/143534/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/arch-design/generalpurpose/section_architecture_general_purpose.xml'],1,06ee449093f33c89a0e574465c07c0a299f3750b,section_architecture_gen," services should take advantage of performance boosting in conjunction with the technical requirements before deciding in the logging sub-category one might consider Logstash, Splunk, instanceware"," sevices should take advantage of performance boosting in conjunction with the technicalrequirements before deciding in the loggin sub-category one might consider Logstach, Splunk, instanceware",3,3
openstack%2Fopenstack-manuals~master~If2c13574cf5cc0f6dc1ce4ce2795e525fa3c7b1e,openstack/openstack-manuals,master,If2c13574cf5cc0f6dc1ce4ce2795e525fa3c7b1e,change to hds-hns doc,MERGED,2014-12-23 01:19:48.000000000,2014-12-23 02:37:57.000000000,2014-12-23 02:37:55.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-23 01:19:48.000000000', 'files': ['doc/config-reference/block-storage/drivers/hds-hnas-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9031b4410012626257803cb485297c1d599ac000', 'message': 'change to hds-hns doc\n\nbefore OpenStack - added “an” instead of “a”\n\nChange-Id: If2c13574cf5cc0f6dc1ce4ce2795e525fa3c7b1e\n'}]",0,143581,9031b4410012626257803cb485297c1d599ac000,7,3,1,9382,,,0,"change to hds-hns doc

before OpenStack - added “an” instead of “a”

Change-Id: If2c13574cf5cc0f6dc1ce4ce2795e525fa3c7b1e
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/81/143581/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/block-storage/drivers/hds-hnas-driver.xml'],1,9031b4410012626257803cb485297c1d599ac000,hds-hnas, <para>Typically an OpenStack Block Storage volume instance has only one such, <para>Typically a OpenStack Block Storage volume instance has only one such,1,1
openstack%2Fkeystone-specs~master~Iecd72c7975fc1f16419a3d495b9ab5f82e9922d5,openstack/keystone-specs,master,Iecd72c7975fc1f16419a3d495b9ab5f82e9922d5,Session Tokens,ABANDONED,2014-05-30 02:11:09.000000000,2014-12-23 02:22:57.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1091}, {'_account_id': 1207}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6650}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 10873}, {'_account_id': 11387}]","[{'number': 1, 'created': '2014-05-30 02:11:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/8a3a25afa60ac925311cfe906565e25e0f361055', 'message': 'Session Tokens\n\nBlueprint session-tokens\n\nChange-Id: Iecd72c7975fc1f16419a3d495b9ab5f82e9922d5\n'}, {'number': 2, 'created': '2014-05-30 02:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/bbba8a1502c570734d86334d91d7bc0b426a5011', 'message': 'Session Tokens\n\nBlueprint session-extendable-tokens\n\nChange-Id: Iecd72c7975fc1f16419a3d495b9ab5f82e9922d5\n'}, {'number': 3, 'created': '2014-07-09 03:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/76d4c1c967232cb77e139e756fb590ba4145b1cd', 'message': 'Session Tokens\n\nMatchi the implementation of unscoped tokens to the needs of web\napplications like Horizon\n\nBlueprint session-extendable-tokens\n\nChange-Id: Iecd72c7975fc1f16419a3d495b9ab5f82e9922d5\n'}, {'number': 4, 'created': '2014-07-09 17:42:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/5bc73663c8fe26dd5f41c6e4234512e726c4403e', 'message': 'Session Tokens\n\nMatchi the implementation of unscoped tokens to the needs of web\napplications like Horizon\n\nBlueprint session-extendable-tokens\n\nChange-Id: Iecd72c7975fc1f16419a3d495b9ab5f82e9922d5\n'}, {'number': 5, 'created': '2014-07-09 18:12:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/018425e074613e7cb904bd5d833e0cc3a9dd1009', 'message': 'Session Tokens\n\nMatchi the implementation of unscoped tokens to the needs of web\napplications like Horizon\n\nBlueprint session-extendable-tokens\n\nChange-Id: Iecd72c7975fc1f16419a3d495b9ab5f82e9922d5\n'}, {'number': 6, 'created': '2014-07-09 22:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/7ada953046572e86cceaea91ef32f108a6571132', 'message': 'Session Tokens\n\nMatchi the implementation of unscoped tokens to the needs of web\napplications like Horizon\n\nBlueprint session-extendable-tokens\n\nChange-Id: Iecd72c7975fc1f16419a3d495b9ab5f82e9922d5\n'}, {'number': 7, 'created': '2014-10-20 03:11:02.000000000', 'files': ['specs/kilo/session-tokens.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/1920f516c7365652fb80a9cf15eb79aa87165b67', 'message': 'Session Tokens\n\nMatch the implementation of unscoped tokens to the needs of web\napplications like Horizon.  A Web applications can use an unscoped\nKeystone token as a record of authentication.  Limit the scope of what\ncan be done with such a token, and allow the lifespan of the token to\nextend with web based (keep alive) activity, so the user does not have\nto resbumit their origianl credentails too often.\n\nBlueprint session-extendable-tokens\n\nChange-Id: Iecd72c7975fc1f16419a3d495b9ab5f82e9922d5\n'}]",74,96648,1920f516c7365652fb80a9cf15eb79aa87165b67,49,17,7,2218,,,0,"Session Tokens

Match the implementation of unscoped tokens to the needs of web
applications like Horizon.  A Web applications can use an unscoped
Keystone token as a record of authentication.  Limit the scope of what
can be done with such a token, and allow the lifespan of the token to
extend with web based (keep alive) activity, so the user does not have
to resbumit their origianl credentails too often.

Blueprint session-extendable-tokens

Change-Id: Iecd72c7975fc1f16419a3d495b9ab5f82e9922d5
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/48/96648/7 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/session-tokens.rst'],1,8a3a25afa60ac925311cfe906565e25e0f361055,bp/session-extendable-tokens,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Session Tokens ========================================== https://blueprints.launchpad.net/keystone/+spec/session-tokens Short lived, unscoped tokens. Used by Horizon and similar applications these tokens can only be used with Keystone. They will serve as a cache of authentication, so that the other services do not need to record the users credentials. A session token will be used to get a scoped token. Problem Description =================== Tokens should only decresea in power. But right now, Horizon requires a scoped token to be converted to a differently scoped token. Horizon then revokes the old token. It does this so that it only needs to hold on to a single token. However, it is a security risk: one expoesed token can provide all access to all rolesa user has. In addition, as the lifespan of the token shrinks, Horizon will start to randomly log users out. This is not how a session is supposed to work. Instead, a Horizon session should only live 10 minutes (be default) but be extended when ever the user communicates with the server. Horizon can choose To limit how often it contacts Keystone (every minute probably is OK) and the expiration time of the Session should be extended when it does. Proposed Change =============== Create a new class of unscoped tokens. Call them session tokens. Aspects of session tokens: * have default expirey of 10 minutes. * can have their expiration time extended. * Only unscoped. * have no catalog, except for the identity service/endpoint * Are only honored by Keystone * Can be exchanged for a scoped token with a longer expiration time Alternatives ------------ Kerberos would not require this. However, Kerberos is slow (multiple round trips for each auth) and thus would likely require a mechanism like this for performance. Data Model Impact ----------------- None. All changes should be to the token structure itself. Questions which need to be addressed by this section include: * What new data objects and/or database schema changes is this going to require? None * What database migrations will accompany this change. None * How will the initial set of new data objects be generated, for example if you need to take into account existing instances, or modify other existing data describe how that will work. Will be created upon request from Horizon. REST API Impact --------------- The additional ""session"" keyword will be present in the token request. In the future, remove the rule that lets scoped token be exchanged for another scoped token. * Discuss any policy changes, and discuss what things a deployer needs to think about when defining their policy. None Security Impact --------------- Describe any potential security impact on the system. Some of the items to consider include: * Does this change touch sensitive data such as tokens, keys, or user data? Yes, tokens. * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? Should limit exposure. * Does this change involve cryptography or hashing? Only in that it continues to use the Crypto for token signing. * Does this change require the use of sudo or any elevated privileges? No * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. Yes, hte aditional paramter to the token request. * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. No more so than the existing Token API Notifications Impact -------------------- Please specify any changes to notifications. Be that an extra notification, changes to an existing notification, or removing a notification. None Other End User Impact --------------------- Aside from the API, are there other ways a user will interact with this feature? Users will only be able to use the tokens to tlak to keystone itself. * Does this change have an impact on python-keystoneclient? What does the user interface there look like? Yes. Keystone client should use a session token to talk to Keystone, and provide and accces mehtod to the other clients to use that session token to get tokens for talking to the other services. Performance Impact ------------------ Describe any potential performance impact on the system, for example how often will new code be called, and is there a major change to the calling pattern of existing code. Examples of things to consider here include: * A small change in a utility function or a commonly used decorator can have a large impacts on performance. No * Calls which result in a database queries can have a profound impact on performance when called in critical sections of the code. No new queries * Will the change include any locking, and if so what considerations are there on holding the lock? No Other Deployer Impact --------------------- Discuss things that will affect how you deploy and configure OpenStack that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example a flag that other hypervisor drivers might want to implement as well)? Are the default values ones which will work well in real deployments? None * Is this a change that takes immediate effect after its merged, or is it something that has to be explicitly enabled? Immediate Developer Impact ---------------- Minimal Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: Nathan Kinder Other contributors: Adam Young Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ None. This should stand alone. Adoption will be driven by Horizon. Testing ======= Majority of testing should b eKeystone unit tests. Tempest tests should make use of session tokens wherever they talk directly to Keystone. Documentation Impact ==================== Docs explianin the differnce, especially the part where a user requests a session token instead of a scoped token by default. References ========== None yet. ",,250,0
openstack%2Fopenstack-manuals~master~I40c74918b2b70f3ce018c5eeb617146ac8b1b5af,openstack/openstack-manuals,master,I40c74918b2b70f3ce018c5eeb617146ac8b1b5af,changes to section_operational_considerations_general_purpose,MERGED,2014-12-22 20:59:50.000000000,2014-12-23 02:08:28.000000000,2014-12-23 02:08:27.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-22 20:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e27de0a20804796b2a925916a4e9d4e3b5364c85', 'message': 'changes to section_operational_consideratoins_general_purpose\n\nplatorms should be platforms\nadded re-spawning hyphen\n\nChange-Id: I40c74918b2b70f3ce018c5eeb617146ac8b1b5af\n'}, {'number': 2, 'created': '2014-12-22 22:25:42.000000000', 'files': ['doc/arch-design/generalpurpose/section_operational_considerations_general_purpose.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/107349963272ebd4144569b138ec1d2c17eec2b7', 'message': 'changes to section_operational_considerations_general_purpose\n\nplatorms should be platforms\nadded re-spawning hyphen\n\nChange-Id: I40c74918b2b70f3ce018c5eeb617146ac8b1b5af\n'}]",0,143535,107349963272ebd4144569b138ec1d2c17eec2b7,10,3,2,9382,,,0,"changes to section_operational_considerations_general_purpose

platorms should be platforms
added re-spawning hyphen

Change-Id: I40c74918b2b70f3ce018c5eeb617146ac8b1b5af
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/35/143535/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/arch-design/generalpurpose/section_operational_considerations_general_purpose.xml'],1,e27de0a20804796b2a925916a4e9d4e3b5364c85,sec_oper, <para>OpenStack clouds require appropriate monitoring platforms to snapshot or re-spawning an instance. The overall application design, <para>OpenStack clouds require appropriate monitoring platorms to snapshot or respawning an instance. The overall application design,2,2
openstack%2Fopenstack-manuals~master~Id5f6d6d204d72aeb2ebd326aedcbd974d073ca94,openstack/openstack-manuals,master,Id5f6d6d204d72aeb2ebd326aedcbd974d073ca94,Edited configuring cells content in the Configuration Reference Guide,MERGED,2014-12-22 05:41:45.000000000,2014-12-23 02:08:20.000000000,2014-12-23 02:08:19.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 9382}]","[{'number': 1, 'created': '2014-12-22 05:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/72de1fb8345e6fc4bd1522e415a2fcfda97f36a4', 'message': 'Edited configuring cells content in the Configuration Reference Guide\n\nUpdated content with settings to enable cells.\n\nbackport: icehouse\nCloses_Bug: #1401772\n\nChange-Id: Id5f6d6d204d72aeb2ebd326aedcbd974d073ca94\n'}, {'number': 2, 'created': '2014-12-22 05:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ddcc1cd3e79013104a69d34696684ed8c3a94f05', 'message': 'Edited configuring cells content in the Configuration Reference Guide\n\nUpdated content with settings to enable cells.\n\nbackport: icehouse\nCloses-Bug: #1401772\n\nChange-Id: Id5f6d6d204d72aeb2ebd326aedcbd974d073ca94\n'}, {'number': 3, 'created': '2014-12-22 23:56:52.000000000', 'files': ['doc/config-reference/compute/section_compute-cells.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/02a0bbc699f19f906737fe986d4476f21982f0b2', 'message': 'Edited configuring cells content in the Configuration Reference Guide\n\nUpdated content with settings to enable cells.\n\nbackport: juno\nCloses-Bug: #1401772\n\nChange-Id: Id5f6d6d204d72aeb2ebd326aedcbd974d073ca94\n'}]",5,143365,02a0bbc699f19f906737fe986d4476f21982f0b2,12,4,3,10705,,,0,"Edited configuring cells content in the Configuration Reference Guide

Updated content with settings to enable cells.

backport: juno
Closes-Bug: #1401772

Change-Id: Id5f6d6d204d72aeb2ebd326aedcbd974d073ca94
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/65/143365/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/compute/section_compute-cells.xml'],1,72de1fb8345e6fc4bd1522e415a2fcfda97f36a4,cells_configref/darren," <para>The cell type must be changed in the API cell so the correct cell properly. Edit the <filename>nova.conf</filename> in the cell, and specify <replaceable>api</replaceable> in the <literal>cell_type</literal> key:<programlisting language=""ini"">[DEFAULT]cell_type= <replaceable>api</replaceable></programlisting> </para> <para>Edit the <filename>nova.conf</filename> file in the child cells, and specify <replaceable>compute</replaceable> in the <literal>cell_type</literal> key:<programlisting language=""ini"">[DEFAULT]cell_type = <replaceable>compute</replaceable></programlisting></para>"," <para>The compute API class must be changed in the API cell so the correct cell properly. Add the following line to <filename>nova.conf</filename> in the API cell:<programlisting language=""ini"">[DEFAULT]enable=True name=api</programlisting></para> <para>Add the following lines to <filename>nova.conf</filename> in the child cells, replacing <replaceable>cell1</replaceable> with the name of each cell:<programlisting language=""ini"">[DEFAULT]enable=True name=<replaceable>cell1</replaceable></programlisting></para>",10,13
openstack%2Fdevstack~stable%2Fjuno~I2134c7d8f58f8b83f33150c9ed86d87f8ccba2f3,openstack/devstack,stable/juno,I2134c7d8f58f8b83f33150c9ed86d87f8ccba2f3,Install prettytable>=0.7 to satisfy pip 6/PEP 440,MERGED,2014-12-22 17:20:44.000000000,2014-12-23 02:07:41.000000000,2014-12-23 02:07:39.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2472}, {'_account_id': 5174}, {'_account_id': 5196}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6482}, {'_account_id': 7687}, {'_account_id': 8411}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-12-22 17:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/cfc48138e7b3db278890e9b17c7d866c9497f061', 'message': 'Install prettytable>=0.7 to satisfy pip 6/PEP 440\n\nChange-Id: I2134c7d8f58f8b83f33150c9ed86d87f8ccba2f3\n(cherry picked from commit 1a89f8cdf4791350a9aacb41037ab3bdcc9ecc9f)\n'}, {'number': 2, 'created': '2014-12-23 00:22:36.000000000', 'files': ['functions-common', 'tools/fixup_stuff.sh', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/817e9b637a0d5edc46e5654c94388ac834e22203', 'message': ""Install prettytable>=0.7 to satisfy pip 6/PEP 440\n\nAlso use sudo -H with pip so that it doesn't create a ~stack/.cache\nother things can't write to as the stack user later.\n\nChange-Id: I2134c7d8f58f8b83f33150c9ed86d87f8ccba2f3\n(cherry picked from commit 1a89f8cdf4791350a9aacb41037ab3bdcc9ecc9f)\n""}]",0,143504,817e9b637a0d5edc46e5654c94388ac834e22203,21,11,2,5263,,,0,"Install prettytable>=0.7 to satisfy pip 6/PEP 440

Also use sudo -H with pip so that it doesn't create a ~stack/.cache
other things can't write to as the stack user later.

Change-Id: I2134c7d8f58f8b83f33150c9ed86d87f8ccba2f3
(cherry picked from commit 1a89f8cdf4791350a9aacb41037ab3bdcc9ecc9f)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/04/143504/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/fixup_stuff.sh'],1,cfc48138e7b3db278890e9b17c7d866c9497f061,pep-440,pip_install 'prettytable>=0.7',pip_install 'prettytable>0.7',1,1
openstack-attic%2Fidentity-api~master~I9605205db173ae39712e620b76fdf8a8eb7253a6,openstack-attic/identity-api,master,I9605205db173ae39712e620b76fdf8a8eb7253a6,Include a link to keystone-specs in the README,MERGED,2014-12-22 20:36:32.000000000,2014-12-23 02:05:08.000000000,2014-12-23 02:05:08.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-22 20:36:32.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/8b1bb39ef11db9b2baa5742e79b76262d3957181', 'message': 'Include a link to keystone-specs in the README\n\nBefore we push identity-api to the attic, we should include something\nabout where we host the APIs now.\n\nChange-Id: I9605205db173ae39712e620b76fdf8a8eb7253a6\n'}]",0,143530,8b1bb39ef11db9b2baa5742e79b76262d3957181,7,3,1,6482,,,0,"Include a link to keystone-specs in the README

Before we push identity-api to the attic, we should include something
about where we host the APIs now.

Change-Id: I9605205db173ae39712e620b76fdf8a8eb7253a6
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/30/143530/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,8b1bb39ef11db9b2baa5742e79b76262d3957181,add_url,The Identity Service APIs are now included in the Keystone Specifications project. Available `to view online at <http://specs.openstack.org/openstack/keystone-specs/>`_ ,,4,0
openstack%2Fdevstack~master~I7b2a7a53724fd8ef7305d2a55eda7f9c3cac1b8f,openstack/devstack,master,I7b2a7a53724fd8ef7305d2a55eda7f9c3cac1b8f,Fix pip prettytable requirement.,ABANDONED,2014-12-23 00:51:50.000000000,2014-12-23 01:41:09.000000000,,"[{'_account_id': 970}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-23 00:51:50.000000000', 'files': ['tools/fixup_stuff.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/19fd763a9037285fa3023bf9043bc9ba2baa574f', 'message': 'Fix pip prettytable requirement.\n\n./stack.sh fails wiht:\n---\nCollecting prettytable>0.7\n  The behavior of the `>` version specifier has changed in PEP 440. `>` is now\n  an exclusive operator, meaning that >0.7 does not match >0.7.*. Perhaps you\n  want `>=` instead of `>`?  Could not find a version that satisfies the\n  requirement prettytable>0.7 (from versions: 0.3, 0.4, 0.5, 0.6, 0.6.1, 0.7,\n  0.7.1, 0.7.2)\n  No distributions matching the version for prettytable>0.7\n---\n\nSo change do the naive thing and change the operator.\n\nChange-Id: I7b2a7a53724fd8ef7305d2a55eda7f9c3cac1b8f\n'}]",0,143577,19fd763a9037285fa3023bf9043bc9ba2baa574f,4,2,1,12898,,,0,"Fix pip prettytable requirement.

./stack.sh fails wiht:
---
Collecting prettytable>0.7
  The behavior of the `>` version specifier has changed in PEP 440. `>` is now
  an exclusive operator, meaning that >0.7 does not match >0.7.*. Perhaps you
  want `>=` instead of `>`?  Could not find a version that satisfies the
  requirement prettytable>0.7 (from versions: 0.3, 0.4, 0.5, 0.6, 0.6.1, 0.7,
  0.7.1, 0.7.2)
  No distributions matching the version for prettytable>0.7
---

So change do the naive thing and change the operator.

Change-Id: I7b2a7a53724fd8ef7305d2a55eda7f9c3cac1b8f
",git fetch https://review.opendev.org/openstack/devstack refs/changes/77/143577/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/fixup_stuff.sh'],1,19fd763a9037285fa3023bf9043bc9ba2baa574f,feature/pip_issue,pip_install 'prettytable>=0.7',pip_install 'prettytable>0.7',1,1
openstack%2Fneutron~master~I18299efc094fa0ab5baf302ac6d73094a5b3c43a,openstack/neutron,master,I18299efc094fa0ab5baf302ac6d73094a5b3c43a,Fix lswitch syntax error in exception path,ABANDONED,2014-08-13 05:46:22.000000000,2014-12-23 00:54:54.000000000,,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 11279}, {'_account_id': 12040}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-08-13 05:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1519697b0b69874786053ec741508742acdee0a4', 'message': ""Fix lswitch syntax error in exception path\n\nlswitch is a dictionary.  lswitch('uuid') should be lswitch['uuid']\n\nChange-Id: I18299efc094fa0ab5baf302ac6d73094a5b3c43a\n""}, {'number': 2, 'created': '2014-08-13 07:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/89c27e15c0c12dc568098ae97168bfc214fd16bf', 'message': ""Fix lswitch syntax error in exception path\n\nlswitch is a dictionary.  lswitch('uuid') should be lswitch['uuid']\n\nChange-Id: I18299efc094fa0ab5baf302ac6d73094a5b3c43a\nCloses-Bug: #1356224\n""}, {'number': 3, 'created': '2014-09-12 05:03:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a34f8e062a48196b575d925a4077ca7cddc76549', 'message': 'Fix lswitch syntax error in exception path\n\nlswitch is a dictionary.  lswitch(\'uuid\') should be lswitch[\'uuid\']\n\nThis change also enables the ""not-callable"" pylint check, after\ndisabling the 2 other cases where the alert triggers but the usage was\nintended.\n\nChange-Id: I18299efc094fa0ab5baf302ac6d73094a5b3c43a\nCloses-Bug: #1356224\n'}, {'number': 4, 'created': '2014-09-12 05:44:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1a12303a876e0fdcb5fac0fc33c67e73493864c2', 'message': 'Fix lswitch syntax error in exception path\n\nlswitch is a dictionary.  lswitch(\'uuid\') should be lswitch[\'uuid\']\n\nThis change also enables the ""not-callable"" pylint check, after\ndisabling the 2 other cases where the alert triggers but the usage was\nintended.\n\nChange-Id: I18299efc094fa0ab5baf302ac6d73094a5b3c43a\nCloses-Bug: #1356224\n'}, {'number': 5, 'created': '2014-09-22 00:03:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/39b7f00ea43f0fa8874c42b2157b229104751fe8', 'message': 'Fix lswitch syntax error in exception path\n\nlswitch is a dictionary.  lswitch(\'uuid\') should be lswitch[\'uuid\']\n\nThis change also enables the ""not-callable"" pylint check, after\ndisabling the 2 other cases where the alert triggers but the usage was\nintended.\n\nChange-Id: I18299efc094fa0ab5baf302ac6d73094a5b3c43a\nCloses-Bug: #1356224\n'}, {'number': 6, 'created': '2014-10-19 22:49:21.000000000', 'files': ['.pylintrc', 'neutron/plugins/ml2/drivers/cisco/apic/mechanism_apic.py', 'neutron/services/l3_router/l3_apic.py', 'neutron/plugins/vmware/plugins/service.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2bb970da45fc0229579f54b5f5c1dca1a7616192', 'message': 'Fix lswitch syntax error in exception path\n\nlswitch is a dictionary.  lswitch(\'uuid\') should be lswitch[\'uuid\']\n\nThis change also enables the ""not-callable"" pylint check, after\ndisabling the 2 other cases where the alert triggers but the usage was\nintended.\n\nChange-Id: I18299efc094fa0ab5baf302ac6d73094a5b3c43a\nCloses-Bug: #1356224\n'}]",3,113777,2bb970da45fc0229579f54b5f5c1dca1a7616192,138,35,6,11279,,,0,"Fix lswitch syntax error in exception path

lswitch is a dictionary.  lswitch('uuid') should be lswitch['uuid']

This change also enables the ""not-callable"" pylint check, after
disabling the 2 other cases where the alert triggers but the usage was
intended.

Change-Id: I18299efc094fa0ab5baf302ac6d73094a5b3c43a
Closes-Bug: #1356224
",git fetch https://review.opendev.org/openstack/neutron refs/changes/77/113777/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/vmware/plugins/service.py'],1,1519697b0b69874786053ec741508742acdee0a4,bug/1356224, self.vcns_driver.delete_lswitch(lswitch['uuid']), self.vcns_driver.delete_lswitch(lswitch('uuid')),1,1
openstack%2Fmagnum~master~Ie8d68a2b1d93fbb6aefb44704f82097aaf03d56e,openstack/magnum,master,Ie8d68a2b1d93fbb6aefb44704f82097aaf03d56e,Update import order for docker.py,ABANDONED,2014-12-23 00:15:51.000000000,2014-12-23 00:28:42.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-23 00:15:51.000000000', 'files': ['magnum/conductor/handlers/docker.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/d7a35437143bc478938eb5ab0f47ede9f3e8e0c5', 'message': 'Update import order for docker.py\n\nChange-Id: Ie8d68a2b1d93fbb6aefb44704f82097aaf03d56e\n'}]",0,143571,d7a35437143bc478938eb5ab0f47ede9f3e8e0c5,3,1,1,7494,,,0,"Update import order for docker.py

Change-Id: Ie8d68a2b1d93fbb6aefb44704f82097aaf03d56e
",git fetch https://review.opendev.org/openstack/magnum refs/changes/71/143571/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/conductor/handlers/docker.py'],1,d7a35437143bc478938eb5ab0f47ede9f3e8e0c5,master,,,1,0
openstack%2Fqa-specs~master~I8c1bd16d4b4dcaa840370322a3e22a701d7d5dce,openstack/qa-specs,master,I8c1bd16d4b4dcaa840370322a3e22a701d7d5dce,Add test UUIDs as decorators and docstrings,ABANDONED,2014-12-22 18:09:42.000000000,2014-12-22 23:56:59.000000000,,"[{'_account_id': 3}, {'_account_id': 5196}]","[{'number': 1, 'created': '2014-12-22 18:09:42.000000000', 'files': ['specs/test-uuids.rst'], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/3f826c1ba686d87be037a015ee87f8d90432ea8a', 'message': 'Add test UUIDs as decorators and docstrings\n\nCurrently the only identification for tests is the name associated with\nthe test. Tests may be moved or renamed during refactoring, and some\nnon-integration tests wil move out of Tempest and into project-specific\ntests. This makes names an unstable identifier. This spec proposes\naddition of a UUID to each test as a means of stable test\nidentification.\n\nPropose bp:test-uuid\n\nChange-Id: I8c1bd16d4b4dcaa840370322a3e22a701d7d5dce\n'}]",15,143511,3f826c1ba686d87be037a015ee87f8d90432ea8a,4,2,1,7822,,,0,"Add test UUIDs as decorators and docstrings

Currently the only identification for tests is the name associated with
the test. Tests may be moved or renamed during refactoring, and some
non-integration tests wil move out of Tempest and into project-specific
tests. This makes names an unstable identifier. This spec proposes
addition of a UUID to each test as a means of stable test
identification.

Propose bp:test-uuid

Change-Id: I8c1bd16d4b4dcaa840370322a3e22a701d7d5dce
",git fetch https://review.opendev.org/openstack/qa-specs refs/changes/11/143511/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/test-uuids.rst'],1,3f826c1ba686d87be037a015ee87f8d90432ea8a,bp/test-uuid,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/tempest/+spec/awesome-thing should be named awesome-thing.rst . Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ============ Test UUIDs ============ Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/tempest/+spec/example This spec proposes the addition of Universally Unique Identifiers (UUIDs) to tests to be used as a stable test identifier. Problem description =================== Currently the only identification for tests is the name associated with the test. Tests may be moved or renamed during refactoring, and some non-integration tests wil move out of Tempest and into project-specific tests. This makes names an unstable identifier. This spec proposes addition of a UUID to each test as a means of stable test identification. Proposed change =============== Each test will have a UUID attached to it, identified both in the test docstring and as a decorator. The docstring will be visible in automated document generation, and the decorator will make UUIDs visible programatically. Alternatives ------------ Other alternatives include identifying tests by file or git hashes. The weakness of these approaches is in the difficulty in tracking tests moving or having patches applied to them. Implementation ============== - Test addition will happen in two phases. - In phase 1 UUIDs will be optional. This will give the QA team sufficient time to tag existing tests. An infra gate will be added to ensure consistency between the docstring and decorator values. An automated tool will do initial bulk test tagging. A hacking tool with check for UUID uniqueness. - In phase 2 UUIDs will be mandatory. All tests will be required as part of the gate to have a UUID associated with it. - The UUID will be generated using the python uuid.uuid4 function. - uuid.uuid1 is also an option, especially if timedate information is available - The UUID will be idenfied in the docstring by the format: 'UUID: 12345678-1234-5678-1234-567812345678' - The UUID will be identified in the decorator by: '@test.uuid('12345678-1234-5678-1234-567812345678')' then in the decorator code set the attr be UUID=arg and add it to the docstring for the function - UUIDs will need to be changed if the functionality of a test changes significantly. This is a massive change that will cause a significant amount of development disruption. To mitigate this we will take a 'big bang' approach: 1. push tool to add a decorator above any test_* method in the test_* files 2. push the patch that applies it everywhere at once including the hacking rule to enforce this. It will be cause a massive number of rebases and will be tough to land, but will make it easier for everyone once does land. Assignee(s) ----------- UUID generation, automated taggind, and gating will be written by the Refstack team members. David Lenwell and Chris Hoge will lead these efforts. The primary author of this implementation is Chris Hoge, chris@openstack.org primary author and contact. Primary assignee: David Lenwell (UUID generation) Chris Hoge (hogepodge, chris@openstack.org) Sergey Slipushenko (automated test tagging) Milestones ---------- Target Milestone for completion: Kilo-2 Work Items ---------- - Define docstring and decorator format. - Write tempest-lib code to generate UUIDS according to format. - Document how to apply tests, and when UUIDs need to change. - Implement and deploy phase 1 gate tests. - Automate test tagging. - Manually tag tests where automation fails. - Implement and deploy phase 2 gate tests. Dependencies ============ - No known external dependencies. ",,117,0
openstack%2Frequirements~stable%2Ficehouse~I8d3dc43ac3aae98852bb833a7216775a0ad4990e,openstack/requirements,stable/icehouse,I8d3dc43ac3aae98852bb833a7216775a0ad4990e,Update glanceclient bounds in icehouse,ABANDONED,2014-12-19 02:04:27.000000000,2014-12-22 23:39:01.000000000,,"[{'_account_id': 3}, {'_account_id': 24}, {'_account_id': 308}, {'_account_id': 979}, {'_account_id': 1420}, {'_account_id': 1561}, {'_account_id': 1955}, {'_account_id': 2750}, {'_account_id': 9656}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-12-19 02:04:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/4908ae1d28c84d6ec28df49338275516ca4a4137', 'message': 'Update glanceclient bounds in icehouse\n\nThe new release of glanceclient 0.15 is outside the bounds of the\nicehouse requirements. This prevents icehouse gate jobs being run.\n\nChange-Id: I8d3dc43ac3aae98852bb833a7216775a0ad4990e\nCloses-Bug: #1404083\n'}, {'number': 2, 'created': '2014-12-19 05:01:48.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/eeaf701e84fee410ee13a75c66316161a4c962ec', 'message': 'Update glanceclient bounds in icehouse\n\nThe new release of glanceclient 0.15 is outside the bounds of the\nicehouse requirements. This prevents icehouse gate jobs being run.\n\nChange-Id: I8d3dc43ac3aae98852bb833a7216775a0ad4990e\nCloses-Bug: #1404083\n'}]",0,142955,eeaf701e84fee410ee13a75c66316161a4c962ec,6,10,2,7191,,,0,"Update glanceclient bounds in icehouse

The new release of glanceclient 0.15 is outside the bounds of the
icehouse requirements. This prevents icehouse gate jobs being run.

Change-Id: I8d3dc43ac3aae98852bb833a7216775a0ad4990e
Closes-Bug: #1404083
",git fetch https://review.opendev.org/openstack/requirements refs/changes/55/142955/2 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,4908ae1d28c84d6ec28df49338275516ca4a4137,glanceclient,"python-glanceclient>=0.9.0,!=0.14.0,<0.16","python-glanceclient>=0.9.0,!=0.14.0,<0.15",1,1
openstack%2Frequirements~stable%2Ficehouse~Idf653790ad989af3f283af8e8d3f6ba6862d6bcd,openstack/requirements,stable/icehouse,Idf653790ad989af3f283af8e8d3f6ba6862d6bcd,Update keystoneclient bounds in icehouse,ABANDONED,2014-12-19 02:02:29.000000000,2014-12-22 23:38:41.000000000,,"[{'_account_id': 3}, {'_account_id': 24}, {'_account_id': 308}, {'_account_id': 979}, {'_account_id': 1420}, {'_account_id': 1561}, {'_account_id': 1955}, {'_account_id': 2750}, {'_account_id': 9656}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-12-19 02:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/dd5d63f2296a928978fd889cfd6215b2cd26d480', 'message': 'Update keystoneclient bounds in icehouse\n\nThe new release of keystoneclient 1.0.0 is outside the bounds of the\nicehouse requirements. This prevents gate icehouse gate jobs being run.\n\nCloses-Bug: #1404081\nChange-Id: Idf653790ad989af3f283af8e8d3f6ba6862d6bcd\n'}, {'number': 2, 'created': '2014-12-19 02:04:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/a6a82745d84175f7e439753e9dda1edbd99e81c2', 'message': 'Update keystoneclient bounds in icehouse\n\nThe new release of keystoneclient 1.0.0 is outside the bounds of the\nicehouse requirements. This prevents icehouse gate jobs being run.\n\nCloses-Bug: #1404081\nChange-Id: Idf653790ad989af3f283af8e8d3f6ba6862d6bcd\n'}, {'number': 3, 'created': '2014-12-19 05:02:39.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/ca059307db3a453c10ec600e572fdb7cb8e0f8a8', 'message': 'Update keystoneclient bounds in icehouse\n\nThe new release of keystoneclient 1.0.0 is outside the bounds of the\nicehouse requirements. This prevents icehouse gate jobs being run.\n\nCloses-Bug: #1404081\nChange-Id: Idf653790ad989af3f283af8e8d3f6ba6862d6bcd\n'}]",0,142954,ca059307db3a453c10ec600e572fdb7cb8e0f8a8,7,10,3,7191,,,0,"Update keystoneclient bounds in icehouse

The new release of keystoneclient 1.0.0 is outside the bounds of the
icehouse requirements. This prevents icehouse gate jobs being run.

Closes-Bug: #1404081
Change-Id: Idf653790ad989af3f283af8e8d3f6ba6862d6bcd
",git fetch https://review.opendev.org/openstack/requirements refs/changes/54/142954/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,dd5d63f2296a928978fd889cfd6215b2cd26d480,concurrency,"python-keystoneclient>=0.7.0,<2.0","python-keystoneclient>=0.7.0,<0.12",1,1
openstack%2Fcongress~master~I6dc9200d1096823e9046fbfcae3222ffb2c21ff5,openstack/congress,master,I6dc9200d1096823e9046fbfcae3222ffb2c21ff5,Add tempest code coverage for ceilometer driver,MERGED,2014-12-19 22:47:02.000000000,2014-12-22 22:46:13.000000000,2014-12-22 22:46:13.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 12256}, {'_account_id': 13050}, {'_account_id': 13664}]","[{'number': 1, 'created': '2014-12-19 22:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/080db496c081403ec7d33c7d6c36ed709d94e693', 'message': 'Add tempest code coverage for ceilometer driver\n\nChange-Id: I6dc9200d1096823e9046fbfcae3222ffb2c21ff5\nCloses-Bug: #1378133\n'}, {'number': 2, 'created': '2014-12-19 22:54:24.000000000', 'files': ['contrib/tempest/tempest/scenario/congress_datasources/test_ceilometer.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/069b48615b13540c2b1d4a4d62eeaa564416718c', 'message': 'Add tempest code coverage for ceilometer driver\n\nChange-Id: I6dc9200d1096823e9046fbfcae3222ffb2c21ff5\nCloses-Bug: #1378133\n'}]",2,143209,069b48615b13540c2b1d4a4d62eeaa564416718c,12,6,2,13664,,,0,"Add tempest code coverage for ceilometer driver

Change-Id: I6dc9200d1096823e9046fbfcae3222ffb2c21ff5
Closes-Bug: #1378133
",git fetch https://review.opendev.org/openstack/congress refs/changes/09/143209/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/tempest/tempest/scenario/congress_datasources/test_ceilometer.py'],1,080db496c081403ec7d33c7d6c36ed709d94e693,1378133,"# Copyright 2014 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest import clients from tempest import config from tempest import exceptions from tempest.openstack.common import log as logging from tempest.scenario import manager_congress from tempest import test CONF = config.CONF LOG = logging.getLogger(__name__) class TestCeilometerDriver(manager_congress.ScenarioPolicyBase): @classmethod def check_preconditions(cls): super(TestCeilometerDriver, cls).check_preconditions() def setUp(cls): super(TestCeilometerDriver, cls).setUp() if not CONF.service_available.ceilometer: msg = (""%s skipped as ceilometer is not available"" % cls.__name__) raise cls.skipException(skip_msg) cls.os = clients.Manager(cls.admin_credentials()) cls.telemetry_client = cls.os.telemetry_client @test.attr(type='smoke') def test_ceilometer_meters_table(self): _, meters = self.telemetry_client.list_meters() meter_map = {} for meter in meters: meter_map[meter['meter_id']] = meter meter_schema = \ self.admin_manager.congress_client.show_datasource_table_schema( 'ceilometer', 'meters')['columns'] def _check_data_table_ceilometer_meters(): results = \ self.admin_manager.congress_client.list_datasource_rows( 'ceilometer', 'meters') for row in results['results']: meter_row = meter_map[row['data'][0]] for index in range(len(meter_schema)): if (str(row['data'][index]) != str(meter_row[meter_schema[index]['name']])): return False return True if not test.call_until_true(func=_check_data_table_ceilometer_meters, duration=20, sleep_for=4): raise exceptions.TimeoutException(""Data did not converge in time "" ""or failure in server"") ",,66,0
openstack%2Fopenstack-manuals~master~I117444cd58f1f6157b07383f056f08ca687a6d40,openstack/openstack-manuals,master,I117444cd58f1f6157b07383f056f08ca687a6d40,changes to section_prescriptive_examples_network_focus,MERGED,2014-12-22 20:14:43.000000000,2014-12-22 22:34:08.000000000,2014-12-22 22:34:07.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-22 20:14:43.000000000', 'files': ['doc/arch-design/network_focus/section_prescriptive_examples_network_focus.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/47e5c81ed37eedacaa2141e055d739db32dabf0b', 'message': 'changes to section_prescriptive_examples_network_focus\n\nmade changes to dependant (corrected)\n\nChange-Id: I117444cd58f1f6157b07383f056f08ca687a6d40\n'}]",0,143525,47e5c81ed37eedacaa2141e055d739db32dabf0b,7,3,1,9382,,,0,"changes to section_prescriptive_examples_network_focus

made changes to dependant (corrected)

Change-Id: I117444cd58f1f6157b07383f056f08ca687a6d40
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/25/143525/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/arch-design/network_focus/section_prescriptive_examples_network_focus.xml'],1,47e5c81ed37eedacaa2141e055d739db32dabf0b,network_focus, <para>The network design in this case is less dependent on availability and more dependent on being able to handle high, <para>The network design in this case is less dependant on availability and more dependant on being able to handle high,2,2
openstack%2Fopenstack-manuals~master~I040455a21d189994e253752333c718617b936955,openstack/openstack-manuals,master,I040455a21d189994e253752333c718617b936955,made change to section_tech_considerations_hybrid,MERGED,2014-12-22 20:42:53.000000000,2014-12-22 22:32:35.000000000,2014-12-22 22:32:34.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-22 20:42:53.000000000', 'files': ['doc/arch-design/hybrid/section_tech_considerations_hybrid.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/352f3df8be75bddd5e185ce04cf953ddcc319e11', 'message': 'made change to section_tech_considerations_hybrid\n\nchanged telemetery to telemetry\n\nChange-Id: I040455a21d189994e253752333c718617b936955\n'}]",0,143532,352f3df8be75bddd5e185ce04cf953ddcc319e11,7,3,1,9382,,,0,"made change to section_tech_considerations_hybrid

changed telemetery to telemetry

Change-Id: I040455a21d189994e253752333c718617b936955
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/32/143532/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/arch-design/hybrid/section_tech_considerations_hybrid.xml'],1,352f3df8be75bddd5e185ce04cf953ddcc319e11,section_tech_consi, <para>Telemetry module (ceilometer): Use of Telemetry, <para>Telemetry module (ceilometer): Use of Telemetery,1,1
openstack%2Fmagnum~master~Ic2e72c04f37095a0cf731465bdf6fb8db0058e53,openstack/magnum,master,Ic2e72c04f37095a0cf731465bdf6fb8db0058e53,Implement container_list,MERGED,2014-12-22 14:38:19.000000000,2014-12-22 21:52:28.000000000,2014-12-22 21:52:28.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-22 14:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/96c708c21fef2613aaccfc77a67f56f1f5a73ca8', 'message': 'Implement container_list\n\nChange-Id: Ic2e72c04f37095a0cf731465bdf6fb8db0058e53\n'}, {'number': 2, 'created': '2014-12-22 14:44:23.000000000', 'files': ['magnum/api/controllers/v1/container.py', 'magnum/conductor/api.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/16ad8207bf590939d53808b7352cf4f3d2e524b8', 'message': 'Implement container_list\n\nChange-Id: Ic2e72c04f37095a0cf731465bdf6fb8db0058e53\n'}]",0,143456,16ad8207bf590939d53808b7352cf4f3d2e524b8,8,2,2,7494,,,0,"Implement container_list

Change-Id: Ic2e72c04f37095a0cf731465bdf6fb8db0058e53
",git fetch https://review.opendev.org/openstack/magnum refs/changes/56/143456/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/api/controllers/v1/container.py', 'magnum/conductor/api.py']",2,96c708c21fef2613aaccfc77a67f56f1f5a73ca8,master," def container_list(self, context, limit, marker, sort_key, sort_dir): return objects.Container.list(context, limit, marker, sort_key, sort_dir)", def container_list(self): return self._call('container_list'),5,3
openstack%2Fmagnum~master~If032a5142b57aa20178a374f764b00bc4abd0f80,openstack/magnum,master,If032a5142b57aa20178a374f764b00bc4abd0f80,Add a hyper-link for quick start,MERGED,2014-12-22 09:36:16.000000000,2014-12-22 21:51:52.000000000,2014-12-22 21:51:52.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-22 09:36:16.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/cbae05b099f43a2787eb5203d4dbd14114165d59', 'message': 'Add a hyper-link for quick start\n\nChange-Id: If032a5142b57aa20178a374f764b00bc4abd0f80\n'}]",0,143406,cbae05b099f43a2787eb5203d4dbd14114165d59,6,2,1,7494,,,0,"Add a hyper-link for quick start

Change-Id: If032a5142b57aa20178a374f764b00bc4abd0f80
",git fetch https://review.opendev.org/openstack/magnum refs/changes/06/143406/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,cbae05b099f43a2787eb5203d4dbd14114165d59,master,* Getting Started Guides: [doc/source/dev/dev-quickstart.rst](doc/source/dev/dev-quickstart.rst),"For installation and usage, please read the developer installation guide located at doc/source/dev/dev-quickstart.rst.",1,2
openstack%2Fmagnum~master~I6bde0149caaf93b6e446f5f01039895fb36751e6,openstack/magnum,master,I6bde0149caaf93b6e446f5f01039895fb36751e6,Implement docker backend for magnum service,MERGED,2014-12-19 17:38:48.000000000,2014-12-22 21:49:17.000000000,2014-12-22 21:49:17.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 5638}, {'_account_id': 7494}, {'_account_id': 8580}]","[{'number': 1, 'created': '2014-12-19 17:38:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/7537e94a6cee203e98bd3acbbf02af663cf8eac6', 'message': 'Implemented docker backend for magnum service.\n\nChange-Id: I6bde0149caaf93b6e446f5f01039895fb36751e6\nImplements: blueprint magnum-backend-docker\n'}, {'number': 2, 'created': '2014-12-22 21:45:10.000000000', 'files': ['magnum/conductor/handlers/docker.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/ea25d067a65b41aeeb6c4d10f6515b32bfeff1df', 'message': 'Implement docker backend for magnum service\n\nChange-Id: I6bde0149caaf93b6e446f5f01039895fb36751e6\nImplements: blueprint magnum-backend-docker\n'}]",7,143145,ea25d067a65b41aeeb6c4d10f6515b32bfeff1df,14,5,2,8580,,,0,"Implement docker backend for magnum service

Change-Id: I6bde0149caaf93b6e446f5f01039895fb36751e6
Implements: blueprint magnum-backend-docker
",git fetch https://review.opendev.org/openstack/magnum refs/changes/45/143145/2 && git format-patch -1 --stdout FETCH_HEAD,['magnum/conductor/handlers/docker.py'],1,7537e94a6cee203e98bd3acbbf02af663cf8eac6,bp/magnum-backend-docker,"from docker import Client from docker import tls from oslo.config import cfg LOG = logging.getLogger(__name__) CONF = cfg.CONF docker_opts = [ cfg.StrOpt('host_url', help='tcp://host:port to bind/connect to or' 'unix://path/to/socker to use'), cfg.BoolOpt('api_secure', default=False, help='If set, ignore any SSL validation issues'), cfg.StrOpt('ca_file', help='Location of CA certificate file for ' 'securing docker api requests (tlscacert).'), cfg.StrOpt('cert_file', help='Location of TLS certificate file for ' 'securing docker api requests (tlscert).'), cfg.StrOpt('key_file', help='Location of TLS private key file for ' 'securing docker api requests (tlskey).'), ] CONF.register_opts(docker_opts, 'docker') class Handler(object): def __init__(self, url): if (CONF.docker.cert_file or CONF.docker.key_file): client_cert = (CONF.docker.cert_file, CONF.docker.key_file) else: client_cert = None if (CONF.docker.ca_file or CONF.docker.api_insecure or client_cert): tls_config = tls.TLSConfig( client_cert=client_cert, ca_Cert=CONF.docker.ca_file, verify=CONF.docker.api_insecure) else: tls_config = None self.client = Client(base_url=url, tls=tls_config) def encode_utf8(self, value): return unicode(value).encode('utf-8') def container_create(self, bay_uuid, image_name, command): LOG.debug(""container_create %s contents=%s"" % (bay_uuid, image_name)) self.client.inspect_image(self._encode_utf8(image_name)) container_id = self.client.create_container(image_name, command) self.container_start(container_id) def container_list(self, bay_uuid): container_list = self.client.containers() return container_list def container_delete(self, bay_uuid, container_id): LOG.debug(""cotainer_delete %s"" % bay_uuid) return ""Not Implemented"" def container_show(self, bay_uuid, container_id): LOG.debug(""container_show %s"" % bay_uuid) return ""Not Implemented"" def container_reboot(self, bay_uuid, container_id): LOG.debug(""container_reboot %s"" % bay_uuid) return ""Not Implemented"" def container_stop(self, bay_uuid, container_id): LOG.debug(""container_stop %s"" % bay_uuid) self.client.start(container_id) def container_start(self, bay_uuid, container_id): LOG.debug(""container_start %s"" % bay_uuid) self.client.start(container_id) def container_pause(self, bay_uuid, container_id): LOG.debug(""container_pause %s"" % bay_uuid) return ""Not Implemented"" def container_unpause(self, bay_uuid, container_id): LOG.debug(""container_unpause %s"" % bay_uuid) return ""Not Implemented"" def container_logs(self, bay_uuid, container_id): LOG.debug(""container_logs %s"" % bay_uuid) return ""Not Implemented"" def container_execute(self, bay_uuid, container_id): LOG.debug(""container_execute %s"" % bay_uuid) return ""Not Implemented""","LOG = logging.getLogger(__name__) class Handler(object): def __init__(self): def container_create(uuid, contents): LOG.debug(""container_create %s contents=%s"" % (uuid, contents)) def container_list(): def container_delete(uuid): LOG.debug(""cotainer_delete %s"" % uuid) def container_show(uuid): LOG.debug(""container_show %s"" % uuid) def container_reboot(uuid): LOG.debug(""container_reboot %s"" % uuid) def container_stop(uuid): LOG.debug(""container_stop %s"" % uuid) def container_start(uuid): LOG.debug(""container_start %s"" % uuid) def container_pause(uuid): LOG.debug(""container_pause %s"" % uuid) def container_unpause(uuid): LOG.debug(""container_unpause %s"" % uuid) def container_logs(uuid): LOG.debug(""container_logs %s"" % uuid) def container_execute(uuid): LOG.debug(""container_execute %s"" % uuid)",82,23
openstack%2Fmagnum~master~I6ce21d737fc341b8df820761c14ffc3b5e7151da,openstack/magnum,master,I6ce21d737fc341b8df820761c14ffc3b5e7151da,Update log message and some functions in kube.py,MERGED,2014-12-22 06:39:09.000000000,2014-12-22 21:48:15.000000000,2014-12-22 21:48:14.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 7494}]","[{'number': 1, 'created': '2014-12-22 06:39:09.000000000', 'files': ['magnum/conductor/handlers/kube.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/878f330636c0c2bfbbee9c628f8d93a701614884', 'message': 'Update log message and some functions in kube.py\n\nChange-Id: I6ce21d737fc341b8df820761c14ffc3b5e7151da\n'}]",0,143373,878f330636c0c2bfbbee9c628f8d93a701614884,8,3,1,7494,,,0,"Update log message and some functions in kube.py

Change-Id: I6ce21d737fc341b8df820761c14ffc3b5e7151da
",git fetch https://review.opendev.org/openstack/magnum refs/changes/73/143373/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/conductor/handlers/kube.py'],1,878f330636c0c2bfbbee9c628f8d93a701614884,master," LOG.debug(""service_update"") status = self.kube_cli.pod_update(pod) pod.refresh(context) status = self.kube_cli.pod_delete(pod.uuid)"," LOG.debug(""service_create"") status = self.kube_cli.pod_create(pod) pod.create(context) status = self.kube_cli.service_delete(pod.uuid)",4,4
openstack%2Fopenstack-manuals~master~I9edc85ef75cfe16353319249fe53444f0364b55b,openstack/openstack-manuals,master,I9edc85ef75cfe16353319249fe53444f0364b55b,Added information on backup encryption in volume metadata,MERGED,2014-12-22 05:18:38.000000000,2014-12-22 20:40:23.000000000,2014-12-22 20:40:22.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-12-22 05:18:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/582f646a50b8dd182ed76c4e5bd177dca7ab5375', 'message': 'Added information on backup encryption in volume metadata\n\nUpdated the Cloud Administrator Guide with information on backup\nencryption: volume encryption remains valid after a\nvolume is backed up, and then restored.\n\nChange-Id: I9edc85ef75cfe16353319249fe53444f0364b55b\nBackport: none\nCloses-Bug: #1401237\n'}, {'number': 2, 'created': '2014-12-22 19:39:23.000000000', 'files': ['doc/admin-guide-cloud/blockstorage/section_volume-backups-export-import.xml', 'doc/admin-guide-cloud/blockstorage/section_volume-backups.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/918be91229cb1db694aa75f357366b9eacee37e1', 'message': 'Added information on backup encryption in volume metadata\n\nUpdated the Cloud Administrator Guide with information on backup\nencryption: volume encryption remains valid after a\nvolume is backed up, and then restored.\n\nChange-Id: I9edc85ef75cfe16353319249fe53444f0364b55b\nBackport: none\nCloses-Bug: #1401237\n'}]",1,143362,918be91229cb1db694aa75f357366b9eacee37e1,12,5,2,10897,,,0,"Added information on backup encryption in volume metadata

Updated the Cloud Administrator Guide with information on backup
encryption: volume encryption remains valid after a
volume is backed up, and then restored.

Change-Id: I9edc85ef75cfe16353319249fe53444f0364b55b
Backport: none
Closes-Bug: #1401237
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/62/143362/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud/blockstorage/section_volume-backups-export-import.xml', 'doc/admin-guide-cloud/blockstorage/section_volume-backups.xml']",2,582f646a50b8dd182ed76c4e5bd177dca7ab5375,bug1401237/joseph-r-email," <para>If you specify a UUID encryption key when setting up the volume specifications, the backup metadata ensures that the key will remain valid when you back up and restore the volume.</para>",,8,0
openstack%2Fopenstack-manuals~master~I036ae43b73c8ca469e04e8090e197d57a7a5f5d0,openstack/openstack-manuals,master,I036ae43b73c8ca469e04e8090e197d57a7a5f5d0,Fix additional issue with _member_ role creation,MERGED,2014-12-22 19:38:26.000000000,2014-12-22 20:39:01.000000000,2014-12-22 20:39:01.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 964}, {'_account_id': 6772}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-12-22 19:38:26.000000000', 'files': ['doc/install-guide/section_keystone-users.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/549be4ba1d84ba749ea79c7a0d1e8953ef9d4cfd', 'message': ""Fix additional issue with _member_ role creation\n\nI removed the '--tenant' option from the admin user/tenant\ncreation step because the latter needs only the admin role.\nAlso, I provided an explanation about automatic assignment\nand/or creation of the _member_ role.\n\nChange-Id: I036ae43b73c8ca469e04e8090e197d57a7a5f5d0\nCloses-Bug: #1403136\nbackport: juno\n""}]",2,143519,549be4ba1d84ba749ea79c7a0d1e8953ef9d4cfd,9,5,1,9515,,,0,"Fix additional issue with _member_ role creation

I removed the '--tenant' option from the admin user/tenant
creation step because the latter needs only the admin role.
Also, I provided an explanation about automatic assignment
and/or creation of the _member_ role.

Change-Id: I036ae43b73c8ca469e04e8090e197d57a7a5f5d0
Closes-Bug: #1403136
backport: juno
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/19/143519/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_keystone-users.xml'],1,549be4ba1d84ba749ea79c7a0d1e8953ef9d4cfd,bug/1403136, <para>Create the <literal>admin</literal> user:</para> <screen><prompt>$</prompt> <userinput>keystone user-create --name admin --pass <replaceable>ADMIN_PASS</replaceable> --email <replaceable>EMAIL_ADDRESS</replaceable></userinput> <note> <para>Using the <literal>--tenant</literal> option automatically assigns the <literal>_member_</literal> role to a user. This option will also create the <literal>_member_</literal> role if it does not exist.</para> </note>, <para>Create the <literal>admin</literal> user under the <literal>admin</literal> tenant:</para> <screen><prompt>$</prompt> <userinput>keystone user-create --name admin --tenant admin --pass <replaceable>ADMIN_PASS</replaceable> --email <replaceable>EMAIL_ADDRESS</replaceable></userinput>| tenantId | 6f4c1e4cbfef4d5a8a1345882fbca110 |,8,4
openstack%2Ffuel-main~stable%2F5.1~Ib409176a4ebfb9e1ab18215ec8cfaf6a8d478e9e,openstack/fuel-main,stable/5.1,Ib409176a4ebfb9e1ab18215ec8cfaf6a8d478e9e,Remove network settings logging from 'info' channel,MERGED,2014-12-17 18:50:49.000000000,2014-12-22 20:36:20.000000000,2014-12-22 20:36:19.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-12-17 18:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0bb103c60bb5e52433480e63553c5b96af6d21c4', 'message': 'Move network settings logging to \'debug\' log\n\nWhen we create a cluster with nova-network then FlatDHCP selected\nby default. There is no logs about the fact of later network\nupdates.\n\n- Move ""Network settings for push"" message to \'debug\' log\n- Add ""Update network with new settings"" debug message to\nNailgunClient.update_network() method.\n\nChange-Id: Ib409176a4ebfb9e1ab18215ec8cfaf6a8d478e9e\nCloses-Bug: #1398071\n'}, {'number': 2, 'created': '2014-12-22 11:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/671f328debe3225d4347fa6a9e60b62668050312', 'message': ""Move network settings logging to 'debug' log\n\nWhen we create a cluster with nova-network then FlatDHCP selected\nby default. Latelly the network configuration can be updated but\n'info' log provides inaccurate information.\n\nThis logging is redundant because all necessary information is\nlogged with @logwrap\n\nChange-Id: Ib409176a4ebfb9e1ab18215ec8cfaf6a8d478e9e\nCloses-Bug: #1398071\n""}, {'number': 3, 'created': '2014-12-22 18:20:13.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9fc9ddde4f042575d3069e88b8f3f41692d5872a', 'message': ""Remove network settings logging from 'info' channel\n\nWhen we create a cluster with nova-network then FlatDHCP selected\nby default. Latelly the network configuration can be updated but\n'info' log provides inaccurate information.\n\nThis logging is redundant because all necessary information is\nlogged with @logwrap\n\nChange-Id: Ib409176a4ebfb9e1ab18215ec8cfaf6a8d478e9e\nCloses-Bug: #1398071\n""}]",1,142536,9fc9ddde4f042575d3069e88b8f3f41692d5872a,19,6,3,11969,,,0,"Remove network settings logging from 'info' channel

When we create a cluster with nova-network then FlatDHCP selected
by default. Latelly the network configuration can be updated but
'info' log provides inaccurate information.

This logging is redundant because all necessary information is
logged with @logwrap

Change-Id: Ib409176a4ebfb9e1ab18215ec8cfaf6a8d478e9e
Closes-Bug: #1398071
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/36/142536/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/models/nailgun_client.py']",2,0bb103c60bb5e52433480e63553c5b96af6d21c4,bug/1398071," logger.debug(""Update network with new settings: {}"".format(nc))",,2,1
openstack%2Ffuel-main~master~Ieef687b815e18ff22c7660e41863e1596c352b91,openstack/fuel-main,master,Ieef687b815e18ff22c7660e41863e1596c352b91,Remove network settings logging from 'info' channel,MERGED,2014-12-17 18:42:26.000000000,2014-12-22 20:35:26.000000000,2014-12-22 20:35:25.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-12-17 18:42:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7b11eddc5c27f26d17e4c44a7a27fb7d56606ff3', 'message': 'Move network settings logging to \'debug\' log\n\nWhen we create a cluster with nova-network then FlatDHCP selected\nby default. There is no logs about the fact of later network\nupdates.\n\n- Move ""Network settings for push"" message to \'debug\' log\n- Add ""Update network with new settings"" debug message to\nNailgunClient.update_network() method.\n\nChange-Id: Ieef687b815e18ff22c7660e41863e1596c352b91\nCloses-Bug: #1398071\n'}, {'number': 2, 'created': '2014-12-22 11:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/57c0cd70b652fc2a45c0a2bd91dc8e0c28fcbf45', 'message': ""Move network settings logging to 'debug' log\n\nWhen we create a cluster with nova-network then FlatDHCP selected\nby default. Latelly the network configuration can be updated but\n'info' log provides inaccurate information.\n\nThis logging is redundant because all necessary information is\nlogged with @logwrap\n\nChange-Id: Ieef687b815e18ff22c7660e41863e1596c352b91\nCloses-Bug: #1398071\n""}, {'number': 3, 'created': '2014-12-22 11:45:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0dcda1def8e48098108687c63dedaeed6694288d', 'message': ""Move network settings logging to 'debug' log\n\nWhen we create a cluster with nova-network then FlatDHCP selected\nby default. Latelly the network configuration can be updated but\n'info' log provides inaccurate information.\n\nThis logging is redundant because all necessary information is\nlogged with @logwrap\n\nChange-Id: Ieef687b815e18ff22c7660e41863e1596c352b91\nCloses-Bug: #1398071\n""}, {'number': 4, 'created': '2014-12-22 18:19:16.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4ee8cd0b9bbc0377850564e55d7f27a3c49e5e5f', 'message': ""Remove network settings logging from 'info' channel\n\nWhen we create a cluster with nova-network then FlatDHCP selected\nby default. Latelly the network configuration can be updated but\n'info' log provides inaccurate information.\n\nThis logging is redundant because all necessary information is\nlogged with @logwrap\n\nChange-Id: Ieef687b815e18ff22c7660e41863e1596c352b91\nCloses-Bug: #1398071\n""}]",1,142532,4ee8cd0b9bbc0377850564e55d7f27a3c49e5e5f,24,6,4,11969,,,0,"Remove network settings logging from 'info' channel

When we create a cluster with nova-network then FlatDHCP selected
by default. Latelly the network configuration can be updated but
'info' log provides inaccurate information.

This logging is redundant because all necessary information is
logged with @logwrap

Change-Id: Ieef687b815e18ff22c7660e41863e1596c352b91
Closes-Bug: #1398071
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/32/142532/4 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/models/nailgun_client.py']",2,7b11eddc5c27f26d17e4c44a7a27fb7d56606ff3,bug/1398071," logger.debug(""Update network with new settings: {}"".format(nc))",,2,1
openstack%2Fkeystone-specs~master~Ibfb287f1ece0f5dcdfe765d0dac8d0f5e754fe09,openstack/keystone-specs,master,Ibfb287f1ece0f5dcdfe765d0dac8d0f5e754fe09,Policy Targets from Config File,ABANDONED,2014-12-06 15:16:57.000000000,2014-12-22 20:34:39.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2218}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-12-06 15:16:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/250439f16c49e2428ec2c0fc453ddc5e79a85232', 'message': 'Policy Targets from Config File\n\nChange-Id: Ibfb287f1ece0f5dcdfe765d0dac8d0f5e754fe09\n'}, {'number': 2, 'created': '2014-12-06 15:36:06.000000000', 'files': ['specs/kilo/config_policy.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/40ef81a41b799bcca68a746a679c35caaf90a973', 'message': 'Policy Targets from Config File\n\nChange-Id: Ibfb287f1ece0f5dcdfe765d0dac8d0f5e754fe09\n'}]",3,139809,40ef81a41b799bcca68a746a679c35caaf90a973,8,4,2,2218,,,0,"Policy Targets from Config File

Change-Id: Ibfb287f1ece0f5dcdfe765d0dac8d0f5e754fe09
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/09/139809/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/config_policy.rst'],1,250439f16c49e2428ec2c0fc453ddc5e79a85232,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================== Configuration Opetion in Policy =============================== `bp config_policy <https://blueprints.launchpad.net/keystone/+spec/config_policy>`_ Make the policy engine capable of using config file options in policy rules. Problem Description =================== The V3 Cloud sample has to be edited to have the admin domain id edited in, and then the two values must be manually synchronized. Proposed Change =============== Make the policy engine capable of reading a config option as one of the Targets in a policy rule. So this rule: ""cloud_admin"": ""rule:admin_required and domain_id:admin_domain_id"", Could become ""cloud_admin"": ""rule:admin_required and domain_id:CONF.identity.default_domain_id"" If a config option for admin domain was added to the conf file it could become ""cloud_admin"": ""rule:admin_required and domain_id:CONF.identity.admin_domain_id"" Security Impact --------------- Describe any potential security impact on the system. Some of the items to consider include: * Does this change touch sensitive data such as tokens, keys, or user data? * Yes, policy. * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? * No, it just provides a more standard way of specify read only data. * Does this change involve cryptography or hashing? * No * Does this change require the use of sudo or any elevated privileges? * No * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. * No * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. * No Notifications Impact -------------------- None Other End User Impact --------------------- None Performance Impact ------------------ None Other Deployer Impact --------------------- Discuss things that will affect how you deploy and configure OpenStack that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example a flag that other hypervisor drivers might want to implement as well)? Are the default values ones which will work well in real deployments? * No new options, but makes it possible to consume existing options. * Is this a change that takes immediate effect after its merged, or is it something that has to be explicitly enabled? * Takes effect Immediately, but will have no impact until the policy files are changed. * If this change is a new binary, how would it be deployed? * No * Please state anything that those doing continuous deployment, or those upgrading from the previous release, need to be aware of. Also describe any plans to deprecate configuration values or features. For example, if we change the directory name that instances are stored in, how do we handle instance directories created before the change landed? Do we move them? Do we have a special case in the code? Do we assume that the operator will recreate all the instances in their cloud? * Will allow a wider array of default policy file options. If coupled with a change to the cloud sample policy file, it means the cloud sample policy file could be deployed without editing it. Developer Impact ---------------- None Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: ayoung Adam Young Other contributors: <launchpad-id or None> Work Items ---------- Should be done in a single commit. Dependencies ============ None Documentation Impact ==================== Once the change goes into effect it should b documented. References ========== * http://adam.younglogic.com/2014/11/dynamic-policy-in-keystone/ ",,163,0
openstack%2Fneutron~master~I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd,openstack/neutron,master,I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd,ipv6: set OtherConfig flag for DHCPv6 stateless subnets,MERGED,2014-11-27 14:53:00.000000000,2014-12-22 20:31:54.000000000,2014-12-22 14:48:37.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6685}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10257}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-11-27 14:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4e52d75df1afc7fd09e71025c36b3f7d34841016', 'message': ""ipv6: set OtherConfig flag for DHCPv6 stateless subnets\n\nIn case of DHCPv6 stateless subnets, we should inform DHCP clients about\nother configuration values available from DHCP server. This is done by\nsetting O (other) flag in RAs, which is controlled by AdvOtherConfigFlag\nsetting in radvd case.\n\nNot adding a unit/functional test since it would state the obvious.\nA reasonable test would explore whether the flag is indeed set in\nRAs sent on wire, but we don't have any framework to easily capture and\nanalyze packets.\n\nChange-Id: I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd\nCloses-Bug: #1397022\n""}, {'number': 2, 'created': '2014-11-28 22:20:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5e4c1796a5c2a286c31589ee349680df41a497fc', 'message': ""ipv6: set OtherConfig flag for DHCPv6 stateless subnets\n\nIn case of DHCPv6 stateless subnets, we should inform DHCP clients about\nother configuration values available from DHCP server. This is done by\nsetting O (other) flag in RAs, which is controlled by AdvOtherConfigFlag\nsetting in radvd case.\n\nAdded a basic unit test that checks that flag is set for stateless mode\nand not SLAAC. For stateful, it doesn't really matter whether other flag\nis set, so no need to expect any value of it.\n\nChange-Id: I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd\nCloses-Bug: #1397022\n""}, {'number': 3, 'created': '2014-11-29 12:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/02333ebe467c8048636cfc8eaa376ed1b1764708', 'message': ""ipv6: set OtherConfig flag for DHCPv6 stateless subnets\n\nIn case of DHCPv6 stateless subnets, we should inform DHCP clients about\nother configuration values available from DHCP server. This is done by\nsetting O (other) flag in RAs, which is controlled by AdvOtherConfigFlag\nsetting in radvd case.\n\nAdded a basic unit test that checks that flag is set for stateless mode\nand not SLAAC. For stateful, it doesn't really matter whether other flag\nis set, so no need to expect any value of it.\n\nChange-Id: I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd\nCloses-Bug: #1397022\n""}, {'number': 4, 'created': '2014-12-08 09:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ecb19e318a6082cf8b0832684f92ddcc0e093559', 'message': ""ipv6: set OtherConfig flag for DHCPv6 stateless subnets\n\nIn case of DHCPv6 stateless subnets, we should inform DHCP clients about\nother configuration values available from DHCP server. This is done by\nsetting O (other) flag in RAs, which is controlled by AdvOtherConfigFlag\nsetting in radvd case.\n\nAdded a basic unit test that checks that flag is set for stateless mode\nand not SLAAC. For stateful, it doesn't really matter whether other flag\nis set, so no need to expect any value of it.\n\nChange-Id: I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd\nCloses-Bug: #1397022\n""}, {'number': 5, 'created': '2014-12-09 10:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dd0cc69b5e8f415fd3817ce33cc7eb9e689cf72b', 'message': ""ipv6: set OtherConfig flag for DHCPv6 stateless subnets\n\nIn case of DHCPv6 stateless subnets, we should inform DHCP clients about\nother configuration values available from DHCP server. This is done by\nsetting O (other) flag in RAs, which is controlled by AdvOtherConfigFlag\nsetting in radvd case.\n\nAdded a basic unit test that checks that flag is set for stateless mode\nand not SLAAC. For stateful, it doesn't really matter whether other flag\nis set, so no need to expect any value of it.\n\nChange-Id: I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd\nCloses-Bug: #1397022\n""}, {'number': 6, 'created': '2014-12-12 15:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8eebebbcc95859d3d312fea48b40331b77562e1a', 'message': ""ipv6: set OtherConfig flag for DHCPv6 stateless subnets\n\nIn case of DHCPv6 stateless subnets, we should inform DHCP clients about\nother configuration values available from DHCP server. This is done by\nsetting O (other) flag in RAs, which is controlled by AdvOtherConfigFlag\nsetting in radvd case.\n\nAdded a basic unit test that checks that flag is set for stateless mode\nand not SLAAC. For stateful, it doesn't really matter whether other flag\nis set, so no need to expect any value of it.\n\nChange-Id: I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd\nCloses-Bug: #1397022\n""}, {'number': 7, 'created': '2014-12-15 13:41:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c858a20e6e7ece81cefacd9b233ad61e930d4b80', 'message': ""ipv6: set OtherConfig flag for DHCPv6 stateless subnets\n\nIn case of DHCPv6 stateless subnets, we should inform DHCP clients about\nother configuration values available from DHCP server. This is done by\nsetting O (other) flag in RAs, which is controlled by AdvOtherConfigFlag\nsetting in radvd case.\n\nAdded a basic unit test that checks that flag is set for stateless mode\nand not SLAAC. For stateful, it doesn't really matter whether other flag\nis set, so no need to expect any value of it.\n\nChange-Id: I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd\nCloses-Bug: #1397022\n""}, {'number': 8, 'created': '2014-12-16 13:33:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/02d2f1f832be5ff71e8e95dd5925e4c8231d2c6e', 'message': ""ipv6: set OtherConfig flag for DHCPv6 stateless subnets\n\nIn case of DHCPv6 stateless subnets, we should inform DHCP clients about\nother configuration values available from DHCP server. This is done by\nsetting O (other) flag in RAs, which is controlled by AdvOtherConfigFlag\nsetting in radvd case.\n\nSince radvd configuration file becomes quite complex, migrated its\ngeneration to Jinja2.\n\nAdded a basic unit test that checks that flag is set for stateless mode\nand not SLAAC. For stateful, it doesn't really matter whether other flag\nis set, so no need to expect any value of it.\n\nNo more unit tests seem to be needed: conditional prefix generation is\nalready covered in test_l3_agent, and other statements are common for\nall ipv6_ra_modes.\n\nChange-Id: I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd\nCloses-Bug: #1397022\n""}, {'number': 9, 'created': '2014-12-16 18:20:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b4591da6d545b3e09275b75d2499a5f1dbb569b3', 'message': ""ipv6: set OtherConfig flag for DHCPv6 stateless subnets\n\nIn case of DHCPv6 stateless subnets, we should inform DHCP clients about\nother configuration values available from DHCP server. This is done by\nsetting O (other) flag in RAs, which is controlled by AdvOtherConfigFlag\nsetting in radvd case.\n\nSince radvd configuration file becomes quite complex, migrated its\ngeneration to Jinja2.\n\nAdded a basic unit test that checks that flag is set for stateless mode\nand not SLAAC. For stateful, it doesn't really matter whether other flag\nis set, so no need to expect any value of it.\n\nNo more unit tests seem to be needed: conditional prefix generation is\nalready covered in test_l3_agent, and other statements are common for\nall ipv6_ra_modes.\n\nChange-Id: I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd\nCloses-Bug: #1397022\n""}, {'number': 10, 'created': '2014-12-22 10:38:20.000000000', 'files': ['neutron/agent/linux/ra.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4f3a9135acb561172f7af45bc82739d6dc49f23c', 'message': ""ipv6: set OtherConfig flag for DHCPv6 stateless subnets\n\nIn case of DHCPv6 stateless subnets, we should inform DHCP clients about\nother configuration values available from DHCP server. This is done by\nsetting O (other) flag in RAs, which is controlled by AdvOtherConfigFlag\nsetting in radvd case.\n\nSince radvd configuration file becomes quite complex, migrated its\ngeneration to Jinja2.\n\nAdded a basic unit test that checks that flag is set for stateless mode\nand not SLAAC. For stateful, it doesn't really matter whether other flag\nis set, so no need to expect any value of it.\n\nNo more unit tests seem to be needed: conditional prefix generation is\nalready covered in test_l3_agent, and other statements are common for\nall ipv6_ra_modes.\n\nChange-Id: I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd\nCloses-Bug: #1397022\n""}]",5,137656,4f3a9135acb561172f7af45bc82739d6dc49f23c,235,35,10,9656,,,0,"ipv6: set OtherConfig flag for DHCPv6 stateless subnets

In case of DHCPv6 stateless subnets, we should inform DHCP clients about
other configuration values available from DHCP server. This is done by
setting O (other) flag in RAs, which is controlled by AdvOtherConfigFlag
setting in radvd case.

Since radvd configuration file becomes quite complex, migrated its
generation to Jinja2.

Added a basic unit test that checks that flag is set for stateless mode
and not SLAAC. For stateful, it doesn't really matter whether other flag
is set, so no need to expect any value of it.

No more unit tests seem to be needed: conditional prefix generation is
already covered in test_l3_agent, and other statements are common for
all ipv6_ra_modes.

Change-Id: I1ddad3e1f5efce2b6da4ec00b9294e08fe1e85dd
Closes-Bug: #1397022
",git fetch https://review.opendev.org/openstack/neutron refs/changes/56/137656/10 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/ra.py'],1,4e52d75df1afc7fd09e71025c36b3f7d34841016,bug/1397022,"slaac_fmt = """"""interface %sstateless_fmt = """"""interface %s { AdvSendAdvert on; AdvOtherConfigFlag on; MinRtrAdvInterval 3; MaxRtrAdvInterval 10; prefix %s { AdvOnLink on; AdvAutonomous on; }; }; """""" stateful_fmt = """"""interface %s ra_mode = p['subnet']['ipv6_ra_mode'] if ra_mode == constants.IPV6_SLAAC: conf_str = slaac_fmt % (interface_name, p['subnet']['cidr']) elif ra_mode == constants.DHCPV6_STATELESS: conf_str = stateless_fmt % (interface_name, p['subnet']['cidr']) else: conf_str = stateful_fmt % interface_name","prefix_fmt = """"""interface %sdefault_fmt = """"""interface %s if _is_slaac(p['subnet']['ipv6_ra_mode']): conf_str = prefix_fmt % (interface_name, p['subnet']['cidr']) else: conf_str = default_fmt % interface_name",24,6
openstack-attic%2Fidentity-api~master~I1a5ec1eb326834f6215de89eb862eacf88b69f78,openstack-attic/identity-api,master,I1a5ec1eb326834f6215de89eb862eacf88b69f78,request unscoped token,ABANDONED,2014-12-18 03:38:31.000000000,2014-12-22 20:15:38.000000000,,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2014-12-18 03:38:31.000000000', 'files': ['v3/src/markdown/identity-api-v3.md'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/4ef3177e12ab40848f9169ab23f94ebebfb74345', 'message': 'request unscoped token\n\nChange-Id: I1a5ec1eb326834f6215de89eb862eacf88b69f78\n'}]",0,142658,4ef3177e12ab40848f9169ab23f94ebebfb74345,4,2,1,2218,,,0,"request unscoped token

Change-Id: I1a5ec1eb326834f6215de89eb862eacf88b69f78
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/58/142658/1 && git format-patch -1 --stdout FETCH_HEAD,['v3/src/markdown/identity-api-v3.md'],1,4ef3177e12ab40848f9169ab23f94ebebfb74345,,"*New in version 3.4* A user may explicitly request an unscoped token by setting the ""scope"" value of the token request to the string ""unscoped."" This will behave the same as a token request with no scope, where the user has no default project defined. ",,6,0
openstack%2Fneutron~master~Id21c38610ed73defb937d971a7aade57713541c0,openstack/neutron,master,Id21c38610ed73defb937d971a7aade57713541c0,PLUMgrid plugin: Fix for delete subnet with admin context,MERGED,2014-12-21 21:01:56.000000000,2014-12-22 20:04:30.000000000,2014-12-22 16:57:00.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 8279}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-21 21:01:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bb80410bd38309fc85b0aa140b8ff69584f17825', 'message': 'PLUMgrid plugin: Fix for delete subnet with admin context\n\nWhen delete call using admin for a subnet created from a\nnon-admin project is made, the tenant_id passed to backend\nhappened to be of admin project. This commit fixes the issues\nby getting the correct tenant_id.\n\nCloses-Bug: 1404688\nChange-Id: Id21c38610ed73defb937d971a7aade57713541c0\n'}, {'number': 2, 'created': '2014-12-22 09:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6746f49e236f18f78692701fd818b2a9e318c2cf', 'message': 'PLUMgrid plugin: Fix for delete subnet with admin context\n\nWhen delete call using admin for a subnet created from a\nnon-admin project is made, the tenant_id passed to backend\nhappened to be of admin project. This commit fixes the issues\nby getting the correct tenant_id.\n\nCloses-Bug: 1404688\nChange-Id: Id21c38610ed73defb937d971a7aade57713541c0\n'}, {'number': 3, 'created': '2014-12-22 09:31:10.000000000', 'files': ['neutron/plugins/plumgrid/plumgrid_plugin/plumgrid_plugin.py', 'neutron/tests/unit/plumgrid/test_plumgrid_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d5e9f06cf34096cd4c68c168086b6f9cc48072c3', 'message': 'PLUMgrid plugin: Fix for delete subnet with admin context\n\nWhen delete call using admin for a subnet created from a\nnon-admin project is made, the tenant_id passed to backend\nhappened to be of admin project. This commit fixes the issues\nby getting the correct tenant_id.\n\nCloses-Bug: 1404688\nChange-Id: Id21c38610ed73defb937d971a7aade57713541c0\n'}]",5,143315,d5e9f06cf34096cd4c68c168086b6f9cc48072c3,58,20,3,8279,,,0,"PLUMgrid plugin: Fix for delete subnet with admin context

When delete call using admin for a subnet created from a
non-admin project is made, the tenant_id passed to backend
happened to be of admin project. This commit fixes the issues
by getting the correct tenant_id.

Closes-Bug: 1404688
Change-Id: Id21c38610ed73defb937d971a7aade57713541c0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/15/143315/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/plumgrid/plumgrid_plugin/plumgrid_plugin.py', 'neutron/tests/unit/plumgrid/test_plumgrid_plugin.py']",2,bb80410bd38309fc85b0aa140b8ff69584f17825,bug/1404688,"from neutron import context def test_subnet_admin_delete(self): plugin = manager.NeutronManager.get_plugin() admin_context = context.get_admin_context() tenant_context = context.Context('', 'not_admin') network1 = self._fake_network('network1') network1_ret = plugin.create_network(tenant_context, network1) subnet1 = self._fake_subnet(network1_ret['id']) subnet1_ret = plugin.create_subnet(tenant_context, subnet1) delete_sub_tenant_id = plugin.delete_subnet(admin_context, subnet1_ret['id']) self.assertEqual(network1_ret['tenant_id'], delete_sub_tenant_id) def _fake_network(self, name): data = {'network': {'name': name, 'admin_state_up': False, 'shared': False, 'router:external': [], 'provider:network_type': None, 'provider:segmentation_id': None, 'provider:physical_network': None}} return data def _fake_subnet(self, net_id): allocation_pools = [{'start': '10.0.0.2', 'end': '10.0.0.254'}] return {'subnet': {'name': net_id, 'network_id': net_id, 'gateway_ip': '10.0.0.1', 'dns_nameservers': ['10.0.0.2'], 'host_routes': [], 'cidr': '10.0.0.0/24', 'allocation_pools': allocation_pools, 'enable_dhcp': True, 'ip_version': 4}} ",,42,1
openstack%2Fceilometer~master~I1ba594784cfca4a2816a0d7caa76a10d8074235d,openstack/ceilometer,master,I1ba594784cfca4a2816a0d7caa76a10d8074235d,Capture network delete events,ABANDONED,2014-05-01 21:49:21.000000000,2014-12-22 19:36:39.000000000,,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6924}, {'_account_id': 8871}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-05-01 21:49:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6f55f05abfe70b5c7a75cb8fd9adab72dff6e9c4', 'message': 'Capture network delete events\n\nCurrently we ignore the network delete events as there\nis not enough payload. A patch has been submitted to\nneutron to include the necessary payload in delete.end\nevent. There is not enough info for delete.start though\nso we still continue to ignore that.\n\nCloses-Bug: #1315166\n\nChange-Id: I1ba594784cfca4a2816a0d7caa76a10d8074235d\n'}, {'number': 2, 'created': '2014-05-02 14:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/41d71dec694b75d758a790c5c1de1114a34b5d8c', 'message': 'Capture network delete events\n\nCurrently we ignore the network delete events as there\nis not enough payload. A patch has been submitted to\nneutron to include the necessary payload in delete.end\nevent. There is not enough info for delete.start though\nso we still continue to ignore that.\n\nCloses-Bug: #1315166\n\nChange-Id: I1ba594784cfca4a2816a0d7caa76a10d8074235d\n'}, {'number': 3, 'created': '2014-05-02 21:46:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9bb42c2e7048745d22be031b832e6355540eebde', 'message': 'Capture network delete events\n\nCurrently we ignore the network delete events as there\nis not enough payload. A patch has been submitted to\nneutron to include the necessary payload in delete.end\nevent. There is not enough info for delete.start though\nso we still continue to ignore that.\n\nCloses-Bug: #1315166\n\nNeutron change: I351e79b741a1b842afc3486c067ce702160a0063\n\nChange-Id: I1ba594784cfca4a2816a0d7caa76a10d8074235d\n'}, {'number': 4, 'created': '2014-06-11 17:25:04.000000000', 'files': ['ceilometer/network/notifications.py', 'ceilometer/tests/network/test_notifications.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/64e8bcbb3cb68a4b1d6fb77b444f36f4a0ea5d82', 'message': 'Capture network delete events\n\nCurrently we ignore the network delete events as there\nis not enough payload. A patch has been submitted to\nneutron to include the necessary payload in delete.end\nevent. There is not enough info for delete.start though\nso we still continue to ignore that.\n\nCloses-Bug: #1315166\n\nNeutron change: I351e79b741a1b842afc3486c067ce702160a0063\n\nChange-Id: I1ba594784cfca4a2816a0d7caa76a10d8074235d\n'}]",1,91686,64e8bcbb3cb68a4b1d6fb77b444f36f4a0ea5d82,30,9,4,6924,,,0,"Capture network delete events

Currently we ignore the network delete events as there
is not enough payload. A patch has been submitted to
neutron to include the necessary payload in delete.end
event. There is not enough info for delete.start though
so we still continue to ignore that.

Closes-Bug: #1315166

Neutron change: I351e79b741a1b842afc3486c067ce702160a0063

Change-Id: I1ba594784cfca4a2816a0d7caa76a10d8074235d
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/86/91686/4 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/network/notifications.py', 'ceilometer/tests/network/test_notifications.py']",2,6f55f05abfe70b5c7a75cb8fd9adab72dff6e9c4,network_delete_events,"NOTIFICATION_NETWORK_DELETE = { u'event_type': u'network.delete.end', u'timestamp': u'2014-05-01 11:11:10.096750', u'_context_tenant_id': u'82ed0c40ebe64d0bb3310027039c8ed2', u'payload': { u'network': { u'id': u'7fd4eb2f-a38e-4c25-8490-71ca8800c9be'}}, u'_context_user_id': u'b44b7ce67fc84414a5c1660a92a1b862', u'publisher_id': u'network.ubuntu-VirtualBox', u'message_id': u'9e839576-cc47-4c60-a7d8-5743681213b1'} NOTIFICATION_SUBNET_DELETE = { u'event_type': u'subnet.delete.end', u'timestamp': u'2014-05-01 11:11:20.096750', u'_context_tenant_id': u'82ed0c40ebe64d0bb3310027039c8ed2', u'payload': { u'subnet': { u'id': u'1a3a170d-d7ce-4cc9-b1db-621da15a25f5'}}, u'_context_user_id': u'b44b7ce67fc84414a5c1660a92a1b862', u'publisher_id': u'network.ubuntu-VirtualBox', u'message_id': u'd86dfc66-d3c3-4aea-b06d-bf37253e6116'} NOTIFICATION_PORT_DELETE = { u'event_type': u'port.delete.end', u'timestamp': u'2014-05-01 11:28:31.536370', u'_context_tenant_id': u'82ed0c40ebe64d0bb3310027039c8ed2', u'payload': { u'port': { u'id': u'9cdfeb92-9391-4da7-95a1-ca214831cfdb',}}, u'_context_user_id': u'b44b7ce67fc84414a5c1660a92a1b862', u'publisher_id': u'network.ubuntu-VirtualBox', u'message_id': u'7135b8ab-e13c-4ac8-bc31-75e7f756622a'} NOTIFICATION_FLOATINGIP_DELETE = { u'event_type': u'floatingip.delete.end', u'timestamp': u'2014-05-01 11:27:27.086575', u'_context_tenant_id': u'82ed0c40ebe64d0bb3310027039c8ed2', u'payload': { u'floatingip': { u'id': u'a68c9390-829e-4732-bad4-e0a978498cc5'}}, u'_context_user_id': u'b44b7ce67fc84414a5c1660a92a1b862', u'publisher_id': u'network.ubuntu-VirtualBox', u'message_id': u'9e839576-cc47-4c60-a7d8-5743681213b1'} def test_network_delete(self): v = notifications.Network(mock.Mock()) samples = list(v.process_notification(NOTIFICATION_NETWORK_DELETE)) self.assertEqual(2, len(samples)) self.assertEqual(""network.delete"", samples[1].name) def test_subnet_delete(self): v = notifications.Subnet(mock.Mock()) samples = list(v.process_notification(NOTIFICATION_SUBNET_DELETE)) self.assertEqual(2, len(samples)) self.assertEqual(""subnet.delete"", samples[1].name) def test_port_delete(self): v = notifications.Port(mock.Mock()) samples = list(v.process_notification(NOTIFICATION_PORT_DELETE)) self.assertEqual(2, len(samples)) self.assertEqual(""port.delete"", samples[1].name) def test_floatingip_delete(self): v = notifications.FloatingIP(mock.Mock()) samples = list(v.process_notification(NOTIFICATION_FLOATINGIP_DELETE)) self.assertEqual(len(samples), 2) self.assertEqual(samples[0].name, ""ip.floating"") ",,75,7
openstack%2Ffuel-main~stable%2F6.0~Ieef687b815e18ff22c7660e41863e1596c352b91,openstack/fuel-main,stable/6.0,Ieef687b815e18ff22c7660e41863e1596c352b91,Remove network settings logging from 'info' channel,MERGED,2014-12-17 18:44:54.000000000,2014-12-22 19:28:14.000000000,2014-12-22 19:28:14.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}]","[{'number': 1, 'created': '2014-12-17 18:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7a4f5fbce534a27f4f9cc4a22e2ede4b549684ab', 'message': 'Move network settings logging to \'debug\' log\n\nWhen we create a cluster with nova-network then FlatDHCP selected\nby default. There is no logs about the fact of later network\nupdates.\n\n- Move ""Network settings for push"" message to \'debug\' log\n- Add ""Update network with new settings"" debug message to\nNailgunClient.update_network() method.\n\nChange-Id: Ieef687b815e18ff22c7660e41863e1596c352b91\nCloses-Bug: #1398071\n'}, {'number': 2, 'created': '2014-12-22 11:45:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6c59b62d7280354ca147d2d9272b016b0ebc9553', 'message': ""Move network settings logging to 'debug' log\n\nWhen we create a cluster with nova-network then FlatDHCP selected\nby default. Latelly the network configuration can be updated but\n'info' log provides inaccurate information.\n\nThis logging is redundant because all necessary information is\nlogged with @logwrap\n\nChange-Id: Ieef687b815e18ff22c7660e41863e1596c352b91\nCloses-Bug: #1398071\n""}, {'number': 3, 'created': '2014-12-22 18:18:19.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/aa24c52ae6cbe7db0d6b58be2288fd15867c796a', 'message': ""Remove network settings logging from 'info' channel\n\nWhen we create a cluster with nova-network then FlatDHCP selected\nby default. Latelly the network configuration can be updated but\n'info' log provides inaccurate information.\n\nThis logging is redundant because all necessary information is\nlogged with @logwrap\n\nChange-Id: Ieef687b815e18ff22c7660e41863e1596c352b91\nCloses-Bug: #1398071\n""}]",3,142535,aa24c52ae6cbe7db0d6b58be2288fd15867c796a,20,7,3,11969,,,0,"Remove network settings logging from 'info' channel

When we create a cluster with nova-network then FlatDHCP selected
by default. Latelly the network configuration can be updated but
'info' log provides inaccurate information.

This logging is redundant because all necessary information is
logged with @logwrap

Change-Id: Ieef687b815e18ff22c7660e41863e1596c352b91
Closes-Bug: #1398071
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/35/142535/3 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/models/nailgun_client.py']",2,7a4f5fbce534a27f4f9cc4a22e2ede4b549684ab,," logger.debug(""Update network with new settings: {}"".format(nc))",,2,1
openstack%2Fopenstack-manuals~stable%2Fjuno~I1a67db2b6aa6a8e2bfd76cc80db1fb09fa353986,openstack/openstack-manuals,stable/juno,I1a67db2b6aa6a8e2bfd76cc80db1fb09fa353986,Fix conflicts with _member_ role creation,MERGED,2014-12-22 17:52:49.000000000,2014-12-22 18:54:46.000000000,2014-12-22 18:54:45.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-22 17:52:49.000000000', 'files': ['doc/install-guide/section_keystone-users.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/311bfdb884a26f75b68d9345036ecb6146b65b32', 'message': ""Fix conflicts with _member_ role creation\n\nHistorically, the installation guide manually created the\ninternal _member_ role to resolve issues with horizon.\nHowever, keystone will preferably create the _member_ role\nautomatically if the 'user-create' command includes the\n'--tenant' option.\n\nChange-Id: I1a67db2b6aa6a8e2bfd76cc80db1fb09fa353986\nCloses-Bug: #1403136\nbackport: juno\n(cherry picked from commit 14e6c86d5a457dbbb90690d55655a4532919255a)\n""}]",0,143509,311bfdb884a26f75b68d9345036ecb6146b65b32,6,2,1,9515,,,0,"Fix conflicts with _member_ role creation

Historically, the installation guide manually created the
internal _member_ role to resolve issues with horizon.
However, keystone will preferably create the _member_ role
automatically if the 'user-create' command includes the
'--tenant' option.

Change-Id: I1a67db2b6aa6a8e2bfd76cc80db1fb09fa353986
Closes-Bug: #1403136
backport: juno
(cherry picked from commit 14e6c86d5a457dbbb90690d55655a4532919255a)
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/09/143509/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_keystone-users.xml'],1,311bfdb884a26f75b68d9345036ecb6146b65b32,juno/backport/143215," <para>OpenStack generates IDs dynamically, so you will see different values from the example command output.</para> <para>Create the <literal>admin</literal> user under the <literal>admin</literal> tenant:</para> <screen><prompt>$</prompt> <userinput>keystone user-create --name admin --tenant admin --pass <replaceable>ADMIN_PASS</replaceable> --email <replaceable>EMAIL_ADDRESS</replaceable></userinput>| tenantId | 6f4c1e4cbfef4d5a8a1345882fbca110 | <para>Add the <literal>admin</literal> role to the <literal>admin</literal> tenant and user:</para> <screen><prompt>$</prompt> <userinput>keystone user-role-add --user admin --tenant admin --role admin</userinput></screen> <para>Create the <literal>demo</literal> user under the <literal>demo</literal> tenant:</para> <screen><prompt>$</prompt> <userinput>keystone user-create --name demo --tenant demo --pass <replaceable>DEMO_PASS</replaceable> --email <replaceable>EMAIL_ADDRESS</replaceable></userinput>| tenantId | 4aa51bb942be4dd0ac0555d7591f80a6 | interact with other services. Each service typically requires creating one or more unique users with the <literal>admin</literal> role under the <literal>service</literal> tenant.</para>"," <para>Because OpenStack generates IDs dynamically, you will see different values from this example command output.</para> <para>Create the <literal>admin</literal> user:</para> <screen><prompt>$</prompt> <userinput>keystone user-create --name admin --pass <replaceable>ADMIN_PASS</replaceable> --email <replaceable>EMAIL_ADDRESS</replaceable></userinput> <para>Add the <literal>admin</literal> tenant and user to the <literal>admin</literal> role:</para> <screen><prompt>$</prompt> <userinput>keystone user-role-add --tenant admin --user admin --role admin</userinput></screen> <note> <para>This command provides no output.</para> </note> </step> <step> <para>By default, the dashboard limits access to users with the <literal>_member_</literal> role.</para> <para>Create the <literal>_member_</literal> role:</para> <screen><prompt>$</prompt> <userinput>keystone role-create --name _member_</userinput> <computeroutput>+----------+----------------------------------+ | Property | Value | +----------+----------------------------------+ | id | 0f198e94ffce416cbcbe344e1843eac8 | | name | _member_ | +----------+----------------------------------+</computeroutput></screen> </step> <step> <para>Add the <literal>admin</literal> tenant and user to the <literal>_member_</literal> role:</para> <screen><prompt>$</prompt> <userinput>keystone user-role-add --tenant admin --user admin --role _member_</userinput></screen> <para>Create the <literal>demo</literal> user:</para> <screen><prompt>$</prompt> <userinput>keystone user-create --name demo --pass <replaceable>DEMO_PASS</replaceable> --email <replaceable>EMAIL_ADDRESS</replaceable></userinput> <step> <para>Add the <literal>demo</literal> tenant and user to the <literal>_member_</literal> role:</para> <screen><prompt>$</prompt> <userinput>keystone user-role-add --tenant demo --user demo --role _member_</userinput></screen> <note> <para>This command provides no output.</para> </note> </step> interact with other services. You will create a user in the <literal>service</literal> tenant for each service that you install.</para>",16,40
openstack%2Fdevstack~stable%2Ficehouse~I2134c7d8f58f8b83f33150c9ed86d87f8ccba2f3,openstack/devstack,stable/icehouse,I2134c7d8f58f8b83f33150c9ed86d87f8ccba2f3,Install prettytable>=0.7 to satisfy pip 6/PEP 440,MERGED,2014-12-22 17:20:00.000000000,2014-12-22 18:45:42.000000000,2014-12-22 18:45:41.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2472}, {'_account_id': 5196}]","[{'number': 1, 'created': '2014-12-22 17:20:00.000000000', 'files': ['tools/fixup_stuff.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7aa7699acb764fd73322f8926eb5e967d71e25b0', 'message': 'Install prettytable>=0.7 to satisfy pip 6/PEP 440\n\nChange-Id: I2134c7d8f58f8b83f33150c9ed86d87f8ccba2f3\n(cherry picked from commit 1a89f8cdf4791350a9aacb41037ab3bdcc9ecc9f)\n'}]",0,143503,7aa7699acb764fd73322f8926eb5e967d71e25b0,8,4,1,5263,,,0,"Install prettytable>=0.7 to satisfy pip 6/PEP 440

Change-Id: I2134c7d8f58f8b83f33150c9ed86d87f8ccba2f3
(cherry picked from commit 1a89f8cdf4791350a9aacb41037ab3bdcc9ecc9f)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/03/143503/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/fixup_stuff.sh'],1,7aa7699acb764fd73322f8926eb5e967d71e25b0,pep-440,pip_install 'prettytable>=0.7',pip_install 'prettytable>0.7',1,1
openstack%2Ffuel-docs~master~I84f4ab991e8cdaac6dea5f63312232e6a6a0936b,openstack/fuel-docs,master,I84f4ab991e8cdaac6dea5f63312232e6a6a0936b,Swift installs only on Controller nodes,MERGED,2014-11-11 03:04:18.000000000,2014-12-22 18:38:58.000000000,2014-12-22 18:38:58.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 12866}]","[{'number': 1, 'created': '2014-11-11 03:04:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/56375ac5e40dbe666a2f298047dced2d0028c256', 'message': 'Swift installs only on Controller nodes\n\nThe Swift docs did not explicitly state that Swift can only\nbe installed on Controller nodes  This is added to the Terminology\narticle and to the list of planning considerations.\n\nCloses-Bug: 1391308\n\nChange-Id: I84f4ab991e8cdaac6dea5f63312232e6a6a0936b\n'}, {'number': 2, 'created': '2014-12-05 23:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/db312addd1cdd70accae8086bd05bd3f3030044c', 'message': 'Swift installs only on Controller nodes\n\nThe Swift docs did not explicitly state that Swift can only\nbe installed on Controller nodes  This is added to the Terminology\narticle and to the list of planning considerations.\n\nCloses-Bug: 1391308\n\nChange-Id: I84f4ab991e8cdaac6dea5f63312232e6a6a0936b\n'}, {'number': 3, 'created': '2014-12-08 09:19:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a0713317948f22d8a67a8d791dd4a9985fb4c19d', 'message': 'Swift installs only on Controller nodes\n\nThe Swift docs did not explicitly state that Swift can only\nbe installed on Controller nodes  This is added to the Terminology\narticle and to the list of planning considerations.\n\nCloses-Bug: 1391308\n\nChange-Id: I84f4ab991e8cdaac6dea5f63312232e6a6a0936b\n'}, {'number': 4, 'created': '2014-12-22 10:25:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/b9da5ae3260a683538932201a32bc7cccdac1d98', 'message': 'Swift installs only on Controller nodes\n\nThe Swift docs did not explicitly state that Swift can only\nbe installed on Controller nodes  This is added to the Terminology\narticle and to the list of planning considerations.\n\nCloses-Bug: 1391308\n\nChange-Id: I84f4ab991e8cdaac6dea5f63312232e6a6a0936b\n'}, {'number': 5, 'created': '2014-12-22 18:11:11.000000000', 'files': ['pages/terminology/g/glance.rst', 'pages/planning-guide/storage/0200-object-storage-for-apps.rst', 'pages/planning-guide/storage/0100-storage-for-images.rst', 'pages/terminology/s/swift-object-storage.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/3d8c583866ab2936e22a23f944cb71ed67cd46bd', 'message': 'Swift installs only on Controller nodes\n\nThe Swift docs did not explicitly state that Swift can only\nbe installed on Controller nodes  This is added to the Terminology\narticle and to the list of planning considerations.\n\nCloses-Bug: 1391308\n\nChange-Id: I84f4ab991e8cdaac6dea5f63312232e6a6a0936b\n'}]",21,133600,3d8c583866ab2936e22a23f944cb71ed67cd46bd,32,7,5,10014,,,0,"Swift installs only on Controller nodes

The Swift docs did not explicitly state that Swift can only
be installed on Controller nodes  This is added to the Terminology
article and to the list of planning considerations.

Closes-Bug: 1391308

Change-Id: I84f4ab991e8cdaac6dea5f63312232e6a6a0936b
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/00/133600/4 && git format-patch -1 --stdout FETCH_HEAD,"['pages/terminology/g/glance.rst', 'pages/planning-guide/storage/0200-object-storage-for-apps.rst', 'pages/planning-guide/storage/0100-storage-for-images.rst', 'pages/terminology/s/swift-object-storage.rst']",4,56375ac5e40dbe666a2f298047dced2d0028c256,bug/1391308,"Fuel can deploy Swift as the storage backend for the :ref:`Glance<glance-term>` image service. Fuel deploys Swift on Controller nodes; it does not provide a separate Swift role that can be installed on other nodes. and its own metadata. * Each object is replicated in the cluster to provide redundancy; or they can write directly to the RESTful API. See :ref:`object-storage-apps-plan`. See: - :ref:`glance-storage-plan` gives planning information, especially how to choose the most appropriate storage backend for Glance. - `Swift documentation <http://swift.openstack.org/>`_ - `OpenStack Swift <https://swiftstack.com/openstack-swift/architecture/>`_ by Joe Arnold and the SwiftStack team, published by O’Reilly, provides a good general introduction to the Swift architecture. ", and its own metadata * Each object is replicated times in the cluster to provide redundancy; or they can write directly to the RESTful API See `Introducing OpenStack Swift <https://swiftstack.com/openstack-swift/architecture/>`_ for a good general introduction to Swift.,49,14
openstack%2Ftraining-guides~master~I4ced02f81c9bbd2d213746b6e05da236e9009168,openstack/training-guides,master,I4ced02f81c9bbd2d213746b6e05da236e9009168,Does required changes for Icehouse release,MERGED,2014-12-09 18:41:31.000000000,2014-12-22 18:26:04.000000000,2014-12-22 18:26:03.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 6923}, {'_account_id': 7007}, {'_account_id': 9178}, {'_account_id': 11109}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-12-09 18:41:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/bb451bdfd8eb15639be0a7f7f49580ebfcd6e12e', 'message': 'Does required changes for Icehouse release\n\nTraining gudies is following in the footsteps of openstack-manuals\nprogram and following the given document for releasing Icehouse\nrelease for training guides.\n\nChange-Id: I4ced02f81c9bbd2d213746b6e05da236e9009168\nLink: https://wiki.openstack.org/wiki/Documentation/Release\n'}, {'number': 2, 'created': '2014-12-10 10:11:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/8c96b506d156be7de7b115d45170eb2a2bc0d797', 'message': 'Does required changes for Icehouse release\n\nTraining gudies is following in the footsteps of openstack-manuals\nprogram and following the given document for releasing Icehouse\nrelease for training guides.\n\nChange-Id: I4ced02f81c9bbd2d213746b6e05da236e9009168\nLink: https://wiki.openstack.org/wiki/Documentation/Release\n'}, {'number': 3, 'created': '2014-12-10 18:44:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/46312aa83c2f0e1ab6a80b01b5268e61e87c4aa7', 'message': 'Does required changes for Icehouse release\n\nTraining guides is following in the footsteps of openstack-manuals\nprogram and following the given document for releasing Icehouse\nrelease for training guides.\n\nChange-Id: I4ced02f81c9bbd2d213746b6e05da236e9009168\nLink: https://wiki.openstack.org/wiki/Documentation/Release'}, {'number': 4, 'created': '2014-12-15 19:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/a9dc2b8a55266ae5f86c4102e3d68c30b0741232', 'message': 'Does required changes for Icehouse release\n\nTraining guides is following in the footsteps of openstack-manuals\nprogram and following the given document for releasing Icehouse\nrelease for training guides.\n\nChange-Id: I4ced02f81c9bbd2d213746b6e05da236e9009168\nLink: https://wiki.openstack.org/wiki/Documentation/Release\n'}, {'number': 5, 'created': '2014-12-17 18:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/d124659eee46c4ad49d24c98af2d2e240e20183e', 'message': 'Does required changes for Icehouse release\n\nTraining guides is following in the footsteps of openstack-manuals\nprogram and following the given document for releasing Icehouse\nrelease for training guides.\n\nChange-Id: I4ced02f81c9bbd2d213746b6e05da236e9009168\nLink: https://wiki.openstack.org/wiki/Documentation/Release\n'}, {'number': 6, 'created': '2014-12-17 21:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/7d38eaaffdc22f080dca62dc50917daf4b4b4962', 'message': 'Does required changes for Icehouse release\n\nTraining guides is following in the footsteps of openstack-manuals\nprogram and following the given document for releasing Icehouse\nrelease for training guides.\n\nChange-Id: I4ced02f81c9bbd2d213746b6e05da236e9009168\nLink: https://wiki.openstack.org/wiki/Documentation/Release\n'}, {'number': 7, 'created': '2014-12-18 10:28:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/6c76172723abb1e2b345ebcbdb86c58011ca1e8b', 'message': 'Does required changes for Icehouse release\n\nTraining guides is following in the footsteps of openstack-manuals\nprogram and following the given document for releasing Icehouse\nrelease for training guides.\n\nChange-Id: I4ced02f81c9bbd2d213746b6e05da236e9009168\nLink: https://wiki.openstack.org/wiki/Documentation/Release\n'}, {'number': 8, 'created': '2014-12-18 13:35:54.000000000', 'files': ['doc/training-guides/st-training-guides.xml'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/dbfe26b2f58b48eec3567deb02ab6d1748dbd067', 'message': 'Does required changes for Icehouse release\n\nTraining guides is following in the footsteps of openstack-manuals\nprogram and following the given document for releasing Icehouse\nrelease for training guides.\n\nChange-Id: I4ced02f81c9bbd2d213746b6e05da236e9009168\nLink: https://wiki.openstack.org/wiki/Documentation/Release\n'}]",6,140428,dbfe26b2f58b48eec3567deb02ab6d1748dbd067,36,8,8,7007,,,0,"Does required changes for Icehouse release

Training guides is following in the footsteps of openstack-manuals
program and following the given document for releasing Icehouse
release for training guides.

Change-Id: I4ced02f81c9bbd2d213746b6e05da236e9009168
Link: https://wiki.openstack.org/wiki/Documentation/Release
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/28/140428/8 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/st-training-guides.xml'],1,bb451bdfd8eb15639be0a7f7f49580ebfcd6e12e,140428, <date>2014-12-2</date> <revdescription> <itemizedlist> <listitem> <para>Icehouse released</para> </listitem> </itemizedlist> </revdescription>,,8,0
openstack%2Ffuel-docs~master~Ie5067c6d2b6e14cb144a9a9579a8ad91808dabbb,openstack/fuel-docs,master,Ie5067c6d2b6e14cb144a9a9579a8ad91808dabbb,6.0 Update instructions,MERGED,2014-12-18 08:03:33.000000000,2014-12-22 18:14:20.000000000,2014-12-22 18:14:20.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8787}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-12-18 08:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/858ceafd6f165a1466fc5724931a524b87755528', 'message': '6.0 Update instructions\n\nMost upgrade information is deleted but I left the header in place\nto avoid build problems.\n\nNote that no changes were made to the ""How Fuel Upgrade Works"" section\n(http://docs.mirantis.com/openstack/fuel/master/reference-architecture.html#how-fuel-upgrade-works).\n\nChange-Id: Ie5067c6d2b6e14cb144a9a9579a8ad91808dabbb\n'}, {'number': 2, 'created': '2014-12-19 01:52:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/75c7e3dfdce876a7bb4d3f6561224334fd308114', 'message': '6.0 Update instructions\n\nMost upgrade information is deleted but I left the header in place\nto avoid build problems.\n\nNote that no changes were made to the ""How Fuel Upgrade Works"" section\n(http://docs.mirantis.com/openstack/fuel/master/reference-architecture.html#how-fuel-upgrade-works).\n\nChange-Id: Ie5067c6d2b6e14cb144a9a9579a8ad91808dabbb\n'}, {'number': 3, 'created': '2014-12-20 02:19:44.000000000', 'files': ['pages/user-guide/8000-upgrade.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/41bf2a1f7bd483028f5c4fdad1c20f97fce93709', 'message': '6.0 Update instructions\n\nMost upgrade information is deleted but I left the header in place\nto avoid build problems.\n\nNote that no changes were made to the ""How Fuel Upgrade Works"" section\n(http://docs.mirantis.com/openstack/fuel/master/reference-architecture.html#how-fuel-upgrade-works).\n\nChange-Id: Ie5067c6d2b6e14cb144a9a9579a8ad91808dabbb\n'}]",22,142698,41bf2a1f7bd483028f5c4fdad1c20f97fce93709,23,7,3,10014,,,0,"6.0 Update instructions

Most upgrade information is deleted but I left the header in place
to avoid build problems.

Note that no changes were made to the ""How Fuel Upgrade Works"" section
(http://docs.mirantis.com/openstack/fuel/master/reference-architecture.html#how-fuel-upgrade-works).

Change-Id: Ie5067c6d2b6e14cb144a9a9579a8ad91808dabbb
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/98/142698/3 && git format-patch -1 --stdout FETCH_HEAD,['pages/user-guide/8000-upgrade.rst'],1,858ceafd6f165a1466fc5724931a524b87755528,upgrade-6.0,"* A **minor update** is applied to an existing environment, enabling it to use a later version of the OpenStack release For example, minor updates were provided for Mirantis OpenStack 5.x releases (Icehouse). No update functionality is provided in Mirantis OpenStack 6.0.to 6.0 from an earlier version of Mirantis OpenStack Release 5.x. After you do this, your new Fuel 6.0 console can manage your existing 5.x.x OpenStack environment(s) and create and manage new 6.0 OpenStack environments.+----------------------+------------------------+--------------------------+ | Initial Fuel version | Fuel is upgraded to | Upgraded Fuel can manage | +======================+========================+==========================+ | 5.0 | 5.1, then to 5.1.1, | 2014.1-5.0 | | | then to 6.0 | | | | | 2014.1.1-5.0.2 | | | | | | | | 2014.1.1-5.1 | | | | | | | | 2014.1.3-5.1.1 | | | | | | | | 2014.2-6.0 | +----------------------+------------------------+--------------------------+ | 5.0 | 5.0.1, then to 5.1, | 2014.1-5.0 | | | | | | | then to 5.1.1 | 2014.1.1-5.0.1 | | | | | | | then to 6.0 | 2014.1.1-5.0.2 | | | | | | | | 2014.1.1-5.1 | | | | | | | | 2014.1.3-5.1.1 | | | | | | | | 2014.2-6.0 | +----------------------+------------------------+--------------------------+ | 5.0.1 | 5.1, then to 5.1.1 | 2014.1.1-5.0.1 | | | | | | | then to 6.0 | 2014.1.1-5.0.2 | | | | | | | | 2014.1.1-5.1 | | | | | | | | 2014.1.3-5.1.1 | | | | | | | | 2014.2-6.0 | +----------------------+------------------------+--------------------------+ | 5.1 | 5.1.1, then to 6.0 | 2014.1.1-5.1 | | | | | | | | 2014.1.3-5.1.1 | | | | | | | | 2014.2-6.0 | +----------------------+------------------------+--------------------------+ `http://software.mirantis.com` New release available: Juno on Ubuntu 12.04.4 (2014.2-6.0) New release available: Juno on CentOS 6.5 (2014.2-6.0)Mirantis OpenStack 6.0 is our first release that is based on the OpenStack Juno release so no update functionality is provided. Update functionality was provided as an :ref:`experimental<experimental-features-term>` feature in 5.x.x releases.","After you upgrade the Fuel Master node version, you can also apply a minor update to your existing environments to apply some of the bug fixes from Mirantis OpenStack 5.1 and to use the latest version of the Icehouse OpenStack release. This is an :ref:`experimental feature<experimental-features-term>` for Fuel 5.1. * You can apply a **minor update** to an existing environment to use a later version of the OpenStack release (Icehouse, in this case) For example, if your environment is running Icehouse 2014.1, you can update it to run 2014.1.1.to 5.1 from an earlier version of Mirantis OpenStack Release 5. After you do this, your new Fuel 5.1 console can manage your existing 5.0 and 5.0.1 OpenStack environment(s) and create and manage new 5.1 OpenStack environments.+----------------------+-------------------------+-----------------------------+ | Initial Fuel version | Fuel is upgraded to | Upgraded Fuel can manage | +======================+=========================+=============================+ | 5.0 | 5.1 | 5.0, 5.1 | +----------------------+-------------------------+-----------------------------+ | 5.0 | 5.0.1, then to 5.1 | 5.0, 5.0.1, 5.1 | +----------------------+-------------------------+-----------------------------+ | 5.0.1 | 5.1 | 5.0.1, 5.1 | +----------------------+-------------------------+-----------------------------+ | 5.1 | N/A | 5.1 | +----------------------+-------------------------+-----------------------------+ `<http://software.mirantis.com>` New release available: Icehouse on Ubuntu 12.04.4 (2014.1.1-5.0.2) New release available: Icehouse on CentOS 6.5 (2014.1.1-5.0.2) New release available: Icehouse on Ubuntu 12.04.4 (2014.1.1-5.1) New release available: Icehouse on CentOS 6.5 (2014.1.1-5.1)When you upgrade your Master Node to Fuel 5.1, you get :ref:`experimental<experimental-features-term>` access to the ability to update existing environments to Mirantis OpenStack 5.0.2. 5.0.2 is a technical release that contains many of the bug fixes that are included in 5.1 but does not include the new 5.1 architecture and features. Because of internal architectural modifications for Fuel 5.1, it is not possible to update from Mirantis OpenStack 5.0.x to 5.1. When applied to a 5.0 environment, 5.0.2 also updates the environment to the 2014.1.1 maintenance release of the OpenStack Icehouse release. To update your existing environments to 5.0.2: - Upgrade the Fuel Master node to Fuel 5.1 as described above. - Enable ""Experimental Features"" if you have not already done so; see :ref:`experimental-features-op` for instructions. - Open an environment that was deployed with Fuel 5.0 or 5.0.1. - Click on the ""Action"" tab. - Select the update package you want. - Fuel prompts you to update the environment to the new level. The update package names are formed by concatenating the OpenStack version number with the Fuel release number. For example, the update package labeled as “2014.1.1-5.0.2” updates your environment to Icehouse 2014.1.1 with Mirantis OpenStack 5.0.2. Note that you can update an Icehouse environment to a later maintenance release, but you cannot update a Havana or earlier environment to be an Icehouse environment. ",60,70
openstack%2Fcinder~master~I32cf9d3774c129cda4449996ceeb4b43b7e42904,openstack/cinder,master,I32cf9d3774c129cda4449996ceeb4b43b7e42904,Catch ImageNotFound exception when deleting rbd volume,MERGED,2014-09-15 22:09:36.000000000,2014-12-22 17:45:00.000000000,2014-12-18 10:48:24.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 6542}, {'_account_id': 7219}, {'_account_id': 7878}, {'_account_id': 8874}, {'_account_id': 9008}, {'_account_id': 9171}, {'_account_id': 9236}, {'_account_id': 9533}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11903}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-09-15 22:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d4dc280638750092704bc38233ed5ab0a6114caa', 'message': 'Catch ImageNotFound exception when deleting rbd volume\n\nWhen deleting a rbd volume it is possible for remove() to\nthrow a ImageNotFound exception. In this case we should\ncatch the exception, so the volume delete can continue.\n\nChange-Id: I32cf9d3774c129cda4449996ceeb4b43b7e42904\n'}, {'number': 2, 'created': '2014-11-20 08:45:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/eccc02fa1a307232a82d5a4ff3414eb46ce00bb0', 'message': 'Catch ImageNotFound exception when deleting rbd volume\n\nWhen deleting a rbd volume it is possible for remove() to\nthrow a ImageNotFound exception. In this case we should\ncatch the exception, so the volume delete can continue.\n\nChange-Id: I32cf9d3774c129cda4449996ceeb4b43b7e42904\n'}, {'number': 3, 'created': '2014-11-21 19:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d521dae33debecb128bbc6e35f4a9af18c46e3e8', 'message': 'Catch ImageNotFound exception when deleting rbd volume\n\nWhen deleting a rbd volume it is possible for remove() to\nthrow a ImageNotFound exception. In this case we should\ncatch the exception, so the volume delete can continue.\n\nChange-Id: I32cf9d3774c129cda4449996ceeb4b43b7e42904\n'}, {'number': 4, 'created': '2014-12-09 20:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0022202a0418b825e599676bbe7a014f4c5f8bfd', 'message': 'Catch ImageNotFound exception when deleting rbd volume\n\nWhen deleting a rbd volume it is possible for remove() to\nthrow a ImageNotFound exception. In this case we should\ncatch the exception, so the volume delete can continue.\n\nChange-Id: I32cf9d3774c129cda4449996ceeb4b43b7e42904\n'}, {'number': 5, 'created': '2014-12-10 20:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/afe4f5d72913cfb6dddd0a782f1334f710ce1590', 'message': 'Catch ImageNotFound exception when deleting rbd volume\n\nWhen deleting a rbd volume it is possible for remove() to\nthrow a ImageNotFound exception. In this case we should\ncatch the exception, so the volume delete can continue.\n\nChange-Id: I32cf9d3774c129cda4449996ceeb4b43b7e42904\n'}, {'number': 6, 'created': '2014-12-10 23:36:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/21e05eeee7cbd52142d6cfbe1f46669a1dd35355', 'message': 'Catch ImageNotFound exception when deleting rbd volume\n\nWhen deleting a rbd volume it is possible for remove() to\nthrow a ImageNotFound exception. In this case we should\ncatch the exception, so the volume delete can continue.\n\nChange-Id: I32cf9d3774c129cda4449996ceeb4b43b7e42904\n'}, {'number': 7, 'created': '2014-12-11 16:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/00845ab2832d388e98dbc9b08a7a4bccd8055f4d', 'message': 'Catch ImageNotFound exception when deleting rbd volume\n\nWhen deleting a rbd volume it is possible for remove() to\nthrow a ImageNotFound exception. In this case we should\ncatch the exception, so the volume delete can continue.\n\nChange-Id: I32cf9d3774c129cda4449996ceeb4b43b7e42904\n'}, {'number': 8, 'created': '2014-12-16 19:07:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e428a4398716b82dcfb43009f2c8051cd2a9225b', 'message': 'Catch ImageNotFound exception when deleting rbd volume\n\nWhen deleting a rbd volume it is possible for remove() to\nthrow a ImageNotFound exception. In this case we should\ncatch the exception, so the volume delete can continue.\n\nCloses-Bug: 1403172\nChange-Id: I32cf9d3774c129cda4449996ceeb4b43b7e42904\n'}, {'number': 9, 'created': '2014-12-17 17:21:42.000000000', 'files': ['cinder/volume/drivers/rbd.py', 'cinder/tests/test_rbd.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ddc8d7a4233aee139f9c91aeee885d7f2e45f8ac', 'message': 'Catch ImageNotFound exception when deleting rbd volume\n\nWhen deleting a rbd volume it is possible for remove() to\nthrow a ImageNotFound exception. In this case we should\ncatch the exception, so the volume delete can continue.\n\nCloses-Bug: 1403172\nChange-Id: I32cf9d3774c129cda4449996ceeb4b43b7e42904\n'}]",22,121688,ddc8d7a4233aee139f9c91aeee885d7f2e45f8ac,96,29,9,7878,,,0,"Catch ImageNotFound exception when deleting rbd volume

When deleting a rbd volume it is possible for remove() to
throw a ImageNotFound exception. In this case we should
catch the exception, so the volume delete can continue.

Closes-Bug: 1403172
Change-Id: I32cf9d3774c129cda4449996ceeb4b43b7e42904
",git fetch https://review.opendev.org/openstack/cinder refs/changes/88/121688/9 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/rbd.py'],1,d4dc280638750092704bc38233ed5ab0a6114caa,," except self.rbd.ImageNotFound: msg = (_(""ImageNotFound error raised while deleting rbd "" ""volume."")) LOG.warn(msg) return",,5,0
openstack%2Foslo.log~master~Ib77e4abb2afdbf805fb14f22033d958e7fe55fe8,openstack/oslo.log,master,Ib77e4abb2afdbf805fb14f22033d958e7fe55fe8,WIP: Just testing for intermittent failures,ABANDONED,2014-12-22 16:51:12.000000000,2014-12-22 17:26:24.000000000,,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-22 16:51:12.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/ff7da4de825c4bc0c2a0c3e1b564048699292217', 'message': 'WIP: Just testing for intermittent failures\n\nChange-Id: Ib77e4abb2afdbf805fb14f22033d958e7fe55fe8\n'}]",0,143493,ff7da4de825c4bc0c2a0c3e1b564048699292217,4,2,1,5638,,,0,"WIP: Just testing for intermittent failures

Change-Id: Ib77e4abb2afdbf805fb14f22033d958e7fe55fe8
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/93/143493/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,ff7da4de825c4bc0c2a0c3e1b564048699292217,,TESTING ,,2,0
openstack%2Fopenstack-ansible~master~Ibe54e19daa7e6d71dbde0f1ac59d86fc31cce7e5,openstack/openstack-ansible,master,Ibe54e19daa7e6d71dbde0f1ac59d86fc31cce7e5,Do not recursively chmod/chown files in container_directories,MERGED,2014-12-19 13:32:43.000000000,2014-12-22 17:13:28.000000000,2014-12-22 17:13:27.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 7353}, {'_account_id': 9820}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-19 13:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/73dce215957297720a402f0887d5cdd364163204', 'message': '[WIP] Do not recursively chmod/chown files in container_directories\n\nCurrently, we recursively chmod/chown files present in the directory\nbeing iterated over in the contain_directories variable.  This is fine\non first run as most of these directories (if not all) do not exist and\nare therefore empty.  However, when the container_common role is\nre-applied, all files within will be altered.  According to\nhttp://docs.ansible.com/file_module.html, non-existent parent\ndirectories will get automatically created when state=directory,\nrecurse=yes is not necessary.  This is presumably why recurse=yes was\noriginally specified.\n\nThis commit also explicitly creates parent directories for two\ndirectories specified in container_directories.  This will ensure that\nthose two directories are created with the right ownership and default\npermission.\n\nChange-Id: Ibe54e19daa7e6d71dbde0f1ac59d86fc31cce7e5\nCloses-Bug: #1403917\n'}, {'number': 2, 'created': '2014-12-19 15:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ee39f3a764a67f038b9bf37b9f426e8f99c26d85', 'message': 'Do not recursively chmod/chown files in container_directories\n\nCurrently, we recursively chmod/chown files present in the directory\nbeing iterated over in the contain_directories variable.  This is fine\non first run as most of these directories (if not all) do not exist and\nare therefore empty.  However, when the container_common role is\nre-applied, all files within will be altered.  According to\nhttp://docs.ansible.com/file_module.html, non-existent parent\ndirectories will get automatically created when state=directory,\nrecurse=yes is not necessary.  This is presumably why recurse=yes was\noriginally specified.\n\nThis commit also explicitly creates parent directories for two\ndirectories specified in container_directories.  This will ensure that\nthose two directories are created with the right ownership and default\npermission.  Lastly, we set some valid ownership/permissions on\n/var/lib/nova/instances.  This was implicitly happening with\nrecurse=yes as the directory gets created in another role prior to\ncontainer_os_setup.yml being run.\n\nChange-Id: Ibe54e19daa7e6d71dbde0f1ac59d86fc31cce7e5\nCloses-Bug: #1403917\n'}, {'number': 3, 'created': '2014-12-19 15:26:39.000000000', 'files': ['rpc_deployment/inventory/group_vars/nova_all.yml', 'rpc_deployment/roles/container_common/tasks/container_os_setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/22c974674aa8c14ac1abef6602a22f9d22ded247', 'message': ""Do not recursively chmod/chown files in container_directories\n\nCurrently, we recursively chmod/chown files present in the directory\nbeing iterated over in the contain_directories variable.  This is fine\non first run as most of these directories (if not all) do not exist and\nare therefore empty.  However, when the container_common role is\nre-applied, all files within will be altered.  According to\nhttp://docs.ansible.com/file_module.html, non-existent parent\ndirectories will get automatically created when state=directory,\nrecurse=yes is not necessary.  This is presumably why recurse=yes was\noriginally specified.\n\nThis commit also explicitly creates /var/lib/nova/cache to ensure it's\ncreated with the right permission/ownership.  Lastly, we set some valid\nownership/permissions on /var/lib/nova/instances.  This was implicitly\nhappening with recurse=yes as the directory gets created in another\nrole prior to container_os_setup.yml being run.\n\nChange-Id: Ibe54e19daa7e6d71dbde0f1ac59d86fc31cce7e5\nCloses-Bug: #1403917\n""}]",0,143083,22c974674aa8c14ac1abef6602a22f9d22ded247,18,7,3,7307,,,0,"Do not recursively chmod/chown files in container_directories

Currently, we recursively chmod/chown files present in the directory
being iterated over in the contain_directories variable.  This is fine
on first run as most of these directories (if not all) do not exist and
are therefore empty.  However, when the container_common role is
re-applied, all files within will be altered.  According to
http://docs.ansible.com/file_module.html, non-existent parent
directories will get automatically created when state=directory,
recurse=yes is not necessary.  This is presumably why recurse=yes was
originally specified.

This commit also explicitly creates /var/lib/nova/cache to ensure it's
created with the right permission/ownership.  Lastly, we set some valid
ownership/permissions on /var/lib/nova/instances.  This was implicitly
happening with recurse=yes as the directory gets created in another
role prior to container_os_setup.yml being run.

Change-Id: Ibe54e19daa7e6d71dbde0f1ac59d86fc31cce7e5
Closes-Bug: #1403917
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/83/143083/2 && git format-patch -1 --stdout FETCH_HEAD,"['rpc_deployment/inventory/group_vars/horizon.yml', 'rpc_deployment/inventory/group_vars/nova_all.yml', 'rpc_deployment/roles/container_common/tasks/container_os_setup.yml']",3,73dce215957297720a402f0887d5cdd364163204,bug/1403917, recurse=no, recurse=true,3,1
openstack%2Ftraining-guides~master~Ic7a2f5547fc4bd5d512da5197e48366c83c21c24,openstack/training-guides,master,Ic7a2f5547fc4bd5d512da5197e48366c83c21c24,labs: force LC_ALL=C for ssh,MERGED,2014-12-10 18:42:06.000000000,2014-12-22 16:51:02.000000000,2014-12-22 16:14:58.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-12-10 18:42:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/93bade373f18e975cc166a9e4e3cc8dfdbaae986', 'message': 'labs: force LC_ALL=C for ssh\n\nMac OS X exports LC_CTYPE=UTF-8 to our ssh environment which makes the\nkeystone install fail (results in a Python traceback complaining about\n""unknown locale: UTF-8"").\n\nThis patch uses LC_ALL=C to override all locale settings.\n\nChange-Id: Ic7a2f5547fc4bd5d512da5197e48366c83c21c24\n'}, {'number': 2, 'created': '2014-12-22 14:18:04.000000000', 'files': ['labs/scripts/config_external_network.sh', 'labs/lib/osbash/functions.host', 'labs/scripts/config_tenant_network.sh'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/cf0aa13715479b90833415c4909663791d59acd5', 'message': 'labs: force LC_ALL=C for ssh\n\nMac OS X exports LC_CTYPE=UTF-8 to our ssh environment which makes the\nkeystone install fail (results in a Python traceback complaining about\n""unknown locale: UTF-8"").\n\nThis patch uses LC_ALL=C to override all locale settings.\n\nThe previous, limited work-arounds for neutron are no longer needed and\nremoved.\n\nChange-Id: Ic7a2f5547fc4bd5d512da5197e48366c83c21c24\n'}]",0,140802,cf0aa13715479b90833415c4909663791d59acd5,20,4,2,11109,,,0,"labs: force LC_ALL=C for ssh

Mac OS X exports LC_CTYPE=UTF-8 to our ssh environment which makes the
keystone install fail (results in a Python traceback complaining about
""unknown locale: UTF-8"").

This patch uses LC_ALL=C to override all locale settings.

The previous, limited work-arounds for neutron are no longer needed and
removed.

Change-Id: Ic7a2f5547fc4bd5d512da5197e48366c83c21c24
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/02/140802/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/lib/osbash/functions.host'],1,93bade373f18e975cc166a9e4e3cc8dfdbaae986,lc_all, LC_ALL=C ssh -q \, ssh -q \,1,1
openstack%2Ftripleo-image-elements~master~I24b04b22e911732ffb9884a15cc45afabc02100a,openstack/tripleo-image-elements,master,I24b04b22e911732ffb9884a15cc45afabc02100a,Add a tempestrunrc for configuring run-tempest,MERGED,2014-12-15 18:18:51.000000000,2014-12-22 16:50:08.000000000,2014-12-22 16:50:07.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 6928}, {'_account_id': 8449}]","[{'number': 1, 'created': '2014-12-15 18:18:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/21f7ad7a330553f09e77ab31a6de01e95637cb0b', 'message': 'Add a tempestrunrc for configuring run-tempest\n\nAdd a tempestrunrc file which is sourced by run-tempest\nto get input settings such as image-name and concurrency.\n\nVariables in tempestrunrc can be via the ExtraConfig of\nthe image where the element is deployed.\n\nChange-Id: I24b04b22e911732ffb9884a15cc45afabc02100a\n'}, {'number': 2, 'created': '2014-12-17 12:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9869610a1a2043f03ab54b0ec2bb39306827b18b', 'message': 'Add a tempestrunrc for configuring run-tempest\n\nAdd a tempestrunrc file which is sourced by run-tempest\nto get input settings such as image-name and concurrency.\n\nVariables in tempestrunrc can be via the ExtraConfig of\nthe image where the element is deployed.\n\nChange-Id: I24b04b22e911732ffb9884a15cc45afabc02100a\n'}, {'number': 3, 'created': '2014-12-22 10:16:15.000000000', 'files': ['elements/tempest/bin/run-tempest', 'elements/tempest/README.md', 'elements/tempest/os-apply-config/etc/tempestrunrc'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/d4e676ec63c542f9d49f10d49076837d322ef156', 'message': 'Add a tempestrunrc for configuring run-tempest\n\nAdd a tempestrunrc file which is sourced by run-tempest\nto get input settings such as image-name and concurrency.\n\nVariables in tempestrunrc can be via the ExtraConfig of\nthe image where the element is deployed.\n\nChange-Id: I24b04b22e911732ffb9884a15cc45afabc02100a\n'}]",7,141871,d4e676ec63c542f9d49f10d49076837d322ef156,21,4,3,1921,,,0,"Add a tempestrunrc for configuring run-tempest

Add a tempestrunrc file which is sourced by run-tempest
to get input settings such as image-name and concurrency.

Variables in tempestrunrc can be via the ExtraConfig of
the image where the element is deployed.

Change-Id: I24b04b22e911732ffb9884a15cc45afabc02100a
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/71/141871/3 && git format-patch -1 --stdout FETCH_HEAD,"['elements/tempest/bin/run-tempest', 'elements/tempest/os-apply-config/etc/tempestrunrc']",2,21f7ad7a330553f09e77ab31a6de01e95637cb0b,tempest_passthrough,{{#tempestrun.concurrency}} # Number of test processes spawned by testr TEMPEST_RUN_CONCURRENCY={{tempestrun.concurrency}} {{/tempestrun.concurrency}} {{#tempestrun.image}} # Name of the test image to be used TEMPEST_IMAGE_NAME={{tempestrun.image}} {{/tempestrun.image}} ,,13,0
openstack%2Ftripleo-image-elements~master~I6c4aa79a0676e2cb651f29249b2ac83ec6d3df0e,openstack/tripleo-image-elements,master,I6c4aa79a0676e2cb651f29249b2ac83ec6d3df0e,Move static settings from run-tempest into conf,MERGED,2014-12-12 16:49:37.000000000,2014-12-22 16:49:32.000000000,2014-12-22 16:49:32.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 6928}, {'_account_id': 8449}]","[{'number': 1, 'created': '2014-12-12 16:49:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/378da2e8f0397d25dc7472643c1f34282f1e9461', 'message': 'Move static settings from run-tempest into conf\n\nThe run-tempest script sets several configuration values to\nstatic settings. With pass-through enabled such settings\nshould be moved instead into the tempest.conf template file.\n\nChange-Id: I6c4aa79a0676e2cb651f29249b2ac83ec6d3df0e\n'}, {'number': 2, 'created': '2014-12-15 18:18:51.000000000', 'files': ['elements/tempest/bin/run-tempest', 'elements/tempest/os-apply-config/opt/stack/tempest/etc/tempest.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9a8100630fc02e4697c8bb7dab0465d754d7ac8f', 'message': 'Move static settings from run-tempest into conf\n\nThe run-tempest script sets several configuration values to\nstatic settings. With pass-through enabled such settings\nshould be moved instead into the tempest.conf template file.\n\nChange-Id: I6c4aa79a0676e2cb651f29249b2ac83ec6d3df0e\n'}]",3,141423,9a8100630fc02e4697c8bb7dab0465d754d7ac8f,20,4,2,1921,,,0,"Move static settings from run-tempest into conf

The run-tempest script sets several configuration values to
static settings. With pass-through enabled such settings
should be moved instead into the tempest.conf template file.

Change-Id: I6c4aa79a0676e2cb651f29249b2ac83ec6d3df0e
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/23/141423/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/tempest/bin/run-tempest', 'elements/tempest/os-apply-config/opt/stack/tempest/etc/tempest.conf']",2,378da2e8f0397d25dc7472643c1f34282f1e9461,tempest_passthrough,[DEFAULT] debug = true use_stderr = false log_file = tempest.log [identity] region = regionOne username = demo_t1 tenant_name = demo_t1 password = secret alt_username = demo_t2 alt_tenant_name = demo_t2 alt_password = secret [compute] flavor_ref_alt = 99 fixed_nextwork_name = default-net [compute-feature-enabled] resize = false [service_available] cinder = false heat = true neutron = true ceilometer = false horizon = false [stress] max_instances = 4 default_thread_number_per_action = 2 [network] tenant_network_cidr = 172.16.0.0/16 ,,35,21
openstack%2Fpython-neutronclient~master~I1c29fbdbd0413b2c58dbf3acf979759aa45123ae,openstack/python-neutronclient,master,I1c29fbdbd0413b2c58dbf3acf979759aa45123ae,Updated from global requirements,MERGED,2014-12-11 07:20:07.000000000,2014-12-22 16:48:53.000000000,2014-12-22 16:48:51.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 7293}]","[{'number': 1, 'created': '2014-12-11 07:20:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/f4f89d3b7e365a57a5c6732f6985af4faebb29d0', 'message': 'Updated from global requirements\n\nChange-Id: I1c29fbdbd0413b2c58dbf3acf979759aa45123ae\n'}, {'number': 2, 'created': '2014-12-16 19:36:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/aaa9338ebe882db3069198cc781e8d65b47bbab3', 'message': 'Updated from global requirements\n\nChange-Id: I1c29fbdbd0413b2c58dbf3acf979759aa45123ae\n'}, {'number': 3, 'created': '2014-12-18 01:28:04.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/4b181cd64c1c14b0eb180665086f9806a09d126b', 'message': 'Updated from global requirements\n\nChange-Id: I1c29fbdbd0413b2c58dbf3acf979759aa45123ae\n'}]",0,140956,4b181cd64c1c14b0eb180665086f9806a09d126b,11,3,3,11131,,,0,"Updated from global requirements

Change-Id: I1c29fbdbd0413b2c58dbf3acf979759aa45123ae
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/56/140956/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f4f89d3b7e365a57a5c6732f6985af4faebb29d0,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Ffuel-main~master~Ibc1e0e2471ccde8beb3a2f50a19014425c5f71e9,openstack/fuel-main,master,Ibc1e0e2471ccde8beb3a2f50a19014425c5f71e9,"Revert ""Add the possibility to work without python virtualenv""",MERGED,2014-12-22 15:36:20.000000000,2014-12-22 16:48:19.000000000,2014-12-22 16:48:19.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8882}, {'_account_id': 8965}, {'_account_id': 8971}, {'_account_id': 9582}]","[{'number': 1, 'created': '2014-12-22 15:36:20.000000000', 'files': ['utils/jenkins/system_tests.sh'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/02b24f42f4ae6e2f8e0074b40575eea932aa8314', 'message': 'Revert ""Add the possibility to work without python virtualenv""\n\nThis reverts commit f5eed8b7fb4d7d800a2f1a64ee985df34297f7b2.\n\nChange-Id: Ibc1e0e2471ccde8beb3a2f50a19014425c5f71e9\n'}]",3,143468,02b24f42f4ae6e2f8e0074b40575eea932aa8314,13,8,1,9977,,,0,"Revert ""Add the possibility to work without python virtualenv""

This reverts commit f5eed8b7fb4d7d800a2f1a64ee985df34297f7b2.

Change-Id: Ibc1e0e2471ccde8beb3a2f50a19014425c5f71e9
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/68/143468/1 && git format-patch -1 --stdout FETCH_HEAD,['utils/jenkins/system_tests.sh'],1,02b24f42f4ae6e2f8e0074b40575eea932aa8314,bug/1377183," if [ -z ""${VENV_PATH}"" ]; then VENV_PATH=""/home/jenkins/venv-nailgun-tests"" fi if [ ""${DRY_RUN}"" = ""yes"" ]; then echo . $VENV_PATH/bin/activate else . $VENV_PATH/bin/activate"," if [ -n ""$VENV_PATH"" ]; then if [ ""${DRY_RUN}"" = ""yes"" ]; then echo source $VENV_PATH/bin/activate else source $VENV_PATH/bin/activate fi",8,6
openstack%2Ftempest~master~Ic647d27c5c4e3bcb8ec0349e31684204e3d0c569,openstack/tempest,master,Ic647d27c5c4e3bcb8ec0349e31684204e3d0c569,DHCP6 Tests fail to remove DVR ports,MERGED,2014-12-18 18:49:38.000000000,2014-12-22 16:48:01.000000000,2014-12-22 16:47:59.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1192}, {'_account_id': 5196}, {'_account_id': 7016}, {'_account_id': 7448}, {'_account_id': 10385}, {'_account_id': 10971}]","[{'number': 1, 'created': '2014-12-18 18:49:38.000000000', 'files': ['tempest/api/network/test_dhcp_ipv6.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/c0514d53e904418b99934ccde66da0f859b6ddbd', 'message': ""DHCP6 Tests fail to remove DVR ports\n\nThe method _clean_network() only removes centralized\nrouter interface ports since it uses only 'network:router_interface'\nas a valid router interface port.\n\nChange-Id: Ic647d27c5c4e3bcb8ec0349e31684204e3d0c569\nCloses-bug: #1403983\n""}]",3,142877,c0514d53e904418b99934ccde66da0f859b6ddbd,17,8,1,10971,,,0,"DHCP6 Tests fail to remove DVR ports

The method _clean_network() only removes centralized
router interface ports since it uses only 'network:router_interface'
as a valid router interface port.

Change-Id: Ic647d27c5c4e3bcb8ec0349e31684204e3d0c569
Closes-bug: #1403983
",git fetch https://review.opendev.org/openstack/tempest refs/changes/77/142877/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/test_dhcp_ipv6.py'],1,c0514d53e904418b99934ccde66da0f859b6ddbd,, if (port['device_owner'].startswith('network:router_interface'), if (port['device_owner'] == 'network:router_interface',1,1
openstack%2Foctavia~master~Iab3558e37e47265220949db10cef4d4bda50028c,openstack/octavia,master,Iab3558e37e47265220949db10cef4d4bda50028c,Add configuration file support for the controller API manager,ABANDONED,2014-12-19 18:03:34.000000000,2014-12-22 16:43:34.000000000,,"[{'_account_id': 3}, {'_account_id': 11685}]","[{'number': 1, 'created': '2014-12-19 18:03:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/8fa028998589bf2911b5163b11df4e885300b6b3', 'message': 'Add configuration file support for the controller\n\nChange-Id: Iab3558e37e47265220949db10cef4d4bda50028c\n'}, {'number': 2, 'created': '2014-12-19 18:27:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/7242b3eb3b96897154af0ea16e06bd276ef2e565', 'message': 'Add configuration file support for the controller\n\nChange-Id: Iab3558e37e47265220949db10cef4d4bda50028c\n'}, {'number': 3, 'created': '2014-12-19 18:46:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/acc20e01dc60fa88f7491e1556e3fecd25d17bc5', 'message': 'Add configuration file support for the controller API manager\n\nChange-Id: Iab3558e37e47265220949db10cef4d4bda50028c\n'}, {'number': 4, 'created': '2014-12-19 18:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d9bbc250943887e5dd18396a5454a236c698876d', 'message': 'Add configuration file support for the controller API manager\n\nChange-Id: Iab3558e37e47265220949db10cef4d4bda50028c\n'}, {'number': 5, 'created': '2014-12-19 19:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/0b1f6b33321bd69e417bb003c06fb085eef66a82', 'message': 'Add configuration file support for the controller API manager\n\nChange-Id: Iab3558e37e47265220949db10cef4d4bda50028c\n'}, {'number': 6, 'created': '2014-12-19 23:48:56.000000000', 'files': ['octavia/common/config.py', 'etc/octavia.conf'], 'web_link': 'https://opendev.org/openstack/octavia/commit/b59815744ed00b454126f90989c551c9587fa423', 'message': 'Add configuration file support for the controller API manager\n\nChange-Id: Iab3558e37e47265220949db10cef4d4bda50028c\n'}]",0,143150,b59815744ed00b454126f90989c551c9587fa423,13,2,6,11628,,,0,"Add configuration file support for the controller API manager

Change-Id: Iab3558e37e47265220949db10cef4d4bda50028c
",git fetch https://review.opendev.org/openstack/octavia refs/changes/50/143150/4 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/controller/etc/controller.conf', 'octavia/controller/load_config.py']",2,8fa028998589bf2911b5163b11df4e885300b6b3,master,"# Copyright 2014 Hewlett-Packard Development Company, L.P. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # from oslo.config import cfg def singleton(cls): instances = {} def getinstance(): if cls not in instances: instances[cls] = cls() return instances[cls] return getinstance @singleton class API-mngr-config: """""" This class loads the Octavia controller API manager configuration. """""" API_mngr_group = cfg.OptionGroup(name='API-manager', title='API Manager Options') API_mngr_opts = [ cfg.StrOpt('AMP-flavor-id', default='', help=_('Nova instance flavor id for the Amphora')), cfg.StrOpt('AMP-image-id', default='', help=_('Glance image id for the Amphora image to boot')), cfg.ListOpt('AMP-key-list', default='', help=_('List of keys to load into the Amphora')), cfg.ListOpt('AMP-network-list', default='', help=_('List of networks to attach to the Amphora')), cfg.ListOpt('AMP-secgroup-list', default='', help=_('List of security groups to attach to the Amphora')) ] def load_API_config(conf=None) """""" Loads the Octavia controller API manager configuration into an oslo configuration object. :param conf: the optional oslo conf object """""" if conf is None: conf = cfg.CONF conf.register_group(API_mngr_group) conf.register_cli_opts(API_mngr_opts, group=API_mngr_group) ",,73,0
openstack%2Fproject-config~master~I43820daa26865fd588dace9300bdc4a3ec455c0c,openstack/project-config,master,I43820daa26865fd588dace9300bdc4a3ec455c0c,Add new Cloud-Pydashie project,MERGED,2014-12-16 22:24:37.000000000,2014-12-22 16:43:00.000000000,2014-12-22 16:42:59.000000000,"[{'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 10420}, {'_account_id': 11809}]","[{'number': 1, 'created': '2014-12-16 22:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5025e021951e5dc5558b945d4a3b22eb20e1eeeb', 'message': ""Add new Openstack-Pydashie project\n\nOpenstack-PyDashie is a monitoring dashboard built on Pydashie\nfor use with Openstack. PyDashie itself being a python port of\nShopify's Dashing. By using a python base we gain access to official\nOpenstack python clients.\n\nChange-Id: I43820daa26865fd588dace9300bdc4a3ec455c0c\n""}, {'number': 2, 'created': '2014-12-16 22:26:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/9452e2df11f911be8cea156edb1e15d74c69e7e7', 'message': ""Add new Openstack-Pydashie project\n\nOpenstack-PyDashie is a monitoring dashboard built on Pydashie\nfor use with Openstack. PyDashie itself being a python port of\nShopify's Dashing. By using a python base we gain access to official\nOpenstack python clients.\n\nChange-Id: I43820daa26865fd588dace9300bdc4a3ec455c0c\n""}, {'number': 3, 'created': '2014-12-17 02:18:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8b1cd3422ab37a14fd00bddae6037f1d4948d90e', 'message': ""Add new Openstack-Pydashie project\n\nOpenstack-PyDashie is a monitoring dashboard built on Pydashie\nfor use with Openstack. PyDashie itself being a python port of\nShopify's Dashing. By using a python base we gain access to official\nOpenstack python clients.\n\nChange-Id: I43820daa26865fd588dace9300bdc4a3ec455c0c\n""}, {'number': 4, 'created': '2014-12-17 21:12:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/bc67dda240c7f958563c5fa109d98ade5db400db', 'message': ""Add new Openstack-Pydashie project\n\nOpenstack-PyDashie is a monitoring dashboard built on Pydashie\nfor use with Openstack. PyDashie itself being a python port of\nShopify's Dashing. By using a python base we gain access to official\nOpenstack python clients.\n\nChange-Id: I43820daa26865fd588dace9300bdc4a3ec455c0c\n""}, {'number': 5, 'created': '2014-12-18 21:27:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/47ab1e5824d9d7eccfea1b10d2b8170b60f7d42a', 'message': ""Add new Cloud-Pydashie project\n\nCloud-PyDashie is a monitoring dashboard built on Pydashie\nfor use with OpenStack. PyDashie itself being a python port of\nShopify's Dashing. By using a python base we gain access to native\nOpenStack python clients.\n\nChange-Id: I43820daa26865fd588dace9300bdc4a3ec455c0c\n""}, {'number': 6, 'created': '2014-12-18 21:46:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7135a18482a2a7f95ab165bd48206f1a2cc5f6b5', 'message': ""Add new Cloud-Pydashie project\n\nCloud-PyDashie is a monitoring dashboard built on Pydashie\nfor use with OpenStack. PyDashie itself being a python port of\nShopify's Dashing. By using a python base we gain access to native\nOpenStack python clients.\n\nChange-Id: I43820daa26865fd588dace9300bdc4a3ec455c0c\n""}, {'number': 7, 'created': '2014-12-18 22:06:32.000000000', 'files': ['gerrit/acls/stackforge/cloud-pydashie.config', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ae681ee4c79bf1d29b427063c8f1fe98600b001e', 'message': ""Add new Cloud-Pydashie project\n\nCloud-PyDashie is a monitoring dashboard built on Pydashie\nfor use with OpenStack. PyDashie itself being a python port of\nShopify's Dashing. By using a python base we gain access to native\nOpenStack python clients.\n\nChange-Id: I43820daa26865fd588dace9300bdc4a3ec455c0c\n""}]",6,142240,ae681ee4c79bf1d29b427063c8f1fe98600b001e,31,7,7,10420,,,0,"Add new Cloud-Pydashie project

Cloud-PyDashie is a monitoring dashboard built on Pydashie
for use with OpenStack. PyDashie itself being a python port of
Shopify's Dashing. By using a python base we gain access to native
OpenStack python clients.

Change-Id: I43820daa26865fd588dace9300bdc4a3ec455c0c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/40/142240/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/stackforge/openstack-pydashie.config', 'gerrit/projects.yaml', 'zuul/layout.yaml']",3,5025e021951e5dc5558b945d4a3b22eb20e1eeeb,new-project, - name: stackforge/openstack-pydashie template: - name: merge-check - name: noop-jobs ,,23,0
openstack%2Fcinder~master~I52211d7b7e1db3454c99d27042dae506adb2c41c,openstack/cinder,master,I52211d7b7e1db3454c99d27042dae506adb2c41c,Rename oslo.concurrency to oslo_concurrency,MERGED,2014-12-20 00:07:04.000000000,2014-12-22 16:19:36.000000000,2014-12-22 16:19:35.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 13868}, {'_account_id': 13900}, {'_account_id': 14206}]","[{'number': 1, 'created': '2014-12-20 00:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/546fbc4ca0f8c2e3925075672291f9806a742547', 'message': 'Rename oslo.concurrency to oslo_concurrency\n\noslo.concurrency-0.3.0 has moved its path to oslo_concurrency,\nthe old path oslo.concurrency can still work but is deprecated now.\n\nCloses-Bug: #1398656\nChange-Id: I52211d7b7e1db3454c99d27042dae506adb2c41c\n'}, {'number': 2, 'created': '2014-12-20 02:40:54.000000000', 'files': ['cinder/service.py', 'cinder/volume/targets/driver.py', 'cinder/volume/drivers/hitachi/hbsd_horcm.py', 'cinder/tests/test_ibmnas.py', 'cinder/brick/iscsi/iscsi.py', 'cinder/tests/test_image_utils.py', 'cinder/tests/zonemanager/test_cisco_fc_zone_driver.py', 'cinder/zonemanager/drivers/cisco/cisco_fc_zone_driver.py', 'cinder/tests/test_ibm_flashsystem.py', 'cinder/volume/drivers/ibm/ibmnas.py', 'cinder/volume/drivers/nfs.py', 'cinder/volume/targets/lio.py', 'cinder/brick/remotefs/remotefs.py', 'cinder/volume/drivers/sheepdog.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/volume/drivers/netapp/dataontap/nfs_base.py', 'cinder/tests/zonemanager/test_brcd_fc_zone_client_cli.py', 'cinder/volume/drivers/coraid.py', 'cinder/volume/drivers/hitachi/hbsd_basiclib.py', 'cinder/volume/drivers/smbfs.py', 'cinder/volume/drivers/netapp/utils.py', 'cinder/volume/drivers/pure.py', 'cinder/tests/fake_utils.py', 'cinder/volume/iscsi.py', 'cinder/tests/test_gpfs.py', 'cinder/tests/test_iscsi.py', 'cinder/tests/test_service.py', 'cinder/tests/test_storwize_svc.py', 'cinder/volume/targets/iscsi.py', 'cinder/volume/utils.py', 'cinder/test.py', 'cinder/tests/test_backup_ceph.py', 'cinder/volume/drivers/ibm/storwize_svc/ssh.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/volume/drivers/fujitsu_eternus_dx_fc.py', 'cinder/tests/test_pure.py', 'cinder/tests/test_srb.py', 'cinder/volume/drivers/hds/nfs.py', 'cinder/brick/initiator/linuxscsi.py', 'cinder/tests/api/contrib/test_admin_actions.py', 'cinder/tests/test_volume_utils.py', 'cinder/tests/brick/test_brick_lvm.py', 'cinder/backup/drivers/tsm.py', 'cinder/tests/test_glusterfs.py', 'cinder/tests/test_quobyte.py', 'cinder/brick/local_dev/lvm.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_driver.py', 'cinder/zonemanager/drivers/cisco/cisco_fc_san_lookup_service.py', 'cinder/volume/drivers/ibm/flashsystem.py', 'cinder/tests/test_backup_tsm.py', 'cinder/volume/drivers/san/san.py', 'cinder/volume/drivers/fujitsu_eternus_dx_iscsi.py', 'cinder/volume/drivers/srb.py', 'cinder/volume/targets/tgt.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py', 'cinder/volume/drivers/san/hp/hp_lefthand_cliq_proxy.py', 'cinder/brick/initiator/linuxfc.py', 'cinder/tests/test_emc_vnxdirect.py', 'cinder/tests/volume/drivers/netapp/test_utils.py', 'cinder/tests/zonemanager/test_cisco_fc_zone_client_cli.py', 'cinder/volume/drivers/lvm.py', 'cinder/tests/brick/test_brick_connector.py', 'cinder/volume/drivers/ibm/gpfs.py', 'cinder/tests/test_utils.py', 'cinder/brick/initiator/connector.py', 'cinder/volume/drivers/eqlx.py', 'cinder/volume/drivers/quobyte.py', 'cinder/tests/test_eqlx.py', 'cinder/tests/test_sheepdog.py', 'cinder/brick/executor.py', 'cinder/volume/driver.py', 'cinder/zonemanager/drivers/cisco/cisco_fc_zone_client_cli.py', 'cinder/image/image_utils.py', 'cinder/utils.py', 'cinder/volume/drivers/remotefs.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_client_cli.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8ddcf590b98182eaf7dcfc46f1d8d5b888d2eac9', 'message': 'Rename oslo.concurrency to oslo_concurrency\n\noslo.concurrency-0.3.0 has moved its path to oslo_concurrency,\nthe old path oslo.concurrency can still work but is deprecated now.\n\nCloses-Bug: #1398656\nChange-Id: I52211d7b7e1db3454c99d27042dae506adb2c41c\n'}]",0,143222,8ddcf590b98182eaf7dcfc46f1d8d5b888d2eac9,28,14,2,170,,,0,"Rename oslo.concurrency to oslo_concurrency

oslo.concurrency-0.3.0 has moved its path to oslo_concurrency,
the old path oslo.concurrency can still work but is deprecated now.

Closes-Bug: #1398656
Change-Id: I52211d7b7e1db3454c99d27042dae506adb2c41c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/22/143222/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/service.py', 'cinder/volume/targets/driver.py', 'cinder/volume/drivers/hitachi/hbsd_horcm.py', 'cinder/tests/test_ibmnas.py', 'cinder/brick/iscsi/iscsi.py', 'cinder/tests/test_image_utils.py', 'cinder/tests/zonemanager/test_cisco_fc_zone_driver.py', 'cinder/zonemanager/drivers/cisco/cisco_fc_zone_driver.py', 'cinder/tests/test_ibm_flashsystem.py', 'cinder/volume/drivers/ibm/ibmnas.py', 'cinder/volume/drivers/nfs.py', 'cinder/volume/targets/lio.py', 'cinder/brick/remotefs/remotefs.py', 'cinder/volume/drivers/sheepdog.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/volume/drivers/netapp/dataontap/nfs_base.py', 'cinder/tests/zonemanager/test_brcd_fc_zone_client_cli.py', 'cinder/volume/drivers/coraid.py', 'cinder/volume/drivers/hitachi/hbsd_basiclib.py', 'cinder/volume/drivers/smbfs.py', 'cinder/volume/drivers/netapp/utils.py', 'cinder/volume/drivers/pure.py', 'cinder/tests/fake_utils.py', 'cinder/volume/iscsi.py', 'cinder/tests/test_gpfs.py', 'cinder/tests/test_iscsi.py', 'cinder/tests/test_service.py', 'cinder/tests/test_storwize_svc.py', 'cinder/volume/targets/iscsi.py', 'cinder/volume/utils.py', 'cinder/test.py', 'cinder/tests/test_backup_ceph.py', 'cinder/volume/drivers/ibm/storwize_svc/ssh.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/volume/drivers/fujitsu_eternus_dx_fc.py', 'cinder/tests/test_pure.py', 'cinder/tests/test_srb.py', 'cinder/volume/drivers/hds/nfs.py', 'cinder/brick/initiator/linuxscsi.py', 'cinder/tests/api/contrib/test_admin_actions.py', 'cinder/tests/test_volume_utils.py', 'cinder/tests/brick/test_brick_lvm.py', 'cinder/backup/drivers/tsm.py', 'cinder/tests/test_glusterfs.py', 'cinder/tests/test_quobyte.py', 'cinder/brick/local_dev/lvm.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_driver.py', 'cinder/zonemanager/drivers/cisco/cisco_fc_san_lookup_service.py', 'cinder/volume/drivers/ibm/flashsystem.py', 'cinder/tests/test_backup_tsm.py', 'cinder/volume/drivers/san/san.py', 'cinder/volume/drivers/fujitsu_eternus_dx_iscsi.py', 'cinder/volume/drivers/srb.py', 'cinder/volume/targets/tgt.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py', 'cinder/volume/drivers/san/hp/hp_lefthand_cliq_proxy.py', 'cinder/brick/initiator/linuxfc.py', 'cinder/tests/test_emc_vnxdirect.py', 'cinder/tests/volume/drivers/netapp/test_utils.py', 'cinder/tests/zonemanager/test_cisco_fc_zone_client_cli.py', 'cinder/volume/drivers/lvm.py', 'cinder/tests/brick/test_brick_connector.py', 'cinder/volume/drivers/ibm/gpfs.py', 'cinder/tests/test_utils.py', 'cinder/brick/initiator/connector.py', 'cinder/volume/drivers/eqlx.py', 'cinder/volume/drivers/quobyte.py', 'cinder/tests/test_eqlx.py', 'cinder/tests/test_sheepdog.py', 'cinder/brick/executor.py', 'cinder/volume/driver.py', 'cinder/zonemanager/drivers/cisco/cisco_fc_zone_client_cli.py', 'cinder/image/image_utils.py', 'cinder/utils.py', 'cinder/volume/drivers/remotefs.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_client_cli.py']",76,546fbc4ca0f8c2e3925075672291f9806a742547,bug/1398656,from oslo_concurrency import processutils,from oslo.concurrency import processutils,88,88
openstack%2Foslo-specs~master~I68523bd62f561c00e6875985281856f9a8ac539b,openstack/oslo-specs,master,I68523bd62f561c00e6875985281856f9a8ac539b,Add debtcollector adoption,MERGED,2014-12-11 23:58:25.000000000,2014-12-22 16:15:59.000000000,2014-12-22 16:15:58.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 5638}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-12-11 23:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/f347f2596fbe66fb28d94760db6e27774d1837e6', 'message': 'Add debtcollector adoption\n\nChange-Id: I68523bd62f561c00e6875985281856f9a8ac539b\n'}, {'number': 2, 'created': '2014-12-12 00:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/879d42a8b5ba6222035d5dfcd7abf7bceb2fe43e', 'message': 'Add debtcollector adoption\n\nChange-Id: I68523bd62f561c00e6875985281856f9a8ac539b\n'}, {'number': 3, 'created': '2014-12-12 00:10:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/83e8427b94295c120eb68820014054a59efac9a7', 'message': 'Add debtcollector adoption\n\nChange-Id: I68523bd62f561c00e6875985281856f9a8ac539b\n'}, {'number': 4, 'created': '2014-12-12 00:11:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/e5e24d9c0e077c1ef6473a36e223c6182c958588', 'message': 'Add debtcollector adoption\n\nChange-Id: I68523bd62f561c00e6875985281856f9a8ac539b\n'}, {'number': 5, 'created': '2014-12-12 01:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/187e2d94452ae045b2e1aaaca8322aaa12b0be58', 'message': 'Add debtcollector adoption\n\nChange-Id: I68523bd62f561c00e6875985281856f9a8ac539b\n'}, {'number': 6, 'created': '2014-12-12 18:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/c8405cae418d462cdfcb3dabeae5098f5639404e', 'message': 'Add debtcollector adoption\n\nChange-Id: I68523bd62f561c00e6875985281856f9a8ac539b\n'}, {'number': 7, 'created': '2014-12-12 19:56:02.000000000', 'files': ['specs/kilo/adopt-debtcollector.rst'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/7b5a155e8de7d8aace47b61e47e19dba9d6cac37', 'message': 'Add debtcollector adoption\n\nChange-Id: I68523bd62f561c00e6875985281856f9a8ac539b\n'}]",14,141220,7b5a155e8de7d8aace47b61e47e19dba9d6cac37,25,8,7,1297,,,0,"Add debtcollector adoption

Change-Id: I68523bd62f561c00e6875985281856f9a8ac539b
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/20/141220/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/adopt-debtcollector.rst'],1,f347f2596fbe66fb28d94760db6e27774d1837e6,,".. =========================== Graduating debtcollector =========================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/taskflow/+spec/adopt-debtcollector The idea for this library is to provide a common set of reusable and understandable, well documented patterns that can be used to remove debt in a project (without forcing that project to completly break backward compatability in a single release). For example the following patterns could be considered common: * Deprecating a keyword argument to be later replaced with a replacement keyword argument (useful when a new name was later determined to be better than an initial name). * Altering the name of a property to refer to a new and improved name (useful when say a property name is discovered after a certain amount of time to make more sense than an initial property name). * Moving a class (with or without breaking those who are inheriting from your old location); this is useful when a class is better located at a different (potentially better named, more meaningfully named) module than it was initially placed at (this is common when the initial location was thought of to be a good location, but after usage a alternative location would make more sense). * ... Library Name ============ What is the name of the new library?: *debtcollector* Contents ======== * ``debtcollector/__init__.py`` * ``debtcollector/utils.py`` (internal utils, not for public usage) * ``debtcollector/moves.py`` (for patterns common to moving code/classes/properties...) * ``debtcollector/renames.py`` (for patterns common to renaming code/classes/properties...) * ... (others as patterns emerge) Early Adopters ============== * Taskflow * Others? Public API ========== Current idea for API (will likely evolve as new patterns appear...) * ``debtcollector/moves.py`` :: # Patterns devoted to 'moving' functions, methods, classes, arguments... def moved_decorator(kind, new_attribute_name, message=None, version=None, removal_version=None, stacklevel=3) # Creates a decorator of the given kind for the given attribute name # with the provided message, version deprecated in, the version it will # be removed in and the given stacklevel (used to output the users code # location when this decorator is called). # # An example message: >>> kind = 'Property' >>> new_attribute_name = 'a' >>> what = ""%s '%s' has moved to '%s"" % (kind, 'b', new_attribute_name) >>> deprecation._generate_moved_message(what, message='sorry its going away', version='0.1', removal_version='0.2') ""Property 'a' has moved to 'b' in version '0.1' and will be removed in version '0.2': sorry its going away"" def moved_property(new_attribute_name, message=None, version=None, removal_version=None, stacklevel=3): # Decorator specialization of moved_decorator that sets the kind to # a property instead of allowing it to be specified. def moved_class(new_class, old_class_name, old_module_name, message=None, version=None, removal_version=None, stacklevel=3): # Same as moved_decorator but for classes, returns a class proxy that can # not be inherited from (useful for when the user of this is aware that no # inheritance is happening) def moved_class_inheritable(new_class, old_class_name, old_module_name, message=None, version=None, removal_version=None, stacklevel=3): # Same as moved_class but for classes, returns a new-old class that can # be inherited from (useful for when the user of this is unaware if any # inheritance is happening) * ``debtcollector/renames.py`` :: # Patterns devoted to 'renaming' functions, methods, classes, arguments... def renamed_kwarg(old_name, new_name, message=None, version=None, removal_version=None, stacklevel=3): # Creates a decorator that can be applied to a keyword argument accepting # method, function, callable that will warn the user of that function # when they are using the old, to be removed keyword argument; creates # an appropriate message telling the user this (in a similar format # as mentioned above). * ``debtcollector/utils.py`` :: # Generic *internal* library used utils... def generate_message(prefix, postfix=None, message=None, version=None, removal_version=None): # Generates the messages for renames or moves in a common (share as much # as possible manner) so that the messages look and feel like they are # coming from a common library Implementation ============== Assignee(s) ----------- Primary assignee: harlowja Primary Maintainer ------------------ Primary Maintainer: harlowja Security Contact ---------------- Security Contact: harlowja Milestones ---------- Target Milestone for completion: kilo-X (?) Work Items ---------- * Change owner of Launchpad project * https://launchpad.net/debtcollector * Give openstackci Owner permissions on PyPI * Create Initial Repository * Make the library do something * Update the README.rst * Publish git repo * Oslo team review new repository * Infra project configuration * Update Gerrit Groups and ACLs * openstack-infra/devstack-gate adjustments * openstack/requirements projects.txt adjustments * Update project list on docs.openstack.org * Tag a release * Profit! Adoption Notes ============== N/A Dependencies ============ Requirements ------------ * python 2.6 (or 2.7?) * wrapt (http://wrapt.readthedocs.org) * six (https://bitbucket.org/gutworth/six) .. note:: All of the currently planned depedencides are in the requirements repository. References ========== ML: http://lists.openstack.org/pipermail/openstack-dev/2014-December/052692.html .. note:: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ",,202,0
openstack%2Fhorizon~master~I341adb3a581337790e22e049e5b72df11b462b44,openstack/horizon,master,I341adb3a581337790e22e049e5b72df11b462b44,Replace set_id_as_name_if_empty with name_or_id,MERGED,2014-09-18 09:28:15.000000000,2014-12-22 16:14:48.000000000,2014-12-22 16:14:46.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 4428}, {'_account_id': 4978}, {'_account_id': 6610}, {'_account_id': 11599}, {'_account_id': 13325}, {'_account_id': 14124}]","[{'number': 1, 'created': '2014-09-18 09:28:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/07771dda8ac422e17be6af4ce1e8f6b0daf9408c', 'message': 'Move set_id_as_name_if_empty to api side for rule/firewall/policy_list\n\nwe can move set_id_as_name_if_empty to the api loop for\nrule_list, firewall_list and policy_list to reduce a extra loop\ncall since set_id_as_name_if_empty is called every after *_list.\n\nChange-Id: I341adb3a581337790e22e049e5b72df11b462b44\nCloses-bug: #1370986\n'}, {'number': 2, 'created': '2014-09-19 01:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e4c0b6cd0dce7d5481787bfe6788ed25d6a77c05', 'message': 'Move set_id_as_name_if_empty to api side for rule/firewall/policy_list\n\nwe can move set_id_as_name_if_empty to the api loop for\nrule_list, firewall_list and policy_list to reduce a extra loop\ncall since set_id_as_name_if_empty is called every after *_list.\n\nChange-Id: I341adb3a581337790e22e049e5b72df11b462b44\nCloses-bug: #1370986\n'}, {'number': 3, 'created': '2014-11-24 08:57:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ff7c1b01e6e9c9c46db20c9d7a8f1a4f7e338a99', 'message': 'Replace set_id_as_name_if_empty with name_or_id\n\nwe can replace set_id_as_name_if_empty with name_or_id for\nrule_list/get, firewall_list/get and policy_list/get to\nreduce a extra loop call since set_id_as_name_if_empty is\ncalled every after *_list.\n\nChange-Id: I341adb3a581337790e22e049e5b72df11b462b44\nCloses-bug: #1370986\n'}, {'number': 4, 'created': '2014-11-24 13:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4b8ad29ab1496f2940a260865cb8c4b386fe40b2', 'message': 'Replace set_id_as_name_if_empty with name_or_id\n\nwe can replace set_id_as_name_if_empty with name_or_id for\nrule_list/get, firewall_list/get and policy_list/get to\nreduce a extra loop call since set_id_as_name_if_empty is\ncalled every after *_list.\n\nChange-Id: I341adb3a581337790e22e049e5b72df11b462b44\nCloses-bug: #1370986\n'}, {'number': 5, 'created': '2014-12-08 01:07:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/011a71d852da93d74cc311903257c6d382534232', 'message': 'Replace set_id_as_name_if_empty with name_or_id\n\nwe can replace set_id_as_name_if_empty with name_or_id for\nrule_list/get, firewall_list/get and policy_list/get to\nreduce a extra loop call since set_id_as_name_if_empty is\ncalled every after *_list.\n\nChange-Id: I341adb3a581337790e22e049e5b72df11b462b44\nCloses-bug: #1370986\n'}, {'number': 6, 'created': '2014-12-08 12:26:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4aa537ecf5acf2f90f0d4ae1a73d87fabcf0d91f', 'message': 'Replace set_id_as_name_if_empty with name_or_id\n\nwe can replace set_id_as_name_if_empty with name_or_id in\nin all neutron related place to reduce a extra loop call\nsince set_id_as_name_if_empty is called every after *_list.\n\nChange-Id: I341adb3a581337790e22e049e5b72df11b462b44\nCloses-bug: #1370986\n'}, {'number': 7, 'created': '2014-12-09 02:01:47.000000000', 'files': ['openstack_dashboard/dashboards/admin/routers/views.py', 'openstack_dashboard/dashboards/project/data_processing/clusters/tabs.py', 'openstack_dashboard/dashboards/project/databases/workflows/create_instance.py', 'openstack_dashboard/dashboards/project/networks/ports/tables.py', 'openstack_dashboard/dashboards/project/networks/tables.py', 'openstack_dashboard/dashboards/project/vpn/tabs.py', 'openstack_dashboard/dashboards/admin/networks/tables.py', 'openstack_dashboard/dashboards/project/firewalls/forms.py', 'openstack_dashboard/dashboards/project/routers/views.py', 'openstack_dashboard/dashboards/project/firewalls/tabs.py', 'openstack_dashboard/dashboards/project/firewalls/workflows.py', 'openstack_dashboard/dashboards/project/networks/subnets/views.py', 'openstack_dashboard/dashboards/admin/networks/subnets/tables.py', 'openstack_dashboard/dashboards/project/instances/workflows/create_instance.py', 'openstack_dashboard/dashboards/project/vpn/tables.py', 'openstack_dashboard/dashboards/project/routers/tabs.py', 'openstack_dashboard/dashboards/project/loadbalancers/tabs.py', 'openstack_dashboard/dashboards/project/data_processing/utils/neutron_support.py', 'openstack_dashboard/dashboards/admin/networks/ports/tables.py', 'openstack_dashboard/dashboards/project/networks/subnets/tables.py', 'openstack_dashboard/dashboards/project/firewalls/views.py', 'openstack_dashboard/dashboards/project/networks/views.py', 'openstack_dashboard/dashboards/project/networks/workflows.py', 'openstack_dashboard/dashboards/project/routers/extensions/routerrules/tabs.py', 'openstack_dashboard/dashboards/project/firewalls/tables.py', 'openstack_dashboard/dashboards/project/loadbalancers/tables.py', 'openstack_dashboard/dashboards/admin/networks/views.py', 'openstack_dashboard/dashboards/project/routers/ports/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/403b81db29aa7e6ac64f446cccce0030f1937a9b', 'message': 'Replace set_id_as_name_if_empty with name_or_id\n\nwe can replace set_id_as_name_if_empty with name_or_id in\nin all neutron related place to reduce a extra loop call\nsince set_id_as_name_if_empty is called every after *_list.\n\nChange-Id: I341adb3a581337790e22e049e5b72df11b462b44\nCloses-bug: #1370986\n'}]",11,122372,403b81db29aa7e6ac64f446cccce0030f1937a9b,32,10,7,4428,,,0,"Replace set_id_as_name_if_empty with name_or_id

we can replace set_id_as_name_if_empty with name_or_id in
in all neutron related place to reduce a extra loop call
since set_id_as_name_if_empty is called every after *_list.

Change-Id: I341adb3a581337790e22e049e5b72df11b462b44
Closes-bug: #1370986
",git fetch https://review.opendev.org/openstack/horizon refs/changes/72/122372/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/firewalls/workflows.py', 'openstack_dashboard/api/fwaas.py', 'openstack_dashboard/dashboards/project/firewalls/forms.py', 'openstack_dashboard/dashboards/project/firewalls/tabs.py']",4,07771dda8ac422e17be6af4ce1e8f6b0daf9408c,move-set_id_as_name_if_empty,, for r in rules: r.set_id_as_name_if_empty() for p in policies: p.set_id_as_name_if_empty() for f in firewalls: f.set_id_as_name_if_empty() ,18,18
openstack%2Frally~master~Ib7df62278e1121c457468467e04012a58411cf1d,openstack/rally,master,Ib7df62278e1121c457468467e04012a58411cf1d,DataBase: Delete BigText class,MERGED,2014-12-19 16:35:31.000000000,2014-12-22 16:11:50.000000000,2014-12-22 16:11:50.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 9545}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-19 16:35:31.000000000', 'files': ['rally/db/sqlalchemy/types.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/ee4aa314cabd955dabf36748e03340d2275ba4c6', 'message': 'DataBase: Delete BigText class\n\nPython 34 env failed with:\n  > ...\n  > TypeError: Cannot create a consistent method resolution\n  > order (MRO) for bases TDComparator, Comparator\n\nFull traceback: http://paste.openstack.org/show/151305/\n\nThis patch fixes this issue.\n\nChange-Id: Ib7df62278e1121c457468467e04012a58411cf1d\n'}]",0,143133,ee4aa314cabd955dabf36748e03340d2275ba4c6,10,5,1,9545,,,0,"DataBase: Delete BigText class

Python 34 env failed with:
  > ...
  > TypeError: Cannot create a consistent method resolution
  > order (MRO) for bases TDComparator, Comparator

Full traceback: http://paste.openstack.org/show/151305/

This patch fixes this issue.

Change-Id: Ib7df62278e1121c457468467e04012a58411cf1d
",git fetch https://review.opendev.org/openstack/rally refs/changes/33/143133/1 && git format-patch -1 --stdout FETCH_HEAD,['rally/db/sqlalchemy/types.py'],1,ee4aa314cabd955dabf36748e03340d2275ba4c6,db,"class JSONEncodedDict(sa_types.TypeDecorator): """"""Represents an immutable structure as a json-encoded string."""""" """"""Represents an immutable structure as a json-encoded string. MySql can store only 64kb in Text type, and for example in psql or sqlite we are able to store more then 1GB. In some cases, like storing results of task 64kb is not enough. So this type uses for MySql LONGTEXT that allows us to store 4GiB. """""" def load_dialect_impl(self, dialect): if dialect.name == ""mysql"": return dialect.type_descriptor(mysql_types.LONGTEXT) else: return dialect.type_descriptor(sa_types.Text) """"""Convert plain dictionaries to MutableDict.""""""","class BigText(sa_types.TypeDecorator): """"""An SQLAlchemy type that uses bigger text type in mysql. MySql can store only 64kb in Text type, and for example in psql or sqlite we are able to store more then 1GB. In some cases, like storing results of task 64kb is not enough. So this type uses for MySql LONGTEXT that allows us to store 4GiB. """""" impl = sa_types.Text def load_dialect_impl(self, dialect): if dialect.name == 'mysql': return dialect.type_descriptor(mysql_types.LONGTEXT) else: return dialect.type_descriptor(sa_types.Text) class JSONEncodedDict(sa_types.TypeDecorator): ""Represents an immutable structure as a json-encoded string."" ""Represents an immutable structure as a json-encoded string."" impl = BigText ""Convert plain dictionaries to MutableDict.""",15,22
openstack%2Fkeystone-specs~master~Id74e4cee91884dd65bad7d177713d45aa6a45557,openstack/keystone-specs,master,Id74e4cee91884dd65bad7d177713d45aa6a45557,Trust redelegation documentation,MERGED,2014-10-28 19:36:33.000000000,2014-12-22 16:07:52.000000000,2014-12-22 16:07:51.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 4328}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6534}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 13055}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-10-28 19:36:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/4472d3daa1b547a97d4e6159c00a7220320a124e', 'message': 'Trust redelegation documentation\n\nAuthor: Alexander Makarov <amakarov@mirantis.com>\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 2, 'created': '2014-10-28 19:56:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/f59dafb7f0c0a28ca9407d777cd8598781d06577', 'message': 'Trust redelegation documentation\n\nAuthor: Alexander Makarov <amakarov@mirantis.com>\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 3, 'created': '2014-11-11 17:39:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/2c126d983e8778fcde0a63baf120e243f58f628a', 'message': 'Trust redelegation documentation\n\nAuthor: Alexander Makarov <amakarov@mirantis.com>\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 4, 'created': '2014-11-11 18:16:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/3a86c7a05a1fd25f88320c61d29adc36f30b63ca', 'message': 'Trust redelegation documentation\n\nAuthor: Alexander Makarov <amakarov@mirantis.com>\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 5, 'created': '2014-11-12 18:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/7d80e6d94b45866105566159e519e9afb8b1efc9', 'message': 'Trust redelegation documentation\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 6, 'created': '2014-11-19 16:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/d0dcf014377292eefe4a7f40ab7cdda55fcd2fd9', 'message': 'Trust redelegation documentation\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 7, 'created': '2014-11-25 16:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/34e111d23162f0fdf00a3eef61efc1261d99501c', 'message': 'Trust redelegation documentation\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 8, 'created': '2014-11-25 17:13:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/9e0680c40c76502573db20a0b1be8b67a15722d2', 'message': 'Trust redelegation documentation\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 9, 'created': '2014-11-26 18:44:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/e4c12e4648e842e07749f0ab9e55c3b9daf93a5f', 'message': 'Trust redelegation documentation\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 10, 'created': '2014-11-26 18:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/8f0704afcd67cfc5dd3b02110045b9c67a8f054d', 'message': 'Trust redelegation documentation\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 11, 'created': '2014-11-27 16:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/fc09dd95f99f69253da65cf104c3ece45213c0d9', 'message': 'Trust redelegation documentation\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 12, 'created': '2014-12-02 15:30:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/793afe62f42a254c895ffed0726d16e8e40aef40', 'message': 'Trust redelegation documentation\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 13, 'created': '2014-12-03 12:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/4036be30551c767473fae37f328b15b63b901a2d', 'message': 'Trust redelegation documentation\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 14, 'created': '2014-12-09 16:31:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/0c26576b896c3974067526bf13b6625750ce35ee', 'message': 'Trust redelegation documentation\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 15, 'created': '2014-12-09 17:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/fd86f4e7e0ede2d63aac274a9719b8a4c0dc8381', 'message': 'Trust redelegation documentation\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 16, 'created': '2014-12-09 18:24:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/af54b8499a759c55600019608dffd9bcea1ff8b7', 'message': 'Trust redelegation documentation\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 17, 'created': '2014-12-18 15:29:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/f28cf8208e5af8d227bc78fe5a9ca7230b64decd', 'message': 'Trust redelegation documentation\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 18, 'created': '2014-12-18 15:32:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/e586146a1f9b381a3fd0c479515e20bf42e2e436', 'message': 'Trust redelegation documentation\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}, {'number': 19, 'created': '2014-12-18 15:53:55.000000000', 'files': ['api/v3/identity-api-v3-os-trust-ext.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/9281df6ed8f029c29c54199596d8a436d70173cb', 'message': 'Trust redelegation documentation\n\nAdd trust redelegation related fields description to documentation.\n\nImplements bp trusts-redelegation\n\nChange-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557\n'}]",59,131541,9281df6ed8f029c29c54199596d8a436d70173cb,61,16,19,13055,,,0,"Trust redelegation documentation

Add trust redelegation related fields description to documentation.

Implements bp trusts-redelegation

Change-Id: Id74e4cee91884dd65bad7d177713d45aa6a45557
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/41/131541/5 && git format-patch -1 --stdout FETCH_HEAD,['api/v3/identity-api-v3-os-trust-ext.rst'],1,4472d3daa1b547a97d4e6159c00a7220320a124e,bp/trusts-redelegation,"- ``trustee_user_id`` (string):``project_id`` attribute. In case of redelegation (when trust-scoped token is used and consumed trust has ``allow_redelegation`` set to ``true``) must not superset redelegated trust's roles.deactivated. In case of redelegation it must not exceed the value of corresponding ``expires_at`` field of redelegated trust or it may be omitted then ``expires_at`` value is copied from redelegated trust.issued through the trust. In case of redelegation it must not be set. - ``allow_redelegation`` (boolean) If ``allow_redelegation`` is set to ``true`` then a trust between ``trustor`` and any third user may be issued by the ``trustee`` just like any regular trust. - ``redelegation_count`` (integer, null or omitted) Specifies depth of redelegated trust chian. Each subsequent trust has this field decremented by 1 or more. Trust issued by ``trustee`` using trust scoped token cannot have ``redelegation_count`` greater or equal to corresponding field of the redelegated trust. If ``redelegation_count`` is set to null or omitted issued trust will be populated with redelegated trust's ``redelegation_count`` field decremented by 1. ""allow_redelegation"": true, ""redelegation_count"": 2,A token created from a redelegated trust will have a ``trust`` section containing the same fields as a regular truest token with addition of ``redelegated_trust_id``, ``redelegation_count`` and ``allow_redelegation``. Example response: :: Headers: X-Subject-Token X-Subject-Token: e80b74 { ""token"": { ""expires_at"": ""2013-02-27T18:30:59.999999Z"", ""issued_at"": ""2013-02-27T16:30:59.999999Z"", ""methods"": [ ""password"" ], ""OS-TRUST:trust"": { ""id"": ""fe0aef"", ""impersonation"": false, ""allow_redelegation"": true, ""redelegated_trust_id"": ""3ba234"", ""redelegation_count"": 2, ""links"": { ""self"": ""http://identity:35357/v3/trusts/fe0aef"" }, ""trustee_user"": { ""id"": ""0ca8f6"", ""links"": { ""self"": ""http://identity:35357/v3/users/0ca8f6"" } }, ""trustor_user"": { ""id"": ""bd263c"", ""links"": { ""self"": ""http://identity:35357/v3/users/bd263c"" } } }, ""user"": { ""domain"": { ""id"": ""1789d1"", ""links"": { ""self"": ""http://identity:35357/v3/domains/1789d1"" }, ""name"": ""example.com"" }, ""email"": ""joe@example.com"", ""id"": ""0ca8f6"", ""links"": { ""self"": ""http://identity:35357/v3/users/0ca8f6"" }, ""name"": ""Joe"" } } } ",- ``trustee_user_id`` (string)``project_id`` attribute.deactivated.issued through the trust.,84,4
openstack%2Fcinder~master~I85d9bffc4f848a38fd11784e6634fd014cc43001,openstack/cinder,master,I85d9bffc4f848a38fd11784e6634fd014cc43001,Outputs the message about failing to bind to IPv6,MERGED,2014-12-15 11:52:44.000000000,2014-12-22 15:59:11.000000000,2014-12-22 15:59:10.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 6542}, {'_account_id': 10068}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 13636}, {'_account_id': 13900}, {'_account_id': 14206}]","[{'number': 1, 'created': '2014-12-15 11:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f7ece896ee0b517c85c9c7bf6a37d2a63b5e6712', 'message': 'Add logging\n\nChange-Id: I85d9bffc4f848a38fd11784e6634fd014cc43001\n'}, {'number': 2, 'created': '2014-12-15 14:33:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/811dfdc173471fc8c73ca68c4dcd4dd2be630191', 'message': 'Add logging if binding to IPv6 failed\n\nChange-Id: I85d9bffc4f848a38fd11784e6634fd014cc43001\n'}, {'number': 3, 'created': '2014-12-17 14:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/eb5650305aa95d767449b2a31ccafa22e97b464e', 'message': 'Outputs the message about failing to bind to IPv6.\n\nChange-Id: I85d9bffc4f848a38fd11784e6634fd014cc43001\n'}, {'number': 4, 'created': '2014-12-17 14:43:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ccdc9b120b422f622a2818d54e859d2b49e38d67', 'message': 'Outputs the message about failing to bind to IPv6\n\nChange-Id: I85d9bffc4f848a38fd11784e6634fd014cc43001\n'}, {'number': 5, 'created': '2014-12-17 14:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4ad6ca1ac93bd82db5f93b14411ad7b5dfa62e62', 'message': 'Outputs the message about failing to bind to IPv6\n\nChange-Id: I85d9bffc4f848a38fd11784e6634fd014cc43001\n'}, {'number': 6, 'created': '2014-12-18 12:07:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3fc7514aac3c9ce97f2704d0e0934ee9d70e2080', 'message': 'Outputs the message about failing to bind to IPv6\n\nChange-Id: I85d9bffc4f848a38fd11784e6634fd014cc43001\n'}, {'number': 7, 'created': '2014-12-22 12:39:55.000000000', 'files': ['cinder/cmd/rtstool.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8b59396182ceacb704e00afe1aee040a19e2a187', 'message': 'Outputs the message about failing to bind to IPv6\n\nChange-Id: I85d9bffc4f848a38fd11784e6634fd014cc43001\n'}]",8,141775,8b59396182ceacb704e00afe1aee040a19e2a187,58,19,7,14305,,,0,"Outputs the message about failing to bind to IPv6

Change-Id: I85d9bffc4f848a38fd11784e6634fd014cc43001
",git fetch https://review.opendev.org/openstack/cinder refs/changes/75/141775/4 && git format-patch -1 --stdout FETCH_HEAD,['cinder/cmd/rtstool.py'],1,f7ece896ee0b517c85c9c7bf6a37d2a63b5e6712,changing-fix,from cinder.openstack.common import log as logging LOG = logging.getLogger(__name__) LOG.error(_('Failed to bind to IPv6.')),,3,0
openstack%2Frally~master~I8325396584432d9d81e10805902690ccf9695bbd,openstack/rally,master,I8325396584432d9d81e10805902690ccf9695bbd,Test for the gates,ABANDONED,2014-12-15 17:14:35.000000000,2014-12-22 15:58:09.000000000,,"[{'_account_id': 3}, {'_account_id': 13609}]","[{'number': 1, 'created': '2014-12-15 17:14:35.000000000', 'files': ['tests/ci/rally-gate.sh', 'rally-jobs/rally.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/7f7be000130e1ffb6163171b5a6f99f72617d728', 'message': 'Test for the gates\n\nChange-Id: I8325396584432d9d81e10805902690ccf9695bbd\n'}]",0,141849,7f7be000130e1ffb6163171b5a6f99f72617d728,4,2,1,13609,,,0,"Test for the gates

Change-Id: I8325396584432d9d81e10805902690ccf9695bbd
",git fetch https://review.opendev.org/openstack/rally refs/changes/49/141849/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/ci/rally-gate.sh', 'rally-jobs/rally.yaml']",2,7f7be000130e1ffb6163171b5a6f99f72617d728,wip-vm-blogbench,," KeystoneBasic.create_user: - args: name_length: 10 runner: type: ""constant"" times: 10 concurrency: 10 sla: failure_rate: max: 0 KeystoneBasic.create_delete_user: - args: name_length: 10 runner: type: ""constant"" times: 10 concurrency: 10 sla: failure_rate: max: 0 KeystoneBasic.create_and_list_tenants: - args: name_length: 10 runner: type: ""constant"" times: 10 concurrency: 10 sla: failure_rate: max: 0 KeystoneBasic.create_and_list_users: - args: name_length: 10 runner: type: ""constant"" times: 10 concurrency: 10 sla: failure_rate: max: 0 KeystoneBasic.create_tenant: - args: name_length: 10 runner: type: ""constant"" times: 10 concurrency: 10 sla: failure_rate: max: 0 KeystoneBasic.create_tenant_with_users: - args: name_length: 10 users_per_tenant: 10 runner: type: ""constant"" times: 10 concurrency: 10 context: users: tenants: 3 sla: failure_rate: max: 0 KeystoneBasic.create_delete_user: - args: name_length: 10 runner: type: ""constant"" times: 10 concurrency: 10 sla: failure_rate: max: 0 CeilometerAlarms.create_alarm: - args: meter_name: ""ram_util"" threshold: 10.0 type: ""threshold"" statistic: ""avg"" alarm_actions: [""http://localhost:8776/alarm""] ok_actions: [""http://localhost:8776/ok""] insufficient_data_actions: [""http://localhost:8776/notok""] runner: type: ""constant"" times: 10 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 CeilometerAlarms.create_and_delete_alarm: - args: meter_name: ""ram_util"" threshold: 10.0 type: ""threshold"" statistic: ""avg"" alarm_actions: [""http://localhost:8776/alarm""] ok_actions: [""http://localhost:8776/ok""] insufficient_data_actions: [""http://localhost:8776/notok""] runner: type: ""constant"" times: 10 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 CeilometerAlarms.create_and_list_alarm: - args: meter_name: ""ram_util"" threshold: 10.0 type: ""threshold"" statistic: ""avg"" alarm_actions: [""http://localhost:8776/alarm""] ok_actions: [""http://localhost:8776/ok""] insufficient_data_actions: [""http://localhost:8776/notok""] runner: type: ""constant"" times: 10 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 CeilometerAlarms.create_and_update_alarm: - args: meter_name: ""ram_util"" threshold: 10.0 type: ""threshold"" statistic: ""avg"" alarm_actions: [""http://localhost:8776/alarm""] ok_actions: [""http://localhost:8776/ok""] insufficient_data_actions: [""http://localhost:8776/notok""] runner: type: ""constant"" times: 10 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 CeilometerAlarms.list_alarms: - runner: type: ""constant"" times: 10 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 CeilometerMeters.list_meters: - runner: type: ""constant"" times: 10 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 CeilometerResource.list_resources: - runner: type: ""constant"" times: 10 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 Dummy.dummy: - args: sleep: 0.25 runner: type: ""constant"" times: 20 concurrency: 5 sla: failure_rate: max: 0 - args: sleep: 0.001 runner: type: ""rps"" times: 2000 rps: 200 sla: failure_rate: max: 0 - args: sleep: 0.01 runner: type: ""constant"" times: 1 concurrency: 1 context: quotas: nova: instances: 200 cores: 200 ram: -1 floating_ips: 200 fixed_ips: 200 metadata_items: -1 injected_files: -1 injected_file_content_bytes: -1 injected_file_path_bytes: -1 key_pairs: 500 security_groups: 400 security_group_rules: 600 cinder: gigabytes: -1 snapshots: -1 volumes: -1 sla: failure_rate: max: 0 - args: sleep: 0.01 runner: type: ""constant"" times: 1 concurrency: 1 context: users: tenants: 30 users_per_tenant: 15 sla: failure_rate: max: 0 Dummy.dummy_exception: - args: size_of_message: 5 runner: type: ""constant"" times: 20 concurrency: 5 Dummy.dummy_exception_probability: - args: exception_probability: 0.5 runner: type: ""constant"" times: 100 concurrency: 1 - args: exception_probability: 0.05 runner: type: ""constant"" times: 2042 concurrency: 1 - args: exception_probability: 0.5 runner: type: ""constant"" times: 100 concurrency: 1 sla: failure_rate: min: 20 max: 80 Dummy.dummy_with_scenario_output: - runner: type: ""constant"" times: 20 concurrency: 10 sla: failure_rate: max: 0 Dummy.dummy_random_fail_in_atomic: - args: exception_probability: 0.5 runner: type: ""constant"" times: 50 concurrency: 10 FakePlugin.testplugin: - runner: type: ""constant"" times: 4 concurrency: 4 sla: failure_rate: max: 0 CeilometerStats.create_meter_and_get_stats: - args: user_id: ""user-id"" resource_id: ""resource-id"" counter_volume: 1.0 counter_unit: """" counter_type: ""cumulative"" runner: type: ""constant"" times: 20 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 CeilometerQueries.create_and_query_alarms: - args: filter: {""and"": [{""!="": {""state"": ""dummy_state""}},{""="": {""type"": ""threshold""}}]} orderby: !!null limit: 10 meter_name: ""ram_util"" threshold: 10.0 type: ""threshold"" statistic: ""avg"" alarm_actions: [""http://localhost:8776/alarm""] ok_actions: [""http://localhost:8776/ok""] insufficient_data_actions: [""http://localhost:8776/notok""] runner: type: ""constant"" times: 20 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 CeilometerQueries.create_and_query_alarm_history: - args: orderby: !!null limit: !!null meter_name: ""ram_util"" threshold: 10.0 type: ""threshold"" statistic: ""avg"" alarm_actions: [""http://localhost:8776/alarm""] ok_actions: [""http://localhost:8776/ok""] insufficient_data_actions: [""http://localhost:8776/notok""] runner: type: ""constant"" times: 20 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 CeilometerQueries.create_and_query_samples: - args: filter: {""="": {""counter_unit"": ""instance""}} orderby: !!null limit: 10 counter_name: ""cpu_util"" counter_type: ""gauge"" counter_unit: ""instance"" counter_volume: ""1.0"" resource_id: ""resource_id"" runner: type: ""constant"" times: 20 concurrency: 10 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 HeatStacks.create_and_list_stack: - runner: type: ""constant"" times: 6 concurrency: 3 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 HeatStacks.create_and_delete_stack: - runner: type: ""constant"" times: 6 concurrency: 3 context: users: tenants: 2 users_per_tenant: 3 sla: failure_rate: max: 0 - args: template_path: '/home/jenkins/.rally/extra/server_with_volume.yaml.template' runner: type: ""constant"" times: 2 concurrency: 2 context: users: tenants: 2 users_per_tenant: 2 sla: failure_rate: max: 0 Authenticate.keystone: - runner: type: ""constant"" times: 40 concurrency: 20 context: users: tenants: 2 users_per_tenant: 10 sla: failure_rate: max: 0 SaharaNodeGroupTemplates.create_and_list_node_group_templates: - args: flavor: name: ""m1.small"" runner: type: ""constant"" times: 20 concurrency: 20 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 SaharaNodeGroupTemplates.create_delete_node_group_templates: - args: flavor: name: ""m1.small"" runner: type: ""constant"" times: 20 concurrency: 20 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 Authenticate.validate_cinder: - args: repetitions: 2 runner: type: ""constant"" times: 10 concurrency: 5 context: users: tenants: 3 users_per_tenant: 5 sla: failure_rate: max: 0 Authenticate.validate_glance: - args: repetitions: 2 runner: type: ""constant"" times: 10 concurrency: 5 context: users: tenants: 3 users_per_tenant: 5 sla: failure_rate: max: 0 Authenticate.validate_heat: - args: repetitions: 2 runner: type: ""constant"" times: 10 concurrency: 5 context: users: tenants: 3 users_per_tenant: 5 sla: failure_rate: max: 0 Authenticate.validate_nova: - args: repetitions: 2 runner: type: ""constant"" times: 10 concurrency: 5 context: users: tenants: 3 users_per_tenant: 5 sla: failure_rate: max: 0 Quotas.cinder_update_and_delete: - args: max_quota: 1024 runner: type: ""constant"" times: 4 concurrency: 1 context: users: tenants: 3 users_per_tenant: 2 sla: failure_rate: max: 0 Quotas.cinder_update: - args: max_quota: 1024 runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: failure_rate: max: 0 Quotas.nova_update_and_delete: - args: max_quota: 1024 runner: type: ""constant"" times: 4 concurrency: 1 context: users: tenants: 3 users_per_tenant: 2 sla: failure_rate: max: 0 Quotas.nova_update: - args: max_quota: 1024 runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: failure_rate: max: 0 CinderVolumes.create_and_delete_volume: - args: size: 1 runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 2 users_per_tenant: 2 sla: failure_rate: max: 0 CinderVolumes.create_and_list_volume: - args: size: 1 detailed: True runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 CinderVolumes.create_volume: - args: size: 1 runner: type: ""constant"" times: 2 concurrency: 2 context: users: tenants: 2 users_per_tenant: 2 sla: failure_rate: max: 0 CinderVolumes.create_and_delete_snapshot: - args: force: false runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 sla: failure_rate: max: 0 CinderVolumes.create_and_attach_volume: - args: volume_size: 1 image: name: ""^cirros.*uec$"" flavor: name: ""m1.tiny"" runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 2 users_per_tenant: 2 sla: failure_rate: max: 0 CinderVolumes.create_snapshot_and_attach_volume: - args: volume_type: false volume_size: min: 1 max: 2 runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 2 users_per_tenant: 1 servers: image: name: ""^cirros.*uec$"" flavor: name: ""m1.tiny"" servers_per_tenant: 2 sla: failure_rate: max: 0 - args: volume_type: true volume_size: min: 1 max: 2 runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 1 users_per_tenant: 1 servers: image: name: ""^cirros.*uec$"" flavor: name: ""m1.tiny"" servers_per_tenant: 1 sla: failure_rate: max: 0 CinderVolumes.create_nested_snapshots_and_attach_volume: - args: volume_size: min: 1 max: 2 nested_level: min: 2 max: 2 runner: type: ""constant"" times: 2 concurrency: 2 context: users: tenants: 2 users_per_tenant: 1 servers: image: name: ""^cirros.*uec$"" flavor: name: ""m1.tiny"" servers_per_tenant: 2 sla: failure_rate: max: 0 GlanceImages.create_and_delete_image: - args: image_location: ""http://download.cirros-cloud.net/0.3.2/cirros-0.3.2-x86_64-disk.img"" container_format: ""bare"" disk_format: ""qcow2"" runner: type: ""constant"" times: 5 concurrency: 5 context: users: tenants: 2 users_per_tenant: 3 sla: failure_rate: max: 0 GlanceImages.create_and_list_image: - args: image_location: ""/home/jenkins/.rally/extra/fake-image.img"" container_format: ""bare"" disk_format: ""qcow2"" runner: type: ""constant"" times: 6 concurrency: 6 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 GlanceImages.create_image_and_boot_instances: - args: image_location: ""http://download.cirros-cloud.net/0.3.2/cirros-0.3.2-x86_64-disk.img"" container_format: ""bare"" disk_format: ""qcow2"" flavor: name: ""m1.tiny"" number_instances: 2 runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 3 users_per_tenant: 1 sla: failure_rate: max: 0 GlanceImages.list_images: - runner: type: ""constant"" times: 4 concurrency: 4 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.1/cirros-0.3.1-x86_64-disk.img"" image_type: ""qcow2"" image_container: ""bare"" images_per_tenant: 2 sla: failure_rate: max: 0 NovaServers.boot_and_delete_server: - args: flavor: name: ""m1.tiny"" image: name: ""^cirros.*uec$"" runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 3 users_per_tenant: 2 sla: failure_rate: max: 0 - args: flavor: name: ""m1.tiny"" image: name: ""^cirros.*uec$"" force_delete: true runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 3 users_per_tenant: 2 sla: failure_rate: max: 0 NovaServers.boot_and_list_server: - args: flavor: name: ""m1.tiny"" image: name: ""^cirros.*uec$"" detailed: True runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 3 users_per_tenant: 1 sla: failure_rate: max: 0 NovaServers.resize_server: - args: flavor: name: ""m1.tiny"" image: name: ""^cirros.*uec$"" to_flavor: name: ""m1.small"" confirm: true runner: type: ""constant"" times: 2 concurrency: 2 context: users: tenants: 2 users_per_tenant: 1 sla: failure_rate: max: 0 NovaServers.boot_and_bounce_server: - args: flavor: name: ""m1.tiny"" image: name: ""^cirros.*uec$"" actions: - hard_reboot: 1 - stop_start: 1 - rescue_unrescue: 1 runner: type: ""constant"" times: 2 concurrency: 2 context: users: tenants: 2 users_per_tenant: 1 sla: failure_rate: max: 0 NovaServers.boot_server_from_volume_and_delete: - args: flavor: name: ""m1.tiny"" image: name: ""^cirros.*uec$"" volume_size: 1 runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 3 users_per_tenant: 3 sla: failure_rate: max: 0 NovaServers.boot_server_from_volume: - args: flavor: name: ""m1.tiny"" image: name: ""^cirros.*uec$"" volume_size: 1 runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 2 users_per_tenant: 2 sla: failure_rate: max: 0 NovaServers.snapshot_server: - args: flavor: name: ""m1.tiny"" image: name: ""^cirros.*uec$"" runner: type: ""constant"" times: 2 concurrency: 2 context: users: tenants: 2 users_per_tenant: 2 sla: failure_rate: max: 0 NovaServers.boot_server: - args: flavor: name: ""m1.tiny"" image: name: ""^cirros.*uec$"" auto_assign_nics: false runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 3 users_per_tenant: 2 sla: failure_rate: max: 0 - args: flavor: name: ""m1.tiny"" image: name: ""^cirros.*uec$"" runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 3 users_per_tenant: 2 sla: failure_rate: max: 0 VMTasks.boot_runcommand_delete: - args: flavor: name: ""m1.tiny"" image: name: ""^cirros.*uec$"" fixed_network: ""private"" floating_network: ""public"" use_floatingip: true script: ""/home/jenkins/.rally/extra/instance_dd_test.sh"" interpreter: ""/bin/sh"" username: ""cirros"" runner: type: ""constant"" times: 2 concurrency: 2 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 - args: flavor: name: ""m1.tiny"" image: name: ""^cirros.*uec$"" volume_args: size: 2 fixed_network: ""private"" floating_network: ""public"" use_floatingip: true script: ""/home/jenkins/.rally/extra/instance_dd_test.sh"" interpreter: ""/bin/sh"" username: ""cirros"" runner: type: ""constant"" times: 2 concurrency: 2 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 - args: flavor: name: ""m1.tiny"" image: name: ""^cirros.*uec$"" fixed_network: ""private"" use_floatingip: false script: ""/home/jenkins/.rally/extra/instance_dd_test.sh"" interpreter: ""/bin/sh"" username: ""cirros"" runner: type: ""constant"" times: 2 concurrency: 2 context: users: tenants: 1 users_per_tenant: 1 sla: failure_rate: max: 0 Requests.check_response: - args: url: ""http://www.google.com"" response: 200 runner: type: ""constant"" times: 5 concurrency: 5 NovaSecGroup.create_and_delete_secgroups: - args: security_group_count: 5 rules_per_security_group: 5 runner: type: ""constant"" times: 4 concurrency: 4 context: users: tenants: 3 users_per_tenant: 2 quotas: nova: security_groups: -1 security_group_rules: -1 sla: failure_rate: max: 0 NovaSecGroup.create_and_list_secgroups: - args: security_group_count: 5 rules_per_security_group: 5 runner: type: ""constant"" times: 4 concurrency: 4 context: users: tenants: 3 users_per_tenant: 2 quotas: nova: security_groups: -1 security_group_rules: -1 sla: failure_rate: max: 0 NovaSecGroup.boot_and_delete_server_with_secgroups: - args: flavor: name: ""m1.tiny"" image: name: ""^cirros.*uec$"" security_group_count: 5 rules_per_security_group: 5 runner: type: ""constant"" times: 4 concurrency: 4 context: users: tenants: 3 users_per_tenant: 2 quotas: nova: security_groups: -1 security_group_rules: -1 sla: failure_rate: max: 25 max_failure_percent: 0 ",1,1259
openstack%2Fceilometer~master~I27494bfda826a3b2a093a5c0e523acbfa8e4de62,openstack/ceilometer,master,I27494bfda826a3b2a093a5c0e523acbfa8e4de62,Add cmd.polling.CLI_OPTS to option list,MERGED,2014-12-22 09:42:58.000000000,2014-12-22 15:55:00.000000000,2014-12-22 15:55:00.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 7049}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-12-22 09:42:58.000000000', 'files': ['ceilometer/opts.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e7501b22f0ac6eea2e695f0a7e4a699354c75b1b', 'message': 'Add cmd.polling.CLI_OPTS to option list\n\npolling_namespaces and pollster_list are defined but not present\nin etc/ceilometer/ceilometer.conf after run tox -egenconfig.\n\nChange-Id: I27494bfda826a3b2a093a5c0e523acbfa8e4de62\n'}]",0,143408,e7501b22f0ac6eea2e695f0a7e4a699354c75b1b,9,5,1,6676,,,0,"Add cmd.polling.CLI_OPTS to option list

polling_namespaces and pollster_list are defined but not present
in etc/ceilometer/ceilometer.conf after run tox -egenconfig.

Change-Id: I27494bfda826a3b2a093a5c0e523acbfa8e4de62
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/08/143408/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/opts.py'],1,e7501b22f0ac6eea2e695f0a7e4a699354c75b1b,add-polling-cli-opts,"import ceilometer.cmd.polling ceilometer.cmd.polling.CLI_OPTS,",,2,0
openstack%2Fceilometer~master~Ia6d88892a7c93cfa880e4383bbefa55c069a12d9,openstack/ceilometer,master,Ia6d88892a7c93cfa880e4383bbefa55c069a12d9,Ignore ceilometer.conf,MERGED,2014-12-22 09:25:35.000000000,2014-12-22 15:54:35.000000000,2014-12-22 15:54:35.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 10987}, {'_account_id': 11564}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-12-22 09:25:35.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d7eabde418fecd2a4ca511b278abda96fa55644b', 'message': 'Ignore ceilometer.conf\n\nceilometer.conf will be generated after we run tox -egenconfig, it\nshould be ignored.\n\nChange-Id: Ia6d88892a7c93cfa880e4383bbefa55c069a12d9\n'}]",0,143405,d7eabde418fecd2a4ca511b278abda96fa55644b,10,6,1,6676,,,0,"Ignore ceilometer.conf

ceilometer.conf will be generated after we run tox -egenconfig, it
should be ignored.

Change-Id: Ia6d88892a7c93cfa880e4383bbefa55c069a12d9
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/05/143405/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,d7eabde418fecd2a4ca511b278abda96fa55644b,ignore-ceilometer.conf,etc/ceilometer/ceilometer.conf*tools/pylint_exceptions ,etc/ceilometer/ceilometer.conf.sampletools/pylint_exceptions,2,2
openstack%2Ffuel-web~master~Ifb66ac70822d23e6d41fe3036b52092d2312ad2f,openstack/fuel-web,master,Ifb66ac70822d23e6d41fe3036b52092d2312ad2f,Stop update button added on UI,ABANDONED,2014-09-03 13:28:54.000000000,2014-12-22 15:53:31.000000000,,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 10391}]","[{'number': 1, 'created': '2014-09-03 13:28:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/924668eeedd108184ad0aee467b33f53e681ec99', 'message': 'Stop update button added\n\n - this is only UI changes, backend cnanges needs for /stop_update\n\nCloses-Bug:#1364907\n\nChange-Id: Ifb66ac70822d23e6d41fe3036b52092d2312ad2f\n'}, {'number': 2, 'created': '2014-09-03 13:45:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b3036585a85699811b6a452d7b268903a9edae9f', 'message': 'Stop update button added on UI\n\n - this is only UI changes, backend cnanges needs for /stop_update\n\nCloses-Bug:#1364907\n\nChange-Id: Ifb66ac70822d23e6d41fe3036b52092d2312ad2f\n'}, {'number': 3, 'created': '2014-09-03 13:58:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/569893fde16f278372706a3e12c1651bcefeb9b2', 'message': 'Stop update button added on UI\n\n - this is only UI changes, backend cnanges needs for /stop_update\n\nCloses-Bug:#1364907\n\nChange-Id: Ifb66ac70822d23e6d41fe3036b52092d2312ad2f\n'}, {'number': 4, 'created': '2014-09-03 15:37:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/79f70b237802d76fc1ae85eb6eb34b9f56834390', 'message': 'Stop update button added on UI\n\n - this is only UI changes, backend cnanges needs for /stop_update\n - /stop_update reverted back to /stop_deployment\n\nCloses-Bug:#1364907\n\nChange-Id: Ifb66ac70822d23e6d41fe3036b52092d2312ad2f\n'}, {'number': 5, 'created': '2014-09-04 11:28:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7099c29bbdd8aa3c32072b35fb424c29bc1f6650', 'message': 'Stop update button added on UI\n\n - Stop Update  button showed only in experimental mode\n\nRelated-Bug:#1364907\n\nChange-Id: Ifb66ac70822d23e6d41fe3036b52092d2312ad2f\n'}, {'number': 6, 'created': '2014-09-04 11:37:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7647b7d103eb5fc15f69eac912a497f08dfdcf10', 'message': 'Stop update button added on UI\n\n - Stop Update  button showed only in experimental mode\n\nRelated-Bug:#1364907\n\nChange-Id: Ifb66ac70822d23e6d41fe3036b52092d2312ad2f\n'}, {'number': 7, 'created': '2014-09-04 11:38:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d7a1f3c4b135fe48ad9b9db51377c0126c2c69eb', 'message': 'Stop update button added on UI\n\n - Stop Update  button showed only in experimental mode\n\nRelated-Bug:#1364907\n\nChange-Id: Ifb66ac70822d23e6d41fe3036b52092d2312ad2f\n'}, {'number': 8, 'created': '2014-09-08 12:19:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/aa6efc28fe7a0b3257eaa253b1ac2a5defe2d607', 'message': 'Stop update button added on UI\n\n - Stop Update  button showed only in experimental mode\n\nRelated-Bug:#1364907\n\nChange-Id: Ifb66ac70822d23e6d41fe3036b52092d2312ad2f\n'}, {'number': 9, 'created': '2014-09-08 13:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bf0e0f9747bc92c38269003075bd61a7f34d1d6e', 'message': 'Stop update button added on UI\n\n - Stop Update  button showed only in experimental mode\n\nRelated-Bug:#1364907\n\nChange-Id: Ifb66ac70822d23e6d41fe3036b52092d2312ad2f\n'}, {'number': 10, 'created': '2014-09-08 13:23:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1b7739d7b2e48ba5c50692bd58f7fd454f8a5353', 'message': 'Stop update button added on UI\n\n - Stop Update  button showed only in experimental mode\n\nRelated-Bug:#1364907\n\nChange-Id: Ifb66ac70822d23e6d41fe3036b52092d2312ad2f\n'}, {'number': 11, 'created': '2014-10-06 11:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/eec0d65e80554ab710eccd6acfd9850b0d2c4655', 'message': 'Stop update button added on UI\n\n - Stop Update  button showed only in experimental mode\n\nRelated-Bug:#1364907\nRalated backend patch: https://review.openstack.org/#/c/118688/\n\nChange-Id: Ifb66ac70822d23e6d41fe3036b52092d2312ad2f\n'}, {'number': 12, 'created': '2014-10-06 11:26:52.000000000', 'files': ['nailgun/static/js/views/dialogs.jsx', 'nailgun/static/i18n/translation.json', 'nailgun/static/js/models.js', 'nailgun/static/js/views/cluster_page_subviews.jsx'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ca93b047c9dc17996a940ee34a7c581f8390833b', 'message': 'Stop update button added on UI\n\n - Stop Update  button showed only in experimental mode\n\nRelated-Bug:#1364907\nRalated backend patch: https://review.openstack.org/#/c/118688/\n\nChange-Id: Ifb66ac70822d23e6d41fe3036b52092d2312ad2f\n'}]",9,118634,ca93b047c9dc17996a940ee34a7c581f8390833b,78,7,12,9730,,,0,"Stop update button added on UI

 - Stop Update  button showed only in experimental mode

Related-Bug:#1364907
Ralated backend patch: https://review.openstack.org/#/c/118688/

Change-Id: Ifb66ac70822d23e6d41fe3036b52092d2312ad2f
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/34/118634/6 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/i18n/translation.json', 'nailgun/static/js/views/dialogs.js', 'nailgun/static/templates/cluster/deployment_control.html', 'nailgun/static/templates/dialogs/stop_deployment.html']",4,924668eeedd108184ad0aee467b33f53e681ec99,bug/1364907,<% var action = cluster.get('tasks').findTask({name: 'update'}) ? 'update' : 'deployment'; %> <h3><%- $.t('dialog.stop_' + action + '.title') %></h3> <%- $.t('dialog.stop_' + action + '.provisioning_warning') %> <%- $.t('dialog.stop_' + action + '.text') %>," <h3 data-i18n=""dialog.stop_deployment.title""></h3> <%- $.t('dialog.stop_deployment.provisioning_warning') %> <%- $.t('dialog.stop_deployment.text') %>",21,12
openstack%2Fproject-config~master~I41ff993aa86e6a7ac1beed3cc5a3b94dcadbdd7c,openstack/project-config,master,I41ff993aa86e6a7ac1beed3cc5a3b94dcadbdd7c,Move to pbr freeze from pip freeze,MERGED,2014-12-16 23:18:27.000000000,2014-12-22 15:43:56.000000000,2014-12-22 15:43:55.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-16 23:18:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d52f800161df89929f0bc57ff38100bb5aa12acc', 'message': ""Move to pbr freeze from pip freeze\n\nFor the things that use pbr, we no longer have git shas in the version\nnumbers. So, in order to verify what exact version of things we're\ninstalling, use pbr freeze to collect the information.\n\nChange-Id: I41ff993aa86e6a7ac1beed3cc5a3b94dcadbdd7c\n""}, {'number': 2, 'created': '2014-12-17 03:53:57.000000000', 'files': ['jenkins/scripts/run-tox.sh', 'jenkins/scripts/run-cover.sh', 'jenkins/scripts/run-pep8.sh', 'jenkins/scripts/run-docs.sh', 'jenkins/scripts/run-selenium.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ad5bbb498b171acefda23fcc37bfd93b6a3a9989', 'message': ""Move to pbr freeze from pip freeze\n\nFor the things that use pbr, we no longer have git shas in the version\nnumbers. So, in order to verify what exact version of things we're\ninstalling, use pbr freeze to collect the information.\n\nChange-Id: I41ff993aa86e6a7ac1beed3cc5a3b94dcadbdd7c\n""}]",1,142257,ad5bbb498b171acefda23fcc37bfd93b6a3a9989,13,7,2,2,,,0,"Move to pbr freeze from pip freeze

For the things that use pbr, we no longer have git shas in the version
numbers. So, in order to verify what exact version of things we're
installing, use pbr freeze to collect the information.

Change-Id: I41ff993aa86e6a7ac1beed3cc5a3b94dcadbdd7c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/57/142257/2 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/scripts/run-tox.sh', 'jenkins/scripts/run-cover.sh', 'jenkins/scripts/run-pep8.sh', 'jenkins/scripts/run-docs.sh', 'jenkins/scripts/run-selenium.sh']",5,d52f800161df89929f0bc57ff38100bb5aa12acc,,"# (non-bundle) test environment. Also, run pbr freeze on theecho ""Begin pbr freeze output from test virtualenv:""[ -e .tox/$venv/bin/pbr ] && .tox/$venv/bin/pbr freeze || .tox/$venv/bin/pip freeze","# (non-bundle) test environment. Also, run pip freeze on theecho ""Begin pip freeze output from test virtualenv:"".tox/$venv/bin/pip freeze",14,14
openstack%2Ffuel-main~master~I6f013bb441d122592f446aab41ecf51960293330,openstack/fuel-main,master,I6f013bb441d122592f446aab41ecf51960293330,Add the possibility to work without python virtualenv,MERGED,2014-10-06 12:20:25.000000000,2014-12-22 15:36:21.000000000,2014-12-22 10:34:58.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8965}, {'_account_id': 8971}, {'_account_id': 9546}, {'_account_id': 9977}, {'_account_id': 13194}, {'_account_id': 13344}, {'_account_id': 13917}]","[{'number': 1, 'created': '2014-10-06 12:20:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1649b16abf979f50f9590301059289d7610aeeca', 'message': 'Added the possibility to work without python virtualenv\n\nChange-Id: I6f013bb441d122592f446aab41ecf51960293330\nCloses-Bug: 1377183\n'}, {'number': 2, 'created': '2014-12-03 09:24:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ff818264ea06bd22a2f212acc9f964e8710d0bf1', 'message': 'Add the possibility to work without python virtualenv\n\nChange-Id: I6f013bb441d122592f446aab41ecf51960293330\nCloses-Bug: 1377183\n'}, {'number': 3, 'created': '2014-12-03 09:43:51.000000000', 'files': ['utils/jenkins/system_tests.sh'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f5eed8b7fb4d7d800a2f1a64ee985df34297f7b2', 'message': 'Add the possibility to work without python virtualenv\n\nChange-Id: I6f013bb441d122592f446aab41ecf51960293330\nCloses-Bug: 1377183\n'}]",1,126273,f5eed8b7fb4d7d800a2f1a64ee985df34297f7b2,27,10,3,13343,,,0,"Add the possibility to work without python virtualenv

Change-Id: I6f013bb441d122592f446aab41ecf51960293330
Closes-Bug: 1377183
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/73/126273/1 && git format-patch -1 --stdout FETCH_HEAD,['utils/jenkins/system_tests.sh'],1,1649b16abf979f50f9590301059289d7610aeeca,bug/1377183," if [ -v VENV_PATH ]; then if [ ""${DRY_RUN}"" = ""yes"" ]; then echo source $VENV_PATH/bin/activate else source $VENV_PATH/bin/activate fi"," if [ -z ""${VENV_PATH}"" ]; then VENV_PATH=""/home/jenkins/venv-nailgun-tests"" fi if [ ""${DRY_RUN}"" = ""yes"" ]; then echo . $VENV_PATH/bin/activate else . $VENV_PATH/bin/activate",6,8
openstack%2Fmagnum~master~I01df1e6b18c247982f1effc1ccb8e15e5c13a9ac,openstack/magnum,master,I01df1e6b18c247982f1effc1ccb8e15e5c13a9ac,Update log message for kubecli.py,MERGED,2014-12-22 05:56:41.000000000,2014-12-22 15:29:43.000000000,2014-12-22 15:29:43.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-22 05:56:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/45c9f42e8769a3f2ce8f904949e399c42842a101', 'message': 'Update log message for kubecli.py\n\nChange-Id: I01df1e6b18c247982f1effc1ccb8e15e5c13a9ac\n'}, {'number': 2, 'created': '2014-12-22 07:06:48.000000000', 'files': ['magnum/conductor/kubecli.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/36244a0443a32565635c697974abe7151b696daf', 'message': 'Update log message for kubecli.py\n\nChange-Id: I01df1e6b18c247982f1effc1ccb8e15e5c13a9ac\n'}]",0,143366,36244a0443a32565635c697974abe7151b696daf,8,2,2,7494,,,0,"Update log message for kubecli.py

Change-Id: I01df1e6b18c247982f1effc1ccb8e15e5c13a9ac
",git fetch https://review.opendev.org/openstack/magnum refs/changes/66/143366/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/conductor/kubecli.py'],1,45c9f42e8769a3f2ce8f904949e399c42842a101,master," LOG.debug(""pod_update contents %s"" % contents) LOG.debug(""pod_get %s"" % uuid)"," LOG.debug(""pod_create contents %s"" % contents) LOG.debug(""service_get %s"" % uuid)",2,2
openstack%2Ffuel-web~master~Ic886a989119c795a512a1bc4d9a19118ed01fbb3,openstack/fuel-web,master,Ic886a989119c795a512a1bc4d9a19118ed01fbb3,[React] Dialogs,MERGED,2014-08-27 16:46:52.000000000,2014-12-22 15:25:23.000000000,2014-12-22 15:25:22.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-08-27 16:46:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/954d278d36366b6444a9c053fca7163813e4bbe5', 'message': '[React] - Dialogs\n\nChange-Id: Ic886a989119c795a512a1bc4d9a19118ed01fbb3\n'}, {'number': 2, 'created': '2014-08-29 16:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c88bd00a0cbe576558e15474527341101d18b0c3', 'message': '[React] - Dialogs\n\nChange-Id: Ic886a989119c795a512a1bc4d9a19118ed01fbb3\n'}, {'number': 3, 'created': '2014-11-17 18:06:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9a5ee537c2c3f7e88d9863d3dfab2d03ca3a9faf', 'message': '[React] - Dialogs\n\nChange-Id: Ic886a989119c795a512a1bc4d9a19118ed01fbb3\n'}, {'number': 4, 'created': '2014-11-24 15:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/062941baecc0c050ba150005f3b8025eacb0f874', 'message': '[React] - Dialogs\n\nChange-Id: Ic886a989119c795a512a1bc4d9a19118ed01fbb3\n'}, {'number': 5, 'created': '2014-12-01 16:03:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3a7d473845a4aa466762eb37c0122e71439dc5d0', 'message': '[React] - Dialogs\n\nChange-Id: Ic886a989119c795a512a1bc4d9a19118ed01fbb3\n'}, {'number': 6, 'created': '2014-12-03 16:36:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f1c2f32cb56c941c591124c99e11560e6cdf9b37', 'message': '[React] - Dialogs\n\nChange-Id: Ic886a989119c795a512a1bc4d9a19118ed01fbb3\n'}, {'number': 7, 'created': '2014-12-04 17:37:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/465d51c498204bd8f54de3af51af6d175878e4a0', 'message': '[React] - Dialogs\n\nChange-Id: Ic886a989119c795a512a1bc4d9a19118ed01fbb3\n'}, {'number': 8, 'created': '2014-12-10 17:37:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b245f018cbf4cd1830057d1d55ba283150e7ccf8', 'message': '[React] - Dialogs\n\nChange-Id: Ic886a989119c795a512a1bc4d9a19118ed01fbb3\n'}, {'number': 9, 'created': '2014-12-11 06:56:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8f4c4d61e7051fb1026173d51c55413c3792db0d', 'message': '[React] - Dialogs\n\nChange-Id: Ic886a989119c795a512a1bc4d9a19118ed01fbb3\n'}, {'number': 10, 'created': '2014-12-12 16:37:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/77d82f780400bdf1ca08efc58e89e46d3f10e8eb', 'message': '[React] - Dialogs\n\nChange-Id: Ic886a989119c795a512a1bc4d9a19118ed01fbb3\n'}, {'number': 11, 'created': '2014-12-18 13:33:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/97c9445c0292bf5cdf58dc2949cd4470b34438b7', 'message': '[React] - Dialogs\n\nChange-Id: Ic886a989119c795a512a1bc4d9a19118ed01fbb3\n'}, {'number': 12, 'created': '2014-12-18 15:52:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/064a9ebf25236c4a80474dfd55333d300b1513a1', 'message': '[React] - Dialogs\n\nChange-Id: Ic886a989119c795a512a1bc4d9a19118ed01fbb3\n'}, {'number': 13, 'created': '2014-12-19 15:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/36ac4cd80bf8452a553734198bb7adc34ab7f1f6', 'message': '[React] Dialogs\n\nRelated to blueprint backbone-to-react\n\nChange-Id: Ic886a989119c795a512a1bc4d9a19118ed01fbb3\n'}, {'number': 14, 'created': '2014-12-22 15:00:37.000000000', 'files': ['nailgun/static/templates/wizard/mode.html', 'nailgun/static/i18n/translation.json', 'nailgun/static/templates/dialogs/base_dialog.html', 'nailgun/static/templates/dialogs/reset_environment.html', 'nailgun/static/js/views/notifications_page.jsx', 'nailgun/static/js/component_mixins.jsx', 'nailgun/static/templates/wizard/create_cluster_wizard.html', 'nailgun/static/templates/wizard/network.html', 'nailgun/static/js/views/cluster_page_tabs/actions_tab.jsx', 'nailgun/static/templates/dialogs/dismiss_settings.html', 'nailgun/static/templates/wizard/storage.html', 'nailgun/static/js/views/dialogs.jsx', 'nailgun/static/templates/wizard/control_template.html', 'nailgun/static/templates/wizard/text_input.html', 'nailgun/static/templates/wizard/common_wizard_panel.html', 'nailgun/static/templates/dialogs/update_environment.html', 'nailgun/static/js/utils.js', 'nailgun/static/templates/wizard/name_and_release.html', 'nailgun/static/js/views/cluster_page_subviews.jsx', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/node_list_screen.js', 'nailgun/static/templates/dialogs/update_interfaces.html', 'nailgun/static/templates/dialogs/delete_nodes.html', 'nailgun/static/templates/dialogs/show_node.html', 'nailgun/static/js/views/layout.jsx', 'nailgun/static/templates/wizard/ready.html', 'nailgun/static/js/views/wizard.js', 'nailgun/static/js/views/cluster_page.js', 'nailgun/static/css/styles.less', 'nailgun/static/templates/wizard/warning.html'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/59cded22af155d29def98ddbb5d203f4589eae55', 'message': '[React] Dialogs\n\nRelated to blueprint backbone-to-react\n\nChange-Id: Ic886a989119c795a512a1bc4d9a19118ed01fbb3\n'}]",135,117301,59cded22af155d29def98ddbb5d203f4589eae55,100,7,14,9730,,,0,"[React] Dialogs

Related to blueprint backbone-to-react

Change-Id: Ic886a989119c795a512a1bc4d9a19118ed01fbb3
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/01/117301/11 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/js/views/dialogs.jsx', 'nailgun/static/i18n/translation.json', 'nailgun/static/js/views/cluster_page.js', 'nailgun/static/templates/dialogs/delete_nodes.html', 'nailgun/static/js/component_mixins.jsx', 'nailgun/static/js/utils.js', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/node_list_screen.js']",7,954d278d36366b6444a9c053fca7163813e4bbe5,bp/backbone-to-react, utils.showDialog(dialogViews.DeleteNodesDialog({nodes: nodes}));, var dialog = new dialogViews.DeleteNodesDialog({nodes: nodes}); app.page.tab.registerSubView(dialog); dialog.render();,96,44
openstack%2Fmagnum~master~I543a7ae07ed2c64b96de7c2b61ea5044b5cc4fb8,openstack/magnum,master,I543a7ae07ed2c64b96de7c2b61ea5044b5cc4fb8,Added log messages to the v1.,ABANDONED,2014-11-21 18:33:17.000000000,2014-12-22 15:25:07.000000000,,"[{'_account_id': 3}, {'_account_id': 7494}]","[{'number': 1, 'created': '2014-11-21 18:33:17.000000000', 'files': ['magnum/api/controllers/v1.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/75e2ceb335b5072413a997a16e0d7a63f14b2337', 'message': 'Added log messages to the v1.\n\nChange-Id: I543a7ae07ed2c64b96de7c2b61ea5044b5cc4fb8\nImplements: blueprint magnum-api-service\n'}]",0,136451,75e2ceb335b5072413a997a16e0d7a63f14b2337,4,2,1,8580,,,0,"Added log messages to the v1.

Change-Id: I543a7ae07ed2c64b96de7c2b61ea5044b5cc4fb8
Implements: blueprint magnum-api-service
",git fetch https://review.opendev.org/openstack/magnum refs/changes/51/136451/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/api/controllers/v1.py'],1,75e2ceb335b5072413a997a16e0d7a63f14b2337,bp/magnum-api-service," """"""Container Model"""""" """"""API Controller Class for Container"""""" ",,5,0
openstack%2Fmagnum~master~I31c89cbb75e615bd893e5e53bb77e383f29df6e5,openstack/magnum,master,I31c89cbb75e615bd893e5e53bb77e383f29df6e5,Added log messages to the v1.,ABANDONED,2014-11-21 18:26:20.000000000,2014-12-22 15:25:01.000000000,,"[{'_account_id': 3}, {'_account_id': 7494}]","[{'number': 1, 'created': '2014-11-21 18:26:20.000000000', 'files': ['magnum/api/controllers/v1.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/94f1629edd36776de6b9e99a3756857adfde9a92', 'message': 'Added log messages to the v1.\n\nChange-Id: I31c89cbb75e615bd893e5e53bb77e383f29df6e5\nImplements: blueprint magnum-api-service\n'}]",1,136447,94f1629edd36776de6b9e99a3756857adfde9a92,4,2,1,8580,,,0,"Added log messages to the v1.

Change-Id: I31c89cbb75e615bd893e5e53bb77e383f29df6e5
Implements: blueprint magnum-api-service
",git fetch https://review.opendev.org/openstack/magnum refs/changes/47/136447/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/api/controllers/v1.py'],1,94f1629edd36776de6b9e99a3756857adfde9a92,bp/magnum-api-service," """"""Container Model"""""" """"""API Controller Class for Container""""""",,3,0
openstack%2Fmagnum~master~Idc911d6b808bb7e508c22ce269c99054fce6b0df,openstack/magnum,master,Idc911d6b808bb7e508c22ce269c99054fce6b0df,Added a doc string for Magnum API.,ABANDONED,2014-11-19 18:04:17.000000000,2014-12-22 15:24:52.000000000,,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 7494}]","[{'number': 1, 'created': '2014-11-19 18:04:17.000000000', 'files': ['magnum/api/controllers/v1.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/111f5691cdf23b396b2447fec16da3957f320432', 'message': 'Added a doc string for Magnum API.\n\nChange-Id: Idc911d6b808bb7e508c22ce269c99054fce6b0df\nImplements: blueprint magnum-api-service\n'}]",0,135682,111f5691cdf23b396b2447fec16da3957f320432,5,3,1,8580,,,0,"Added a doc string for Magnum API.

Change-Id: Idc911d6b808bb7e508c22ce269c99054fce6b0df
Implements: blueprint magnum-api-service
",git fetch https://review.opendev.org/openstack/magnum refs/changes/82/135682/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/api/controllers/v1.py'],1,111f5691cdf23b396b2447fec16da3957f320432,bp/magnum-api-service," """"""Container Attributes."""""" """""" Implementation of Container API calls. """""" ",,7,0
openstack%2Fmagnum~master~I6ecb154aaf514ddebf52ed37af51d4c563f338b0,openstack/magnum,master,I6ecb154aaf514ddebf52ed37af51d4c563f338b0,Adding docker backend to the magnum.,ABANDONED,2014-12-12 16:58:33.000000000,2014-12-22 15:24:30.000000000,,"[{'_account_id': 3}, {'_account_id': 7494}]","[{'number': 1, 'created': '2014-12-12 16:58:33.000000000', 'files': ['magnum/conductor/handlers/docker_agent.py', 'magnum/conductor/handlers/docker.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/1a270fc7e78e1ad5023b5dccae09bdb1441ad904', 'message': 'Adding docker backend to the magnum.\n\nChange-Id: I6ecb154aaf514ddebf52ed37af51d4c563f338b0\nImplements: blueprint magnum-backend-docker\n'}]",0,141426,1a270fc7e78e1ad5023b5dccae09bdb1441ad904,4,2,1,8580,,,0,"Adding docker backend to the magnum.

Change-Id: I6ecb154aaf514ddebf52ed37af51d4c563f338b0
Implements: blueprint magnum-backend-docker
",git fetch https://review.opendev.org/openstack/magnum refs/changes/26/141426/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/conductor/handlers/docker_agent.py', 'magnum/conductor/handlers/docker.py']",2,1a270fc7e78e1ad5023b5dccae09bdb1441ad904,bp/magnum-backend-docker,,"# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Magnum Docker RPC handler."""""" from magnum.openstack.common import log as logging LOG = logging.getLogger(__name__) # These are the backend operations. They are executed by the backend # service. API calls via AMQP (within the ReST API) trigger the handlers to # be called. class Handler(object): def __init__(self): super(Handler, self).__init__() # Container operations def container_create(uuid, contents): LOG.debug(""container_create %s contents=%s"" % (uuid, contents)) def container_list(): LOG.debug(""container_list"") # return container list dict def container_delete(uuid): LOG.debug(""cotainer_delete %s"" % uuid) def container_show(uuid): LOG.debug(""container_show %s"" % uuid) # return container information dict def container_reboot(uuid): LOG.debug(""container_reboot %s"" % uuid) def container_stop(uuid): LOG.debug(""container_stop %s"" % uuid) def container_start(uuid): LOG.debug(""container_start %s"" % uuid) def container_pause(uuid): LOG.debug(""container_pause %s"" % uuid) def container_unpause(uuid): LOG.debug(""container_unpause %s"" % uuid) def container_logs(uuid): LOG.debug(""container_logs %s"" % uuid) def container_execute(uuid): LOG.debug(""container_execute %s"" % uuid) ",128,63
openstack%2Fmagnum~master~I4b937369a42a14daccc44f5572a182e9908f382c,openstack/magnum,master,I4b937369a42a14daccc44f5572a182e9908f382c,Grouped Import error has fixed.,ABANDONED,2014-12-18 18:37:43.000000000,2014-12-22 15:24:21.000000000,,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 7494}]","[{'number': 1, 'created': '2014-12-18 18:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/efc82ffb32183c902b018b4a78a40a032ca838cf', 'message': 'Grouped Import error has fixed.\nImplements: blueprint magnum-backend-docker\n\nChange-Id: I4b937369a42a14daccc44f5572a182e9908f382c\n'}, {'number': 2, 'created': '2014-12-18 18:45:56.000000000', 'files': ['magnum/conductor/handlers/docker.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/f6430845bea6161d2f40822303f3c8c7c281dee1', 'message': 'Grouped Import error has fixed.\n\nImplements: blueprint magnum-backend-docker\n\nChange-Id: I4b937369a42a14daccc44f5572a182e9908f382c\n'}]",1,142871,f6430845bea6161d2f40822303f3c8c7c281dee1,7,3,2,8580,,,0,"Grouped Import error has fixed.

Implements: blueprint magnum-backend-docker

Change-Id: I4b937369a42a14daccc44f5572a182e9908f382c
",git fetch https://review.opendev.org/openstack/magnum refs/changes/71/142871/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/conductor/handlers/docker.py'],1,efc82ffb32183c902b018b4a78a40a032ca838cf,bp/magnum-backend-docker,from oslo.config import cfg ,from oslo.config import cfg,2,1
openstack%2Fmagnum~master~Ibee978f8811f1c810ad24ebaebfd538ae2068ca0,openstack/magnum,master,Ibee978f8811f1c810ad24ebaebfd538ae2068ca0,Docker implementation with import error fixed.,ABANDONED,2014-12-18 18:21:00.000000000,2014-12-22 15:24:08.000000000,,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 7494}]","[{'number': 1, 'created': '2014-12-18 18:21:00.000000000', 'files': ['magnum/conductor/handlers/docker.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/001451f7e8a223c86e919e436b8ab2b8bc9350a3', 'message': 'Docker implementation with import error fixed.\n\nChange-Id: Ibee978f8811f1c810ad24ebaebfd538ae2068ca0\nImplements: blueprint magnum-backend-docker\n'}]",0,142866,001451f7e8a223c86e919e436b8ab2b8bc9350a3,5,3,1,8580,,,0,"Docker implementation with import error fixed.

Change-Id: Ibee978f8811f1c810ad24ebaebfd538ae2068ca0
Implements: blueprint magnum-backend-docker
",git fetch https://review.opendev.org/openstack/magnum refs/changes/66/142866/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/conductor/handlers/docker.py'],1,001451f7e8a223c86e919e436b8ab2b8bc9350a3,bp/magnum-backend-docker,,,0,1
openstack%2Fmagnum~master~Idc6f8b8c096c704403a68f4a90268319de69b70b,openstack/magnum,master,Idc6f8b8c096c704403a68f4a90268319de69b70b,Implemented docker backend in the handler.,ABANDONED,2014-12-18 17:45:58.000000000,2014-12-22 15:23:54.000000000,,"[{'_account_id': 3}, {'_account_id': 7494}]","[{'number': 1, 'created': '2014-12-18 17:45:58.000000000', 'files': ['magnum/conductor/handlers/docker.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/626080676867145f9fd4581af823c86db82d6482', 'message': 'Implemented docker backend in the handler.\n\nChange-Id: Idc6f8b8c096c704403a68f4a90268319de69b70b\nImplements: blueprint magnum-backend-docker\n'}]",0,142857,626080676867145f9fd4581af823c86db82d6482,4,2,1,8580,,,0,"Implemented docker backend in the handler.

Change-Id: Idc6f8b8c096c704403a68f4a90268319de69b70b
Implements: blueprint magnum-backend-docker
",git fetch https://review.opendev.org/openstack/magnum refs/changes/57/142857/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/conductor/handlers/docker.py'],1,626080676867145f9fd4581af823c86db82d6482,bp/magnum-backend-docker,"import docker from docker import tls from oslo.config import cfg CONF = cfg.CONF docker_opts = [ cfg.StrOpt('host_url', default=""unix:///var/run/docker.sock"", help='tcp://host:port to bind/connect to or' 'unix://path/to/socker to use'), cfg.BoolOpt('api_secure', default=False, help='If set, ignore any SSL validation issues'), cfg.StrOpt('ca_file', help='Location of CA certificate file for ' 'securing docker api requests (tlscacert).'), cfg.StrOpt('cert_file', help='Location of TLS certificate file for ' 'securing docker api requests (tlscert).'), cfg.StrOpt('key_file', help='Location of TLS private key file for ' 'securing docker api requests (tlskey).'), ] CONF.register_opts(docker_opts, 'docker') class Handler(object): def __init__(self, url): if (CONF.docker.cert_file or CONF.docker.key_file): client_cert = (CONF.docker.cert_file, CONF.docker.key_file) else: client_cert = None if (CONF.docker.ca_file or CONF.docker.api_insecure or client_cert): tls_Config = tls.TLSConfig( client_cert=client_cert, ca_Cert=CONF.docker.ca_file, verify=CONF.docker.api_insecure) else: tls_config = None self.client = Client(base_url=url, tls=tls_config) def encode_utf8(self, value): return unicode(value).encode('utf-8') def container_create(self, uuid, image_name, command): LOG.debug(""container_create %s contents=%s"" % (uuid, image_name)) self.client.inspect_image(self._encode_utf8(image_name)) container_id = self.client.create_container(image_name, command) self.container_start(container_id) def container_list(self): container_list = self.client.containers() return container_list def container_delete(self, uuid): def container_show(self, uuid): def container_reboot(self, uuid): def container_stop(self, uuid): self.client.start(uuid) def container_start(self, uuid): self.client.start(uuid) def container_pause(self, uuid): def container_unpause(self, uuid): def container_logs(self, uuid): def container_execute(self, uuid):","class Handler(object): def __init__(self): def container_create(uuid, contents): LOG.debug(""container_create %s contents=%s"" % (uuid, contents)) def container_list(): def container_delete(uuid): def container_show(uuid): def container_reboot(uuid): def container_stop(uuid): def container_start(uuid): def container_pause(uuid): def container_unpause(uuid): def container_logs(uuid): def container_execute(uuid):",66,13
openstack%2Fmagnum~master~I4d5c091ee8afc3b3232e972f975bcec413daa678,openstack/magnum,master,I4d5c091ee8afc3b3232e972f975bcec413daa678,Added docker backend to magnum in handler.,ABANDONED,2014-12-12 18:07:04.000000000,2014-12-22 15:23:41.000000000,,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 7494}, {'_account_id': 11105}]","[{'number': 1, 'created': '2014-12-12 18:07:04.000000000', 'files': ['magnum/conductor/handlers/docker_agent.py', 'magnum/conductor/handlers/docker.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/dba62059e7a2458ed74e5ad38256bb422ebc7d92', 'message': 'Added docker backend to magnum in handler.\n\nChange-Id: I4d5c091ee8afc3b3232e972f975bcec413daa678\nImplements: blueprint magnum-backend-docker\n'}]",5,141448,dba62059e7a2458ed74e5ad38256bb422ebc7d92,6,4,1,8580,,,0,"Added docker backend to magnum in handler.

Change-Id: I4d5c091ee8afc3b3232e972f975bcec413daa678
Implements: blueprint magnum-backend-docker
",git fetch https://review.opendev.org/openstack/magnum refs/changes/48/141448/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/conductor/handlers/docker_agent.py', 'magnum/conductor/handlers/docker.py']",2,dba62059e7a2458ed74e5ad38256bb422ebc7d92,bp/magnum-backend-docker,,"# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Magnum Docker RPC handler."""""" from magnum.openstack.common import log as logging LOG = logging.getLogger(__name__) # These are the backend operations. They are executed by the backend # service. API calls via AMQP (within the ReST API) trigger the handlers to # be called. class Handler(object): def __init__(self): super(Handler, self).__init__() # Container operations def container_create(uuid, contents): LOG.debug(""container_create %s contents=%s"" % (uuid, contents)) def container_list(): LOG.debug(""container_list"") # return container list dict def container_delete(uuid): LOG.debug(""cotainer_delete %s"" % uuid) def container_show(uuid): LOG.debug(""container_show %s"" % uuid) # return container information dict def container_reboot(uuid): LOG.debug(""container_reboot %s"" % uuid) def container_stop(uuid): LOG.debug(""container_stop %s"" % uuid) def container_start(uuid): LOG.debug(""container_start %s"" % uuid) def container_pause(uuid): LOG.debug(""container_pause %s"" % uuid) def container_unpause(uuid): LOG.debug(""container_unpause %s"" % uuid) def container_logs(uuid): LOG.debug(""container_logs %s"" % uuid) def container_execute(uuid): LOG.debug(""container_execute %s"" % uuid) ",127,63
openstack%2Fmagnum~master~I989828940ba202ff983f386b285eac8b22a47bb4,openstack/magnum,master,I989828940ba202ff983f386b285eac8b22a47bb4,Docker has implemented in the conductor/handlers.,ABANDONED,2014-12-18 18:13:03.000000000,2014-12-22 15:23:22.000000000,,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 7494}, {'_account_id': 8580}, {'_account_id': 12385}]","[{'number': 1, 'created': '2014-12-18 18:13:03.000000000', 'files': ['magnum/conductor/handlers/docker.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/79e1fc01147dd3f68f1521964b5875ba401e92c9', 'message': 'Docker has implemented in the conductor/handlers.\n\nChange-Id: I989828940ba202ff983f386b285eac8b22a47bb4\nImplements: blueprint magnum-backend-docker\n'}]",4,142865,79e1fc01147dd3f68f1521964b5875ba401e92c9,9,5,1,8580,,,0,"Docker has implemented in the conductor/handlers.

Change-Id: I989828940ba202ff983f386b285eac8b22a47bb4
Implements: blueprint magnum-backend-docker
",git fetch https://review.opendev.org/openstack/magnum refs/changes/65/142865/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/conductor/handlers/docker.py'],1,79e1fc01147dd3f68f1521964b5875ba401e92c9,bp/magnum-backend-docker,"from docker import Client from docker import tls from oslo.config import cfg CONF = cfg.CONF docker_opts = [ cfg.StrOpt('host_url', default=""unix:///var/run/docker.sock"", help='tcp://host:port to bind/connect to or' 'unix://path/to/socker to use'), cfg.BoolOpt('api_secure', default=False, help='If set, ignore any SSL validation issues'), cfg.StrOpt('ca_file', help='Location of CA certificate file for ' 'securing docker api requests (tlscacert).'), cfg.StrOpt('cert_file', help='Location of TLS certificate file for ' 'securing docker api requests (tlscert).'), cfg.StrOpt('key_file', help='Location of TLS private key file for ' 'securing docker api requests (tlskey).'), ] CONF.register_opts(docker_opts, 'docker') class Handler(object): def __init__(self, url): if (CONF.docker.cert_file or CONF.docker.key_file): client_cert = (CONF.docker.cert_file, CONF.docker.key_file) else: client_cert = None if (CONF.docker.ca_file or CONF.docker.api_insecure or client_cert): tls_config = tls.TLSConfig( client_cert=client_cert, ca_Cert=CONF.docker.ca_file, verify=CONF.docker.api_insecure) else: tls_config = None self.client = Client(base_url=url, tls=tls_config) def encode_utf8(self, value): return unicode(value).encode('utf-8') def container_create(self, uuid, image_name, command): LOG.debug(""container_create %s contents=%s"" % (uuid, image_name)) self.client.inspect_image(self._encode_utf8(image_name)) container_id = self.client.create_container(image_name, command) self.container_start(container_id) def container_list(self): container_list = self.client.containers() return container_list def container_delete(self, uuid): def container_show(self, uuid): def container_reboot(self, uuid): def container_stop(self, uuid): self.client.start(uuid) def container_start(self, uuid): self.client.start(uuid) def container_pause(self, uuid): def container_unpause(self, uuid): def container_logs(self, uuid): def container_execute(self, uuid):","class Handler(object): def __init__(self): def container_create(uuid, contents): LOG.debug(""container_create %s contents=%s"" % (uuid, contents)) def container_list(): def container_delete(uuid): def container_show(uuid): def container_reboot(uuid): def container_stop(uuid): def container_start(uuid): def container_pause(uuid): def container_unpause(uuid): def container_logs(uuid): def container_execute(uuid):",66,13
openstack%2Fheat~master~Ieed667073fa1ec4eb864e195860266355e6f9d1c,openstack/heat,master,Ieed667073fa1ec4eb864e195860266355e6f9d1c,Fix tox for integration tests,MERGED,2014-12-22 12:41:17.000000000,2014-12-22 15:16:47.000000000,2014-12-22 15:16:46.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-12-22 12:41:17.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/heat/commit/15777b2973dcb36e95b8e8088836a4be5fb10a18', 'message': 'Fix tox for integration tests\n\nBefore providing tox with regex to run specific integration tests\nwas broken.\n\nChange-Id: Ieed667073fa1ec4eb864e195860266355e6f9d1c\n'}]",0,143434,15777b2973dcb36e95b8e8088836a4be5fb10a18,8,3,1,13323,,,0,"Fix tox for integration tests

Before providing tox with regex to run specific integration tests
was broken.

Change-Id: Ieed667073fa1ec4eb864e195860266355e6f9d1c
",git fetch https://review.opendev.org/openstack/heat refs/changes/34/143434/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,15777b2973dcb36e95b8e8088836a4be5fb10a18,tox-integrationtests, python setup.py testr --slowest --testr-args='--concurrency=1 ^heat_integrationtests.*{posargs}', python setup.py testr --slowest --testr-args='--concurrency=1 ^heat_integrationtests{posargs}',1,1
openstack%2Ftempest~master~I4be9678656d0da5689070959c7f56c2ed903dd69,openstack/tempest,master,I4be9678656d0da5689070959c7f56c2ed903dd69,Add VolumeClient for cleanup,MERGED,2014-12-17 08:55:11.000000000,2014-12-22 15:16:38.000000000,2014-12-22 15:16:37.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 08:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/89381da5638c2026b354c2a81fc996e63a3b4848', 'message': 'Add VolumeClient for cleanup\n\nIn volume clients, there is a lot of duplicated code for\nsetting CONF. This patch adds VolumeClient for removing them.\n\nChange-Id: I4be9678656d0da5689070959c7f56c2ed903dd69\n'}, {'number': 2, 'created': '2014-12-17 12:55:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e654b2db3813e4743dc65ac477370246df34c576', 'message': 'Add VolumeClient for cleanup\n\nIn volume clients, there is a lot of duplicated code for\nsetting CONF. This patch adds VolumeClient for removing them.\n\nChange-Id: I4be9678656d0da5689070959c7f56c2ed903dd69\n'}, {'number': 3, 'created': '2014-12-18 04:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6045aa5e4fef9e9fa3878f0ff79b738826f5516a', 'message': 'Add VolumeClient for cleanup\n\nIn volume clients, there is a lot of duplicated code for\nsetting CONF. This patch adds VolumeClient for removing them.\n\nChange-Id: I4be9678656d0da5689070959c7f56c2ed903dd69\n'}, {'number': 4, 'created': '2014-12-19 11:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b5b0751ecb1931cb3a7140b35ffb9b011d45e147', 'message': 'Add VolumeClient for cleanup\n\nIn volume clients, there is a lot of duplicated code for\nsetting CONF. This patch adds VolumeClient for removing them.\n\nChange-Id: I4be9678656d0da5689070959c7f56c2ed903dd69\n'}, {'number': 5, 'created': '2014-12-21 13:13:18.000000000', 'files': ['tempest/services/volume/json/qos_client.py', 'tempest/services/volume/json/snapshots_client.py', 'tempest/services/volume/json/admin/volume_hosts_client.py', 'tempest/services/volume/json/admin/volume_services_client.py', 'tempest/services/volume/json/extensions_client.py', 'tempest/services/volume/json/volumes_client.py', 'tempest/services/volume/json/backups_client.py', 'tempest/services/volume/json/availability_zone_client.py', 'tempest/services/volume/json/admin/volume_types_client.py', 'tempest/services/volume/json/base.py', 'tempest/services/volume/json/admin/volume_quotas_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/a39d0be90d3843a6738d4b4125462d89f7cefc5f', 'message': 'Add VolumeClient for cleanup\n\nIn volume clients, there is a lot of duplicated code for\nsetting CONF. This patch adds VolumeClient for removing them.\n\nChange-Id: I4be9678656d0da5689070959c7f56c2ed903dd69\n'}]",0,142385,a39d0be90d3843a6738d4b4125462d89f7cefc5f,25,5,5,6167,,,0,"Add VolumeClient for cleanup

In volume clients, there is a lot of duplicated code for
setting CONF. This patch adds VolumeClient for removing them.

Change-Id: I4be9678656d0da5689070959c7f56c2ed903dd69
",git fetch https://review.opendev.org/openstack/tempest refs/changes/85/142385/4 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/volume/json/qos_client.py', 'tempest/services/volume/json/snapshots_client.py', 'tempest/services/volume/json/admin/volume_hosts_client.py', 'tempest/services/volume/json/admin/volume_services_client.py', 'tempest/services/volume/json/extensions_client.py', 'tempest/services/volume/json/volumes_client.py', 'tempest/services/volume/json/backups_client.py', 'tempest/services/volume/json/availability_zone_client.py', 'tempest/services/volume/json/admin/volume_types_client.py', 'tempest/services/volume/json/base.py', 'tempest/services/volume/json/admin/volume_quotas_client.py']",11,89381da5638c2026b354c2a81fc996e63a3b4848,rest-client,from tempest.services.volume.json import base class BaseVolumeQuotasClientJSON(base.VolumeClient):,"from tempest.common import rest_client from tempest import config CONF = config.CONF class BaseVolumeQuotasClientJSON(rest_client.RestClient): def __init__(self, auth_provider): super(BaseVolumeQuotasClientJSON, self).__init__(auth_provider) self.service = CONF.volume.catalog_type self.build_interval = CONF.volume.build_interval self.build_timeout = CONF.volume.build_timeout ",52,106
openstack%2Ftempest~master~Ib31e351fe7c3d27824241cf142c213eae287483f,openstack/tempest,master,Ib31e351fe7c3d27824241cf142c213eae287483f,Actually attach a volume to an instance before taking snapshot,MERGED,2014-12-11 00:14:56.000000000,2014-12-22 15:16:29.000000000,2014-12-22 15:16:28.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 6983}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 9176}, {'_account_id': 10115}, {'_account_id': 10385}, {'_account_id': 13915}]","[{'number': 1, 'created': '2014-12-11 00:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/deb90daa00b2c872aaa75e598a6d7c2f7da180e9', 'message': 'Actually attach a volume to an instance before taking snapshot\n\nIn the test test_snapshot_create_with_volume_in_use, the test calls Cinder\n""os-attach"" for attaching a volume. The ""os-attach"" to tell Cinder the\nvolume is attached, but the API doesn\'t actually attach the volume to an\ninstance.(Only update volume status in DB)\n\nThis is not right test case for taking a snapshot with in-use volume.\nIn this test, Nova ""os-volume_attachment"" should be called for volume\nattachment.\n\nAlso, some Cinder drivers fails assisted snapshot due to this problem.\nIn order to perform the snapshot properly, this fix is needed.\n\nCloses-Bug #1401110\nChange-Id: Ib31e351fe7c3d27824241cf142c213eae287483f\n'}, {'number': 2, 'created': '2014-12-12 21:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4efab57f97720652b05275cd11c09af1a6a229b6', 'message': 'Actually attach a volume to an instance before taking snapshot\n\nIn the test test_snapshot_create_with_volume_in_use, the test calls Cinder\n""os-attach"" for attaching a volume. The ""os-attach"" to tell Cinder the\nvolume is attached, but the API doesn\'t actually attach the volume to an\ninstance.(Only update volume status in DB)\n\nThis is not right test case for taking a snapshot with in-use volume.\nIn this test, Nova ""os-volume_attachment"" should be called for volume\nattachment.\n\nAlso, some Cinder drivers fails assisted snapshot due to this problem.\nIn order to perform the snapshot properly, this fix is needed.\n\nCloses-Bug #1401110\nChange-Id: Ib31e351fe7c3d27824241cf142c213eae287483f\n'}, {'number': 3, 'created': '2014-12-15 19:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/076afa7a924a1629e6bfcb5a1159f3eefe31eade', 'message': 'Actually attach a volume to an instance before taking snapshot\n\nIn the test test_snapshot_create_with_volume_in_use, the test calls Cinder\n""os-attach"" for attaching a volume. The ""os-attach"" to tell Cinder the\nvolume is attached, but the API doesn\'t actually attach the volume to an\ninstance.(Only update volume status in DB)\n\nThis is not right test case for taking a snapshot with in-use volume.\nIn this test, Nova ""os-volume_attachment"" should be called for volume\nattachment.\n\nAlso, some Cinder drivers fails assisted snapshot due to this problem.\nIn order to perform the snapshot properly, this fix is needed.\n\nCloses-Bug #1401110\nChange-Id: Ib31e351fe7c3d27824241cf142c213eae287483f\n'}, {'number': 4, 'created': '2014-12-18 21:59:09.000000000', 'files': ['tempest/api/volume/test_volumes_snapshots.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/ab667960ef337538cf777bb0f325cb5d0e865d76', 'message': 'Actually attach a volume to an instance before taking snapshot\n\nIn the test test_snapshot_create_with_volume_in_use, the test calls Cinder\n""os-attach"" for attaching a volume. The ""os-attach"" to tell Cinder the\nvolume is attached, but the API doesn\'t actually attach the volume to an\ninstance.(Only update volume status in DB)\n\nThis is not right test case for taking a snapshot with in-use volume.\nIn this test, Nova ""os-volume_attachment"" should be called for volume\nattachment.\n\nAlso, some Cinder drivers fails assisted snapshot due to this problem.\nIn order to perform the snapshot properly, this fix is needed.\n\nCloses-Bug #1401110\nChange-Id: Ib31e351fe7c3d27824241cf142c213eae287483f\n'}]",4,140873,ab667960ef337538cf777bb0f325cb5d0e865d76,50,10,4,10115,,,0,"Actually attach a volume to an instance before taking snapshot

In the test test_snapshot_create_with_volume_in_use, the test calls Cinder
""os-attach"" for attaching a volume. The ""os-attach"" to tell Cinder the
volume is attached, but the API doesn't actually attach the volume to an
instance.(Only update volume status in DB)

This is not right test case for taking a snapshot with in-use volume.
In this test, Nova ""os-volume_attachment"" should be called for volume
attachment.

Also, some Cinder drivers fails assisted snapshot due to this problem.
In order to perform the snapshot properly, this fix is needed.

Closes-Bug #1401110
Change-Id: Ib31e351fe7c3d27824241cf142c213eae287483f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/73/140873/4 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/volume/test_volumes_snapshots.py'],1,deb90daa00b2c872aaa75e598a6d7c2f7da180e9,bug/1401110," _, body = self.servers_client.attach_volume( server['id'], self.volume_origin['id'], mountpoint)"," _, body = self.volumes_client.attach_volume( self.volume_origin['id'], server['id'], mountpoint)",2,2
openstack%2Fhorizon~master~Ie9f228feebd31fc76adc62102a84235a93b23930,openstack/horizon,master,Ie9f228feebd31fc76adc62102a84235a93b23930,add missing icons for Project > Images filter,MERGED,2014-09-09 21:23:20.000000000,2014-12-22 15:15:04.000000000,2014-12-22 15:15:03.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4978}, {'_account_id': 6635}, {'_account_id': 6763}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 9981}, {'_account_id': 11592}, {'_account_id': 11880}, {'_account_id': 11881}, {'_account_id': 11941}, {'_account_id': 12355}, {'_account_id': 13086}, {'_account_id': 13325}, {'_account_id': 14107}]","[{'number': 1, 'created': '2014-09-09 21:23:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4ac397fe2d55cdf516f5e5c06dc9f61fa8966e5d', 'message': 'add missing icons for Project > Images filter\n\nThe fixed filter (Project | Shared with Me | Public) should have\nicons like before the Bootstrap 3 upgrade.\n\nChange-Id: Ie9f228feebd31fc76adc62102a84235a93b23930\nCloses-Bug: #1367442\n'}, {'number': 2, 'created': '2014-09-10 21:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6a96f0a2f60f273826ea58fdb0903bfc50cf0f37', 'message': 'add missing icons for Project > Images filter\n\nThe fixed filter (Project | Shared with Me | Public) should have\nicons like before the Bootstrap 3 upgrade.\n\nChange-Id: Ie9f228feebd31fc76adc62102a84235a93b23930\nCloses-Bug: #1367442\n'}, {'number': 3, 'created': '2014-09-12 22:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bbab1b50f212a48142d0c55c3cb29fa3e0f9158a', 'message': 'add missing icons for Project > Images filter\n\nThe fixed filter (Project | Shared with Me | Public) should have\nicons like before the Bootstrap 3 upgrade.  Using icons from\nthe new font-awesome package instead of Bootstrap.\n\nAlso fix the tabbing in the html file.\n\nChange-Id: Ie9f228feebd31fc76adc62102a84235a93b23930\nCloses-Bug: #1367442\n'}, {'number': 4, 'created': '2014-10-03 23:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1b2ed520c3f9162b787a85855158424129338a3d', 'message': 'add missing icons for Project > Images filter\n\nThe fixed filter (Project | Shared with Me | Public) should have\nicons like before the Bootstrap 3 upgrade.  Using icons from\nthe new font-awesome package instead of Bootstrap.\n\nAlso fix the tabbing in the html file.\n\nChange-Id: Ie9f228feebd31fc76adc62102a84235a93b23930\nCloses-Bug: #1367442\n'}, {'number': 5, 'created': '2014-10-08 17:02:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6f4c39931347a022a9e20e3e513153175d955c14', 'message': 'add missing icons for Project > Images filter\n\nThe fixed filter (Project | Shared with Me | Public) should have\nicons like before the Bootstrap 3 upgrade.  Using icons from\nthe new font-awesome package instead of Bootstrap.\n\nAlso fix the tabbing in the html file.\n\nChange-Id: Ie9f228feebd31fc76adc62102a84235a93b23930\nCloses-Bug: #1367442\n'}, {'number': 6, 'created': '2014-10-08 21:12:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4b0d7f4563924d3214676eec0ff158db7524fb20', 'message': 'add missing icons for Project > Images filter\n\nThe fixed filter (Project | Shared with Me | Public) should have\nicons like before the Bootstrap 3 upgrade.  Using icons from\nthe new font-awesome package instead of Bootstrap.\n\nAlso fix the tabbing in the html file.\n\nChange-Id: Ie9f228feebd31fc76adc62102a84235a93b23930\nCloses-Bug: #1367442\n'}, {'number': 7, 'created': '2014-10-14 19:35:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e32ec105817cbc8162306ec142a3129d72280c27', 'message': 'add missing icons for Project > Images filter\n\nThe fixed filter (Project | Shared with Me | Public) should have\nicons like before the Bootstrap 3 upgrade.  Using icons from\nthe new font-awesome package instead of Bootstrap.\n\nAlso fix the tabbing in the html file.\n\nChange-Id: Ie9f228feebd31fc76adc62102a84235a93b23930\nCloses-Bug: #1367442\n'}, {'number': 8, 'created': '2014-12-09 00:54:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/05641144225275bcede7ddbd065e71dc28727c7a', 'message': 'add missing icons for Project > Images filter\n\nThe fixed filter (Project | Shared with Me | Public) should have icons.\nUsing font awesome icons.\n\nAlso fix the tabbing in the html file.\n\nChange-Id: Ie9f228feebd31fc76adc62102a84235a93b23930\nCloses-Bug: #1367442\n'}, {'number': 9, 'created': '2014-12-11 22:00:54.000000000', 'files': ['openstack_dashboard/dashboards/project/images/images/tables.py', 'horizon/templates/horizon/common/_data_table_table_actions.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d0254a859b6e9ee2443dddb15a3bebb6362498e3', 'message': 'add missing icons for Project > Images filter\n\nThe fixed filter (Project | Shared with Me | Public) should have icons.\nUsing font awesome icons.\n\nAlso fix the tabbing in the html file.\n\nChange-Id: Ie9f228feebd31fc76adc62102a84235a93b23930\nCloses-Bug: #1367442\n'}]",3,120237,d0254a859b6e9ee2443dddb15a3bebb6362498e3,56,16,9,9622,,,0,"add missing icons for Project > Images filter

The fixed filter (Project | Shared with Me | Public) should have icons.
Using font awesome icons.

Also fix the tabbing in the html file.

Change-Id: Ie9f228feebd31fc76adc62102a84235a93b23930
Closes-Bug: #1367442
",git fetch https://review.opendev.org/openstack/horizon refs/changes/37/120237/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/images/images/tables.py', 'horizon/templates/horizon/common/_data_table_table_actions.html']",2,4ac397fe2d55cdf516f5e5c06dc9f61fa8966e5d,bug/1367442," <button name=""{{ filter.get_param_name }}"" type=""submit"" value=""{{ button.value }}"" class=""btn btn-default btn-sm{% ifequal button.value filter.filter_string %} active{% endifequal %}"">{% if button.icon %}<span class=""glyphicon {{ button.icon }}""></span> {% endif %}{{ button.text }}{% if button.count >= 0 %} ({{ button.count }}){% endif %}</button>"," <button name=""{{ filter.get_param_name }}"" type=""submit"" value=""{{ button.value }}"" class=""btn btn-default btn-sm{% ifequal button.value filter.filter_string %} active{% endifequal %}"">{% if button.icon %}<i class=""{{ button.icon }}""></i> {% endif %}{{ button.text }}{% if button.count >= 0 %} ({{ button.count }}){% endif %}</button>",5,4
openstack%2Ftempest~master~Iefdc45555beb2ff0807925efc7fc992e30f14899,openstack/tempest,master,Iefdc45555beb2ff0807925efc7fc992e30f14899,Test wrong IP version of prefix in security rule,MERGED,2014-11-21 12:14:56.000000000,2014-12-22 15:14:46.000000000,2014-12-22 15:14:44.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 6524}, {'_account_id': 6685}, {'_account_id': 6983}, {'_account_id': 7249}, {'_account_id': 7350}, {'_account_id': 8576}, {'_account_id': 8767}, {'_account_id': 8871}, {'_account_id': 10257}, {'_account_id': 10385}, {'_account_id': 10969}, {'_account_id': 12632}, {'_account_id': 13753}]","[{'number': 1, 'created': '2014-11-21 12:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ff044749b5c89be07a4d0d408e5be178c131315d', 'message': 'Test wrong IP version of prefix in security rule\n\nNegative tests combines wrong sombination of ethertype and\nIP prefix arguments in security rule creating. Shall be BadRequest\nresponse and appropriate error message.\n\nChange-Id: Iefdc45555beb2ff0807925efc7fc992e30f14899\n'}, {'number': 2, 'created': '2014-11-21 14:34:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b6cea33e7259ee6a04cd6e8798ab8c24d6984018', 'message': 'Test wrong IP version of prefix in security rule\n\nNegative tests combines wrong sombination of ethertype and\nIP prefix arguments in security rule creating. Shall be BadRequest\nresponse and appropriate error message.\n\nChange-Id: Iefdc45555beb2ff0807925efc7fc992e30f14899\n'}, {'number': 3, 'created': '2014-11-26 23:10:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/15f15a206f8192fc640ed2e8d12479b429600bd2', 'message': 'Test wrong IP version of prefix in security rule\n\nNegative tests combines wrong sombination of ethertype and\nIP prefix arguments in security rule creating. Shall be BadRequest\nresponse and appropriate error message.\n\nChange-Id: Iefdc45555beb2ff0807925efc7fc992e30f14899\n'}, {'number': 4, 'created': '2014-11-27 07:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/de5ec56e040ed5553fa08e4f60445299a3a7aa1b', 'message': 'Test wrong IP version of prefix in security rule\n\nNegative tests combines wrong combination of ethertype and\nIP prefix arguments in security rule creating. Shall be BadRequest\nresponse and appropriate error message.\n\nChange-Id: Iefdc45555beb2ff0807925efc7fc992e30f14899'}, {'number': 5, 'created': '2014-12-18 13:09:53.000000000', 'files': ['tempest/api/network/test_security_groups_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b25c5b80b33a050072e8589d8455c8620d9fc01b', 'message': 'Test wrong IP version of prefix in security rule\n\nNegative tests combines wrong sombination of ethertype and\nIP prefix arguments in security rule creating. Shall be BadRequest\nresponse and appropriate error message.\n\nChange-Id: Iefdc45555beb2ff0807925efc7fc992e30f14899\n'}]",5,136316,b25c5b80b33a050072e8589d8455c8620d9fc01b,41,17,5,10969,,,0,"Test wrong IP version of prefix in security rule

Negative tests combines wrong sombination of ethertype and
IP prefix arguments in security rule creating. Shall be BadRequest
response and appropriate error message.

Change-Id: Iefdc45555beb2ff0807925efc7fc992e30f14899
",git fetch https://review.opendev.org/openstack/tempest refs/changes/16/136316/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/test_security_groups_negative.py'],1,ff044749b5c89be07a4d0d408e5be178c131315d,negsec," @test.attr(type=['negative', 'gate']) def test_create_security_group_rule_wrong_ip_prefix_version(self): group_create_body, _ = self._create_security_group() # Create rule with bad remote_ip_prefix pairs = ({'ethertype': 'IPv6', 'ip_prefix': CONF.network.tenant_network_cidr}, {'ethertype': 'IPv4', 'ip_prefix': CONF.network.tenant_network_v6_cidr}) for pair in pairs: self.assertRaisesRegexp( exceptions.BadRequest, ""Conflicting value ethertype"", self.client.create_security_group_rule, security_group_id=group_create_body['security_group']['id'], protocol='tcp', direction='ingress', ethertype=pair['ethertype'], remote_ip_prefix=pair['ip_prefix'])",,18,0
openstack%2Fec2-api~master~Ief2021fb041907a83a43765165fba29574ad2bd7,openstack/ec2-api,master,Ief2021fb041907a83a43765165fba29574ad2bd7,Refactor describe methods to use Describer class,MERGED,2014-12-22 10:56:46.000000000,2014-12-22 15:14:28.000000000,2014-12-22 15:14:28.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-12-22 10:56:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/bafd8c27ccda62073898dce28fffd1081d807961', 'message': 'Refactor describe methods to use Describer class\n\nExcept instances due their complexity\n\nChange-Id: Ief2021fb041907a83a43765165fba29574ad2bd7\n'}, {'number': 2, 'created': '2014-12-22 11:11:50.000000000', 'files': ['ec2api/api/network_interface.py', 'ec2api/api/volume.py', 'ec2api/api/dhcp_options.py', 'ec2api/api/subnet.py', 'ec2api/api/internet_gateway.py', 'ec2api/api/common.py', 'ec2api/api/key_pair.py', 'ec2api/api/vpc.py', 'ec2api/api/route_table.py', 'ec2api/api/address.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/807d36b64a162c9723d2ffd19a790472164361c9', 'message': 'Refactor describe methods to use Describer class\n\nExcept instances due their complexity\n\nChange-Id: Ief2021fb041907a83a43765165fba29574ad2bd7\n'}]",0,143422,807d36b64a162c9723d2ffd19a790472164361c9,8,3,2,10224,,,0,"Refactor describe methods to use Describer class

Except instances due their complexity

Change-Id: Ief2021fb041907a83a43765165fba29574ad2bd7
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/22/143422/2 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/network_interface.py', 'ec2api/api/volume.py', 'ec2api/api/dhcp_options.py', 'ec2api/api/subnet.py', 'ec2api/api/common.py', 'ec2api/api/internet_gateway.py', 'ec2api/api/key_pair.py', 'ec2api/api/vpc.py', 'ec2api/api/route_table.py', 'ec2api/api/address.py']",10,bafd8c27ccda62073898dce28fffd1081d807961,master," FILTER_MAP = {'allocation-id': 'allocationId', 'association-id': 'associationId', 'domain': 'domain', 'instance-id': 'instanceId', 'network-interface-id': 'networkInterfaceId', 'network-interface-owner-id': 'networkInterfaceOwnerId', 'privateIpAddress': 'privateIpAddress', 'public-ip': 'publicIp'}", FILTER_MAP = {'vpc-id': 'vpcId'},185,133
openstack%2Fec2-api~master~Ifcc52758bed9f855928d56527c2a0edb4d5c113e,openstack/ec2-api,master,Ifcc52758bed9f855928d56527c2a0edb4d5c113e,Tags implementation,MERGED,2014-12-22 05:39:04.000000000,2014-12-22 15:08:41.000000000,2014-12-22 15:08:41.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-12-22 05:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/bc1e3fd536db82f8596c036badf55f62f84f69e4', 'message': 'Tags implementation\n\nChange-Id: Ifcc52758bed9f855928d56527c2a0edb4d5c113e\n'}, {'number': 2, 'created': '2014-12-22 05:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/e60059e1f4bd746ee6ac42305637e15ec8a63829', 'message': 'Tags implementation\n\nChange-Id: Ifcc52758bed9f855928d56527c2a0edb4d5c113e\n'}, {'number': 3, 'created': '2014-12-22 06:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/f8995f0e567fe8ec1773248a4048089900a3c058', 'message': 'Tags implementation\n\nChange-Id: Ifcc52758bed9f855928d56527c2a0edb4d5c113e\n'}, {'number': 4, 'created': '2014-12-22 10:56:46.000000000', 'files': ['ec2api/api/tag.py', 'ec2api/api/__init__.py', 'ec2api/api/cloud.py', 'ec2api/db/api.py', 'ec2api/db/sqlalchemy/api.py', 'ec2api/db/sqlalchemy/models.py', 'ec2api/api/ec2utils.py', 'ec2api/exception.py', 'ec2api/db/sqlalchemy/migrate_repo/versions/001_juno.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/01e20e6cfac70d1585104535e5e207974cd82aff', 'message': 'Tags implementation\n\nChange-Id: Ifcc52758bed9f855928d56527c2a0edb4d5c113e\n'}]",0,143364,01e20e6cfac70d1585104535e5e207974cd82aff,15,4,4,10224,,,0,"Tags implementation

Change-Id: Ifcc52758bed9f855928d56527c2a0edb4d5c113e
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/64/143364/3 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/tag.py', 'ec2api/api/__init__.py', 'ec2api/api/cloud.py', 'ec2api/db/api.py', 'ec2api/db/sqlalchemy/api.py', 'ec2api/db/sqlalchemy/models.py', 'ec2api/api/ec2utils.py', 'ec2api/exception.py', 'ec2api/db/sqlalchemy/migrate_repo/versions/001_juno.py']",9,bc1e3fd536db82f8596c036badf55f62f84f69e4,master," tags = Table('tags', meta, Column(""project_id"", String(length=64)), Column(""item_id"", String(length=30)), Column(""key"", String(length=127)), Column(""value"", String(length=255)), PrimaryKeyConstraint('project_id', 'item_id', 'key'), mysql_engine=""InnoDB"", mysql_charset=""utf8"" ) tags.create() ",,281,34
openstack%2Fneutron~master~Ie8a15318e71ea47cccad3b788751d914d51cbf18,openstack/neutron,master,Ie8a15318e71ea47cccad3b788751d914d51cbf18,Update L3 agent drivers singletons to look at new agent,MERGED,2014-12-21 14:24:35.000000000,2014-12-22 15:07:48.000000000,2014-12-22 10:57:30.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 7448}, {'_account_id': 7743}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 12040}, {'_account_id': 14208}]","[{'number': 1, 'created': '2014-12-21 14:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1a488ca2133a5f83c56d61030e90709a15ab8b7a', 'message': ""Update L3 agent drivers singletons to look at new agent\n\nL3 agent drivers are singletons. They're created once, and hold\nself.l3_agent. During testing, the agent is tossed away and\nre-built, but the drivers singletons are pointing at the old\nagent, and its old configuration.\n\nChange-Id: Ie8a15318e71ea47cccad3b788751d914d51cbf18\nCloses-Bug: #1404662\n""}, {'number': 2, 'created': '2014-12-21 14:37:45.000000000', 'files': ['neutron/tests/common/agents/l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1e562decdc03295dec4cb37d26162e5d9aa31079', 'message': ""Update L3 agent drivers singletons to look at new agent\n\nL3 agent drivers are singletons. They're created once, and hold\nself.l3_agent. During testing, the agent is tossed away and\nre-built, but the drivers singletons are pointing at the old\nagent, and its old configuration.\n\nChange-Id: Ie8a15318e71ea47cccad3b788751d914d51cbf18\nCloses-Bug: #1404662\n""}]",2,143300,1e562decdc03295dec4cb37d26162e5d9aa31079,30,20,2,8873,,,0,"Update L3 agent drivers singletons to look at new agent

L3 agent drivers are singletons. They're created once, and hold
self.l3_agent. During testing, the agent is tossed away and
re-built, but the drivers singletons are pointing at the old
agent, and its old configuration.

Change-Id: Ie8a15318e71ea47cccad3b788751d914d51cbf18
Closes-Bug: #1404662
",git fetch https://review.opendev.org/openstack/neutron refs/changes/00/143300/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/functional/agent/test_l3_agent.py'],1,1a488ca2133a5f83c56d61030e90709a15ab8b7a,bug/1404662, agent.event_observers.observers = set( observer.__class__(agent) for observer in agent.event_observers.observers) ,,4,0
openstack%2Fec2-api~master~I8d85f9fba9c5d2c034a0a1305ce8636b2511bb2b,openstack/ec2-api,master,I8d85f9fba9c5d2c034a0a1305ce8636b2511bb2b,Use image DB items for instances,MERGED,2014-12-21 11:52:34.000000000,2014-12-22 15:03:43.000000000,2014-12-22 15:03:42.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-12-21 11:52:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/c1daa6fc8f98f7805f7b4b8f1a12ac72891c2a72', 'message': 'Use image DB items for instances\n\nChange-Id: I8d85f9fba9c5d2c034a0a1305ce8636b2511bb2b\n'}, {'number': 2, 'created': '2014-12-21 12:04:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/34207619ae9ba7f37cbc976b30eabd10f7bb5903', 'message': 'Use image DB items for instances\n\nChange-Id: I8d85f9fba9c5d2c034a0a1305ce8636b2511bb2b\n'}, {'number': 3, 'created': '2014-12-21 12:12:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/e7447c3778d564c3baecb47d0551939aa14c69f6', 'message': 'Use image DB items for instances\n\nChange-Id: I8d85f9fba9c5d2c034a0a1305ce8636b2511bb2b\n'}, {'number': 4, 'created': '2014-12-21 13:39:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/1ca6f628ecf17d49feba88b198f45d7fae25c108', 'message': 'Use image DB items for instances\n\nChange-Id: I8d85f9fba9c5d2c034a0a1305ce8636b2511bb2b\n'}, {'number': 5, 'created': '2014-12-22 05:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/9dfdb8ee3b78169478f9e723ff7362331a1cbd4c', 'message': 'Use image DB items for instances\n\nChange-Id: I8d85f9fba9c5d2c034a0a1305ce8636b2511bb2b\n'}, {'number': 6, 'created': '2014-12-22 05:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/001fcf1e1b99419475ebcc97c8da984b621b6a87', 'message': 'Use image DB items for instances\n\nChange-Id: I8d85f9fba9c5d2c034a0a1305ce8636b2511bb2b\n'}, {'number': 7, 'created': '2014-12-22 06:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/b29294f01b627224ad6ec28085f18e5527f1fb55', 'message': 'Use image DB items for instances\n\nChange-Id: I8d85f9fba9c5d2c034a0a1305ce8636b2511bb2b\n'}, {'number': 8, 'created': '2014-12-22 10:56:46.000000000', 'files': ['ec2api/api/instance.py', 'ec2api/db/api.py', 'ec2api/db/sqlalchemy/api.py', 'ec2api/tests/fakes.py', 'ec2api/tests/test_instance.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/4f8fdef22e8415232f48189192008cf14a88f7f0', 'message': 'Use image DB items for instances\n\nChange-Id: I8d85f9fba9c5d2c034a0a1305ce8636b2511bb2b\n'}]",0,143296,4f8fdef22e8415232f48189192008cf14a88f7f0,23,4,8,10224,,,0,"Use image DB items for instances

Change-Id: I8d85f9fba9c5d2c034a0a1305ce8636b2511bb2b
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/96/143296/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/instance.py', 'ec2api/db/api.py', 'ec2api/db/sqlalchemy/api.py', 'ec2api/tests/fakes.py', 'ec2api/tests/test_instance.py']",5,c1daa6fc8f98f7805f7b4b8f1a12ac72891c2a72,master,"from ec2api.tests.fakes import ID_OS_IMAGE_1 self.db_api.get_item_ids.return_value = [ (fakes.ID_EC2_IMAGE_1, fakes.ID_OS_IMAGE_1)] self.glance.images.get.return_value = fakes.OSImage(fakes.OS_IMAGE_1) # self.ec2_id_to_glance_id.return_value = 'fake_image_id' # self.glance_id_to_ec2_id.return_value = None params.update({'ImageId': fakes.ID_EC2_IMAGE_1, 'EC2 server', ID_OS_IMAGE_1, fake_flavor, self.db_api.get_item_ids.assert_called_once_with( mock.ANY, 'ami', (fakes.ID_EC2_IMAGE_1,)) self.db_api.get_item_ids.return_value = [ (fakes.ID_EC2_IMAGE_1, fakes.ID_OS_IMAGE_1)] self.glance.images.get.return_value = fakes.OSImage(fakes.OS_IMAGE_1) image={'id': fakes.ID_OS_IMAGE_1}, params.update({'ImageId': fakes.ID_EC2_IMAGE_1, if kind == 'i' else [fakes.DB_IMAGE_1, fakes.DB_IMAGE_2] if kind == 'ami' else [])"," self.glance.images.get.return_value = self.fake_image_class( 'fake_image_id', 'active', {}) self.ec2_id_to_glance_id.return_value = 'fake_image_id' self.glance_id_to_ec2_id.return_value = None params.update({'ImageId': 'ami-00000001', 'EC2 server', 'fake_image_id', fake_flavor, self.glance.images.get.return_value = self.fake_image_class( 'fake_image_id', 'active', {}) self.ec2_id_to_glance_id.return_value = 'fake_image_id' params.update({'ImageId': 'ami-00000001', if kind == 'i' else []) self.glance_id_to_ec2_id.return_value = None",115,50
openstack%2Fec2-api~master~Ia261740fa168f157e62ae3b9ff45861b1bd6473c,openstack/ec2-api,master,Ia261740fa168f157e62ae3b9ff45861b1bd6473c,Extract image manipulation methods,MERGED,2014-12-19 20:00:54.000000000,2014-12-22 15:01:48.000000000,2014-12-22 15:01:47.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-12-19 20:00:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/1a19c9c7f4bda661b0d359d30880f6a2a0673e93', 'message': 'Extract image manipulation methods.\n\nChange-Id: Ia261740fa168f157e62ae3b9ff45861b1bd6473c\n'}, {'number': 2, 'created': '2014-12-19 21:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/690ef54b3da1fb755821ff3c92407f0ab111142d', 'message': 'Extract image manipulation methods.\n\nChange-Id: Ia261740fa168f157e62ae3b9ff45861b1bd6473c\n'}, {'number': 3, 'created': '2014-12-20 13:04:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/0dc7a8a4f4ef5480e2596ce888d4b9adbae84021', 'message': 'Extract image manipulation methods.\n\nChange-Id: Ia261740fa168f157e62ae3b9ff45861b1bd6473c\n'}, {'number': 4, 'created': '2014-12-20 13:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/fa5204d73ad6c2490700000214342a1ee817ebb8', 'message': 'Extract image manipulation methods.\n\nChange-Id: Ia261740fa168f157e62ae3b9ff45861b1bd6473c\n'}, {'number': 5, 'created': '2014-12-20 13:53:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/37d849d321f1741170c5deb933ae19b5f22d3af2', 'message': 'Extract image manipulation methods.\n\nChange-Id: Ia261740fa168f157e62ae3b9ff45861b1bd6473c\n'}, {'number': 6, 'created': '2014-12-20 21:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/caba3cc277cea021f39e89f075c986802b132d8c', 'message': 'Extract image manipulation methods.\n\nChange-Id: Ia261740fa168f157e62ae3b9ff45861b1bd6473c\n'}, {'number': 7, 'created': '2014-12-20 21:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/de66f575e195b3e9bfb0ba8853bc9cf7741c659b', 'message': 'Extract image manipulation methods.\n\nChange-Id: Ia261740fa168f157e62ae3b9ff45861b1bd6473c\n'}, {'number': 8, 'created': '2014-12-21 11:52:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/a853efcaa119545f0e1100fe312fd6c90bfafbf4', 'message': 'Extract image manipulation methods.\n\nChange-Id: Ia261740fa168f157e62ae3b9ff45861b1bd6473c\n'}, {'number': 9, 'created': '2014-12-21 12:04:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/c98580c8e975407054b23ed8124b33ded8750c4d', 'message': 'Extract image manipulation methods.\n\nChange-Id: Ia261740fa168f157e62ae3b9ff45861b1bd6473c\n'}, {'number': 10, 'created': '2014-12-22 05:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/de36e24b69bfd1562fc45636bcc05a041d67ed9d', 'message': 'Extract image manipulation methods\n\nChange-Id: Ia261740fa168f157e62ae3b9ff45861b1bd6473c\n'}, {'number': 11, 'created': '2014-12-22 06:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/d5ebe64c1e997fcc8856a087248694d340244b3b', 'message': 'Extract image manipulation methods\n\nChange-Id: Ia261740fa168f157e62ae3b9ff45861b1bd6473c\n'}, {'number': 12, 'created': '2014-12-22 10:56:46.000000000', 'files': ['ec2api/api/image.py', 'install.sh', 'requirements.txt', 'ec2api/api/instance.py', 'ec2api/api/cloud.py', 'ec2api/cmd/api.py', 'ec2api/api/clients.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/cc05d7afe9ce7c1dbd0c6b03f428fa82db2e3711', 'message': 'Extract image manipulation methods\n\nChange-Id: Ia261740fa168f157e62ae3b9ff45861b1bd6473c\n'}]",4,143172,cc05d7afe9ce7c1dbd0c6b03f428fa82db2e3711,33,4,12,10224,,,0,"Extract image manipulation methods

Change-Id: Ia261740fa168f157e62ae3b9ff45861b1bd6473c
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/72/143172/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/image.py', 'requirements.txt', 'ec2api/api/instance.py', 'ec2api/api/cloud.py']",4,1a19c9c7f4bda661b0d359d30880f6a2a0673e93,master," volume_type (str): The volume type. Not used now. def create_volume(self, context, availability_zone=None, size=None, It's required by AWS but optional for legacy Nova EC2 API. def create_image(self, context, instance_id, name=None, description=None, no_reboot=False, block_device_mapping=None): """"""Creates an EBS-backed AMI from an EBS-backed instance. Args: context (RequestContext): The request context. instance_id (str): The ID of the instance. name (str): A name for the new image. It's required by AWS but optional for legacy Nova EC2 API. description (str): A description for the new image. Not used now. no_reboot (boolean): When the parameter is set to false, EC2 attempts to shut down the instance cleanly before image creation and then reboots the instance. block_device_mapping (list of dict): Dict can contain: device_name (str): The device name exposed to the instance (for example, /dev/sdh or xvdh). virtual_name (str): The virtual device name (ephemeral[0..3]). ebs (dict): Dict can contain: volume_id (str): The ID of the volume (Nova extension). snapshot_id (str): The ID of the snapshot. volume_size (str): The size of the volume, in GiBs. volume_type (str): The volume type. Not used now. delete_on_termination (bool): Indicates whether to delete the volume on instance termination. iops (int): he number of IOPS to provision for the volume. Not used now. encrypted (boolean): Whether the volume is encrypted. Not used now. no_device (str): Suppresses the device mapping. Returns: The ID of the new AMI. """""" return image.create_image(context, instance_id, name, description, no_reboot, block_device_mapping) def register_image(self, context, name=None, image_location=None, description=None, architecture=None, root_device_name=None, block_device_mapping=None, virtualization_type=None, kernel_id=None, ramdisk_id=None, sriov_net_support=None): """"""Registers an AMI. Args: context (RequestContext): The request context. name (str): A name for your AMI. It's required by AWS but optional for legacy Nova EC2 API. image_location (str): The full path to AMI manifest in S3 storage. description (str): A description for your AMI. Not used now. architecture (str): The architecture of the AMI. Not used now. root_device_name (str): The name of the root device block_device_mapping (list of dict): Dict can contain: device_name (str): The device name exposed to the instance (for example, /dev/sdh or xvdh). virtual_name (str): The virtual device name (ephemeral[0..3]). ebs (dict): Dict can contain: volume_id (str): The ID of the volume (Nova extension). snapshot_id (str): The ID of the snapshot. volume_size (str): The size of the volume, in GiBs. volume_type (str): The volume type. Not used now. delete_on_termination (bool): Indicates whether to delete the volume on instance termination. iops (int): he number of IOPS to provision for the volume. Not used now. encrypted (boolean): Whether the volume is encrypted. Not used now. no_device (str): Suppresses the device mapping. virtualization_type (str): The type of virtualization. Not used now. kernel_id (str): The ID of the kernel. Not used now. ramdisk_id (str): The ID of the RAM disk. Not used now. sriov_net_support (str): SR-IOV mode for networking. Not used now. Returns: The ID of the new AMI. """""" return image.register_image(context, name, image_location, description, architecture, root_device_name, block_device_mapping, virtualization_type, kernel_id, ramdisk_id, sriov_net_support) def deregister_image(self, context, image_id): """"""Deregisters the specified AMI. Args: context (RequestContext): The request context. image_id (str): The ID of the AMI. Returns: true if the request succeeds. """""" return image.deregister_image(context, image_id) def update_image(self, context, image_id, **kwargs): """"""Update image metadata (Nova EC2 extension). Args: context (RequestContext): The request context. image_id (str): The ID of the image. **kwargs: Metadata key-value pairs to be added/updated. Returns: The updated image. """""" pass Not used now."," def create_volume(self, context, availability_zone, size=None,",648,37
openstack%2Frally~master~I4aa303565f02929bf52a9907a456334eb723d63d,openstack/rally,master,I4aa303565f02929bf52a9907a456334eb723d63d,Add the benchmark Blogbench for the Virtual Machines,ABANDONED,2014-12-14 23:28:54.000000000,2014-12-22 14:47:33.000000000,,"[{'_account_id': 3}, {'_account_id': 13609}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-14 23:28:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1a6d3f9c63cd1677afb92d2e16a99ae42f0ea0cd', 'message': 'Add the benchmark Blogbench for the Virtual Machines\n\nIntroduce the filesystem benchmark Blogbench [1] that can be used for\nmeasuring the performance of a Virtual Machine by reproducing the load\nof a real-world busy file server.\n\nCo-Authored-By: Tzanetos Balitsaris <tzabal@freebsd.org>\nImplements: blueprint benchmark-vms\nChange-Id: I4aa303565f02929bf52a9907a456334eb723d63d\n'}, {'number': 2, 'created': '2014-12-15 00:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/645be952363ec193c4fe7504dd4446b4e9bc1f76', 'message': 'Add the benchmark Blogbench for the Virtual Machines\n\nIntroduce the filesystem benchmark Blogbench [1] that can be used for\nmeasuring the performance of a Virtual Machine by reproducing the load\nof a real-world busy file server.\n\nCo-Authored-By: Tzanetos Balitsaris <tzabal@freebsd.org>\nImplements: blueprint benchmark-vms\nChange-Id: I4aa303565f02929bf52a9907a456334eb723d63d\n'}, {'number': 3, 'created': '2014-12-15 17:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/44566eb5620d191d3be7b8ef481b59604c99d2c3', 'message': 'Add the benchmark Blogbench for the Virtual Machines\n\nIntroduce the filesystem benchmark Blogbench [1] that can be used for\nmeasuring the performance of a Virtual Machine by reproducing the load\nof a real-world busy file server.\n\nCo-Authored-By: Tzanetos Balitsaris <tzabal@freebsd.org>\nImplements: blueprint benchmark-vms\nChange-Id: I4aa303565f02929bf52a9907a456334eb723d63d\n'}, {'number': 4, 'created': '2014-12-20 16:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/360fdfef462fefbb66c12b0adde79e61ebf6fea5', 'message': 'Add the benchmark Blogbench for the Virtual Machines\n\nIntroduce the filesystem benchmark Blogbench [1] that can be used for\nmeasuring the performance of a Virtual Machine by reproducing the load\nof a real-world busy file server.\n\nCo-Authored-By: Tzanetos Balitsaris <tzabal@freebsd.org>\nImplements: blueprint benchmark-vms\nChange-Id: I4aa303565f02929bf52a9907a456334eb723d63d\n'}, {'number': 5, 'created': '2014-12-20 17:57:55.000000000', 'files': ['rally/benchmark/context/vm/blogbench.sh', 'rally/exceptions.py', 'doc/samples/tasks/scenarios/vm/blogbench.yaml', 'rally/benchmark/scenarios/vm/blogbench_remote.py', 'rally/benchmark/utils.py', 'rally/benchmark/scenarios/vm/blogbench.py', 'rally/benchmark/context/vm/blogbench.py', 'doc/samples/tasks/scenarios/vm/blogbench.json', 'rally-jobs/rally.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/ac7ba9527a11f0c24879d08d9671a9ec6eae1428', 'message': 'Add the benchmark Blogbench for the Virtual Machines\n\nIntroduce the filesystem benchmark Blogbench [1] that can be used for\nmeasuring the performance of a Virtual Machine by reproducing the load\nof a real-world busy file server.\n\nCo-Authored-By: Tzanetos Balitsaris <tzabal@freebsd.org>\nImplements: blueprint benchmark-vms\nChange-Id: I4aa303565f02929bf52a9907a456334eb723d63d\n'}]",0,141672,ac7ba9527a11f0c24879d08d9671a9ec6eae1428,17,3,5,13609,,,0,"Add the benchmark Blogbench for the Virtual Machines

Introduce the filesystem benchmark Blogbench [1] that can be used for
measuring the performance of a Virtual Machine by reproducing the load
of a real-world busy file server.

Co-Authored-By: Tzanetos Balitsaris <tzabal@freebsd.org>
Implements: blueprint benchmark-vms
Change-Id: I4aa303565f02929bf52a9907a456334eb723d63d
",git fetch https://review.opendev.org/openstack/rally refs/changes/72/141672/5 && git format-patch -1 --stdout FETCH_HEAD,"['rally/exceptions.py', 'doc/samples/tasks/scenarios/vm/blogbench.yaml', 'rally/benchmark/utils.py', 'rally/benchmark/scenarios/vm/blogbench.py', 'rally/benchmark/context/vm/blogbench.py', 'doc/samples/tasks/scenarios/vm/blogbench.json', 'rally-jobs/rally.yaml']",7,1a6d3f9c63cd1677afb92d2e16a99ae42f0ea0cd,bp/benchmark-vms,"<<<<<<< HEAD max_failure_percent: 0 BlogbenchScenario.blogbench: - args: flavor: name: ""^vm.fedora$"" use_floatingip: false runner: type: ""constant"" times: 1 concurrency: 1 context: flavors: - flavor_name: ""vm.fedora"" ram: 1024 disk: 4 users: tenants: 1 users_per_tenant: 1 blogbench: image: name: ""Fedora-x86_64-20-20140618-sda"" flavor: name: ""^vm.fedora$"" fixed_network: ""private"" use_floatingip: false",,313,3
openstack%2Frally~master~I35beecd640e9ac5838202ef7845f8c3f703b34fc,openstack/rally,master,I35beecd640e9ac5838202ef7845f8c3f703b34fc,Exclude buggy version of pbr in requirements,ABANDONED,2014-12-22 12:29:51.000000000,2014-12-22 14:46:19.000000000,,"[{'_account_id': 3}, {'_account_id': 9545}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-22 12:29:51.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/rally/commit/0382b89db9cabeeb28575a3996d83d2a1a349e41', 'message': 'Exclude buggy version of pbr in requirements\n\nOnly 0.10.5 version of pbr is affected\nhttps://bugs.launchpad.net/pbr/+bug/1404621\n\nChange-Id: I35beecd640e9ac5838202ef7845f8c3f703b34fc\nRelated-Bug: #1404621\nCloses-Bug: #1404665\n'}]",0,143433,0382b89db9cabeeb28575a3996d83d2a1a349e41,5,3,1,7369,,,0,"Exclude buggy version of pbr in requirements

Only 0.10.5 version of pbr is affected
https://bugs.launchpad.net/pbr/+bug/1404621

Change-Id: I35beecd640e9ac5838202ef7845f8c3f703b34fc
Related-Bug: #1404621
Closes-Bug: #1404665
",git fetch https://review.opendev.org/openstack/rally refs/changes/33/143433/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,0382b89db9cabeeb28575a3996d83d2a1a349e41,bug/1404621,"pbr>=0.6,!=0.7,!=0.10.5,<1.0","pbr>=0.6,!=0.7,<1.0",1,1
openstack%2Ffuel-library~master~I738e46909d9fa69d99a43dec099adf531431bb08,openstack/fuel-library,master,I738e46909d9fa69d99a43dec099adf531431bb08,Add support for external MongoDB,MERGED,2014-07-16 12:45:54.000000000,2014-12-22 14:38:39.000000000,2014-12-22 14:38:38.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6926}, {'_account_id': 7126}, {'_account_id': 7195}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-07-16 12:45:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a2d1e75b2dfd6ebaeb697b05f6cfa3a2cd11ffe5', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 2, 'created': '2014-07-16 13:00:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/01f58fffd27feff538cc00675aadbf047514706a', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 3, 'created': '2014-07-17 13:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/637382156321b0fff4f3441888dd2ada87187b90', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 4, 'created': '2014-07-17 15:14:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7046586068608756a358f615e1fdae7247e798b1', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 5, 'created': '2014-07-18 15:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/177accb54f1eaed04db6bdd61152421fc024bbdf', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 6, 'created': '2014-07-21 08:05:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5380f38914970afd96c76df657a60bac21162126', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 7, 'created': '2014-07-21 08:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0aa5b0391aa783076ed023baf62e54272568ffb4', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 8, 'created': '2014-09-11 09:05:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0c2ee88b7a2cda9d8a62efa12245cc6dad38245b', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 9, 'created': '2014-09-11 14:31:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0a38aadb651b50a244f94644eb4bf041556c78b4', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 10, 'created': '2014-09-11 16:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/747edf9a21df3ef2f5a0bdf74381186d66e8e05e', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 11, 'created': '2014-09-15 09:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a4be906cad2f0b6e1f2f9e1f6fa99663add6e4c6', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 12, 'created': '2014-10-06 11:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/951aa00608d0606afadc47b8a2df4b886e32751f', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 13, 'created': '2014-10-23 16:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f463eb037c831d46fa49d63ed090cfcd8a12845c', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nCloses-bug: #1383225\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 14, 'created': '2014-10-24 07:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9761a58548993ac338e7a2078318bdd76197a764', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nCloses-bug: #1383225\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 15, 'created': '2014-10-24 09:27:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/19aeeb6ffad508881d05340cb2c32a6635d4c3f6', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nCloses-bug: #1383225\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 16, 'created': '2014-10-28 09:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/50eea6014cb171972cbec6490cfb6330b5e0f71f', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nCloses-bug: #1383225\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 17, 'created': '2014-10-28 16:51:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bc253dabd896b6262a7e1de701e10cfc82bae25e', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nCloses-bug: #1383225\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 18, 'created': '2014-10-29 07:36:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e1834eb12750a70aa4889a15b82bfd5bb7dcc623', 'message': 'Add support for external MongoDB\n\n\nPartial implements blueprint external-mongodb-support\n\nCloses-bug: #1383225\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 19, 'created': '2014-11-17 10:12:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/af4a3b2b0700763015295cd16603516f66838b3a', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 20, 'created': '2014-11-17 11:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/13de8df9e704d0ae2eb698f70a000026204c7a45', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}, {'number': 21, 'created': '2014-12-08 11:17:24.000000000', 'files': ['deployment/puppet/openstack/manifests/controller.pp', 'deployment/puppet/openstack/manifests/controller_ha.pp', 'deployment/puppet/openstack/manifests/mongo_primary.pp', 'deployment/puppet/openstack/manifests/ceilometer.pp', 'deployment/puppet/openstack/manifests/db/mysql.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f4555466a71cfb5496a732831fa71d8d8d9ac6ce', 'message': 'Add support for external MongoDB\n\nPartial implements blueprint external-mongodb-support\n\nChange-Id: I738e46909d9fa69d99a43dec099adf531431bb08\n'}]",2,107355,f4555466a71cfb5496a732831fa71d8d8d9ac6ce,171,9,21,7732,,,0,"Add support for external MongoDB

Partial implements blueprint external-mongodb-support

Change-Id: I738e46909d9fa69d99a43dec099adf531431bb08
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/55/107355/17 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/manifests/controller.pp', 'deployment/puppet/openstack/manifests/controller_ha.pp', 'deployment/puppet/openstack/manifests/ceilometer.pp', 'deployment/puppet/openstack/manifests/db/mysql.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp']",6,a2d1e75b2dfd6ebaeb697b05f6cfa3a2cd11ffe5,bp/external-mongodb-support," # External mongo integration if !$::fuel_settings['external_mongo'] { $ceilometer_db_user = 'ceilometer' $ceilometer_db_password = $ceilometer_hash[db_password] $ceilometer_db_name = 'ceilometer' $ext_mongo = false } else { $ceilometer_db_user = $::fuel_settings['external_mongo']['mongo_user'] $ceilometer_db_password = $::fuel_settings['external_mongo']['mongo_password'] $ceilometer_db_name = $::fuel_settings['external_mongo']['mongo_db_name'] $ext_mongo = true } if $ext_mongo { $mongo_hosts = $::fuel_settings['external_mongo']['hosts_ip'] } else { $mongo_hosts = mongo_hosts($nodes_hash) } ceilometer_db_user => $ceilometer_db_user, ceilometer_db_password => $ceilometer_db_password, ceilometer_db_dbname => $ceilometer_db_name, ceilometer_db_host => $mongo_hosts, ceilometer_ext_mongo => $ext_mongo, ceilometer_db_password => $ceilometer_db_password,# ceilometer_db_password => $ceilometer_db_password,"," ceilometer_db_password => $ceilometer_hash[db_password], ceilometer_db_host => mongo_hosts($nodes_hash), ceilometer_db_password => $ceilometer_hash['db_password'],# ceilometer_db_password => $ceilometer_hash['db_password'],",87,47
openstack%2Fpython-neutronclient~master~I747778259656f1c9803bcf990cdd85f87a77fd1a,openstack/python-neutronclient,master,I747778259656f1c9803bcf990cdd85f87a77fd1a,Fix issues with Unicode compatibility for Py3,MERGED,2014-08-26 11:42:00.000000000,2014-12-22 14:25:21.000000000,2014-12-22 14:25:20.000000000,"[{'_account_id': 3}, {'_account_id': 55}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 5950}, {'_account_id': 6524}, {'_account_id': 7141}, {'_account_id': 7448}, {'_account_id': 7634}, {'_account_id': 7787}, {'_account_id': 8122}, {'_account_id': 8298}, {'_account_id': 9107}, {'_account_id': 10237}, {'_account_id': 11822}]","[{'number': 1, 'created': '2014-08-26 11:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/795f1fdefe7936a75844b0bb6e13513b15b9021c', 'message': 'Fix issues with Unicode compatibility for Py3\n\n1. There is no need to encode HTTP arguments in the client code -\n   requests library deals with that\n2. Unicode-related tests should not encode strings into utf8 - this\n   is done transparently due to #1\n3. HTTP header can contain ASCII chars only, thus removing test for\n   unicode case\n\nChange-Id: I747778259656f1c9803bcf990cdd85f87a77fd1a\n'}, {'number': 2, 'created': '2014-08-27 04:48:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/a0209a70940df466177d9f1a24c418da8d3d331f', 'message': 'Fix issues with Unicode compatibility for Py3\n\n1. There is no need to encode HTTP arguments in the client code -\n   requests library deals with that\n2. Unicode-related tests should not encode strings into utf8 - this\n   is done transparently due to #1\n3. HTTP header can contain ASCII chars only, thus removing test for\n   unicode case\n\nChange-Id: I747778259656f1c9803bcf990cdd85f87a77fd1a\n'}, {'number': 3, 'created': '2014-09-24 13:31:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/5130a47d3e84e84fa5fe172901ba14444c50a1e3', 'message': ""Fix issues with Unicode compatibility for Py3\n\nChanges:\n1. HTTP arguments don't need to be encoded in the client code -\n   requests library deals with that\n2. HTTP headers can contain ASCII chars only, encode them\n   appropriately (affects test code only)\n\nChange-Id: I747778259656f1c9803bcf990cdd85f87a77fd1a\n""}, {'number': 4, 'created': '2014-12-03 15:05:20.000000000', 'files': ['neutronclient/client.py', 'neutronclient/tests/unit/test_cli20.py', 'neutronclient/tests/unit/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/62063c12b222f0cdff0383d908ab60a2ed970334', 'message': 'Fix issues with Unicode compatibility for Py3\n\nHTTP arguments should not be encoded because:\n * requests library does it automatically replacing unicode\n   characters with utf-8 sequences\n * on py3 encoding function replaces string with byte array,\n   thus breaking keystone client\n\nCloses bug 1398854\n\nChange-Id: I747778259656f1c9803bcf990cdd85f87a77fd1a\n'}]",2,116864,62063c12b222f0cdff0383d908ab60a2ed970334,29,17,4,5950,,,0,"Fix issues with Unicode compatibility for Py3

HTTP arguments should not be encoded because:
 * requests library does it automatically replacing unicode
   characters with utf-8 sequences
 * on py3 encoding function replaces string with byte array,
   thus breaking keystone client

Closes bug 1398854

Change-Id: I747778259656f1c9803bcf990cdd85f87a77fd1a
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/64/116864/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/client.py', 'neutronclient/tests/unit/test_cli20.py', 'neutronclient/tests/unit/test_shell.py']",3,795f1fdefe7936a75844b0bb6e13513b15b9021c,green_py33_step3," argv = ['net-list', unicode_text, unicode_text]"," argv = ['net-list', unicode_text, unicode_text.encode('utf-8')]",10,16
openstack%2Fglance~master~Icdc39a2fd0da71a75f4ad0e60e34cfb8e1883787,openstack/glance,master,Icdc39a2fd0da71a75f4ad0e60e34cfb8e1883787,Allow $OS_AUTH_URL environment variable to override config file value,MERGED,2014-04-29 18:49:07.000000000,2014-12-22 14:19:43.000000000,2014-12-22 14:19:42.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 5202}, {'_account_id': 5280}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 8158}, {'_account_id': 10327}, {'_account_id': 12114}]","[{'number': 1, 'created': '2014-04-29 18:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/bdf907a1b61406525b4d142544648dafcafa79eb', 'message': 'Allow $OS_AUTH_URL environment variable to override config file value\n\nMake the Glance APIs use this value in a consistent/expected manner\nwhen it is set.  The Principle of Least Surprise dictates that\nsetting the value in the environment should override any values in\nthe config files.\n\nChange-Id: Icdc39a2fd0da71a75f4ad0e60e34cfb8e1883787\nCloses-Bug: 1314354\n'}, {'number': 2, 'created': '2014-10-20 20:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/cd2dc875d6344c49e5aebd582319f050c82e6f2b', 'message': 'Allow $OS_AUTH_URL environment variable to override config file value\n\nMake the Glance APIs use this value in a consistent/expected manner\nwhen it is set.  The Principle of Least Surprise dictates that\nsetting the value in the environment should override any values in\nthe config files.\n\nChange-Id: Icdc39a2fd0da71a75f4ad0e60e34cfb8e1883787\nCloses-Bug: 1314354\n'}, {'number': 3, 'created': '2014-12-20 05:50:59.000000000', 'files': ['glance/registry/client/v2/api.py', 'glance/registry/client/v1/api.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/348cef70b90df439301b05e981f8912c0822ecdd', 'message': 'Allow $OS_AUTH_URL environment variable to override config file value\n\nMake the Glance APIs use this value in a consistent/expected manner\nwhen it is set.  The Principle of Least Surprise dictates that\nsetting the value in the environment should override any values in\nthe config files.\n\nChange-Id: Icdc39a2fd0da71a75f4ad0e60e34cfb8e1883787\nCloses-Bug: 1314354\n'}]",0,91127,348cef70b90df439301b05e981f8912c0822ecdd,26,9,3,5280,,,0,"Allow $OS_AUTH_URL environment variable to override config file value

Make the Glance APIs use this value in a consistent/expected manner
when it is set.  The Principle of Least Surprise dictates that
setting the value in the environment should override any values in
the config files.

Change-Id: Icdc39a2fd0da71a75f4ad0e60e34cfb8e1883787
Closes-Bug: 1314354
",git fetch https://review.opendev.org/openstack/glance refs/changes/27/91127/2 && git format-patch -1 --stdout FETCH_HEAD,"['glance/registry/client/v2/api.py', 'glance/registry/client/v1/api.py']",2,bdf907a1b61406525b4d142544648dafcafa79eb,bug/1314354," 'auth_url': os.getenv('OS_AUTH_URL') or CONF.auth_url,"," 'auth_url': CONF.auth_url,",2,2
openstack%2Ffuel-web~master~I53576df677d1723a81888a7380f4bc7ba99ebe77,openstack/fuel-web,master,I53576df677d1723a81888a7380f4bc7ba99ebe77,WIP: substituse string hw addresses by netaddr,ABANDONED,2014-12-11 21:53:52.000000000,2014-12-22 14:18:37.000000000,,"[{'_account_id': 3}, {'_account_id': 6623}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-11 21:53:52.000000000', 'files': ['nailgun/nailgun/db/sqlalchemy/utils.py', 'nailgun/nailgun/objects/node.py', 'nailgun/nailgun/objects/serializers/base.py', 'nailgun/nailgun/api/v1/validators/node.py', 'nailgun/nailgun/db/sqlalchemy/models/node.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/398ea48b7a8b58791a21dff429a7dcb5dabd88fd', 'message': 'WIP: substituse string hw addresses by netaddr\n\nChange-Id: I53576df677d1723a81888a7380f4bc7ba99ebe77\n'}]",0,141181,398ea48b7a8b58791a21dff429a7dcb5dabd88fd,7,3,1,6623,,,0,"WIP: substituse string hw addresses by netaddr

Change-Id: I53576df677d1723a81888a7380f4bc7ba99ebe77
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/81/141181/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/db/sqlalchemy/utils.py', 'nailgun/nailgun/objects/node.py', 'nailgun/nailgun/objects/serializers/base.py', 'nailgun/nailgun/api/v1/validators/node.py', 'nailgun/nailgun/db/sqlalchemy/models/node.py']",5,398ea48b7a8b58791a21dff429a7dcb5dabd88fd,mac_validation,"from nailgun.db.sqlalchemy import utils as db_utils mac = Column(db_utils.EUIEncodedString, nullable=False, unique=True) mac = Column(db_utils.EUIEncodedString, nullable=False)"," mac = Column(LowercaseString(17), nullable=False, unique=True) mac = Column(LowercaseString(17), nullable=False)",67,5
openstack%2Fglance_store~master~I065b9a3e8e674ea74ff8563aad99d7d022417caa,openstack/glance_store,master,I065b9a3e8e674ea74ff8563aad99d7d022417caa,Raise appropriate exception if socket error occurs,MERGED,2014-12-02 10:15:09.000000000,2014-12-22 14:08:32.000000000,2014-12-22 14:08:30.000000000,"[{'_account_id': 3}, {'_account_id': 5202}, {'_account_id': 6549}, {'_account_id': 7634}, {'_account_id': 8158}, {'_account_id': 8759}, {'_account_id': 10485}, {'_account_id': 11356}, {'_account_id': 11391}, {'_account_id': 13717}]","[{'number': 1, 'created': '2014-12-02 10:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/ee691400f3604f25f639617e4471542a95c8d1d0', 'message': 'Raise appropriate exception if socket error occurs\n\nAdded a custom exception ServiceUnavailable in glance_store.exceptions\nand raised it from ""get"" method of http store in case of\nsocket.error exception is found.\n\nPartial-Bug: #1379798\nChange-Id: I065b9a3e8e674ea74ff8563aad99d7d022417caa\n'}, {'number': 2, 'created': '2014-12-03 07:30:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/b1504aa3f1dbf9ce535962bee2b5d8f348237ab4', 'message': 'Raise appropriate exception if socket error occurs\n\nAdded a custom exception ServiceUnavailable in glance_store.exceptions\nand raised it from ""get"" method of http store in case of\nsocket.error exception is found.\n\nMoved mocking httplib request and response logic from setup method\nto a private method and callled it only from the unit test cases where\nit is required.\n\nPartial-Bug: #1379798\nChange-Id: I065b9a3e8e674ea74ff8563aad99d7d022417caa\n'}, {'number': 3, 'created': '2014-12-04 12:09:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/af59c06cf3d69441b06de6c595706f637a046235', 'message': 'Raise appropriate exception if socket error occurs\n\nAdded a custom exception ServiceUnavailable in glance_store.exceptions\nand raised it from ""get"" method of http store in case of\nsocket.error exception is found.\n\nMoved mocking httplib request and response logic from setup method\nto a private method and callled it only from the unit test cases where\nit is required.\n\nPartial-Bug: #1379798\nChange-Id: I065b9a3e8e674ea74ff8563aad99d7d022417caa\n'}, {'number': 4, 'created': '2014-12-05 06:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/147459a6e55e82b8da7a7a80623d41904c395a43', 'message': 'Raise appropriate exception if socket error occurs\n\nAdded a custom exception ServiceUnavailable in glance_store.exceptions\nand raised it from ""get"" method of http store in case of\nsocket.error exception is found.\n\nMoved mocking httplib request and response logic from setup method\nto a private method and callled it only from the unit test cases where\nit is required.\n\nPartial-Bug: #1379798\nChange-Id: I065b9a3e8e674ea74ff8563aad99d7d022417caa\n'}, {'number': 5, 'created': '2014-12-08 10:02:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/1df586fb86cf38e46c9c02a034f5613dac8529c0', 'message': 'Raise appropriate exception if socket error occurs\n\nAdded a custom exception ServiceUnavailable in glance_store.exceptions\nand raised it from ""get"" method of http store in case of\nsocket.error exception is found.\n\nMoved mocking httplib request and response logic from setup method\nto a private method and callled it only from the unit test cases where\nit is required.\n\nPartial-Bug: #1379798\nChange-Id: I065b9a3e8e674ea74ff8563aad99d7d022417caa\n'}, {'number': 6, 'created': '2014-12-08 10:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/f5ed2d90d703cf434c04d47b6f6840966dd2ea94', 'message': 'Raise appropriate exception if socket error occurs\n\nAdded a custom exception ServiceUnavailable in glance_store.exceptions\nand raised it from ""get"" method of http store in case of\nsocket.error exception is found.\n\nMoved mocking httplib request and response logic from setup method\nto a private method and called it only from the unit test cases where\nit is required.\n\nPartial-Bug: #1379798\nChange-Id: I065b9a3e8e674ea74ff8563aad99d7d022417caa\n'}, {'number': 7, 'created': '2014-12-18 10:15:05.000000000', 'files': ['tests/unit/test_http_store.py', 'glance_store/exceptions.py', 'glance_store/_drivers/http.py'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/e6b5e8bb34df7c74e1ed248e9d5414c74b04ce1d', 'message': 'Raise appropriate exception if socket error occurs\n\nAdded a custom exception RemoteServiceUnavailable in\nglance_store.exceptions and raised it from ""get"" method of http store\nin case of socket.error exception is found.\n\nMoved mocking httplib request and response logic from setup method\nto a private method and called it only from the unit test cases where\nit is required.\n\nPartial-Bug: #1379798\nChange-Id: I065b9a3e8e674ea74ff8563aad99d7d022417caa\n'}]",12,138306,e6b5e8bb34df7c74e1ed248e9d5414c74b04ce1d,40,10,7,10485,,,0,"Raise appropriate exception if socket error occurs

Added a custom exception RemoteServiceUnavailable in
glance_store.exceptions and raised it from ""get"" method of http store
in case of socket.error exception is found.

Moved mocking httplib request and response logic from setup method
to a private method and called it only from the unit test cases where
it is required.

Partial-Bug: #1379798
Change-Id: I065b9a3e8e674ea74ff8563aad99d7d022417caa
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/06/138306/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_http_store.py', 'glance_store/_drivers/http.py', 'glance_store/exceptions.py']",3,ee691400f3604f25f639617e4471542a95c8d1d0,bug/1379798,"class ServiceUnavailable(GlanceStoreException): message = _(""Remote server where the image is present is unavailable."") ",,31,1
openstack%2Fneutron~master~Ic683f82aaa1a00a1bd63293d30f0ec6a5808c064,openstack/neutron,master,Ic683f82aaa1a00a1bd63293d30f0ec6a5808c064,L3 Agent refactor - extract device driver loading from agents,ABANDONED,2014-11-18 18:59:49.000000000,2014-12-22 14:08:32.000000000,,"[{'_account_id': 3}, {'_account_id': 162}, {'_account_id': 333}, {'_account_id': 490}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 7448}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9828}, {'_account_id': 9845}, {'_account_id': 9911}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-11-18 18:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d17f637f7573f5a836bf6f04f218e49bda2233b1', 'message': 'L3 Agent refactor - extract device driver loading from agents\n\nAs part of the restructuring of the L3 agent, this small step extracts\nthe loading of the device drivers from the FW, LB, and VPN agents.\n\nIt uses the same logic as is currently done by the agents, and\nmaintains the same config attributes in neutron.conf.\n\nNote: FW only loads one driver, and LB/VPN load multiple drivers. In\naddition, different arguments are passed to the inits for each of\nthese.\n\nUnit tests were added for the new methods created. Some unit tests\nwere updated to allow use of the new loader methods.\n\nChange-Id: Ic683f82aaa1a00a1bd63293d30f0ec6a5808c064\nPartially-implements: blueprint restructure-l3-agent\n'}, {'number': 2, 'created': '2014-11-20 15:02:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/30d147e2d283acdf04e0195a190d1045eda13db7', 'message': 'L3 Agent refactor - extract device driver loading from agents\n\nAs part of the restructuring of the L3 agent, this small step extracts\nthe loading of the device drivers from the FW, LB, and VPN agents.\n\nIt uses the same logic as is currently done by the agents, and\nmaintains the same config attributes in neutron.conf.\n\nNote: FW only loads one driver, and LB/VPN load multiple drivers. In\naddition, different arguments are passed to the inits for each of\nthese.\n\nUnit tests were added for the new methods created. Some unit tests\nwere updated to allow use of the new loader methods.\n\nChange-Id: Ic683f82aaa1a00a1bd63293d30f0ec6a5808c064\nPartially-implements: blueprint restructure-l3-agent\n'}, {'number': 3, 'created': '2014-11-21 14:44:52.000000000', 'files': ['neutron/services/advanced_services_loader.py', 'neutron/tests/unit/services/test_advanced_services_loader.py', 'neutron/services/loadbalancer/agent/agent_manager.py', 'neutron/tests/unit/services/loadbalancer/agent/test_agent_manager.py', 'neutron/services/vpn/agent.py', 'neutron/services/firewall/agents/l3reference/firewall_l3_agent.py', 'neutron/tests/unit/services/loadbalancer/agent/dummy_lbaas_device_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c3fd585250154bcc6da5670d182810fcf7edce24', 'message': 'L3 Agent refactor - extract device driver loading from agents\n\nAs part of the restructuring of the L3 agent, this small step extracts\nthe loading of the device drivers from the FW, LB, and VPN agents.\n\nIt uses the same logic as is currently done by the agents, and\nmaintains the same config attributes in neutron.conf.\n\nNote: FW only loads one driver, and LB/VPN load multiple drivers. In\naddition, different arguments are passed to the inits for each of\nthese.\n\nUnit tests were added for the new methods created. Some unit tests\nwere updated to allow use of the new loader methods.\n\nChange-Id: Ic683f82aaa1a00a1bd63293d30f0ec6a5808c064\nPartially-implements: blueprint restructure-l3-agent\n'}]",17,135392,c3fd585250154bcc6da5670d182810fcf7edce24,73,23,3,6659,,,0,"L3 Agent refactor - extract device driver loading from agents

As part of the restructuring of the L3 agent, this small step extracts
the loading of the device drivers from the FW, LB, and VPN agents.

It uses the same logic as is currently done by the agents, and
maintains the same config attributes in neutron.conf.

Note: FW only loads one driver, and LB/VPN load multiple drivers. In
addition, different arguments are passed to the inits for each of
these.

Unit tests were added for the new methods created. Some unit tests
were updated to allow use of the new loader methods.

Change-Id: Ic683f82aaa1a00a1bd63293d30f0ec6a5808c064
Partially-implements: blueprint restructure-l3-agent
",git fetch https://review.opendev.org/openstack/neutron refs/changes/92/135392/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/advanced_services_loader.py', 'neutron/services/loadbalancer/agent/agent_manager.py', 'neutron/tests/unit/services/test_advanced_services_loader.py', 'neutron/tests/unit/services/loadbalancer/agent/test_agent_manager.py', 'neutron/services/vpn/agent.py', 'neutron/services/firewall/agents/l3reference/firewall_l3_agent.py', 'etc/neutron/plugins/cisco/cisco_cfg_agent.ini', 'neutron/tests/unit/services/loadbalancer/agent/dummy_lbaas_device_driver.py']",8,d17f637f7573f5a836bf6f04f218e49bda2233b1,bp/cisco-vpnaas-with-cisco-csr-router,"# Copyright 2014 Cisco Systems, Inc. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from neutron.services.loadbalancer.agent import agent_device_driver class NoopLoadbalancerDriver1(agent_device_driver.AgentDeviceDriver): def __init__(self, conf, plugin_rpc): pass def get_name(cls): return 'NoopLoadbalancerDriver' def deploy_instance(self, logical_config): pass def undeploy_instance(self, pool_id): pass def get_stats(self, pool_id): pass def create_vip(self, vip): pass def update_vip(self, old_vip, vip): pass def delete_vip(self, vip): pass def create_pool(self, pool): pass def update_pool(self, old_pool, pool): pass def delete_pool(self, pool): pass def create_member(self, member): pass def update_member(self, old_member, member): pass def delete_member(self, member): pass def create_pool_health_monitor(self, health_monitor, pool_id): pass def update_pool_health_monitor(self, old_health_monitor, health_monitor, pool_id): pass def delete_pool_health_monitor(self, health_monitor, pool_id): pass class NoopLoadbalancerDriver2(NoopLoadbalancerDriver1): def get_name(cls): return 'NoopLoadbalancerDriver2' ",,318,57
openstack%2Fswift~feature%2Fec~I3a9628b404e3921108c132093162331acb3e73d3,openstack/swift,feature/ec,I3a9628b404e3921108c132093162331acb3e73d3,EC: Allow tuning ec_object_segment_size per policy,MERGED,2014-11-01 12:28:02.000000000,2014-12-22 14:07:00.000000000,2014-12-22 14:06:59.000000000,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 4608}, {'_account_id': 5189}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7485}, {'_account_id': 7847}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-11-01 12:28:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f586f2550e1c50997324723e26e7553ee3c57dbf', 'message': ""EC: Allow tuning ec_object_segment_size per policy\n\nFor 'erasure_coding' type (EC) policies, objects are buffered up to\na defined 'segment size' before they are erasure (en)coded.  There\nis a desire to make this size configurable per policy given PyECLib\nmetadata/padding overheads and thus fragment sizes vary depending on\nthe EC scheme and ec_num_data_fragments/ec_num_parity_fragments values\nchosen.  A cluster administrator setting up an EC policy may be able\nto tune the object segment size value for a balance of space savings\nand performance for a particular EC scheme.\n\nChanges:\n\n - Parsing support for 'ec_object_segment_size' swift.conf option\n - Add 'ec_objsegsz' property to ECStoragePolicy class\n - Add unit test cases for ec_object_segment_size\n\nChange-Id: I3a9628b404e3921108c132093162331acb3e73d3\nImplements: blueprint ec-proxy-work\n""}, {'number': 2, 'created': '2014-11-19 01:01:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7f9403ca43f43ff9bd4a8d3b4a5a6dc1b90d777b', 'message': ""EC: Allow tuning ec_object_segment_size per policy\n\nFor 'erasure_coding' type (EC) policies, objects are buffered up to\na defined 'segment size' before they are erasure (en)coded.  There\nis a desire to make this size configurable per policy given PyECLib\nmetadata/padding overheads and thus fragment sizes vary depending on\nthe EC scheme and ec_num_data_fragments/ec_num_parity_fragments values\nchosen.  A cluster administrator setting up an EC policy may be able\nto tune the object segment size value for a balance of space savings\nand performance for a particular EC scheme.\n\nChanges:\n\n - Parsing support for 'ec_object_segment_size' swift.conf option\n - Add 'ec_objsegsz' property to ECStoragePolicy class\n - Add unit test cases for ec_object_segment_size\n\nCo-Authored-By: Yuan Zhou <yuan.zhou@intel.com>\n\nDocImpact\nImplements: blueprint ec-proxy-work\nChange-Id: I3a9628b404e3921108c132093162331acb3e73d3\n""}, {'number': 3, 'created': '2014-11-19 02:07:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/67ca9ad23c70cef63dd71653338103f52c3df17a', 'message': ""EC: Allow tuning ec_object_segment_size per policy\n\nFor 'erasure_coding' type (EC) policies, objects are buffered up to\na defined 'segment size' before they are erasure (en)coded.  There\nis a desire to make this size configurable per policy given PyECLib\nmetadata/padding overheads and thus fragment sizes vary depending on\nthe EC scheme and ec_num_data_fragments/ec_num_parity_fragments values\nchosen.  A cluster administrator setting up an EC policy may be able\nto tune the object segment size value for a balance of space savings\nand performance for a particular EC scheme.\n\nChanges:\n\n - Parsing support for 'ec_object_segment_size' swift.conf option\n - Add 'ec_segment_size' property to ECStoragePolicy class\n - Add unit test cases for ec_object_segment_size\n\nCo-Authored-By: Yuan Zhou <yuan.zhou@intel.com>\n\nDocImpact\nImplements: blueprint ec-proxy-work\nChange-Id: I3a9628b404e3921108c132093162331acb3e73d3\n""}, {'number': 4, 'created': '2014-12-15 19:03:07.000000000', 'files': ['test/unit/common/test_storage_policy.py', 'swift/common/storage_policy.py', 'etc/swift.conf-sample', 'swift/common/constraints.py', 'doc/source/overview_erasure_code.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/4021c151adb5449e6933d3612c7aba7dca7fde7e', 'message': ""EC: Allow tuning ec_object_segment_size per policy\n\nFor 'erasure_coding' type (EC) policies, objects are buffered up to\na defined 'segment size' before they are erasure (en)coded.  There\nis a desire to make this size configurable per policy given PyECLib\nmetadata/padding overheads and thus fragment sizes vary depending on\nthe EC scheme and ec_num_data_fragments/ec_num_parity_fragments values\nchosen.  A cluster administrator setting up an EC policy may be able\nto tune the object segment size value for a balance of space savings\nand performance for a particular EC scheme.\n\nChanges:\n\n - Parsing support for 'ec_object_segment_size' swift.conf option\n - Add 'ec_segment_size' property to ECStoragePolicy class\n - Add unit test cases for ec_object_segment_size\n\nCo-Authored-By: Yuan Zhou <yuan.zhou@intel.com>\n\nDocImpact\nImplements: blueprint ec-proxy-work\nChange-Id: I3a9628b404e3921108c132093162331acb3e73d3\n""}]",3,132389,4021c151adb5449e6933d3612c7aba7dca7fde7e,50,9,4,7485,,,0,"EC: Allow tuning ec_object_segment_size per policy

For 'erasure_coding' type (EC) policies, objects are buffered up to
a defined 'segment size' before they are erasure (en)coded.  There
is a desire to make this size configurable per policy given PyECLib
metadata/padding overheads and thus fragment sizes vary depending on
the EC scheme and ec_num_data_fragments/ec_num_parity_fragments values
chosen.  A cluster administrator setting up an EC policy may be able
to tune the object segment size value for a balance of space savings
and performance for a particular EC scheme.

Changes:

 - Parsing support for 'ec_object_segment_size' swift.conf option
 - Add 'ec_segment_size' property to ECStoragePolicy class
 - Add unit test cases for ec_object_segment_size

Co-Authored-By: Yuan Zhou <yuan.zhou@intel.com>

DocImpact
Implements: blueprint ec-proxy-work
Change-Id: I3a9628b404e3921108c132093162331acb3e73d3
",git fetch https://review.opendev.org/openstack/swift refs/changes/89/132389/2 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/test_storage_policy.py', 'test/unit/proxy/test_server.py', 'swift/common/storage_policy.py', 'swift/common/constraints.py']",4,f586f2550e1c50997324723e26e7553ee3c57dbf,bp/ec-proxy-work,"EC_OBJECT_SEGMENT_SIZE = 1048576 'ec_object_segment_size': EC_OBJECT_SEGMENT_SIZE,",,83,4
openstack%2Ffuel-web~master~Ifa6e9f7ea3292c8176c3d277285fd46a9b5693bd,openstack/fuel-web,master,Ifa6e9f7ea3292c8176c3d277285fd46a9b5693bd,Adds restriction check to settings changes detection algorithm,MERGED,2014-12-09 10:46:58.000000000,2014-12-22 14:06:07.000000000,2014-12-22 14:06:07.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-12-09 10:46:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/cd1fc9467052e848206e00517433fb97c76f5e16', 'message': 'Adds restriction check to settings changes detection algorithm\n\nCloses-Bug: #1377870\nCloses-Bug: #1389671\n\nChange-Id: Ifa6e9f7ea3292c8176c3d277285fd46a9b5693bd\n'}, {'number': 2, 'created': '2014-12-09 15:46:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2efb086565d05c431d94d14f8e9ba1730ae432e1', 'message': 'Adds restriction check to settings changes detection algorithm\n\nCloses-Bug: #1377870\nCloses-Bug: #1389671\n\nChange-Id: Ifa6e9f7ea3292c8176c3d277285fd46a9b5693bd\n'}, {'number': 3, 'created': '2014-12-19 11:02:39.000000000', 'files': ['nailgun/static/js/views/cluster_page_tabs/settings_tab.jsx', 'nailgun/static/js/models.js', 'nailgun/static/js/views/statistics_mixin.jsx'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ae6083e467aef9caf26e6e72429a3e654e2f5530', 'message': 'Adds restriction check to settings changes detection algorithm\n\nCloses-Bug: #1377870\nCloses-Bug: #1389671\n\nChange-Id: Ifa6e9f7ea3292c8176c3d277285fd46a9b5693bd\n'}]",5,140294,ae6083e467aef9caf26e6e72429a3e654e2f5530,26,7,3,8766,,,0,"Adds restriction check to settings changes detection algorithm

Closes-Bug: #1377870
Closes-Bug: #1389671

Change-Id: Ifa6e9f7ea3292c8176c3d277285fd46a9b5693bd
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/94/140294/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/js/views/cluster_page_tabs/settings_tab.jsx', 'nailgun/static/js/models.js', 'nailgun/static/js/views/statistics_mixin.jsx']",3,cd1fc9467052e848206e00517433fb97c76f5e16,bug/1377870," return this.props.settings.hasChanges(this.initialSettings, this.configModels);"," return !_.isEqual(this.props.settings.toJSON().settings, this.initialSettings);",15,7
openstack%2Fha-guide~master~I9dc46e2809ece647da9a5bc1f0ee9d4706359065,openstack/ha-guide,master,I9dc46e2809ece647da9a5bc1f0ee9d4706359065,Fix the metadata agent resource configuration,MERGED,2014-12-22 08:02:08.000000000,2014-12-22 14:05:08.000000000,2014-12-22 14:05:07.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-22 08:02:08.000000000', 'files': ['doc/high-availability-guide/includes/pacemaker-network-metadata.crm'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/d8c0338564c04c1dcd40893e8c61067d02567df7', 'message': ""Fix the metadata agent resource configuration\n\nThe `plugin_config` parameter doesn't exist, use `agent_config` instead.\n\nChange-Id: I9dc46e2809ece647da9a5bc1f0ee9d4706359065\n""}]",0,143389,d8c0338564c04c1dcd40893e8c61067d02567df7,7,3,1,7923,,,0,"Fix the metadata agent resource configuration

The `plugin_config` parameter doesn't exist, use `agent_config` instead.

Change-Id: I9dc46e2809ece647da9a5bc1f0ee9d4706359065
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/89/143389/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/high-availability-guide/includes/pacemaker-network-metadata.crm'],1,d8c0338564c04c1dcd40893e8c61067d02567df7,arg-name-metadata," agent_config=""/etc/neutron/metadata_agent.ini"" \"," plugin_config=""/etc/neutron/metadata_agent.ini"" \",1,1
openstack%2Fsahara~master~I77cafbf0a54c82e3fe4dfcb24782cc966b5622dd,openstack/sahara,master,I77cafbf0a54c82e3fe4dfcb24782cc966b5622dd,[WIP] Add Spark EDP job support for CDH plugin,ABANDONED,2014-11-13 17:26:58.000000000,2014-12-22 13:47:20.000000000,,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 7710}]","[{'number': 1, 'created': '2014-11-13 17:26:58.000000000', 'files': ['sahara/plugins/cdh/edp_engine.py', 'sahara/tests/integration/tests/gating/test_cdh_gating.py', 'sahara/plugins/cdh/plugin.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/a268e9daf6b322d44fe08b4c9f8ab0bfcbac0287', 'message': '[WIP] Add Spark EDP job support for CDH plugin\n\nChange-Id: I77cafbf0a54c82e3fe4dfcb24782cc966b5622dd\n'}]",0,134310,a268e9daf6b322d44fe08b4c9f8ab0bfcbac0287,8,3,1,7710,,,0,"[WIP] Add Spark EDP job support for CDH plugin

Change-Id: I77cafbf0a54c82e3fe4dfcb24782cc966b5622dd
",git fetch https://review.opendev.org/openstack/sahara refs/changes/10/134310/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/cdh/edp_engine.py', 'sahara/tests/integration/tests/gating/test_cdh_gating.py', 'sahara/plugins/cdh/plugin.py']",3,a268e9daf6b322d44fe08b4c9f8ab0bfcbac0287,cdh-edp-spark, if job_type in edp_engine.EDPOozieEngine.get_supported_job_types(): return edp_engine.EDPOozieEngine(cluster) elif job_type in edp_engine.EDPSparkEngine.get_supported_job_types(): return edp_engine.EDPSparkEngine(cluster) , if job_type in edp_engine.EdpOozieEngine.get_supported_job_types(): return edp_engine.EdpOozieEngine(cluster),33,7
openstack%2Fneutron-specs~master~Ie1eb34c79a84ed2fa8520bd81838f88ed0c6c3b5,openstack/neutron-specs,master,Ie1eb34c79a84ed2fa8520bd81838f88ed0c6c3b5,Introducing v3 plugin interface,MERGED,2014-12-09 23:40:31.000000000,2014-12-22 13:47:01.000000000,2014-12-22 13:47:01.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 261}, {'_account_id': 333}, {'_account_id': 748}, {'_account_id': 1561}, {'_account_id': 1935}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 8792}, {'_account_id': 8976}, {'_account_id': 9093}]","[{'number': 1, 'created': '2014-12-09 23:40:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b335f3c98a8888118bcaf4e009121e635ddcc226', 'message': 'Introducing v3 plugin interface\n\nThis specification discusses a new and improved\ninterface between the REST layer and the plugin.\n\nChange-Id: Ie1eb34c79a84ed2fa8520bd81838f88ed0c6c3b5\n'}, {'number': 2, 'created': '2014-12-10 19:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/38a6738dc5f75a40d8e6f1d866d2c905e66bc2b1', 'message': 'Introducing v3 plugin interface\n\nThis specification discusses a new and improved\ninterface between the REST layer and the plugin.\n\nChange-Id: Ie1eb34c79a84ed2fa8520bd81838f88ed0c6c3b5\n'}, {'number': 3, 'created': '2014-12-10 20:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/457d11160e166d0ca191b0464757e36982bb8950', 'message': 'Introducing v3 plugin interface\n\nThis specification discusses a new and improved\ninterface between the REST layer and the plugin.\n\nChange-Id: Ie1eb34c79a84ed2fa8520bd81838f88ed0c6c3b5\n'}, {'number': 4, 'created': '2014-12-10 22:28:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/a932845da5239a26c434bd297047c80ecd63cfa0', 'message': 'Introducing v3 plugin interface\n\nThis specification discusses a new and improved\ninterface between the REST layer and the plugin.\n\nChange-Id: Ie1eb34c79a84ed2fa8520bd81838f88ed0c6c3b5\n'}, {'number': 5, 'created': '2014-12-15 14:43:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6c8700e5883d5ea68468281e82f073a32351f15f', 'message': 'Introducing v3 plugin interface\n\nThis specification discusses a new and improved\ninterface between the REST layer and the plugin.\n\nChange-Id: Ie1eb34c79a84ed2fa8520bd81838f88ed0c6c3b5\n'}, {'number': 6, 'created': '2014-12-19 10:57:10.000000000', 'files': ['specs/kilo/plugin-interface-perestroika.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/16f1bffd8d1be5cbe3cc109f49b84a8ec933ccf7', 'message': 'Introducing v3 plugin interface\n\nThis specification discusses a new and improved\ninterface between the REST layer and the plugin.\n\nChange-Id: Ie1eb34c79a84ed2fa8520bd81838f88ed0c6c3b5\n'}]",121,140527,16f1bffd8d1be5cbe3cc109f49b84a8ec933ccf7,37,16,6,261,,,0,"Introducing v3 plugin interface

This specification discusses a new and improved
interface between the REST layer and the plugin.

Change-Id: Ie1eb34c79a84ed2fa8520bd81838f88ed0c6c3b5
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/27/140527/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/plugin-interface-perestroika.rst'],1,b335f3c98a8888118bcaf4e009121e635ddcc226,plugin_interface,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Introduce a new plugin interface ========================================== https://blueprints.launchpad.net/neutron/+spec/plugin-interface-perestroika This specification proposes a new plugin interface which will provide a stronger interface between the management layer and the plugin themselves, as well as paving the way for a proper separation of concerns between the REST layer, Neutron management layer, and the plugin layer. Problem Description =================== It is well known that there are a few shortcomings with both the current plugin interface and the inheritance pattern with ties all the plugins to the database ""base"" class [#]_ .. [#] DB plugin base class: http://git.openstack.org/cgit/openstack/neutron/tree/neutron/db/db_base_plugin_v2.py While issues arising from the inheritance pattern and its (ab)use are outside of the scope of this document, in the rest of this section we list the issues that we are planning to solve with this piece of work. * The interface is currently operation oriented. While this worked fairly well in the Folsom world, when plugins where required to implement only a small set of operations, it is now not practical anymore. * While python's abc enforces checks on the shape of implementation of the plugin interface, no sort of contract exists when it comes to data passed to such interface (and returned by it). This happens because data are passed as free form dicts, with the plugin implementations expecting these dicts to have a particular structure * The current plugin interface delegates all the business logic to the plugin, with the exception of authorization and quota enforcement. This leads plugin to over rely on the business logic contained in the ""db base plugin"", whereas some of that logic, especially the one for managing ""composite"" operations such as attaching a subnet to a router, should be moved to the plugin layer thus ensuring plugin operations are as simple as possible. * As the plugin is currently 100% responsible for determining how an API operation is performed, it is very difficult to add capabilities such as task-based workflow, server failure recovery without having them as plugin specific. Summarizing the current plugin interface has become hardly maintainable. Proposed Change =============== The aim of this specification is to introduce a new, and hopefully better, interface between the REST layer and the plugin layer, which addresses the issues listed in the section above. This specification relies on the following assumptions: * There will be an object framework for describing API resources. This objects framework will encapsulate resource validation logic, but should not, at least at this stage, include capabilities such as persistency and call remoting. * Plugins are able to accept such objects, and return them. The plugin interface being introduced with this blueprint will be called the ""v3"" plugin interface, to distinguish it from the ""v2"" interface which Neutron has been running since the Folsom release (2012.1). It is important to note that the versioning here is purely informal and has absolutely no relationship with REST or RPC API versioning. It is within the scope of this blueprint to ensure that the v3 plugin interface works perfectly with the Neutron v2 REST API. Together with the plugin interface, a new management layer will be added in Neutron's architecture. The role of this management layer is to perform common business logic tasks which are currently performed either within the REST layer or within the plugin, mostly in the base database plugin class. This management layer will be initially very thin. It is likely to expect it to grow over time. The new interface will be namespaced for the sake of readability and maintanability. As an example the REST layer calls the plugin interface by building a method name given resource and operation as seen in [#]_ .. [#] http://git.openstack.org/cgit/openstack/neutron/tree/neutron/api/v2/base.py#n244 On the other hand, with the new interface being proposed here calls to the plugin interface will look like the following: .. net = Network(...) net.validate() plugin.networks.create(net) Just like the v2 interface, the v3 interface will be consistuted by the sum of the interface for ""core"" operations and the various interfaces for API extensions. For this reason, every API extension which introduces new resources and therefore extends the surface of the plugin interface will have to be redefined in order to comply with the new interface. We expect this work to not be overwhelming, even if there are some large extensions such as load balancing or VPN which might prove challenging. It is also worth noting that the proposal [#]_ advocates for a condensation of API. While this proposal .. [#] https://review.openstack.org/#/c/136760 Summarizing the following changes will be included within the scope of this blueprint: * Introduce a new namespaced interface to the plugin layer, called the ""v3"" plugin interface (where ""v3"" has no reference whatsover to REST API versioning) * Both the neutron core interface [#]_ and extension interfaces as [#]_ will be redesigned to reflect this new interface. .. [#] Core plugin interface: http://git.openstack.org/cgit/openstack/neutron/tree/neutron/neutron_plugin_base_v2.py .. [#] L3 extension interface: http://git.openstack.org/cgit/openstack/neutron/tree/neutron/extensions/l3.py As a consequence of this change, there won't be anymore such a thing as a ""v2"" interface. This won't be a problem however for existing plugins, because of the introduction of the ""adaptor"" discussed below. * Implement a thin management layer beyond the plugin interface which will take care of performing ""common operations"" which are now delegated to plugins. This management layer will also be used for doing ops like authorization and quota enforcement as discussed in [#]_ .. [#] Pecan switch spec: https://review.openstack.org/#/c/140454/ * Define an adaptor (or shim) to be able to run ""v2"" plugins from the ""v3"" interface. This will allow for seamless backward compatibility when switching to the new plugin interface. The implementation of a reference plugin, possibly based on a modular driver approach, for the v3 interface is outside of the scope of the blueprint. However, such plugin is highly desirable, and the contributors to this blueprint should strive to implement it, even if only for PoC purposes. [COMPONENT DIAGRAM GOES HERE] Data Model Impact ----------------- No change in Neutron's data model is expected, at least in terms of database schemas. Clearly the objects introduced here represent a rather important change when it comes to how data are transferred across interfaces. This change will definetely be beneficial from a maintainability perspective. On the other hand current plugins clearly do not support it. As depicted in the diagram discussed in the previous section, existing plugins will attach to the v3 interface through a shim layer. The role of this shim layer is mostly to convert API objects into a dict representation which is understood by v2 plugins and viceversa. While this seems illogical (for instance on responses there is a dict -> object -> dict conversion from the plugin to the REST layer), it is apparently the best solution to evolve the plugin interface without impacting all the existing plugins. REST API Impact --------------- None Security Impact --------------- We do not expect that the code changes that will be performed as part of this blueprint will bring in any security flaw. Moreover, it is not possible to perform an analysis of the security implication of this kind of change without analyzing the code. Notifications Impact -------------------- The management layer inserted behind the plugin interface will take care of doing notifications currently performed by the REST layer. Other End User Impact --------------------- None. Performance Impact ------------------ This blueprint is not about performance and scalability, so no improvement on this front is expected. The introduction of the shim laye adds some latency in the call path; we expect this additional latency to be negligible. Accurate testing is however needed to ensure no performance or scalability regressions are introduced. IPv6 Impact ----------- None Other Deployer Impact --------------------- None Developer Impact ---------------- Developers should be encouraged to start developing new plugins against the v3 API. Also, the proposed changes will also impact some API extensions as they will need to use the v3 interface rather than defining a simple abstract class as they currently do. Appropriate developer documentation should be added to this aim. Community Impact ---------------- The blueprint has been coinceived in order to minimize the impact on the community, and in particular to contributors and maintainers of plugins implementing the v2 API. These plugins will continue to be supported. We are not yet able to make a call on a potential deprecation date, but it is unlikely that something like that will happen before 12-18 months. Alternatives ------------ It should be possible to run a ""dual stack"" version of neutron server. This would allow v2 plugins to have a choice of running in the ""old"" environment consistuted by the home grown WSGI and dict based interface, or in the ""new"" environment built around Pecan and the v3 interface. This however requires the neutron team to keep supporting the ""old"" way of running plugins for the foreseeable future, and such an effort is probably not worth if v2 plugins can efficiently run under the v3 interface through the v3/v2 shim. Implementation ============== Assignee(s) ----------- Primary assignee: Mark McClain (markmcclain) Other contributors: Salvatore Orlando (salv-orlando) [in the role of the code monkey] Work Items ---------- * Completion of the API objects framework * Definition of new namespace oriented interface * Implementation of ""manager"" classes sitting between REST and plugin layer * Implementation of the v3/v2 adaptor * Verify performance and scalability impact * Documentation Dependencies ============ None Testing ======= This change is likely to require some change in the unit test framework, just like the blueprint for switching the WSGI layer to Pecan. However, considering how unit tests are currently executed in Neutron, the adoption of the v3/v2 shim should ease the transition from a unit testing perspective. Tempest Tests ------------- Current coverage is enough considering the scope of this change Functional Tests ---------------- No new functional test needed API Tests --------- No additional API tests are needed Documentation Impact ==================== The changes in the blueprint require large updates in developer documentation User Documentation ------------------ This change is transparent to both final users and deployers. Developer Documentation ----------------------- Additional developer documentation is needed for * implementing v3 plugins * definition extensions which expand the v3 plugin interface References ========== ",,323,0
openstack%2Fdevstack~master~Idbe70200e1c296676a40217bae327b827bf92969,openstack/devstack,master,Idbe70200e1c296676a40217bae327b827bf92969,Do not use the nova-cells conf to setup floating ips,ABANDONED,2014-12-01 21:20:20.000000000,2014-12-22 13:40:52.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5441}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-01 21:20:20.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a1a931556b94a4c210bf34dd3da1d40051a9dd08', 'message': ""Do not use the nova-cells conf to setup floating ips\n\nIn a Nova cells deployment floating ip information should be stored at\nthe parent level since that's where the API will look for it.  It has\nbeen incorrectly configured to set them up in a child cell which is\ncausing the tempest floating ip tests to fail for cells.\n\nChange-Id: Idbe70200e1c296676a40217bae327b827bf92969\n""}]",0,138185,a1a931556b94a4c210bf34dd3da1d40051a9dd08,6,4,1,5441,,,0,"Do not use the nova-cells conf to setup floating ips

In a Nova cells deployment floating ip information should be stored at
the parent level since that's where the API will look for it.  It has
been incorrectly configured to set them up in a child cell which is
causing the tempest floating ip tests to fail for cells.

Change-Id: Idbe70200e1c296676a40217bae327b827bf92969
",git fetch https://review.opendev.org/openstack/devstack refs/changes/85/138185/1 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,a1a931556b94a4c210bf34dd3da1d40051a9dd08,cells_floating_ips,, if is_service_enabled n-cell; then NM_CONF=${NOVA_CELLS_CONF} fi,0,3
openstack%2Ffuel-main~master~Ic89ffe5a1733499db6c925d9c42821e61eac2ea0,openstack/fuel-main,master,Ic89ffe5a1733499db6c925d9c42821e61eac2ea0,Add a System test vCenter + VLanManager Simple,MERGED,2014-12-15 15:21:29.000000000,2014-12-22 13:16:46.000000000,2014-12-22 13:16:46.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8782}, {'_account_id': 8882}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12141}, {'_account_id': 12199}, {'_account_id': 12415}, {'_account_id': 12867}, {'_account_id': 13306}, {'_account_id': 13917}, {'_account_id': 14342}]","[{'number': 1, 'created': '2014-12-15 15:21:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/41c491d827b53e31c1b683b9454824312b9e71ba', 'message': 'Add automated set of test vCenter+VLan Simple\n\nChange-Id: Ic89ffe5a1733499db6c925d9c42821e61eac2ea0\n'}, {'number': 2, 'created': '2014-12-15 15:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a109a37d4ae08b2c244f14fa874aa150681d669f', 'message': 'Add automated set of test vCenter+VLan Simple\n\nChange-Id: Ic89ffe5a1733499db6c925d9c42821e61eac2ea0\n'}, {'number': 3, 'created': '2014-12-15 15:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5f28b19fa22d059908698a341849f9956fae8c1a', 'message': 'Add automated set of test vCenter+VLan Simple\n\nChange-Id: Ic89ffe5a1733499db6c925d9c42821e61eac2ea0\n'}, {'number': 4, 'created': '2014-12-15 16:47:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1deb2e024fccb5f92ec86a883e5324cab4be3f70', 'message': 'Add automated set of test vCenter+VLan Simple\n\nChange-Id: Ic89ffe5a1733499db6c925d9c42821e61eac2ea0\n'}, {'number': 5, 'created': '2014-12-16 10:30:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7a3d2369682e2c033c415c25e4d245030623a5c5', 'message': 'Add automated set of test vCenter+VLan Simple\n\nChange-Id: Ic89ffe5a1733499db6c925d9c42821e61eac2ea0\n'}, {'number': 6, 'created': '2014-12-16 10:45:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6532d86b6a11eb1077d317e12663fd08723d45a4', 'message': 'Add automated set of test vCenter+VLan Simple\n\nChange-Id: Ic89ffe5a1733499db6c925d9c42821e61eac2ea0\n'}, {'number': 7, 'created': '2014-12-17 12:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/e769e7258bb9945bd9f53b17d6efad609264676a', 'message': 'Add automated set of test vCenter+VLan Simple\n\nChange-Id: Ic89ffe5a1733499db6c925d9c42821e61eac2ea0\n'}, {'number': 8, 'created': '2014-12-18 17:26:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8c8a0e78baf7107fd4205ed7e623bb3d7f99a3a8', 'message': 'Add automated set of test vCenter+VLan Simple\n\nChange-Id: Ic89ffe5a1733499db6c925d9c42821e61eac2ea0\n'}, {'number': 9, 'created': '2014-12-18 18:22:55.000000000', 'files': ['fuelweb_test/tests/test_vcenter.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/535a4b1f6ceff96fc1e4143ec631f53f259cce21', 'message': 'Add a System test vCenter + VLanManager Simple\n\nChange-Id: Ic89ffe5a1733499db6c925d9c42821e61eac2ea0\n'}]",4,141822,535a4b1f6ceff96fc1e4143ec631f53f259cce21,50,17,9,13306,,,0,"Add a System test vCenter + VLanManager Simple

Change-Id: Ic89ffe5a1733499db6c925d9c42821e61eac2ea0
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/22/141822/8 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_vcenter.py'],1,41c491d827b53e31c1b683b9454824312b9e71ba,," @test(depends_on=[SetupEnvironment.prepare_slaves_3], groups=[""vcenter_vlan_simple"", ""vcenter_vlan""]) @log_snapshot_on_error def vcenter_vlan_simple(self): """"""Deploy cluster with 1 controller node and 2 cinder nodes and test vlan driver support feature Scenario: 1. Create cluster 2. Add 3 nodes with controller and cinder roles 3. Deploy the cluster 4. Run network verification 5. Run osft """""" self.env.revert_snapshot(""ready_with_3_slaves"") # Configure cluster cluster_id = self.fuel_web.create_cluster( name=self.__class__.__name__, mode=settings.DEPLOYMENT_MODE_SIMPLE, settings={ 'use_vcenter': True, 'volumes_vmdk': True, 'volumes_lvm': False, 'host_ip': settings.VCENTER_IP, 'vc_user': settings.VCENTER_USERNAME, 'vc_password': settings.VCENTER_PASSWORD, 'cluster': settings.VCENTER_CLUSTERS, 'tenant': 'vcenter', 'user': 'vcenter', 'password': 'vcenter' } ) logger.info(""cluster is {0}"".format(cluster_id)) # Add nodes to roles self.fuel_web.update_nodes( cluster_id, {'slave-01': ['controller'], 'slave-02': ['cinder'], 'slave-03': ['cinder'], } ) #Configure network interfaces interfaces = { 'eth0': [""fuelweb_admin""], 'eth1': [""public"", ""fixed""], 'eth2': [""management"", ], 'eth3': [], 'eth4': [""storage""], } nets = self.fuel_web.client.get_networks(cluster_id)['networks'] nailgun_nodes = self.fuel_web.client.list_cluster_nodes(cluster_id) for node in nailgun_nodes: self.fuel_web.update_node_networks(node['id'], interfaces) #Configure VLan self.fuel_web.update_vlan_network_fixed( cluster_id, amount=8, network_size=32) # Deploy cluster self.fuel_web.deploy_cluster_wait(cluster_id) # Wait until nova-compute get information about clusters # Fix me. Later need to change sleep with wait function. time.sleep(60) self.fuel_web.verify_network(cluster_id) self.fuel_web.run_ostf( cluster_id=cluster_id, test_sets=['smoke', 'sanity'], ) ",,75,0
openstack%2Fdevstack~master~Ib82b19d5d5dd22b6635ad95ce58a5cf0f48b8387,openstack/devstack,master,Ib82b19d5d5dd22b6635ad95ce58a5cf0f48b8387,Copy datastore templates when installing Trove,ABANDONED,2014-11-25 12:44:58.000000000,2014-12-22 12:56:48.000000000,,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 8415}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-25 12:44:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7c11712fa4ba7cf2325681e61dfe0bee4239f985', 'message': ""Copy datastore templates when installing Trove\n\nReasons:\n - MongoDB doesn't work in DevStack due to its 'smallfiles' because\n   instance datastore cannot start properly on any flavors that Nova provides;\n - Trove developer should have an easy way to modify datastore templates\n   out of codebase at $DEST/trove;\n - Without this fix we cannot gate mongodb in devstack-gate.\n\nChanges:\n - copying trove/templates to /etc/trove/tempaltes;\n - modifying mongodb conf 'smallfiles' from 'false' to 'true'\n\nChange-Id: Ib82b19d5d5dd22b6635ad95ce58a5cf0f48b8387\n""}, {'number': 2, 'created': '2014-11-25 13:29:48.000000000', 'files': ['lib/trove'], 'web_link': 'https://opendev.org/openstack/devstack/commit/412ee217759a60e20d2f24b1085e0348cd922aa8', 'message': ""Copy datastore templates when installing Trove\n\nReasons:\n - MongoDB doesn't work in DevStack due to its 'smallfiles' because\n   instance datastore cannot start properly on any flavors that Nova provides;\n - Trove developer should have an easy way to modify datastore templates\n   out of codebase at $DEST/trove;\n - Without this fix we cannot gate mongodb in devstack-gate.\n\nChanges:\n - copying trove/templates to /etc/trove/tempaltes;\n - modifying mongodb conf 'smallfiles' from 'false' to 'true'\n\nChange-Id: Ib82b19d5d5dd22b6635ad95ce58a5cf0f48b8387\n""}]",0,137039,412ee217759a60e20d2f24b1085e0348cd922aa8,8,4,2,8415,,,0,"Copy datastore templates when installing Trove

Reasons:
 - MongoDB doesn't work in DevStack due to its 'smallfiles' because
   instance datastore cannot start properly on any flavors that Nova provides;
 - Trove developer should have an easy way to modify datastore templates
   out of codebase at $DEST/trove;
 - Without this fix we cannot gate mongodb in devstack-gate.

Changes:
 - copying trove/templates to /etc/trove/tempaltes;
 - modifying mongodb conf 'smallfiles' from 'false' to 'true'

Change-Id: Ib82b19d5d5dd22b6635ad95ce58a5cf0f48b8387
",git fetch https://review.opendev.org/openstack/devstack refs/changes/39/137039/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/trove'],1,7c11712fa4ba7cf2325681e61dfe0bee4239f985,fix-trove-templates, # Make sure that datastore templates are available in $TROVE_CONF_DIR cp -r $TROVE_DIR/trove/templates/ $TROVE_CONF_DIR # Make sure that MongoDB datastore is able to be snipped up proprely in DevStack: # smallfiles = true local mongodb_conf=$TROVE_CONF_DIR/templates/mongodb/config.template sed -i '3 c\smallfiles = true' $mongodb_conf,},8,1
openstack%2Fdevstack~master~Icabdea69cfeefddbe8acf7d7989193ced93ec974,openstack/devstack,master,Icabdea69cfeefddbe8acf7d7989193ced93ec974,Increate time on start for instance datastore,ABANDONED,2014-11-25 13:37:46.000000000,2014-12-22 12:56:38.000000000,,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 8415}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-25 13:37:46.000000000', 'files': ['lib/trove'], 'web_link': 'https://opendev.org/openstack/devstack/commit/1771532b1fd2cada764f6e8c7bfc7dfd955e1e23', 'message': ""Increate time on start for instance datastore\n\nReasons:\n - for passing simple-box int-tests for Cassandra datastore in Trove\n   there's need to increase state_change_wait_time to 1000 secs,\n   that time would be enough to start Cassandra small instances.\n\nChanges:\n - setting state_change_wait_time to 1000 secs\n\nChange-Id: Icabdea69cfeefddbe8acf7d7989193ced93ec974\nRelated-Bug: #1314980\n""}]",0,137062,1771532b1fd2cada764f6e8c7bfc7dfd955e1e23,8,4,1,8415,,,0,"Increate time on start for instance datastore

Reasons:
 - for passing simple-box int-tests for Cassandra datastore in Trove
   there's need to increase state_change_wait_time to 1000 secs,
   that time would be enough to start Cassandra small instances.

Changes:
 - setting state_change_wait_time to 1000 secs

Change-Id: Icabdea69cfeefddbe8acf7d7989193ced93ec974
Related-Bug: #1314980
",git fetch https://review.opendev.org/openstack/devstack refs/changes/62/137062/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/trove'],1,1771532b1fd2cada764f6e8c7bfc7dfd955e1e23,increase-state-change-wait-time-for-guest, iniset $TROVE_CONF_DIR/trove-guestagent.conf DEFAULT state_change_wait_time 1000,,1,0
openstack%2Fopenstack-manuals~master~I571ec09cb525876a561c5b931a3c88ff7f67d5de,openstack/openstack-manuals,master,I571ec09cb525876a561c5b931a3c88ff7f67d5de,Removed mellanox plug-in content in the Configuration Reference Guide and Cloud Administrator Guide,MERGED,2014-12-18 00:16:05.000000000,2014-12-22 12:28:55.000000000,2014-12-22 12:28:54.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 3114}, {'_account_id': 6772}, {'_account_id': 7923}, {'_account_id': 10705}]","[{'number': 1, 'created': '2014-12-18 00:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/05c8563d8bd101a6b0256d645d66b5b493c35662', 'message': 'Removed mellanox plug-in content in the Configuration Reference Guide and Cloud Administrator Guide\n\n1. Removed mellanox plug-in content.\n2. Added plug-in removal notices where appropriate.\n\nChange-Id: I571ec09cb525876a561c5b931a3c88ff7f67d5de\nbackport: none\nCloses-Bug: #1403206\n'}, {'number': 2, 'created': '2014-12-19 03:52:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ffc5e0d6939a8005bab8a232655c16e2498fcfa0', 'message': 'Removed mellanox plug-in content in the Configuration Reference Guide and Cloud Administrator Guide\n\n1. Removed mellanox plug-in content.\n2. Added plug-in removal notices where appropriate.\n\nChange-Id: I571ec09cb525876a561c5b931a3c88ff7f67d5de\nbackport: none\nCloses-Bug: #1403206\n'}, {'number': 3, 'created': '2014-12-22 02:27:53.000000000', 'files': ['doc/admin-guide-cloud/networking/section_networking_introduction.xml', 'doc/common/tables/neutron-mlnx.xml', 'doc/config-reference/networking/section_networking-plugins.xml', 'doc/config-reference/networking/section_networking-plugins-ml2.xml', 'doc/common/tables/neutron-ml2_mlnx.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/850fd7bff89fd1bc99aef50224cc4dfaf39a0eb8', 'message': 'Removed mellanox plug-in content in the Configuration Reference Guide and Cloud Administrator Guide\n\n1. Removed mellanox plug-in content.\n2. Added plug-in removal notices where appropriate.\n\nChange-Id: I571ec09cb525876a561c5b931a3c88ff7f67d5de\nbackport: none\nCloses-Bug: #1403206\n'}]",6,142617,850fd7bff89fd1bc99aef50224cc4dfaf39a0eb8,17,7,3,10705,,,0,"Removed mellanox plug-in content in the Configuration Reference Guide and Cloud Administrator Guide

1. Removed mellanox plug-in content.
2. Added plug-in removal notices where appropriate.

Change-Id: I571ec09cb525876a561c5b931a3c88ff7f67d5de
backport: none
Closes-Bug: #1403206
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/17/142617/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud/networking/section_networking_introduction.xml', 'doc/common/tables/neutron-mlnx.xml', 'doc/config-reference/networking/section_networking-plugins.xml', 'doc/config-reference/networking/section_networking-plugins-ml2.xml', 'doc/common/tables/neutron-ml2_mlnx.xml']",5,05c8563d8bd101a6b0256d645d66b5b493c35662,mlnxplugin_remove/darren,,"<?xml version='1.0' encoding='UTF-8'?> <para xmlns=""http://docbook.org/ns/docbook"" version=""5.0""> <!-- Warning: Do not edit this file. It is automatically generated and your changes will be overwritten. The tool to do so lives in openstack-doc-tools repository. --> <table rules=""all"" xml:id=""config_table_neutron_ml2_mlnx""> <caption>Description of Mellanox ML2 mechanism driver configuration options</caption> <col width=""50%""/> <col width=""50%""/> <thead> <tr> <th>Configuration option = Default value</th> <th>Description</th> </tr> </thead> <tbody> <tr> <th colspan=""2"">[ESWITCH]</th> </tr> <tr> <td>vnic_type = mlnx_direct</td> <td>(StrOpt) Type of VM network interface: mlnx_direct or hostdev</td> </tr> </tbody> </table> </para> ",16,111
openstack%2Fbarbican-specs~master~Ifce76a6c6b279111f8476e6804db07c519f59a08,openstack/barbican-specs,master,Ifce76a6c6b279111f8476e6804db07c519f59a08,Add worker retry and future updates support,MERGED,2014-10-13 22:48:31.000000000,2014-12-22 12:13:07.000000000,2014-12-22 12:13:06.000000000,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 7262}, {'_account_id': 7687}, {'_account_id': 7789}, {'_account_id': 8004}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 11970}]","[{'number': 1, 'created': '2014-10-13 22:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/470a8d9d38ef511376748f084a691bc2991e9ba7', 'message': 'Add worker retry and future updates support\n\nThe Barbican worker processes need a means to support retrying failed\nyet recoverable tasks (such as when remote systems are unavailable) and\nfor handling updates for long-running order processes such as\ncertificate generation. This blueprint defines the requirements for\nthis retry and update processing, and proposes an implementation to add\nthis feature.\n\nChange-Id: Ifce76a6c6b279111f8476e6804db07c519f59a08\n'}, {'number': 2, 'created': '2014-10-15 23:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/3fa6a53fe377dd7ed9514d6508c7916ee031519f', 'message': 'Add worker retry and future updates support\n\nThe Barbican worker processes need a means to support retrying failed\nyet recoverable tasks (such as when remote systems are unavailable) and\nfor handling updates for long-running order processes such as\ncertificate generation. This blueprint defines the requirements for\nthis retry and update processing, and proposes an implementation to add\nthis feature.\n\nChange-Id: Ifce76a6c6b279111f8476e6804db07c519f59a08\n'}, {'number': 3, 'created': '2014-10-15 23:07:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/cee18e672eadb359f5eeb4454a5023d32a48c4bf', 'message': 'Add worker retry and future updates support\n\nThe Barbican worker processes need a means to support retrying failed\nyet recoverable tasks (such as when remote systems are unavailable) and\nfor handling updates for long-running order processes such as\ncertificate generation. This blueprint defines the requirements for\nthis retry and update processing, and proposes an implementation to add\nthis feature.\n\nChange-Id: Ifce76a6c6b279111f8476e6804db07c519f59a08\n'}, {'number': 4, 'created': '2014-12-03 00:34:02.000000000', 'files': ['specs/kilo/add-worker-retry-update-support.rst'], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/eb432093e73f48bd4bbea78577e7367018f2e0af', 'message': 'Add worker retry and future updates support\n\nThe Barbican worker processes need a means to support retrying failed\nyet recoverable tasks (such as when remote systems are unavailable) and\nfor handling updates for long-running order processes such as\ncertificate generation. This blueprint defines the requirements for\nthis retry and update processing, and proposes an implementation to add\nthis feature.\n\nChange-Id: Ifce76a6c6b279111f8476e6804db07c519f59a08\n'}]",57,128113,eb432093e73f48bd4bbea78577e7367018f2e0af,29,10,4,7789,,,0,"Add worker retry and future updates support

The Barbican worker processes need a means to support retrying failed
yet recoverable tasks (such as when remote systems are unavailable) and
for handling updates for long-running order processes such as
certificate generation. This blueprint defines the requirements for
this retry and update processing, and proposes an implementation to add
this feature.

Change-Id: Ifce76a6c6b279111f8476e6804db07c519f59a08
",git fetch https://review.opendev.org/openstack/barbican-specs refs/changes/13/128113/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/add-worker-retry-update-support.rst'],1,470a8d9d38ef511376748f084a691bc2991e9ba7,bp/defines,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================================== Add worker retry and future updates support =========================================== Launchpad blueprint: https://blueprints.launchpad.net/barbican/+spec/add-worker-retry-update-support The Barbican worker processes need a means to support retrying failed yet recoverable tasks (such as when remote systems are unavailable) and for handling updates for long-running order processes such as certificate generation. This blueprint defines the requirements for this retry and update processing, and proposes an implementation to add this feature. Problem Description =================== Barbican manages asynchronous tasks, such as generating secrets, via datastore tracking entities such as orders (currently the only tracking entity in Barbican). These entities have a status field that tracks their state, starting with PENDING for new entities, and moving to either ACTIVE or ERROR states for successful or unsuccessful termination of the asynchronous task respectively. Barbican worker processes implement these asynchronous tasks, as depicted on this wiki page: https://github.com/cloudkeep/barbican/wiki/Architecture As shown in the diagram, a typical deployment can include multiple worker processes operating in parallel off a tasking queue. The queue invokes task methods on the worker processes via RPC. In some cases, these invoked tasks require the entity (eg. order) to stay PENDING, either to allow for follow on processing in the future or else to retry processing due to a temporary blocking condition (eg. remote service is not available at this time). The following are requirements for retrying tasks in the future and thus keeping the tracking entity in the PENDING state:: R-1) Barbican needs to support extended workflow processes whereby an entity might be PENDING for a long time, requiring periodic status checks to see if the workflow is completed R-2) Barbican needs to support re-attempting an RPC task at some point in the future if a dependent services are temporarily unavailable Note that this blueprint does not handle concurrent updates made to the same entity, say to perform a periodic status check on an order and also apply client updates to that same order. This will be addressed in a future blueprint. Note also that this blueprint does handle with entities that are 'stuck' in the PENDING state because of lost messages in the queue or workers that crash while processing an entity. This will also be addressed in a future blueprint. In addition, the following non-functional requirements are needed in the final implementation:: NF-1) To keep entity state consistent, only one worker can work on an entity or manage retrying tasks at a time. NF-2) For resilience of the worker cluster: a) Any worker process (of a cluster of workers) should be able to handle retrying entities independently of other worker processes, even if these worker processes are intermittently available. b) If a worker comes back online after going down, it should be able to start processing retry tasks again, without need to synchronize with other workers. NF-3) In the default standalone Barbican implementation, it should be possible to demonstrate the periodic status check feature via the SimpleCertificatePlugin class in barbican.plugin.simple_certificate-Manager.py. The following assumptions are made:: A-1) Accurate retry times are not required. For example, if a task is to be retried in 5 minutes, it would be acceptable if the task was actually retried after more than 5 minutes. This allows for more granular retry checking intervals, and to allow for delays due to excessive tasks in queues during busy times. Proposed Change =============== This blueprint proposes that for requirements R-1 and R-2, the plugins used by worker tasks (such as the certificate plugin) determine if tasks should be retried and at what point in the future. If plugins determine that a task should be retried, then these tasks will be scheduled for a future retry attempt. To implement this scheduling process, this blueprint proposes using the Oslo periodic task feature for each worker node that invoke a method on a scheduled basis (configurable, say every 15 seconds). This method would then query which tasks need to be retried (if current time >= retry time), and for each one issue a retry task message to the queue. Once tasks are enqueued, this method would remove the retry records from the retry list. Eventually the queue would invoke workers to implement these retry tasks. To provide a means to evaluate the retry feature in standalone Barbican per NF-3, the SimpleCertificatePlugin class in barbican.plugin.simple_certificate_manager.py would be modified to have the issue_certificate_request() method return a retry time of 5 seconds (configurable). The check_certificate_status() method would then return a successful execution to terminate the order in the ACTIVE state. This blueprint proposes adding the following new entities to the data model: OrderRetryTask, EntityLock, and OrderRecordLock. The OrderRetryTask entity would manage which tasks need to be retried on which entities, and would have the following attributes:: 1) id: Primary key for this record. 2) order_id: FK to the order record the retry task is intended for 3) retry_task: The RPC method to invoke for the retry 4) retry_at: The timestamp at or after which to retry the task 5) retry_args: A list of args to send to the retry_task. This list includes the entity ID, so no need for an entity FK in this entity 6) retry_kwargs: A JSON-ified dict of the kwargs to send to retry_task 7) retry_count: A count of how many times this task has been retried New retry records would be added for tasks that need to be retried in the future, as determined by the plugin as part of workflow processing. The next periodic task method invocation would then send this task to the queue for another worker to implement later. The EntityLock entity would manage which worker is allowed to delete from the OrderRetryTask table, since per NF-1 above only one worker should be able to delete from this table. This entity would have the following attributes:: 1) entity_to_lock: The name of the entity to lock ('OrderRetryTask' here). This would be a primary key. 2) worker_host_name: The host name of the worker that has the OrderRetryTask entity 'locked'. 3) created_at: When this table was locked. This entity would only have zero or one records. So the periodic method above would execute the following psuedo code:: Start SQLAlchemy session/transaction try: Attempt to insert a new record into the EntityLock table session.commit() except: session.rollback() return try: Query for retry tasks Send retry tasks to the queue Remove enqueued retry tasks from OrderRetryTask table session.commit() except: session.rollback() finally: Remove record from EntityLock table Clear SQLAlchemy session/transaction Lock tables can be problematic if the locking process crashes without removing the locks. The overall time a worker holds on to a lock should be brief however, so the lock attempt rollback process above could check for and remove a stale lock based on the 'created_at' time on the lock. To separate coding concerns, it makes sense to implement this process in a separate Oslo server process, similar to the `Keystone listener approach <https://github.com/openstack/barbican/blob/master/barbican/queue/keystone_listener.py#L130>`_ Alternatives ------------ Rather than having each worker process manage retrying tasks, a separate node could be designated to manage these retries. This would eliminate the need for the EntityLock entity. However, this approach would require configuring yet another node in the Barbican network, adding to deployment complexity. This manager node would also be a single point of failure for managing retry tasks. Data model impact ----------------- As mentioned above, two new entities would be required. No migrations would be needed. REST API impact --------------- None Security impact --------------- None Notifications & Audit Impact ---------------------------- None Other end user impact --------------------- None Performance Impact ------------------ The addition of a periodic task to identify task to be retried presents an extra load on the worker nodes (assuming they are co-located processes to the normal worker processing, as expected). However, this process does not perform the retry work, but rather issues tasks into the queue to then evenly distribute back to the worker processes. Hence the additional load on a given worker should be minimal. This proposal includes utilizing locks to deal with concurrency concerns, which could result in 'stuck' locks. Since the conditions which involve locks are either long-running orders that can suffer delays until locks are restored, or (hopefully) rare conditions when resources aren't available, this condition should not be critical to resolve. The proposal does suggest a means to remove stuck locks utilizing their created-at times. Other deployer impact --------------------- The Barbican configuration file will need a configuration parameter to periodically run the retry-query process, called 'schedule_period_seconds', with a default value of 15 seconds. This parameter would be placed in a new '[scheduler]' group. A configuration parameter called 'retry_lock_timeout_seconds' would be used to release 'stuck' locks on the retry tasks table. This parameter would also be added to the '[scheduler]' group. A configuration parameter called 'delay_before_update_seconds' would be used to configure the amount of time the SimpleCertificatePlugin delays from initiating a demo certificate order to the time the update certificate method is invoked. This parameter would be placed in a new '[simple_certificate]' group. These configurations would be applied and utilized once the revised code base is deployed. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: john-wood-w Other contributors: Chelsea Winfree Work Items ---------- 1) Add data model entities and unit tests, for OrderRetryTask and EntityLock 2) Add logic to SimpleCertificatePlugin per the Approach section, to allow demonstration of retry feature 3) Modify barbican.tasks.certificate_resources.py's _schedule_retry_task to add retry records into OrderRetryTask table 4) Add Oslo periodic task support 5) Implement periodic method, that performs the query for tasks that need to be retried 6) Implement workers sending retry RPC messages back to the queue 7) Add new scripts to launch the Oslo periodic task called bin/barbican-task-scheduler.py and .sh, similar to bin/barbican-keystone-listener.py and .sh 8) Add to the Barbican Devstack gate functional tests a test of the new retry feature via the SimpleCertificatePlugin logic added above 9) Add logic to handle expired locks on the OrderRetryTask table Dependencies ============ None Testing ======= In addition to planned unit testing, the functional Tempest-based tests in the Barbican repository would be augmented to add a test of the new retry feature for the default certificate plugin. Documentation Impact ==================== Developer guides will need to updated, to include the additional periodic retry process detailed above. Deployment guides will need to be updated to specify that a new process needs to executed (for the bin/barbican-task-scheduler.sh process). References ========== None ",,299,0
openstack%2Fglance~master~I214ae6466ac85876cc9589069913258e80db29b5,openstack/glance,master,I214ae6466ac85876cc9589069913258e80db29b5,Bump API version to 2.3,MERGED,2014-12-15 14:11:04.000000000,2014-12-22 11:44:57.000000000,2014-12-22 11:44:55.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 8158}, {'_account_id': 11356}, {'_account_id': 11391}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-12-15 14:11:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9b5ffb0f0c40e46c1f39853f54dafcb711c312c6', 'message': ""Bump API version to 2.3\n\nSome changes have landed in Glance's tree during Kilo that require a\nminor bump to the API. The following change is probably the one that had\nthe biggest impact on the current v2.2 API.\n\n- Allow null fields to be returned: Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6\n\nApiImpact\nDocImpact\n\nChange-Id: I214ae6466ac85876cc9589069913258e80db29b5\n""}, {'number': 2, 'created': '2014-12-15 21:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/62ca35bb5fb822f1d8e773e6a34be6a5c3cf0f68', 'message': ""Bump API version to 2.3\n\nSome changes have landed in Glance's tree during Kilo that require a\nminor bump to the API. The following change is probably the one that had\nthe biggest impact on the current v2.2 API.\n\n- Allow null fields to be returned: Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6\n\nApiImpact\nDocImpact\n\nChange-Id: I214ae6466ac85876cc9589069913258e80db29b5\n""}, {'number': 3, 'created': '2014-12-15 22:59:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b8a1253dee02eda4cd737b6418cc73be7cfb5813', 'message': ""Bump API version to 2.3\n\nSome changes have landed in Glance's tree during Kilo that require a\nminor bump to the API. The following change is probably the one that had\nthe biggest impact on the current v2.2 API.\n\n- Allow null fields to be returned: Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6\n\nApiImpact\nDocImpact\n\nChange-Id: I214ae6466ac85876cc9589069913258e80db29b5\n""}, {'number': 4, 'created': '2014-12-18 16:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9caaf1715bab46ab30d3e591eb2bdd154a30b13e', 'message': ""Bump API version to 2.3\n\nSome changes have landed in Glance's tree during Kilo that require a\nminor bump to the API. The following change is probably the one that had\nthe biggest impact on the current v2.2 API.\n\n- Allow null fields to be returned: Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6\n\nApiImpact\nDocImpact\n\nChange-Id: I214ae6466ac85876cc9589069913258e80db29b5\n""}, {'number': 5, 'created': '2014-12-19 17:56:24.000000000', 'files': ['glance/tests/unit/test_versions.py', 'glance/tests/functional/test_api.py', 'glance/tests/functional/v1/test_ssl.py', 'glance/api/versions.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/40fe44a3fdfe6f7d3b9a1a419d5822e6759e9e28', 'message': ""Bump API version to 2.3\n\nSome changes have landed in Glance's tree during Kilo that require a\nminor bump to the API. The following change is probably the one that had\nthe biggest impact on the current v2.2 API.\n\n- Allow null fields to be returned: Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6\n\nApiImpact\nDocImpact\n\nChange-Id: I214ae6466ac85876cc9589069913258e80db29b5\n""}]",2,141805,40fe44a3fdfe6f7d3b9a1a419d5822e6759e9e28,34,10,5,6159,,,0,"Bump API version to 2.3

Some changes have landed in Glance's tree during Kilo that require a
minor bump to the API. The following change is probably the one that had
the biggest impact on the current v2.2 API.

- Allow null fields to be returned: Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6

ApiImpact
DocImpact

Change-Id: I214ae6466ac85876cc9589069913258e80db29b5
",git fetch https://review.opendev.org/openstack/glance refs/changes/05/141805/4 && git format-patch -1 --stdout FETCH_HEAD,['glance/api/versions.py'],1,9b5ffb0f0c40e46c1f39853f54dafcb711c312c6,bump-version," build_version_object(2.3, 'v2', 'CURRENT'), build_version_object(2.2, 'v2', 'SUPPORTED'),"," build_version_object(2.2, 'v2', 'CURRENT'),",2,1
openstack%2Fmagnetodb~master~I213aea56c47261d90a2ab0f8b5042bae9da3d8bc,openstack/magnetodb,master,I213aea56c47261d90a2ab0f8b5042bae9da3d8bc,Role based policy implementation,MERGED,2014-09-26 12:53:29.000000000,2014-12-22 11:28:13.000000000,2014-12-22 11:28:12.000000000,"[{'_account_id': 3}, {'_account_id': 5538}, {'_account_id': 8188}, {'_account_id': 8491}, {'_account_id': 8601}, {'_account_id': 8863}, {'_account_id': 10665}, {'_account_id': 11428}]","[{'number': 1, 'created': '2014-09-26 12:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/677fa77dd0c885c5016077f11f1013cf9bd8ab25', 'message': '(WIP) Role based policy checking\n\nThis patch adds role based policy checks in three\noperations. Those are create_table, delete_table\nand list_table. Put the policy file in\n/etc/magnetodb/policy.json\n\nExamples:\n\n""mdb:create_table"" : ""tenant:(tenant_id)s""\nThe above rule would allow someone to create a table in a tenant\nif he has token scoped to that tenant.\n\n""mdb:create_table"" : ""role:XYZ""\nThis rule would allow anyone with role XYZ in any project to\ncreate a table in any project.\n\n""mdb:create_table"" : ""role:XYZ and tenant:(tenant_id)s""\nThis rule would allow someone to create a table in his tenant\nonly provided he has XYZ role in it.\n\n""mdb:create_table"" : ""!""\nThis means that nobody would be allowed to access this api.\n\nChange-Id: I213aea56c47261d90a2ab0f8b5042bae9da3d8bc\n'}, {'number': 2, 'created': '2014-09-26 12:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/6e2d106521412b713e2ec064dae08e1e8c024ad7', 'message': '(WIP) Role based policy checking\n\nThis patch adds role based policy checks in three\noperations. Those are create_table, delete_table\nand list_table. Put the policy file in\n/etc/magnetodb/policy.json\n\nExamples:\n\n""mdb:create_table"" : ""tenant:(tenant_id)s""\nThe above rule would allow someone to create a table in a tenant\nif he has token scoped to that tenant.\n\n""mdb:create_table"" : ""role:XYZ""\nThis rule would allow anyone with role XYZ in any project to\ncreate a table in any project.\n\n""mdb:create_table"" : ""role:XYZ and tenant:(tenant_id)s""\nThis rule would allow someone to create a table in his tenant\nonly provided he has XYZ role in it.\n\n""mdb:create_table"" : ""!""\nThis means that nobody would be allowed to access this api.\n\nChange-Id: I213aea56c47261d90a2ab0f8b5042bae9da3d8bc\n'}, {'number': 3, 'created': '2014-09-26 13:35:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/433941a9edcefb06118705073f1f5e8e4c607088', 'message': '(WIP) Role based policy checking\n\nThis patch adds role based policy checks in three\noperations. Those are create_table, delete_table\nand list_table. Put the policy file in\n/etc/magnetodb/policy.json\n\nExamples:\n\n""mdb:create_table"" : ""tenant:(tenant_id)s""\nThe above rule would allow someone to create a table in a tenant\nif he has token scoped to that tenant.\n\n""mdb:create_table"" : ""role:XYZ""\nThis rule would allow anyone with role XYZ in any project to\ncreate a table in any project.\n\n""mdb:create_table"" : ""role:XYZ and tenant:(tenant_id)s""\nThis rule would allow someone to create a table in his tenant\nonly provided he has XYZ role in it.\n\n""mdb:create_table"" : ""!""\nThis means that nobody would be allowed to access this api.\n\nbp : support-roles\n\nChange-Id: I213aea56c47261d90a2ab0f8b5042bae9da3d8bc\n'}, {'number': 4, 'created': '2014-10-06 12:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/57e56883d31ade720bf05877905e2cc6fd0691f7', 'message': '(WIP) Role based policy implementation\n\nThis patch adds role based policy checks in three\noperations. Those are create_table, delete_table\nand list_table. Put the policy file in\n/etc/magnetodb/policy.json\n\nA rule ""mdb:create_table"":""role:admin or tenant:(tenant_id)s""\nmeans that anyone having role admin or anyone having a token\nscoped to project whose project_id is present in the url can\ncreate a table.\n\nA rule ""mdb:list_table"":""!"" means that nobody would be allowed\nto access the api applying this check.\n\nbp : support-roles\n\nChange-Id: I213aea56c47261d90a2ab0f8b5042bae9da3d8bc\n'}, {'number': 5, 'created': '2014-11-05 15:19:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/19b933980659a49a45100d492322bd6bd86abb9b', 'message': '(WIP) Role based policy implementation\n\nThis patch adds role based policy checks in three\noperations. Those are create_table, delete_table\nand list_table. Put the policy file in\n/etc/magnetodb/policy.json\n\nA rule ""mdb:create_table"":""role:admin or tenant:(tenant_id)s""\nmeans that anyone having role admin or anyone having a token\nscoped to project whose project_id is present in the url can\ncreate a table.\n\nA rule ""mdb:list_table"":""!"" means that nobody would be allowed\nto access the api applying this check.\n\nbp : support-roles\n\nChange-Id: I213aea56c47261d90a2ab0f8b5042bae9da3d8bc\n'}, {'number': 6, 'created': '2014-11-10 14:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/392687c1841209563064a9ec7453450f16be2ab0', 'message': 'Role based policy implementation\n\nIt adds role bases access control in all openstack apis of\nMagnetoDB.The policy file lives in /etc/magnetodb/policy.json.\n\nA rule ""mdb:create_table"":""role:admin or tenant:(tenant_id)s""\nmeans that anyone having role admin or anyone having a token\nscoped to project whose project_id is present in the url can\ncreate a table.\n\nA rule ""mdb:list_table"":""!"" means that nobody would be allowed\nto access the api applying this check.\n\nA rule ""mdb:list_table"":"""" means that everyone is allowed to\naccess the api.\n\nbp : support-roles\n\nChange-Id: I213aea56c47261d90a2ab0f8b5042bae9da3d8bc\n'}, {'number': 7, 'created': '2014-11-18 14:10:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/05fd8e5982ce76aa66839d69d4cac08f9d39a578', 'message': 'Role based policy implementation\n\nIt adds role bases access control in all openstack apis of\nMagnetoDB.The policy file lives in /etc/magnetodb/policy.json.\n\nA rule ""mdb:create_table"":""role:admin or tenant:(tenant_id)s""\nmeans that anyone having role admin or anyone having a token\nscoped to project whose project_id is present in the url can\ncreate a table.\n\nA rule ""mdb:list_table"":""!"" means that nobody would be allowed\nto access the api applying this check.\n\nA rule ""mdb:list_table"":"""" means that everyone is allowed to\naccess the api.\n\nbp : support-roles\n\nChange-Id: I213aea56c47261d90a2ab0f8b5042bae9da3d8bc\n'}, {'number': 8, 'created': '2014-11-18 14:23:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/c904c9bf14f7fb3e1f534a9334594b758f2e8299', 'message': 'Role based policy implementation\n\nIt adds role bases access control in all openstack apis of\nMagnetoDB.The policy file lives in /etc/magnetodb/policy.json.\n\nA rule ""mdb:create_table"":""role:admin or tenant:(tenant_id)s""\nmeans that anyone having role admin or anyone having a token\nscoped to project whose project_id is present in the url can\ncreate a table.\n\nA rule ""mdb:list_table"":""!"" means that nobody would be allowed\nto access the api applying this check.\n\nA rule ""mdb:list_table"":"""" means that everyone is allowed to\naccess the api.\n\nbp : support-roles\n\nChange-Id: I213aea56c47261d90a2ab0f8b5042bae9da3d8bc\n'}, {'number': 9, 'created': '2014-11-21 10:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/013ed21e634887817c389f9676d14698d53303c9', 'message': 'Role based policy implementation\n\nIt adds role bases access control in all openstack apis of\nMagnetoDB.The policy file lives in /etc/magnetodb/policy.json.\n\nA rule ""mdb:create_table"":""role:admin or tenant:(tenant_id)s""\nmeans that anyone having role admin or anyone having a token\nscoped to project whose project_id is present in the url can\ncreate a table.\n\nA rule ""mdb:list_tables"":""!"" means that nobody would be allowed\nto access the api applying this check.\n\nA rule ""mdb:list_tables"":"""" means that everyone is allowed to\naccess the api.\n\nThe rule ""default"" applies for the rules which are not present\nin the policy.json file. For example if you remove all the rules\nand keep just ""default"":"""" then all the apis are accessible by\neveryone.\n\nbp : support-roles\n\nChange-Id: I213aea56c47261d90a2ab0f8b5042bae9da3d8bc\n'}, {'number': 10, 'created': '2014-12-08 12:47:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/8b41882142c8557218dddd903270dfa7348c5102', 'message': 'Role based policy implementation\n\nIt adds role bases access control in all openstack apis of\nMagnetoDB.The policy file lives in /etc/magnetodb/policy.json.\n\nA rule ""mdb:create_table"":""role:admin or tenant:(tenant_id)s""\nmeans that anyone having role admin or anyone having a token\nscoped to project whose project_id is present in the url can\ncreate a table.\n\nA rule ""mdb:list_tables"":""!"" means that nobody would be allowed\nto access the api applying this check.\n\nA rule ""mdb:list_tables"":"""" means that everyone is allowed to\naccess the api.\n\nThe rule ""default"" applies for the rules which are not present\nin the policy.json file. For example if you remove all the rules\nand keep just ""default"":"""" then all the apis are accessible by\neveryone.\n\nbp : support-roles\n\nChange-Id: I213aea56c47261d90a2ab0f8b5042bae9da3d8bc\n'}, {'number': 11, 'created': '2014-12-10 14:02:22.000000000', 'files': ['magnetodb/api/openstack/v1/data/update_item.py', 'magnetodb/common/middleware/context.py', 'magnetodb/policy.py', 'magnetodb/tests/unittests/common/policy_fixture.py', 'magnetodb/api/__init__.py', 'magnetodb/api/openstack/v1/data/put_item.py', 'magnetodb/api/openstack/v1/data/scan.py', 'magnetodb/api/openstack/v1/data/batch_get_item.py', 'magnetodb/api/openstack/v1/data/create_table.py', 'magnetodb/common/utils/fileutil.py', 'magnetodb/openstack/common/context.py', 'etc/policy.json', 'magnetodb/api/openstack/v1/data/get_item.py', 'magnetodb/api/openstack/v1/data/query.py', 'magnetodb/api/openstack/v1/data/delete_table.py', 'magnetodb/tests/unittests/api/openstack/v1/test_base_testcase.py', 'magnetodb/api/openstack/v1/data/batch_write_item.py', 'magnetodb/tests/unittests/common/test_policy.py', 'magnetodb/api/openstack/v1/data/delete_item.py', 'magnetodb/common/exception.py', 'magnetodb/api/openstack/v1/data/list_tables.py', 'magnetodb/api/openstack/v1/data/describe_table.py', 'magnetodb/openstack/common/policy.py', 'magnetodb/tests/unittests/api/openstack/v1/test_create_table.py'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/1a978c6b8687f4044d62bc50145745c5e74984d8', 'message': 'Role based policy implementation\n\nIt adds role bases access control in all openstack apis of\nMagnetoDB.The policy file lives in /etc/magnetodb/policy.json.\n\nA rule ""mdb:create_table"":""role:admin"" means that anyone having\nrole admin can create a table.\n\nA rule ""mdb:list_tables"":""!"" means that nobody would be allowed\nto access the api applying this check.\n\nA rule ""mdb:list_tables"":"""" means that everyone is allowed to\naccess the api.\n\nThe rule ""default"" applies for the rules which are not present\nin the policy.json file. For example if you remove all the rules\nand keep just ""default"":"""" then all the apis are accessible by\neveryone.\n\nbp : support-roles\n\nChange-Id: I213aea56c47261d90a2ab0f8b5042bae9da3d8bc\n'}]",19,124391,1a978c6b8687f4044d62bc50145745c5e74984d8,44,8,11,11428,,,0,"Role based policy implementation

It adds role bases access control in all openstack apis of
MagnetoDB.The policy file lives in /etc/magnetodb/policy.json.

A rule ""mdb:create_table"":""role:admin"" means that anyone having
role admin can create a table.

A rule ""mdb:list_tables"":""!"" means that nobody would be allowed
to access the api applying this check.

A rule ""mdb:list_tables"":"""" means that everyone is allowed to
access the api.

The rule ""default"" applies for the rules which are not present
in the policy.json file. For example if you remove all the rules
and keep just ""default"":"""" then all the apis are accessible by
everyone.

bp : support-roles

Change-Id: I213aea56c47261d90a2ab0f8b5042bae9da3d8bc
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/91/124391/8 && git format-patch -1 --stdout FETCH_HEAD,"['magnetodb/common/exception.py', 'magnetodb/api/openstack/v1/delete_table.py', 'magnetodb/api/openstack/v1/list_tables.py', 'magnetodb/common/utils/util.py', 'magnetodb/common/middleware/context.py', 'magnetodb/openstack/common/policy.py', 'magnetodb/policy.py', 'magnetodb/openstack/common/context.py', 'etc/policy.json', 'magnetodb/api/openstack/v1/create_table.py']",10,677fa77dd0c885c5016077f11f1013cf9bd8ab25,bp/support-roles,"from magnetodb import policy # utils.check_project_id(req.context, project_id) # Pass project_id attribute from the URL to policy engine. policy.enforce(req.context, ""mdb:create_table"", {'tenant_id':project_id})"," utils.check_project_id(req.context, project_id) req.context.tenant = project_id",993,11
openstack%2Foslo-incubator~stable%2Fjuno~If4ee7ed09696c3f5f3273f4d280c567b328ca75c,openstack/oslo-incubator,stable/juno,If4ee7ed09696c3f5f3273f4d280c567b328ca75c,ServiceRestartTest: make it more resilient,MERGED,2014-11-10 16:18:05.000000000,2014-12-22 11:10:16.000000000,2014-12-22 11:10:15.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-11-10 16:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/6d16380be9074817645d28888654cb7466625327', 'message': 'Restart child processes gracefully if greenlet thread gets killed\n\nIf ServiceLauncher is run from within a thread we should be able to\ncall wait after the thread is killed to restart the child processes.\nCatching this exception and then proceeding to the restart phase\naccomplishes this.\n\nCloses-Bug: #1382573\nChange-Id: If4ee7ed09696c3f5f3273f4d280c567b328ca75c\n'}, {'number': 2, 'created': '2014-11-10 16:42:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/0ba38cb188b02bc0ca260f1386ffdbe6f8788daa', 'message': 'Restart child processes gracefully if greenlet thread gets killed\n\nIf ServiceLauncher is run from within a thread we should be able to\ncall wait after the thread is killed to restart the child processes.\nCatching this exception and then proceeding to the restart phase\naccomplishes this.\n\nCloses-Bug: #1382573\nChange-Id: If4ee7ed09696c3f5f3273f4d280c567b328ca75c\n'}, {'number': 4, 'created': '2014-11-25 11:45:21.000000000', 'files': ['tests/unit/test_service.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/686682699630b4a4366894e15467da82a36d1100', 'message': ""ServiceRestartTest: make it more resilient\n\nThe test spawned new processes to run services in, but didn't guard test\nsuite with due attention not to leak those processes into test\nenvironment.\n\nProper guarding mechanism is already implemented for another test,\nServiceLauncherTest. Hence it was moved to their common ancestor\n(ServiceTestBase) and reused in both test classes.\n\nCloses-Bug: #1382573\nChange-Id: If4ee7ed09696c3f5f3273f4d280c567b328ca75c\n(cherry picked from commit 3c94482a8f7ebc86866b6793ffde1a58bdd2b00d)\n""}]",0,133515,686682699630b4a4366894e15467da82a36d1100,13,3,3,9656,,,0,"ServiceRestartTest: make it more resilient

The test spawned new processes to run services in, but didn't guard test
suite with due attention not to leak those processes into test
environment.

Proper guarding mechanism is already implemented for another test,
ServiceLauncherTest. Hence it was moved to their common ancestor
(ServiceTestBase) and reused in both test classes.

Closes-Bug: #1382573
Change-Id: If4ee7ed09696c3f5f3273f4d280c567b328ca75c
(cherry picked from commit 3c94482a8f7ebc86866b6793ffde1a58bdd2b00d)
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/15/133515/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/service.py'],1,6d16380be9074817645d28888654cb7466625327,(detached," try: status, signo = self._wait_for_exit_or_signal(ready_callback) if not _is_sighup_and_daemon(signo): return status except eventlet.greenlet.GreenletExit: LOG.info(_LI(""Wait called after thread killed. Cleaning up."")) LOG.info(_LI(""Wait called after thread killed. Cleaning up.""))"," status, signo = self._wait_for_exit_or_signal(ready_callback) if not _is_sighup_and_daemon(signo): return status LOG.info(_LI(""Wait called after thread killed. Cleaning up.""))",7,4
openstack%2Fnova~master~I7c51f6191f0acd73957e41d361485da8d937586d,openstack/nova,master,I7c51f6191f0acd73957e41d361485da8d937586d,Add debug log for connection information while attaching volume,ABANDONED,2014-08-05 08:04:39.000000000,2014-12-22 11:09:55.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 2243}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6849}, {'_account_id': 7730}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 9796}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10618}]","[{'number': 1, 'created': '2014-08-05 08:04:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ee15efe2ecd26cfb76b8c8a68bb7e3334d31192', 'message': ""Add debug log for connection information while attaching volume\n\nWhen attach volume to an instance, need collect two kinds of connection\ninformation: instance's host connection information like iscsi initiator,\nwwpns etc. and volume connection information. These are useful for\ndebugging, so it'd better record these information.\n\nChange-Id: I7c51f6191f0acd73957e41d361485da8d937586d\n""}, {'number': 2, 'created': '2014-08-19 05:30:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a7943bbc72f0d16a98e6c1249bf48309ec6f2450', 'message': ""Add debug log for connection information while attaching volume\n\nWhen attach volume to an instance, need collect two kinds of connection\ninformation: instance's host connection information like iscsi initiator,\nwwpns etc. and volume connection information. These are useful for\ndebugging, so it'd better record these information.\n\nChange-Id: I7c51f6191f0acd73957e41d361485da8d937586d\n""}, {'number': 3, 'created': '2014-09-24 02:17:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/33b2465b671a549458e2d46bf49eb12c0280b346', 'message': ""Add debug log for connection information while attaching volume\n\nWhen attach volume to an instance, need collect two kinds of connection\ninformation: instance's host connection information like iscsi initiator,\nwwpns etc. and volume connection information. These are useful for\ndebugging, so it'd better record these information.\n\nChange-Id: I7c51f6191f0acd73957e41d361485da8d937586d\n""}, {'number': 4, 'created': '2014-12-22 07:06:02.000000000', 'files': ['nova/tests/unit/virt/test_block_device.py', 'nova/virt/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/faf762c7f9fc723a9a0b6a0c64b3c56fa22854d5', 'message': ""Add debug log for connection information while attaching volume\n\nWhen attach volume to an instance, need collect two kinds of connection\ninformation: instance's host connection information like iscsi initiator,\nwwpns etc. and volume connection information. These are useful for\ndebugging, so it'd better record these information.\n\nChange-Id: I7c51f6191f0acd73957e41d361485da8d937586d\n""}]",3,111948,faf762c7f9fc723a9a0b6a0c64b3c56fa22854d5,52,16,4,9796,,,0,"Add debug log for connection information while attaching volume

When attach volume to an instance, need collect two kinds of connection
information: instance's host connection information like iscsi initiator,
wwpns etc. and volume connection information. These are useful for
debugging, so it'd better record these information.

Change-Id: I7c51f6191f0acd73957e41d361485da8d937586d
",git fetch https://review.opendev.org/openstack/nova refs/changes/48/111948/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/block_device.py'],1,0ee15efe2ecd26cfb76b8c8a68bb7e3334d31192,volume_con_debug," LOG.debug(""Got volume connector: %s"", connector) LOG.debug(""Initialized volume %(volume_id)s with connection_info:"" ""%(connection_info)s"", {'volume_id': volume_id, 'connection_info': connection_info})",,4,0
openstack%2Fglance~master~I5df61d9d17cf24ce9b58bebbefb610b7043fc39c,openstack/glance,master,I5df61d9d17cf24ce9b58bebbefb610b7043fc39c,Fixes typo: glance exception additional dot,MERGED,2014-12-22 08:50:49.000000000,2014-12-22 11:08:45.000000000,2014-12-22 11:08:45.000000000,"[{'_account_id': 3}, {'_account_id': 6549}]","[{'number': 1, 'created': '2014-12-22 08:50:49.000000000', 'files': ['glance/api/v2/images.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/b742f80ceee63cac261db978c6d34f4ae8847139', 'message': 'Fixes typo: glance exception additional dot\n\nwhen I try to fix the glanceclient html output, i found the result has\nadditional dot before the word quota,as follow\nDenying attempt to upload image because it exceeds the .quota: The size\nof the data 41126400 will exceed the limit. 11210240 bytes remaining\n\nChange-Id: I5df61d9d17cf24ce9b58bebbefb610b7043fc39c\nCloses-bug: #1404820\n'}]",0,143399,b742f80ceee63cac261db978c6d34f4ae8847139,6,2,1,9337,,,0,"Fixes typo: glance exception additional dot

when I try to fix the glanceclient html output, i found the result has
additional dot before the word quota,as follow
Denying attempt to upload image because it exceeds the .quota: The size
of the data 41126400 will exceed the limit. 11210240 bytes remaining

Change-Id: I5df61d9d17cf24ce9b58bebbefb610b7043fc39c
Closes-bug: #1404820
",git fetch https://review.opendev.org/openstack/glance refs/changes/99/143399/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/api/v2/images.py'],1,b742f80ceee63cac261db978c6d34f4ae8847139,bug/1404820," "" quota: %s"") % utils.exception_to_str(e))"," "" .quota: %s"") % utils.exception_to_str(e))",1,1
openstack%2Fopenstack-manuals~master~I98621bb9d17f397af4d3998d4a4634852aff0747,openstack/openstack-manuals,master,I98621bb9d17f397af4d3998d4a4634852aff0747,Imported Translations from Transifex,MERGED,2014-12-22 06:13:43.000000000,2014-12-22 10:48:52.000000000,2014-12-22 10:48:52.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-22 06:13:43.000000000', 'files': ['doc/install-guide/locale/install-guide.pot', 'doc/config-reference/locale/config-reference.pot', 'doc/image-guide/locale/image-guide.pot', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/common/locale/common.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/cli-reference/locale/cli-reference.pot', 'doc/common/locale/fr.po', 'doc/install-guide/locale/pt_BR.po', 'doc/image-guide/locale/fr.po', 'doc/image-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9b1f9f4e87c44961f5cbb19561a6de5d10d563b0', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I98621bb9d17f397af4d3998d4a4634852aff0747\n'}]",0,143370,9b1f9f4e87c44961f5cbb19561a6de5d10d563b0,10,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I98621bb9d17f397af4d3998d4a4634852aff0747
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/70/143370/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/install-guide.pot', 'doc/config-reference/locale/config-reference.pot', 'doc/image-guide/locale/image-guide.pot', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/common/locale/common.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/cli-reference/locale/cli-reference.pot', 'doc/common/locale/fr.po', 'doc/install-guide/locale/pt_BR.po', 'doc/image-guide/locale/fr.po', 'doc/image-guide/locale/ja.po']",13,9b1f9f4e87c44961f5cbb19561a6de5d10d563b0,transifex/translations,"""POT-Creation-Date: 2014-12-22 02:28+0000\n"" ""PO-Revision-Date: 2014-12-22 01:16+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""""the line \""touch /var/lock/subsys/local\"". This code fragment is taken from ""msgstr """"","""POT-Creation-Date: 2014-12-11 05:08+0000\n"" ""PO-Revision-Date: 2014-12-11 05:40+0000\n"" ""Last-Translator: Tomoyuki KATO <tomo@dream.daynight.jp>\n""""the line “touch /var/lock/subsys/local”. This code fragment is taken from ""msgstr ""SSH 公開鍵を取得し、root アカウントに追加するために、<filename>/etc/rc.local</filename> ファイルを編集し、「touch /var/lock/subsys/local」行の前に以下の行を追加します。このコードは、<link href=\""https://github.com/rackerjoe/oz-image-build/blob/master/templates/centos60_x86_64.tdl\"">rackerjoe oz-image-build CentOS 6 template</link> から引用しました。""",484,346
openstack%2Foperations-guide~master~I1dd92196a66735451fe94376b6c658ba02a6e9df,openstack/operations-guide,master,I1dd92196a66735451fe94376b6c658ba02a6e9df,Imported Translations from Transifex,MERGED,2014-12-22 06:00:20.000000000,2014-12-22 10:45:33.000000000,2014-12-22 10:45:32.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-22 06:00:20.000000000', 'files': ['doc/openstack-ops/locale/openstack-ops.pot', 'doc/openstack-ops/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/d236c219e8d47781606560a06ab557b641069b4a', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I1dd92196a66735451fe94376b6c658ba02a6e9df\n'}]",0,143367,d236c219e8d47781606560a06ab557b641069b4a,12,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I1dd92196a66735451fe94376b6c658ba02a6e9df
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/67/143367/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/openstack-ops/locale/openstack-ops.pot', 'doc/openstack-ops/locale/ja.po']",2,d236c219e8d47781606560a06ab557b641069b4a,transifex/translations,"""POT-Creation-Date: 2014-12-22 01:02+0000\n"" ""PO-Revision-Date: 2014-12-22 01:02+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgid ""Manually Disassociating a Floating IP""msgstr ""<xref linkend=\""thirdparty-table\""/> および <xref linkend=\""openstack-config-table\""/> には、サードパーティーおよび OpenStack の両方のコンポーネントの設定例および考慮事項を記載しています<indexterm class=\""singular\""><primary>OpenStack Networking (neutron)</primary><secondary>サードパーティーコンポーネントの設定</secondary></indexterm>: <table rules=\""all\"" xml:id=\""thirdparty-table\""><caption>Third-party component configuration</caption><col width=\""10%\""/><col width=\""30%\""/><col width=\""30%\""/><col width=\""30%\""/><thead><tr><th>コンポーネント</th><th>チューニング</th><th>可用性</th><th>拡張性</th></tr></thead><tbody><tr><td>MySQL</td><td><literal>binlog-format = row</literal></td><td>マスター/マスターレプリケーション。ただし、両ノードは同時には使用されません。レプリケーションにより、全ノードは可能な限り最新に近い状態で維持されます (ただし、非同期レプリケーションの性質により、完全な一貫性を確保することは不可能です)。データベースへの接続は、Pacemaker の仮想 IP を使用してのみ行い、マスター/マスターレプリケーションで発生する大半の問題を回避することができるようにします。</td><td>大きくは考慮されません。MySQL サーバーの負荷が十分に高くなったら、拡張性を検討する必要があり、マスターを複数またはマスター/スレーブ設定を 1 つ使用することができます。</td></tr><tr><td>Qpid</td><td><literal>max-connections=1000</literal><literal>worker-threads=20</literal><literal>connection-backlog=10</literal>、SASL-BASIC 認証で sasl セキュリティを有効化</td><td>Qpid は、配置先のコントローラーノードで実行されるPacemaker ソフトウェアにリソースとして追加されます。これにより、1 回に実行される Qpid インスタンスは 1 つのみとなり、Pacemaker の仮想 IP が割り当てられているノードが、常に Qpid を実行するノードとなります。</td><td>大きくは考慮されません。ただし、拡張性と可用性を目的として、Qpid を全コントローラーノードで実行するように変更し、Pacemaker から削除することが可能です。</td></tr><tr><td>HAProxy</td><td><literal>maxconn 3000</literal></td><td>HAProxy は、クラスター化されたすべての OpenStack API コンポーネントのフロントドアに使用して、すべての SSL 終了を実行するソフトウェア L7 ロードバランサーです。HAProxy は、配置先のコントローラーノードで実行される Pacemaker ソフトウェアにリソースとして追加することができます。これにより、1 回に実行されるHAProxy インスタンスは 1 つのみとなり、Pacemaker の仮想 IP が割り当てられているノードが、常に HAProxy を実行するノードとなります。</td><td>考慮されません。HAProxy はパフォーマンスオーバーヘッドが十分小さいので、1 つのインスタンスで。このレベルのワークロードには十分に拡張できるはずです。さらなる拡張性が要求される場合には、<literal>keepalived</literal> またはその他の L4 ロードバランシングを HAProxy の複数コピーの前に配置することができます。</td></tr><tr><td>Memcached</td><td><literal>MAXCONN=\""8192\"" CACHESIZE=\""30457\""</literal></td><td>Memcached は、OpenStack コンポーネントがデータのキャッシュとパフォーマンス向上のために使用する高速のインメモリーキー値キャッシュソフトウェアです。Memcached は、全コントローラーノード上で実行して、いずれかが停止した場合には、別の Memcached インスタンスが利用できるようにします。</td><td>考慮されません。単一の Memcached インスタンスで必要なワークロードに拡張可能なはずです。拡張性が要求される場合には、HAProxy を Memcached の前に (raw <literal>tcp</literal> モードで) 配置して、複数の Memcached インスタンスを活用することで拡張性を実現することができます。ただし、これにより、キャッシュの一貫性に問題が生じる可能性があります。</td></tr><tr><td>Pacemaker</td><td><phrase role=\""keep-together\""><literal>corosync</literal> および </phrase><literal>cman</literal> をクラスター通信スタック/クォーラムマネージャーおよび 2 ノード構成のクラスターとして使用するように設定。</td><placeholder-1/><td>それよりも多い数のノードをクラスターに認識させる必要がある場合には、Pacemaker は 64 ノードまで拡張が可能です。</td></tr><tr><td>GlusterFS</td><td><literal>glusterfs</literal> パフォーマンスプロファイル \""virt\"" を全ボリュームで有効化。ボリュームは 2 ノードレプリケーションに設定。</td><td>Glusterfs は、環境内で永続的な拡張性のあるデータストレージを提供するためにストレージノード上で実行するクラスター化したファイルシステムです。gluster への接続にはすべて <literal>gluster</literal> ネイティブのマウントポイントを使用するので、<literal>gluster</literal> インスタンス自体が可用性とフェイルオーバー機能を提供します。</td><td>GlusterFS ストレージの拡張性は、ストレージボリュームを追加することによって実現することができます。</td></tr></tbody></table><table rules=\""all\"" xml:id=\""openstack-config-table\""><caption>OpenStack コンポーネントの設定</caption><col width=\""8%\""/><col width=\""8%\""/><col width=\""25%\""/><col width=\""29%\""/><col width=\""30%\""/><thead><tr><th>コンポーネント</th><th>ノードタイプ</th><th>チューニング</th><th>可用性</th><th>拡張性</th></tr></thead><tbody><tr><td>Dashboard (horizon)</td><td>コントローラー</td><td>セッションストアとして Memcached を使用するように設定、 <literal>neutron</literal> サポートの有効化、 <literal>can_set_mount_point = False</literal></td><td>ダッシュボードは、全コントローラーノード上で実行され、ノードに障害が発生した場合には、少なくとも 1 インスタンスが利用可能な状態となるようにします。また、ソフトウェアの障害発生時に検出し、障害が発生したインスタンスを迂回してルーティングする HAProxy の背後に配置されます。</td><td>ダッシュボードは全コントローラー上で実行されるため、追加のコントローラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴うダッシュボードの拡張性を可能にします。</td></tr><tr><td>Identity (keystone)</td><td>コントローラー</td><td>キャッシングとトークン用の PKI に Memcached を使用するように設定。</td><td>Identity は全ノードで実行され、ノードに障害が発生した場合には少なくとも 1 インスタンスが利用可能な状態となるようにします。Identity も、ソフトウェアの障害発生時に検出し、障害が発生したインスタンスを迂回してルーティングする HAProxy の背後に配置されます。</td><td>Identity は全コントローラーノード上で実行されるため、追加のコントローラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴う Identity の拡張性を可能にします。</td></tr><tr><td>Image Service (glance)</td><td>コントローラー</td><td><literal>/var/lib/glance/images</literal> は ストレージレイヤー外のGluster ボリュームへの GlusterFS ネイティブマウントです。</td><td>Image Service は、全コントローラーノードで実行され、ノードの障害が発生した場合には少なくとも 1 インスタンスが利用できるようにします。これも、ソフトウェアの障害発生時に検出し、障害が発生したインスタンスを迂回してルーティングする HAProxy の背後に配置されます。</td><td>Image Service は全コントローラーノードで実行されるため、追加のコントローラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴う Image Service の拡張性を可能にします。</td></tr><tr><td>Compute (nova)</td><td>コントローラー、コンピュート</td><placeholder-2/><placeholder-3/><td>nova API、scheduler、objectstore、cert,、consoleauth、conductor および vncproxy サービスは、全コントローラーノードで実行されるため、追加のコントラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴う Compute の拡張性を可能にします。コンピュートノードで実行されるサービス (compute、conductor) の拡張性は、コンピュートノードをさらに追加することによって直線的に実現されます。</td></tr><tr><td>Block Storage (cinder)</td><td>コントローラー</td><td>Qpid を使用するように設定<phrase role=\""keep-together\""><literal>qpid_heartbeat = </literal><phrase role=\""keep-together\""><literal>10</literal>、</phrase></phrase>Gluster ネイティブクライアントを使用して、ストレージ層から Block Storage のバックエンドとして<phrase role=\""keep-together\""> Gluster ボリュームを使用するように設定</phrase></td><td>Block Storage API、scheduler、および volume サービスは、全コントローラーノードで実行され、ノードに障害が発生した場合には、少なくとも 1 インスタンスが利用可能な状態となるようにします。Block Storage も、ソフトウェアの障害発生時に検出して、障害が発生したインスタンスを迂回してルーティングする HAProxy の背後に配置されます。.</td><td>Block Storage API、scheduler、および volume サービスは、全コントローラーノードで実行されるため、追加のコントローラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴う Block Storage の拡張性を可能にします。</td></tr><tr><td>OpenStack Networking (neutron)</td><td>コントローラー、コンピュート、ネットワーク</td><td>QPID を使用するように設定<phrase role=\""keep-together\""><literal>qpid_heartbeat = 10</literal></phrase>、カーネル名前空間のサポートの有効化、<literal>tenant_network_type = vlan</literal>、<literal>allow_overlapping_ips = true</literal>、<literal>tenant_network_type = vlan</literal>、<literal>bridge_uplinks = br-ex:em2</literal>、<literal>bridge_mappings = physnet1:br-ex</literal></td><placeholder-4/><td>OpenStack Networking サーバーサービスは、全コントローラーノードで実行されるため、追加のコントローラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴う OpenStack Networking の拡張性を可能にします。OpenStack Networking では、ネットワークノード上で実行されるサービスの拡張性は現在サポートされていないため、考慮されていません。各サービスのコピーを 1 つでワークロードの処理に十分なはずです。コンピュートノードで実行される <literal>ovs-agent</literal> の拡張性は、必要に応じてコンピュートノードをさらに追加することによって実現されます。</td></tr></tbody></table>""msgstr ""本章では、作業環境を設定し、クラウドの全体像を概観するのに役立つ内容を記載します。""msgstr ""pip ユーティリティは、PyPI アーカイブからのパッケージインストールの管理に使用するツールで、大半の Linux ディストリビューションの python-pip パッケージに含まれています。各 OpenStack プロジェクトにはそれぞれ独自のクライアントがあります。サイトで実行するサービスに応じて、以下のパッケージの一部またはすべてをインストールしてください。<indexterm class=\""singular\""><primary>neutron</primary><secondary>python-neutronclient</secondary></indexterm><indexterm class=\""singular\""><primary>swift</primary><secondary>python-swiftclient</secondary></indexterm><indexterm class=\""singular\""><primary>cinder</primary></indexterm><indexterm class=\""singular\""><primary>keystone</primary></indexterm><indexterm class=\""singular\""><primary>glance</primary><secondary>python-glanceclient</secondary></indexterm><indexterm class=\""singular\""><primary>nova</primary><secondary>python-novaclient</secondary></indexterm>""msgstr ""pip を使用して PyPI アーカイブからパッケージをインストール (またはアップグレード) するには、<indexterm class=\""singular\""><primary>コマンドラインツール</primary><secondary>インストール</secondary></indexterm>root として以下のコマンドを実行します。""msgstr ""クラウド上で EC2 API をサポートする場合には、ユーザーと同じビューを表示できるように、euca2ools パッケージまたはその他の EC2 API ツールもインストールする必要があります。EC2 API ベースのツールの使用に関する内容の大半は本ガイドの対象範囲外となりますが、このツールで使用する認証情報の取得方法についての説明は記載しています。""msgstr ""<literal>*-manage</literal> のコマンドラインツールも複数あります。これらは、プロジェクトのサービスとともにクラウドコントローラーにインストールされるので、別途インストールする必要はありません。 <indexterm class=\""singular\""><primary>*-manage コマンドラインツール</primary></indexterm><indexterm class=\""singular\""><primary>コマンドラインツール</primary><secondary>管理系</secondary></indexterm>""msgstr ""<code>*-manage</code> ツールの存在は、レガシーの問題です。OpenStack プロジェクトでは、最終的には <code>*-manage</code> ツールの残りの機能をすべて API ベースのツールに移行することを目標としています。移行が完了するまで、<phrase role=\""keep-together\""><code role=\""keep-together\"">*-manage</code> ツール</phrase> を必要とするメンテナンス操作は、<glossterm>クラウドコントローラーノード</glossterm> に SSH 接続して実行する必要があります。<indexterm class=\""singular\""><primary>クラウドコントローラーノード</primary><secondary>コマンドラインツール</secondary></indexterm>""msgstr ""EC2 互換のクレデンシャルをダウンロードするには、<guimenuitem>プロジェクト</guimenuitem>、<guimenuitem>アクセスとセキュリティ</guimenuitem>、<guimenuitem>API アクセス</guimenuitem> の順に選択し、<guilabel>EC2 認証情報のダウンロード</guilabel> ボタンを表示します。このボタンをクリックすると、 サーバーの x509 証明書とシェルスクリプトフラグメントが含まれた ZIP が生成されます。これらのファイルは、デフォルトの <code>user-openrc</code> とは異なり、クラウドのアイデンティティへのアクセスに必要なすべての認証情報を含む有効なクレデンシャルなので、セキュリティ保護された場所に新規ディレクトリを作成して、そこで ZIP ファイルを展開します。<filename>cacert.pem</filename>、<filename>cert.pem</filename>、<filename>ec2rc.sh</filename>、および <filename>pk.pem</filename> が含まれているはずです。<filename>ec2rc.sh</filename> には、以下と似たような内容が記述されています:<indexterm class=\""singular\""><primary>アクセスキー</primary></indexterm>""msgstr ""コマンドラインツールに <code>--debug</code> フラグを渡すことにより、実行する OpenStack API コールを表示することができます。<indexterm class=\""singular\""><primary>API (Application Programming Interface)</primary><secondary>API コール、検査</secondary></indexterm><indexterm class=\""singular\""><primary>コマンドラインツール</primary><secondary>API コールの検査</secondary></indexterm> 例えば、以下のようになります。""msgstr ""<link href=\""https://wiki.openstack.org/wiki/KeyringSupport\"">キーリングのサポート</link>により、暗号化されたファイルに OpenStack のパスワードをセキュアに保存することができます。<indexterm class=\""singular\""><primary>キーリングのサポート</primary></indexterm>""msgstr ""次の要求での作業をより簡単に行うには、環境変数にトークンを保管します。""msgstr ""上記の cURL コマンドで使用している <code>-s flag</code> は、進行状況メーターが表示されないようにするために使用します。cURL コマンドの実行で問題が生じた場合には、このオプションを削除してください。また、cURL コマンドのトラブルシューティングを行う場合には、<code>-v</code> フラグを指定してより詳細な出力を表示すると役立ちます。cURL には他にも多数の役立つ機能があります。全オプションは、man ページで参照してください。""msgstr ""管理者は、利用可能な OpenStack ツールを使用して、OpenStack クラウドが全体像を確認する方法がいくつかあります。本項では、クラウドの概要、形態、サイズ、現在の状態についての情報を取得する方法について説明します。<indexterm class=\""singular\""><primary>サービス</primary><secondary>概観の取得</secondary></indexterm><indexterm class=\""singular\""><primary>サーバー</primary><secondary概要の取得</secondary></indexterm><indexterm class=\""singular\""><primary>クラウドコンピューティング</primary><secondary>クラウドの全体像</secondary></indexterm><indexterm class=\""singular\""><primary>コマンドラインツール</primary><secondary>サーバーとサービス</secondary></indexterm>""msgstr ""出力には、5 つのコンピュートノードと 1 つのクラウドコントローラーが表示されています。スマイリーフェイス <code>:-)</code> が見えます。これはサービスが稼働中であることを示しています。サービスが利用できなくなると、<code>:-)</code> のシンボルが <code>XXX</code> に変わります。これは、サービスが停止している理由をトラブルシューティングする必要があることを示しています。""msgstr ""以下のコマンドを実行するには、管理系の変数を正しく設定したシェル環境が必要です。""msgstr ""上記の出力は、2 つのサービスのみを表示するようにカットされています。クラウドが提供するサービスごとにサービスブロックが 1 つ表示されているのがわかります。エンドポイントタイプによってエンドポイントドメインが異なる場合がある点に注意してください。タイプによってエンドポイントドメインを別にする必要はありませんが、エンドポイントのプライバシーやネットワークトラフィックの分離などの異なる理由で分けることができます。""msgstr ""実行中の仮想マシンの CPU 使用状況、メモリー、ディスク I/O、ネットワーク I/O などの追加情報を取得するには、<literal>nova diagnostics</literal> コマンドに<indexterm class=\""singular\""><primary>コンピュートノード</primary><secondary>診断</secondary></indexterm><indexterm class=\""singular\""><primary>コマンドラインツール</primary><secondary>コンピュートノードの診断</secondary></indexterm>サーバー ID を指定して実行します:""msgstr ""ハイパーバイザーによってサポートする属性が異なるため、コマンドの出力はハイパーバイザーによって異なります。<indexterm class=\""singular\""><primary>ハイパーバイザー</primary><secondary>コンピュートノードの診断</secondary></indexterm> 以下の実例は、最もよく使用されている 2 つのハイパーバイザーの間で出力がどのように異なるかを示しています。ハイパーバイザーが Xen の場合の例は以下のようになります: <placeholder-1/>このコマンドは、libvirt によって管理されている任意のハイパーバイザー (例: KVM、QEMU、LXC) で機能するはずですが、KVM でのみテスト済みです。ハイパーバイザーが KVM の場合の例は以下のようになります""msgstr ""この出力は、2 つのネットワークが設定されており、各ネットワークには 255 の IP アドレス (/24 サブネットが 1 つ) が含まれていることを示しています。1 番目のネットワークは、特定のプロジェクトに割り当て済みですが、2 番目のネットワークはまだ割り当てができる状態です。このネットワークは手動で割り当てることができます。手動での割り当てを行わなかった場合には、プロジェクトで最初のインスタンスが起動されたときに自動で割り当てられます。""msgstr ""クラウドに追加されたプロジェクトの一覧を確認するには、<indexterm class=\""singular\""><primary>プロジェクト</primary><secondary>現在の一覧の取得</secondary></indexterm><indexterm class=\""singular\""><primary>ユーザー管理</primary><secondary>ユーザーの一覧表示</secondary></indexterm><indexterm class=\""singular\""><primary>作業環境</primary><secondary>users and projects</secondary></indexterm>以下のコマンドを実行します:""msgstr ""ユーザーとグループは、一対一でマッピングされる場合があります。このようなマッピングは cinder、glance、nova、swift などの標準システムアカウントや、グループにユーザーが 1 人しかいない場合に発生します。""msgstr ""実行中のインスタンスを確認するには、<indexterm class=\""singular\""><primary>instances</primary><secondary>実行中の一覧</secondary></indexterm><indexterm class=\""singular\""><primary>作業環境</primary><secondary>実行中のインスタンス</secondary></indexterm>以下のコマンドを実行します:""msgstr ""残念ながら、このコマンドは、インスタンスを実行しているコンピュートノードやインスタンスのフレーバーなどのような、実行中の<phrase role=\""keep-together\"">インスタンス</phrase>についての多様な情報は提供しません。個別のインスタンスについての詳しい情報を確認するには以下のコマンドを使用してください:<indexterm class=\""singular\""><primary>コンフィグドライブ</primary></indexterm>""msgstr ""この出力は、<placeholder-1/> という名前のインスタンスが Ubuntu 12.04 イメージから <literal>m1.small</literal> のフレーバーで作成され、コンピュートノード <literal>c02.example.com</literal> でホストされていることを示しています。""msgstr ""クラウドとの対話や有用な情報の抽出の方法など、作業環境の概観を確認する手順を簡単にご紹介しました。役立てていただければ幸いです。ここで説明した内容よりもさらに詳しい情報は、クラウドの全コマンドライン機能についての参考資料として<emphasis><link href=\""http://docs.openstack.org/user-guide-admin/content/\"">管理ユーザーガイド</link></emphasis>を参照してください。""","""POT-Creation-Date: 2014-12-19 06:54+0000\n"" ""PO-Revision-Date: 2014-12-21 05:50+0000\n"" ""Last-Translator: ykatabam <ykatabam@redhat.com>\n""msgid ""Manually Dissaociating a Floating IP""msgstr ""<xref linkend=\""thirdparty-table\""/> および <xref linkend=\""openstack-config-table\""/> には、サードパーティーおよび OpenStack の両方のコンポーネントの設定例および考慮事項を記載しています<indexterm class=\""singular\""><primary>OpenStack Networking (neutron)</primary><secondary>サードパーティーコンポーネントの設定</secondary></indexterm>: <table rules=\""all\"" xml:id=\""thirdparty-table\""><caption>Third-party component configuration</caption><col width=\""10%\""/><col width=\""30%\""/><col width=\""30%\""/><col width=\""30%\""/><thead><tr><th>コンポーネント</th><th>チューニング</th><th>可用性</th><th>拡張性</th></tr></thead><tbody><tr><td>MySQL</td><td><literal>binlog-format = row</literal></td><td>マスター/マスターレプリケーション。ただし、両ノードは同時には使用されません。レプリケーションにより、全ノードは可能な限り最新に近い状態で維持されます (ただし、非同期レプリケーションの性質により、完全な一貫性を確保することは不可能です)。データベースへの接続は、Pacemaker の仮想 IP を使用してのみ行い、マスター/マスターレプリケーションで発生する大半の問題を回避することができるようにします。</td><td>大きくは考慮されません。MySQL サーバーの負荷が十分に高くなったら、拡張性を検討する必要があり、マスターを複数またはマスター/スレーブ設定を 1 つ使用することができます。</td></tr><tr><td>Qpid</td><td><literal>max-connections=1000</literal><literal>worker-threads=20</literal><literal>connection-backlog=10</literal>、SASL-BASIC 認証で sasl セキュリティを有効化</td><td>Qpid は、配置先のコントローラーノードで実行されるPacemaker ソフトウェアにリソースとして追加されます。これにより、1 回に実行される Qpid インスタンスは 1 つのみとなり、Pacemaker の仮想 IP が割り当てられているノードが、常に Qpid を実行するノードとなります。</td><td>大きくは考慮されません。ただし、拡張性と可用性を目的として、Qpid を全コントローラーノードで実行するように変更し、Pacemaker から削除することが可能です。</td></tr><tr><td>HAProxy</td><td><literal>maxconn 3000</literal></td><td>HAProxy は、クラスター化されたすべての OpenStack API コンポーネントのフロントドアに使用して、すべての SSL 終了を実行するソフトウェア L7 ロードバランサーです。HAProxy は、配置先のコントローラーノードで実行される Pacemaker ソフトウェアにリソースとして追加することができます。これにより、1 回に実行されるHAProxy インスタンスは 1 つのみとなり、Pacemaker の仮想 IP が割り当てられているノードが、常に HAProxy を実行するノードとなります。</td><td>考慮されません。HAProxy はパフォーマンスオーバーヘッドが十分小さいので、1 つのインスタンスで。このレベルのワークロードには十分に拡張できるはずです。さらなる拡張性が要求される場合には、<literal>keepalived</literal> またはその他の L4 ロードバランシングを HAProxy の複数コピーの前に配置することができます。</td></tr><tr><td>Memcached</td><td><literal>MAXCONN=\""8192\"" CACHESIZE=\""30457\""</literal></td><td>Memcached は、OpenStack コンポーネントがデータのキャッシュとパフォーマンス向上のために使用する高速のインメモリーキー値キャッシュソフトウェアです。Memcached は、全コントローラーノード上で実行して、いずれかが停止した場合には、別の Memcached インスタンスが利用できるようにします。</td><td>考慮されません。単一の Memcached インスタンスで必要なワークロードに拡張可能なはずです。拡張性が要求される場合には、HAProxy を Memcached の前に (raw <literal>tcp</literal> モードで) 配置して、複数の Memcached インスタンスを活用することで拡張性を実現することができます。ただし、これにより、キャッシュの一貫性に問題が生じる可能性があります。</td></tr><tr><td>Pacemaker</td><td><phrase role=\""keep-together\""><literal>corosync</literal> および </phrase><literal>cman</literal> をクラスター通信スタック/クォーラムマネージャーおよび 2 ノード構成のクラスターとして使用するように設定。</td><placeholder-1/><td>それよりも多い数のノードをクラスターに認識させる必要がある場合には、Pacemaker は 64 ノードまで拡張が可能です。</td></tr><tr><td>GlusterFS</td><td><literal>glusterfs</literal> パフォーマンスプロファイル \""virt\"" を全ボリュームで有効化。ボリュームは 2 ノードレプリケーションに設定。</td><td>Glusterfs は、環境内で永続的な拡張性のあるデータストレージを提供するためにストレージノード上で実行するクラスター化したファイルシステムです。gluster への接続にはすべて <literal>gluster</literal> ネイティブのマウントポイントを使用するので、<literal>gluster</literal> インスタンス自体が可用性とフェイルオーバー機能を提供します。</td><td>GlusterFS ストレージの拡張性は、ストレージボリュームを追加することによって実現することができます。</td></tr></tbody></table><table rules=\""all\"" xml:id=\""openstack-config-table\""><caption>OpenStack コンポーネントの設定</caption><col width=\""8%\""/><col width=\""8%\""/><col width=\""25%\""/><col width=\""29%\""/><col width=\""30%\""/><thead><tr><th>コンポーネント</th><th>ノードタイプ</th><th>チューニング</th><th>可用性</th><th>拡張性</th></tr></thead><tbody><tr><td>Dashboard (horizon)</td><td>コントローラー</td><td>セッションストアとして Memcached を使用するように設定、 <literal>neutron</literal> サポートの有効化、 <literal>can_set_mount_point = False</literal></td><td>ダッシュボードは、全コントローラーノード上で実行され、ノードに障害が発生した場合には、少なくとも 1 インスタンスが利用可能な状態となるようにします。また、ソフトウェアの障害発生時に検出し、障害が発生したインスタンスを迂回してルーティングする HAProxy の背後に配置されます。</td><td>ダッシュボードは全コントローラー上で実行されるため、追加のコントローラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴うダッシュボードの拡張性を可能にします。</td></tr><tr><td>Identity (keystone)</td><td>コントローラー</td><td>キャッシングとトークン用の PKI に Memcached を使用するように設定。</td><td>Identity は全ノードで実行され、ノードに障害が発生した場合には少なくとも 1 インスタンスが利用可能な状態となるようにします。Identity も、ソフトウェアの障害発生時に検出し、障害が発生したインスタンスを迂回してルーティングする HAProxy の背後に配置されます。</td><td>Identity は全コントローラーノード上で実行されるため、追加のコントローラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴う Identity の拡張性を可能にします。</td></tr><tr><td>Image Service (glance)</td><td>Controller</td><td><literal>/var/lib/glance/images</literal> は ストレージレイヤー外のGluster ボリュームへの GlusterFS ネイティブマウントです。</td><td>Image Service は、全コントローラーノードで実行され、ノードの障害が発生した場合には少なくとも 1 インスタンスが利用できるようにします。これも、ソフトウェアの障害発生時に検出し、障害が発生したインスタンスを迂回してルーティングする HAProxy の背後に配置されます。</td><td>Image Service は全コントローラーノードで実行されるため、追加のコントローラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴う Image Service の拡張性を可能にします。</td></tr><tr><td>Compute (nova)</td><td>コントローラー、コンピュート</td><placeholder-2/><placeholder-3/><td>nova API、scheduler、objectstore、cert,、consoleauth、conductor および vncproxy サービスは、全コントローラーノードで実行されるため、追加のコントラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴う Compute の拡張性を可能にします。コンピュートノードで実行されるサービス (compute、conductor) の拡張性は、コンピュートノードをさらに追加することによって直線的に実現されます。</td></tr><tr><td>Block Storage (cinder)</td><td>コントローラー</td><td>Qpid を使用するように設定<phrase role=\""keep-together\""><literal>qpid_heartbeat = </literal><phrase role=\""keep-together\""><literal>10</literal>、</phrase></phrase>Gluster ネイティブクライアントを使用して、ストレージ層から Block Storage のバックエンドとして<phrase role=\""keep-together\""> Gluster ボリュームを使用するように設定</phrase></td><td>Block Storage API、scheduler、および volume サービスは、全コントローラーノードで実行され、ノードに障害が発生した場合には、少なくとも 1 インスタンスが利用可能な状態となるようにします。Block Storage も、ソフトウェアの障害発生時に検出して、障害が発生したインスタンスを迂回してルーティングする HAProxy の背後に配置されます。.</td><td>Block Storage API、scheduler、および volume サービスは、全コントローラーノードで実行されるため、追加のコントローラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴う Block Storage の拡張性を可能にします。</td></tr><tr><td>OpenStack Networking (neutron)</td><td>Controller、Compute、Network</td><td>QPID を使用するように設定<phrase role=\""keep-together\""><literal>qpid_heartbeat = 10</literal></phrase>、カーネル名前空間のサポートの有効化、<literal>tenant_network_type = vlan</literal>、<literal>allow_overlapping_ips = true</literal>、<literal>tenant_network_type = vlan</literal>、<literal>bridge_uplinks = br-ex:em2</literal>、<literal>bridge_mappings = physnet1:br-ex</literal></td><placeholder-4/><td>OpenStack Networking サーバーサービスは、全コントローラーノードで実行されるため、追加のコントローラーノードで拡張性を実現することができます。HAProxy は、ノードの追加に伴う OpenStack Networking の拡張性を可能にします。OpenStack Networking では、ネットワークノード上で実行されるサービスの拡張性は現在サポートされていないため、考慮されていません。各サービスのコピーを 1 つでワークロードの処理に十分なはずです。コンピュートノードで実行される <literal>ovs-agent</literal> の拡張性は、必要に応じてコンピュートノードをさらに追加することによって実現されます。</td></tr></tbody></table>""msgstr ""本章の内容は、作業環境を設定し、クラウドの考察に使用するのに役立ちます。""msgstr ""pip ユーティリティは、PyPI アーカイブからのパッケージインストールの管理に使用するツールで、大半の Linux ディストリビューションの python-pip パッケージに含まれています。各 OpenStack プロジェクトはそれぞれ独自のクライアントがあります。サイトで実行するサービスに応じて、以下のパッケージの一部またはすべてをインストールしてください。<indexterm class=\""singular\""><primary>neutron</primary><secondary>python-neutronclient</secondary></indexterm><indexterm class=\""singular\""><primary>swift</primary><secondary>python-swiftclient</secondary></indexterm><indexterm class=\""singular\""><primary>cinder</primary></indexterm><indexterm class=\""singular\""><primary>keystone</primary></indexterm><indexterm class=\""singular\""><primary>glance</primary><secondary>python-glanceclient</secondary></indexterm><indexterm class=\""singular\""><primary>nova</primary><secondary>python-novaclient</secondary></indexterm>""msgstr ""pip を使用して PyPI アーカイブからパッケージをインストール (またはアップグレード) するには、<indexterm class=\""singular\""><primary>コマンドラインツール</primary><secondary>インストール</secondary></indexterm> root として以下のコマンドを実行します。""msgstr ""クラウド上で EC2 API をサポートする場合には、ユーザーと同じビューを表示できるように、euca2ools パッケージまたはその他の EC2 API ツールもインストールする必要があります。EC2 API ベースのツールの使用に関する内容の大半は本ガイドの適用範囲外となりますが、このツールで使用する認証情報の取得方法についての説明は記載しています。""msgstr ""また、<literal>*-manage</literal> のコマンドラインツールも複数あります。これらは、プロジェクトのサービスとともにクラウドコントローラーにインストールされるので、別途インストールする必要はありません。 <indexterm class=\""singular\""><primary>*-manage コマンドラインツール</primary></indexterm><indexterm class=\""singular\""><primary>コマンドラインツール</primary><secondary>管理系</secondary></indexterm>""msgstr ""<code>*-manage</code> ツールが存在するのは、レガシーの問題です。OpenStack プロジェクトでは、最終的には <code>*-manage</code> ツールの残りの機能をすべて API ベースのツールに移行することを目標としています。移行が完了するまで、<phrase role=\""keep-together\""><code role=\""keep-together\"">*-manage</code> ツール</phrase> を必要とするメンテナンス操作は、<glossterm>cloud controller node</glossterm> に SSH 接続して実行する必要があります。<indexterm class=\""singular\""><primary>クラウドコントローラーノード</primary><secondary>コマンドラインツール</secondary></indexterm>""msgstr ""EC2 互換のクレデンシャルをダウンロードするには、<guimenuitem>プロジェクト</guimenuitem>、<guimenuitem>アクセスとセキュリティ</guimenuitem>、<guimenuitem>API アクセス</guimenuitem> の順に選択し、<guilabel>EC2 認証情報のダウンロード</guilabel> ボタンを表示します。このボタンをクリックすると、 サーバーの x509 証明書とシェルスクリプトフラグメントが含まれた ZIP が生成されます。これらのファイルは、デフォルトの <code>user-openrc</code> とは異なり、クラウドのアイデンティティへのアクセスに必要なすべての認証情報を含む有効なクレデンシャルなので、セキュリティ保護された場所に新規ディレクトリを作成して、そこで ZIP ファイルを展開します。<filename>cacert.pem</filename>、<filename>cert.pem</filename>、<filename>ec2rc.sh</filename>、および <filename>pk.pem</filename> が含まれているはずです。<filename>ec2rc.sh</filename> には、以下と似たような内容が記述されています:<indexterm class=\""singular\""><primary>access key</primary></indexterm>""msgstr ""コマンドラインツールに <code>--debug</code> フラグを渡すことにより、実行する OpenStack API を表示することができます。<indexterm class=\""singular\""><primary>API (Application Programming Interface)</primary><secondary>API コール、確認</secondary></indexterm><indexterm class=\""singular\""><primary>コマンドラインツール</primary><secondary>API コールの検査</secondary></indexterm> 例えば、以下のようになります。""msgstr ""<link href=\""https://wiki.openstack.org/wiki/KeyringSupport\"">キーリングのサポート</link> により、暗号化されたファイルに OpenStack のパスワードをセキュアに保存することができます。<indexterm class=\""singular\""><primary>キーリングのサポート</primary></indexterm>""msgstr ""後に続く要求への対応を容易にするには、環境変数にトークンを保管します。""msgstr ""上記の cURL コマンドで使用している <code>-s flag</code> は、進行状況メーターが表示されないようにするために使用します。cURL コマンドの実行で問題が生じた場合には、このオプションを削除してください。また、cURL コマンドのトラブるシューティングを行う場合には、<code>-v</code> フラグを指定してより詳細な出力を表示すると役立ちます。cURL には他にも多数の役立つ機能があります。全オプションは、man ページで参照してください。""msgstr ""管理者は、利用可能な OpenStack を使用して、OpenStack クラウドの全容を確認する方法がいくつかあります。本項では、クラウドの概要、形態、サイズ、現在の状態を確認する方法について説明します。<indexterm class=\""singular\""><primary>サービス</primary><secondary>概要の取得</secondary></indexterm><indexterm class=\""singular\""><primary>サーバー</primary><secondary概要の取得</secondary></indexterm><indexterm class=\""singular\""><primary>クラウドコンピューティング</primary><secondary>クラウドの概観</secondary></indexterm><indexterm class=\""singular\""><primary>コマンドラインツール</primary><secondary>サーバーとサービス</secondary></indexterm>""msgstr ""出力には、5 つのコンピュートノードと 1 つのクラウドコントローラーが表示されています。スマイリーフェイス (<code>:-)</code> など)が見えます。これはサービスが稼働中であることを示しています。サービスがりようできなくなると、<code>:-)</code> のシンボルが <code>XXX</code> に変わります。これは、サービスが停止している理由をトラブルシューティングする必要があることを示しています。""msgstr ""以下のコマンドを実行するには、正しい管理用の変数を設定済みのシェル環境が必要です。""msgstr ""上記の出力は、2 つのサービスのみを表示するように、カットされています。クラウドが提供するサービスごとにサービスブロックが 1 つ表示されているのがわかります。エンドポイントタイプによってエンドポイントドメインが異なる点に注意してください。タイプによってエンドポイントドメインを別にする必要ありませんが、エンドポイントのプライバシーやネットワークトラフィックの分離などの異なる理由で分けることができます。""msgstr ""実行中の仮想マシンの CPU 使用状況、メモリー、ディスク I/O、ネットワーク I/O などの追加情報を取得するには、<literal>nova diagnostics</literal> コマンドに<indexterm class=\""singular\""><primary>コンピュートノード</primary><secondary>診断</secondary></indexterm><indexterm class=\""singular\""><primary>コマンドラインツール</primary><secondary>コンピュートノードの診断</secondary></indexterm> サーバー ID を指定して実行します:""msgstr ""ハイパーバイザーによってサポートする属性が異なるため、コマンドの出力はハイパーバイザーによって異なります。<indexterm class=\""singular\""><primary>ハイパーバイザー</primary><secondary>コンピュートノードの診断</secondary></indexterm> 以下の実例は、最もよく使用されている 2 つのハイパーバイザーの間で出力がどのように異なるかを示しています。ハイパーバイザーが Xen の場合の例は以下のようになります: <placeholder-1/>このコマンドは、libvirt によって管理されている任意のハイパーバイザー (例: KVM、QEMU、LXC) で機能しますが、KVM でのみテスト済みです。ハイパーバイザーが KVM の場合の例は以下のようになります""msgstr ""この出力は、2 つのネットワークが設定されており、各ネットワークには 255 の IP アドレス ( /24 サブネットが 1 つ) が含まれていることを示しています。1 番目のネットワークは、特定のプロジェクトに割り当てられていますが、2 番目のネットワークはまだ割り当てができる状態です。このネットワークは手動で割り当てることができます。割り当てられていない場合には、プロジェクトで最初のインスタンスが起動されたときに自動で割り当てられます。""msgstr ""クラウドに追加されたプロジェクトの一覧を確認するには、<indexterm class=\""singular\""><primary>プロジェクト</primary><secondary>現在の一覧の取得</secondary></indexterm><indexterm class=\""singular\""><primary>ユーザー管理</primary><secondary>ユーザーの一覧表示</secondary></indexterm><indexterm class=\""singular\""><primary>作業環境</primary><secondary>users and projects</secondary></indexterm> 以下のコマンドを実行します:""msgstr ""ユーザーおよびグループは、一対一でマッピングされる場合があります。このような状況は cinder、glance、nova、swift などの標準システムアカウントやグループにユーザーが 1 人しかいない場合に発生します。""msgstr ""実行中のインスタンスを確認するには、<indexterm class=\""singular\""><primary>instances</primary><secondary>実行中のリスト</secondary></indexterm><indexterm class=\""singular\""><primary>作業環境</primary><secondary>実行中のインスタンス</secondary></indexterm> 以下のコマンドを実行します:""msgstr """"msgstr """"msgstr """"",31,31
openstack%2Fceilometer~master~I6ce5a82510db45986412753e22275394376d11d6,openstack/ceilometer,master,I6ce5a82510db45986412753e22275394376d11d6,[WIP] Add sample generator for oslo.messaging,ABANDONED,2014-11-01 12:55:07.000000000,2014-12-22 10:35:23.000000000,,"[{'_account_id': 3}, {'_account_id': 7729}]","[{'number': 1, 'created': '2014-11-01 12:55:07.000000000', 'files': ['tools/messaging_sample_generator.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/28c9acb51445407d584e882bf78f1feeacea9b70', 'message': '[WIP] Add sample generator for oslo.messaging\n\nThis generator sends messages to rabbit for collector.\n\nChange-Id: I6ce5a82510db45986412753e22275394376d11d6\n'}]",0,132391,28c9acb51445407d584e882bf78f1feeacea9b70,4,2,1,7729,,,0,"[WIP] Add sample generator for oslo.messaging

This generator sends messages to rabbit for collector.

Change-Id: I6ce5a82510db45986412753e22275394376d11d6
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/91/132391/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/messaging_sample_generator.py'],1,28c9acb51445407d584e882bf78f1feeacea9b70,,"from __future__ import print_function import random import sys import uuid import make_test_data from ceilometer import agent from ceilometer import messaging from ceilometer.openstack.common import jsonutils from ceilometer import service import time import datetime from oslo.config import cfg from ceilometer.publisher import utils def send_batch(rpc_client, rabbit_topic, batch): print(""SEND BATCH. Topic %s."" % rabbit_topic) rpc_client.prepare(topic=rabbit_topic).cast(agent.context.RequestContext(), 'record_metering_data', data=batch) def get_rpc_client(config_file): service.prepare_service(argv=['/', '--config-file', config_file]) transport = messaging.get_transport() rpc_client = messaging.get_rpc_client(transport, version='1.0') return rpc_client def get_parser(parser=None): if not parser: parser = make_test_data.get_parser() parser.add_argument( '--count', default=100000, type=int, help='Count of samples', ) parser.add_argument( '--sample-batch-size', default=20, type=int, help='Size of samples packet which is sent by rabbit', ) parser.add_argument( '--config-file', help='Config file for ceilometer services', ) parser.add_argument( '--rabbit-topic', default='perfmetering', help='Rabbit topic for samples', ) parser.add_argument( '--rate', default=1000, help='Rate of samples per seconds', ) parser.add_argument( '--resource-count', default=100, ) parser.add_argument('--counters', nargs='+', default=['instance'], help='') return parser def generate_resources(count): resources = [] for i in xrange(count): resources.append(uuid.uuid4().hex) return resources def send_test_data(args, producer_log_file=None): batch_size = args.sample_batch_size start = datetime.datetime.utcnow() - datetime.timedelta( days=50, minutes=int(args.count)+100) rpc_client = get_rpc_client(args.config_file) sample_count = 0 resources_by_counter = {} counter_len = len(args.counters) output = None user_id = uuid.uuid4().hex project_id = uuid.uuid4().hex try: if producer_log_file: output = open(producer_log_file, 'w') while sample_count < args.count: start_time = time.time() counter_name = args.counters[random.randint(0, counter_len - 1)] if counter_name not in resources_by_counter: resources_by_counter[counter_name] = \ generate_resources(args.resource_count) resource_id = resources_by_counter[counter_name][random.randint(0, args.resource_count -1)] end = start + datetime.timedelta(minutes=batch_size) gen = make_test_data.make_samples(name=counter_name, meter_type=args.type, unit=args.unit, volume=1, random_min=args.random_min, random_max=args.random_max, user_id=user_id, project_id=project_id, resource_id=resource_id, start=start, end=end, interval=1) batch = [] for sample in gen: sample.timestamp = jsonutils.to_primitive(sample.timestamp) data = utils.meter_message_from_counter( sample, cfg.CONF.publisher.metering_secret) batch.append(data) sample_count += batch_size if sample_count > args.count: batch = batch[:-(sample_count - args.count) - 1] start = start + datetime.timedelta(minutes=batch_size + 1) send_batch(rpc_client, args.rabbit_topic, batch) delta_time = time.time() - start_time rate = batch_size / delta_time if output: output.write(""%.0f\t%s\n"" % (time.time(), rate)) except Exception: raise finally: if output: output.close() def main(argv=None): argv = argv or sys.argv cfg.CONF([], project='ceilometer') parser = get_parser() try: args = parser.parse_args(argv[1:]) except Exception as e: raise print(args) send_test_data(args, ""/tmp/default_messaging_rate"") if __name__ == '__main__': main() ",,153,0
openstack%2Fceilometer~master~Ib6e1a9d3cece374658ca2321ef9e2426443ef46b,openstack/ceilometer,master,Ib6e1a9d3cece374658ca2321ef9e2426443ef46b,[Do not merge] Add opentsdb dispatcher,ABANDONED,2014-11-01 12:35:05.000000000,2014-12-22 10:35:14.000000000,,"[{'_account_id': 3}, {'_account_id': 7729}]","[{'number': 1, 'created': '2014-11-01 12:35:05.000000000', 'files': ['ceilometer/dispatcher/opentsdb.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9e13c5caabe85dcf307025b58b953fc02a8251d6', 'message': '[Do not merge] Add opentsdb dispatcher\n\nThis dispatcher added only for test performance of directly writing\nto opentsdb from ceilometer collector.\n\nChange-Id: Ib6e1a9d3cece374658ca2321ef9e2426443ef46b\n'}]",0,132390,9e13c5caabe85dcf307025b58b953fc02a8251d6,4,2,1,7729,,,0,"[Do not merge] Add opentsdb dispatcher

This dispatcher added only for test performance of directly writing
to opentsdb from ceilometer collector.

Change-Id: Ib6e1a9d3cece374658ca2321ef9e2426443ef46b
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/90/132390/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/dispatcher/opentsdb.py', 'setup.cfg']",2,9e13c5caabe85dcf307025b58b953fc02a8251d6,, gnocchi = gnocchi.ceilometer.dispatcher:GnocchiDispatcher opentsdb = ceilometer.dispatcher.opentsdb:OpentsdbDispatcher,,59,0
openstack%2Fec2-api~master~I217a9c6abd52fd423e775459334e590a8e1549e7,openstack/ec2-api,master,I217a9c6abd52fd423e775459334e590a8e1549e7,Keypair unit tests,MERGED,2014-12-22 07:57:55.000000000,2014-12-22 10:19:00.000000000,2014-12-22 10:19:00.000000000,"[{'_account_id': 3}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-12-22 07:57:55.000000000', 'files': ['ec2api/tests/test_key_pair.py', 'ec2api/api/cloud.py', 'ec2api/tests/base.py', 'ec2api/tests/fakes.py', 'ec2api/api/key_pair.py', 'ec2api/exception.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/92e11cc9d801503045a3c1a66f2a5a2bd1f1c7d0', 'message': 'Keypair unit tests\n\nChange-Id: I217a9c6abd52fd423e775459334e590a8e1549e7\n'}]",0,143388,92e11cc9d801503045a3c1a66f2a5a2bd1f1c7d0,6,3,1,9312,,,0,"Keypair unit tests

Change-Id: I217a9c6abd52fd423e775459334e590a8e1549e7
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/88/143388/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/tests/test_key_pair.py', 'ec2api/api/cloud.py', 'ec2api/tests/base.py', 'ec2api/tests/fakes.py', 'ec2api/api/key_pair.py', 'ec2api/exception.py']",6,92e11cc9d801503045a3c1a66f2a5a2bd1f1c7d0,,class SecurityGroupLimitExceeded(Overlimit): msg_fmt = _('You have reached the limit of security groups') class InvalidKeyPairDuplicate(Invalid):,class KeyPairExists(Invalid):,185,8
openstack%2Fanchor~master~I67aa06769850f1b7ff3a991240549f1177fb968a,openstack/anchor,master,I67aa06769850f1b7ff3a991240549f1177fb968a,Update README.md,ABANDONED,2014-12-20 14:05:24.000000000,2014-12-22 10:17:22.000000000,,"[{'_account_id': 3}, {'_account_id': 7063}, {'_account_id': 11650}, {'_account_id': 11716}]","[{'number': 1, 'created': '2014-12-20 14:05:24.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/anchor/commit/996d91c8f90a45dc4aa9dc2010f84505ebd6a227', 'message': 'Update README.md\n\nAdd missing new line show code block.\nMake installing the modified M2Crypto library easier\n\nChange-Id: I67aa06769850f1b7ff3a991240549f1177fb968a\n'}]",0,143272,996d91c8f90a45dc4aa9dc2010f84505ebd6a227,6,4,1,11650,,,0,"Update README.md

Add missing new line show code block.
Make installing the modified M2Crypto library easier

Change-Id: I67aa06769850f1b7ff3a991240549f1177fb968a
",git fetch https://review.opendev.org/openstack/anchor refs/changes/72/143272/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,996d91c8f90a45dc4aa9dc2010f84505ebd6a227,update-doc,preferred package manager. Install the modified M2Crypto: pip install git+git://github.com/viraptor/M2Crypto,preferred package manager. Download and install the modified M2crypto: git clone https://github.com/viraptor/M2Crypto.git cd M2Crypto python setup.py build && python setup.py install cd ..,5,6
openstack%2Fec2-api~master~I82c04794ba5e030ee683d1c9e7249ca48f0e0382,openstack/ec2-api,master,I82c04794ba5e030ee683d1c9e7249ca48f0e0382,Workaround of a pbr bug,ABANDONED,2014-12-21 12:52:04.000000000,2014-12-22 10:12:47.000000000,,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-12-21 12:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/832a2053df8460c87c8b9d603af6cf64867ea537', 'message': 'Workaround of a pbr bug\n\nPbr 0.10.5 crashes on projects with no tags.\n\nChange-Id: I82c04794ba5e030ee683d1c9e7249ca48f0e0382\n'}, {'number': 2, 'created': '2014-12-21 12:53:28.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/ab94caed53a334236231c63eb8ad26cd0f36137a', 'message': 'Workaround of a pbr bug\n\nPbr 0.10.5 crashes on projects with no tags.\n\nChange-Id: I82c04794ba5e030ee683d1c9e7249ca48f0e0382\n'}]",0,143298,ab94caed53a334236231c63eb8ad26cd0f36137a,5,3,2,10224,,,0,"Workaround of a pbr bug

Pbr 0.10.5 crashes on projects with no tags.

Change-Id: I82c04794ba5e030ee683d1c9e7249ca48f0e0382
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/98/143298/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,832a2053df8460c87c8b9d603af6cf64867ea537,pbr-bug,"pbr>=0.6,!=0.7,!=0.10.5<1.0","pbr>=0.6,!=0.7,<1.0",1,1
openstack%2Fneutron~master~I4d76255a559489f2f0e074b4489cfa5f33f1dddf,openstack/neutron,master,I4d76255a559489f2f0e074b4489cfa5f33f1dddf,Fix typo'd format parameter in midonet_lib.py,MERGED,2014-12-21 23:27:44.000000000,2014-12-22 09:59:39.000000000,2014-12-22 09:59:37.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 7743}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 12271}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-21 23:27:44.000000000', 'files': ['neutron/plugins/midonet/midonet_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a9571b5d8ecc2db8f2d0808eb444bab4baf348c3', 'message': 'Fix typo\'d format parameter in midonet_lib.py\n\nIn add_static_nat(...):\n\n        LOG.debug(""MidoClient.add_static_nat called: ""\n                  ""tenant_id=%(tenant_id)s, chain_name=%(chain_name)s, ""\n                  ""from_ip=%(from_ip)s, to_ip=%(to_ip)s, ""\n                  ""port_id=%(port_id)s, nat_type=%(nat_type)s"",\n                  {\'tenant_id\': tenant_id, \'chain_name\': chain_name,\n                   \'from_ip\': from_ip, \'to_ip\': to_ip,\n                   \'portid\': port_id, \'nat_type\': nat_type})\n\nNote port_id vs portid.  This line of code raises a KeyError if debug\nlogging is enabled.\n\n(Found via pylint)\n\nChange-Id: I4d76255a559489f2f0e074b4489cfa5f33f1dddf\nCloses-Bug: #1404755\n'}]",0,143334,a9571b5d8ecc2db8f2d0808eb444bab4baf348c3,23,19,1,11279,,,0,"Fix typo'd format parameter in midonet_lib.py

In add_static_nat(...):

        LOG.debug(""MidoClient.add_static_nat called: ""
                  ""tenant_id=%(tenant_id)s, chain_name=%(chain_name)s, ""
                  ""from_ip=%(from_ip)s, to_ip=%(to_ip)s, ""
                  ""port_id=%(port_id)s, nat_type=%(nat_type)s"",
                  {'tenant_id': tenant_id, 'chain_name': chain_name,
                   'from_ip': from_ip, 'to_ip': to_ip,
                   'portid': port_id, 'nat_type': nat_type})

Note port_id vs portid.  This line of code raises a KeyError if debug
logging is enabled.

(Found via pylint)

Change-Id: I4d76255a559489f2f0e074b4489cfa5f33f1dddf
Closes-Bug: #1404755
",git fetch https://review.opendev.org/openstack/neutron refs/changes/34/143334/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/midonet/midonet_lib.py'],1,a9571b5d8ecc2db8f2d0808eb444bab4baf348c3,bug/1404755," 'port_id': port_id, 'nat_type': nat_type})"," 'portid': port_id, 'nat_type': nat_type})",1,1
openstack%2Fxstatic-angular~master~Ib45130a624cace9139a5309470f70ed2983b8cb3,openstack/xstatic-angular,master,Ib45130a624cace9139a5309470f70ed2983b8cb3,Angular xstatic for Version 1.3.7,MERGED,2014-12-17 17:50:01.000000000,2014-12-22 09:39:51.000000000,2014-12-19 16:19:01.000000000,"[{'_account_id': 3}, {'_account_id': 2455}, {'_account_id': 7665}, {'_account_id': 8648}, {'_account_id': 9576}, {'_account_id': 12071}, {'_account_id': 13805}]","[{'number': 1, 'created': '2014-12-17 17:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/xstatic-angular/commit/da175638d79a7bd0aeaaf1d290dae67e57b41f5f', 'message': 'Version 1.3.7\n\nAdding version 1.3.7\n\n1.3.x angular is needed for launch instance work.\n\nPartially Implements: blueprint launch-instance-redesign\n\nChange-Id: Ib45130a624cace9139a5309470f70ed2983b8cb3\n'}, {'number': 2, 'created': '2014-12-17 17:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/xstatic-angular/commit/459757c66ed5606618aefd8eb06ddc1b3d76369a', 'message': 'Angular xstatic for Version 1.3.7\n\nAdding version 1.3.7\n\n1.3.x angular is needed for launch instance work.\n\nPartially Implements: blueprint launch-instance-redesign\n\nChange-Id: Ib45130a624cace9139a5309470f70ed2983b8cb3\n'}, {'number': 3, 'created': '2014-12-18 18:04:28.000000000', 'files': ['xstatic/pkg/angular/data/version.json', 'xstatic/pkg/angular/__init__.py', 'xstatic/pkg/angular/data/angular-csp.css', 'xstatic/pkg/angular/data/angular-scenario.js', 'xstatic/pkg/angular/data/angular-loader.js', 'xstatic/pkg/angular/data/version.txt', 'xstatic/pkg/angular/data/angular-messages.js', 'xstatic/pkg/angular/data/angular-route.js', 'xstatic/pkg/angular/data/angular-aria.js', 'xstatic/pkg/angular/data/angular.js', 'xstatic/pkg/angular/data/errors.json', 'xstatic/pkg/angular/data/angular-mocks.js', 'xstatic/pkg/angular/data/angular-sanitize.js', 'xstatic/pkg/angular/data/angular-animate.js', 'xstatic/pkg/angular/data/angular-resource.js', 'xstatic/pkg/angular/data/angular-cookies.js', 'xstatic/pkg/angular/data/angular-touch.js'], 'web_link': 'https://opendev.org/openstack/xstatic-angular/commit/dac047df05da5bb20de4e78876bc03820d0c6671', 'message': 'Angular xstatic for Version 1.3.7\n\nAdding version 1.3.7\n\n1.3.x angular is needed for launch instance work.\n\nPartially Implements: blueprint launch-instance-redesign\n\nChange-Id: Ib45130a624cace9139a5309470f70ed2983b8cb3\n'}]",0,142520,dac047df05da5bb20de4e78876bc03820d0c6671,23,7,3,7665,,,0,"Angular xstatic for Version 1.3.7

Adding version 1.3.7

1.3.x angular is needed for launch instance work.

Partially Implements: blueprint launch-instance-redesign

Change-Id: Ib45130a624cace9139a5309470f70ed2983b8cb3
",git fetch https://review.opendev.org/openstack/xstatic-angular refs/changes/20/142520/1 && git format-patch -1 --stdout FETCH_HEAD,"['xstatic/pkg/angular/__init__.py', 'xstatic/pkg/angular/angular-csp.css', 'xstatic/pkg/angular/angular.min.js.map', 'xstatic/pkg/angular/angular.js', 'xstatic/pkg/angular/angular-aria.js', 'xstatic/pkg/angular/data/errors.json', 'xstatic/pkg/angular/angular-animate.js', 'xstatic/pkg/angular/data/angular-animate.js', 'xstatic/pkg/angular/angular-touch.js', 'xstatic/pkg/angular/angular.min.js', 'xstatic/pkg/angular/angular-mocks.js', 'xstatic/pkg/angular/angular-sanitize.js', 'xstatic/pkg/angular/version.txt', 'xstatic/pkg/angular/angular-cookies.js', 'xstatic/pkg/angular/angular-messages.js', 'xstatic/pkg/angular/version.json', 'xstatic/pkg/angular/data/version.json', 'xstatic/pkg/angular/data/version.txt', 'xstatic/pkg/angular/angular-loader.js', 'xstatic/pkg/angular/angular-route.js', 'xstatic/pkg/angular/angular-resource.js', 'xstatic/pkg/angular/errors.json', 'xstatic/pkg/angular/data/angular-resource.js', 'xstatic/pkg/angular/angular-scenario.js']",24,da175638d79a7bd0aeaaf1d290dae67e57b41f5f,bp/launch-instance-redesign," * jQuery JavaScript Library v2.1.1 * Copyright 2005, 2014 jQuery Foundation, Inc. and other contributors * Date: 2014-05-01T17:11Z (function( global, factory ) {'use strict'; if ( typeof module === ""object"" && typeof module.exports === ""object"" ) { // For CommonJS and CommonJS-like environments where a proper window is present, // execute the factory and get jQuery // For environments that do not inherently posses a window with a document // (such as Node.js), expose a jQuery-making factory as module.exports // This accentuates the need for the creation of a real window // e.g. var jQuery = require(""jquery"")(window); // See ticket #14549 for more info module.exports = global.document ? factory( global, true ) : function( w ) { if ( !w.document ) { throw new Error( ""jQuery requires a window with a document"" ); } return factory( w ); }; } else { factory( global ); } // Pass this if window is not defined yet }(typeof window !== ""undefined"" ? window : this, function( window, noGlobal ) {var arr = []; var slice = arr.slice; var concat = arr.concat; var push = arr.push; var indexOf = arr.indexOf; var class2type = {}; var toString = class2type.toString; var hasOwn = class2type.hasOwnProperty; var support = {}; version = ""2.1.1"", // Need init if jQuery is called (just allow error to be thrown if not included) return new jQuery.fn.init( selector, context ); // Support: Android<4.1 // Make sure we trim BOM and NBSP jquery: version, return slice.call( this ); return num != null ? // Return just the one element from the set ( num < 0 ? this[ num + this.length ] : this[ num ] ) : // Return all the elements in a clean array slice.call( this ); map: function( callback ) { return this.pushStack( jQuery.map(this, function( elem, i ) { return callback.call( elem, i, elem ); })); return this.pushStack( slice.apply( this, arguments ) ); push: push, sort: arr.sort, splice: arr.splice var options, name, src, copy, copyIsArray, clone, target = arguments[ i ] || {}; i++; if ( i === length ) { i--; expando: ""jQuery"" + ( version + Math.random() ).replace( /\D/g, """" ), // Assume jQuery is ready without the ready module isReady: true, error: function( msg ) { throw new Error( msg ); noop: function() {}, isArray: Array.isArray, return obj != null && obj === obj.window; // parseFloat NaNs numeric-cast false positives (null|true|false|"""") // ...but misinterprets leading-number strings, particularly hex literals (""0x..."") // subtraction forces infinities to NaN return !jQuery.isArray( obj ) && obj - parseFloat( obj ) >= 0; // Not plain objects: // - Any object or value whose internal [[Class]] property is not ""[object Object]"" // - DOM nodes // - window if ( jQuery.type( obj ) !== ""object"" || obj.nodeType || jQuery.isWindow( obj ) ) { if ( obj.constructor && !hasOwn.call( obj.constructor.prototype, ""isPrototypeOf"" ) ) { // If the function hasn't returned already, we're confident that // |obj| is a plain object, created by {} or constructed with new Object return true; type: function( obj ) { if ( obj == null ) { return obj + """"; } // Support: Android < 4.0, iOS < 6 (functionish RegExp) return typeof obj === ""object"" || typeof obj === ""function"" ? class2type[ toString.call(obj) ] || ""object"" : typeof obj; globalEval: function( code ) { var script, indirect = eval; code = jQuery.trim( code ); if ( code ) { // If the code includes a valid, prologue position // strict mode pragma, execute code by injecting a // script tag into the document. if ( code.indexOf(""use strict"") === 1 ) { script = document.createElement(""script""); script.text = code; document.head.appendChild( script ).parentNode.removeChild( script ); } else { // Otherwise, avoid the DOM node creation, insertion // and removal by using an indirect global eval indirect( code ); } // Support: Android<4.1 trim: function( text ) { return text == null ? """" : ( text + """" ).replace( rtrim, """" ); }, push.call( ret, arr ); return arr == null ? -1 : indexOf.call( arr, elem, i ); var len = +second.length, j = 0, i = first.length; for ( ; j < len; j++ ) { first[ i++ ] = second[ j ]; grep: function( elems, callback, invert ) { var callbackInverse, matches = [], length = elems.length, callbackExpect = !invert; callbackInverse = !callback( elems[ i ], i ); if ( callbackInverse !== callbackExpect ) { matches.push( elems[ i ] ); return matches; // Go through the array, translating each of the items to their new values ret.push( value ); ret.push( value ); return concat.apply( [], ret ); var tmp, args, proxy; args = slice.call( arguments, 2 ); return fn.apply( context || this, args.concat( slice.call( arguments ) ) ); now: Date.now, // jQuery.support is not used in Core but other projects attach their // properties to it so it needs to exist. support: support if ( type === ""function"" || jQuery.isWindow( obj ) ) { return type === ""array"" || length === 0 || typeof length === ""number"" && length > 0 && ( length - 1 ) in obj;var Sizzle = * Sizzle CSS Selector Engine v1.10.19 * Date: 2014-04-18(function( window ) { tokenize, select, hasDuplicate, // Attribute selectors: http://www.w3.org/TR/selectors/#attribute-selectors attributes = ""\\["" + whitespace + ""*("" + characterEncoding + "")(?:"" + whitespace + // Operator (capture 2) ""*([*^$|!~]?=)"" + whitespace + // ""Attribute values must be CSS identifiers [capture 5] or strings [capture 3 or capture 4]"" ""*(?:'((?:\\\\.|[^\\\\'])*)'|\""((?:\\\\.|[^\\\\\""])*)\""|("" + identifier + ""))|)"" + whitespace + ""*\\]"", pseudos = "":("" + characterEncoding + "")(?:\\(("" + // To reduce the number of selectors needing tokenize in the preFilter, prefer arguments: // 1. quoted (capture 3; capture 4 or capture 5) ""('((?:\\\\.|[^\\\\'])*)'|\""((?:\\\\.|[^\\\\\""])*)\"")|"" + // 2. simple (capture 6) ""((?:\\\\.|[^\\\\()[\\]]|"" + attributes + "")*)|"" + // 3. anything else (capture 2) "".*"" + "")\\)|)"", rattributeQuotes = new RegExp( ""="" + whitespace + ""*([^\\]'\""]*?)"" + whitespace + ""*\\]"", ""g"" ), rinputs = /^(?:input|select|textarea|button)$/i, rheader = /^h\d$/i, rsibling = /[+~]/, // Support: Firefox<24 // BMP codepoint // nodes that are no longer in the document (jQuery #6963) newContext = rsibling.test( selector ) && testContext( context.parentNode ) || context; if ( keys.push( key + "" "" ) > Expr.cacheLength ) { return (cache[ key + "" "" ] = value); * Checks a node for validity as a Sizzle context * @param {Element|Object=} context * @returns {Element|Object|Boolean} The input node if acceptable, otherwise a falsy value */ function testContext( context ) { return context && typeof context.getElementsByTagName !== strundefined && context; } // Expose support vars for convenience support = Sizzle.support = {}; /** * Detects XML nodes * @returns {Boolean} True iff elem is a non-HTML XML node var hasCompare, doc = node ? node.ownerDocument || node : preferredDoc, if ( parent && parent !== parent.top ) { // IE11 does not have attachEvent, so all must suffer if ( parent.addEventListener ) { parent.addEventListener( ""unload"", function() { setDocument(); }, false ); } else if ( parent.attachEvent ) { parent.attachEvent( ""onunload"", function() { setDocument(); }); } support.getElementsByClassName = rnative.test( doc.getElementsByClassName ) && assert(function( div ) { return m && m.parentNode ? [ m ] : []; div.innerHTML = ""<select msallowclip=''><option selected=''></option></select>""; // Support: IE8, Opera 11-12.16 // Nothing should be selected when empty strings follow ^= or $= or *= // The test attribute must be unknown in Opera but ""safe"" for WinRT // http://msdn.microsoft.com/en-us/library/ie/hh465388.aspx#attribute_section if ( div.querySelectorAll(""[msallowclip^='']"").length ) { rbuggyQSA.push( ""[*^$]="" + whitespace + ""*(?:''|\""\"")"" ); } // The type and name attributes are restricted during .innerHTML assignment div.appendChild( input ).setAttribute( ""name"", ""D"" ); // Support: IE8 // Enforce case-sensitivity of name attribute if ( div.querySelectorAll(""[name=d]"").length ) { rbuggyQSA.push( ""name"" + whitespace + ""*[*^$|!~]?="" ); if ( (support.matchesSelector = rnative.test( (matches = docElem.matches || docElem.webkitMatchesSelector || hasCompare = rnative.test( docElem.compareDocumentPosition ); contains = hasCompare || rnative.test( docElem.contains ) ? sortOrder = hasCompare ? // Sort on method existence if only one input has compareDocumentPosition var compare = !a.compareDocumentPosition - !b.compareDocumentPosition; return compare; // Calculate position if both inputs belong to the same document compare = ( a.ownerDocument || a ) === ( b.ownerDocument || b ) ? a.compareDocumentPosition( b ) : // Otherwise we know they are disconnected 1; // Disconnected nodes if ( compare & 1 || (!support.sortDetached && b.compareDocumentPosition( a ) === compare) ) { // Choose the first element that is related to our preferred document if ( a === doc || a.ownerDocument === preferredDoc && contains(preferredDoc, a) ) { return -1; } if ( b === doc || b.ownerDocument === preferredDoc && contains(preferredDoc, b) ) { return 1; } // Maintain original order return sortInput ? ( indexOf.call( sortInput, a ) - indexOf.call( sortInput, b ) ) : 0; } return compare & 4 ? -1 : 1; // Exit early if the nodes are identical if ( a === b ) { hasDuplicate = true; return 0; } if ( !aup || !bup ) { return Sizzle( expr, document, null, [ elem ] ).length > 0; return val !== undefined ? val : null; // Clear input after sorting to release objects // See https://github.com/jquery/sizzle/pull/225 sortInput = null; while ( (node = elem[i++]) ) { // innerText usage removed for consistency of new lines (jQuery #11153) match[3] = ( match[3] || match[4] || match[5] || """" ).replace( runescape, funescape ); unquoted = !match[6] && match[2]; if ( match[3] ) { match[2] = match[4] || match[5] || """"; // :empty is negated by element (1) or content nodes (text: 3; cdata: 4; entity ref: 5), // but not by others (comment: 8; processing instruction: 7; etc.) // nodeType < 6 works because attributes (2) do not appear as children if ( elem.nodeType < 6 ) { // Support: IE<8 // New HTML5 attribute values (e.g., ""search"") appear with elem.type === ""text"" ( (attr = elem.getAttribute(""type"")) == null || attr.toLowerCase() === ""text"" );tokenize = Sizzle.tokenize = function( selector, parseOnly ) { groups.push( (tokens = []) );}; var oldCache, outerCache, newCache = [ dirruns, doneName ]; if ( (oldCache = outerCache[ dir ]) && oldCache[ 0 ] === dirruns && oldCache[ 1 ] === doneName ) { // Assign to newCache so results back-propagate to previous elements return (newCache[ 2 ] = oldCache[ 2 ]); // Reuse newcache so results back-propagate to previous elements outerCache[ dir ] = newCache; // A match means we're done; a fail means we have to keep checking if ( (newCache[ 2 ] = matcher( elem, context, xml )) ) {function multipleContexts( selector, contexts, results ) { var i = 0, len = contexts.length; for ( ; i < len; i++ ) { Sizzle( selector, contexts[i], results ); } return results; } var bySet = setMatchers.length > 0, superMatcher = function( seed, context, xml, results, outermost ) { setMatched = [], // We must always have either seed elements or outermost context elems = seed || byElement && Expr.find[""TAG""]( ""*"", outermost ), dirrunsUnique = (dirruns += contextBackup == null ? 1 : Math.random() || 0.1), len = elems.length; // Support: IE<9, Safari // Tolerate NodeList properties (IE: ""length""; Safari: <number>) matching elements by id for ( ; i !== len && (elem = elems[i]) != null; i++ ) {compile = Sizzle.compile = function( selector, match /* Internal Use Only */ ) { if ( !match ) { match = tokenize( selector ); i = match.length; cached = matcherFromTokens( match[i] ); // Save selector and tokenization cached.selector = selector;/** * A low-level selection function that works with Sizzle's compiled * selector functions * @param {String|Function} selector A selector or a pre-compiled * selector function built with Sizzle.compile * @param {Element} context * @param {Array} [results] * @param {Array} [seed] A set of elements to match against */ select = Sizzle.select = function( selector, context, results, seed ) { compiled = typeof selector === ""function"" && selector, match = !seed && tokenize( (selector = compiled.selector || selector) ); results = results || []; // Try to minimize operations if there is no seed and only one group if ( match.length === 1 ) { // Take a shortcut and set the context if the root selector is an ID tokens = match[0] = match[0].slice( 0 ); if ( tokens.length > 2 && (token = tokens[0]).type === ""ID"" && support.getById && context.nodeType === 9 && documentIsHTML && Expr.relative[ tokens[1].type ] ) { context = ( Expr.find[""ID""]( token.matches[0].replace(runescape, funescape), context ) || [] )[0]; if ( !context ) { return results; // Precompiled matchers will still verify ancestry, so step up a level } else if ( compiled ) { context = context.parentNode; selector = selector.slice( tokens.shift().value.length ); } // Fetch a seed set for right-to-left matching i = matchExpr[""needsContext""].test( selector ) ? 0 : tokens.length; while ( i-- ) { token = tokens[i]; // Abort if we hit a combinator if ( Expr.relative[ (type = token.type) ] ) { break; } if ( (find = Expr.find[ type ]) ) { // Search, expanding context for leading sibling combinators if ( (seed = find( token.matches[0].replace( runescape, funescape ), rsibling.test( tokens[0].type ) && testContext( context.parentNode ) || context )) ) { // If seed is empty or no tokens remain, we can return early tokens.splice( i, 1 ); selector = seed.length && toSelector( tokens ); if ( !selector ) { push.apply( results, seed ); return results; break; // Compile and execute a filtering function if one is not provided ( compiled || compile( selector, match ) )( rsibling.test( selector ) && testContext( context.parentNode ) || context};support.detectDuplicates = !!hasDuplicate; return elem[ name ] === true ? name.toLowerCase() : (val = elem.getAttributeNode( name )) && val.specified ? val.value : null;return Sizzle; })( window ); var rneedsContext = jQuery.expr.match.needsContext; var rsingleTag = (/^<(\w+)\s*\/?>(?:<\/\1>|)$/); var risSimple = /^.[^:#\[\.,]*$/; // Implement the identical functionality for filter and not function winnow( elements, qualifier, not ) { if ( jQuery.isFunction( qualifier ) ) { return jQuery.grep( elements, function( elem, i ) { /* jshint -W018 */ return !!qualifier.call( elem, i, elem ) !== not; }); } if ( qualifier.nodeType ) { return jQuery.grep( elements, function( elem ) { return ( elem === qualifier ) !== not; }); } if ( typeof qualifier === ""string"" ) { if ( risSimple.test( qualifier ) ) { return jQuery.filter( qualifier, elements, not ); } qualifier = jQuery.filter( qualifier, elements ); } return jQuery.grep( elements, function( elem ) { return ( indexOf.call( qualifier, elem ) >= 0 ) !== not; }); } jQuery.filter = function( expr, elems, not ) { var elem = elems[ 0 ]; if ( not ) { expr = "":not("" + expr + "")""; } return elems.length === 1 && elem.nodeType === 1 ? jQuery.find.matchesSelector( elem, expr ) ? [ elem ] : [] : jQuery.find.matches( expr, jQuery.grep( elems, function( elem ) { return elem.nodeType === 1; })); }; jQuery.fn.extend({ find: function( selector ) { var i, len = this.length, ret = [], self = this; if ( typeof selector !== ""string"" ) { return this.pushStack( jQuery( selector ).filter(function() { for ( i = 0; i < len; i++ ) { if ( jQuery.contains( self[ i ], this ) ) { return true; } } }) ); } for ( i = 0; i < len; i++ ) { jQuery.find( selector, self[ i ], ret ); } // Needed because $( selector, context ) becomes $( context ).find( selector ) ret = this.pushStack( len > 1 ? jQuery.unique( ret ) : ret ); ret.selector = this.selector ? this.selector + "" "" + selector : selector; return ret; }, filter: function( selector ) { return this.pushStack( winnow(this, selector || [], false) ); }, not: function( selector ) { return this.pushStack( winnow(this, selector || [], true) ); }, is: function( selector ) { return !!winnow( this, // If this is a positional/relative selector, check membership in the returned set // so $(""p:first"").is(""p:last"") won't return true for a doc with two ""p"". typeof selector === ""string"" && rneedsContext.test( selector ) ? jQuery( selector ) : selector || [], false ).length; } }); // Initialize a jQuery object // A central reference to the root jQuery(document) var rootjQuery, // A simple way to check for HTML strings // Prioritize #id over <tag> to avoid XSS via location.hash (#9521) // Strict HTML recognition (#11290: must start with <) rquickExpr = /^(?:\s*(<[\w\W]+>)[^>]*|#([\w-]*))$/, init = jQuery.fn.init = function( selector, context ) { var match, elem; // HANDLE: $(""""), $(null), $(undefined), $(false) if ( !selector ) { return this; } // Handle HTML strings if ( typeof selector === ""string"" ) { if ( selector[0] === ""<"" && selector[ selector.length - 1 ] === "">"" && selector.length >= 3 ) { // Assume that strings that start and end with <> are HTML and skip the regex check match = [ null, selector, null ]; } else { match = rquickExpr.exec( selector ); } // Match html or make sure no context is specified for #id if ( match && (match[1] || !context) ) { // HANDLE: $(html) -> $(array) if ( match[1] ) { context = context instanceof jQuery ? context[0] : context; // scripts is true for back-compat // Intentionally let the error be thrown if parseHTML is not present jQuery.merge( this, jQuery.parseHTML( match[1], context && context.nodeType ? context.ownerDocument || context : document, true ) ); // HANDLE: $(html, props) if ( rsingleTag.test( match[1] ) && jQuery.isPlainObject( context ) ) { for ( match in context ) { // Properties of context are called as methods if possible if ( jQuery.isFunction( this[ match ] ) ) { this[ match ]( context[ match ] ); // ...and otherwise set as attributes } else { this.attr( match, context[ match ] ); } } } return this; // HANDLE: $(#id) } else { elem = document.getElementById( match[2] ); // Check parentNode to catch when Blackberry 4.6 returns // nodes that are no longer in the document #6963 if ( elem && elem.parentNode ) { // Inject the element directly into the jQuery object this.length = 1; this[0] = elem; } this.context = document; this.selector = selector; return this; } // HANDLE: $(expr, $(...)) } else if ( !context || context.jquery ) { return ( context || rootjQuery ).find( selector ); // HANDLE: $(expr, context) // (which is just equivalent to: $(context).find(expr) } else { return this.constructor( context ).find( selector ); } // HANDLE: $(DOMElement) } else if ( selector.nodeType ) { this.context = this[0] = selector; this.length = 1; return this; // HANDLE: $(function) // Shortcut for document ready } else if ( jQuery.isFunction( selector ) ) { return typeof rootjQuery.ready !== ""undefined"" ? rootjQuery.ready( selector ) : // Execute immediately if ready is not present selector( jQuery ); } if ( selector.selector !== undefined ) { this.selector = selector.selector; this.context = selector.context; } return jQuery.makeArray( selector, this ); }; // Give the init function the jQuery prototype for later instantiation init.prototype = jQuery.fn; // Initialize central reference rootjQuery = jQuery( document ); var rparentsprev = /^(?:parents|prev(?:Until|All))/, // methods guaranteed to produce a unique set when starting from a unique set guaranteedUnique = { children: true, contents: true, next: true, prev: true }; jQuery.extend({ dir: function( elem, dir, until ) { var matched = [], truncate = until !== undefined; while ( (elem = elem[ dir ]) && elem.nodeType !== 9 ) { if ( elem.nodeType === 1 ) { if ( truncate && jQuery( elem ).is( until ) ) { break; } matched.push( elem ); } } return matched; }, sibling: function( n, elem ) { var matched = []; for ( ; n; n = n.nextSibling ) { if ( n.nodeType === 1 && n !== elem ) { matched.push( n ); } } return matched; } }); jQuery.fn.extend({ has: function( target ) { var targets = jQuery( target, this ), l = targets.length; return this.filter(function() { var i = 0; for ( ; i < l; i++ ) { if ( jQuery.contains( this, targets[i] ) ) { return true; } } }); }, closest: function( selectors, context ) { var cur, i = 0, l = this.length, matched = [], pos = rneedsContext.test( selectors ) || typeof selectors !== ""string"" ? jQuery( selectors, context || this.context ) : 0; for ( ; i < l; i++ ) { for ( cur = this[i]; cur && cur !== context; cur = cur.parentNode ) { // Always skip document fragments if ( cur.nodeType < 11 && (pos ? pos.index(cur) > -1 : // Don't pass non-elements to Sizzle cur.nodeType === 1 && jQuery.find.matchesSelector(cur, selectors)) ) { matched.push( cur ); break; } } } return this.pushStack( matched.length > 1 ? jQuery.unique( matched ) : matched ); }, // Determine the position of an element within // the matched set of elements index: function( elem ) { // No argument, return index in parent if ( !elem ) { return ( this[ 0 ] && this[ 0 ].parentNode ) ? this.first().prevAll().length : -1; } // index in selector if ( typeof elem === ""string"" ) { return indexOf.call( jQuery( elem ), this[ 0 ] ); } // Locate the position of the desired element return indexOf.call( this, // If it receives a jQuery object, the first element is used elem.jquery ? elem[ 0 ] : elem ); }, add: function( selector, context ) { return this.pushStack( jQuery.unique( jQuery.merge( this.get(), jQuery( selector, context ) ) ) ); }, addBack: function( selector ) { return this.add( selector == null ? this.prevObject : this.prevObject.filter(selector) ); } }); function sibling( cur, dir ) { while ( (cur = cur[dir]) && cur.nodeType !== 1 ) {} return cur; } jQuery.each({ parent: function( elem ) { var parent = elem.parentNode; return parent && parent.nodeType !== 11 ? parent : null; }, parents: function( elem ) { return jQuery.dir( elem, ""parentNode"" ); }, parentsUntil: function( elem, i, until ) { return jQuery.dir( elem, ""parentNode"", until ); }, next: function( elem ) { return sibling( elem, ""nextSibling"" ); }, prev: function( elem ) { return sibling( elem, ""previousSibling"" ); }, nextAll: function( elem ) { return jQuery.dir( elem, ""nextSibling"" ); }, prevAll: function( elem ) { return jQuery.dir( elem, ""previousSibling"" ); }, nextUntil: function( elem, i, until ) { return jQuery.dir( elem, ""nextSibling"", until ); }, prevUntil: function( elem, i, until ) { return jQuery.dir( elem, ""previousSibling"", until ); }, siblings: function( elem ) { return jQuery.sibling( ( elem.parentNode || {} ).firstChild, elem ); }, children: function( elem ) { return jQuery.sibling( elem.firstChild ); }, contents: function( elem ) { return elem.contentDocument || jQuery.merge( [], elem.childNodes ); } }, function( name, fn ) { jQuery.fn[ name ] = function( until, selector ) { var matched = jQuery.map( this, fn, until ); if ( name.slice( -5 ) !== ""Until"" ) { selector = until; } if ( selector && typeof selector === ""string"" ) { matched = jQuery.filter( selector, matched ); } if ( this.length > 1 ) { // Remove duplicates if ( !guaranteedUnique[ name ] ) { jQuery.unique( matched ); } // Reverse order for parents* and prev-derivatives if ( rparentsprev.test( name ) ) { matched.reverse(); } } return this.pushStack( matched ); }; }); var rnotwhite = (/\S+/g); jQuery.each( options.match( rnotwhite ) || [], function( _, flag ) { var // Last fire value (for non-forgettable lists) // Flag to know if list is currently firing firing, // First callback to fire (used internally by add and fireWith) firingStart, while ( ( index = jQuery.inArray( arg, list, index ) ) > -1 ) { var fn = jQuery.isFunction( fns[ i ] ) && fns[ i ]; newDefer[ tuple[ 0 ] + ""With"" ]( this === promise ? newDefer.promise() : this, fn ? [ returned ] : arguments ); resolveValues = slice.call( arguments ), values[ i ] = arguments.length > 1 ? slice.call( arguments ) : value; if ( values === progressValues ) {// The deferred used on DOM ready var readyList;jQuery.fn.ready = function( fn ) { // Add the callback jQuery.ready.promise().done( fn ); return this; };jQuery.extend({ // Is the DOM ready to be used? Set to true once it occurs. isReady: false, // A counter to track how many items to wait for before // the ready event fires. See #6781 readyWait: 1, // Hold (or release) the ready event holdReady: function( hold ) { if ( hold ) { jQuery.readyWait++; } else { jQuery.ready( true ); } }, // Handle when the DOM is ready ready: function( wait ) { // Abort if there are pending holds or we're already ready if ( wait === true ? --jQuery.readyWait : jQuery.isReady ) { // Remember that the DOM is ready jQuery.isReady = true; // If a normal DOM Ready event fired, decrement, and wait if need be if ( wait !== true && --jQuery.readyWait > 0 ) { return; // If there are functions bound, to execute readyList.resolveWith( document, [ jQuery ] ); // Trigger any bound ready events if ( jQuery.fn.triggerHandler ) { jQuery( document ).triggerHandler( ""ready"" ); jQuery( document ).off( ""ready"" ); } } });/** * The ready event handler and self cleanup method */ function completed() { document.removeEventListener( ""DOMContentLoaded"", completed, false ); window.removeEventListener( ""load"", completed, false ); jQuery.ready(); } jQuery.ready.promise = function( obj ) { if ( !readyList ) { readyList = jQuery.Deferred(); // Catch cases where $(document).ready() is called after the browser event has already occurred. // we once tried to use readyState ""interactive"" here, but it caused issues like the one // discovered by ChrisS here: http://bugs.jquery.com/ticket/12282#comment:15 if ( document.readyState === ""complete"" ) { // Handle it asynchronously to allow scripts the opportunity to delay ready setTimeout( jQuery.ready ); } else { // Use the handy event callback document.addEventListener( ""DOMContentLoaded"", completed, false ); // A fallback to window.onload, that will always work window.addEventListener( ""load"", completed, false ); } } return readyList.promise( obj ); }; // Kick off the DOM ready check even if the user does not jQuery.ready.promise(); // Multifunctional method to get and set values of a collection // The value/s can optionally be executed if it's a function var access = jQuery.access = function( elems, fn, key, value, chainable, emptyGet, raw ) { var i = 0, len = elems.length, bulk = key == null; // Sets many values if ( jQuery.type( key ) === ""object"" ) { chainable = true; for ( i in key ) { jQuery.access( elems, fn, i, key[i], true, emptyGet, raw ); } // Sets one value } else if ( value !== undefined ) { chainable = true; if ( !jQuery.isFunction( value ) ) { raw = true; } if ( bulk ) { // Bulk operations run against the entire set if ( raw ) { fn.call( elems, value ); fn = null; // ...except when executing function values } else { bulk = fn; fn = function( elem, key, value ) { return bulk.call( jQuery( elem ), value ); }; if ( fn ) { for ( ; i < len; i++ ) { fn( elems[i], key, raw ? value : value.call( elems[i], i, fn( elems[i], key ) ) ); } } } return chainable ? elems : // Gets bulk ? fn.call( elems ) : len ? fn( elems[0], key ) : emptyGet; }; /** * Determines whether an object can have data */ jQuery.acceptData = function( owner ) { // Accepts only: // - Node // - Node.ELEMENT_NODE // - Node.DOCUMENT_NODE // - Object // - Any /* jshint -W018 */ return owner.nodeType === 1 || owner.nodeType === 9 || !( +owner.nodeType ); }; function Data() { // Support: Android < 4, // Old WebKit does not have Object.preventExtensions/freeze method, // return new empty object instead with no [[set]] accessor Object.defineProperty( this.cache = {}, 0, { get: function() { return {}; } this.expando = jQuery.expando + Math.random();Data.uid = 1; Data.accepts = jQuery.acceptData;Data.prototype = { key: function( owner ) { // We can accept data for non-element nodes in modern browsers, // but we should not, see #8335. // Always return the key for a frozen object. if ( !Data.accepts( owner ) ) { return 0; } var descriptor = {}, // Check if the owner object already has a cache key unlock = owner[ this.expando ]; // If not, create one if ( !unlock ) { unlock = Data.uid++; // Secure it in a non-enumerable, non-writable property try { descriptor[ this.expando ] = { value: unlock }; Object.defineProperties( owner, descriptor ); // Support: Android < 4 // Fallback to a less secure definition } catch ( e ) { descriptor[ this.expando ] = unlock; jQuery.extend( owner, descriptor ); } } // Ensure the cache object if ( !this.cache[ unlock ] ) { this.cache[ unlock ] = {}; } return unlock; }, set: function( owner, data, value ) { var prop, // There may be an unlock assigned to this node, // if there is no entry for this ""owner"", create one inline // and set the unlock as though an owner entry had always existed unlock = this.key( owner ), cache = this.cache[ unlock ]; // Handle: [ owner, key, value ] args if ( typeof data === ""string"" ) { cache[ data ] = value; // Handle: [ owner, { properties } ] args } else { // Fresh assignments by object are shallow copied if ( jQuery.isEmptyObject( cache ) ) { jQuery.extend( this.cache[ unlock ], data ); // Otherwise, copy the properties one-by-one to the cache object for ( prop in data ) { cache[ prop ] = data[ prop ]; } } } return cache; }, get: function( owner, key ) { // Either a valid cache is found, or will be created. // New caches will be created and the unlock returned, // allowing direct access to the newly created // empty data object. A valid owner object must be provided. var cache = this.cache[ this.key( owner ) ]; return key === undefined ? cache : cache[ key ]; }, access: function( owner, key, value ) { var stored; // In cases where either: // // 1. No key was specified // 2. A string key was specified, but no value provided // // Take the ""read"" path and allow the get method to determine // which value to return, respectively either: // // 1. The entire cache object // 2. The data stored at the key // if ( key === undefined || ((key && typeof key === ""string"") && value === undefined) ) { stored = this.get( owner, key ); return stored !== undefined ? stored : this.get( owner, jQuery.camelCase(key) ); } // [*]When the key is not a string, or both a key and value // are specified, set or extend (existing objects) with either: // // 1. An object of properties // 2. A key and value // this.set( owner, key, value ); // Since the ""set"" path can have two possible entry points // return the expected data based on which path was taken[*] return value !== undefined ? value : key; }, remove: function( owner, key ) { var i, name, camel, unlock = this.key( owner ), cache = this.cache[ unlock ]; if ( key === undefined ) { this.cache[ unlock ] = {}; } else { // Support array or space separated string of keys if ( jQuery.isArray( key ) ) { name = key.concat( key.map( jQuery.camelCase ) ); } else { camel = jQuery.camelCase( key ); // Try the string as a key before any manipulation if ( key in cache ) { name = [ key, camel ]; } else { // If a key with the spaces exists, use it. // Otherwise, create an array by matching non-whitespace name = camel; name = name in cache ? [ name ] : ( name.match( rnotwhite ) || [] ); } delete cache[ name[ i ] ]; }, hasData: function( owner ) { return !jQuery.isEmptyObject( this.cache[ owner[ this.expando ] ] || {} ); }, discard: function( owner ) { if ( owner[ this.expando ] ) { delete this.cache[ owner[ this.expando ] ];}; var data_priv = new Data();var data_user = new Data();/* Implementation Summary 1. Enforce API surface and semantic compatibility with 1.9.x branch 2. Improve the module's maintainability by reducing the storage paths to a single mechanism. 3. Use the same single mechanism to support ""private"" and ""user"" data. 4. _Never_ expose ""private"" data to user code (TODO: Drop _data, _removeData) 5. Avoid exposing implementation details on user objects (eg. expando properties) 6. Provide a clear path for implementation upgrade to WeakMap in 2014 */ var rbrace = /^(?:\{[\w\W]*\}|\[[\w\W]*\])$/, rmultiDash = /([A-Z])/g; var name; name = ""data-"" + key.replace( rmultiDash, ""-$1"" ).toLowerCase(); data; data_user.set( elem, key, data );jQuery.extend({ hasData: function( elem ) { return data_user.hasData( elem ) || data_priv.hasData( elem ); }, data: function( elem, name, data ) { return data_user.access( elem, name, data ); }, removeData: function( elem, name ) { data_user.remove( elem, name ); }, // TODO: Now that all calls to _data and _removeData have been replaced // with direct calls to data_priv methods, these can be deprecated. _data: function( elem, name, data ) { return data_priv.access( elem, name, data ); }, _removeData: function( elem, name ) { data_priv.remove( elem, name );});jQuery.fn.extend({ data: function( key, value ) { var i, name, data, elem = this[ 0 ], attrs = elem && elem.attributes; // Gets all values if ( key === undefined ) { if ( this.length ) { data = data_user.get( elem ); if ( elem.nodeType === 1 && !data_priv.get( elem, ""hasDataAttrs"" ) ) { i = attrs.length; while ( i-- ) { // Support: IE11+ // The attrs elements can be null (#14894) if ( attrs[ i ] ) { name = attrs[ i ].name; if ( name.indexOf( ""data-"" ) === 0 ) { name = jQuery.camelCase( name.slice(5) ); dataAttr( elem, name, data[ name ] ); } } } data_priv.set( elem, ""hasDataAttrs"", true ); } } return data; } // Sets multiple values if ( typeof key === ""object"" ) { return this.each(function() { data_user.set( this, key ); }); } return access( this, function( value ) { var data, camelKey = jQuery.camelCase( key ); // The calling jQuery object (element matches) is not empty // (and therefore has an element appears at this[ 0 ]) and the // `value` parameter was not undefined. An empty jQuery object // will result in `undefined` for elem = this[ 0 ] which will // throw an exception if an attempt to read a data cache is made. if ( elem && value === undefined ) { // Attempt to get data from the cache // with the key as-is data = data_user.get( elem, key ); if ( data !== undefined ) { return data; } // Attempt to get data from the cache // with the key camelized data = data_user.get( elem, camelKey ); if ( data !== undefined ) { return data; } // Attempt to ""discover"" the data in // HTML5 custom data-* attrs data = dataAttr( elem, camelKey, undefined ); if ( data !== undefined ) { return data; } // We tried really hard, but the data doesn't exist. return; } // Set the data... this.each(function() { // First, attempt to store a copy or reference of any // data that might've been store with a camelCased key. var data = data_user.get( this, camelKey ); // For HTML5 data-* attribute interop, we have to // store property names with dashes in a camelCase form. // This might not apply to all properties...* data_user.set( this, camelKey, value ); // *... In the case of properties that might _actually_ // have dashes, we need to also store a copy of that // unchanged property. if ( key.indexOf(""-"") !== -1 && data !== undefined ) { data_user.set( this, key, value ); } }); }, null, value, arguments.length > 1, null, true ); }, removeData: function( key ) { return this.each(function() { data_user.remove( this, key ); }); } }); queue = data_priv.get( elem, type ); if ( !queue || jQuery.isArray( data ) ) { queue = data_priv.access( elem, type, jQuery.makeArray(data) ); return data_priv.get( elem, key ) || data_priv.access( elem, key, { data_priv.remove( elem, [ type + ""queue"", key ] ); while ( i-- ) { tmp = data_priv.get( elements[ i ], type + ""queueHooks"" );var pnum = (/[+-]?(?:\d*\.|)\d+(?:[eE][+-]?\d+|)/).source;var cssExpand = [ ""Top"", ""Right"", ""Bottom"", ""Left"" ];var isHidden = function( elem, el ) { // isHidden might be called from jQuery#filter function; // in that case, element will be second argument elem = el || elem; return jQuery.css( elem, ""display"" ) === ""none"" || !jQuery.contains( elem.ownerDocument, elem );var rcheckableType = (/^(?:checkbox|radio)$/i);(function() { var fragment = document.createDocumentFragment(), div = fragment.appendChild( document.createElement( ""div"" ) ), input = document.createElement( ""input"" ); // #11217 - WebKit loses check when the name is after the checked attribute // Support: Windows Web Apps (WWA) // `name` and `type` need .setAttribute for WWA input.setAttribute( ""type"", ""radio"" ); input.setAttribute( ""checked"", ""checked"" ); input.setAttribute( ""name"", ""t"" ); div.appendChild( input ); // Support: Safari 5.1, iOS 5.1, Android 4.x, Android 2.3 // old WebKit doesn't clone checked state correctly in fragments support.checkClone = div.cloneNode( true ).cloneNode( true ).lastChild.checked; // Make sure textarea (and checkbox) defaultValue is properly cloned // Support: IE9-IE11+ div.innerHTML = ""<textarea>x</textarea>""; support.noCloneChecked = !!div.cloneNode( true ).lastChild.defaultValue; })(); var strundefined = typeof undefined; support.focusinBubbles = ""onfocusin"" in window; var rmouseEvent = /^(?:mouse|pointer|contextmenu)|click/, var handleObjIn, eventHandle, tmp, events, t, handleObj, special, handlers, type, namespaces, origType, elemData = data_priv.get( elem ); return typeof jQuery !== strundefined && jQuery.event.triggered !== e.type ? jQuery.event.dispatch.apply( elem, arguments ) : undefined; types = ( types || """" ).match( rnotwhite ) || [ """" ]; // Only use addEventListener if the special events handler returns false var j, origCount, tmp, events, t, handleObj, special, handlers, type, namespaces, origType, elemData = data_priv.hasData( elem ) && data_priv.get( elem ); types = ( types || """" ).match( rnotwhite ) || [ """" ]; data_priv.remove( elem, ""events"" ); var i, cur, tmp, bubbleType, ontype, handle, special, type = hasOwn.call( event, ""type"" ) ? event.type : event, namespaces = hasOwn.call( event, ""namespace"" ) ? event.namespace.split(""."") : []; handle = ( data_priv.get( cur, ""events"" ) || {} )[ event.type ] && data_priv.get( cur, ""handle"" ); if ( handle && handle.apply && jQuery.acceptData( cur ) ) { event.result = handle.apply( cur, data ); if ( event.result === false ) { event.preventDefault(); } if ( ontype && jQuery.isFunction( elem[ type ] ) && !jQuery.isWindow( elem ) ) { elem[ type ](); var i, j, ret, matched, handleObj, args = slice.call( arguments ), handlers = ( data_priv.get( this, ""events"" ) || {} )[ event.type ] || [], var i, matches, sel, handleObj, for ( ; cur !== this; cur = cur.parentNode || this ) { if ( cur.disabled !== true || event.type !== ""click"" ) { // Includes some event props shared by KeyEvent and MouseEvent props: ""altKey bubbles cancelable ctrlKey currentTarget eventPhase metaKey relatedTarget shiftKey target timeStamp view which"".split("" ""), fixHooks: {}, keyHooks: { props: ""char charCode key keyCode"".split("" ""), filter: function( event, original ) { // Add which for key events if ( event.which == null ) { event.which = original.charCode != null ? original.charCode : original.keyCode; } return event; } }, mouseHooks: { props: ""button buttons clientX clientY offsetX offsetY pageX pageY screenX screenY toElement"".split("" ""), filter: function( event, original ) { var eventDoc, doc, body, button = original.button; // Calculate pageX/Y if missing and clientX/Y available if ( event.pageX == null && original.clientX != null ) { eventDoc = event.target.ownerDocument || document; doc = eventDoc.documentElement; body = eventDoc.body; event.pageX = original.clientX + ( doc && doc.scrollLeft || body && body.scrollLeft || 0 ) - ( doc && doc.clientLeft || body && body.clientLeft || 0 ); event.pageY = original.clientY + ( doc && doc.scrollTop || body && body.scrollTop || 0 ) - ( doc && doc.clientTop || body && body.clientTop || 0 ); } // Add which for click: 1 === left; 2 === middle; 3 === right // Note: button is not normalized, so don't use it if ( !event.which && button !== undefined ) { event.which = ( button & 1 ? 1 : ( button & 2 ? 3 : ( button & 4 ? 2 : 0 ) ) ); } return event; } }, // Support: Cordova 2.5 (WebKit) (#13255) // All events should have a target; Cordova deviceready doesn't event.target = document; // Support: Safari 6.0+, Chrome < 28 this.focus(); return false; if ( this.type === ""checkbox"" && this.click && jQuery.nodeName( this, ""input"" ) ) { // Support: Firefox 20+ // Firefox doesn't alert if the returnValue field is not set. if ( event.result !== undefined && event.originalEvent ) {jQuery.removeEvent = function( elem, type, handle ) { if ( elem.removeEventListener ) { elem.removeEventListener( type, handle, false ); } }; this.isDefaultPrevented = src.defaultPrevented || src.defaultPrevented === undefined && // Support: Android < 4.0 src.returnValue === false ? returnTrue : returnFalse; if ( e && e.preventDefault ) { if ( e && e.stopPropagation ) { var e = this.originalEvent; if ( e && e.stopImmediatePropagation ) { e.stopImmediatePropagation(); } // Support: Chrome 15+ mouseleave: ""mouseout"", pointerenter: ""pointerover"", pointerleave: ""pointerout""// Support: Firefox, Chrome, Safari if ( !support.focusinBubbles ) { // Attach a single capturing handler on the document while someone wants focusin/focusout var handler = function( event ) { var doc = this.ownerDocument || this, attaches = data_priv.access( doc, fix ); if ( !attaches ) { doc.addEventListener( orig, handler, true ); data_priv.access( doc, fix, ( attaches || 0 ) + 1 ); var doc = this.ownerDocument || this, attaches = data_priv.access( doc, fix ) - 1; if ( !attaches ) { doc.removeEventListener( orig, handler, true ); data_priv.remove( doc, fix ); } else { data_priv.access( doc, fix, attaches ); var origFn, type;var // Support: IE 9 col: [ 2, ""<table><colgroup>"", ""</colgroup></table>"" ], _default: [ 0, """", """" ] };// Support: IE 9// Support: 1.x compatibility // Manipulating tables requires a tbody function manipulationTarget( elem, content ) { return jQuery.nodeName( elem, ""table"" ) && jQuery.nodeName( content.nodeType !== 11 ? content : content.firstChild, ""tr"" ) ? elem.getElementsByTagName(""tbody"")[0] || elem.appendChild( elem.ownerDocument.createElement(""tbody"") ) : elem; } // Replace/restore the type attribute of script elements for safe DOM manipulation function disableScript( elem ) { elem.type = (elem.getAttribute(""type"") !== null) + ""/"" + elem.type; return elem; } function restoreScript( elem ) { var match = rscriptTypeMasked.exec( elem.type ); if ( match ) { elem.type = match[ 1 ]; } else { elem.removeAttribute(""type""); } return elem; } // Mark scripts as having already been evaluated function setGlobalEval( elems, refElements ) { var i = 0, l = elems.length; for ( ; i < l; i++ ) { data_priv.set( elems[ i ], ""globalEval"", !refElements || data_priv.get( refElements[ i ], ""globalEval"" ) ); } } function cloneCopyEvent( src, dest ) { var i, l, type, pdataOld, pdataCur, udataOld, udataCur, events; if ( dest.nodeType !== 1 ) { return; } // 1. Copy private data: events, handlers, etc. if ( data_priv.hasData( src ) ) { pdataOld = data_priv.access( src ); pdataCur = data_priv.set( dest, pdataOld ); events = pdataOld.events; if ( events ) { delete pdataCur.handle; pdataCur.events = {}; for ( type in events ) { for ( i = 0, l = events[ type ].length; i < l; i++ ) { jQuery.event.add( dest, type, events[ type ][ i ] ); } } } } // 2. Copy user data if ( data_user.hasData( src ) ) { udataOld = data_user.access( src ); udataCur = jQuery.extend( {}, udataOld ); data_user.set( dest, udataCur ); } } function getAll( context, tag ) { var ret = context.getElementsByTagName ? context.getElementsByTagName( tag || ""*"" ) : context.querySelectorAll ? context.querySelectorAll( tag || ""*"" ) : []; return tag === undefined || tag && jQuery.nodeName( context, tag ) ? jQuery.merge( [ context ], ret ) : ret; } // Support: IE >= 9 function fixInput( src, dest ) { var nodeName = dest.nodeName.toLowerCase(); // Fails to persist the checked state of a cloned checkbox or radio button. if ( nodeName === ""input"" && rcheckableType.test( src.type ) ) { dest.checked = src.checked; // Fails to return the selected option to the default selected state when cloning options } else if ( nodeName === ""input"" || nodeName === ""textarea"" ) { dest.defaultValue = src.defaultValue; } } jQuery.extend({ clone: function( elem, dataAndEvents, deepDataAndEvents ) { var i, l, srcElements, destElements, clone = elem.cloneNode( true ), inPage = jQuery.contains( elem.ownerDocument, elem ); // Support: IE >= 9 // Fix Cloning issues if ( !support.noCloneChecked && ( elem.nodeType === 1 || elem.nodeType === 11 ) && !jQuery.isXMLDoc( elem ) ) { // We eschew Sizzle here for performance reasons: http://jsperf.com/getall-vs-sizzle/2 destElements = getAll( clone ); srcElements = getAll( elem ); for ( i = 0, l = srcElements.length; i < l; i++ ) { fixInput( srcElements[ i ], destElements[ i ] ); } } // Copy the events from the original to the clone if ( dataAndEvents ) { if ( deepDataAndEvents ) { srcElements = srcElements || getAll( elem ); destElements = destElements || getAll( clone ); for ( i = 0, l = srcElements.length; i < l; i++ ) { cloneCopyEvent( srcElements[ i ], destElements[ i ] ); } } else { cloneCopyEvent( elem, clone ); } } // Preserve script evaluation history destElements = getAll( clone, ""script"" ); if ( destElements.length > 0 ) { setGlobalEval( destElements, !inPage && getAll( elem, ""script"" ) ); } // Return the cloned set return clone; }, buildFragment: function( elems, context, scripts, selection ) { var elem, tmp, tag, wrap, contains, j, fragment = context.createDocumentFragment(), nodes = [], i = 0, l = elems.length; for ( ; i < l; i++ ) { elem = elems[ i ]; if ( elem || elem === 0 ) { // Add nodes directly if ( jQuery.type( elem ) === ""object"" ) { // Support: QtWebKit // jQuery.merge because push.apply(_, arraylike) throws jQuery.merge( nodes, elem.nodeType ? [ elem ] : elem ); // Convert non-html into a text node } else if ( !rhtml.test( elem ) ) { nodes.push( context.createTextNode( elem ) ); // Convert html into DOM nodes } else { tmp = tmp || fragment.appendChild( context.createElement(""div"") ); // Deserialize a standard representation tag = ( rtagName.exec( elem ) || [ """", """" ] )[ 1 ].toLowerCase(); wrap = wrapMap[ tag ] || wrapMap._default; tmp.innerHTML = wrap[ 1 ] + elem.replace( rxhtmlTag, ""<$1></$2>"" ) + wrap[ 2 ]; // Descend through wrappers to the right content j = wrap[ 0 ]; while ( j-- ) { tmp = tmp.lastChild; } // Support: QtWebKit // jQuery.merge because push.apply(_, arraylike) throws jQuery.merge( nodes, tmp.childNodes ); // Remember the top-level container tmp = fragment.firstChild; // Fixes #12346 // Support: Webkit, IE tmp.textContent = """"; } } } // Remove wrapper from fragment fragment.textContent = """"; i = 0; while ( (elem = nodes[ i++ ]) ) { // #4087 - If origin and destination elements are the same, and this is // that element, do not do anything if ( selection && jQuery.inArray( elem, selection ) !== -1 ) { continue; } contains = jQuery.contains( elem.ownerDocument, elem ); // Append to fragment tmp = getAll( fragment.appendChild( elem ), ""script"" ); // Preserve script evaluation history if ( contains ) { setGlobalEval( tmp ); } // Capture executables if ( scripts ) { j = 0; while ( (elem = tmp[ j++ ]) ) { if ( rscriptType.test( elem.type || """" ) ) { scripts.push( elem ); } } } } return fragment; }, cleanData: function( elems ) { var data, elem, type, key, special = jQuery.event.special, i = 0; for ( ; (elem = elems[ i ]) !== undefined; i++ ) { if ( jQuery.acceptData( elem ) ) { key = elem[ data_priv.expando ]; if ( key && (data = data_priv.cache[ key ]) ) { if ( data.events ) { for ( type in data.events ) { if ( special[ type ] ) { jQuery.event.remove( elem, type ); // This is a shortcut to avoid jQuery.event.remove's overhead } else { jQuery.removeEvent( elem, type, data.handle ); } } } if ( data_priv.cache[ key ] ) { // Discard any remaining `private` data delete data_priv.cache[ key ]; } } } // Discard any remaining `user` data delete data_user.cache[ elem[ data_user.expando ] ]; } } }); return access( this, function( value ) { this.empty().each(function() { if ( this.nodeType === 1 || this.nodeType === 11 || this.nodeType === 9 ) { this.textContent = value; } }); remove: function( selector, keepData /* Internal Use Only */ ) { // Prevent memory leaks // Remove any remaining nodes elem.textContent = """"; return this.map(function() { return access( this, function( value ) { var elem = this[ 0 ] || {}, if ( value === undefined && elem.nodeType === 1 ) { return elem.innerHTML; !wrapMap[ ( rtagName.exec( value ) || [ """", """" ] )[ 1 ].toLowerCase() ] ) { for ( ; i < l; i++ ) { elem = this[ i ] || {}; } catch( e ) {} var arg = arguments[ 0 ]; arg = this.parentNode; jQuery.cleanData( getAll( this ) ); if ( arg ) { arg.replaceChild( elem, this ); }); return arg && (arg.length || arg.nodeType) ? this : this.remove(); domManip: function( args, callback ) { args = concat.apply( [], args ); var fragment, first, scripts, hasScripts, node, doc, value = args[ 0 ], if ( isFunction || ( l > 1 && typeof value === ""string"" && !support.checkClone && rchecked.test( value ) ) ) { args[ 0 ] = value.call( this, index, self.html() ); self.domManip( args, callback ); fragment = jQuery.buildFragment( args, this[ 0 ].ownerDocument, false, this ); // Support: QtWebKit // jQuery.merge because push.apply(_, arraylike) throws callback.call( this[ i ], node, i ); !data_priv.access( node, ""globalEval"" ) && jQuery.contains( doc, node ) ) { // Optional AJAX dependency, but won't run scripts if not present if ( jQuery._evalUrl ) { jQuery._evalUrl( node.src ); } jQuery.globalEval( node.textContent.replace( rcleanScript, """" ) ); last = insert.length - 1, i = 0; elems = i === last ? this : this.clone( true ); jQuery( insert[ i ] )[ original ]( elems ); // Support: QtWebKit // .get() because push.apply(_, arraylike) throws push.apply( ret, elems.get() );var iframe, elemdisplay = {};/** * Retrieve the actual display of a element * @param {String} name nodeName of the element * @param {Object} doc Document object */ // Called only from within defaultDisplay function actualDisplay( name, doc ) { var style, elem = jQuery( doc.createElement( name ) ).appendTo( doc.body ), // getDefaultComputedStyle might be reliably used only on attached element display = window.getDefaultComputedStyle && ( style = window.getDefaultComputedStyle( elem[ 0 ] ) ) ? // Use of this method is a temporary fix (more like optmization) until something better comes along, // since it was removed from specification and supported only in FF style.display : jQuery.css( elem[ 0 ], ""display"" ); // We don't have any data stored on the element, // so use ""detach"" method as fast way to get rid of the element elem.detach(); return display;/** * Try to determine the default display value of an element * @param {String} nodeName */ function defaultDisplay( nodeName ) { var doc = document, display = elemdisplay[ nodeName ]; if ( !display ) { display = actualDisplay( nodeName, doc ); // If the simple way fails, read from inside an iframe if ( display === ""none"" || !display ) { // Use the already-created iframe if possible iframe = (iframe || jQuery( ""<iframe frameborder='0' width='0' height='0'/>"" )).appendTo( doc.documentElement ); // Always write a new HTML skeleton so Webkit and Firefox don't choke on reuse doc = iframe[ 0 ].contentDocument; // Support: IE doc.write(); doc.close(); display = actualDisplay( nodeName, doc ); iframe.detach(); } // Store the correct default display elemdisplay[ nodeName ] = display; return display; } var rmargin = (/^margin/); var rnumnonpx = new RegExp( ""^("" + pnum + "")(?!px)[a-z%]+$"", ""i"" ); var getStyles = function( elem ) { return elem.ownerDocument.defaultView.getComputedStyle( elem, null ); }; function curCSS( elem, name, computed ) { var width, minWidth, maxWidth, ret, style = elem.style; computed = computed || getStyles( elem ); // Support: IE9 // getPropertyValue is only needed for .css('filter') in IE9, see #12537 if ( computed ) { ret = computed.getPropertyValue( name ) || computed[ name ]; } if ( computed ) { if ( ret === """" && !jQuery.contains( elem.ownerDocument, elem ) ) { ret = jQuery.style( elem, name ); } // Support: iOS < 6 // A tribute to the ""awesome hack by Dean Edwards"" // iOS < 6 (at least) returns percentage for a larger set of values, but width seems to be reliably pixels // this is against the CSSOM draft spec: http://dev.w3.org/csswg/cssom/#resolved-values if ( rnumnonpx.test( ret ) && rmargin.test( name ) ) { // Remember the original values width = style.width; minWidth = style.minWidth; maxWidth = style.maxWidth; // Put in the new values to get a computed value out style.minWidth = style.maxWidth = style.width = ret; ret = computed.width; // Revert the changed values style.width = width; style.minWidth = minWidth; style.maxWidth = maxWidth; } } return ret !== undefined ? // Support: IE // IE returns zIndex value as an integer. ret + """" : ret;function addGetHookIf( conditionFn, hookFn ) { // Define the hook, we'll check on the first run if it's really needed. return { get: function() { if ( conditionFn() ) { // Hook not needed (or it's not possible to use it due to missing dependency), // remove it. // Since there are no other hooks for marginRight, remove the whole object. delete this.get; return; } // Hook needed; redefine it so that the support test is not executed again. return (this.get = hookFn).apply( this, arguments ); }; }(function() { var pixelPositionVal, boxSizingReliableVal, docElem = document.documentElement, container = document.createElement( ""div"" ), div = document.createElement( ""div"" ); if ( !div.style ) { return; } div.style.backgroundClip = ""content-box""; div.cloneNode( true ).style.backgroundClip = """"; support.clearCloneStyle = div.style.backgroundClip === ""content-box""; container.style.cssText = ""border:0;width:0;height:0;top:0;left:-9999px;margin-top:1px;"" + ""position:absolute""; container.appendChild( div ); // Executing both pixelPosition & boxSizingReliable tests require only one layout // so they're executed at the same time to save the second computation. function computePixelPositionAndBoxSizingReliable() { div.style.cssText = // Support: Firefox<29, Android 2.3 // Vendor-prefix box-sizing ""-webkit-box-sizing:border-box;-moz-box-sizing:border-box;"" + ""box-sizing:border-box;display:block;margin-top:1%;top:1%;"" + ""border:1px;padding:1px;width:4px;position:absolute""; div.innerHTML = """"; docElem.appendChild( container ); var divStyle = window.getComputedStyle( div, null ); pixelPositionVal = divStyle.top !== ""1%""; boxSizingReliableVal = divStyle.width === ""4px""; docElem.removeChild( container ); } // Support: node.js jsdom // Don't assume that getComputedStyle is a property of the global object if ( window.getComputedStyle ) { jQuery.extend( support, { pixelPosition: function() { // This test is executed only once but we still do memoizing // since we can use the boxSizingReliable pre-computing. // No need to check if the test was already performed, though. computePixelPositionAndBoxSizingReliable(); return pixelPositionVal; }, boxSizingReliable: function() { if ( boxSizingReliableVal == null ) { computePixelPositionAndBoxSizingReliable(); return boxSizingReliableVal; }, reliableMarginRight: function() { // Support: Android 2.3 // Check if div with explicit width and no margin-right incorrectly // gets computed margin-right based on width of container. (#3333) // WebKit Bug 13343 - getComputedStyle returns wrong value for margin-right // This support function is only executed once so no memoizing is needed. var ret, marginDiv = div.appendChild( document.createElement( ""div"" ) ); // Reset CSS: box-sizing; display; margin; border; padding marginDiv.style.cssText = div.style.cssText = // Support: Firefox<29, Android 2.3 // Vendor-prefix box-sizing ""-webkit-box-sizing:content-box;-moz-box-sizing:content-box;"" + ""box-sizing:content-box;display:block;margin:0;border:0;padding:0""; marginDiv.style.marginRight = marginDiv.style.width = ""0""; div.style.width = ""1px""; docElem.appendChild( container ); ret = !parseFloat( window.getComputedStyle( marginDiv, null ).marginRight ); docElem.removeChild( container ); return ret;})();// A method for quickly swapping in/out CSS properties to get correct calculations. jQuery.swap = function( elem, options, callback, args ) { var ret, name, old = {}; // Remember the old values, and insert the new ones for ( name in options ) { old[ name ] = elem.style[ name ]; elem.style[ name ] = options[ name ]; ret = callback.apply( elem, args || [] ); // Revert the old values for ( name in options ) { elem.style[ name ] = old[ name ]; } return ret; }; var rnumsplit = new RegExp( ""^("" + pnum + "")(.*)$"", ""i"" ), rrelNum = new RegExp( ""^([+-])=("" + pnum + "")"", ""i"" ), letterSpacing: ""0"", fontWeight: ""400"" var capName = name[0].toUpperCase() + name.slice(1), isBorderBox = jQuery.css( elem, ""boxSizing"", false, styles ) === ""border-box""; valueIsBorderBox = isBorderBox && ( support.boxSizingReliable() || val === elem.style[ name ] );function showHide( elements, show ) { var display, elem, hidden, values = [], index = 0, length = elements.length; for ( ; index < length; index++ ) { elem = elements[ index ]; if ( !elem.style ) { continue; values[ index ] = data_priv.get( elem, ""olddisplay"" ); display = elem.style.display; if ( show ) { // Reset the inline display of this element to learn if it is // being hidden by cascaded rules or not if ( !values[ index ] && display === ""none"" ) { elem.style.display = """"; } // Set elements which have been overridden with display: none // in a stylesheet to whatever the default browser style is // for such an element if ( elem.style.display === """" && isHidden( elem ) ) { values[ index ] = data_priv.access( elem, ""olddisplay"", defaultDisplay(elem.nodeName) ); } } else { hidden = isHidden( elem ); if ( display !== ""none"" || !hidden ) { data_priv.set( elem, ""olddisplay"", hidden ? display : jQuery.css( elem, ""display"" ) ); } } // Set the display of most of the elements in a second loop // to avoid the constant reflow for ( index = 0; index < length; index++ ) { elem = elements[ index ]; if ( !elem.style ) { continue; } if ( !show || elem.style.display === ""none"" || elem.style.display === """" ) { elem.style.display = show ? values[ index ] || """" : ""none""; } } return elements;jQuery.extend({ // Add in style property hooks for overriding the default // behavior of getting and setting a style property cssHooks: { opacity: { get: function( elem, computed ) { if ( computed ) { // We should always get a number back from opacity var ret = curCSS( elem, ""opacity"" ); return ret === """" ? ""1"" : ret; } } } }, // Don't automatically add ""px"" to these possibly-unitless properties cssNumber: { ""columnCount"": true, ""fillOpacity"": true, ""flexGrow"": true, ""flexShrink"": true, ""fontWeight"": true, ""lineHeight"": true, ""opacity"": true, ""order"": true, ""orphans"": true, ""widows"": true, ""zIndex"": true, ""zoom"": true }, // Add in properties whose names you wish to fix before // setting or getting the value cssProps: { // normalize float css property ""float"": ""cssFloat"" }, // Get and set the style property on a DOM Node style: function( elem, name, value, extra ) { // Don't set styles on text and comment nodes if ( !elem || elem.nodeType === 3 || elem.nodeType === 8 || !elem.style ) { return; } // Make sure that we're working with the right name var ret, type, hooks, origName = jQuery.camelCase( name ), style = elem.style; name = jQuery.cssProps[ origName ] || ( jQuery.cssProps[ origName ] = vendorPropName( style, origName ) ); // gets hook for the prefixed version // followed by the unprefixed version hooks = jQuery.cssHooks[ name ] || jQuery.cssHooks[ origName ]; // Check if we're setting a value if ( value !== undefined ) { type = typeof value; // convert relative number strings (+= or -=) to relative numbers. #7345 if ( type === ""string"" && (ret = rrelNum.exec( value )) ) { value = ( ret[1] + 1 ) * ret[2] + parseFloat( jQuery.css( elem, name ) ); // Fixes bug #9237 type = ""number""; } // Make sure that null and NaN values aren't set. See: #7116 if ( value == null || value !== value ) { return; } // If a number was passed in, add 'px' to the (except for certain CSS properties) if ( type === ""number"" && !jQuery.cssNumber[ origName ] ) { value += ""px""; } // Fixes #8908, it can be done more correctly by specifying setters in cssHooks, // but it would mean to define eight (for every problematic property) identical functions if ( !support.clearCloneStyle && value === """" && name.indexOf( ""background"" ) === 0 ) { style[ name ] = ""inherit""; } // If a hook was provided, use that value, otherwise just set the specified value if ( !hooks || !(""set"" in hooks) || (value = hooks.set( elem, value, extra )) !== undefined ) { style[ name ] = value; } } else { // If a hook was provided get the non-computed value from there if ( hooks && ""get"" in hooks && (ret = hooks.get( elem, false, extra )) !== undefined ) { return ret; } // Otherwise just get the value from the style object return style[ name ]; } }, css: function( elem, name, extra, styles ) { var val, num, hooks, origName = jQuery.camelCase( name ); // Make sure that we're working with the right name name = jQuery.cssProps[ origName ] || ( jQuery.cssProps[ origName ] = vendorPropName( elem.style, origName ) ); // gets hook for the prefixed version // followed by the unprefixed version hooks = jQuery.cssHooks[ name ] || jQuery.cssHooks[ origName ]; // If a hook was provided get the computed value from there if ( hooks && ""get"" in hooks ) { val = hooks.get( elem, true, extra ); } // Otherwise, if a way to get the computed value exists, use that if ( val === undefined ) { val = curCSS( elem, name, styles ); } //convert ""normal"" to computed value if ( val === ""normal"" && name in cssNormalTransform ) { val = cssNormalTransform[ name ]; } // Return, converting to number if forced or a qualifier was provided and val looks numeric if ( extra === """" || extra ) { num = parseFloat( val ); return extra === true || jQuery.isNumeric( num ) ? num || 0 : val; } return val; } }); return rdisplayswap.test( jQuery.css( elem, ""display"" ) ) && elem.offsetWidth === 0 ? jQuery.css( elem, ""boxSizing"", false, styles ) === ""border-box"",// Support: Android 2.3 jQuery.cssHooks.marginRight = addGetHookIf( support.reliableMarginRight, function( elem, computed ) { if ( computed ) { // WebKit Bug 13343 - getComputedStyle returns wrong value for margin-right // Work around by temporarily setting element display to inline-block return jQuery.swap( elem, { ""display"": ""inline-block"" }, curCSS, [ elem, ""marginRight"" ] );); css: function( name, value ) { return access( this, function( elem, name, value ) { var styles, len, map = {}, i = 0; if ( jQuery.isArray( name ) ) { styles = getStyles( elem ); len = name.length; for ( ; i < len; i++ ) { map[ name[ i ] ] = jQuery.css( elem, name[ i ], false, styles ); } return map; } return value !== undefined ? jQuery.style( elem, name, value ) : jQuery.css( elem, name ); }, name, value, arguments.length > 1 ); }, show: function() { return showHide( this, true ); }, hide: function() { return showHide( this ); }, toggle: function( state ) { if ( typeof state === ""boolean"" ) { return state ? this.show() : this.hide(); } return this.each(function() { if ( isHidden( this ) ) { jQuery( this ).show(); } else { jQuery( this ).hide(); } });function Tween( elem, options, prop, end, easing ) { return new Tween.prototype.init( elem, options, prop, end, easing ); } jQuery.Tween = Tween;Tween.prototype = { constructor: Tween, init: function( elem, options, prop, end, easing, unit ) { this.elem = elem; this.prop = prop; this.easing = easing || ""swing""; this.options = options; this.start = this.now = this.cur(); this.end = end; this.unit = unit || ( jQuery.cssNumber[ prop ] ? """" : ""px"" ); }, cur: function() { var hooks = Tween.propHooks[ this.prop ]; return hooks && hooks.get ? hooks.get( this ) : Tween.propHooks._default.get( this ); }, run: function( percent ) { var eased, hooks = Tween.propHooks[ this.prop ]; if ( this.options.duration ) { this.pos = eased = jQuery.easing[ this.easing ]( percent, this.options.duration * percent, 0, 1, this.options.duration ); } else { this.pos = eased = percent; this.now = ( this.end - this.start ) * eased + this.start; if ( this.options.step ) { this.options.step.call( this.elem, this.now, this ); } if ( hooks && hooks.set ) { hooks.set( this ); } else { Tween.propHooks._default.set( this ); } return this; }Tween.prototype.init.prototype = Tween.prototype;Tween.propHooks = { _default: { get: function( tween ) { var result; if ( tween.elem[ tween.prop ] != null && (!tween.elem.style || tween.elem.style[ tween.prop ] == null) ) { return tween.elem[ tween.prop ]; // passing an empty string as a 3rd parameter to .css will automatically // attempt a parseFloat and fallback to a string if the parse fails // so, simple values such as ""10px"" are parsed to Float. // complex values such as ""rotate(1rad)"" are returned as is. result = jQuery.css( tween.elem, tween.prop, """" ); // Empty strings, null, undefined and ""auto"" are converted to 0. return !result || result === ""auto"" ? 0 : result; }, set: function( tween ) { // use step hook for back compat - use cssHook if its there - use .style if its // available and use plain properties where available if ( jQuery.fx.step[ tween.prop ] ) { jQuery.fx.step[ tween.prop ]( tween ); } else if ( tween.elem.style && ( tween.elem.style[ jQuery.cssProps[ tween.prop ] ] != null || jQuery.cssHooks[ tween.prop ] ) ) { jQuery.style( tween.elem, tween.prop, tween.now + tween.unit ); } else { tween.elem[ tween.prop ] = tween.now; } } };// Support: IE9 // Panic based approach to setting things on disconnected nodes Tween.propHooks.scrollTop = Tween.propHooks.scrollLeft = { set: function( tween ) { if ( tween.elem.nodeType && tween.elem.parentNode ) { tween.elem[ tween.prop ] = tween.now; } } }; jQuery.easing = { linear: function( p ) { return p; }, swing: function( p ) { return 0.5 - Math.cos( p * Math.PI ) / 2; } }; jQuery.fx = Tween.prototype.init; // Back Compat <1.8 extension point jQuery.fx.step = {}; var fxNow, timerId, rfxtypes = /^(?:toggle|show|hide)$/, rfxnum = new RegExp( ""^(?:([+-])=|)("" + pnum + "")([a-z%]*)$"", ""i"" ), rrun = /queueHooks$/, animationPrefilters = [ defaultPrefilter ], tweeners = { ""*"": [ function( prop, value ) { var tween = this.createTween( prop, value ), target = tween.cur(), parts = rfxnum.exec( value ), unit = parts && parts[ 3 ] || ( jQuery.cssNumber[ prop ] ? """" : ""px"" ), // Starting value computation is required for potential unit mismatches start = ( jQuery.cssNumber[ prop ] || unit !== ""px"" && +target ) && rfxnum.exec( jQuery.css( tween.elem, prop ) ), scale = 1, maxIterations = 20; if ( start && start[ 3 ] !== unit ) { // Trust units reported by jQuery.css unit = unit || start[ 3 ]; // Make sure we update the tween properties later on parts = parts || []; // Iteratively approximate from a nonzero starting point start = +target || 1; do { // If previous iteration zeroed out, double until we get *something* // Use a string for doubling factor so we don't accidentally see scale as unchanged below scale = scale || "".5""; // Adjust and apply start = start / scale; jQuery.style( tween.elem, prop, start + unit ); // Update scale, tolerating zero or NaN from tween.cur() // And breaking the loop if scale is unchanged or perfect, or if we've just had enough } while ( scale !== (scale = tween.cur() / target) && scale !== 1 && --maxIterations ); } // Update tween properties if ( parts ) { start = tween.start = +start || +target || 0; tween.unit = unit; // If a +=/-= token was provided, we're doing a relative animation tween.end = parts[ 1 ] ? start + ( parts[ 1 ] + 1 ) * parts[ 2 ] : +parts[ 2 ]; } return tween; } ] }; // Animations created synchronously will run synchronously function createFxNow() { setTimeout(function() { fxNow = undefined; }); return ( fxNow = jQuery.now() ); } // Generate parameters to create a standard animation function genFx( type, includeWidth ) { var which, i = 0, attrs = { height: type }; // if we include width, step value is 1 to do all cssExpand values, // if we don't include width, step value is 2 to skip over Left and Right includeWidth = includeWidth ? 1 : 0; for ( ; i < 4 ; i += 2 - includeWidth ) { which = cssExpand[ i ]; attrs[ ""margin"" + which ] = attrs[ ""padding"" + which ] = type; } if ( includeWidth ) { attrs.opacity = attrs.width = type; } return attrs; } function createTween( value, prop, animation ) { var tween, collection = ( tweeners[ prop ] || [] ).concat( tweeners[ ""*"" ] ), index = 0, length = collection.length; for ( ; index < length; index++ ) { if ( (tween = collection[ index ].call( animation, prop, value )) ) { // we're done with this property return tween; } function defaultPrefilter( elem, props, opts ) { /* jshint validthis: true */ var prop, value, toggle, tween, hooks, oldfire, display, checkDisplay, anim = this, orig = {}, style = elem.style, hidden = elem.nodeType && isHidden( elem ), dataShow = data_priv.get( elem, ""fxshow"" ); // handle queue: false promises if ( !opts.queue ) { hooks = jQuery._queueHooks( elem, ""fx"" ); if ( hooks.unqueued == null ) { hooks.unqueued = 0; oldfire = hooks.empty.fire; hooks.empty.fire = function() { if ( !hooks.unqueued ) { oldfire(); } }; } hooks.unqueued++; anim.always(function() { // doing this makes sure that the complete handler will be called // before this completes anim.always(function() { hooks.unqueued--; if ( !jQuery.queue( elem, ""fx"" ).length ) { hooks.empty.fire(); } }); }); } // height/width overflow pass if ( elem.nodeType === 1 && ( ""height"" in props || ""width"" in props ) ) { // Make sure that nothing sneaks out // Record all 3 overflow attributes because IE9-10 do not // change the overflow attribute when overflowX and // overflowY are set to the same value opts.overflow = [ style.overflow, style.overflowX, style.overflowY ]; // Set display property to inline-block for height/width // animations on inline elements that are having width/height animated display = jQuery.css( elem, ""display"" ); // Test default display if display is currently ""none"" checkDisplay = display === ""none"" ? data_priv.get( elem, ""olddisplay"" ) || defaultDisplay( elem.nodeName ) : display; if ( checkDisplay === ""inline"" && jQuery.css( elem, ""float"" ) === ""none"" ) { style.display = ""inline-block""; } } if ( opts.overflow ) { style.overflow = ""hidden""; anim.always(function() { style.overflow = opts.overflow[ 0 ]; style.overflowX = opts.overflow[ 1 ]; style.overflowY = opts.overflow[ 2 ]; }); } // show/hide pass for ( prop in props ) { value = props[ prop ]; if ( rfxtypes.exec( value ) ) { delete props[ prop ]; toggle = toggle || value === ""toggle""; if ( value === ( hidden ? ""hide"" : ""show"" ) ) { // If there is dataShow left over from a stopped hide or show and we are going to proceed with show, we should pretend to be hidden if ( value === ""show"" && dataShow && dataShow[ prop ] !== undefined ) { hidden = true; } else { continue; } } orig[ prop ] = dataShow && dataShow[ prop ] || jQuery.style( elem, prop ); // Any non-fx value stops us from restoring the original display value } else { display = undefined; } } if ( !jQuery.isEmptyObject( orig ) ) { if ( dataShow ) { if ( ""hidden"" in dataShow ) { hidden = dataShow.hidden; } } else { dataShow = data_priv.access( elem, ""fxshow"", {} ); } // store state if its toggle - enables .stop().toggle() to ""reverse"" if ( toggle ) { dataShow.hidden = !hidden; } if ( hidden ) { jQuery( elem ).show(); } else { anim.done(function() { jQuery( elem ).hide(); }); } anim.done(function() { var prop; data_priv.remove( elem, ""fxshow"" ); for ( prop in orig ) { jQuery.style( elem, prop, orig[ prop ] ); } }); for ( prop in orig ) { tween = createTween( hidden ? dataShow[ prop ] : 0, prop, anim ); if ( !( prop in dataShow ) ) { dataShow[ prop ] = tween.start; if ( hidden ) { tween.end = tween.start; tween.start = prop === ""width"" || prop === ""height"" ? 1 : 0; } } } // If this is a noop like .hide().hide(), restore an overwritten display value } else if ( (display === ""none"" ? defaultDisplay( elem.nodeName ) : display) === ""inline"" ) { style.display = display; } } function propFilter( props, specialEasing ) { var index, name, easing, value, hooks; // camelCase, specialEasing and expand cssHook pass for ( index in props ) { name = jQuery.camelCase( index ); easing = specialEasing[ name ]; value = props[ index ]; if ( jQuery.isArray( value ) ) { easing = value[ 1 ]; value = props[ index ] = value[ 0 ]; } if ( index !== name ) { props[ name ] = value; delete props[ index ]; } hooks = jQuery.cssHooks[ name ]; if ( hooks && ""expand"" in hooks ) { value = hooks.expand( value ); delete props[ name ]; // not quite $.extend, this wont overwrite keys already present. // also - reusing 'index' from above because we have the correct ""name"" for ( index in value ) { if ( !( index in props ) ) { props[ index ] = value[ index ]; specialEasing[ index ] = easing; } } } else { specialEasing[ name ] = easing; } } } function Animation( elem, properties, options ) { var result, stopped, index = 0, length = animationPrefilters.length, deferred = jQuery.Deferred().always( function() { // don't match elem in the :animated selector delete tick.elem; }), tick = function() { if ( stopped ) { return false; } var currentTime = fxNow || createFxNow(), remaining = Math.max( 0, animation.startTime + animation.duration - currentTime ), // archaic crash bug won't allow us to use 1 - ( 0.5 || 0 ) (#12497) temp = remaining / animation.duration || 0, percent = 1 - temp, index = 0, length = animation.tweens.length; for ( ; index < length ; index++ ) { animation.tweens[ index ].run( percent ); } deferred.notifyWith( elem, [ animation, percent, remaining ]); if ( percent < 1 && length ) { return remaining; } else { deferred.resolveWith( elem, [ animation ] ); return false; } }, animation = deferred.promise({ elem: elem, props: jQuery.extend( {}, properties ), opts: jQuery.extend( true, { specialEasing: {} }, options ), originalProperties: properties, originalOptions: options, startTime: fxNow || createFxNow(), duration: options.duration, tweens: [], createTween: function( prop, end ) { var tween = jQuery.Tween( elem, animation.opts, prop, end, animation.opts.specialEasing[ prop ] || animation.opts.easing ); animation.tweens.push( tween ); return tween; }, stop: function( gotoEnd ) { var index = 0, // if we are going to the end, we want to run all the tweens // otherwise we skip this part length = gotoEnd ? animation.tweens.length : 0; if ( stopped ) { return this; } stopped = true; for ( ; index < length ; index++ ) { animation.tweens[ index ].run( 1 ); } // resolve when we played the last frame // otherwise, reject if ( gotoEnd ) { deferred.resolveWith( elem, [ animation, gotoEnd ] ); } else { deferred.rejectWith( elem, [ animation, gotoEnd ] ); } return this; } }), props = animation.props; propFilter( props, animation.opts.specialEasing ); for ( ; index < length ; index++ ) { result = animationPrefilters[ index ].call( animation, elem, props, animation.opts ); if ( result ) { return result; } } jQuery.map( props, createTween, animation ); if ( jQuery.isFunction( animation.opts.start ) ) { animation.opts.start.call( elem, animation ); } jQuery.fx.timer( jQuery.extend( tick, { elem: elem, anim: animation, queue: animation.opts.queue }) ); // attach callbacks from options return animation.progress( animation.opts.progress ) .done( animation.opts.done, animation.opts.complete ) .fail( animation.opts.fail ) .always( animation.opts.always ); } jQuery.Animation = jQuery.extend( Animation, { tweener: function( props, callback ) { if ( jQuery.isFunction( props ) ) { callback = props; props = [ ""*"" ]; } else { props = props.split("" ""); } var prop, index = 0, length = props.length; for ( ; index < length ; index++ ) { prop = props[ index ]; tweeners[ prop ] = tweeners[ prop ] || []; tweeners[ prop ].unshift( callback ); } }, prefilter: function( callback, prepend ) { if ( prepend ) { animationPrefilters.unshift( callback ); } else { animationPrefilters.push( callback ); } } }); jQuery.speed = function( speed, easing, fn ) { var opt = speed && typeof speed === ""object"" ? jQuery.extend( {}, speed ) : { complete: fn || !fn && easing || jQuery.isFunction( speed ) && speed, duration: speed, easing: fn && easing || easing && !jQuery.isFunction( easing ) && easing }; opt.duration = jQuery.fx.off ? 0 : typeof opt.duration === ""number"" ? opt.duration : opt.duration in jQuery.fx.speeds ? jQuery.fx.speeds[ opt.duration ] : jQuery.fx.speeds._default; // normalize opt.queue - true/undefined/null -> ""fx"" if ( opt.queue == null || opt.queue === true ) { opt.queue = ""fx""; } // Queueing opt.old = opt.complete; opt.complete = function() { if ( jQuery.isFunction( opt.old ) ) { opt.old.call( this ); } if ( opt.queue ) { jQuery.dequeue( this, opt.queue ); } }; return opt; }; jQuery.fn.extend({ fadeTo: function( speed, to, easing, callback ) { // show any hidden elements after setting opacity to 0 return this.filter( isHidden ).css( ""opacity"", 0 ).show() // animate to the value specified .end().animate({ opacity: to }, speed, easing, callback ); }, animate: function( prop, speed, easing, callback ) { var empty = jQuery.isEmptyObject( prop ), optall = jQuery.speed( speed, easing, callback ), doAnimation = function() { // Operate on a copy of prop so per-property easing won't be lost var anim = Animation( this, jQuery.extend( {}, prop ), optall ); // Empty animations, or finishing resolves immediately if ( empty || data_priv.get( this, ""finish"" ) ) { anim.stop( true ); } }; doAnimation.finish = doAnimation; return empty || optall.queue === false ? this.each( doAnimation ) : this.queue( optall.queue, doAnimation ); }, stop: function( type, clearQueue, gotoEnd ) { var stopQueue = function( hooks ) { var stop = hooks.stop; delete hooks.stop; stop( gotoEnd ); }; if ( typeof type !== ""string"" ) { gotoEnd = clearQueue; clearQueue = type; type = undefined; } if ( clearQueue && type !== false ) { this.queue( type || ""fx"", [] ); } return this.each(function() { var dequeue = true, index = type != null && type + ""queueHooks"", timers = jQuery.timers, data = data_priv.get( this ); if ( index ) { if ( data[ index ] && data[ index ].stop ) { stopQueue( data[ index ] ); } } else { for ( index in data ) { if ( data[ index ] && data[ index ].stop && rrun.test( index ) ) { stopQueue( data[ index ] ); } } } for ( index = timers.length; index--; ) { if ( timers[ index ].elem === this && (type == null || timers[ index ].queue === type) ) { timers[ index ].anim.stop( gotoEnd ); dequeue = false; timers.splice( index, 1 ); } } // start the next in the queue if the last step wasn't forced // timers currently will call their complete callbacks, which will dequeue // but only if they were gotoEnd if ( dequeue || !gotoEnd ) { jQuery.dequeue( this, type ); } }); }, finish: function( type ) { if ( type !== false ) { type = type || ""fx""; } return this.each(function() { var index, data = data_priv.get( this ), queue = data[ type + ""queue"" ], hooks = data[ type + ""queueHooks"" ], timers = jQuery.timers, length = queue ? queue.length : 0; // enable finishing flag on private data data.finish = true; // empty the queue first jQuery.queue( this, type, [] ); if ( hooks && hooks.stop ) { hooks.stop.call( this, true ); } // look for any active animations, and finish them for ( index = timers.length; index--; ) { if ( timers[ index ].elem === this && timers[ index ].queue === type ) { timers[ index ].anim.stop( true ); timers.splice( index, 1 ); } } // look for any animations in the old queue and finish them for ( index = 0; index < length; index++ ) { if ( queue[ index ] && queue[ index ].finish ) { queue[ index ].finish.call( this ); } } // turn off finishing flag delete data.finish; }); } }); jQuery.each([ ""toggle"", ""show"", ""hide"" ], function( i, name ) { var cssFn = jQuery.fn[ name ]; jQuery.fn[ name ] = function( speed, easing, callback ) { return speed == null || typeof speed === ""boolean"" ? cssFn.apply( this, arguments ) : this.animate( genFx( name, true ), speed, easing, callback ); }; }); // Generate shortcuts for custom animations jQuery.each({ slideDown: genFx(""show""), slideUp: genFx(""hide""), slideToggle: genFx(""toggle""), fadeIn: { opacity: ""show"" }, fadeOut: { opacity: ""hide"" }, fadeToggle: { opacity: ""toggle"" } }, function( name, props ) { jQuery.fn[ name ] = function( speed, easing, callback ) { return this.animate( props, speed, easing, callback ); }; }); jQuery.timers = []; jQuery.fx.tick = function() { var timer, i = 0, timers = jQuery.timers; fxNow = jQuery.now(); for ( ; i < timers.length; i++ ) { timer = timers[ i ]; // Checks the timer has not already been removed if ( !timer() && timers[ i ] === timer ) { timers.splice( i--, 1 ); } } if ( !timers.length ) { jQuery.fx.stop(); } fxNow = undefined; }; jQuery.fx.timer = function( timer ) { jQuery.timers.push( timer ); if ( timer() ) { jQuery.fx.start(); } else { jQuery.timers.pop(); } }; jQuery.fx.interval = 13; jQuery.fx.start = function() { if ( !timerId ) { timerId = setInterval( jQuery.fx.tick, jQuery.fx.interval ); } }; jQuery.fx.stop = function() { clearInterval( timerId ); timerId = null; }; jQuery.fx.speeds = { slow: 600, fast: 200, // Default speed _default: 400 }; // Based off of the plugin by Clint Helfers, with permission. // http://blindsignals.com/index.php/2009/07/jquery-delay/ jQuery.fn.delay = function( time, type ) { time = jQuery.fx ? jQuery.fx.speeds[ time ] || time : time; type = type || ""fx""; return this.queue( type, function( next, hooks ) { var timeout = setTimeout( next, time ); hooks.stop = function() { clearTimeout( timeout ); }; }); }; (function() { var input = document.createElement( ""input"" ), select = document.createElement( ""select"" ), opt = select.appendChild( document.createElement( ""option"" ) ); input.type = ""checkbox""; // Support: iOS 5.1, Android 4.x, Android 2.3 // Check the default checkbox/radio value ("""" on old WebKit; ""on"" elsewhere) support.checkOn = input.value !== """"; // Must access the parent to make an option select properly // Support: IE9, IE10 support.optSelected = opt.selected; // Make sure that the options inside disabled selects aren't marked as disabled // (WebKit marks them as disabled) select.disabled = true; support.optDisabled = !opt.disabled; // Check if an input maintains its value after becoming a radio // Support: IE9, IE10 input = document.createElement( ""input"" ); input.value = ""t""; input.type = ""radio""; support.radioValue = input.value === ""t""; })(); var nodeHook, boolHook, attrHandle = jQuery.expr.attrHandle; jQuery.fn.extend({ attr: function( name, value ) { return access( this, jQuery.attr, name, value, arguments.length > 1 ); }, removeAttr: function( name ) { return this.each(function() { jQuery.removeAttr( this, name ); }); } }); jQuery.extend({ attr: function( elem, name, value ) { var hooks, ret, nType = elem.nodeType; // don't get/set attributes on text, comment and attribute nodes if ( !elem || nType === 3 || nType === 8 || nType === 2 ) { return; } // Fallback to prop when attributes are not supported if ( typeof elem.getAttribute === strundefined ) { return jQuery.prop( elem, name, value ); } // All attributes are lowercase // Grab necessary hook if one is defined if ( nType !== 1 || !jQuery.isXMLDoc( elem ) ) { name = name.toLowerCase(); hooks = jQuery.attrHooks[ name ] || ( jQuery.expr.match.bool.test( name ) ? boolHook : nodeHook ); } if ( value !== undefined ) { if ( value === null ) { jQuery.removeAttr( elem, name ); } else if ( hooks && ""set"" in hooks && (ret = hooks.set( elem, value, name )) !== undefined ) { return ret; } else { elem.setAttribute( name, value + """" ); return value; } } else if ( hooks && ""get"" in hooks && (ret = hooks.get( elem, name )) !== null ) { return ret; } else { ret = jQuery.find.attr( elem, name ); // Non-existent attributes return null, we normalize to undefined return ret == null ? undefined : ret; } }, removeAttr: function( elem, value ) { var name, propName, i = 0, attrNames = value && value.match( rnotwhite ); if ( attrNames && elem.nodeType === 1 ) { while ( (name = attrNames[i++]) ) { propName = jQuery.propFix[ name ] || name; // Boolean attributes get special treatment (#10870) if ( jQuery.expr.match.bool.test( name ) ) { // Set corresponding property to false elem[ propName ] = false; } elem.removeAttribute( name ); } } }, attrHooks: { type: { set: function( elem, value ) { if ( !support.radioValue && value === ""radio"" && jQuery.nodeName( elem, ""input"" ) ) { // Setting the type on a radio button after the value resets the value in IE6-9 // Reset value to default in case type is set after value during creation var val = elem.value; elem.setAttribute( ""type"", value ); if ( val ) { elem.value = val; } return value; } } } } }); // Hooks for boolean attributes boolHook = { set: function( elem, value, name ) { if ( value === false ) { // Remove boolean attributes when set to false jQuery.removeAttr( elem, name ); } else { elem.setAttribute( name, name ); } return name; } }; jQuery.each( jQuery.expr.match.bool.source.match( /\w+/g ), function( i, name ) { var getter = attrHandle[ name ] || jQuery.find.attr; attrHandle[ name ] = function( elem, name, isXML ) { var ret, handle; if ( !isXML ) { // Avoid an infinite loop by temporarily removing this function from the getter handle = attrHandle[ name ]; attrHandle[ name ] = ret; ret = getter( elem, name, isXML ) != null ? name.toLowerCase() : null; attrHandle[ name ] = handle; } return ret; }; }); var rfocusable = /^(?:input|select|textarea|button)$/i; jQuery.fn.extend({ prop: function( name, value ) { return access( this, jQuery.prop, name, value, arguments.length > 1 ); }, removeProp: function( name ) { return this.each(function() { delete this[ jQuery.propFix[ name ] || name ]; }); } }); jQuery.extend({ propFix: { ""for"": ""htmlFor"", ""class"": ""className"" }, prop: function( elem, name, value ) { var ret, hooks, notxml, nType = elem.nodeType; // don't get/set properties on text, comment and attribute nodes if ( !elem || nType === 3 || nType === 8 || nType === 2 ) { return; } notxml = nType !== 1 || !jQuery.isXMLDoc( elem ); if ( notxml ) { // Fix name and attach hooks name = jQuery.propFix[ name ] || name; hooks = jQuery.propHooks[ name ]; } if ( value !== undefined ) { return hooks && ""set"" in hooks && (ret = hooks.set( elem, value, name )) !== undefined ? ret : ( elem[ name ] = value ); } else { return hooks && ""get"" in hooks && (ret = hooks.get( elem, name )) !== null ? ret : elem[ name ]; } }, propHooks: { tabIndex: { get: function( elem ) { return elem.hasAttribute( ""tabindex"" ) || rfocusable.test( elem.nodeName ) || elem.href ? elem.tabIndex : -1; } } } }); // Support: IE9+ // Selectedness for an option in an optgroup can be inaccurate if ( !support.optSelected ) { jQuery.propHooks.selected = { get: function( elem ) { var parent = elem.parentNode; if ( parent && parent.parentNode ) { parent.parentNode.selectedIndex; } return null; } }; } jQuery.each([ ""tabIndex"", ""readOnly"", ""maxLength"", ""cellSpacing"", ""cellPadding"", ""rowSpan"", ""colSpan"", ""useMap"", ""frameBorder"", ""contentEditable"" ], function() { jQuery.propFix[ this.toLowerCase() ] = this; }); var rclass = /[\t\r\n\f]/g; jQuery.fn.extend({ addClass: function( value ) { var classes, elem, cur, clazz, j, finalValue, proceed = typeof value === ""string"" && value, i = 0, len = this.length; if ( jQuery.isFunction( value ) ) { return this.each(function( j ) { jQuery( this ).addClass( value.call( this, j, this.className ) ); }); } if ( proceed ) { // The disjunction here is for better compressibility (see removeClass) classes = ( value || """" ).match( rnotwhite ) || []; for ( ; i < len; i++ ) { elem = this[ i ]; cur = elem.nodeType === 1 && ( elem.className ? ( "" "" + elem.className + "" "" ).replace( rclass, "" "" ) : "" "" ); if ( cur ) { j = 0; while ( (clazz = classes[j++]) ) { if ( cur.indexOf( "" "" + clazz + "" "" ) < 0 ) { cur += clazz + "" ""; } } // only assign if different to avoid unneeded rendering. finalValue = jQuery.trim( cur ); if ( elem.className !== finalValue ) { elem.className = finalValue; } } } } return this; }, removeClass: function( value ) { var classes, elem, cur, clazz, j, finalValue, proceed = arguments.length === 0 || typeof value === ""string"" && value, i = 0, len = this.length; if ( jQuery.isFunction( value ) ) { return this.each(function( j ) { jQuery( this ).removeClass( value.call( this, j, this.className ) ); }); } if ( proceed ) { classes = ( value || """" ).match( rnotwhite ) || []; for ( ; i < len; i++ ) { elem = this[ i ]; // This expression is here for better compressibility (see addClass) cur = elem.nodeType === 1 && ( elem.className ? ( "" "" + elem.className + "" "" ).replace( rclass, "" "" ) : """" ); if ( cur ) { j = 0; while ( (clazz = classes[j++]) ) { // Remove *all* instances while ( cur.indexOf( "" "" + clazz + "" "" ) >= 0 ) { cur = cur.replace( "" "" + clazz + "" "", "" "" ); } } // only assign if different to avoid unneeded rendering. finalValue = value ? jQuery.trim( cur ) : """"; if ( elem.className !== finalValue ) { elem.className = finalValue; } } } } return this; }, toggleClass: function( value, stateVal ) { var type = typeof value; if ( typeof stateVal === ""boolean"" && type === ""string"" ) { return stateVal ? this.addClass( value ) : this.removeClass( value ); } if ( jQuery.isFunction( value ) ) { return this.each(function( i ) { jQuery( this ).toggleClass( value.call(this, i, this.className, stateVal), stateVal ); }); } return this.each(function() { if ( type === ""string"" ) { // toggle individual class names var className, i = 0, self = jQuery( this ), classNames = value.match( rnotwhite ) || []; while ( (className = classNames[ i++ ]) ) { // check each className given, space separated list if ( self.hasClass( className ) ) { self.removeClass( className ); } else { self.addClass( className ); } } // Toggle whole class name } else if ( type === strundefined || type === ""boolean"" ) { if ( this.className ) { // store className if set data_priv.set( this, ""__className__"", this.className ); } // If the element has a class name or if we're passed ""false"", // then remove the whole classname (if there was one, the above saved it). // Otherwise bring back whatever was previously saved (if anything), // falling back to the empty string if nothing was stored. this.className = this.className || value === false ? """" : data_priv.get( this, ""__className__"" ) || """"; } }); }, hasClass: function( selector ) { var className = "" "" + selector + "" "", i = 0, l = this.length; for ( ; i < l; i++ ) { if ( this[i].nodeType === 1 && ("" "" + this[i].className + "" "").replace(rclass, "" "").indexOf( className ) >= 0 ) { return true; } } return false; } }); var rreturn = /\r/g; jQuery.fn.extend({ val: function( value ) { var hooks, ret, isFunction, elem = this[0]; if ( !arguments.length ) { if ( elem ) { hooks = jQuery.valHooks[ elem.type ] || jQuery.valHooks[ elem.nodeName.toLowerCase() ]; if ( hooks && ""get"" in hooks && (ret = hooks.get( elem, ""value"" )) !== undefined ) { return ret; } ret = elem.value; return typeof ret === ""string"" ? // handle most common string cases ret.replace(rreturn, """") : // handle cases where value is null/undef or number ret == null ? """" : ret; } return; } isFunction = jQuery.isFunction( value ); return this.each(function( i ) { var val; if ( this.nodeType !== 1 ) { return; } if ( isFunction ) { val = value.call( this, i, jQuery( this ).val() ); } else { val = value; } // Treat null/undefined as """"; convert numbers to string if ( val == null ) { val = """"; } else if ( typeof val === ""number"" ) { val += """"; } else if ( jQuery.isArray( val ) ) { val = jQuery.map( val, function( value ) { return value == null ? """" : value + """"; }); } hooks = jQuery.valHooks[ this.type ] || jQuery.valHooks[ this.nodeName.toLowerCase() ]; // If set returns undefined, fall back to normal setting if ( !hooks || !(""set"" in hooks) || hooks.set( this, val, ""value"" ) === undefined ) { this.value = val; } }); } }); jQuery.extend({ valHooks: { option: { get: function( elem ) { var val = jQuery.find.attr( elem, ""value"" ); return val != null ? val : // Support: IE10-11+ // option.text throws exceptions (#14686, #14858) jQuery.trim( jQuery.text( elem ) ); } }, select: { get: function( elem ) { var value, option, options = elem.options, index = elem.selectedIndex, one = elem.type === ""select-one"" || index < 0, values = one ? null : [], max = one ? index + 1 : options.length, i = index < 0 ? max : one ? index : 0; // Loop through all the selected options for ( ; i < max; i++ ) { option = options[ i ]; // IE6-9 doesn't update selected after form reset (#2551) if ( ( option.selected || i === index ) && // Don't return options that are disabled or in a disabled optgroup ( support.optDisabled ? !option.disabled : option.getAttribute( ""disabled"" ) === null ) && ( !option.parentNode.disabled || !jQuery.nodeName( option.parentNode, ""optgroup"" ) ) ) { // Get the specific value for the option value = jQuery( option ).val(); // We don't need an array for one selects if ( one ) { return value; } // Multi-Selects return an array values.push( value ); } } return values; }, set: function( elem, value ) { var optionSet, option, options = elem.options, values = jQuery.makeArray( value ), i = options.length; while ( i-- ) { option = options[ i ]; if ( (option.selected = jQuery.inArray( option.value, values ) >= 0) ) { optionSet = true; } } // force browsers to behave consistently when non-matching value is set if ( !optionSet ) { elem.selectedIndex = -1; } return values; } } } }); // Radios and checkboxes getter/setter jQuery.each([ ""radio"", ""checkbox"" ], function() { jQuery.valHooks[ this ] = { set: function( elem, value ) { if ( jQuery.isArray( value ) ) { return ( elem.checked = jQuery.inArray( jQuery(elem).val(), value ) >= 0 ); } } }; if ( !support.checkOn ) { jQuery.valHooks[ this ].get = function( elem ) { // Support: Webkit // """" is returned instead of ""on"" if a value isn't specified return elem.getAttribute(""value"") === null ? ""on"" : elem.value; }; } }); // Return jQuery for attributes-only inclusion var nonce = jQuery.now(); var rquery = (/\?/); // Support: Android 2.3 // Workaround failure to string-cast null input jQuery.parseJSON = function( data ) { return JSON.parse( data + """" ); }; // Cross-browser xml parsing jQuery.parseXML = function( data ) { var xml, tmp; if ( !data || typeof data !== ""string"" ) { return null; } // Support: IE9 try { tmp = new DOMParser(); xml = tmp.parseFromString( data, ""text/xml"" ); } catch ( e ) { xml = undefined; } if ( !xml || xml.getElementsByTagName( ""parsererror"" ).length ) { jQuery.error( ""Invalid XML: "" + data ); } return xml; }; rheaders = /^(.*?):[ \t]*([^\r\n]*)$/mg, rurl = /^([\w.+-]+:)(?:\/\/(?:[^\/?#]*@|)([^\/?#:]*)(?::(\d+)|)|)/, dataTypes = dataTypeExpression.toLowerCase().match( rnotwhite ) || []; if ( typeof dataTypeOrTransport === ""string"" && !seekingTransport && !inspected[ dataTypeOrTransport ] ) { var key, deep,/* Handles responses to an ajax request: * - finds the right dataType (mediates between content-type and expected dataType) * - returns the corresponding response */ function ajaxHandleResponses( s, jqXHR, responses ) { var ct, type, finalDataType, firstDataType, contents = s.contents, dataTypes = s.dataTypes; // Remove auto dataType and get content-type in the process while ( dataTypes[ 0 ] === ""*"" ) { dataTypes.shift(); if ( ct === undefined ) { ct = s.mimeType || jqXHR.getResponseHeader(""Content-Type""); } // Check if we're dealing with a known content-type if ( ct ) { for ( type in contents ) { if ( contents[ type ] && contents[ type ].test( ct ) ) { dataTypes.unshift( type ); break; } } // Check to see if we have a response for the expected dataType if ( dataTypes[ 0 ] in responses ) { finalDataType = dataTypes[ 0 ]; } else { // Try convertible dataTypes for ( type in responses ) { if ( !dataTypes[ 0 ] || s.converters[ type + "" "" + dataTypes[0] ] ) { finalDataType = type; break; } if ( !firstDataType ) { firstDataType = type; } } // Or just use first one finalDataType = finalDataType || firstDataType; // If we found a dataType // We add the dataType to the list if needed // and return the corresponding response if ( finalDataType ) { if ( finalDataType !== dataTypes[ 0 ] ) { dataTypes.unshift( finalDataType ); } return responses[ finalDataType ]; } }/* Chain conversions given the request and the original response * Also sets the responseXXX fields on the jqXHR instance */ function ajaxConvert( s, response, jqXHR, isSuccess ) { var conv2, current, conv, tmp, prev, converters = {}, // Work with a copy of dataTypes in case we need to modify it for conversion dataTypes = s.dataTypes.slice(); // Create converters map with lowercased keys if ( dataTypes[ 1 ] ) { for ( conv in s.converters ) { converters[ conv.toLowerCase() ] = s.converters[ conv ]; } current = dataTypes.shift(); // Convert to each sequential dataType while ( current ) { if ( s.responseFields[ current ] ) { jqXHR[ s.responseFields[ current ] ] = response; } // Apply the dataFilter if provided if ( !prev && isSuccess && s.dataFilter ) { response = s.dataFilter( response, s.dataType ); } prev = current; current = dataTypes.shift(); if ( current ) { // There's only work to do if current dataType is non-auto if ( current === ""*"" ) { current = prev; // Convert response if prev dataType is non-auto and differs from current } else if ( prev !== ""*"" && prev !== current ) { // Seek a direct converter conv = converters[ prev + "" "" + current ] || converters[ ""* "" + current ]; // If none found, seek a pair if ( !conv ) { for ( conv2 in converters ) { // If conv2 outputs current tmp = conv2.split( "" "" ); if ( tmp[ 1 ] === current ) { // If prev can be converted to accepted input conv = converters[ prev + "" "" + tmp[ 0 ] ] || converters[ ""* "" + tmp[ 0 ] ]; if ( conv ) { // Condense equivalence converters if ( conv === true ) { conv = converters[ conv2 ]; // Otherwise, insert the intermediate dataType } else if ( converters[ conv2 ] !== true ) { current = tmp[ 0 ]; dataTypes.unshift( tmp[ 1 ] ); } break; } } } } // Apply converter (if not an equivalence) if ( conv !== true ) { // Unless errors are allowed to bubble, catch and return them if ( conv && s[ ""throws"" ] ) { response = conv( response ); } else { try { response = conv( response ); } catch ( e ) { return { state: ""parsererror"", error: conv ? e : ""No conversion from "" + prev + "" to "" + current }; } } } } } } return { state: ""success"", data: response }; } var transport, // Response headers responseHeaders, // Cross-domain detection vars parts, // Loop variable i, // Add protocol if not provided (prefilters might expect it) s.url = ( ( url || s.url || ajaxLocation ) + """" ).replace( rhash, """" ) .replace( rprotocol, ajaxLocParts[ 1 ] + ""//"" ); s.dataTypes = jQuery.trim( s.dataType || ""*"" ).toLowerCase().match( rnotwhite ) || [ """" ]; cacheURL = ( s.url += ( rquery.test( cacheURL ) ? ""&"" : ""?"" ) + s.data ); cacheURL.replace( rts, ""$1_="" + nonce++ ) : cacheURL + ( rquery.test( cacheURL ) ? ""&"" : ""?"" ) + ""_="" + nonce++;// Attach a bunch of functions for handling common AJAX events jQuery.each( [ ""ajaxStart"", ""ajaxStop"", ""ajaxComplete"", ""ajaxError"", ""ajaxSuccess"", ""ajaxSend"" ], function( i, type ) { jQuery.fn[ type ] = function( fn ) { return this.on( type, fn ); }; }); jQuery._evalUrl = function( url ) { return jQuery.ajax({ url: url, type: ""GET"", dataType: ""script"", async: false, global: false, ""throws"": true }); }; jQuery.fn.extend({ wrapAll: function( html ) { var wrap; if ( jQuery.isFunction( html ) ) { return this.each(function( i ) { jQuery( this ).wrapAll( html.call(this, i) ); }); if ( this[ 0 ] ) { // The elements to wrap the target around wrap = jQuery( html, this[ 0 ].ownerDocument ).eq( 0 ).clone( true ); if ( this[ 0 ].parentNode ) { wrap.insertBefore( this[ 0 ] ); wrap.map(function() { var elem = this; while ( elem.firstElementChild ) { elem = elem.firstElementChild; } return elem; }).append( this ); } return this; }, wrapInner: function( html ) { if ( jQuery.isFunction( html ) ) { return this.each(function( i ) { jQuery( this ).wrapInner( html.call(this, i) ); }); } return this.each(function() { var self = jQuery( this ), contents = self.contents(); if ( contents.length ) { contents.wrapAll( html ); } else { self.append( html ); } }); }, wrap: function( html ) { var isFunction = jQuery.isFunction( html ); return this.each(function( i ) { jQuery( this ).wrapAll( isFunction ? html.call(this, i) : html ); }); }, unwrap: function() { return this.parent().each(function() { if ( !jQuery.nodeName( this, ""body"" ) ) { jQuery( this ).replaceWith( this.childNodes ); } }).end(); } }); jQuery.expr.filters.hidden = function( elem ) { // Support: Opera <= 12.12 // Opera reports offsetWidths and offsetHeights less than zero on some elements return elem.offsetWidth <= 0 && elem.offsetHeight <= 0; }; jQuery.expr.filters.visible = function( elem ) { return !jQuery.expr.filters.hidden( elem ); }; var r20 = /%20/g, rbracket = /\[\]$/, rCRLF = /\r?\n/g, rsubmitterTypes = /^(?:submit|button|image|reset|file)$/i, rsubmittable = /^(?:input|select|textarea|keygen)/i; function buildParams( prefix, obj, traditional, add ) { var name; if ( jQuery.isArray( obj ) ) { // Serialize array item. jQuery.each( obj, function( i, v ) { if ( traditional || rbracket.test( prefix ) ) { // Treat each array item as a scalar. add( prefix, v ); } else { // Item is non-scalar (array or object), encode its numeric index. buildParams( prefix + ""["" + ( typeof v === ""object"" ? i : """" ) + ""]"", v, traditional, add ); } }); } else if ( !traditional && jQuery.type( obj ) === ""object"" ) { // Serialize object item. for ( name in obj ) { buildParams( prefix + ""["" + name + ""]"", obj[ name ], traditional, add ); } // Serialize scalar item. add( prefix, obj );// Serialize an array of form elements or a set of // key/values into a query string jQuery.param = function( a, traditional ) { var prefix, s = [], add = function( key, value ) { // If value is a function, invoke it and return its value value = jQuery.isFunction( value ) ? value() : ( value == null ? """" : value ); s[ s.length ] = encodeURIComponent( key ) + ""="" + encodeURIComponent( value ); }; // Set traditional to true for jQuery <= 1.3.2 behavior. if ( traditional === undefined ) { traditional = jQuery.ajaxSettings && jQuery.ajaxSettings.traditional; } // If an array was passed in, assume that it is an array of form elements. if ( jQuery.isArray( a ) || ( a.jquery && !jQuery.isPlainObject( a ) ) ) { // Serialize the form elements jQuery.each( a, function() { add( this.name, this.value ); }); } else { // If traditional, encode the ""old"" way (the way 1.3.2 or older // did it), otherwise encode params recursively. for ( prefix in a ) { buildParams( prefix, a[ prefix ], traditional, add ); // Return the resulting serialization return s.join( ""&"" ).replace( r20, ""+"" ); };jQuery.fn.extend({ serialize: function() { return jQuery.param( this.serializeArray() ); }, serializeArray: function() { return this.map(function() { // Can add propHook for ""elements"" to filter or add form elements var elements = jQuery.prop( this, ""elements"" ); return elements ? jQuery.makeArray( elements ) : this; }) .filter(function() { var type = this.type; // Use .is( "":disabled"" ) so that fieldset[disabled] works return this.name && !jQuery( this ).is( "":disabled"" ) && rsubmittable.test( this.nodeName ) && !rsubmitterTypes.test( type ) && ( this.checked || !rcheckableType.test( type ) ); }) .map(function( i, elem ) { var val = jQuery( this ).val(); return val == null ? null : jQuery.isArray( val ) ? jQuery.map( val, function( val ) { return { name: elem.name, value: val.replace( rCRLF, ""\r\n"" ) }; }) : { name: elem.name, value: val.replace( rCRLF, ""\r\n"" ) }; }).get(); } }); jQuery.ajaxSettings.xhr = function() { try { return new XMLHttpRequest(); } catch( e ) {} }; var xhrId = 0, xhrCallbacks = {}, xhrSuccessStatus = { // file protocol always yields status code 0, assume 200 0: 200, // Support: IE9 // #1450: sometimes IE returns 1223 when it should be 204 1223: 204 }, xhrSupported = jQuery.ajaxSettings.xhr(); // Support: IE9 // Open requests must be manually aborted on unload (#5280) if ( window.ActiveXObject ) { jQuery( window ).on( ""unload"", function() { for ( var key in xhrCallbacks ) { xhrCallbacks[ key ](); }); }support.cors = !!xhrSupported && ( ""withCredentials"" in xhrSupported ); support.ajax = xhrSupported = !!xhrSupported;jQuery.ajaxTransport(function( options ) { var callback; // Cross domain only allowed if supported through XMLHttpRequest if ( support.cors || xhrSupported && !options.crossDomain ) { return { send: function( headers, complete ) { var i, xhr = options.xhr(), id = ++xhrId; xhr.open( options.type, options.url, options.async, options.username, options.password ); // Apply custom fields if provided if ( options.xhrFields ) { for ( i in options.xhrFields ) { xhr[ i ] = options.xhrFields[ i ]; } } // Override mime type if needed if ( options.mimeType && xhr.overrideMimeType ) { xhr.overrideMimeType( options.mimeType ); } // X-Requested-With header // For cross-domain requests, seeing as conditions for a preflight are // akin to a jigsaw puzzle, we simply never set it to be sure. // (it can always be set on a per-request basis or even using ajaxSetup) // For same-domain requests, won't change header if already provided. if ( !options.crossDomain && !headers[""X-Requested-With""] ) { headers[""X-Requested-With""] = ""XMLHttpRequest""; } // Set headers for ( i in headers ) { xhr.setRequestHeader( i, headers[ i ] ); } // Callback callback = function( type ) { return function() { if ( callback ) { delete xhrCallbacks[ id ]; callback = xhr.onload = xhr.onerror = null; if ( type === ""abort"" ) { xhr.abort(); } else if ( type === ""error"" ) { complete( // file: protocol always yields status 0; see #8605, #14207 xhr.status, xhr.statusText ); } else { complete( xhrSuccessStatus[ xhr.status ] || xhr.status, xhr.statusText, // Support: IE9 // Accessing binary-data responseText throws an exception // (#11426) typeof xhr.responseText === ""string"" ? { text: xhr.responseText } : undefined, xhr.getAllResponseHeaders() ); }; }; // Listen to events xhr.onload = callback(); xhr.onerror = callback(""error""); // Create the abort callback callback = xhrCallbacks[ id ] = callback(""abort""); try { // Do send the request (this may raise an exception) xhr.send( options.hasContent && options.data || null ); } catch ( e ) { // #14683: Only rethrow if this hasn't been notified as an error yet if ( callback ) { throw e; }, abort: function() { if ( callback ) { callback(); };}); // Handle cache's special case and crossDomainjQuery.ajaxTransport( ""script"", function( s ) { var script, callback; send: function( _, complete ) { script = jQuery(""<script>"").prop({ async: true, charset: s.scriptCharset, src: s.url }).on( ""load error"", callback = function( evt ) { script.remove(); callback = null; if ( evt ) { complete( evt.type === ""error"" ? 404 : 200, evt.type ); ); document.head.appendChild( script[ 0 ] ); if ( callback ) { callback(); var callback = oldCallbacks.pop() || ( jQuery.expando + ""_"" + ( nonce++ ) ); s.url += ( rquery.test( s.url ) ? ""&"" : ""?"" ) + s.jsonp + ""="" + callbackName;// data: string of html // context (optional): If specified, the fragment will be created in this context, defaults to document // keepScripts (optional): If true, will include scripts passed in the html string jQuery.parseHTML = function( data, context, keepScripts ) { if ( !data || typeof data !== ""string"" ) { return null; if ( typeof context === ""boolean"" ) { keepScripts = context; context = false; } context = context || document; var parsed = rsingleTag.exec( data ), scripts = !keepScripts && []; // Single tag if ( parsed ) { return [ context.createElement( parsed[1] ) ]; parsed = jQuery.buildFragment( [ data ], context, scripts ); if ( scripts && scripts.length ) { jQuery( scripts ).remove(); return jQuery.merge( [], parsed.childNodes ); };// Keep a copy of the old load method var _load = jQuery.fn.load;/** * Load a url into a page */ jQuery.fn.load = function( url, params, callback ) { if ( typeof url !== ""string"" && _load ) { return _load.apply( this, arguments ); var selector, type, response, self = this, off = url.indexOf("" ""); if ( off >= 0 ) { selector = jQuery.trim( url.slice( off ) ); url = url.slice( 0, off ); // If it's a function if ( jQuery.isFunction( params ) ) { // We assume that it's the callback callback = params; params = undefined; // Otherwise, build a param string } else if ( params && typeof params === ""object"" ) { type = ""POST""; } // If we have elements to modify, make the request if ( self.length > 0 ) { jQuery.ajax({ url: url, // if ""type"" variable is undefined, then ""GET"" method will be used type: type, dataType: ""html"", data: params }).done(function( responseText ) { // Save response for use in complete callback response = arguments; self.html( selector ? // If a selector was specified, locate the right elements in a dummy div // Exclude scripts to avoid IE 'Permission Denied' errors jQuery(""<div>"").append( jQuery.parseHTML( responseText ) ).find( selector ) : // Otherwise use the full result responseText ); }).complete( callback && function( jqXHR, status ) { self.each( callback, response || [ jqXHR.responseText, status, jqXHR ] ); return this; };jQuery.expr.filters.animated = function( elem ) { return jQuery.grep(jQuery.timers, function( fn ) { return elem === fn.elem; }).length; }; var docElem = window.document.documentElement; /** * Gets a window from an element */ function getWindow( elem ) { return jQuery.isWindow( elem ) ? elem : elem.nodeType === 9 && elem.defaultView; var curPosition, curLeft, curCSSTop, curTop, curOffset, curCSSLeft, calculatePosition, position = jQuery.css( elem, ""position"" ), curElem = jQuery( elem ), props = {}; // Set position first, in-case top/left are set even on static elem curOffset = curElem.offset(); curCSSTop = jQuery.css( elem, ""top"" ); curCSSLeft = jQuery.css( elem, ""left"" ); calculatePosition = ( position === ""absolute"" || position === ""fixed"" ) && ( curCSSTop + curCSSLeft ).indexOf(""auto"") > -1; // Need to be able to calculate position if either top or left is auto and position is either absolute or fixed offset: function( options ) { if ( arguments.length ) { return options === undefined ? this : this.each(function( i ) { jQuery.offset.setOffset( this, options, i ); }); } var docElem, win, elem = this[ 0 ], box = { top: 0, left: 0 }, doc = elem && elem.ownerDocument; if ( !doc ) { return; } docElem = doc.documentElement; // Make sure it's not a disconnected DOM node if ( !jQuery.contains( docElem, elem ) ) { return box; } // If we don't have gBCR, just use 0,0 rather than error // BlackBerry 5, iOS 3 (original iPhone) if ( typeof elem.getBoundingClientRect !== strundefined ) { box = elem.getBoundingClientRect(); } win = getWindow( doc ); return { top: box.top + win.pageYOffset - docElem.clientTop, left: box.left + win.pageXOffset - docElem.clientLeft }; }, elem = this[ 0 ], parentOffset = { top: 0, left: 0 }; // Fixed elements are offset from window (parentOffset = {top:0, left: 0}, because it is its only offset parent // We assume that getBoundingClientRect is available when computed position is fixed parentOffset.top += jQuery.css( offsetParent[ 0 ], ""borderTopWidth"", true ); top: offset.top - parentOffset.top - jQuery.css( elem, ""marginTop"", true ), left: offset.left - parentOffset.left - jQuery.css( elem, ""marginLeft"", true ) while ( offsetParent && ( !jQuery.nodeName( offsetParent, ""html"" ) && jQuery.css( offsetParent, ""position"" ) === ""static"" ) ) {jQuery.each( { scrollLeft: ""pageXOffset"", scrollTop: ""pageYOffset"" }, function( method, prop ) { var top = ""pageYOffset"" === prop; return access( this, function( elem, method, val ) { return win ? win[ prop ] : elem[ method ]; !top ? val : window.pageXOffset, top ? val : window.pageYOffset// Add the top/left cssHooks using jQuery.fn.position // Webkit bug: https://bugs.webkit.org/show_bug.cgi?id=29084 // getComputedStyle returns percent when specified for top/left/bottom/right // rather than make the css module depend on the offset module, we just check for it here jQuery.each( [ ""top"", ""left"" ], function( i, prop ) { jQuery.cssHooks[ prop ] = addGetHookIf( support.pixelPosition, function( elem, computed ) { if ( computed ) { computed = curCSS( elem, prop ); // if curCSS returns percentage, fallback to offset return rnumnonpx.test( computed ) ? jQuery( elem ).position()[ prop ] + ""px"" : computed; } } ); }); return access( this, function( elem, type, value ) { // Either scroll[Width/Height] or offset[Width/Height] or client[Width/Height], // whichever is greatest // Register as a named AMD module, since jQuery can be concatenated with other // files that may use define, but not via a proper concatenation script that // understands anonymous AMD modules. A named AMD is safest and most robust // way to register. Lowercase jquery is used because AMD module names are // derived from file names, and jQuery is normally delivered in a lowercase // file name. Do this after creating the global so that if an AMD module wants // to call noConflict to hide this version of jQuery, it will work. // Note that for maximum portability, libraries that are not jQuery should // declare themselves as anonymous modules, and avoid setting a global if an // AMD loader is present. jQuery is a special case. For more information, see // https://github.com/jrburke/requirejs/wiki/Updating-existing-libraries#wiki-anon if ( typeof define === ""function"" && define.amd ) { define( ""jquery"", [], function() { return jQuery; }); var // Map over jQuery in case of overwrite _jQuery = window.jQuery, // Map over the $ in case of overwrite _$ = window.$; jQuery.noConflict = function( deep ) { if ( window.$ === jQuery ) { window.$ = _$; } if ( deep && window.jQuery === jQuery ) { window.jQuery = _jQuery; } return jQuery; }; // Expose jQuery and $ identifiers, even in // AMD (#7102#comment:10, https://github.com/jquery/jquery/pull/557) // and CommonJS for browser emulators (#13566) if ( typeof noGlobal === strundefined ) { window.jQuery = window.$ = jQuery; } return jQuery; })); * @license AngularJS v1.3.7 * @param {function} ErrorConstructor Custom error constructor to be instantiated when returning * error from returned function, for cases when a particular type of error is useful.function minErr(module, ErrorConstructor) { ErrorConstructor = ErrorConstructor || Error; return function() { message = prefix + template.replace(/\{\d+\}/g, function(match) { return toDebugString(templateArgs[index + 2]); message = message + '\nhttp://errors.angularjs.org/1.3.7/' + message = message + (i == 2 ? '?' : '&') + 'p' + (i - 2) + '=' + encodeURIComponent(toDebugString(arguments[i])); return new ErrorConstructor(message);/* global angular: true, msie: true, jqLite: true, jQuery: true, slice: true, splice: true, push: true, toString: true, ngMinErr: true, angularModule: true, uid: true, REGEX_STRING_REGEXP: true, VALIDITY_STATE_PROPERTY: true, lowercase: true, uppercase: true, manualLowercase: true, manualUppercase: true, nodeName_: true, isArrayLike: true, forEach: true, sortedKeys: true, forEachSorted: true, reverseParams: true, nextUid: true, setHashKey: true, extend: true, int: true, inherit: true, noop: true, identity: true, valueFn: true, isUndefined: true, isDefined: true, isObject: true, isString: true, isNumber: true, isDate: true, isArray: true, isFunction: true, isRegExp: true, isWindow: true, isScope: true, isFile: true, isFormData: true, isBlob: true, isBoolean: true, isPromiseLike: true, trim: true, escapeForRegexp: true, isElement: true, makeMap: true, includes: true, arrayRemove: true, copy: true, shallowCopy: true, equals: true, csp: true, concat: true, sliceArgs: true, bind: true, toJsonReplacer: true, toJson: true, fromJson: true, startingTag: true, tryDecodeURIComponent: true, parseKeyValue: true, toKeyValue: true, encodeUriSegment: true, encodeUriQuery: true, angularInit: true, bootstrap: true, getTestability: true, snake_case: true, bindJQuery: true, assertArg: true, assertArgFn: true, assertNotHasOwnProperty: true, getter: true, getBlockNodes: true, hasOwnProperty: true, createMap: true, NODE_TYPE_ELEMENT: true, NODE_TYPE_TEXT: true, NODE_TYPE_COMMENT: true, NODE_TYPE_DOCUMENT: true, NODE_TYPE_DOCUMENT_FRAGMENT: true,var REGEX_STRING_REGEXP = /^\/(.+)\/([a-z]*)$/; // The name of a form control's ValidityState property. // This is used so that it's possible for internal tests to create mock ValidityStates. var VALIDITY_STATE_PROPERTY = 'validity'; * @kind functionvar lowercase = function(string) {return isString(string) ? string.toLowerCase() : string;}; * @kind functionvar uppercase = function(string) {return isString(string) ? string.toUpperCase() : string;};var msie, // holds major version number for IE, or NaN if UA is not IE. splice = [].splice, uid = 0; * documentMode is an IE-only property * http://msdn.microsoft.com/en-us/library/ie/cc196988(v=vs.85).aspxmsie = document.documentMode; if (obj.nodeType === NODE_TYPE_ELEMENT && length) { * @kind function * object or an array. The `iterator` function is invoked with `iterator(value, key, obj)`, where `value` * is the value of an object property or an array element, `key` is the object property key or * array element index and obj is the `obj` itself. Specifying a `context` for the function is optional. * Unlike ES262's * [Array.prototype.forEach](http://www.ecma-international.org/ecma-262/5.1/#sec-15.4.4.18), * Providing 'undefined' or 'null' values for `obj` will not throw a TypeError, but rather just * return the value provided. * angular.forEach(values, function(value, key) { var key, length; if (isFunction(obj)) { iterator.call(context, obj[key], key, obj); } } } else if (isArray(obj) || isArrayLike(obj)) { var isPrimitive = typeof obj !== 'object'; for (key = 0, length = obj.length; key < length; key++) { if (isPrimitive || key in obj) { iterator.call(context, obj[key], key, obj); obj.forEach(iterator, context, obj); iterator.call(context, obj[key], key, obj); return Object.keys(obj).sort(); for (var i = 0; i < keys.length; i++) { * A consistent way of creating unique IDs in angular. * Using simple numbers allows us to generate 28.6 million unique ids per second for 10 years before * we hit number precision issues in JavaScript. * * Math.pow(2,53) / 60 / 60 / 24 / 365 / 10 = 28.6M * * @returns {number} an unique alpha-numeric string return ++uid; * @kind function * Extends the destination object `dst` by copying own enumerable properties from the `src` object(s) * to `dst`. You can specify multiple `src` objects. If you want to preserve original objects, you can do so * by passing an empty object as the target: `var object = angular.extend({}, object1, object2)`. * Note: Keep in mind that `angular.extend` does not support recursive merge (deep copy). for (var i = 1, ii = arguments.length; i < ii; i++) { var obj = arguments[i]; if (obj) { var keys = Object.keys(obj); for (var j = 0, jj = keys.length; j < jj; j++) { var key = keys[j]; dst[key] = obj[key]; } } } setHashKey(dst, h); return extend(Object.create(parent), extra); * @kind function * @kind function * @kind functionfunction isUndefined(value) {return typeof value === 'undefined';} * @kind functionfunction isDefined(value) {return typeof value !== 'undefined';} * @kind functionfunction isObject(value) { // http://jsperf.com/isobject4 return value !== null && typeof value === 'object'; } * @kind functionfunction isString(value) {return typeof value === 'string';} * @kind functionfunction isNumber(value) {return typeof value === 'number';} * @kind functionfunction isDate(value) { * @kind functionvar isArray = Array.isArray; * @kind functionfunction isFunction(value) {return typeof value === 'function';} return obj && obj.window === obj;function isFormData(obj) { return toString.call(obj) === '[object FormData]'; } function isPromiseLike(obj) { return obj && isFunction(obj.then); } var trim = function(value) { return isString(value) ? value.trim() : value; }; // Copied from: // http://docs.closure-library.googlecode.com/git/local_closure_goog_string_string.js.source.html#line1021 // Prereq: s is a string. var escapeForRegexp = function(s) { return s.replace(/([-()\[\]{}+?*.$\^|,:#<!\\])/g, '\\$1'). replace(/\x08/g, '\\x08'); }; * @kind functionfunction makeMap(str) { for (i = 0; i < items.length; i++)function nodeName_(element) { return lowercase(element.nodeName || (element[0] && element[0].nodeName)); return Array.prototype.indexOf.call(array, obj) != -1; var index = array.indexOf(value); if (index >= 0) * @kind function <example module=""copyExample""> <div ng-controller=""ExampleController""> angular.module('copyExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.master= {}; $scope.update = function(user) { // Example with 1 argument $scope.master= angular.copy(user); }; $scope.reset = function() { // Example with 2 arguments angular.copy($scope.master, $scope.user); }; $scope.reset(); }]);function copy(source, destination, stackSource, stackDest) { destination = copy(source, [], stackSource, stackDest); destination = new RegExp(source.source, source.toString().match(/[^\/]*$/)[0]); destination.lastIndex = source.lastIndex; var emptyObject = Object.create(Object.getPrototypeOf(source)); destination = copy(source, emptyObject, stackSource, stackDest); stackSource = stackSource || []; stackDest = stackDest || []; if (isObject(source)) { var index = stackSource.indexOf(source); if (index !== -1) return stackDest[index]; stackSource.push(source); stackDest.push(destination); } var result; for (var i = 0; i < source.length; i++) { result = copy(source[i], null, stackSource, stackDest); if (isObject(source[i])) { stackSource.push(source[i]); stackDest.push(result); } destination.push(result); if (isArray(destination)) { destination.length = 0; } else { forEach(destination, function(value, key) { delete destination[key]; }); } for (var key in source) { if (source.hasOwnProperty(key)) { result = copy(source[key], null, stackSource, stackDest); if (isObject(source[key])) { stackSource.push(source[key]); stackDest.push(result); } destination[key] = result; } * Creates a shallow copy of an object, an array or a primitive. * * Assumes that there are no proto properties for objects. if (isArray(src)) { dst = dst || []; for (var i = 0, ii = src.length; i < ii; i++) { dst[i] = src[i]; } } else if (isObject(src)) { dst = dst || {}; for (var key in src) { if (!(key.charAt(0) === '$' && key.charAt(1) === '$')) { dst[key] = src[key]; } return dst || src; * @kind function * * Both values represent the same regular expression (In JavaScript, for (key = 0; key < length; key++) { if (!isDate(o2)) return false; return equals(o1.getTime(), o2.getTime()); for (key in o1) { for (key in o2) {var csp = function() { if (isDefined(csp.isActive_)) return csp.isActive_; var active = !!(document.querySelector('[ng-csp]') || document.querySelector('[data-ng-csp]')); if (!active) { try { /* jshint -W031, -W054 */ new Function(''); /* jshint +W031, +W054 */ } catch (e) { active = true; } } return (csp.isActive_ = active); }; * @kind function ? fn.apply(self, concat(curryArgs, arguments, 0)) if (typeof key === 'string' && key.charAt(0) === '$' && key.charAt(1) === '$') { * @kind function * Serializes input into a JSON-formatted string. Properties with leading $$ characters will be * @param {boolean|number=} pretty If set to true, the JSON output will contain newlines and whitespace. * If set to an integer, the JSON output will contain that many spaces per indentation (the default is 2). if (!isNumber(pretty)) { pretty = pretty ? 2 : null; } return JSON.stringify(obj, toJsonReplacer, pretty); * @kind function } catch (e) {} return element[0].nodeType === NODE_TYPE_TEXT ? lowercase(elemHtml) : } catch (e) { } catch (e) { forEach((keyValue || """").split('&'), function(keyValue) { if (keyValue) { key_value = keyValue.replace(/\+/g,'%20').split('='); if (isDefined(key)) { if (!hasOwnProperty.call(obj, key)) { } else if (isArray(obj[key])) { replace(/%3B/gi, ';').var ngAttrPrefixes = ['ng-', 'data-ng-', 'ng:', 'x-ng-']; function getNgAttribute(element, ngAttr) { var attr, i, ii = ngAttrPrefixes.length; element = jqLite(element); for (i = 0; i < ii; ++i) { attr = ngAttrPrefixes[i] + ngAttr; if (isString(attr = element.attr(attr))) { return attr; } } return null; } * @param {boolean=} ngStrictDi if this attribute is present on the app element, the injector will be * created in ""strict-di"" mode. This means that the application will fail to invoke functions which * do not use explicit function annotation (and are thus unsuitable for minification), as described * in {@link guide/di the Dependency Injection guide}, and useful debugging info will assist in * tracking down the root of these bugs. * Using `ngStrictDi`, you would see something like this: * <example ng-app-included=""true""> <file name=""index.html""> <div ng-app=""ngAppStrictDemo"" ng-strict-di> <div ng-controller=""GoodController1""> I can add: {{a}} + {{b}} = {{ a+b }} <p>This renders because the controller does not fail to instantiate, by using explicit annotation style (see script.js for details) </p> </div> <div ng-controller=""GoodController2""> Name: <input ng-model=""name""><br /> Hello, {{name}}! <p>This renders because the controller does not fail to instantiate, by using explicit annotation style (see script.js for details) </p> </div> <div ng-controller=""BadController""> I can add: {{a}} + {{b}} = {{ a+b }} <p>The controller could not be instantiated, due to relying on automatic function annotations (which are disabled in strict mode). As such, the content of this section is not interpolated, and there should be an error in your web console. </p> </div> </div> </file> <file name=""script.js""> angular.module('ngAppStrictDemo', []) // BadController will fail to instantiate, due to relying on automatic function annotation, // rather than an explicit annotation .controller('BadController', function($scope) { $scope.a = 1; $scope.b = 2; }) // Unlike BadController, GoodController1 and GoodController2 will not fail to be instantiated, // due to using explicit annotations using the array style and $inject property, respectively. .controller('GoodController1', ['$scope', function($scope) { $scope.a = 1; $scope.b = 2; }]) .controller('GoodController2', GoodController2); function GoodController2($scope) { $scope.name = ""World""; } GoodController2.$inject = ['$scope']; </file> <file name=""style.css""> div[ng-controller] { margin-bottom: 1em; -webkit-border-radius: 4px; border-radius: 4px; border: 1px solid; padding: .5em; } div[ng-controller^=Good] { border-color: #d6e9c6; background-color: #dff0d8; color: #3c763d; } div[ng-controller^=Bad] { border-color: #ebccd1; background-color: #f2dede; color: #a94442; margin-bottom: 0; } </file> </example> var appElement, config = {}; // The element `element` has priority over any other element forEach(ngAttrPrefixes, function(prefix) { var name = prefix + 'app'; if (!appElement && element.hasAttribute && element.hasAttribute(name)) { appElement = element; module = element.getAttribute(name); forEach(ngAttrPrefixes, function(prefix) { var name = prefix + 'app'; var candidate; if (!appElement && (candidate = element.querySelector('[' + name.replace(':', '\\:') + ']'))) { appElement = candidate; module = candidate.getAttribute(name); config.strictDi = getNgAttribute(appElement, ""strict-di"") !== null; bootstrap(appElement, module ? [module] : [], config); * Note that Protractor based end-to-end tests cannot use this function to bootstrap manually. * each of the subsequent scripts. This prevents strange results in applications, where otherwise * ```html * <!doctype html> * <html> * <body> * <div ng-controller=""WelcomeController""> * {{greeting}} * <script src=""angular.js""></script> * <script> * var app = angular.module('demo', []) * .controller('WelcomeController', function($scope) { * $scope.greeting = 'Welcome!'; * }); * angular.bootstrap(document, ['demo']); * </script> * </body> * </html> * ``` * @param {Object=} config an object for defining configuration options for the application. The * following keys are supported: * * * `strictDi` - disable automatic function annotation for the application. This is meant to * assist in finding bugs which break minified code. Defaults to `false`. *function bootstrap(element, modules, config) { if (!isObject(config)) config = {}; var defaultConfig = { strictDi: false }; config = extend(defaultConfig, config); //Encode angle brackets to prevent input from being sanitized to empty string #8683 throw ngMinErr( 'btstrpd', ""App Already Bootstrapped with this Element '{0}'"", tag.replace(/</,'&lt;').replace(/>/,'&gt;')); if (config.debugInfoEnabled) { // Pushing so that this overrides `debugInfoEnabled` setting defined in user's `modules`. modules.push(['$compileProvider', function($compileProvider) { $compileProvider.debugInfoEnabled(true); }]); } var injector = createInjector(modules, config.strictDi); injector.invoke(['$rootScope', '$rootElement', '$compile', '$injector', function bootstrapApply(scope, element, compile, injector) { var NG_ENABLE_DEBUG_INFO = /^NG_ENABLE_DEBUG_INFO!/; if (window && NG_ENABLE_DEBUG_INFO.test(window.name)) { config.debugInfoEnabled = true; window.name = window.name.replace(NG_ENABLE_DEBUG_INFO, ''); } /** * @ngdoc function * @name angular.reloadWithDebugInfo * @module ng * @description * Use this function to reload the current application with debug information turned on. * This takes precedence over a call to `$compileProvider.debugInfoEnabled(false)`. * * See {@link ng.$compileProvider#debugInfoEnabled} for more. */ function reloadWithDebugInfo() { window.name = 'NG_ENABLE_DEBUG_INFO!' + window.name; window.location.reload(); } /** * @name angular.getTestability * @module ng * @description * Get the testability service for the instance of Angular on the given * element. * @param {DOMElement} element DOM element which is the root of angular application. */ function getTestability(rootElement) { var injector = angular.element(rootElement).injector(); if (!injector) { throw ngMinErr('test', 'no injector found for element argument to getTestability'); } return injector.get('$$testability'); } function snake_case(name, separator) {var bindJQueryFired = false; var skipDestroyOnNextJQueryCleanData; var originalCleanData; if (bindJQueryFired) { return; } // Use jQuery if it exists with proper functionality, otherwise default to us. // Angular 1.2+ requires jQuery 1.7+ for on()/off() support. // Angular 1.3+ technically requires at least jQuery 2.1+ but it may work with older // versions. It will not work for sure with jQuery <1.7, though. if (jQuery && jQuery.fn.on) { // All nodes removed from the DOM via various jQuery APIs like .remove() // are passed through jQuery.cleanData. Monkey-patch this method to fire // the $destroy event on all removed nodes. originalCleanData = jQuery.cleanData; jQuery.cleanData = function(elems) { var events; if (!skipDestroyOnNextJQueryCleanData) { for (var i = 0, elem; (elem = elems[i]) != null; i++) { events = jQuery._data(elem, ""events""); if (events && events.$destroy) { jQuery(elem).triggerHandler('$destroy'); } } } else { skipDestroyOnNextJQueryCleanData = false; } originalCleanData(elems); }; // Prevent double-proxying. bindJQueryFired = true; (arg && typeof arg === 'object' ? arg.constructor.name || 'Object' : typeof arg)); * @returns {jqLite} jqLite collection containing the nodesfunction getBlockNodes(nodes) { // TODO(perf): just check if all items in `nodes` are siblings and if they are return the original // collection, otherwise update the original collection. var node = nodes[0]; var endNode = nodes[nodes.length - 1]; var blockNodes = [node]; node = node.nextSibling; if (!node) break; blockNodes.push(node); } while (node !== endNode); return jqLite(blockNodes); /** * Creates a new object without a prototype. This object is useful for lookup without having to * guard against prototypically inherited properties via hasOwnProperty. * * Related micro-benchmarks: * - http://jsperf.com/object-create2 * - http://jsperf.com/proto-map-lookup/2 * - http://jsperf.com/for-in-vs-object-keys2 * * @returns {Object} */ function createMap() { return Object.create(null); } var NODE_TYPE_ELEMENT = 1; var NODE_TYPE_TEXT = 3; var NODE_TYPE_COMMENT = 8; var NODE_TYPE_DOCUMENT = 9; var NODE_TYPE_DOCUMENT_FRAGMENT = 11; * A module is a collection of services, directives, controllers, filters, and configuration information. * @param {!Array.<string>=} requires If specified then new module is being created. If * unspecified then the module is being retrieved for further configuration. * @param {Function=} configFn Optional configuration function for the module. Same as var configBlocks = []; /** @type {!Array.<Function>} */ var config = invokeLater('$injector', 'invoke', 'push', configBlocks); _configBlocks: configBlocks, * * * Name of the module. * See {@link ng.$animateProvider#register $animateProvider.register()} and * For more about how to configure services, see * {@link providers#provider-recipe Provider Recipe}. return moduleInstance; function invokeLater(provider, method, insertMethod, queue) { if (!queue) queue = invokeQueue; queue[insertMethod || 'push']([provider, method, arguments]);/* global: toDebugString: true */function serializeObject(obj) { var seen = []; return JSON.stringify(obj, function(key, val) { val = toJsonReplacer(key, val); if (isObject(val)) { if (seen.indexOf(val) >= 0) return '<<already seen>>'; seen.push(val); } return val; }); } function toDebugString(obj) { if (typeof obj === 'function') { return obj.toString().replace(/ \{[\s\S]*$/, ''); } else if (typeof obj === 'undefined') { return 'undefined'; } else if (typeof obj !== 'string') { return serializeObject(obj); } return obj; } /* global angularModule: true, version: true, $LocaleProvider, $CompileProvider, htmlAnchorDirective, inputDirective, inputDirective, formDirective, scriptDirective, selectDirective, styleDirective, optionDirective, ngBindDirective, ngBindHtmlDirective, ngBindTemplateDirective, ngClassDirective, ngClassEvenDirective, ngClassOddDirective, ngCspDirective, ngCloakDirective, ngControllerDirective, ngFormDirective, ngHideDirective, ngIfDirective, ngIncludeDirective, ngIncludeFillContentDirective, ngInitDirective, ngNonBindableDirective, ngPluralizeDirective, ngRepeatDirective, ngShowDirective, ngStyleDirective, ngSwitchDirective, ngSwitchWhenDirective, ngSwitchDefaultDirective, ngOptionsDirective, ngTranscludeDirective, ngModelDirective, ngListDirective, ngChangeDirective, patternDirective, patternDirective, requiredDirective, requiredDirective, minlengthDirective, minlengthDirective, maxlengthDirective, maxlengthDirective, ngValueDirective, ngModelOptionsDirective, ngAttributeAliasDirectives, ngEventDirectives, $AnchorScrollProvider, $AnimateProvider, $BrowserProvider, $CacheFactoryProvider, $ControllerProvider, $DocumentProvider, $ExceptionHandlerProvider, $FilterProvider, $InterpolateProvider, $IntervalProvider, $HttpProvider, $HttpBackendProvider, $LocationProvider, $LogProvider, $ParseProvider, $RootScopeProvider, $QProvider, $$QProvider, $$SanitizeUriProvider, $SceProvider, $SceDelegateProvider, $SnifferProvider, $TemplateCacheProvider, $TemplateRequestProvider, $$TestabilityProvider, $TimeoutProvider, $$RAFProvider, $$AsyncCallbackProvider, $WindowProvider, $$jqLiteProvider full: '1.3.7', // all of these placeholder strings will be replaced by grunt's minor: 3, dot: 7, codeName: 'leaky-obstruction'function publishExternalAPI(angular) { 'noop': noop, 'bind': bind, 'identity': identity, 'getTestability': getTestability, '$$csp': csp, 'reloadWithDebugInfo': reloadWithDebugInfo pattern: patternDirective, ngPattern: patternDirective, minlength: minlengthDirective, ngMinlength: minlengthDirective, maxlength: maxlengthDirective, ngMaxlength: maxlengthDirective, ngValue: ngValueDirective, ngModelOptions: ngModelOptionsDirective $$q: $$QProvider, $templateRequest: $TemplateRequestProvider, $$testability: $$TestabilityProvider, $$asyncCallback: $$AsyncCallbackProvider, $$jqLite: $$jqLiteProvider/* global JQLitePrototype: true, addEventListenerFn: true, removeEventListenerFn: true, BOOLEAN_ATTR: true, ALIASED_ATTR: true, * @kind function * - [`attr()`](http://api.jquery.com/attr/) - Does not support functions as parameters * - [`css()`](http://api.jquery.com/css/) - Only retrieves inline-styles, does not call `getComputedStyle()` * - [`detach()`](http://api.jquery.com/detach/) * element or its parent. Requires {@link guide/production#disabling-debug-data Debug Data} to * be enabled. * Requires {@link guide/production#disabling-debug-data Debug Data} to be enabled.JQLite.expando = 'ng339'; addEventListenerFn = function(element, type, fn) { element.addEventListener(type, fn, false); }, removeEventListenerFn = function(element, type, fn) { element.removeEventListener(type, fn, false); };JQLite._data = function(node) {var MOUSE_EVENT_MAP= { mouseleave: ""mouseout"", mouseenter: ""mouseover""};function jqLiteAcceptsData(node) { // The window object can accept data but has no nodeType // Otherwise we are only interested in elements (1) and documents (9) var nodeType = node.nodeType; return nodeType === NODE_TYPE_ELEMENT || !nodeType || nodeType === NODE_TYPE_DOCUMENT; } var tmp, tag, wrap, nodes = [], i; tmp = tmp || fragment.appendChild(context.createElement(""div"")); tmp.innerHTML = wrap[1] + html.replace(XHTML_TAG_REGEXP, ""<$1></$2>"") + wrap[2]; nodes = concat(nodes, tmp.childNodes); forEach(nodes, function(node) { fragment.appendChild(node); }); return fragment; if ((parsed = jqLiteBuildFragment(html, context))) { return parsed.childNodes; } return []; var argIsString; argIsString = true; if (argIsString && element.charAt(0) != '<') { if (argIsString) {function jqLiteDealoc(element, onlyDescendants) { if (!onlyDescendants) jqLiteRemoveData(element); if (element.querySelectorAll) { var descendants = element.querySelectorAll('*'); for (var i = 0, l = descendants.length; i < l; i++) { jqLiteRemoveData(descendants[i]); } var expandoStore = jqLiteExpandoStore(element); var events = expandoStore && expandoStore.events; var handle = expandoStore && expandoStore.handle; if (!type) { for (type in events) { if (type !== '$destroy') { removeEventListenerFn(element, type, handle); } } if (isDefined(fn)) { var listenerFns = events[type]; arrayRemove(listenerFns || [], fn); if (listenerFns && listenerFns.length > 0) { return; } removeEventListenerFn(element, type, handle); delete events[type]; var expandoId = element.ng339; var expandoStore = expandoId && jqCache[expandoId]; delete expandoStore.data[name]; if (expandoStore.events.$destroy) { expandoStore.handle({}, '$destroy'); } element.ng339 = undefined; // don't delete DOM expandos. IE and Chrome don't like itfunction jqLiteExpandoStore(element, createIfNecessary) { var expandoId = element.ng339, expandoStore = expandoId && jqCache[expandoId]; if (createIfNecessary && !expandoStore) { element.ng339 = expandoId = jqNextId(); expandoStore = jqCache[expandoId] = {events: {}, data: {}, handle: undefined}; return expandoStore; if (jqLiteAcceptsData(element)) { var isSimpleSetter = isDefined(value); var isSimpleGetter = !isSimpleSetter && key && !isObject(key); var massGetter = !key; var expandoStore = jqLiteExpandoStore(element, !isSimpleGetter); var data = expandoStore && expandoStore.data; if (isSimpleSetter) { // data('key', value) data[key] = value; if (massGetter) { // data() return data; } else { if (isSimpleGetter) { // data('key') // don't force creation of expandoStore if it doesn't exist yet return data && data[key]; } else { // mass-setter: data({key1: val1, key2: val2}) extend(data, key); } } indexOf("" "" + selector + "" "") > -1); // THIS CODE IS VERY HOT. Don't make changes without benchmarking. // if a Node (the most common case) if (elements.nodeType) { root[root.length++] = elements; } else { var length = elements.length; // if an Array or NodeList and not a Window if (typeof length === 'number' && elements.window !== elements) { if (length) { for (var i = 0; i < length; i++) { root[root.length++] = elements[i]; } } } else { root[root.length++] = elements; } return jqLiteInheritedData(element, '$' + (name || 'ngController') + 'Controller'); if (element.nodeType == NODE_TYPE_DOCUMENT) { element = element.documentElement; while (element) { if ((value = jqLite.data(element, names[i])) !== undefined) return value; element = element.parentNode || (element.nodeType === NODE_TYPE_DOCUMENT_FRAGMENT && element.host); jqLiteDealoc(element, true);function jqLiteRemove(element, keepData) { if (!keepData) jqLiteDealoc(element); var parent = element.parentNode; if (parent) parent.removeChild(element); } function jqLiteDocumentLoaded(action, win) { win = win || window; if (win.document.readyState === 'complete') { // Force the action to be run async for consistent behaviour // from the action's point of view // i.e. it will definitely not be in a $apply win.setTimeout(action); } else { // No need to unbind this handler as load is only ever called once jqLite(win).on('load', action); } } // check if document is already loaded if (document.readyState === 'complete') { forEach(this, function(e) { value.push('' + e);}); BOOLEAN_ELEMENTS[value] = true;var ALIASED_ATTR = { 'ngMinlength': 'minlength', 'ngMaxlength': 'maxlength', 'ngMin': 'min', 'ngMax': 'max', 'ngPattern': 'pattern' }; return booleanAttr && BOOLEAN_ELEMENTS[nodeName_(element)] && booleanAttr;function getAliasedAttrName(element, name) { var nodeName = element.nodeName; return (nodeName === 'INPUT' || nodeName === 'TEXTAREA') && ALIASED_ATTR[name]; } forEach({ data: jqLiteData, removeData: jqLiteRemoveData }, function(fn, name) { JQLite[name] = fn; }); return jqLite.data(element, '$scope') || jqLiteInheritedData(element.parentNode || element, ['$isolateScope', '$scope']); return jqLite.data(element, '$isolateScope') || jqLite.data(element, '$isolateScopeNoTemplate'); removeAttr: function(element, name) { return element.style[name]; attr: function(element, name, value) { (element.attributes.getNamedItem(name) || noop).specified) var nodeType = element.nodeType; return (nodeType === NODE_TYPE_ELEMENT || nodeType === NODE_TYPE_TEXT) ? element.textContent : ''; element.textContent = value; if (element.multiple && nodeName_(element) === 'select') { forEach(element.options, function(option) { jqLiteDealoc(element, true);}, function(fn, name) { var nodeCount = this.length; for (i = 0; i < nodeCount; i++) { // TODO: do we still need this? var jj = (value === undefined) ? Math.min(nodeCount, 1) : nodeCount; for (i = 0; i < nodeCount; i++) { var eventHandler = function(event, type) { // jQuery specific api return event.defaultPrevented; }; var eventFns = events[type || event.type]; var eventFnsLength = eventFns ? eventFns.length : 0; if (!eventFnsLength) return; if (isUndefined(event.immediatePropagationStopped)) { var originalStopImmediatePropagation = event.stopImmediatePropagation; event.stopImmediatePropagation = function() { event.immediatePropagationStopped = true; if (event.stopPropagation) { event.stopPropagation(); } if (originalStopImmediatePropagation) { originalStopImmediatePropagation.call(event); } }; } event.isImmediatePropagationStopped = function() { return event.immediatePropagationStopped === true; if ((eventFnsLength > 1)) { eventFns = shallowCopy(eventFns); } for (var i = 0; i < eventFnsLength; i++) { if (!event.isImmediatePropagationStopped()) { eventFns[i].call(element, event); } // TODO: this is a hack for angularMocks/clearDataCache that makes it possible to deregister all // events on `element` on: function jqLiteOn(element, type, fn, unsupported) { // Do not add event handlers to non-elements because they will not be cleaned up. if (!jqLiteAcceptsData(element)) { return; } var expandoStore = jqLiteExpandoStore(element, true); var events = expandoStore.events; var handle = expandoStore.handle; if (!handle) { handle = expandoStore.handle = createEventHandler(element, events); } // http://jsperf.com/string-indexof-vs-split var types = type.indexOf(' ') >= 0 ? type.split(' ') : [type]; var i = types.length; while (i--) { type = types[i]; events[type] = []; if (type === 'mouseenter' || type === 'mouseleave') { jqLiteOn(element, MOUSE_EVENT_MAP[type], function(event) { if (!related || (related !== target && !target.contains(related))) { if (type !== '$destroy') { addEventListenerFn(element, type, handle); } } forEach(new JQLite(replaceNode), function(node) { forEach(element.childNodes, function(element) { if (element.nodeType === NODE_TYPE_ELEMENT) var nodeType = element.nodeType; if (nodeType !== NODE_TYPE_ELEMENT && nodeType !== NODE_TYPE_DOCUMENT_FRAGMENT) return; node = new JQLite(node); for (var i = 0, ii = node.length; i < ii; i++) { var child = node[i]; element.appendChild(child); } if (element.nodeType === NODE_TYPE_ELEMENT) { forEach(new JQLite(node), function(child) { wrapNode = jqLite(wrapNode).eq(0).clone()[0]; remove: jqLiteRemove, detach: function(element) { jqLiteRemove(element, true); newElement = new JQLite(newElement); for (var i = 0, ii = newElement.length; i < ii; i++) { var node = newElement[i]; } forEach(selector.split(' '), function(className) { return parent && parent.nodeType !== NODE_TYPE_DOCUMENT_FRAGMENT ? parent : null; return element.nextElementSibling; triggerHandler: function(element, event, extraParameters) { var dummyEvent, eventFnsCopy, handlerArgs; var eventName = event.type || event; var expandoStore = jqLiteExpandoStore(element); var events = expandoStore && expandoStore.events; var eventFns = events && events[eventName]; if (eventFns) { // Create a dummy event to pass to the handlers dummyEvent = { preventDefault: function() { this.defaultPrevented = true; }, isDefaultPrevented: function() { return this.defaultPrevented === true; }, stopImmediatePropagation: function() { this.immediatePropagationStopped = true; }, isImmediatePropagationStopped: function() { return this.immediatePropagationStopped === true; }, stopPropagation: noop, type: eventName, target: element }; // If a custom event was provided then extend our dummy event with it if (event.type) { dummyEvent = extend(dummyEvent, event); } // Copy event handlers in case event handlers array is modified during execution. eventFnsCopy = shallowCopy(eventFns); handlerArgs = extraParameters ? [dummyEvent].concat(extraParameters) : [dummyEvent]; forEach(eventFnsCopy, function(fn) { if (!dummyEvent.isImmediatePropagationStopped()) { fn.apply(element, handlerArgs); } }); }}, function(fn, name) { for (var i = 0, ii = this.length; i < ii; i++) { // Provider for private $$jqLite service function $$jqLiteProvider() { this.$get = function $$jqLite() { return extend(JQLite, { hasClass: function(node, classes) { if (node.attr) node = node[0]; return jqLiteHasClass(node, classes); }, addClass: function(node, classes) { if (node.attr) node = node[0]; return jqLiteAddClass(node, classes); }, removeClass: function(node, classes) { if (node.attr) node = node[0]; return jqLiteRemoveClass(node, classes); } }); }; } function hashKey(obj, nextUidFn) { var key = obj && obj.$$hashKey; if (key) { if (typeof key === 'function') { return key; var objType = typeof obj; if (objType == 'function' || (objType == 'object' && obj !== null)) { key = obj.$$hashKey = objType + ':' + (nextUidFn || nextUid)(); } else { key = objType + ':' + obj; } return key;function HashMap(array, isolatedUid) { if (isolatedUid) { var uid = 0; this.nextUid = function() { return ++uid; }; } this[hashKey(key, this.nextUid)] = value; return this[hashKey(key, this.nextUid)]; var value = this[key = hashKey(key, this.nextUid)]; * @kind function * Creates an injector object that can be used for retrieving services as well as for * {@link angular.module}. The `ng` module must be explicitly added. * @param {boolean=} [strictDi=false] Whether the injector should be in strict mode, which * disallows argument name annotation inference. * @returns {injector} Injector object. See {@link auto.$injector $injector}. * $injector.invoke(function($rootScope, $compile, $document) { * application has been bootstrapped. You can do this using the extra `injector()` added function anonFn(fn) { // For anonymous functions, showing at the very least the function signature can help in // debugging. var fnText = fn.toString().replace(STRIP_COMMENTS, ''), args = fnText.match(FN_ARGS); if (args) { return 'function(' + (args[1] || '').replace(/[\s\r\n]+/, ' ') + ')'; } return 'fn'; } function annotate(fn, strictDi, name) { if (typeof fn === 'function') { if (strictDi) { if (!isString(name) || !name) { name = fn.name || anonFn(fn); } throw $injectorMinErr('strictdi', '{0} is not using explicit annotation and cannot be invoked in strict mode', name); } forEach(argDecl[1].split(FN_ARG_SPLIT), function(arg) { arg.replace(FN_ARG, function(all, underscore, name) { * expect($injector.invoke(function($injector) { * })).toBe($injector); * can then be parsed and the function arguments can be extracted. This method of discovering * annotations is disallowed when the injector is in strict mode. * *NOTE:* This does not work with minification, and obfuscation tools since these tools change the * argument names. * By adding an `$inject` property onto a function the injection parameters can be specified. * @param {string} caller An optional string to provide the origin of the function call for error messages. * Allows the user to query if the particular service exists. * @param {string} name Name of the service to query. * @returns {boolean} `true` if injector has given service. * Create a new instance of JS type. The method takes a constructor function, invokes the new * operator, and supplies all of the arguments to the constructor function as specified by the * You can disallow this method by using strict injection mode. * * @param {boolean=} [strictDi=false] Disallow argument name annotation inference. * * @ngdoc servicefunction createInjector(modulesToLoad, strictDi) { strictDi = (strictDi === true); loadedModules = new HashMap([], true), createInternalInjector(providerCache, function(serviceName, caller) { if (angular.isString(caller)) { path.push(caller); } createInternalInjector(instanceCache, function(serviceName, caller) { var provider = providerInjector.get(serviceName + providerSuffix, caller); return instanceInjector.invoke(provider.$get, provider, undefined, serviceName); function enforceReturnValue(name, factory) { return function enforcedReturnValue() { var result = instanceInjector.invoke(factory, this); if (isUndefined(result)) { throw $injectorMinErr('undef', ""Provider '{0}' must return a value from $get factory method."", name); } return result; }; } function factory(name, factoryFn, enforce) { return provider(name, { $get: enforce !== false ? enforceReturnValue(name, factoryFn) : factoryFn }); } function value(name, val) { return factory(name, valueFn(val), false); } function loadModules(modulesToLoad) { var runBlocks = [], moduleFn; function runInvokeQueue(queue) { var i, ii; for (i = 0, ii = queue.length; i < ii; i++) { var invokeArgs = queue[i], provider = providerInjector.get(invokeArgs[0]); provider[invokeArgs[1]].apply(provider, invokeArgs[2]); } } runInvokeQueue(moduleFn._invokeQueue); runInvokeQueue(moduleFn._configBlocks); function getService(serviceName, caller) { throw $injectorMinErr('cdep', 'Circular dependency found: {0}', serviceName + ' <- ' + path.join(' <- ')); return cache[serviceName] = factory(serviceName, caller); function invoke(fn, self, locals, serviceName) { if (typeof locals === 'string') { serviceName = locals; locals = null; } $inject = annotate(fn, strictDi, serviceName), for (i = 0, length = $inject.length; i < length; i++) { : getService(key, serviceName) if (isArray(fn)) { function instantiate(Type, locals, serviceName) { // Object creation: http://jsperf.com/create-constructor/2 var instance = Object.create((isArray(Type) ? Type[Type.length - 1] : Type).prototype); var returnedValue = invoke(Type, instance, locals, serviceName);createInjector.$$annotate = annotate; * @ngdoc provider * @name $anchorScrollProvider * Use `$anchorScrollProvider` to disable automatic scrolling whenever * {@link ng.$location#hash $location.hash()} changes. /** * @ngdoc method * @name $anchorScrollProvider#disableAutoScrolling * * @description * By default, {@link ng.$anchorScroll $anchorScroll()} will automatically detect changes to * {@link ng.$location#hash $location.hash()} and scroll to the element matching the new hash.<br /> * Use this method to disable automatic scrolling. * * If automatic scrolling is disabled, one must explicitly call * {@link ng.$anchorScroll $anchorScroll()} in order to scroll to the element related to the * current hash. */ /** * @ngdoc service * @name $anchorScroll * @kind function * @requires $window * @requires $location * @requires $rootScope * * @description * When called, it checks the current value of {@link ng.$location#hash $location.hash()} and * scrolls to the related element, according to the rules specified in the * [Html5 spec](http://dev.w3.org/html5/spec/Overview.html#the-indicated-part-of-the-document). * * It also watches the {@link ng.$location#hash $location.hash()} and automatically scrolls to * match any anchor whenever it changes. This can be disabled by calling * {@link ng.$anchorScrollProvider#disableAutoScrolling $anchorScrollProvider.disableAutoScrolling()}. * * Additionally, you can use its {@link ng.$anchorScroll#yOffset yOffset} property to specify a * vertical scroll-offset (either fixed or dynamic). * * @property {(number|function|jqLite)} yOffset * If set, specifies a vertical scroll-offset. This is often useful when there are fixed * positioned elements at the top of the page, such as navbars, headers etc. * * `yOffset` can be specified in various ways: * - **number**: A fixed number of pixels to be used as offset.<br /><br /> * - **function**: A getter function called everytime `$anchorScroll()` is executed. Must return * a number representing the offset (in pixels).<br /><br /> * - **jqLite**: A jqLite/jQuery element to be used for specifying the offset. The distance from * the top of the page to the element's bottom will be used as offset.<br /> * **Note**: The element will be taken into account only as long as its `position` is set to * `fixed`. This option is useful, when dealing with responsive navbars/headers that adjust * their height and/or positioning according to the viewport's size. * * <br /> * <div class=""alert alert-warning""> * In order for `yOffset` to work properly, scrolling should take place on the document's root and * not some child element. * </div> * * @example <example module=""anchorScrollExample""> <file name=""index.html""> <div id=""scrollArea"" ng-controller=""ScrollController""> <a ng-click=""gotoBottom()"">Go to bottom</a> <a id=""bottom""></a> You're at the bottom! </div> </file> <file name=""script.js""> angular.module('anchorScrollExample', []) .controller('ScrollController', ['$scope', '$location', '$anchorScroll', function ($scope, $location, $anchorScroll) { $scope.gotoBottom = function() { // set the location.hash to the id of // the element you wish to scroll to. $location.hash('bottom'); // call $anchorScroll() $anchorScroll(); }; }]); </file> <file name=""style.css""> #scrollArea { height: 280px; overflow: auto; } #bottom { display: block; margin-top: 2000px; } </file> </example> * * <hr /> * The example below illustrates the use of a vertical scroll-offset (specified as a fixed value). * See {@link ng.$anchorScroll#yOffset $anchorScroll.yOffset} for more details. * * @example <example module=""anchorScrollOffsetExample""> <file name=""index.html""> <div class=""fixed-header"" ng-controller=""headerCtrl""> <a href="""" ng-click=""gotoAnchor(x)"" ng-repeat=""x in [1,2,3,4,5]""> Go to anchor {{x}} </a> </div> <div id=""anchor{{x}}"" class=""anchor"" ng-repeat=""x in [1,2,3,4,5]""> Anchor {{x}} of 5 </div> </file> <file name=""script.js""> angular.module('anchorScrollOffsetExample', []) .run(['$anchorScroll', function($anchorScroll) { $anchorScroll.yOffset = 50; // always scroll by 50 extra pixels }]) .controller('headerCtrl', ['$anchorScroll', '$location', '$scope', function ($anchorScroll, $location, $scope) { $scope.gotoAnchor = function(x) { var newHash = 'anchor' + x; if ($location.hash() !== newHash) { // set the $location.hash to `newHash` and // $anchorScroll will automatically scroll to it $location.hash('anchor' + x); } else { // call $anchorScroll() explicitly, // since $location.hash hasn't changed $anchorScroll(); } }; } ]); </file> <file name=""style.css""> body { padding-top: 50px; } .anchor { border: 2px dashed DarkOrchid; padding: 10px 10px 200px 10px; } .fixed-header { background-color: rgba(0, 0, 0, 0.2); height: 50px; position: fixed; top: 0; left: 0; right: 0; } .fixed-header > a { display: inline-block; margin: 5px 15px; } </file> </example> */ // Helper function to get first anchor from a NodeList // (using `Array#some()` instead of `angular#forEach()` since it's more performant // and working in all supported browsers.) Array.prototype.some.call(list, function(element) { if (nodeName_(element) === 'a') { result = element; return true; } function getYOffset() { var offset = scroll.yOffset; if (isFunction(offset)) { offset = offset(); } else if (isElement(offset)) { var elem = offset[0]; var style = $window.getComputedStyle(elem); if (style.position !== 'fixed') { offset = 0; } else { offset = elem.getBoundingClientRect().bottom; } } else if (!isNumber(offset)) { offset = 0; } return offset; } function scrollTo(elem) { if (elem) { elem.scrollIntoView(); var offset = getYOffset(); if (offset) { // `offset` is the number of pixels we should scroll UP in order to align `elem` properly. // This is true ONLY if the call to `elem.scrollIntoView()` initially aligns `elem` at the // top of the viewport. // // IF the number of pixels from the top of `elem` to the end of the page's content is less // than the height of the viewport, then `elem.scrollIntoView()` will align the `elem` some // way down the page. // // This is often the case for elements near the bottom of the page. // // In such cases we do not need to scroll the whole `offset` up, just the difference between // the top of the element and the offset, which is enough to align the top of `elem` at the // desired position. var elemTop = elem.getBoundingClientRect().top; $window.scrollBy(0, elemTop - offset); } } else { $window.scrollTo(0, 0); } } if (!hash) scrollTo(null); else if ((elm = document.getElementById(hash))) scrollTo(elm); else if ((elm = getFirstAnchor(document.getElementsByName(hash)))) scrollTo(elm); else if (hash === 'top') scrollTo(null); function autoScrollWatchAction(newVal, oldVal) { // skip the initial scroll if $location.hash is empty if (newVal === oldVal && newVal === '') return; jqLiteDocumentLoaded(function() { $rootScope.$evalAsync(scroll); }); if (arguments.length === 1) { this.$get = ['$$q', '$$asyncCallback', '$rootScope', function($$q, $$asyncCallback, $rootScope) { var currentDefer; function runAnimationPostDigest(fn) { var cancelFn, defer = $$q.defer(); defer.promise.$$cancelFn = function ngAnimateMaybeCancel() { cancelFn && cancelFn(); }; $rootScope.$$postDigest(function ngAnimatePostDigest() { cancelFn = fn(function ngAnimateNotifyComplete() { defer.resolve(); }); }); return defer.promise; } function resolveElementClasses(element, classes) { var toAdd = [], toRemove = []; var hasClasses = createMap(); forEach((element.attr('class') || '').split(/\s+/), function(className) { hasClasses[className] = true; }); forEach(classes, function(status, className) { var hasClass = hasClasses[className]; // If the most recent class manipulation (via $animate) was to remove the class, and the // element currently has the class, the class is scheduled for removal. Otherwise, if // the most recent class manipulation (via $animate) was to add the class, and the // element does not currently have the class, the class is scheduled to be added. if (status === false && hasClass) { toRemove.push(className); } else if (status === true && !hasClass) { toAdd.push(className); } }); return (toAdd.length + toRemove.length) > 0 && [toAdd.length ? toAdd : null, toRemove.length ? toRemove : null]; } function cachedClassManipulation(cache, classes, op) { for (var i=0, ii = classes.length; i < ii; ++i) { var className = classes[i]; cache[className] = op; } } function asyncPromise() { // only serve one instance of a promise in order to save CPU cycles if (!currentDefer) { currentDefer = $$q.defer(); $$asyncCallback(function() { currentDefer.resolve(); currentDefer = null; }); } return currentDefer.promise; } function applyStyles(element, options) { if (angular.isObject(options)) { var styles = extend(options.from || {}, options.to || {}); element.css(styles); } animate: function(element, from, to) { applyStyles(element, { from: from, to: to }); return asyncPromise(); }, * @kind function * @description Inserts the element into the DOM either after the `after` element or * as the first child within the `parent` element. When the function is called a promise * is returned that will be resolved at a later time. * @param {object=} options an optional collection of styles that will be applied to the element. * @return {Promise} the animation callback promise enter: function(element, parent, after, options) { applyStyles(element, options); after ? after.after(element) : parent.prepend(element); return asyncPromise(); * @kind function * @description Removes the element from the DOM. When the function is called a promise * is returned that will be resolved at a later time. * @param {object=} options an optional collection of options that will be applied to the element. * @return {Promise} the animation callback promise leave: function(element, options) { return asyncPromise(); * @kind function * either after the `after` element or inside of the `parent` element. When the function * is called a promise is returned that will be resolved at a later time. * @param {object=} options an optional collection of options that will be applied to the element. * @return {Promise} the animation callback promise move: function(element, parent, after, options) { return this.enter(element, parent, after, options); * @kind function * @description Adds the provided className CSS class value to the provided element. * When the function is called a promise is returned that will be resolved at a later time. * @param {object=} options an optional collection of options that will be applied to the element. * @return {Promise} the animation callback promise addClass: function(element, className, options) { return this.setClass(element, className, [], options); }, $$addClassImmediately: function(element, className, options) { element = jqLite(element); className = !isString(className) ? (isArray(className) ? className.join(' ') : '') : className; forEach(element, function(element) { applyStyles(element, options); return asyncPromise(); * @kind function * When the function is called a promise is returned that will be resolved at a later time. * @param {object=} options an optional collection of options that will be applied to the element. * @return {Promise} the animation callback promise removeClass: function(element, className, options) { return this.setClass(element, [], className, options); }, $$removeClassImmediately: function(element, className, options) { element = jqLite(element); className = !isString(className) ? (isArray(className) ? className.join(' ') : '') : className; forEach(element, function(element) { applyStyles(element, options); return asyncPromise(); * @kind function * When the function is called a promise is returned that will be resolved at a later time. * @param {DOMElement} element the element which will have its CSS classes changed * @param {object=} options an optional collection of options that will be applied to the element. * @return {Promise} the animation callback promise setClass: function(element, add, remove, options) { var self = this; var STORAGE_KEY = '$$animateClasses'; var createdCache = false; element = jqLite(element); var cache = element.data(STORAGE_KEY); if (!cache) { cache = { classes: {}, options: options }; createdCache = true; } else if (options && cache.options) { cache.options = angular.extend(cache.options || {}, options); } var classes = cache.classes; add = isArray(add) ? add : add.split(' '); remove = isArray(remove) ? remove : remove.split(' '); cachedClassManipulation(classes, add, true); cachedClassManipulation(classes, remove, false); if (createdCache) { cache.promise = runAnimationPostDigest(function(done) { var cache = element.data(STORAGE_KEY); element.removeData(STORAGE_KEY); // in the event that the element is removed before postDigest // is run then the cache will be undefined and there will be // no need anymore to add or remove and of the element classes if (cache) { var classes = resolveElementClasses(element, cache.classes); if (classes) { self.$$setClassImmediately(element, classes[0], classes[1], cache.options); } } done(); }); element.data(STORAGE_KEY, cache); } return cache.promise; $$setClassImmediately: function(element, add, remove, options) { add && this.$$addClassImmediately(element, add); remove && this.$$removeClassImmediately(element, remove); applyStyles(element, options); return asyncPromise(); }, enabled: noop, cancel: noopfunction $$AsyncCallbackProvider() {/* global stripHash: true */ * @param {object} $log window.console or an object with the same interface. while (outstandingRequestCallbacks.length) { function getHash(url) { var index = url.indexOf('#'); return index === -1 ? '' : url.substr(index + 1); } forEach(pollFns, function(pollFn) { pollFn(); }); forEach(pollFns, function(pollFn) { pollFn(); }); var cachedState, lastHistoryState, lastBrowserUrl = location.href, reloadLocation = null; cacheState(); lastHistoryState = cachedState; * @param {boolean=} replace Should new url replace current history record? * @param {object=} state object to use with pushState/replaceState self.url = function(url, replace, state) { // In modern browsers `history.state` is `null` by default; treating it separately // from `undefined` would cause `$browser.url('/foo')` to change `history.state` // to undefined via `pushState`. Instead, let's change `undefined` to `null` here. if (isUndefined(state)) { state = null; } var sameState = lastHistoryState === state; // Don't change anything if previous and current URLs and states match. This also prevents // IE<10 from getting into redirect loop when in LocationHashbangInHtml5Url mode. // See https://github.com/angular/angular.js/commit/ffb2701 if (lastBrowserUrl === url && (!$sniffer.history || sameState)) { return self; } var sameBase = lastBrowserUrl && stripHash(lastBrowserUrl) === stripHash(url); lastHistoryState = state; // Don't use history API if only the hash changed // due to a bug in IE10/IE11 which leads // to not firing a `hashchange` nor `popstate` event // in some cases (see #9143). if ($sniffer.history && (!sameBase || !sameState)) { history[replace ? 'replaceState' : 'pushState'](state, '', url); cacheState(); // Do the assignment again so that those two variables are referentially identical. lastHistoryState = cachedState; if (!sameBase) { reloadLocation = url; } } else if (!sameBase) { } else { location.hash = getHash(url); // - reloadLocation is needed as browsers don't allow to read out // the new location.href if a reload happened. return reloadLocation || location.href.replace(/%27/g,""'""); /** * @name $browser#state * * @description * This method is a getter. * * Return history.state or null if history.state is undefined. * * @returns {object} state */ self.state = function() { return cachedState; }; function cacheStateAndFireUrlChange() { cacheState(); fireUrlChange(); } // This variable should be used *only* inside the cacheState function. var lastCachedState = null; function cacheState() { // This should be the only place in $browser where `history.state` is read. cachedState = window.history.state; cachedState = isUndefined(cachedState) ? null : cachedState; // Prevent callbacks fo fire twice if both hashchange & popstate were fired. if (equals(cachedState, lastCachedState)) { cachedState = lastCachedState; } lastCachedState = cachedState; } if (lastBrowserUrl === self.url() && lastHistoryState === cachedState) { return; } lastHistoryState = cachedState; listener(self.url(), cachedState); if ($sniffer.history) jqLite(window).on('popstate', cacheStateAndFireUrlChange); jqLite(window).on('hashchange', cacheStateAndFireUrlChange); /** * Checks whether the url has changed outside of Angular. * Needs to be exported to be able to check for changes that have been done in sync, * as hashchange/popstate events fire in async. */ self.$$checkUrlChange = fireUrlChange; function safeDecodeURIComponent(str) { try { return decodeURIComponent(str); } catch (e) { return str; } } rawDocument.cookie = encodeURIComponent(name) + ""=;path="" + cookiePath + cookieLength = (rawDocument.cookie = encodeURIComponent(name) + '=' + encodeURIComponent(value) + $log.warn(""Cookie '"" + name + ""' possibly not set or overflowed because it was too large ("" + name = safeDecodeURIComponent(cookie.substring(0, index)); lastCookies[name] = safeDecodeURIComponent(cookie.substring(index + 1));function $BrowserProvider() { function($window, $log, $sniffer, $document) { if ($scope.cache.get(key) === undefined) { $scope.keys.push(key); } $scope.cache.put(key, value === undefined ? null : value); * @kind function * @kind function * @kind function * @kind function * @kind function * @kind function * Get information about all the caches that have been created * the document, but it must be a descendent of the {@link ng.$rootElement $rootElement} (IE, * element with ng-app attribute), otherwise the template will be ignored. * @kind function * templateNamespace: 'html', * #### `multiElement` * When this property is set to true, the HTML compiler will collect DOM nodes between * nodes with the attributes `directive-name-start` and `directive-name-end`, and group them * together as the directive elements. It is recommended that this feature be used on directives * which are not strictly behavioural (such as {@link ngClick}), and which * do not manipulate or replace child nodes (such as {@link ngInclude}). * * as the order of execution on same `priority` is undefined). Note that expressions * and other directives used in the directive's template will also be excluded from execution. * can avoid this behavior using `=?` or `=?attr` in order to flag the property as optional. If * you want to shallow watch for changes (i.e. $watchCollection instead of $watch) you can use * `=*` or `=*attr` (`=*?` or `=*?attr` if the property is optional). * pass data from the isolated scope via an expression to the parent scope, this can be * #### `bindToController` * When an isolate scope is used for a component (see above), and `controllerAs` is used, `bindToController: true` will * allow a component to have its properties bound to the controller, rather than to scope. When the controller * is instantiated, the initial values of the isolate scope bindings are already available. * * `$transclude` - A transclude linking function pre-bound to the correct transclusion scope: * `function([scope], cloneLinkingFn, futureParentElement)`. * * `scope`: optional argument to override the scope. * * `cloneLinkingFn`: optional argument to create clones of the original transcluded content. * * `futureParentElement`: * * defines the parent to which the `cloneLinkingFn` will add the cloned elements. * * default: `$element.parent()` resp. `$element` for `transclude:'element'` resp. `transclude:true`. * * only needed for transcludes that are allowed to contain non html elements (e.g. SVG elements) * and when the `cloneLinkinFn` is passed, * as those elements need to created and cloned in a special way when they are defined outside their * usual containers (e.g. like `<svg>`). * * See also the `directive.templateNamespace` property. * * `^` - Locate the required controller by searching the element and its parents. Throw an error if not found. * * `^^` - Locate the required controller by searching the element's parents. Throw an error if not found. * * `?^` - Attempt to locate the required controller by searching the element and its parents or pass * `null` to the `link` fn if not found. * * `?^^` - Attempt to locate the required controller by searching the element's parents, or pass * `null` to the `link` fn if not found. * declaration style. If omitted, the defaults (elements and attributes) are used. * * `E` - Element name (default): `<my-directive></my-directive>` * #### `templateNamespace` * String representing the document type used by the markup in the template. * AngularJS needs this information as those elements need to be created and cloned * in a special way when they are defined outside their usual containers like `<svg>` and `<math>`. * * `html` - All root nodes in the template are HTML. Root nodes may also be * top-level elements such as `<svg>` or `<math>`. * * `svg` - The root nodes in the template are SVG elements (excluding `<math>`). * * `math` - The root nodes in the template are MathML elements (excluding `<svg>`). * * If no `templateNamespace` is specified, then the namespace is considered to be `html`. * * #### `template` * HTML markup that may: * * Replace the contents of the directive's element (default). * * Replace the directive's element itself (if `replace` is true - DEPRECATED). * * Wrap the contents of the directive's element (if `transclude` is true). * * Value may be: * * * A string. For example `<div red-on-hover>{{delete_str}}</div>`. * * A function which takes two arguments `tElement` and `tAttrs` (described in the `compile` * function api below) and returns a string value. * This is similar to `template` but the template is loaded from the specified URL, asynchronously. * * Because template loading is asynchronous the compiler will suspend compilation of directives on that element * for later when the template has been resolved. In the meantime it will continue to compile and link * sibling and parent elements as though this element had not contained any directives. * * The compiler does not suspend the entire compilation to wait for templates to be loaded because this * would result in the whole app ""stalling"" until all templates are loaded asynchronously - even in the * case when only one deeply nested directive has `templateUrl`. * * Template loading is asynchronous even if the template has been preloaded into the {@link $templateCache} * $sce#getTrustedResourceUrl $sce.getTrustedResourceUrl}. * #### `replace` ([*DEPRECATED*!], will be removed in next major release - i.e. v2.0) * specify what the template should replace. Defaults to `false`. * * `true` - the template will replace the directive's element. * * `false` - the template will replace the contents of the directive's element. * The replacement process migrates all of the attributes / classes from the old element to the new * one. See the {@link guide/directive#template-expanding-directive * Directives Guide} for an example. * * There are very few scenarios where element replacement is required for the application function, * the main one being reusable custom components that are used within SVG contexts * (because SVG doesn't work with custom elements in the DOM tree). * Extract the contents of the element where the directive appears and make it available to the directive. * The contents are compiled and provided to the directive as a **transclusion function**. See the * {@link $compile#transclusion Transclusion} section below. * There are two kinds of transclusion depending upon whether you want to transclude just the contents of the * directive's element or the entire element: * * * `true` - transclude the content (i.e. the child nodes) of the directive's element. * * `'element'` - transclude the whole of the directive's element including any directives on this * element that defined at a lower priority than this directive. When used, the `template` * property is ignored. * template transformation, it is not used often. The compile function takes the following arguments: * This is the same as the `$transclude` * parameter of directive controllers, see there for details. * `function([scope], cloneLinkingFn, futureParentElement)`. * Executed after the child elements are linked. * Note that child elements that contain `templateUrl` directives will not have been compiled * and linked since they are waiting for their template to load asynchronously and their own * compilation and linking has been suspended until that occurs. * * It is safe to do DOM transformation in the post-linking function on elements that are not waiting * for their async templates to be resolved. * * * ### Transclusion * * Transclusion is the process of extracting a collection of DOM element from one part of the DOM and * copying them to another part of the DOM, while maintaining their connection to the original AngularJS * scope from where they were taken. * * Transclusion is used (often with {@link ngTransclude}) to insert the * original contents of a directive's element into a specified place in the template of the directive. * The benefit of transclusion, over simply moving the DOM elements manually, is that the transcluded * content has access to the properties on the scope from which it was taken, even if the directive * has isolated scope. * See the {@link guide/directive#creating-a-directive-that-wraps-other-elements Directives Guide}. * * This makes it possible for the widget to have private state for its template, while the transcluded * content has access to its originating scope. * * <div class=""alert alert-warning""> * **Note:** When testing an element transclude directive you must not place the directive at the root of the * DOM fragment that is being compiled. See {@link guide/unit-testing#testing-transclusion-directives * Testing Transclusion Directives}. * </div> * * #### Transclusion Functions * * When a directive requests transclusion, the compiler extracts its contents and provides a **transclusion * function** to the directive's `link` function and `controller`. This transclusion function is a special * **linking function** that will return the compiled contents linked to a new transclusion scope. * * <div class=""alert alert-info""> * If you are just using {@link ngTransclude} then you don't need to worry about this function, since * ngTransclude will deal with it for us. * </div> * * If you want to manually control the insertion and removal of the transcluded content in your directive * then you must use this transclude function. When you call a transclude function it returns a a jqLite/JQuery * object that contains the compiled DOM, which is linked to the correct transclusion scope. * * When you call a transclusion function you can pass in a **clone attach function**. This function accepts * two parameters, `function(clone, scope) { ... }`, where the `clone` is a fresh compiled copy of your transcluded * content and the `scope` is the newly created transclusion scope, to which the clone is bound. * * <div class=""alert alert-info""> * **Best Practice**: Always provide a `cloneFn` (clone attach function) when you call a translude function * since you then get a fresh clone of the original DOM and also have access to the new transclusion scope. * </div> * * It is normal practice to attach your transcluded content (`clone`) to the DOM inside your **clone * attach function**: * * ```js * var transcludedContent, transclusionScope; * * $transclude(function(clone, scope) { * element.append(clone); * transcludedContent = clone; * transclusionScope = scope; * }); * ``` * * Later, if you want to remove the transcluded content from your DOM then you should also destroy the * associated transclusion scope: * * ```js * transcludedContent.remove(); * transclusionScope.$destroy(); * ``` * * <div class=""alert alert-info""> * **Best Practice**: if you intend to add and remove transcluded content manually in your directive * (by calling the transclude function to get the DOM and and calling `element.remove()` to remove it), * then you are also responsible for calling `$destroy` on the transclusion scope. * </div> * * The built-in DOM manipulation directives, such as {@link ngIf}, {@link ngSwitch} and {@link ngRepeat} * automatically destroy their transluded clones as necessary so you do not need to worry about this if * you are simply using {@link ngTransclude} to inject the transclusion into your directive. * * * #### Transclusion Scopes * * When you call a transclude function it returns a DOM fragment that is pre-bound to a **transclusion * scope**. This scope is special, in that it is a child of the directive's scope (and so gets destroyed * when the directive's scope gets destroyed) but it inherits the properties of the scope from which it * was taken. * * For example consider a directive that uses transclusion and isolated scope. The DOM hierarchy might look * like this: * * ```html * <div ng-app> * <div isolate> * <div transclusion> * </div> * </div> * </div> * ``` * * The `$parent` scope hierarchy will look like this: * * ``` * - $rootScope * - isolate * - transclusion * ``` * * but the scopes will inherit prototypically from different scopes to their `$parent`. * * ``` * - $rootScope * - transclusion * - isolate * ``` * * * ## Example <example module=""compileExample""> angular.module('compileExample', [], function($compileProvider) { }); }) .controller('GreeterController', ['$scope', function($scope) { }]); <div ng-controller=""GreeterController""> * @param {function(angular.Scope, cloneAttachFn=)} transclude function available to directives - DEPRECATED. * * <div class=""alert alert-error""> * **Note:** Passing a `transclude` function to the $compile function is deprecated, as it * e.g. will not use the right outer scope. Please pass the transclude function as a * `parentBoundTranscludeFn` to the link function instead. * </div> * * @returns {function(scope, cloneAttachFn=, options=)} a link function which is used to bind template * * `options` - An optional object hash with linking options. If `options` is provided, then the following * keys may be used to control linking behavior: * * * `parentBoundTranscludeFn` - the transclude function made available to * directives; if given, it will be passed through to the link functions of * directives found in `element` during compilation. * * `transcludeControllers` - an object hash with keys that map controller names * to controller instances; if given, it will make the controllers * available to directives. * * `futureParentElement` - defines the parent to which the `cloneAttachFn` will add * the cloned elements; only needed for transcludes that are allowed to contain non html * elements (e.g. SVG elements). See also the directive.controller property. * COMMENT_DIRECTIVE_REGEXP = /^\s*directive\:\s*([\w\-]+)\s+(.*)$/, CLASS_DIRECTIVE_REGEXP = /(([\w\-]+)(?:\:([^;]+))?;?)/, ALL_OR_NOTHING_ATTRS = makeMap('ngSrc,ngSrcset,src,srcset'), REQUIRE_PREFIX_REGEXP = /^(?:(\^\^?)?(\?)?(\^\^?)?)?/; function parseIsolateBindings(scope, directiveName) { var LOCAL_REGEXP = /^\s*([@&]|=(\*?))(\??)\s*(\w*)\s*$/; var bindings = {}; forEach(scope, function(definition, scopeName) { var match = definition.match(LOCAL_REGEXP); if (!match) { throw $compileMinErr('iscp', ""Invalid isolate scope definition for directive '{0}'."" + "" Definition: {... {1}: '{2}' ...}"", directiveName, scopeName, definition); } bindings[scopeName] = { mode: match[1][0], collection: match[2] === '*', optional: match[3] === '?', attrName: match[4] || scopeName }; }); return bindings; } * @kind function directive.restrict = directive.restrict || 'EA'; if (isObject(directive.scope)) { directive.$$isolateBindings = parseIsolateBindings(directive.scope, directive.name); } * @kind function * The sanitization is a security measure aimed at preventing XSS attacks via html links. * @kind function /** * @ngdoc method * @name $compileProvider#debugInfoEnabled * * @param {boolean=} enabled update the debugInfoEnabled state if provided, otherwise just return the * current debugInfoEnabled state * @returns {*} current value if used as getter or itself (chaining) if used as setter * * @kind function * * @description * Call this method to enable/disable various debug runtime information in the compiler such as adding * binding information and a reference to the current scope on to DOM elements. * If enabled, the compiler will add the following to DOM elements that have been bound to the scope * * `ng-binding` CSS class * * `$binding` data property containing an array of the binding expressions * * You may want to disable this in production for a significant performance boost. See * {@link guide/production#disabling-debug-data Disabling Debug Data} for more. * * The default value is true. */ var debugInfoEnabled = true; this.debugInfoEnabled = function(enabled) { if (isDefined(enabled)) { debugInfoEnabled = enabled; return this; } return debugInfoEnabled; }; '$injector', '$interpolate', '$exceptionHandler', '$templateRequest', '$parse', function($injector, $interpolate, $exceptionHandler, $templateRequest, $parse, var Attributes = function(element, attributesToCopy) { if (attributesToCopy) { var keys = Object.keys(attributesToCopy); var i, l, key; for (i = 0, l = keys.length; i < l; i++) { key = keys[i]; this[key] = attributesToCopy[key]; } } else { this.$attr = {}; } /** * @ngdoc method * @name $compile.directive.Attributes#$normalize * @kind function * * @description * Converts an attribute name (e.g. dash/colon/underscore-delimited string, optionally prefixed with `x-` or * `data-`) to its normalized, camelCase form. * * Also there is special case for Moz prefix starting with upper case letter. * * For further information check out the guide on {@link guide/directive#matching-directives Matching Directives} * * @param {string} name Name to normalize */ * @kind function $addClass: function(classVal) { if (classVal && classVal.length > 0) { * @kind function $removeClass: function(classVal) { if (classVal && classVal.length > 0) { * @kind function $updateClass: function(newClasses, oldClasses) { if (toAdd && toAdd.length) { } var toRemove = tokenDifference(oldClasses, newClasses); if (toRemove && toRemove.length) { $animate.removeClass(this.$$element, toRemove); var node = this.$$element[0], booleanKey = getBooleanAttrName(node, key), aliasedKey = getAliasedAttrName(node, key), observer = key, } else if (aliasedKey) { this[aliasedKey] = value; observer = aliasedKey; if ((nodeName === 'a' && key === 'href') || (nodeName === 'img' && key === 'src')) { // sanitize a[href] and img[src] values } else if (nodeName === 'img' && key === 'srcset') { // sanitize img[srcset] values var result = """"; // first check if there are spaces because it's not the same pattern var trimmedSrcset = trim(value); // ( 999x ,| 999w ,| ,|, ) var srcPattern = /(\s+\d+x\s*,|\s+\d+w\s*,|\s+,|,\s+)/; var pattern = /\s/.test(trimmedSrcset) ? srcPattern : /(,)/; // split srcset into tuple of uri and descriptor except for the last item var rawUris = trimmedSrcset.split(pattern); // for each tuples var nbrUrisWith2parts = Math.floor(rawUris.length / 2); for (var i = 0; i < nbrUrisWith2parts; i++) { var innerIdx = i * 2; // sanitize the uri result += $$sanitizeUri(trim(rawUris[innerIdx]), true); // add the descriptor result += ("" "" + trim(rawUris[innerIdx + 1])); } // split the last item into uri and descriptor var lastTuple = trim(rawUris[i * 2]).split(/\s/); // sanitize the last uri result += $$sanitizeUri(trim(lastTuple[0]), true); // and add the last descriptor if any if (lastTuple.length === 2) { result += ("" "" + trim(lastTuple[1])); } this[key] = value = result; $$observers && forEach($$observers[observer], function(fn) { * @kind function * See the {@link guide/directive#text-and-attribute-bindings Directives} guide for more info. * @returns {function()} Returns a deregistration function for this observer. $$observers = (attrs.$$observers || (attrs.$$observers = createMap())), if (!listeners.$$inter && attrs.hasOwnProperty(key)) { return function() { arrayRemove(listeners, fn); }; function safeAddClass($element, className) { try { $element.addClass(className); } catch (e) { // ignore, since it means that we are trying to set class on // SVG element, where class name is read-only. } } compile.$$addBindingInfo = debugInfoEnabled ? function $$addBindingInfo($element, binding) { var bindings = $element.data('$binding') || []; if (isArray(binding)) { bindings = bindings.concat(binding); } else { bindings.push(binding); } $element.data('$binding', bindings); } : noop; compile.$$addBindingClass = debugInfoEnabled ? function $$addBindingClass($element) { safeAddClass($element, 'ng-binding'); } : noop; compile.$$addScopeInfo = debugInfoEnabled ? function $$addScopeInfo($element, scope, isolated, noTemplate) { var dataName = isolated ? (noTemplate ? '$isolateScopeNoTemplate' : '$isolateScope') : '$scope'; $element.data(dataName, scope); } : noop; compile.$$addScopeClass = debugInfoEnabled ? function $$addScopeClass($element, isolated) { safeAddClass($element, isolated ? 'ng-isolate-scope' : 'ng-scope'); } : noop; forEach($compileNodes, function(node, index) { if (node.nodeType == NODE_TYPE_TEXT && node.nodeValue.match(/\S+/) /* non-empty */ ) { $compileNodes[index] = jqLite(node).wrap('<span></span>').parent()[0]; compile.$$addScopeClass($compileNodes); var namespace = null; return function publicLinkFn(scope, cloneConnectFn, options) { options = options || {}; var parentBoundTranscludeFn = options.parentBoundTranscludeFn, transcludeControllers = options.transcludeControllers, futureParentElement = options.futureParentElement; // When `parentBoundTranscludeFn` is passed, it is a // `controllersBoundTransclude` function (it was previously passed // as `transclude` to directive.link) so we must unwrap it to get // its `boundTranscludeFn` if (parentBoundTranscludeFn && parentBoundTranscludeFn.$$boundTransclude) { parentBoundTranscludeFn = parentBoundTranscludeFn.$$boundTransclude; } if (!namespace) { namespace = detectNamespaceForChildElements(futureParentElement); } var $linkNode; if (namespace !== 'html') { // When using a directive with replace:true and templateUrl the $compileNodes // (or a child element inside of them) // might change, so we need to recreate the namespace adapted compileNodes // for call to the link function. // Note: This will already clone the nodes... $linkNode = jqLite( wrapTemplate(namespace, jqLite('<div>').append($compileNodes).html()) ); } else if (cloneConnectFn) { // important!!: we must call our jqLite.clone() since the jQuery one is trying to be smart // and sometimes changes the structure of the DOM. $linkNode = JQLitePrototype.clone.call($compileNodes); } else { $linkNode = $compileNodes; } if (transcludeControllers) { for (var controllerName in transcludeControllers) { $linkNode.data('$' + controllerName + 'Controller', transcludeControllers[controllerName].instance); compile.$$addScopeInfo($linkNode, scope); if (compositeLinkFn) compositeLinkFn(scope, $linkNode, $linkNode, parentBoundTranscludeFn); function detectNamespaceForChildElements(parentElement) { // TODO: Make this detect MathML as well... var node = parentElement && parentElement[0]; if (!node) { return 'html'; } else { return nodeName_(node) !== 'foreignobject' && node.toString().match(/SVG/) ? 'svg' : 'html'; attrs, directives, nodeLinkFn, childNodes, childLinkFn, linkFnFound, nodeLinkFnFound; compile.$$addScopeClass(attrs.$$element); nodeLinkFn ? ( (nodeLinkFn.transcludeOnThisElement || !nodeLinkFn.templateOnThisElement) && nodeLinkFn.transclude) : transcludeFn); if (nodeLinkFn || childLinkFn) { linkFns.push(i, nodeLinkFn, childLinkFn); linkFnFound = true; nodeLinkFnFound = nodeLinkFnFound || nodeLinkFn; } function compositeLinkFn(scope, nodeList, $rootElement, parentBoundTranscludeFn) { var nodeLinkFn, childLinkFn, node, childScope, i, ii, idx, childBoundTranscludeFn; var stableNodeList; if (nodeLinkFnFound) { // copy nodeList so that if a nodeLinkFn removes or adds an element at this DOM level our // offsets don't get screwed up var nodeListLength = nodeList.length; stableNodeList = new Array(nodeListLength); // create a sparse array by only copying the elements which have a linkFn for (i = 0; i < linkFns.length; i+=3) { idx = linkFns[i]; stableNodeList[idx] = nodeList[idx]; } } else { stableNodeList = nodeList; for (i = 0, ii = linkFns.length; i < ii;) { node = stableNodeList[linkFns[i++]]; compile.$$addScopeInfo(jqLite(node), childScope); if (nodeLinkFn.transcludeOnThisElement) { childBoundTranscludeFn = createBoundTranscludeFn( scope, nodeLinkFn.transclude, parentBoundTranscludeFn, nodeLinkFn.elementTranscludeOnThisElement); } else if (!nodeLinkFn.templateOnThisElement && parentBoundTranscludeFn) { childBoundTranscludeFn = parentBoundTranscludeFn; } else if (!parentBoundTranscludeFn && transcludeFn) { childBoundTranscludeFn = createBoundTranscludeFn(scope, transcludeFn); childBoundTranscludeFn = null; nodeLinkFn(childLinkFn, childScope, node, $rootElement, childBoundTranscludeFn); childLinkFn(scope, node.childNodes, undefined, parentBoundTranscludeFn); function createBoundTranscludeFn(scope, transcludeFn, previousBoundTranscludeFn, elementTransclusion) { var boundTranscludeFn = function(transcludedScope, cloneFn, controllers, futureParentElement, containingScope) { transcludedScope = scope.$new(false, containingScope); return transcludeFn(transcludedScope, cloneFn, { parentBoundTranscludeFn: previousBoundTranscludeFn, transcludeControllers: controllers, futureParentElement: futureParentElement }); return boundTranscludeFn; switch (nodeType) { case NODE_TYPE_ELEMENT: /* Element */ directiveNormalize(nodeName_(node)), 'E', maxPriority, ignoreDirective); for (var attr, name, nName, ngAttrName, value, isNgAttr, nAttrs = node.attributes, name = attr.name; value = trim(attr.value); // support ngAttr attribute binding ngAttrName = directiveNormalize(name); if (isNgAttr = NG_ATTR_BINDING.test(ngAttrName)) { name = name.replace(PREFIX_REGEXP, '') .substr(8).replace(/_(.)/g, function(match, letter) { return letter.toUpperCase(); }); } var directiveNName = ngAttrName.replace(/(Start|End)$/, ''); if (directiveIsMultiElement(directiveNName)) { nName = directiveNormalize(name.toLowerCase()); attrsMap[nName] = name; if (isNgAttr || !attrs.hasOwnProperty(nName)) { attrs[nName] = value; if (getBooleanAttrName(node, nName)) { attrs[nName] = true; // presence means true } } addAttrInterpolateDirective(node, directives, value, nName, isNgAttr); addDirective(directives, nName, 'A', maxPriority, ignoreDirective, attrStartName, attrEndName); case NODE_TYPE_TEXT: /* Text Node */ case NODE_TYPE_COMMENT: /* Comment */ if (node.nodeType == NODE_TYPE_ELEMENT) { controllers, hasTemplate = false, for (var i = 0, ii = directives.length; i < ii; i++) { // This directive is trying to add an isolated scope. // Check that there is no scope of any kind already assertNoDuplicate('new/isolated scope', newIsolateScopeDirective || newScopeDirective, directive, $compileNode); } else { // This directive is trying to add a child scope. // Check that there is no isolated scope already assertNoDuplicate('new/isolated scope', newIsolateScopeDirective, directive, $compileNode); newScopeDirective = newScopeDirective || directive; $template = $compileNode; replaceWith(jqCollection, sliceArgs($template), compileNode); hasTemplate = true; $template = removeComments(wrapTemplate(directive.templateNamespace, trim(directiveValue))); if ($template.length != 1 || compileNode.nodeType !== NODE_TYPE_ELEMENT) { hasTemplate = true; templateAttrs, jqCollection, hasTranscludeDirective && childTranscludeFn, preLinkFns, postLinkFns, { nodeLinkFn.transcludeOnThisElement = hasTranscludeDirective; nodeLinkFn.elementTranscludeOnThisElement = hasElementTranscludeDirective; nodeLinkFn.templateOnThisElement = hasTemplate; nodeLinkFn.transclude = childTranscludeFn; pre.directiveName = directiveName; post.directiveName = directiveName; function getControllers(directiveName, require, $element, elementControllers) { var $searchElement = $element; var match; match = require.match(REQUIRE_PREFIX_REGEXP); require = require.substring(match[0].length); if (match[3]) { if (match[1]) match[3] = null; else match[1] = match[3]; if (match[1] === '^') { retrievalMethod = 'inheritedData'; } else if (match[1] === '^^') { retrievalMethod = 'inheritedData'; $searchElement = $element.parent(); } if (match[2] === '?') { optional = true; } if (value = elementControllers[require]) { value = value.instance; } value = value || $searchElement[retrievalMethod]('$' + require + 'Controller'); return value || null; value.push(getControllers(directiveName, require, $element, elementControllers)); var i, ii, linkFn, controller, isolateScope, elementControllers, transcludeFn, $element, attrs; $element = templateAttrs.$$element; $element = jqLite(linkNode); attrs = new Attributes($element, templateAttrs); if (boundTranscludeFn) { // track `boundTranscludeFn` so it can be unwrapped if `transcludeFn` // is later passed as `parentBoundTranscludeFn` to `publicLinkFn` transcludeFn = controllersBoundTransclude; transcludeFn.$$boundTransclude = boundTranscludeFn; } // TODO: merge `controllers` and `elementControllers` into single object. controllers = {}; elementControllers = {}; controllerInstance = $controller(controller, locals, true, directive.controllerAs); $element.data('$' + directive.name + 'Controller', controllerInstance.instance); controllers[directive.name] = controllerInstance; if (newIsolateScopeDirective) { compile.$$addScopeInfo($element, isolateScope, true, !(templateDirective && (templateDirective === newIsolateScopeDirective || templateDirective === newIsolateScopeDirective.$$originalDirective))); compile.$$addScopeClass($element, true); var isolateScopeController = controllers && controllers[newIsolateScopeDirective.name]; var isolateBindingContext = isolateScope; if (isolateScopeController && isolateScopeController.identifier && newIsolateScopeDirective.bindToController === true) { isolateBindingContext = isolateScopeController.instance; forEach(isolateScope.$$isolateBindings = newIsolateScopeDirective.$$isolateBindings, function(definition, scopeName) { var attrName = definition.attrName, optional = definition.optional, mode = definition.mode, // @, =, or & lastValue, parentGet, parentSet, compare; switch (mode) { case '@': attrs.$observe(attrName, function(value) { isolateBindingContext[scopeName] = value; }); attrs.$$observers[attrName].$$scope = scope; if (attrs[attrName]) { // If the attribute has been provided then we trigger an interpolation to ensure // the value is there for use in the link fn isolateBindingContext[scopeName] = $interpolate(attrs[attrName])(scope); } break; case '=': if (optional && !attrs[attrName]) { return; } parentGet = $parse(attrs[attrName]); if (parentGet.literal) { compare = equals; } else { compare = function(a, b) { return a === b || (a !== a && b !== b); }; } parentSet = parentGet.assign || function() { // reset the change, or we will throw this exception on every $digest lastValue = isolateBindingContext[scopeName] = parentGet(scope); throw $compileMinErr('nonassign', ""Expression '{0}' used with directive '{1}' is non-assignable!"", attrs[attrName], newIsolateScopeDirective.name); }; lastValue = isolateBindingContext[scopeName] = parentGet(scope); var parentValueWatch = function parentValueWatch(parentValue) { if (!compare(parentValue, isolateBindingContext[scopeName])) { // we are out of sync and need to copy if (!compare(parentValue, lastValue)) { // parent changed and it has precedence isolateBindingContext[scopeName] = parentValue; } else { // if the parent can be assigned then do so parentSet(scope, parentValue = isolateBindingContext[scopeName]); } } return lastValue = parentValue; }; parentValueWatch.$stateful = true; var unwatch; if (definition.collection) { unwatch = scope.$watchCollection(attrs[attrName], parentValueWatch); } else { unwatch = scope.$watch($parse(attrs[attrName], parentValueWatch), null, parentGet.literal); } isolateScope.$on('$destroy', unwatch); break; case '&': parentGet = $parse(attrs[attrName]); isolateBindingContext[scopeName] = function(locals) { return parentGet(scope, locals); }; break; } }); } if (controllers) { forEach(controllers, function(controller) { controller(); }); controllers = null; } // PRELINKING for (i = 0, ii = preLinkFns.length; i < ii; i++) { linkFn = preLinkFns[i]; invokeLinkFn(linkFn, linkFn.isolateScope ? isolateScope : scope, $element, attrs, linkFn.require && getControllers(linkFn.directiveName, linkFn.require, $element, elementControllers), transcludeFn ); for (i = postLinkFns.length - 1; i >= 0; i--) { linkFn = postLinkFns[i]; invokeLinkFn(linkFn, linkFn.isolateScope ? isolateScope : scope, $element, attrs, linkFn.require && getControllers(linkFn.directiveName, linkFn.require, $element, elementControllers), transcludeFn ); // Note: all arguments are optional! function controllersBoundTransclude(scope, cloneAttachFn, futureParentElement) { // No scope passed in: if (!isScope(scope)) { futureParentElement = cloneAttachFn; if (!futureParentElement) { futureParentElement = hasElementTranscludeDirective ? $element.parent() : $element; } return boundTranscludeFn(scope, cloneAttachFn, transcludeControllers, futureParentElement, scopeToChild); for (var directive, directives = $injector.get(name + Suffix), i = 0, ii = directives.length; i < ii; i++) { if ((maxPriority === undefined || maxPriority > directive.priority) && } catch (e) { $exceptionHandler(e); } * looks up the directive and returns true if it is a multi-element directive, * and therefore requires DOM nodes between -start and -end markers to be grouped * together. * * @param {string} name name of the directive to look up. * @returns true if directive was registered as multi-element. */ function directiveIsMultiElement(name) { if (hasDirectives.hasOwnProperty(name)) { for (var directive, directives = $injector.get(name + Suffix), i = 0, ii = directives.length; i < ii; i++) { directive = directives[i]; if (directive.multiElement) { return true; } } } return false; } /** if (src[key] && src[key] !== value) { : origAsyncDirective.templateUrl, templateNamespace = origAsyncDirective.templateNamespace; $templateRequest($sce.getTrustedResourceUrl(templateUrl)) .then(function(content) { $template = removeComments(wrapTemplate(templateNamespace, trim(content))); if ($template.length != 1 || compileNode.nodeType !== NODE_TYPE_ELEMENT) { while (linkQueue.length) { if (scope.$$destroyed) continue; if (afterTemplateNodeLinkFn.transcludeOnThisElement) { childBoundTranscludeFn = createBoundTranscludeFn(scope, afterTemplateNodeLinkFn.transclude, boundTranscludeFn); var childBoundTranscludeFn = boundTranscludeFn; if (scope.$$destroyed) return; linkQueue.push(scope, node, rootElement, childBoundTranscludeFn); if (afterTemplateNodeLinkFn.transcludeOnThisElement) { childBoundTranscludeFn = createBoundTranscludeFn(scope, afterTemplateNodeLinkFn.transclude, boundTranscludeFn); } afterTemplateNodeLinkFn(afterTemplateChildLinkFn, scope, node, rootElement, childBoundTranscludeFn); compile: function textInterpolateCompileFn(templateNode) { var templateNodeParent = templateNode.parent(), hasCompileParent = !!templateNodeParent.length; // When transcluding a template that has bindings in the root // we don't have a parent and thus need to add the class during linking fn. if (hasCompileParent) compile.$$addBindingClass(templateNodeParent); return function textInterpolateLinkFn(scope, node) { var parent = node.parent(); if (!hasCompileParent) compile.$$addBindingClass(parent); compile.$$addBindingInfo(parent, interpolateFn.expressions); scope.$watch(interpolateFn, function interpolateFnWatchAction(value) { node[0].nodeValue = value; }); }; } function wrapTemplate(type, template) { type = lowercase(type || 'html'); switch (type) { case 'svg': case 'math': var wrapper = document.createElement('div'); wrapper.innerHTML = '<' + type + '>' + template + '</' + type + '>'; return wrapper.childNodes[0].childNodes; default: return template; } } (tag == ""form"" && attrNormalizedName == ""action"") || (tag != ""img"" && (attrNormalizedName == ""src"" || function addAttrInterpolateDirective(node, directives, value, name, allOrNothing) { var trustedContext = getTrustedContext(node, name); allOrNothing = ALL_OR_NOTHING_ATTRS[name] || allOrNothing; var interpolateFn = $interpolate(value, true, trustedContext, allOrNothing); if (name === ""multiple"" && nodeName_(node) === ""select"") { // If the attribute has changed since last $interpolate()ed var newValue = attr[name]; if (newValue !== value) { // we need to interpolate again since the attribute value has been updated // (e.g. by another directive's compile function) // ensure unset/empty values make interpolateFn falsy interpolateFn = newValue && $interpolate(newValue, true, trustedContext, allOrNothing); value = newValue; } // initialize attr object so that it's ready in case we need the value for isolate // scope initialization, otherwise the value would not be available from isolate // directive's linking fn during linking phase if (name === 'class' && newValue != oldValue) { for (i = 0, ii = $rootElement.length; i < ii; i++) { // If the replaced element is also the jQuery .context then replace it // .context is a deprecated jQuery api, so we should set it only when jQuery set it // http://api.jquery.com/context/ if ($rootElement.context === firstElementToRemove) { $rootElement.context = newNode; } // TODO(perf): what's this document fragment for? is it needed? can we at least reuse it? // Copy over user data (that includes Angular's $scope etc.). Don't copy private // data here because there's no public interface in jQuery to do that and copying over // event listeners (which is the main use of private data) wouldn't work anyway. jqLite(newNode).data(jqLite(firstElementToRemove).data()); // Remove data of the replaced element. We cannot just call .remove() // on the element it since that would deallocate scope that is needed // for the new node. Instead, remove the data ""manually"". if (!jQuery) { delete jqLite.cache[firstElementToRemove[jqLite.expando]]; } else { // jQuery 2.x doesn't expose the data storage. Use jQuery.cleanData to clean up after // the replaced element. The cleanData version monkey-patched by Angular would cause // the scope to be trashed and we do need the very same scope to work with the new // element. However, we cannot just cache the non-patched version and use it here as // that would break if another library patches the method after Angular does (one // example is jQuery UI). Instead, set a flag indicating scope destroying should be // skipped this one time. skipDestroyOnNextJQueryCleanData = true; jQuery.cleanData([firstElementToRemove]); } function invokeLinkFn(linkFn, scope, $element, attrs, controllers, transcludeFn) { try { linkFn(scope, $element, attrs, controllers, transcludeFn); } catch (e) { $exceptionHandler(e, startingTag($element)); } }var PREFIX_REGEXP = /^((?:x|data)[\:\-_])/i; * ``` * ``` * * @description * A map of DOM element attribute names to the normalized name. This is * needed to do reverse lookup from normalized name back to actual name. * @kind function) {}) {} for (var i = 0; i < tokens1.length; i++) { for (var j = 0; j < tokens2.length; j++) { if (token == tokens2[j]) continue outer;function removeComments(jqNodes) { jqNodes = jqLite(jqNodes); var i = jqNodes.length; if (i <= 1) { return jqNodes; } while (i--) { var node = jqNodes[i]; if (node.nodeType === NODE_TYPE_COMMENT) { splice.call(jqNodes, i, 1); } } return jqNodes; } globals = false, /** * @ngdoc method * @name $controllerProvider#allowGlobals * @description If called, allows `$controller` to find controller constructors on `window` */ this.allowGlobals = function() { globals = true; }; * * if $controllerProvider#allowGlobals, check `window[constructor]` on the global * `window` object (not recommended) * * The string can use the `controller as property` syntax, where the controller instance is published * as the specified property on the `scope`; the `scope` must be injected into `locals` param for this * to work correctly. return function(expression, locals, later, ident) { // PRIVATE API: // param `later` --- indicates that the controller's constructor is invoked at a later time. // If true, $controller will allocate the object with the correct // prototype chain, but will not invoke the controller until a returned // callback is invoked. // param `ident` --- An optional label which overrides the label parsed from the controller // expression, if any. later = later === true; if (ident && isString(ident)) { identifier = ident; } if (isString(expression)) { identifier = identifier || match[3]; : getter(locals.$scope, constructor, true) || (globals ? getter($window, constructor, true) : undefined); if (later) { // Instantiate controller later: // This machinery is used to create an instance of the object before calling the // controller's constructor itself. // // This allows properties to be added to the controller before the constructor is // invoked. Primarily, this is used for isolate scope bindings in $compile. // // This feature is not intended for use by applications, and is thus not documented // publicly. // Object creation: http://jsperf.com/create-constructor/2 var controllerPrototype = (isArray(expression) ? expression[expression.length - 1] : expression).prototype; instance = Object.create(controllerPrototype); if (identifier) { addIdentifier(locals, identifier, instance, constructor || expression.name); return extend(function() { $injector.invoke(expression, instance, locals, constructor); return instance; }, { instance: instance, identifier: identifier }); } instance = $injector.instantiate(expression, locals, constructor); if (identifier) { addIdentifier(locals, identifier, instance, constructor || expression.name); function addIdentifier(locals, identifier, instance, name) { if (!(locals && isObject(locals.$scope))) { throw minErr('$controller')('noscp', ""Cannot export controller '{0}' as '{1}'! No $scope object provided via `locals`."", name, identifier); } locals.$scope[identifier] = instance; } <example module=""documentExample""> <div ng-controller=""ExampleController""> angular.module('documentExample', []) .controller('ExampleController', ['$scope', '$document', function($scope, $document) { $scope.title = $document[0].title; $scope.windowTitle = angular.element(window.document)[0].title; }]);function $DocumentProvider() { this.$get = ['$window', function(window) { * angular.module('exceptionOverride', []).factory('$exceptionHandler', function() { * return function(exception, cause) { * <hr /> * Note, that code executed in event-listeners (even those registered using jqLite's `on`/`bind` * methods) does not delegate exceptions to the {@link ng.$exceptionHandler $exceptionHandler} * (unless executed during a digest). * * If you wish, you can manually delegate exceptions, e.g. * `try { ... } catch(e) { $exceptionHandler(e); }` *var APPLICATION_JSON = 'application/json'; var CONTENT_TYPE_APPLICATION_JSON = {'Content-Type': APPLICATION_JSON + ';charset=utf-8'}; var JSON_START = /^\[|^\{(?!\{)/; var JSON_ENDS = { '[': /]$/, '{': /}$/ }; var JSON_PROTECTION_PREFIX = /^\)\]\}',?\n/; function defaultHttpResponseTransform(data, headers) { if (isString(data)) { // Strip json vulnerability protection prefix and trim whitespace var tempData = data.replace(JSON_PROTECTION_PREFIX, '').trim(); if (tempData) { var contentType = headers('Content-Type'); if ((contentType && (contentType.indexOf(APPLICATION_JSON) === 0)) || isJsonLike(tempData)) { data = fromJson(tempData); } } } return data; } function isJsonLike(str) { var jsonStart = str.match(JSON_START); return jsonStart && JSON_ENDS[jsonStart[0]].test(str); } var parsed = createMap(), key, val, i; parsed[key] = parsed[key] ? parsed[key] + ', ' + val : val; var value = headersObj[lowercase(name)]; if (value === void 0) { value = null; } return value; * @param {function(string=)} headers HTTP headers getter fn. * @param {number} status HTTP status code of the response.function transformData(data, headers, status, fns) { return fns(data, headers, status); data = fn(data, headers, status);/** * @ngdoc provider * @name $httpProvider * @description * Use `$httpProvider` to change the default behavior of the {@link ng.$http $http} service. * */ /** * @ngdoc property * @name $httpProvider#defaults * @description * * Object containing default values for all {@link ng.$http $http} requests. * * - **`defaults.cache`** - {Object} - an object built with {@link ng.$cacheFactory `$cacheFactory`} * that will provide the cache for all requests who set their `cache` property to `true`. * If you set the `default.cache = false` then only requests that specify their own custom * cache object will be cached. See {@link $http#caching $http Caching} for more information. * * - **`defaults.xsrfCookieName`** - {string} - Name of cookie containing the XSRF token. * Defaults value is `'XSRF-TOKEN'`. * * - **`defaults.xsrfHeaderName`** - {string} - Name of HTTP header to populate with the * XSRF token. Defaults value is `'X-XSRF-TOKEN'`. * * - **`defaults.headers`** - {Object} - Default headers for all $http requests. * Refer to {@link ng.$http#setting-http-headers $http} for documentation on * setting default headers. * - **`defaults.headers.common`** * - **`defaults.headers.post`** * - **`defaults.headers.put`** * - **`defaults.headers.patch`** * **/ transformResponse: [defaultHttpResponseTransform], return isObject(d) && !isFile(d) && !isBlob(d) && !isFormData(d) ? toJson(d) : d; post: shallowCopy(CONTENT_TYPE_APPLICATION_JSON), put: shallowCopy(CONTENT_TYPE_APPLICATION_JSON), patch: shallowCopy(CONTENT_TYPE_APPLICATION_JSON) var useApplyAsync = false; * @ngdoc method * @name $httpProvider#useApplyAsync * @description * * Configure $http service to combine processing of multiple http responses received at around * the same time via {@link ng.$rootScope.Scope#$applyAsync $rootScope.$applyAsync}. This can result in * significant performance improvement for bigger applications that make many HTTP requests * concurrently (common during application bootstrap). * * Defaults to false. If no value is specifed, returns the current configured value. * * @param {boolean=} value If true, when requests are loaded, they will schedule a deferred * ""apply"" on the next tick, giving time for subsequent requests in a roughly ~10ms window * to load and share the same digest cycle. * * @returns {boolean|Object} If a value is specified, returns the $httpProvider for chaining. * otherwise, returns the current configured value. **/ this.useApplyAsync = function(value) { if (isDefined(value)) { useApplyAsync = !!value; return this; } return useApplyAsync; }; * @ngdoc property * @name $httpProvider#interceptors * @description * * Array containing service factories for all synchronous or asynchronous {@link ng.$http $http} * pre-processing of request or postprocessing of responses. * * These service factories are ordered by request, i.e. they are applied in the same order as the * array, on request, but reverse order, on response. * * {@link ng.$http#interceptors Interceptors detailed info} **/ var interceptorFactories = this.interceptors = []; * ## General usage * // Simple GET request example : * $http.get('/someUrl'). * ```js * // Simple POST request example (passing data) : * $http.post('/someUrl', {msg:'hello word!'}). * success(function(data, status, headers, config) { * // this callback will be called asynchronously * // when the response is available * }). * error(function(data, status, headers, config) { * // called asynchronously if an error occurs * // or server returns response with an error status. * }); * ``` * * * ## Writing Unit Tests that use $http * ## Shortcut methods * - {@link ng.$http#patch $http.patch} * ## Setting HTTP Headers * To explicitly remove a header automatically added via $httpProvider.defaults.headers on a per request basis, * Use the `headers` property, setting the desired header to `undefined`. For example: * ```js * var req = { * method: 'POST', * url: 'http://example.com', * headers: { * 'Content-Type': undefined * }, * data: { test: 'test' }, * } * $http(req).success(function(){...}).error(function(){...}); * ``` * ## Transforming Requests and Responses * * Both requests and responses can be transformed using transformation functions: `transformRequest` * and `transformResponse`. These properties can be a single function that returns * the transformed value (`{function(data, headersGetter, status)`) or an array of such transformation functions, * which allows you to `push` or `unshift` a new transformation function into the transformation chain. * * ### Default Transformations * * The `$httpProvider` provider and `$http` service expose `defaults.transformRequest` and * `defaults.transformResponse` properties. If a request does not provide its own transformations * then these will be applied. * * You can augment or replace the default transformations by modifying these properties by adding to or * replacing the array. * * Angular provides the following default transformations: * * Request transformations (`$httpProvider.defaults.transformRequest` and `$http.defaults.transformRequest`): * Response transformations (`$httpProvider.defaults.transformResponse` and `$http.defaults.transformResponse`): * ### Overriding the Default Transformations Per Request * * If you wish override the request/response transformations only for a single request then provide * `transformRequest` and/or `transformResponse` properties on the configuration object passed * Note that if you provide these properties on the config object the default transformations will be * overwritten. If you wish to augment the default transformations then you must include them in your * local transformation array. * The following code demonstrates adding a new response transformation to be run after the default response * transformations have been run. * * ```js * function appendTransform(defaults, transform) { * * // We can't guarantee that the default transformation is an array * defaults = angular.isArray(defaults) ? defaults : [defaults]; * * // Append the new transformation to the defaults * return defaults.concat(transform); * } * * $http({ * url: '...', * method: 'GET', * transformResponse: appendTransform($http.defaults.transformResponse, function(value) { * return doTransform(value); * }) * }); * ``` * * * ## Caching * {@link ng.$http#defaults `$http.defaults.cache`} property. All requests who set * ## Interceptors * * `request`: interceptors get called with a http `config` object. The function is free to * modify the `config` object or create a new one. The function needs to return the `config` * object directly, or a promise containing the `config` or a new `config` object. * modify the `response` object or create a new one. The function needs to return the `response` * object directly, or as a promise containing the `response` or a new `response` object. * return config; * return response; * ## Security Considerations * ### JSON Vulnerability Protection * ### Cross Site Request Forgery (XSRF) Protection * authentication cookie with a [salt](https://en.wikipedia.org/wiki/Salt_(cryptography&#41;) * See {@link ng.$http#overriding-the-default-transformations-per-request * Overriding the Default Transformations} * `{function(data, headersGetter, status)|Array.<function(data, headersGetter, status)>}` – * response body, headers and status and returns its transformed (typically deserialized) version. * See {@link ng.$http#overriding-the-default-transformations-per-request * Overriding the Default Transformations} * - **withCredentials** - `{boolean}` - whether to set the `withCredentials` flag on the * XHR object. See [requests with credentials](https://developer.mozilla.org/docs/Web/HTTP/Access_control_CORS#Requests_with_credentials)<example module=""httpExample""> <div ng-controller=""FetchController""> 'https://angularjs.org/greet.php?callback=JSON_CALLBACK&name=Super%20Hero')""> ng-click=""updateModel('JSONP', 'https://angularjs.org/doesntexist&callback=JSON_CALLBACK')""> angular.module('httpExample', []) .controller('FetchController', ['$scope', '$http', '$templateCache', function($scope, $http, $templateCache) { $scope.method = 'GET'; $scope.url = 'http-hello.html'; $scope.fetch = function() { $scope.code = null; $scope.response = null; $http({method: $scope.method, url: $scope.url, cache: $templateCache}). success(function(data, status) { $scope.status = status; $scope.data = data; }). error(function(data, status) { $scope.data = data || ""Request failed""; $scope.status = status; }); }; $scope.updateModel = function(method, url) { $scope.method = method; $scope.url = url; }; }]);// Commented out due to flakes. See https://github.com/angular/angular.js/issues/9185 // it('should make a JSONP request to angularjs.org', function() { // sampleJsonpBtn.click(); // fetchBtn.click(); // expect(status.getText()).toMatch('200'); // expect(data.getText()).toMatch(/Super Hero!/); // }); if (!angular.isObject(requestConfig)) { throw minErr('$http')('badreq', 'Http request configuration must be an object. Received: {0}', requestConfig); } var config = extend({ }, requestConfig); config.headers = mergeHeaders(requestConfig); var headers = config.headers; var reqData = transformData(config.data, headersGetter(headers), undefined, config.transformRequest); if (isUndefined(reqData)) { return sendReq(config, reqData).then(transformResponse, transformResponse); while (chain.length) { var resp = extend({}, response); if (!response.data) { resp.data = response.data; } else { resp.data = transformData(response.data, response.headers, response.status, config.transformResponse); } function executeHeaderFns(headers) { var headerContent, processedHeaders = {}; forEach(headers, function(headerFn, header) { if (isFunction(headerFn)) { headerContent = headerFn(); if (headerContent != null) { processedHeaders[header] = headerContent; } } else { processedHeaders[header] = headerFn; } }); return processedHeaders; } // execute if header value is a function for merged headers return executeHeaderFns(reqHeaders); * The name of the callback should be the string `JSON_CALLBACK`. /** * @ngdoc method * @name $http#patch * * @description * Shortcut method to perform `PATCH` request. * * @param {string} url Relative or absolute URL specifying the destination of the request * @param {*} data Request content * @param {Object=} config Optional configuration object * @returns {HttpPromise} Future object */ createShortMethodsWithData('post', 'put', 'patch'); function sendReq(config, reqData) { reqHeaders = config.headers, if ((config.cache || defaults.cache) && config.cache !== false && (config.method === 'GET' || config.method === 'JSONP')) { if (isPromiseLike(cachedResp)) { cachedResp.then(resolvePromiseWithResult, resolvePromiseWithResult); resolvePromise(cachedResp[1], cachedResp[0], shallowCopy(cachedResp[2]), cachedResp[3]); // if we won't have the response in cache, set the xsrf headers and // send the request to the backend var xsrfValue = urlIsSameOrigin(config.url) ? $browser.cookies()[config.xsrfCookieName || defaults.xsrfCookieName] : undefined; if (xsrfValue) { reqHeaders[(config.xsrfHeaderName || defaults.xsrfHeaderName)] = xsrfValue; } function resolveHttpPromise() { resolvePromise(response, status, headersString, statusText); } if (useApplyAsync) { $rootScope.$applyAsync(resolveHttpPromise); } else { resolveHttpPromise(); if (!$rootScope.$$phase) $rootScope.$apply(); } statusText: statusText function resolvePromiseWithResult(result) { resolvePromise(result.data, result.status, shallowCopy(result.headers()), result.statusText); } var idx = $http.pendingRequests.indexOf(config); if (!params) return url; var parts = []; forEachSorted(params, function(value, key) { if (value === null || isUndefined(value)) return; if (!isArray(value)) value = [value]; forEach(value, function(v) { if (isObject(v)) { if (isDate(v)) { v = v.toISOString(); } else { v = toJson(v); } parts.push(encodeUriQuery(key) + '=' + encodeUriQuery(v)); }); }); if (parts.length > 0) { url += ((url.indexOf('?') == -1) ? '?' : '&') + parts.join('&'); } return url; }function createXhr() { return new window.XMLHttpRequest(); callbacks[callbackId].called = true; callbackId, function(status, text) { completeRequest(callback, status, callbacks[callbackId].data, """", text); callbacks[callbackId] = noop; var xhr = createXhr(); xhr.onload = function requestLoaded() { var statusText = xhr.statusText || ''; // responseText is the old-school way of retrieving response (supported by IE8 & 9) // response/responseType properties were introduced in XHR Level2 spec (supported by IE10) var response = ('response' in xhr) ? xhr.response : xhr.responseText; // normalize IE9 bug (http://bugs.jquery.com/ticket/1450) var status = xhr.status === 1223 ? 204 : xhr.status; // fix status code when it is 0 (0 status is undocumented). // Occurs when accessing file resources or on Android 4.1 stock browser // while retrieving files from application cache. if (status === 0) { status = response ? 200 : urlResolve(url).protocol == 'file' ? 404 : 0; completeRequest(callback, status, response, xhr.getAllResponseHeaders(), statusText); var requestError = function() { // The response is always empty // See https://xhr.spec.whatwg.org/#request-error-steps and https://fetch.spec.whatwg.org/#concept-network-error completeRequest(callback, -1, null, null, ''); }; xhr.onerror = requestError; xhr.onabort = requestError; } else if (isPromiseLike(timeout)) { if (timeoutId !== undefined) { $browserDefer.cancel(timeoutId); jsonpDone = xhr = null; function jsonpReq(url, callbackId, done) { var script = rawDocument.createElement('script'), callback = null; script.type = ""text/javascript""; script.async = true; callback = function(event) { removeEventListenerFn(script, ""load"", callback); removeEventListenerFn(script, ""error"", callback); rawDocument.body.removeChild(script); script = null; var status = -1; var text = ""unknown""; if (event) { if (event.type === ""load"" && !callbacks[callbackId].called) { event = { type: ""error"" }; text = event.type; status = event.type === ""error"" ? 404 : 200; } if (done) { done(status, text); } }; addEventListenerFn(script, ""load"", callback); addEventListenerFn(script, ""error"", callback); return callback; customInterpolationApp.controller('DemoController', function() { this.startSymbol = function(value) { this.endSymbol = function(value) { endSymbolLength = endSymbol.length, escapedStartRegexp = new RegExp(startSymbol.replace(/./g, escape), 'g'), escapedEndRegexp = new RegExp(endSymbol.replace(/./g, escape), 'g'); function escape(ch) { return '\\\\\\' + ch; } * @kind function * `$interpolate` takes an optional fourth argument, `allOrNothing`. If `allOrNothing` is * `true`, the interpolation function will return `undefined` unless all embedded expressions * evaluate to a value other than `undefined`. * * ```js * var $interpolate = ...; // injected * var context = {greeting: 'Hello', name: undefined }; * * // default ""forgiving"" mode * var exp = $interpolate('{{greeting}} {{name}}!'); * expect(exp(context)).toEqual('Hello !'); * * // ""allOrNothing"" mode * exp = $interpolate('{{greeting}} {{name}}!', false, null, true); * expect(exp(context)).toBeUndefined(); * context.name = 'Angular'; * expect(exp(context)).toEqual('Hello Angular!'); * ``` * * `allOrNothing` is useful for interpolating URLs. `ngSrc` and `ngSrcset` use this behavior. * * ####Escaped Interpolation * $interpolate provides a mechanism for escaping interpolation markers. Start and end markers * can be escaped by preceding each of their characters with a REVERSE SOLIDUS U+005C (backslash). * It will be rendered as a regular start/end marker, and will not be interpreted as an expression * or binding. * * This enables web-servers to prevent script injection attacks and defacing attacks, to some * degree, while also enabling code examples to work without relying on the * {@link ng.directive:ngNonBindable ngNonBindable} directive. * * **For security purposes, it is strongly encouraged that web servers escape user-supplied data, * replacing angle brackets (&lt;, &gt;) with &amp;lt; and &amp;gt; respectively, and replacing all * interpolation start/end markers with their escaped counterparts.** * * Escaped interpolation markers are only replaced with the actual interpolation markers in rendered * output when the $interpolate service processes the text. So, for HTML elements interpolated * by {@link ng.$compile $compile}, or otherwise interpolated with the `mustHaveExpression` parameter * set to `true`, the interpolated text must contain an unescaped interpolation expression. As such, * this is typically useful only when user-data is used in rendering a template from the server, or * when otherwise untrusted data is used by a directive. * * <example> * <file name=""index.html""> * <div ng-init=""username='A user'""> * <p ng-init=""apptitle='Escaping demo'"">{{apptitle}}: \{\{ username = ""defaced value""; \}\} * </p> * <p><strong>{{username}}</strong> attempts to inject code which will deface the * application, but fails to accomplish their task, because the server has correctly * escaped the interpolation start/end markers with REVERSE SOLIDUS U+005C (backslash) * characters.</p> * <p>Instead, the result of the attempted script injection is visible, and can be removed * from the database by an administrator.</p> * </div> * </file> * </example> * @param {boolean=} allOrNothing if `true`, then the returned function returns undefined * unless all embedded expressions evaluate to a value other than `undefined`. * - `context`: evaluation context for all expressions embedded in the interpolated text function $interpolate(text, mustHaveExpression, trustedContext, allOrNothing) { allOrNothing = !!allOrNothing; expressions = [], parseFns = [], textLength = text.length, concat = [], expressionPositions = []; while (index < textLength) { if (((startIndex = text.indexOf(startSymbol, index)) != -1) && ((endIndex = text.indexOf(endSymbol, startIndex + startSymbolLength)) != -1)) { if (index !== startIndex) { concat.push(unescapeText(text.substring(index, startIndex))); } exp = text.substring(startIndex + startSymbolLength, endIndex); expressions.push(exp); parseFns.push($parse(exp, parseStringifyInterceptor)); expressionPositions.push(concat.length); concat.push(''); // we did not find an interpolation, so we have to add the remainder to the separators array if (index !== textLength) { concat.push(unescapeText(text.substring(index))); } break; if (trustedContext && concat.length > 1) { if (!mustHaveExpression || expressions.length) { var compute = function(values) { for (var i = 0, ii = expressions.length; i < ii; i++) { if (allOrNothing && isUndefined(values[i])) return; concat[expressionPositions[i]] = values[i]; return concat.join(''); var getValue = function(value) { return trustedContext ? $sce.getTrusted(trustedContext, value) : $sce.valueOf(value); }; var stringify = function(value) { if (value == null) { // null || undefined return ''; } switch (typeof value) { case 'string': break; case 'number': value = '' + value; break; default: value = toJson(value); } return value; }; return extend(function interpolationFn(context) { var i = 0; var ii = expressions.length; var values = new Array(ii); try { for (; i < ii; i++) { values[i] = parseFns[i](context); } return compute(values); } catch (err) { var newErr = $interpolateMinErr('interr', ""Can't interpolate: {0}\n{1}"", text, err.toString()); $exceptionHandler(newErr); } }, { // all of these properties are undocumented for now exp: text, //just for compatibility with regular watchers created via $watch expressions: expressions, $$watchDelegate: function(scope, listener, objectEquality) { var lastValue; return scope.$watchGroup(parseFns, function interpolateFnWatcher(values, oldValues) { var currValue = compute(values); if (isFunction(listener)) { listener.call(this, currValue, values !== oldValues ? lastValue : currValue, scope); } lastValue = currValue; }, objectEquality); } }); } function unescapeText(text) { return text.replace(escapedStartRegexp, startSymbol). replace(escapedEndRegexp, endSymbol); } function parseStringifyInterceptor(value) { try { value = getValue(value); return allOrNothing && !isDefined(value) ? value : stringify(value); } catch (err) { var newErr = $interpolateMinErr('interr', ""Can't interpolate: {0}\n{1}"", text, err.toString()); $exceptionHandler(newErr); } * Use {@link ng.$interpolateProvider#startSymbol `$interpolateProvider.startSymbol`} to change * Use {@link ng.$interpolateProvider#endSymbol `$interpolateProvider.endSymbol`} to change this.$get = ['$rootScope', '$window', '$q', '$$q', function($rootScope, $window, $q, $$q) { * <example module=""intervalExample""> * <file name=""index.html""> * <script> * angular.module('intervalExample', []) * .controller('ExampleController', ['$scope', '$interval', * function($scope, $interval) { * $scope.format = 'M/d/yy h:mm:ss a'; * var stop; * $scope.fight = function() { * // Don't start a new fight if we are already fighting * if ( angular.isDefined(stop) ) return; * stop = $interval(function() { * if ($scope.blood_1 > 0 && $scope.blood_2 > 0) { * $scope.blood_1 = $scope.blood_1 - 3; * $scope.blood_2 = $scope.blood_2 - 4; * } else { * $scope.stopFight(); * } * }, 100); * }; * * $scope.stopFight = function() { * if (angular.isDefined(stop)) { * $interval.cancel(stop); * stop = undefined; * } * }; * * $scope.resetFight = function() { * $scope.blood_1 = 100; * $scope.blood_2 = 120; * }; * * $scope.$on('$destroy', function() { * // Make sure that the interval is destroyed too * $scope.stopFight(); * }); * }]) * // Register the 'myCurrentTime' directive factory method. * // We inject $interval and dateFilter service since the factory method is DI. * .directive('myCurrentTime', ['$interval', 'dateFilter', * function($interval, dateFilter) { * stopTime; // so that we can cancel the time updates * // to prevent updating time after the DOM element was removed. * element.on('$destroy', function() { * }]); * </script> * <div> * <div ng-controller=""ExampleController""> * Date format: <input ng-model=""format""> <hr/> * Current time is: <span my-current-time=""format""></span> * <hr/> * Blood 1 : <font color='red'>{{blood_1}}</font> * Blood 2 : <font color='red'>{{blood_2}}</font> * <button type=""button"" data-ng-click=""fight()"">Fight</button> * <button type=""button"" data-ng-click=""stopFight()"">StopFight</button> * <button type=""button"" data-ng-click=""resetFight()"">resetFight</button> * </div> * </file> skipApply = (isDefined(invokeApply) && !invokeApply), deferred = (skipApply ? $$q : $q).defer(), promise = deferred.promise; $window.clearInterval(promise.$$intervalId);function $LocaleProvider() { 'short': 'M/d/yy h:mm a',function parseAbsoluteUrl(absoluteUrl, locationObj) { var parsedUrl = urlResolve(absoluteUrl);function parseAppUrl(relativeUrl, locationObj) { var match = urlResolve(relativeUrl);function trimEmptyHash(url) { return url.replace(/(#.+)|#$/, '$1'); } parseAbsoluteUrl(appBase, this); * @param {string} url HTML5 url parseAppUrl(pathUrl, this); this.$$parseLinkUrl = function(url, relHref) { if (relHref && relHref[0] === '#') { // special case for links to hash fragments: // keep the old url and only replace the hash fragment this.hash(relHref.slice(1)); return true; var appUrl, prevAppUrl; var rewrittenUrl; if ((appUrl = beginsWith(appBase, url)) !== undefined) { prevAppUrl = appUrl; if ((appUrl = beginsWith(basePrefix, appUrl)) !== undefined) { rewrittenUrl = appBaseNoFile + (beginsWith('/', appUrl) || appUrl); } else { rewrittenUrl = appBase + prevAppUrl; } } else if ((appUrl = beginsWith(appBaseNoFile, url)) !== undefined) { rewrittenUrl = appBaseNoFile + appUrl; } else if (appBaseNoFile == url + '/') { rewrittenUrl = appBaseNoFile; } if (rewrittenUrl) { this.$$parse(rewrittenUrl); } return !!rewrittenUrl; parseAbsoluteUrl(appBase, this); var withoutHashUrl; if (withoutBaseUrl.charAt(0) === '#') { // The rest of the url starts with a hash so we have // got either a hashbang path or a plain hash fragment withoutHashUrl = beginsWith(hashPrefix, withoutBaseUrl); if (isUndefined(withoutHashUrl)) { // There was no hashbang prefix so we just have a hash fragment withoutHashUrl = withoutBaseUrl; } } else { // There was no hashbang path nor hash fragment: // If we are in HTML5 mode we use what is left as the path; // Otherwise we ignore what is left withoutHashUrl = this.$$html5 ? withoutBaseUrl : ''; parseAppUrl(withoutHashUrl, this); function removeWindowsDriveName(path, url, base) { var windowsFilePathExp = /^\/[A-Z]:(\/.*)/; // The input URL intentionally contains a first path segment that ends with a colon. this.$$parseLinkUrl = function(url, relHref) { if (stripHash(appBase) == stripHash(url)) { this.$$parse(url); return true; return false; this.$$parseLinkUrl = function(url, relHref) { if (relHref && relHref[0] === '#') { // special case for links to hash fragments: // keep the old url and only replace the hash fragment this.hash(relHref.slice(1)); return true; } var rewrittenUrl; if (appBase == stripHash(url)) { rewrittenUrl = url; } else if ((appUrl = beginsWith(appBaseNoFile, url))) { rewrittenUrl = appBase + hashPrefix + appUrl; } else if (appBaseNoFile === url + '/') { rewrittenUrl = appBaseNoFile; if (rewrittenUrl) { this.$$parse(rewrittenUrl); } return !!rewrittenUrl; this.$$compose = function() { var search = toKeyValue(this.$$search), hash = this.$$hash ? '#' + encodeUriSegment(this.$$hash) : ''; this.$$url = encodePath(this.$$path) + (search ? '?' + search : '') + hash; // include hashPrefix in $$absUrl when $$url is empty so IE8 & 9 do not reload page because of removal of '#' this.$$absUrl = appBase + hashPrefix + this.$$url; }; var locationPrototype = { * Has any change been replacing? * * ```js * // given url http://example.com/#/some/path?foo=bar&baz=xoxo * var absUrl = $location.absUrl(); * // => ""http://example.com/#/some/path?foo=bar&baz=xoxo"" * ``` * * * ```js * // given url http://example.com/#/some/path?foo=bar&baz=xoxo * var url = $location.url(); * // => ""/some/path?foo=bar&baz=xoxo"" * ``` * url: function(url) { if (match[1] || url === '') this.path(decodeURIComponent(match[1])); if (match[2] || match[1] || url === '') this.search(match[3] || ''); this.hash(match[5] || ''); * * ```js * // given url http://example.com/#/some/path?foo=bar&baz=xoxo * var protocol = $location.protocol(); * // => ""http"" * ``` * * * ```js * // given url http://example.com/#/some/path?foo=bar&baz=xoxo * var host = $location.host(); * // => ""example.com"" * ``` * * * ```js * // given url http://example.com/#/some/path?foo=bar&baz=xoxo * var port = $location.port(); * // => 80 * ``` * * * ```js * // given url http://example.com/#/some/path?foo=bar&baz=xoxo * var path = $location.path(); * // => ""/some/path"" * ``` * * @param {(string|number)=} path New path path = path !== null ? path.toString() : ''; * * ```js * // given url http://example.com/#/some/path?foo=bar&baz=xoxo * var searchObject = $location.search(); * // => {foo: 'bar', baz: 'xoxo'} * * // set foo to 'yipee' * $location.search('foo', 'yipee'); * // $location.search() => {foo: 'yipee', baz: 'xoxo'} * ``` * * hash object. * When called with a single argument the method acts as a setter, setting the `search` component * of `$location` to the specified value. * If the argument is a hash object containing an array of values, these values will be encoded * as duplicate search parameters in the url. * * @param {(string|Number|Array<string>|boolean)=} paramValue If `search` is a string or number, then `paramValue` * will override only a single search property. * * If `paramValue` is an array, it will override the property of the `search` component of * `$location` specified via the first argument. * * If `paramValue` is `null`, the property specified via the first argument will be deleted. * * If `paramValue` is `true`, the property specified via the first argument will be added with no * value nor trailing equal sign. * * @return {Object} If called with no arguments returns the parsed `search` object. If called with * one or more arguments returns `$location` object itself. if (isString(search) || isNumber(search)) { search = search.toString(); search = copy(search, {}); // remove object undefined or null properties forEach(search, function(value, key) { if (value == null) delete search[key]; }); * * ```js * // given url http://example.com/#/some/path?foo=bar&baz=xoxo#hashValue * var hash = $location.hash(); * // => ""hashValue"" * ``` * * @param {(string|number)=} hash New hash fragment hash: locationGetterSetter('$$hash', function(hash) { return hash !== null ? hash.toString() : ''; }),forEach([LocationHashbangInHtml5Url, LocationHashbangUrl, LocationHtml5Url], function(Location) { Location.prototype = Object.create(locationPrototype); /** * @ngdoc method * @name $location#state * * @description * This method is getter / setter. * * Return the history state object when called without any parameter. * * Change the history state object when called with one parameter and return `$location`. * The state object is later passed to `pushState` or `replaceState`. * * NOTE: This method is supported only in HTML5 mode and only in browsers supporting * the HTML5 History API (i.e. methods `pushState` and `replaceState`). If you need to support * older browsers (like IE9 or Android < 4.0), don't use this method. * * @param {object=} state State object for pushState or replaceState * @return {object} state */ Location.prototype.state = function(state) { if (!arguments.length) return this.$$state; if (Location !== LocationHtml5Url || !this.$$html5) { throw $locationMinErr('nostate', 'History API state support is available only ' + 'in HTML5 mode and only in browsers supporting HTML5 History API'); } // The user might modify `stateObject` after invoking `$location.state(stateObject)` // but we're changing the $$state reference to $browser.state() during the $digest // so the modification window is narrow. this.$$state = isUndefined(state) ? null : state; return this; }; }); function $LocationProvider() { html5Mode = { enabled: false, requireBase: true, rewriteLinks: true }; * @ngdoc method * @ngdoc method * @param {(boolean|Object)=} mode If boolean, sets `html5Mode.enabled` to value. * If object, sets `enabled`, `requireBase` and `rewriteLinks` to respective values. Supported * properties: * - **enabled** – `{boolean}` – (default: false) If true, will rely on `history.pushState` to * change urls where supported. Will fall back to hash-prefixed paths in browsers that do not * support `pushState`. * - **requireBase** - `{boolean}` - (default: `true`) When html5Mode is enabled, specifies * whether or not a <base> tag is required to be present. If `enabled` and `requireBase` are * true, and a base tag is not present, an error will be thrown when `$location` is injected. * See the {@link guide/$location $location guide for more information} * - **rewriteLinks** - `{boolean}` - (default: `true`) When html5Mode is enabled, * enables/disables url rewriting for relative links. * * @returns {Object} html5Mode object if used as getter or itself (chaining) if used as setter if (isBoolean(mode)) { html5Mode.enabled = mode; return this; } else if (isObject(mode)) { if (isBoolean(mode.enabled)) { html5Mode.enabled = mode.enabled; } if (isBoolean(mode.requireBase)) { html5Mode.requireBase = mode.requireBase; } if (isBoolean(mode.rewriteLinks)) { html5Mode.rewriteLinks = mode.rewriteLinks; } * Broadcasted before a URL will change. * * This change can be prevented by calling * {@link ng.$location#$locationChangeSuccess $locationChangeSuccess} is fired. * * The `newState` and `oldState` parameters may be defined only in HTML5 mode and when * the browser supports the HTML5 History API. * @param {string=} newState New history state object * @param {string=} oldState History state object that was before it was changed. * The `newState` and `oldState` parameters may be defined only in HTML5 mode and when * the browser supports the HTML5 History API. * * @param {string=} newState New history state object * @param {string=} oldState History state object that was before it was changed. this.$get = ['$rootScope', '$browser', '$sniffer', '$rootElement', '$window', function($rootScope, $browser, $sniffer, $rootElement, $window) { if (html5Mode.enabled) { if (!baseHref && html5Mode.requireBase) { throw $locationMinErr('nobase', ""$location in HTML5 mode requires a <base> tag to be present!""); } $location.$$parseLinkUrl(initialUrl, initialUrl); $location.$$state = $browser.state(); var IGNORE_URI_REGEXP = /^\s*(javascript|mailto):/i; function setBrowserUrlWithFallback(url, replace, state) { var oldUrl = $location.url(); var oldState = $location.$$state; try { $browser.url(url, replace, state); // Make sure $location.state() returns referentially identical (not just deeply equal) // state object; this makes possible quick checking if the state changed in the digest // loop. Checking deep equality would be too expensive. $location.$$state = $browser.state(); } catch (e) { // Restore old values if pushState fails $location.url(oldUrl); $location.$$state = oldState; throw e; } } if (!html5Mode.rewriteLinks || event.ctrlKey || event.metaKey || event.which == 2) return; while (nodeName_(elm[0]) !== 'a') { // get the actual href attribute - see // http://msdn.microsoft.com/en-us/library/ie/dd347148(v=vs.85).aspx var relHref = elm.attr('href') || elm.attr('xlink:href'); // Ignore when url is started with javascript: or mailto: if (IGNORE_URI_REGEXP.test(absHref)) return; if (absHref && !elm.attr('target') && !event.isDefaultPrevented()) { if ($location.$$parseLinkUrl(absHref, relHref)) { // We do a preventDefault for all urls that are part of the angular application, // in html5mode and also without, so that we are able to abort navigation without // getting double entries in the location history. event.preventDefault(); if ($location.absUrl() != $browser.url()) { $rootScope.$apply(); // hack to work around FF6 bug 684208 when scenario runner clicks on links $window.angular['ff-684208-preventDefault'] = true; } var initializing = true; // update $location when $browser url changes $browser.onUrlChange(function(newUrl, newState) { $rootScope.$evalAsync(function() { var oldUrl = $location.absUrl(); var oldState = $location.$$state; var defaultPrevented; $location.$$parse(newUrl); $location.$$state = newState; defaultPrevented = $rootScope.$broadcast('$locationChangeStart', newUrl, oldUrl, newState, oldState).defaultPrevented; // if the location was changed by a `$locationChangeStart` handler then stop // processing this location change if ($location.absUrl() !== newUrl) return; if (defaultPrevented) { $location.$$parse(oldUrl); $location.$$state = oldState; setBrowserUrlWithFallback(oldUrl, false, oldState); } else { initializing = false; afterLocationChange(oldUrl, oldState); } }); if (!$rootScope.$$phase) $rootScope.$digest(); var oldUrl = trimEmptyHash($browser.url()); var newUrl = trimEmptyHash($location.absUrl()); var oldState = $browser.state(); var urlOrStateChanged = oldUrl !== newUrl || ($location.$$html5 && $sniffer.history && oldState !== $location.$$state); if (initializing || urlOrStateChanged) { initializing = false; var newUrl = $location.absUrl(); var defaultPrevented = $rootScope.$broadcast('$locationChangeStart', newUrl, oldUrl, $location.$$state, oldState).defaultPrevented; // if the location was changed by a `$locationChangeStart` handler then stop // processing this location change if ($location.absUrl() !== newUrl) return; if (defaultPrevented) { $location.$$state = oldState; if (urlOrStateChanged) { setBrowserUrlWithFallback(newUrl, currentReplace, oldState === $location.$$state ? null : $location.$$state); } afterLocationChange(oldUrl, oldState); // we don't need to return anything because $evalAsync will make the digest loop dirty when // there is a change function afterLocationChange(oldUrl, oldState) { $rootScope.$broadcast('$locationChangeSuccess', $location.absUrl(), oldUrl, $location.$$state, oldState); <example module=""logExample""> angular.module('logExample', []) .controller('LogController', ['$scope', '$log', function($scope, $log) { $scope.$log = $log; $scope.message = 'Hello World!'; }]); <div ng-controller=""LogController"">function $LogProvider() { * @ngdoc method this.$get = ['$window', function($window) { debug: (function() {// access to `$scope` and locals. However, one can obtain the ability to execute arbitrary JS code by// {}.toString.constructor('alert(""evil JS code"")')// sensitive JavaScript or browser APIs on Scope. Exposing such objects on a Scope is never a good// Similarly we prevent invocations of function known to be dangerous, as well as assignments to // native objects. // // See https://docs.angularjs.org/guide/security if (name === ""__defineGetter__"" || name === ""__defineSetter__"" || name === ""__lookupGetter__"" || name === ""__lookupSetter__"" || name === ""__proto__"") { 'Attempting to access a disallowed field in Angular expressions! ' + 'Expression: {0}', fullExpression); obj.window === obj) { } else if (// block Object so that we can't get hold of dangerous Object.* methods obj === Object) { throw $parseMinErr('isecobj', 'Referencing Object in Angular expressions is disallowed! Expression: {0}', fullExpression);var CALL = Function.prototype.call; var APPLY = Function.prototype.apply; var BIND = Function.prototype.bind; function ensureSafeFunction(obj, fullExpression) { if (obj) { if (obj.constructor === obj) { throw $parseMinErr('isecfn', 'Referencing Function in Angular expressions is disallowed! Expression: {0}', fullExpression); } else if (obj === CALL || obj === APPLY || obj === BIND) { throw $parseMinErr('isecff', 'Referencing call, apply or bind in Angular expressions is disallowed! Expression: {0}', fullExpression); } } } //Keyword constants var CONSTANTS = createMap(); forEach({ 'null': function() { return null; }, 'true': function() { return true; }, 'false': function() { return false; }, 'undefined': function() {} }, function(constantGetter, name) { constantGetter.constant = constantGetter.literal = constantGetter.sharedGetter = true; CONSTANTS[name] = constantGetter; }); //Not quite a constant, but can be lex/parsed the same CONSTANTS['this'] = function(self) { return self; }; CONSTANTS['this'].sharedGetter = true; //Operators - will be wrapped by binaryFn/unaryFn/assignment/filter var OPERATORS = extend(createMap(), { '+':function(self, locals, a, b) { return isDefined(b) ? b : undefined;}, '-':function(self, locals, a, b) { return (isDefined(a) ? a : 0) - (isDefined(b) ? b : 0); '*':function(self, locals, a, b) {return a(self, locals) * b(self, locals);}, '/':function(self, locals, a, b) {return a(self, locals) / b(self, locals);}, '%':function(self, locals, a, b) {return a(self, locals) % b(self, locals);}, '===':function(self, locals, a, b) {return a(self, locals) === b(self, locals);}, '!==':function(self, locals, a, b) {return a(self, locals) !== b(self, locals);}, '==':function(self, locals, a, b) {return a(self, locals) == b(self, locals);}, '!=':function(self, locals, a, b) {return a(self, locals) != b(self, locals);}, '<':function(self, locals, a, b) {return a(self, locals) < b(self, locals);}, '>':function(self, locals, a, b) {return a(self, locals) > b(self, locals);}, '<=':function(self, locals, a, b) {return a(self, locals) <= b(self, locals);}, '>=':function(self, locals, a, b) {return a(self, locals) >= b(self, locals);}, '&&':function(self, locals, a, b) {return a(self, locals) && b(self, locals);}, '||':function(self, locals, a, b) {return a(self, locals) || b(self, locals);}, '!':function(self, locals, a) {return !a(self, locals);}, //Tokenized as operators but parsed as assignment/filters '=':true, '|':true });var Lexer = function(options) { lex: function(text) { var ch = this.text.charAt(this.index); if (ch === '""' || ch === ""'"") { this.readString(ch); } else if (this.isNumber(ch) || ch === '.' && this.isNumber(this.peek())) { } else if (this.isIdent(ch)) { } else if (this.is(ch, '(){}[].,;:?')) { this.tokens.push({index: this.index, text: ch}); } else if (this.isWhitespace(ch)) { var ch2 = ch + this.peek(); var op1 = OPERATORS[ch]; var op2 = OPERATORS[ch2]; var op3 = OPERATORS[ch3]; if (op1 || op2 || op3) { var token = op3 ? ch3 : (op2 ? ch2 : ch); this.tokens.push({index: this.index, text: token, operator: true}); this.index += token.length; is: function(ch, chars) { return chars.indexOf(ch) !== -1; return ('0' <= ch && ch <= '9') && typeof ch === ""string""; constant: true, value: Number(number) var ch = this.text.charAt(this.index); if (!(this.isIdent(ch) || this.isNumber(ch))) { this.tokens.push({ text: this.text.slice(start, this.index), identifier: true }); string = string + (rep || ch); constant: true, value: stringfunction isConstant(exp) { return exp.constant; } var Parser = function(lexer, $filter, options) {Parser.ZERO = extend(function() { sharedGetter: true, parse: function(text) { var value = this.statements(); primary: function() { } else if (this.peek().identifier && this.peek().text in CONSTANTS) { primary = CONSTANTS[this.consume().text]; } else if (this.peek().identifier) { primary = this.identifier(); } else if (this.peek().constant) { primary = this.constant(); this.throwError('not a primary expression', this.peek()); return this.peekAhead(0, e1, e2, e3, e4); }, peekAhead: function(i, e1, e2, e3, e4) { if (this.tokens.length > i) { var token = this.tokens[i]; expect: function(e1, e2, e3, e4) { consume: function(e1) { if (this.tokens.length === 0) { throw $parseMinErr('ueoe', 'Unexpected end of expression: {0}', this.text); } var token = this.expect(e1); if (!token) { return token; unaryFn: function(op, right) { var fn = OPERATORS[op]; return extend(function $parseUnaryFn(self, locals) { constant:right.constant, inputs: [right] binaryFn: function(left, op, right, isBranching) { var fn = OPERATORS[op]; return extend(function $parseBinaryFn(self, locals) { constant: left.constant && right.constant, inputs: !isBranching && [left, right] }); }, identifier: function() { var id = this.consume().text; //Continue reading each `.identifier` unless it is a method invocation while (this.peek('.') && this.peekAhead(1).identifier && !this.peekAhead(2, '(')) { id += this.consume().text + this.consume().text; } return getterFn(id, this.options, this.text); }, constant: function() { var value = this.consume().value; return extend(function $parseConstant() { return value; }, { constant: true, literal: true : function $parseStatements(self, locals) { for (var i = 0, ii = statements.length; i < ii; i++) { value = statements[i](self, locals); while ((token = this.expect('|'))) { left = this.filter(left); return left; filter: function(inputFn) { var fn = this.$filter(this.consume().text); var argsFn; var args; if (this.peek(':')) { argsFn = []; args = []; // we can safely reuse the array while (this.expect(':')) { var inputs = [inputFn].concat(argsFn || []); return extend(function $parseFilter(self, locals) { var input = inputFn(self, locals); if (args) { args[0] = input; var i = argsFn.length; while (i--) { args[i + 1] = argsFn[i](self, locals); } return fn.apply(undefined, args); } return fn(input); }, { constant: !fn.$stateful && inputs.every(isConstant), inputs: !fn.$stateful && inputs }); return extend(function $parseAssignment(scope, locals) { }, { inputs: [left, right] }); middle = this.assignment(); if (this.consume(':')) { var right = this.assignment(); return extend(function $parseTernary(self, locals) { return left(self, locals) ? middle(self, locals) : right(self, locals); }, { constant: left.constant && middle.constant && right.constant }); return left; while ((token = this.expect('||'))) { left = this.binaryFn(left, token.text, this.logicalAND(), true); return left; while ((token = this.expect('&&'))) { left = this.binaryFn(left, token.text, this.equality(), true); while ((token = this.expect('==','!=','===','!=='))) { left = this.binaryFn(left, token.text, this.relational()); while ((token = this.expect('<', '>', '<=', '>='))) { left = this.binaryFn(left, token.text, this.additive()); left = this.binaryFn(left, token.text, this.multiplicative()); left = this.binaryFn(left, token.text, this.unary()); return this.binaryFn(Parser.ZERO, token.text, this.unary()); return this.unaryFn(token.text, this.unary()); var getter = this.identifier(); return extend(function $parseFieldAccess(scope, locals, self) { var o = self || object(scope, locals); return (o == null) ? undefined : getter(o); var o = object(scope, locals); if (!o) object.assign(scope, o = {}); return getter.assign(o, value); var expression = this.text; return extend(function $parseObjectIndex(self, locals) { v; ensureSafeMemberName(i, expression); v = ensureSafeObject(o[i], expression); var key = ensureSafeMemberName(indexFn(self, locals), expression); var o = ensureSafeObject(obj(self, locals), expression); if (!o) obj.assign(self, o = {}); return o[key] = value; functionCall: function(fnGetter, contextGetter) { var expressionText = this.text; // we can safely reuse the array across invocations var args = argsFn.length ? [] : null; return function $parseFunctionCall(scope, locals) { var context = contextGetter ? contextGetter(scope, locals) : isDefined(contextGetter) ? undefined : scope; var fn = fnGetter(scope, locals, context) || noop; if (args) { var i = argsFn.length; while (i--) { args[i] = ensureSafeObject(argsFn[i](scope, locals), expressionText); } ensureSafeObject(context, expressionText); ensureSafeFunction(fn, expressionText); // IE doesn't have apply for some native functions var v = fn.apply ? fn.apply(context, args) : fn(args[0], args[1], args[2], args[3], args[4]); return ensureSafeObject(v, expressionText); }; arrayDeclaration: function() { elementFns.push(this.expression()); return extend(function $parseArrayLiteral(self, locals) { for (var i = 0, ii = elementFns.length; i < ii; i++) { constant: elementFns.every(isConstant), inputs: elementFns object: function() { var keys = [], valueFns = []; var token = this.consume(); if (token.constant) { keys.push(token.value); } else if (token.identifier) { keys.push(token.text); } else { this.throwError(""invalid key"", token); this.consume(':'); valueFns.push(this.expression()); return extend(function $parseObjectLiteral(self, locals) { for (var i = 0, ii = valueFns.length; i < ii; i++) { object[keys[i]] = valueFns[i](self, locals); constant: valueFns.every(isConstant), inputs: valueFnsfunction setter(obj, path, setValue, fullExp) { ensureSafeObject(obj, fullExp); var propertyObj = ensureSafeObject(obj[key], fullExp); ensureSafeObject(obj[key], fullExp);var getterFnCacheDefault = createMap(); var getterFnCacheExpensive = createMap(); function isPossiblyDangerousMemberName(name) { return name == 'constructor'; }function cspSafeGetterFn(key0, key1, key2, key3, key4, fullExp, expensiveChecks) { var eso = function(o) { return ensureSafeObject(o, fullExp); }; var eso0 = (expensiveChecks || isPossiblyDangerousMemberName(key0)) ? eso : identity; var eso1 = (expensiveChecks || isPossiblyDangerousMemberName(key1)) ? eso : identity; var eso2 = (expensiveChecks || isPossiblyDangerousMemberName(key2)) ? eso : identity; var eso3 = (expensiveChecks || isPossiblyDangerousMemberName(key3)) ? eso : identity; var eso4 = (expensiveChecks || isPossiblyDangerousMemberName(key4)) ? eso : identity; return function cspSafeGetter(scope, locals) { var pathVal = (locals && locals.hasOwnProperty(key0)) ? locals : scope; if (pathVal == null) return pathVal; pathVal = eso0(pathVal[key0]); if (!key1) return pathVal; if (pathVal == null) return undefined; pathVal = eso1(pathVal[key1]); if (!key2) return pathVal; if (pathVal == null) return undefined; pathVal = eso2(pathVal[key2]); if (!key3) return pathVal; if (pathVal == null) return undefined; pathVal = eso3(pathVal[key3]); if (!key4) return pathVal; if (pathVal == null) return undefined; pathVal = eso4(pathVal[key4]); return pathVal;function getterFnWithEnsureSafeObject(fn, fullExpression) { return function(s, l) { return fn(s, l, ensureSafeObject, fullExpression); var expensiveChecks = options.expensiveChecks; var getterFnCache = (expensiveChecks ? getterFnCacheExpensive : getterFnCacheDefault); var fn = getterFnCache[path]; if (fn) return fn; pathKeysLength = pathKeys.length; if (options.csp) { fn = cspSafeGetterFn(pathKeys[0], pathKeys[1], pathKeys[2], pathKeys[3], pathKeys[4], fullExp, expensiveChecks); fn = function cspSafeGetter(scope, locals) { pathKeys[i++], fullExp, expensiveChecks)(scope, locals); var code = ''; if (expensiveChecks) { code += 's = eso(s, fe);\nl = eso(l, fe);\n'; } var needsEnsureSafeObject = expensiveChecks; var lookupJs = (index : '((l&&l.hasOwnProperty(""' + key + '""))?l:s)') + '.' + key; if (expensiveChecks || isPossiblyDangerousMemberName(key)) { lookupJs = 'eso(' + lookupJs + ', fe)'; needsEnsureSafeObject = true; } code += 'if(s == null) return undefined;\n' + 's=' + lookupJs + ';\n'; var evaledFnGetter = new Function('s', 'l', 'eso', 'fe', code); // s=scope, l=locals, eso=ensureSafeObject if (needsEnsureSafeObject) { evaledFnGetter = getterFnWithEnsureSafeObject(evaledFnGetter, fullExp); } fn = evaledFnGetter; fn.sharedGetter = true; fn.assign = function(self, value) { return setter(self, path, value, path); }; getterFnCache[path] = fn;var objectValueOf = Object.prototype.valueOf; function getValueOf(value) { return isFunction(value.valueOf) ? value.valueOf() : objectValueOf.call(value); } var cacheDefault = createMap(); var cacheExpensive = createMap(); this.$get = ['$filter', '$sniffer', function($filter, $sniffer) { var $parseOptions = { csp: $sniffer.csp, expensiveChecks: false }, $parseOptionsExpensive = { csp: $sniffer.csp, expensiveChecks: true }; function wrapSharedExpression(exp) { var wrapped = exp; if (exp.sharedGetter) { wrapped = function $parseWrapper(self, locals) { return exp(self, locals); }; wrapped.literal = exp.literal; wrapped.constant = exp.constant; wrapped.assign = exp.assign; } return wrapped; return function $parse(exp, interceptorFn, expensiveChecks) { var parsedExpression, oneTime, cacheKey; cacheKey = exp = exp.trim(); var cache = (expensiveChecks ? cacheExpensive : cacheDefault); parsedExpression = cache[cacheKey]; if (!parsedExpression) { if (exp.charAt(0) === ':' && exp.charAt(1) === ':') { oneTime = true; exp = exp.substring(2); } var parseOptions = expensiveChecks ? $parseOptionsExpensive : $parseOptions; var lexer = new Lexer(parseOptions); var parser = new Parser(lexer, $filter, parseOptions); parsedExpression = parser.parse(exp); if (parsedExpression.constant) { parsedExpression.$$watchDelegate = constantWatchDelegate; } else if (oneTime) { //oneTime is not part of the exp passed to the Parser so we may have to //wrap the parsedExpression before adding a $$watchDelegate parsedExpression = wrapSharedExpression(parsedExpression); parsedExpression.$$watchDelegate = parsedExpression.literal ? oneTimeLiteralWatchDelegate : oneTimeWatchDelegate; } else if (parsedExpression.inputs) { parsedExpression.$$watchDelegate = inputsWatchDelegate; } cache[cacheKey] = parsedExpression; return addInterceptor(parsedExpression, interceptorFn); return addInterceptor(exp, interceptorFn); return addInterceptor(noop, interceptorFn); function collectExpressionInputs(inputs, list) { for (var i = 0, ii = inputs.length; i < ii; i++) { var input = inputs[i]; if (!input.constant) { if (input.inputs) { collectExpressionInputs(input.inputs, list); } else if (list.indexOf(input) === -1) { // TODO(perf) can we do better? list.push(input); } } } return list; } function expressionInputDirtyCheck(newValue, oldValueOfValue) { if (newValue == null || oldValueOfValue == null) { // null/undefined return newValue === oldValueOfValue; } if (typeof newValue === 'object') { // attempt to convert the value to a primitive type // TODO(docs): add a note to docs that by implementing valueOf even objects and arrays can // be cheaply dirty-checked newValue = getValueOf(newValue); if (typeof newValue === 'object') { // objects/arrays are not supported - deep-watching them would be too expensive return false; } // fall-through to the primitive equality check } //Primitive or NaN return newValue === oldValueOfValue || (newValue !== newValue && oldValueOfValue !== oldValueOfValue); } function inputsWatchDelegate(scope, listener, objectEquality, parsedExpression) { var inputExpressions = parsedExpression.$$inputs || (parsedExpression.$$inputs = collectExpressionInputs(parsedExpression.inputs, [])); var lastResult; if (inputExpressions.length === 1) { var oldInputValue = expressionInputDirtyCheck; // init to something unique so that equals check fails inputExpressions = inputExpressions[0]; return scope.$watch(function expressionInputWatch(scope) { var newInputValue = inputExpressions(scope); if (!expressionInputDirtyCheck(newInputValue, oldInputValue)) { lastResult = parsedExpression(scope); oldInputValue = newInputValue && getValueOf(newInputValue); } return lastResult; }, listener, objectEquality); } var oldInputValueOfValues = []; for (var i = 0, ii = inputExpressions.length; i < ii; i++) { oldInputValueOfValues[i] = expressionInputDirtyCheck; // init to something unique so that equals check fails } return scope.$watch(function expressionInputsWatch(scope) { var changed = false; for (var i = 0, ii = inputExpressions.length; i < ii; i++) { var newInputValue = inputExpressions[i](scope); if (changed || (changed = !expressionInputDirtyCheck(newInputValue, oldInputValueOfValues[i]))) { oldInputValueOfValues[i] = newInputValue && getValueOf(newInputValue); } } if (changed) { lastResult = parsedExpression(scope); } return lastResult; }, listener, objectEquality); } function oneTimeWatchDelegate(scope, listener, objectEquality, parsedExpression) { var unwatch, lastValue; return unwatch = scope.$watch(function oneTimeWatch(scope) { return parsedExpression(scope); }, function oneTimeListener(value, old, scope) { lastValue = value; if (isFunction(listener)) { listener.apply(this, arguments); } if (isDefined(value)) { scope.$$postDigest(function() { if (isDefined(lastValue)) { unwatch(); } }); } }, objectEquality); } function oneTimeLiteralWatchDelegate(scope, listener, objectEquality, parsedExpression) { var unwatch, lastValue; return unwatch = scope.$watch(function oneTimeWatch(scope) { return parsedExpression(scope); }, function oneTimeListener(value, old, scope) { lastValue = value; if (isFunction(listener)) { listener.call(this, value, old, scope); } if (isAllDefined(value)) { scope.$$postDigest(function() { if (isAllDefined(lastValue)) unwatch(); }); } }, objectEquality); function isAllDefined(value) { var allDefined = true; forEach(value, function(val) { if (!isDefined(val)) allDefined = false; }); return allDefined; } } function constantWatchDelegate(scope, listener, objectEquality, parsedExpression) { var unwatch; return unwatch = scope.$watch(function constantWatch(scope) { return parsedExpression(scope); }, function constantListener(value, old, scope) { if (isFunction(listener)) { listener.apply(this, arguments); } unwatch(); }, objectEquality); } function addInterceptor(parsedExpression, interceptorFn) { if (!interceptorFn) return parsedExpression; var watchDelegate = parsedExpression.$$watchDelegate; var regularWatch = watchDelegate !== oneTimeLiteralWatchDelegate && watchDelegate !== oneTimeWatchDelegate; var fn = regularWatch ? function regularInterceptedExpression(scope, locals) { var value = parsedExpression(scope, locals); return interceptorFn(value, scope, locals); } : function oneTimeInterceptedExpression(scope, locals) { var value = parsedExpression(scope, locals); var result = interceptorFn(value, scope, locals); // we only return the interceptor's result if the // initial value is defined (for bind-once) return isDefined(value) ? result : value; }; // Propagate $$watchDelegates other then inputsWatchDelegate if (parsedExpression.$$watchDelegate && parsedExpression.$$watchDelegate !== inputsWatchDelegate) { fn.$$watchDelegate = parsedExpression.$$watchDelegate; } else if (!interceptorFn.$stateful) { // If there is an interceptor, but no watchDelegate then treat the interceptor like // we treat filters - it is assumed to be a pure function unless flagged with $stateful fn.$$watchDelegate = inputsWatchDelegate; fn.inputs = [parsedExpression]; } return fn; } * A service that helps you run functions asynchronously, and use their return values (or exceptions) * when they are done processing. * * This is an implementation of promises/deferred objects inspired by * [Kris Kowal's Q](https://github.com/kriskowal/q). * * $q can be used in two fashions --- one which is more similar to Kris Kowal's Q or jQuery's Deferred * implementations, and the other which resembles ES6 promises to some degree. * * # $q constructor * * The streamlined ES6 style promise is essentially just using $q as a constructor which takes a `resolver` * function as the first argument. This is similar to the native Promise implementation from ES6 Harmony, * see [MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise). * * While the constructor-style use is supported, not all of the supporting methods from ES6 Harmony promises are * available yet. * * It can be used like so: * * ```js * // for the purpose of this example let's assume that variables `$q` and `okToGreet` * // are available in the current lexical scope (they could have been injected or passed in). * * function asyncGreet(name) { * // perform some asynchronous operation, resolve or reject the promise when appropriate. * return $q(function(resolve, reject) { * setTimeout(function() { * if (okToGreet(name)) { * resolve('Hello, ' + name + '!'); * } else { * reject('Greeting ' + name + ' is not allowed.'); * } * }, 1000); * }); * } * * var promise = asyncGreet('Robin Hood'); * promise.then(function(greeting) { * alert('Success: ' + greeting); * }, function(reason) { * alert('Failed: ' + reason); * }); * ``` * * Note: progress/notify callbacks are not currently supported via the ES6-style interface. * * However, the more traditional CommonJS-style usage is still available, and documented below. * // for the purpose of this example let's assume that variables `$q` and `okToGreet` * deferred.notify('About to greet ' + name + '.'); * if (okToGreet(name)) { * deferred.resolve('Hello, ' + name + '!'); * } else { * deferred.reject('Greeting ' + name + ' is not allowed.'); * } * `notifyCallback` method. The promise cannot be resolved or rejected from the notifyCallback * - `finally(callback, notifyCallback)` – allows you to observe either the fulfillment or rejection of a promise, * * @param {function(function, function)} resolver Function which is responsible for resolving or * rejecting the newly created promise. The first parameter is a function which resolves the * promise, the second parameter is a function which rejects the promise. * * @returns {Promise} The newly created promise.function $$QProvider() { this.$get = ['$browser', '$exceptionHandler', function($browser, $exceptionHandler) { return qFactory(function(callback) { $browser.defer(callback); }, $exceptionHandler); }]; } * @param {function(function)} nextTick Function for executing functions in the next turn. var $qMinErr = minErr('$q', TypeError); function callOnce(self, resolveFn, rejectFn) { var called = false; function wrap(fn) { return function(value) { if (called) return; called = true; fn.call(self, value); }; } return [wrap(resolveFn), wrap(rejectFn)]; } * @name ng.$q#defer * @kind function return new Deferred(); function Promise() { this.$$state = { status: 0 }; } Promise.prototype = { then: function(onFulfilled, onRejected, progressBack) { var result = new Deferred(); this.$$state.pending = this.$$state.pending || []; this.$$state.pending.push([result, onFulfilled, onRejected, progressBack]); if (this.$$state.status > 0) scheduleProcessQueue(this.$$state); return result.promise; }, ""catch"": function(callback) { return this.then(null, callback); }, ""finally"": function(callback, progressBack) { return this.then(function(value) { return handleCallback(value, true, callback); }, function(error) { return handleCallback(error, false, callback); }, progressBack); } }; //Faster, more basic than angular.bind http://jsperf.com/angular-bind-vs-custom-vs-native function simpleBind(context, fn) { return function(value) { fn.call(context, value); }; } function processQueue(state) { var fn, promise, pending; pending = state.pending; state.processScheduled = false; state.pending = undefined; for (var i = 0, ii = pending.length; i < ii; ++i) { promise = pending[i][0]; fn = pending[i][state.status]; try { if (isFunction(fn)) { promise.resolve(fn(state.value)); } else if (state.status === 1) { promise.resolve(state.value); } else { promise.reject(state.value); } } catch (e) { promise.reject(e); exceptionHandler(e); } } } function scheduleProcessQueue(state) { if (state.processScheduled || !state.pending) return; state.processScheduled = true; nextTick(function() { processQueue(state); }); } function Deferred() { this.promise = new Promise(); //Necessary to support unbound execution :/ this.resolve = simpleBind(this, this.resolve); this.reject = simpleBind(this, this.reject); this.notify = simpleBind(this, this.notify); } Deferred.prototype = { resolve: function(val) { if (this.promise.$$state.status) return; if (val === this.promise) { this.$$reject($qMinErr( 'qcycle', ""Expected promise to be resolved with value other than itself '{0}'"", val)); } else { this.$$resolve(val); } }, $$resolve: function(val) { var then, fns; fns = callOnce(this, this.$$resolve, this.$$reject); try { if ((isObject(val) || isFunction(val))) then = val && val.then; if (isFunction(then)) { this.promise.$$state.status = -1; then.call(val, fns[0], fns[1], this.notify); } else { this.promise.$$state.value = val; this.promise.$$state.status = 1; scheduleProcessQueue(this.promise.$$state); } } catch (e) { fns[1](e); exceptionHandler(e); } }, reject: function(reason) { if (this.promise.$$state.status) return; this.$$reject(reason); }, $$reject: function(reason) { this.promise.$$state.value = reason; this.promise.$$state.status = 2; scheduleProcessQueue(this.promise.$$state); }, notify: function(progress) { var callbacks = this.promise.$$state.pending; if ((this.promise.$$state.status <= 0) && callbacks && callbacks.length) { var callback, result; for (var i = 0, ii = callbacks.length; i < ii; i++) { result = callbacks[i][0]; callback = callbacks[i][3]; try { result.notify(isFunction(callback) ? callback(progress) : progress); } catch (e) { exceptionHandler(e); } } } * @kind function var result = new Deferred(); var makePromise = function makePromise(value, resolved) { var result = new Deferred(); if (resolved) { result.resolve(value); } else { result.reject(value); } return result.promise; var handleCallback = function handleCallback(value, isResolved, callback) { var callbackOutput = null; try { if (isFunction(callback)) callbackOutput = callback(); } catch (e) { return makePromise(e, false); } if (isPromiseLike(callbackOutput)) { return callbackOutput.then(function() { return makePromise(value, isResolved); }, function(error) { return makePromise(error, false); }); } else { return makePromise(value, isResolved); } }; * @kind function var when = function(value, callback, errback, progressBack) { var result = new Deferred(); result.resolve(value); return result.promise.then(callback, errback, progressBack); * @kind function var deferred = new Deferred(), when(promise).then(function(value) { var $Q = function Q(resolver) { if (!isFunction(resolver)) { throw $qMinErr('norslvr', ""Expected resolverFn, got '{0}'"", resolver); } if (!(this instanceof Q)) { // More useful when $Q is the Promise itself. return new Q(resolver); } var deferred = new Deferred(); function resolveFn(value) { deferred.resolve(value); } function rejectFn(reason) { deferred.reject(reason); } resolver(resolveFn, rejectFn); return deferred.promise; $Q.defer = defer; $Q.reject = reject; $Q.when = when; $Q.all = all; return $Q;function $$RAFProvider() { //rAF $window.webkitRequestAnimationFrame; * items to the array at the beginning (unshift) instead of at the end (push)function $RootScopeProvider() { var applyAsyncId = null; function($injector, $exceptionHandler, $parse, $browser) { * When interacting with `Scope` in tests, additional helper methods are available on the * instances of `Scope` type. See {@link ngMock.$rootScope.Scope ngMock Scope} for additional * details. * this.$root = this; this.$$isolateBindings = null; * * @description * Unique scope ID (monotonically increasing) useful for debugging. /** * @ngdoc property * @name $rootScope.Scope#$parent * * @description * Reference to the parent scope. */ /** * @ngdoc property * @name $rootScope.Scope#$root * * @description * Reference to the root scope. */ * @kind function * The parent scope will propagate the {@link ng.$rootScope.Scope#$digest $digest()} event. * The scope can be removed from the scope hierarchy using {@link ng.$rootScope.Scope#$destroy $destroy()}. * @param {Scope} [parent=this] The {@link ng.$rootScope.Scope `Scope`} that will be the `$parent` * of the newly created scope. Defaults to `this` scope if not provided. * This is used when creating a transclude scope to correctly place it * in the scope hierarchy while maintaining the correct prototypical * inheritance. * $new: function(isolate, parent) { var child; parent = parent || this; // Only create a child scope class if somebody asks for one, // but cache it to allow the VM to optimize lookups. if (!this.$$ChildScope) { this.$$ChildScope = function ChildScope() { this.$$watchers = this.$$nextSibling = this.$$childHead = this.$$childTail = null; this.$$listeners = {}; this.$$listenerCount = {}; this.$id = nextUid(); this.$$ChildScope = null; }; this.$$ChildScope.prototype = this; } child = new this.$$ChildScope(); child.$parent = parent; child.$$prevSibling = parent.$$childTail; if (parent.$$childHead) { parent.$$childTail.$$nextSibling = child; parent.$$childTail = child; parent.$$childHead = parent.$$childTail = child; // When the new scope is not isolated or we inherit from `this`, and // the parent scope is destroyed, the property `$$destroyed` is inherited // prototypically. In all other cases, this property needs to be set // when the parent scope is destroyed. // The listener needs to be added after the parent is set if (isolate || parent != this) child.$on('$destroy', destroyChild); function destroyChild() { child.$$destroyed = true; } * @kind function * see below). Inequality is determined according to reference inequality, * [strict comparison](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Comparison_Operators) * via the `!==` Javascript operator, unless `objectEquality == true` * (see next point) * - When `objectEquality == true`, inequality of the `watchExpression` is determined * according to the {@link angular.equals} function. To save the value of the object for * later comparison, the {@link angular.copy} function is used. This therefore means that * watching complex objects will have adverse memory and performance implications. // the listener is always called during the first $digest loop after it was registered expect(scope.counter).toEqual(1); scope.$digest(); // but now it will not be called unless the value changes expect(scope.counter).toEqual(1); expect(scope.counter).toEqual(2); // Using a function as a watchExpression // This function returns the value being watched. It is called for each turn of the $digest loop // This is the change listener, called when the value returned from the above function changes * @param {function(newVal, oldVal, scope)} listener Callback called whenever the value * of `watchExpression` changes. * - `newVal` contains the current value of the `watchExpression` * - `oldVal` contains the previous value of the `watchExpression` * - `scope` refers to the current scope var get = $parse(watchExp); if (get.$$watchDelegate) { return get.$$watchDelegate(this, listener, objectEquality, get); } watcher.fn = noop; return function deregisterWatch() { /** * @ngdoc method * @name $rootScope.Scope#$watchGroup * @kind function * * @description * A variant of {@link ng.$rootScope.Scope#$watch $watch()} where it watches an array of `watchExpressions`. * If any one expression in the collection changes the `listener` is executed. * * - The items in the `watchExpressions` array are observed via standard $watch operation and are examined on every * call to $digest() to see if any items changes. * - The `listener` is called whenever any expression in the `watchExpressions` array changes. * * @param {Array.<string|Function(scope)>} watchExpressions Array of expressions that will be individually * watched using {@link ng.$rootScope.Scope#$watch $watch()} * * @param {function(newValues, oldValues, scope)} listener Callback called whenever the return value of any * expression in `watchExpressions` changes * The `newValues` array contains the current values of the `watchExpressions`, with the indexes matching * those of `watchExpression` * and the `oldValues` array contains the previous values of the `watchExpressions`, with the indexes matching * those of `watchExpression` * The `scope` refers to the current scope. * @returns {function()} Returns a de-registration function for all listeners. */ $watchGroup: function(watchExpressions, listener) { var oldValues = new Array(watchExpressions.length); var newValues = new Array(watchExpressions.length); var deregisterFns = []; var self = this; var changeReactionScheduled = false; var firstRun = true; if (!watchExpressions.length) { // No expressions means we call the listener ASAP var shouldCall = true; self.$evalAsync(function() { if (shouldCall) listener(newValues, newValues, self); }); return function deregisterWatchGroup() { shouldCall = false; }; } if (watchExpressions.length === 1) { // Special case size of one return this.$watch(watchExpressions[0], function watchGroupAction(value, oldValue, scope) { newValues[0] = value; oldValues[0] = oldValue; listener(newValues, (value === oldValue) ? newValues : oldValues, scope); }); } forEach(watchExpressions, function(expr, i) { var unwatchFn = self.$watch(expr, function watchGroupSubAction(value, oldValue) { newValues[i] = value; oldValues[i] = oldValue; if (!changeReactionScheduled) { changeReactionScheduled = true; self.$evalAsync(watchGroupAction); } }); deregisterFns.push(unwatchFn); }); function watchGroupAction() { changeReactionScheduled = false; if (firstRun) { firstRun = false; listener(newValues, newValues, self); } else { listener(newValues, oldValues, self); } } return function deregisterWatchGroup() { while (deregisterFns.length) { deregisterFns.shift()(); } }; }, * @kind function $watchCollectionInterceptor.$stateful = true; var changeDetector = $parse(obj, $watchCollectionInterceptor); function $watchCollectionInterceptor(_value) { newValue = _value; var newLength, key, bothNaN, newItem, oldItem; // If the new value is undefined, then return undefined as the watch may be a one-time watch if (isUndefined(newValue)) return; oldItem = oldValue[i]; newItem = newValue[i]; bothNaN = (oldItem !== oldItem) && (newItem !== newItem); if (!bothNaN && (oldItem !== newItem)) { oldValue[i] = newItem; newItem = newValue[key]; oldItem = oldValue[key]; if (key in oldValue) { bothNaN = (oldItem !== oldItem) && (newItem !== newItem); if (!bothNaN && (oldItem !== newItem)) { oldValue[key] = newItem; oldValue[key] = newItem; for (key in oldValue) { if (!newValue.hasOwnProperty(key)) { return this.$watch(changeDetector, $watchCollectionAction); * @kind function * a {@link ng.$compileProvider#directive directive}), which will force a `$digest()`. // the listener is always called during the first $digest loop after it was registered expect(scope.counter).toEqual(1); scope.$digest(); // but now it will not be called unless the value changes expect(scope.counter).toEqual(1); expect(scope.counter).toEqual(2); // Check for changes to browser url that happened in sync before the call to $digest $browser.$$checkUrlChange(); if (this === $rootScope && applyAsyncId !== null) { // If this is the root scope, and $applyAsync has scheduled a deferred $apply(), then // cancel the scheduled $apply and flush the queue of expressions to be evaluated. $browser.defer.cancel(applyAsyncId); flushApplyAsync(); } while (asyncQueue.length) { asyncTask.scope.$eval(asyncTask.expression, asyncTask.locals); : (typeof value === 'number' && typeof last === 'number' watch.last = watch.eq ? copy(value, null) : value; watchLog[logIdx].push({ msg: isFunction(watch.exp) ? 'fn: ' + (watch.exp.name || watch.exp.toString()) : watch.exp, newVal: value, oldVal: last }); while (current !== target && !(next = current.$$nextSibling)) { if ((dirty || asyncQueue.length) && !(ttl--)) { TTL, watchLog); while (postDigestQueue.length) { * @kind function for (var eventName in this.$$listenerCount) { decrementListenerCount(this, this.$$listenerCount[eventName], eventName); } // Disable listeners, watchers and apply/digest methods this.$destroy = this.$digest = this.$apply = this.$evalAsync = this.$applyAsync = noop; this.$on = this.$watch = this.$watchGroup = function() { return noop; }; this.$$listeners = {}; this.$$childTail = this.$root = this.$$watchers = null; * @kind function * @kind function * @param {(object)=} locals Local variables object, useful for overriding values in scope. $evalAsync: function(expr, locals) { if (!$rootScope.$$phase && !asyncQueue.length) { if (asyncQueue.length) { asyncQueue.push({scope: this, expression: expr, locals: locals}); $$postDigest: function(fn) { postDigestQueue.push(fn); * @kind function * @name $rootScope.Scope#$applyAsync * @kind function * * @description * Schedule the invokation of $apply to occur at a later time. The actual time difference * varies across browsers, but is typically around ~10 milliseconds. * * This can be used to queue up multiple expressions which need to be evaluated in the same * digest. * * @param {(string|function())=} exp An angular expression to be executed. * * - `string`: execute using the rules as defined in {@link guide/expression expression}. * - `function(scope)`: execute the function with current `scope` parameter. */ $applyAsync: function(expr) { var scope = this; expr && applyAsyncQueue.push($applyAsyncExpression); scheduleApplyAsync(); function $applyAsyncExpression() { scope.$eval(expr); } }, /** * @ngdoc method * @kind function * - `currentScope` - `{Scope}`: the scope that is currently handling the event. Once the * event propagates through the scope hierarchy, this property is set to null. var indexOfListener = namedListeners.indexOf(listener); if (indexOfListener !== -1) { namedListeners[indexOfListener] = null; decrementListenerCount(self, 1, name); } * @kind function for (i = 0, length = namedListeners.length; i < length; i++) { if (stopPropagation) { event.currentScope = null; return event; } event.currentScope = null; * @kind function }; if (!target.$$listenerCount[name]) return event; var listenerArgs = concat([event], arguments, 1), for (i = 0, length = listeners.length; i < length; i++) { } catch (e) { while (current !== target && !(next = current.$$nextSibling)) { event.currentScope = null; //The internal queues. Expose them on the $rootScope for debugging/testing purposes. var asyncQueue = $rootScope.$$asyncQueue = []; var postDigestQueue = $rootScope.$$postDigestQueue = []; var applyAsyncQueue = $rootScope.$$applyAsyncQueue = []; function flushApplyAsync() { while (applyAsyncQueue.length) { try { applyAsyncQueue.shift()(); } catch (e) { $exceptionHandler(e); } } applyAsyncId = null; } function scheduleApplyAsync() { if (applyAsyncId === null) { applyAsyncId = $browser.defer(function() { $rootScope.$apply(flushApplyAsync); }); } } imgSrcSanitizationWhitelist = /^\s*((https?|ftp|file|blob):|data:image\/)/; normalizedVal = urlResolve(uri).href; if (normalizedVal !== '' && !normalizedVal.match(regex)) { return 'unsafe:' + normalizedVal; * @kind function * ``` * angular.module('myApp', []).config(function($sceDelegateProvider) { * $sceDelegateProvider.resourceUrlWhitelist([ * // Allow same origin resource loads. * 'self', * // Allow loading from our assets domain. Notice the difference between * and **. * 'http://srv*.assets.example.com/**' * ]); * // The blacklist overrides the whitelist so the open redirect here is blocked. * $sceDelegateProvider.resourceUrlBlacklist([ * 'http://myapp.example.com/clickThru**' * ]); * }); * ``` * @kind function this.resourceUrlWhitelist = function(value) { * @kind function this.resourceUrlBlacklist = function(value) { * @kind function * Note: When enabled (the default), IE<11 in quirks mode is not supported. In this mode, IE<11 allow * ``` * <input ng-model=""userHtml""> * <div ng-bind-html=""userHtml""></div> * ``` * ng.$sce#parseAs $sce.parseAs} rather than `$parse` to watch attribute bindings, which performs the * ``` * var ngBindHtmlDirective = ['$sce', function($sce) { * return function(scope, element, attr) { * scope.$watch($sce.parseAsHtml(attr.ngBindHtml), function(value) { * element.html(value || ''); * }); * }; * }]; * ``` * ## This feels like too much overhead * | `$sce.HTML` | For HTML that's safe to source into the application. The {@link ng.directive:ngBindHtml ngBindHtml} directive uses this context for bindings. If an unsafe value is encountered and the {@link ngSanitize $sanitize} module is present this will sanitize the value instead of throwing an error. | * not have been the intention.) Its usage at the very end of the path is ok. (e.g. * <example module=""mySceApp"" deps=""angular-sanitize.js""> * <file name=""index.html""> * <div ng-controller=""AppController as myCtrl""> * <i ng-bind-html=""myCtrl.explicitlyTrustedHtml"" id=""explicitlyTrustedHtml""></i><br><br> * <b>User comments</b><br> * By default, HTML that isn't explicitly trusted (e.g. Alice's comment) is sanitized when * $sanitize is available. If $sanitize isn't available, this results in an error instead of an * exploit. * <div class=""well""> * <div ng-repeat=""userComment in myCtrl.userComments""> * <b>{{userComment.name}}</b>: * <span ng-bind-html=""userComment.htmlComment"" class=""htmlComment""></span> * <br> * </div> * </div> * </div> * </file> * * <file name=""script.js""> * angular.module('mySceApp', ['ngSanitize']) * .controller('AppController', ['$http', '$templateCache', '$sce', * function($http, $templateCache, $sce) { * var self = this; * $http.get(""test_data.json"", {cache: $templateCache}).success(function(userComments) { * self.userComments = userComments; * }); * self.explicitlyTrustedHtml = $sce.trustAsHtml( * '<span onmouseover=""this.textContent=&quot;Explicitly trusted HTML bypasses ' + * 'sanitization.&quot;"">Hover over this text.</span>'); * }]); * </file> * * <file name=""test_data.json""> * [ * { ""name"": ""Alice"", * ""htmlComment"": * ""<span onmouseover='this.textContent=\""PWN3D!\""'>Is <i>anyone</i> reading this?</span>"" * }, * { ""name"": ""Bob"", * ""htmlComment"": ""<i>Yes!</i> Am I the only other one?"" * } * ] * </file> * * <file name=""protractor.js"" type=""protractor""> * describe('SCE doc demo', function() { * it('should sanitize untrusted values', function() { * expect(element.all(by.css('.htmlComment')).first().getInnerHtml()) * .toBe('<span>Is <i>anyone</i> reading this?</span>'); * }); * * it('should NOT sanitize explicitly trusted values', function() { * expect(element(by.id('explicitlyTrustedHtml')).getInnerHtml()).toBe( * '<span onmouseover=""this.textContent=&quot;Explicitly trusted HTML bypasses ' + * 'sanitization.&quot;"">Hover over this text.</span>'); * }); * }); * </file> * </example> * ``` * angular.module('myAppWithSceDisabledmyApp', []).config(function($sceProvider) { * // Completely disable SCE. For demonstration purposes only! * // Do not use in new projects. * $sceProvider.enabled(false); * }); * ``` * @kind function this.enabled = function(value) { this.$get = ['$parse', '$sceDelegate', function( $parse, $sceDelegate) { // Prereq: Ensure that we're not running in IE<11 quirks mode. In that mode, IE < 11 allow if (enabled && msie < 8) { 'Strict Contextual Escaping does not support Internet Explorer version < 11 in quirks ' + var sce = shallowCopy(SCE_CONTEXTS); * @kind function sce.isEnabled = function() { * @name $sce#parseAs return $parse(expr, function(value) { return sce.getTrusted(type, value); }); * {@link ng.$sce#parseAs `$sce.parseAs($sce.HTML, value)`} * {@link ng.$sce#parseAs `$sce.parseAs($sce.CSS, value)`} * {@link ng.$sce#parseAs `$sce.parseAs($sce.URL, value)`} * {@link ng.$sce#parseAs `$sce.parseAs($sce.RESOURCE_URL, value)`} * {@link ng.$sce#parseAs `$sce.parseAs($sce.JS, value)`} forEach(SCE_CONTEXTS, function(enumValue, name) { sce[camelCase(""parse_as_"" + lName)] = function(expr) { sce[camelCase(""get_trusted_"" + lName)] = function(value) { sce[camelCase(""trust_as_"" + lName)] = function(value) { vendorRegex = /^(Moz|webkit|ms)(?=[A-Z])/, for (var prop in bodyStyle) { if (match = vendorRegex.exec(prop)) { if (!vendorPrefix) { if (android && (!transitions || !animations)) { // IE10+ implements 'input' event but it erroneously fires under various situations, // e.g. when placeholder changes, or a form is focused. if (event === 'input' && msie <= 11) return false; transitions: transitions, animations: animations, android: androidvar $compileMinErr = minErr('$compile'); /** * @ngdoc service * @name $templateRequest * * @description * The `$templateRequest` service downloads the provided template using `$http` and, upon success, * stores the contents inside of `$templateCache`. If the HTTP request fails or the response data * of the HTTP request is empty then a `$compile` error will be thrown (the exception can be thwarted * by setting the 2nd parameter of the function to true). * * @param {string} tpl The HTTP request template URL * @param {boolean=} ignoreRequestError Whether or not to ignore the exception when the request fails or the template is empty * * @return {Promise} the HTTP Promise for the given. * * @property {number} totalPendingRequests total amount of pending template requests being downloaded. */ function $TemplateRequestProvider() { this.$get = ['$templateCache', '$http', '$q', function($templateCache, $http, $q) { function handleRequestFn(tpl, ignoreRequestError) { var self = handleRequestFn; self.totalPendingRequests++; var transformResponse = $http.defaults && $http.defaults.transformResponse; if (isArray(transformResponse)) { transformResponse = transformResponse.filter(function(transformer) { return transformer !== defaultHttpResponseTransform; }); } else if (transformResponse === defaultHttpResponseTransform) { transformResponse = null; } var httpOptions = { cache: $templateCache, transformResponse: transformResponse }; return $http.get(tpl, httpOptions) .then(function(response) { self.totalPendingRequests--; return response.data; }, handleError); function handleError(resp) { self.totalPendingRequests--; if (!ignoreRequestError) { throw $compileMinErr('tpload', 'Failed to load template: {0}', tpl); } return $q.reject(resp); } } handleRequestFn.totalPendingRequests = 0; return handleRequestFn; }]; } function $$TestabilityProvider() { this.$get = ['$rootScope', '$browser', '$location', function($rootScope, $browser, $location) { /** * @name $testability * * @description * The private $$testability service provides a collection of methods for use when debugging * or by automated test and debugging tools. */ var testability = {}; /** * @name $$testability#findBindings * * @description * Returns an array of elements that are bound (via ng-bind or {{}}) * to expressions matching the input. * * @param {Element} element The element root to search from. * @param {string} expression The binding expression to match. * @param {boolean} opt_exactMatch If true, only returns exact matches * for the expression. Filters and whitespace are ignored. */ testability.findBindings = function(element, expression, opt_exactMatch) { var bindings = element.getElementsByClassName('ng-binding'); var matches = []; forEach(bindings, function(binding) { var dataBinding = angular.element(binding).data('$binding'); if (dataBinding) { forEach(dataBinding, function(bindingName) { if (opt_exactMatch) { var matcher = new RegExp('(^|\\s)' + escapeForRegexp(expression) + '(\\s|\\||$)'); if (matcher.test(bindingName)) { matches.push(binding); } } else { if (bindingName.indexOf(expression) != -1) { matches.push(binding); } } }); } }); return matches; }; /** * @name $$testability#findModels * * @description * Returns an array of elements that are two-way found via ng-model to * expressions matching the input. * * @param {Element} element The element root to search from. * @param {string} expression The model expression to match. * @param {boolean} opt_exactMatch If true, only returns exact matches * for the expression. */ testability.findModels = function(element, expression, opt_exactMatch) { var prefixes = ['ng-', 'data-ng-', 'ng\\:']; for (var p = 0; p < prefixes.length; ++p) { var attributeEquals = opt_exactMatch ? '=' : '*='; var selector = '[' + prefixes[p] + 'model' + attributeEquals + '""' + expression + '""]'; var elements = element.querySelectorAll(selector); if (elements.length) { return elements; } } }; /** * @name $$testability#getLocation * * @description * Shortcut for getting the location in a browser agnostic way. Returns * the path, search, and hash. (e.g. /path?a=b#hash) */ testability.getLocation = function() { return $location.url(); }; /** * @name $$testability#setLocation * * @description * Shortcut for navigating to a location without doing a full page reload. * * @param {string} url The location url (path, search and hash, * e.g. /path?a=b#hash) to go to. */ testability.setLocation = function(url) { if (url !== $location.url()) { $location.url(url); $rootScope.$digest(); } }; /** * @name $$testability#whenStable * * @description * Calls the callback when $timeout and $http requests are completed. * * @param {function} callback */ testability.whenStable = function(callback) { $browser.notifyWhenNoOutstandingRequests(callback); }; return testability; }]; } this.$get = ['$rootScope', '$browser', '$q', '$$q', '$exceptionHandler', function($rootScope, $browser, $q, $$q, $exceptionHandler) { var skipApply = (isDefined(invokeApply) && !invokeApply), deferred = (skipApply ? $$q : $q).defer(), } catch (e) {var originUrl = urlResolve(window.location.href); * @kind functionfunction urlResolve(url) { <example module=""windowExample""> angular.module('windowExample', []) .controller('ExampleController', ['$scope', '$window', function($scope, $window) { $scope.greeting = 'Hello, World!'; $scope.doGreeting = function(greeting) { }; }]); <div ng-controller=""ExampleController"">function $WindowProvider() {/* global currencyFilter: true, dateFilter: true, filterFilter: true, jsonFilter: true, limitToFilter: true, lowercaseFilter: true, numberFilter: true, orderByFilter: true, uppercaseFilter: true, */ * @kind function * @example <example name=""$filter"" module=""filterExample""> <file name=""index.html""> <div ng-controller=""MainCtrl""> <h3>{{ originalText }}</h3> <h3>{{ filteredText }}</h3> </div> </file> <file name=""script.js""> angular.module('filterExample', []) .controller('MainCtrl', function($scope, $filter) { $scope.originalText = 'hello'; $scope.filteredText = $filter('uppercase')($scope.originalText); }); </file> </example> */ * @name $filterProvider#register if (isObject(name)) { * @kind function * as described above. The predicate can be negated by prefixing the string with `!`. * For Example `{name: ""!M""}` predicate will return an array of items which have property `name` * not containing ""M"". * - `function(value, index)`: A predicate function can be used to write arbitrary filters. The * function is called for each element of `array`. The final result is an array of those * elements that the predicate returned true for. * - `function(actual, expected)`: * The function will be given the object value and the predicate value to compare and * should return true if the item should be included in filtered result. * - `true`: A shorthand for `function(actual, expected) { return angular.equals(expected, actual)}`. * this is essentially strict comparison of expected and actual. * - `false|undefined`: A short hand for a function which will look for a substring match in case * insensitive way. var predicateFn; var matchAgainstAnyProp; predicateFn = expression; break; case 'boolean': case 'number': case 'string': matchAgainstAnyProp = true; //jshint -W086 case 'object': //jshint +W086 predicateFn = createPredicateFn(expression, comparator, matchAgainstAnyProp); return array.filter(predicateFn);// Helper functions for `filterFilter` function createPredicateFn(expression, comparator, matchAgainstAnyProp) { var predicateFn; if (comparator === true) { comparator = equals; } else if (!isFunction(comparator)) { comparator = function(actual, expected) { if (isObject(actual) || isObject(expected)) { // Prevent an object to be considered equal to a string like `'[object'` return false; } actual = lowercase('' + actual); expected = lowercase('' + expected); return actual.indexOf(expected) !== -1; }; } predicateFn = function(item) { return deepCompare(item, expression, comparator, matchAgainstAnyProp); }; return predicateFn; } function deepCompare(actual, expected, comparator, matchAgainstAnyProp) { var actualType = typeof actual; var expectedType = typeof expected; if ((expectedType === 'string') && (expected.charAt(0) === '!')) { return !deepCompare(actual, expected.substring(1), comparator, matchAgainstAnyProp); } else if (actualType === 'array') { // In case `actual` is an array, consider it a match // if ANY of it's items matches `expected` return actual.some(function(item) { return deepCompare(item, expected, comparator, matchAgainstAnyProp); }); } switch (actualType) { case 'object': var key; if (matchAgainstAnyProp) { for (key in actual) { if ((key.charAt(0) !== '$') && deepCompare(actual[key], expected, comparator)) { return true; } } return false; } else if (expectedType === 'object') { for (key in expected) { var expectedVal = expected[key]; if (isFunction(expectedVal)) { continue; } var keyIsDollar = key === '$'; var actualVal = keyIsDollar ? actual : actual[key]; if (!deepCompare(actualVal, expectedVal, comparator, keyIsDollar)) { return false; } } return true; } else { return comparator(actual, expected); } break; case 'function': return false; default: return comparator(actual, expected); } } * @kind function * @param {number=} fractionSize Number of decimal places to round the amount to, defaults to default max fraction size for current locale <example module=""currencyExample""> angular.module('currencyExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.amount = 1234.56; }]); <div ng-controller=""ExampleController""> custom currency identifier (USD$): <span id=""currency-custom"">{{amount | currency:""USD$""}}</span> no fractions (0): <span id=""currency-no-fractions"">{{amount | currency:""USD$"":0}}</span> expect(element(by.id('currency-custom')).getText()).toBe('USD$1,234.56'); expect(element(by.id('currency-no-fractions')).getText()).toBe('USD$1,235'); expect(element(by.id('currency-custom')).getText()).toBe('(USD$1,234.00)'); expect(element(by.id('currency-no-fractions')).getText()).toBe('(USD$1,234)'); return function(amount, currencySymbol, fractionSize) { if (isUndefined(currencySymbol)) { currencySymbol = formats.CURRENCY_SYM; } if (isUndefined(fractionSize)) { fractionSize = formats.PATTERNS[1].maxFrac; } // if null or undefined pass it through return (amount == null) ? amount : formatNumber(amount, formats.PATTERNS[1], formats.GROUP_SEP, formats.DECIMAL_SEP, fractionSize). replace(/\u00A4/g, currencySymbol); * @kind function <example module=""numberFilterExample""> angular.module('numberFilterExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.val = 1234.56789; }]); <div ng-controller=""ExampleController""> // if null or undefined pass it through return (number == null) ? number : formatNumber(number, formats.PATTERNS[0], formats.GROUP_SEP, formats.DECIMAL_SEP, fractionSize); if (!isFinite(number) || isObject(number)) return ''; number = 0; // safely round numbers in JS without hitting imprecisions of floating-point arithmetics // inspired by: // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/round number = +(Math.round(+(number.toString() + 'e' + fractionSize)).toString() + 'e' + -fractionSize); if ((pos - i) % group === 0 && i !== 0) { if ((whole.length - i) % lgroup === 0 && i !== 0) { while (fraction.length < fractionSize) { if (fractionSize > 0 && number < 1) { number = parseFloat(formatedText); if (number === 0) { isNegative = false; } parts.push(isNegative ? pattern.negPre : pattern.posPre, formatedText, isNegative ? pattern.negSuf : pattern.posSuf); while (num.length < digits) num = '0' + num; if (value === 0 && offset == -12) value = 12;function getFirstThursdayOfYear(year) { // 0 = index of January var dayOfWeekOnFirst = (new Date(year, 0, 1)).getDay(); // 4 = index of Thursday (+1 to account for 1st = 5) // 11 = index of *next* Thursday (+1 account for 1st = 12) return new Date(year, 0, ((dayOfWeekOnFirst <= 4) ? 5 : 12) - dayOfWeekOnFirst); } function getThursdayThisWeek(datetime) { return new Date(datetime.getFullYear(), datetime.getMonth(), // 4 = index of Thursday datetime.getDate() + (4 - datetime.getDay())); } function weekGetter(size) { return function(date) { var firstThurs = getFirstThursdayOfYear(date.getFullYear()), thisThurs = getThursdayThisWeek(date); var diff = +thisThurs - +firstThurs, result = 1 + Math.round(diff / 6.048e8); // 6.048e8 ms per week return padNumber(result, size); }; } Z: timeZoneGetter, ww: weekGetter(2), w: weekGetter(1)var DATE_FORMATS_SPLIT = /((?:[^yMdHhmsaZEw']+)|(?:'(?:[^']|'')*')|(?:E+|y+|M+|d+|H+|h+|m+|s+|a|Z|w+))(.*)/, * @kind function * * `'hh'`: Hour in AM/PM, padded (01-12) * * `'h'`: Hour in AM/PM, (1-12) * * `'a'`: AM/PM marker * * `'ww'`: Week of year, padded (00-53). Week 01 is the week with the first Thursday of the year * * `'w'`: Week of year (0-53). Week 1 is the week with the first Thursday of the year * (e.g. Sep 3, 2010 12:05:08 PM) * * `'short'`: equivalent to `'M/d/yy h:mm a'` for en_US locale (e.g. 9/3/10 12:05 PM) * * `'fullDate'`: equivalent to `'EEEE, MMMM d, y'` for en_US locale * * `'mediumTime'`: equivalent to `'h:mm:ss a'` for en_US locale (e.g. 12:05:08 PM) * * `'shortTime'`: equivalent to `'h:mm a'` for en_US locale (e.g. 12:05 PM) * `format` string can contain literal values. These need to be escaped by surrounding with single quotes (e.g. * `""h 'in the morning'""`). In order to output a single quote, escape it - i.e., two single quotes in a sequence * number) or various ISO 8601 datetime string formats (e.g. yyyy-MM-ddTHH:mm:ss.sssZ and its * @param {string=} timezone Timezone to be used for formatting. Right now, only `'UTC'` is supported. * If not specified, the timezone of the browser will be used. <span ng-non-bindable>{{1288323623006 | date:""MM/dd/yyyy 'at' h:mma""}}</span>: <span>{{'1288323623006' | date:""MM/dd/yyyy 'at' h:mma""}}</span><br> expect(element(by.binding(""'1288323623006' | date:\""MM/dd/yyyy 'at' h:mma\"""")).getText()). toMatch(/10\/2\d\/2010 at \d{1,2}:\d{2}(AM|PM)/); var h = int(match[4] || 0) - tzHour; var m = int(match[5] || 0) - tzMin; var s = int(match[6] || 0); var ms = Math.round(parseFloat('0.' + (match[7] || 0)) * 1000); return function(date, format, timezone) { date = NUMBER_STRING.test(date) ? int(date) : jsonStringToDate(date); while (format) { if (timezone && timezone === 'UTC') { date = new Date(date.getTime()); date.setMinutes(date.getMinutes() + date.getTimezoneOffset()); } forEach(parts, function(value) { * @kind function * @param {number=} spacing The number of spaces to use per indentation, defaults to 2. <pre id=""default-spacing"">{{ {'name':'value'} | json }}</pre> <pre id=""custom-spacing"">{{ {'name':'value'} | json:4 }}</pre> expect(element(by.id('default-spacing')).getText()).toMatch(/\{\n ""name"": ?""value""\n}/); expect(element(by.id('custom-spacing')).getText()).toMatch(/\{\n ""name"": ?""value""\n}/); return function(object, spacing) { if (isUndefined(spacing)) { spacing = 2; } return toJson(object, spacing); * @kind function * @kind function * @kind function * are taken from either the beginning or the end of the source array, string or number, as specified by * the value and sign (positive or negative) of `limit`. If a number is used as input, it is * converted to a string. * @param {Array|string|number} input Source array, string or number to be limited. <example module=""limitToExample""> angular.module('limitToExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.numbers = [1,2,3,4,5,6,7,8,9]; $scope.letters = ""abcdefghi""; $scope.longNumber = 2345432342; $scope.numLimit = 3; $scope.letterLimit = 3; $scope.longNumberLimit = 3; }]); <div ng-controller=""ExampleController""> Limit {{numbers}} to: <input type=""number"" step=""1"" ng-model=""numLimit""> Limit {{letters}} to: <input type=""number"" step=""1"" ng-model=""letterLimit""> Limit {{longNumber}} to: <input type=""number"" step=""1"" ng-model=""longNumberLimit""> <p>Output long number: {{ longNumber | limitTo:longNumberLimit }}</p> var longNumberLimitInput = element(by.model('longNumberLimit')); var limitedLongNumber = element(by.binding('longNumber | limitTo:longNumberLimit')); expect(longNumberLimitInput.getAttribute('value')).toBe('3'); expect(limitedLongNumber.getText()).toEqual('Output long number: 234'); // There is a bug in safari and protractor that doesn't like the minus key // it('should update the output when -3 is entered', function() { // numLimitInput.clear(); // numLimitInput.sendKeys('-3'); // letterLimitInput.clear(); // letterLimitInput.sendKeys('-3'); // longNumberLimitInput.clear(); // longNumberLimitInput.sendKeys('-3'); // expect(limitedNumbers.getText()).toEqual('Output numbers: [7,8,9]'); // expect(limitedLetters.getText()).toEqual('Output letters: ghi'); // expect(limitedLongNumber.getText()).toEqual('Output long number: 342'); // }); longNumberLimitInput.clear(); longNumberLimitInput.sendKeys('100'); expect(limitedLongNumber.getText()).toEqual('Output long number: 2345432342');*/ function limitToFilter() { if (isNumber(input)) input = input.toString(); if (Math.abs(Number(limit)) === Infinity) { limit = Number(limit); } else { limit = int(limit); } for (; i < n; i++) { * @kind function * Orders a specified `array` by the `expression` predicate. It is ordered alphabetically * for strings and numerically for numbers. Note: if you notice numbers are not being sorted * correctly, make sure they are actually being saved as numbers and not strings. * @param {function(*)|string|Array.<(function(*)|string)>=} expression A predicate to be * - `string`: An Angular expression. The result of this expression is used to compare elements * (for example `name` to sort by a property called `name` or `name.substr(0, 3)` to sort by * 3 first characters of a property called `name`). The result of a constant expression * is interpreted as a property name to be used in comparisons (for example `""special name""` * to sort object by the value of their `special name` property). An expression can be * optionally prefixed with `+` or `-` to control ascending or descending sort order * (for example, `+name` or `-name`). If no property is provided, (e.g. `'+'`) then the array * element itself is used to compare where sorting. * If the predicate is missing or empty then it defaults to `'+'`. * <example module=""orderByExample""> angular.module('orderByExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.friends = [{name:'John', phone:'555-1212', age:10}, {name:'Mary', phone:'555-9876', age:19}, {name:'Mike', phone:'555-4321', age:21}, {name:'Adam', phone:'555-5678', age:35}, {name:'Julie', phone:'555-8765', age:29}]; $scope.predicate = '-age'; }]); <div ng-controller=""ExampleController""> * * It's also possible to call the orderBy filter manually, by injecting `$filter`, retrieving the * filter routine with `$filter('orderBy')`, and calling the returned filter routine with the * desired parameters. * * Example: * * @example <example module=""orderByExample""> <file name=""index.html""> <div ng-controller=""ExampleController""> <table class=""friend""> <tr> <th><a href="""" ng-click=""reverse=false;order('name', false)"">Name</a> (<a href="""" ng-click=""order('-name',false)"">^</a>)</th> <th><a href="""" ng-click=""reverse=!reverse;order('phone', reverse)"">Phone Number</a></th> <th><a href="""" ng-click=""reverse=!reverse;order('age',reverse)"">Age</a></th> </tr> <tr ng-repeat=""friend in friends""> <td>{{friend.name}}</td> <td>{{friend.phone}}</td> <td>{{friend.age}}</td> </tr> </table> </div> </file> <file name=""script.js""> angular.module('orderByExample', []) .controller('ExampleController', ['$scope', '$filter', function($scope, $filter) { var orderBy = $filter('orderBy'); $scope.friends = [ { name: 'John', phone: '555-1212', age: 10 }, { name: 'Mary', phone: '555-9876', age: 19 }, { name: 'Mike', phone: '555-4321', age: 21 }, { name: 'Adam', phone: '555-5678', age: 35 }, { name: 'Julie', phone: '555-8765', age: 29 } ]; $scope.order = function(predicate, reverse) { $scope.friends = orderBy($scope.friends, predicate, reverse); }; $scope.order('-age',false); }]); </file> </example>function orderByFilter($parse) { if (!(isArrayLike(array))) return array; sortPredicate = isArray(sortPredicate) ? sortPredicate : [sortPredicate]; if (sortPredicate.length === 0) { sortPredicate = ['+']; } sortPredicate = sortPredicate.map(function(predicate) { if (predicate === '') { // Effectively no predicate was passed so we compare identity return reverseComparator(function(a, b) { return compare(a, b); }, descending); } return reverseComparator(function(a, b) { return reverseComparator(function(a, b) { return slice.call(array).sort(reverseComparator(comparator, reverseOrder)); function comparator(o1, o2) { for (var i = 0; i < sortPredicate.length; i++) { return descending ? function(a, b) {return comp(b,a);} function isPrimitive(value) { switch (typeof value) { case 'number': /* falls through */ case 'boolean': /* falls through */ case 'string': return true; default: return false; } } function objectToString(value) { if (value === null) return 'null'; if (typeof value.toString === 'function') { value = value.toString(); if (isPrimitive(value)) return value; } if (typeof value.valueOf === 'function') { value = value.valueOf(); if (isPrimitive(value)) return value; } return ''; } function compare(v1, v2) { if (t1 === t2 && t1 === ""object"") { v1 = objectToString(v1); v2 = objectToString(v2); } if (t1 === t2) { if (t1 === ""string"") { element.on('click', function(event) { * and will most likely return a 404 error. The `ngHref` directive * solves this problem. * <a href=""http://www.gravatar.com/avatar/{{hash}}"">link1</a> * <a ng-href=""http://www.gravatar.com/avatar/{{hash}}"">link1</a> }, 5000, 'page should navigate to /123'); }, 5000, 'page should navigate to /6'); * We shouldn't do this, because it will make the button enabled on Chrome/Firefox but not on IE8 and older IEs: restrict: 'A',// aliased input attrs are evaluated forEach(ALIASED_ATTR, function(htmlAttr, ngAttr) { ngAttributeAliasDirectives[ngAttr] = function() { return { priority: 100, link: function(scope, element, attr) { //special case ngPattern when a literal regular expression value //is used as the expression (this way we don't have to watch anything). if (ngAttr === ""ngPattern"" && attr.ngPattern.charAt(0) == ""/"") { var match = attr.ngPattern.match(REGEX_STRING_REGEXP); if (match) { attr.$set(""ngPattern"", new RegExp(match[1], match[2])); return; } } scope.$watch(attr[ngAttr], function ngAttrAliasWatchAction(value) { attr.$set(ngAttr, value); }); } }; }; }); if (!value) { if (attrName === 'href') { attr.$set(name, null); } return; }/* global -nullFormCtrl, -SUBMITTED_CLASS, addSetValidityMethod: true */ $$renameControl: nullFormRenameControl, $setPristine: noop, $setSubmitted: noop }, SUBMITTED_CLASS = 'ng-submitted'; function nullFormRenameControl(control, name) { control.$name = name; } * @property {boolean} $submitted True if user has submitted the form even if its invalid. * @property {Object} $error Is an object hash, containing references to controls or * forms with failing validators, where: * - values are arrays of controls or forms that have a failing validator for given error name. * - `date` * - `datetimelocal` * - `time` * - `week` * - `month` * `FormController` keeps track of all its controls and nested forms as well as the state of them,FormController.$inject = ['$element', '$attrs', '$scope', '$animate', '$interpolate']; function FormController(element, attrs, $scope, $animate, $interpolate) { var parentForm = form.$$parentForm = element.parent().controller('form') || nullFormCtrl; form.$error = {}; form.$$success = {}; form.$pending = undefined; form.$name = $interpolate(attrs.name || attrs.ngForm || '')($scope); form.$submitted = false; /** * @ngdoc method * @name form.FormController#$rollbackViewValue * * @description * Rollback all form controls pending updates to the `$modelValue`. * * Updates may be pending by a debounced event or because the input is waiting for a some future * event defined in `ng-model-options`. This method is typically needed by the reset button of * a form that uses `ng-model-options` to pend updates. */ form.$rollbackViewValue = function() { forEach(controls, function(control) { control.$rollbackViewValue(); }); }; /** * @ngdoc method * @name form.FormController#$commitViewValue * * @description * Commit all form controls pending updates to the `$modelValue`. * * Updates may be pending by a debounced event or because the input is waiting for a some future * event defined in `ng-model-options`. This method is rarely needed as `NgModelController` * usually handles calling this in response to input events. */ form.$commitViewValue = function() { forEach(controls, function(control) { control.$commitViewValue(); }); }; // Private API: rename a form control form.$$renameControl = function(control, newName) { var oldName = control.$name; if (form[oldName] === control) { delete form[oldName]; } form[newName] = control; control.$name = newName; }; forEach(form.$pending, function(value, name) { form.$setValidity(name, null, control); }); forEach(form.$error, function(value, name) { form.$setValidity(name, null, control); addSetValidityMethod({ ctrl: this, $element: element, set: function(object, property, control) { var list = object[property]; if (!list) { object[property] = [control]; } else { var index = list.indexOf(control); if (index === -1) { list.push(control); }, unset: function(object, property, control) { var list = object[property]; if (!list) { return; arrayRemove(list, control); if (list.length === 0) { delete object[property]; }, parentForm: parentForm, $animate: $animate }); form.$setPristine = function() { $animate.setClass(element, PRISTINE_CLASS, DIRTY_CLASS + ' ' + SUBMITTED_CLASS); form.$submitted = false; /** * @ngdoc method * @name form.FormController#$setUntouched * * @description * Sets the form to its untouched state. * * This method can be called to remove the 'ng-touched' class and set the form controls to their * untouched state (ng-untouched class). * * Setting a form controls back to their untouched state is often useful when setting the form * back to its pristine state. */ form.$setUntouched = function() { forEach(controls, function(control) { control.$setUntouched(); }); }; /** * @ngdoc method * @name form.FormController#$setSubmitted * * @description * Sets the form to its submitted state. */ form.$setSubmitted = function() { $animate.addClass(element, SUBMITTED_CLASS); form.$submitted = true; parentForm.$setSubmitted(); }; } * - `ng-submitted` is set if the form was submitted. * Any pending `ngModelOptions` changes will take place immediately when an enclosing form is * submitted. Note that `ngClick` events will occur before the model is updated. Use `ngSubmit` * to have access to the updated model. <example deps=""angular-animate.js"" animations=""true"" fixBase=""true"" module=""formExample""> angular.module('formExample', []) .controller('FormController', ['$scope', function($scope) { $scope.userType = 'guest'; }]); <form name=""myForm"" ng-controller=""FormController"" class=""my-form""> * @param {string=} name Name of the form. If specified, the form controller will be published into * related scope, under this name. compile: function ngFormCompile(formElement) { // Setup initial state of the control formElement.addClass(PRISTINE_CLASS).addClass(VALID_CLASS); pre: function ngFormPreLink(scope, formElement, attr, controller) { // if `action` attr is not present on the form, prevent the default action (submission) if (!('action' in attr)) { var handleFormSubmission = function(event) { scope.$apply(function() { controller.$commitViewValue(); controller.$setSubmitted(); }); event.preventDefault(); addEventListenerFn(formElement[0], 'submit', handleFormSubmission); removeEventListenerFn(formElement[0], 'submit', handleFormSubmission); var parentFormCtrl = controller.$$parentForm, alias = controller.$name; attr.$observe(attr.name ? 'name' : 'ngForm', function(newValue) { if (alias === newValue) return; setter(scope, alias, undefined, alias); alias = newValue; setter(scope, alias, controller, alias); parentFormCtrl.$$renameControl(controller, alias); formElement.on('$destroy', function() { parentFormCtrl.$removeControl(controller); if (alias) { setter(scope, alias, undefined, alias); } extend(controller, nullFormCtrl); //stop propagating child destruction handlers upwards });/* global VALID_CLASS: true, INVALID_CLASS: true, PRISTINE_CLASS: true, DIRTY_CLASS: true, UNTOUCHED_CLASS: true, TOUCHED_CLASS: true,// Regex code is obtained from SO: https://stackoverflow.com/questions/3143070/javascript-regex-iso-datetime#answer-3143231 var ISO_DATE_REGEXP = /\d{4}-[01]\d-[0-3]\dT[0-2]\d:[0-5]\d:[0-5]\d\.\d+([+-][0-2]\d:[0-5]\d|Z)/;var EMAIL_REGEXP = /^[a-z0-9!#$%&'*+\/=?^_`{|}~.-]+@[a-z0-9]([a-z0-9-]*[a-z0-9])?(\.[a-z0-9]([a-z0-9-]*[a-z0-9])?)*$/i;var DATE_REGEXP = /^(\d{4})-(\d{2})-(\d{2})$/; var DATETIMELOCAL_REGEXP = /^(\d{4})-(\d\d)-(\d\d)T(\d\d):(\d\d)(?::(\d\d)(\.\d{1,3})?)?$/; var WEEK_REGEXP = /^(\d{4})-W(\d\d)$/; var MONTH_REGEXP = /^(\d{4})-(\d\d)$/; var TIME_REGEXP = /^(\d\d):(\d\d)(?::(\d\d)(\.\d{1,3})?)?$/; var DEFAULT_REGEXP = /(\s+|^)default(\s+|$)/; var $ngModelMinErr = new minErr('ngModel'); * Standard HTML text input with angular data binding, inherited by most of the `input` elements. * * maxlength. Setting the attribute to a negative or non-numeric value, allows view values of * any length. * @param {string=} pattern Similar to `ngPattern` except that the attribute value is the actual string * that contains the regular expression body that will be converted to a regular expression * as in the ngPattern directive. * @param {string=} ngPattern Sets `pattern` validation error key if the ngModel value does not match * a RegExp found by evaluating the Angular expression given in the attribute value. * If the expression evaluates to a RegExp object then this is used directly. * If the expression is a string then it will be converted to a RegExp after wrapping it in `^` and `$` * characters. For instance, `""abc""` will be converted to `new RegExp('^abc$')`. * This parameter is ignored for input[type=password] controls, which will never trim the * input. <example name=""text-input-directive"" module=""textInputExample""> angular.module('textInputExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.text = 'guest'; $scope.word = /^\s*\w*\s*$/; }]); <form name=""myForm"" ng-controller=""ExampleController""> /** * @ngdoc input * @name input[date] * * @description * Input with date validation and transformation. In browsers that do not yet support * the HTML5 date input, a text element will be used. In that case, text must be entered in a valid ISO-8601 * date format (yyyy-MM-dd), for example: `2009-01-06`. Since many * modern browsers do not yet support this input type, it is important to provide cues to users on the * expected input format via a placeholder or label. * * The model must always be a Date object, otherwise Angular will throw an error. * Invalid `Date` objects (dates whose `getTime()` is `NaN`) will be rendered as an empty string. * * The timezone to be used to read/write the `Date` instance in the model can be defined using * {@link ng.directive:ngModelOptions ngModelOptions}. By default, this is the timezone of the browser. * * @param {string} ngModel Assignable angular expression to data-bind to. * @param {string=} name Property name of the form under which the control is published. * @param {string=} min Sets the `min` validation error key if the value entered is less than `min`. This must be a * valid ISO date string (yyyy-MM-dd). * @param {string=} max Sets the `max` validation error key if the value entered is greater than `max`. This must be * a valid ISO date string (yyyy-MM-dd). * @param {string=} required Sets `required` validation error key if the value is not entered. * @param {string=} ngRequired Adds `required` attribute and `required` validation constraint to * the element when the ngRequired expression evaluates to true. Use `ngRequired` instead of * `required` when you want to data-bind to the `required` attribute. * @param {string=} ngChange Angular expression to be executed when input changes due to user * interaction with the input element. * * @example <example name=""date-input-directive"" module=""dateInputExample""> <file name=""index.html""> <script> angular.module('dateInputExample', []) .controller('DateController', ['$scope', function($scope) { $scope.value = new Date(2013, 9, 22); }]); </script> <form name=""myForm"" ng-controller=""DateController as dateCtrl""> Pick a date in 2013: <input type=""date"" id=""exampleInput"" name=""input"" ng-model=""value"" placeholder=""yyyy-MM-dd"" min=""2013-01-01"" max=""2013-12-31"" required /> <span class=""error"" ng-show=""myForm.input.$error.required""> Required!</span> <span class=""error"" ng-show=""myForm.input.$error.date""> Not a valid date!</span> <tt>value = {{value | date: ""yyyy-MM-dd""}}</tt><br/> <tt>myForm.input.$valid = {{myForm.input.$valid}}</tt><br/> <tt>myForm.input.$error = {{myForm.input.$error}}</tt><br/> <tt>myForm.$valid = {{myForm.$valid}}</tt><br/> <tt>myForm.$error.required = {{!!myForm.$error.required}}</tt><br/> </form> </file> <file name=""protractor.js"" type=""protractor""> var value = element(by.binding('value | date: ""yyyy-MM-dd""')); var valid = element(by.binding('myForm.input.$valid')); var input = element(by.model('value')); // currently protractor/webdriver does not support // sending keys to all known HTML5 input controls // for various browsers (see https://github.com/angular/protractor/issues/562). function setInput(val) { // set the value of the element and force validation. var scr = ""var ipt = document.getElementById('exampleInput'); "" + ""ipt.value = '"" + val + ""';"" + ""angular.element(ipt).scope().$apply(function(s) { s.myForm[ipt.name].$setViewValue('"" + val + ""'); });""; browser.executeScript(scr); } it('should initialize to model', function() { expect(value.getText()).toContain('2013-10-22'); expect(valid.getText()).toContain('myForm.input.$valid = true'); }); it('should be invalid if empty', function() { setInput(''); expect(value.getText()).toEqual('value ='); expect(valid.getText()).toContain('myForm.input.$valid = false'); }); it('should be invalid if over max', function() { setInput('2015-01-01'); expect(value.getText()).toContain(''); expect(valid.getText()).toContain('myForm.input.$valid = false'); }); </file> </example> */ 'date': createDateInputType('date', DATE_REGEXP, createDateParser(DATE_REGEXP, ['yyyy', 'MM', 'dd']), 'yyyy-MM-dd'), /** * @ngdoc input * @name input[datetime-local] * * @description * Input with datetime validation and transformation. In browsers that do not yet support * the HTML5 date input, a text element will be used. In that case, the text must be entered in a valid ISO-8601 * local datetime format (yyyy-MM-ddTHH:mm:ss), for example: `2010-12-28T14:57:00`. * * The model must always be a Date object, otherwise Angular will throw an error. * Invalid `Date` objects (dates whose `getTime()` is `NaN`) will be rendered as an empty string. * * The timezone to be used to read/write the `Date` instance in the model can be defined using * {@link ng.directive:ngModelOptions ngModelOptions}. By default, this is the timezone of the browser. * * @param {string} ngModel Assignable angular expression to data-bind to. * @param {string=} name Property name of the form under which the control is published. * @param {string=} min Sets the `min` validation error key if the value entered is less than `min`. This must be a * valid ISO datetime format (yyyy-MM-ddTHH:mm:ss). * @param {string=} max Sets the `max` validation error key if the value entered is greater than `max`. This must be * a valid ISO datetime format (yyyy-MM-ddTHH:mm:ss). * @param {string=} required Sets `required` validation error key if the value is not entered. * @param {string=} ngRequired Adds `required` attribute and `required` validation constraint to * the element when the ngRequired expression evaluates to true. Use `ngRequired` instead of * `required` when you want to data-bind to the `required` attribute. * @param {string=} ngChange Angular expression to be executed when input changes due to user * interaction with the input element. * * @example <example name=""datetimelocal-input-directive"" module=""dateExample""> <file name=""index.html""> <script> angular.module('dateExample', []) .controller('DateController', ['$scope', function($scope) { $scope.value = new Date(2010, 11, 28, 14, 57); }]); </script> <form name=""myForm"" ng-controller=""DateController as dateCtrl""> Pick a date between in 2013: <input type=""datetime-local"" id=""exampleInput"" name=""input"" ng-model=""value"" placeholder=""yyyy-MM-ddTHH:mm:ss"" min=""2001-01-01T00:00:00"" max=""2013-12-31T00:00:00"" required /> <span class=""error"" ng-show=""myForm.input.$error.required""> Required!</span> <span class=""error"" ng-show=""myForm.input.$error.datetimelocal""> Not a valid date!</span> <tt>value = {{value | date: ""yyyy-MM-ddTHH:mm:ss""}}</tt><br/> <tt>myForm.input.$valid = {{myForm.input.$valid}}</tt><br/> <tt>myForm.input.$error = {{myForm.input.$error}}</tt><br/> <tt>myForm.$valid = {{myForm.$valid}}</tt><br/> <tt>myForm.$error.required = {{!!myForm.$error.required}}</tt><br/> </form> </file> <file name=""protractor.js"" type=""protractor""> var value = element(by.binding('value | date: ""yyyy-MM-ddTHH:mm:ss""')); var valid = element(by.binding('myForm.input.$valid')); var input = element(by.model('value')); // currently protractor/webdriver does not support // sending keys to all known HTML5 input controls // for various browsers (https://github.com/angular/protractor/issues/562). function setInput(val) { // set the value of the element and force validation. var scr = ""var ipt = document.getElementById('exampleInput'); "" + ""ipt.value = '"" + val + ""';"" + ""angular.element(ipt).scope().$apply(function(s) { s.myForm[ipt.name].$setViewValue('"" + val + ""'); });""; browser.executeScript(scr); } it('should initialize to model', function() { expect(value.getText()).toContain('2010-12-28T14:57:00'); expect(valid.getText()).toContain('myForm.input.$valid = true'); }); it('should be invalid if empty', function() { setInput(''); expect(value.getText()).toEqual('value ='); expect(valid.getText()).toContain('myForm.input.$valid = false'); }); it('should be invalid if over max', function() { setInput('2015-01-01T23:59:00'); expect(value.getText()).toContain(''); expect(valid.getText()).toContain('myForm.input.$valid = false'); }); </file> </example> */ 'datetime-local': createDateInputType('datetimelocal', DATETIMELOCAL_REGEXP, createDateParser(DATETIMELOCAL_REGEXP, ['yyyy', 'MM', 'dd', 'HH', 'mm', 'ss', 'sss']), 'yyyy-MM-ddTHH:mm:ss.sss'), /** * @ngdoc input * @name input[time] * * @description * Input with time validation and transformation. In browsers that do not yet support * the HTML5 date input, a text element will be used. In that case, the text must be entered in a valid ISO-8601 * local time format (HH:mm:ss), for example: `14:57:00`. Model must be a Date object. This binding will always output a * Date object to the model of January 1, 1970, or local date `new Date(1970, 0, 1, HH, mm, ss)`. * * The model must always be a Date object, otherwise Angular will throw an error. * Invalid `Date` objects (dates whose `getTime()` is `NaN`) will be rendered as an empty string. * * The timezone to be used to read/write the `Date` instance in the model can be defined using * {@link ng.directive:ngModelOptions ngModelOptions}. By default, this is the timezone of the browser. * * @param {string} ngModel Assignable angular expression to data-bind to. * @param {string=} name Property name of the form under which the control is published. * @param {string=} min Sets the `min` validation error key if the value entered is less than `min`. This must be a * valid ISO time format (HH:mm:ss). * @param {string=} max Sets the `max` validation error key if the value entered is greater than `max`. This must be a * valid ISO time format (HH:mm:ss). * @param {string=} required Sets `required` validation error key if the value is not entered. * @param {string=} ngRequired Adds `required` attribute and `required` validation constraint to * the element when the ngRequired expression evaluates to true. Use `ngRequired` instead of * `required` when you want to data-bind to the `required` attribute. * @param {string=} ngChange Angular expression to be executed when input changes due to user * interaction with the input element. * * @example <example name=""time-input-directive"" module=""timeExample""> <file name=""index.html""> <script> angular.module('timeExample', []) .controller('DateController', ['$scope', function($scope) { $scope.value = new Date(1970, 0, 1, 14, 57, 0); }]); </script> <form name=""myForm"" ng-controller=""DateController as dateCtrl""> Pick a between 8am and 5pm: <input type=""time"" id=""exampleInput"" name=""input"" ng-model=""value"" placeholder=""HH:mm:ss"" min=""08:00:00"" max=""17:00:00"" required /> <span class=""error"" ng-show=""myForm.input.$error.required""> Required!</span> <span class=""error"" ng-show=""myForm.input.$error.time""> Not a valid date!</span> <tt>value = {{value | date: ""HH:mm:ss""}}</tt><br/> <tt>myForm.input.$valid = {{myForm.input.$valid}}</tt><br/> <tt>myForm.input.$error = {{myForm.input.$error}}</tt><br/> <tt>myForm.$valid = {{myForm.$valid}}</tt><br/> <tt>myForm.$error.required = {{!!myForm.$error.required}}</tt><br/> </form> </file> <file name=""protractor.js"" type=""protractor""> var value = element(by.binding('value | date: ""HH:mm:ss""')); var valid = element(by.binding('myForm.input.$valid')); var input = element(by.model('value')); // currently protractor/webdriver does not support // sending keys to all known HTML5 input controls // for various browsers (https://github.com/angular/protractor/issues/562). function setInput(val) { // set the value of the element and force validation. var scr = ""var ipt = document.getElementById('exampleInput'); "" + ""ipt.value = '"" + val + ""';"" + ""angular.element(ipt).scope().$apply(function(s) { s.myForm[ipt.name].$setViewValue('"" + val + ""'); });""; browser.executeScript(scr); } it('should initialize to model', function() { expect(value.getText()).toContain('14:57:00'); expect(valid.getText()).toContain('myForm.input.$valid = true'); }); it('should be invalid if empty', function() { setInput(''); expect(value.getText()).toEqual('value ='); expect(valid.getText()).toContain('myForm.input.$valid = false'); }); it('should be invalid if over max', function() { setInput('23:59:00'); expect(value.getText()).toContain(''); expect(valid.getText()).toContain('myForm.input.$valid = false'); }); </file> </example> */ 'time': createDateInputType('time', TIME_REGEXP, createDateParser(TIME_REGEXP, ['HH', 'mm', 'ss', 'sss']), 'HH:mm:ss.sss'), /** * @ngdoc input * @name input[week] * * @description * Input with week-of-the-year validation and transformation to Date. In browsers that do not yet support * the HTML5 week input, a text element will be used. In that case, the text must be entered in a valid ISO-8601 * week format (yyyy-W##), for example: `2013-W02`. * * The model must always be a Date object, otherwise Angular will throw an error. * Invalid `Date` objects (dates whose `getTime()` is `NaN`) will be rendered as an empty string. * * The timezone to be used to read/write the `Date` instance in the model can be defined using * {@link ng.directive:ngModelOptions ngModelOptions}. By default, this is the timezone of the browser. * * @param {string} ngModel Assignable angular expression to data-bind to. * @param {string=} name Property name of the form under which the control is published. * @param {string=} min Sets the `min` validation error key if the value entered is less than `min`. This must be a * valid ISO week format (yyyy-W##). * @param {string=} max Sets the `max` validation error key if the value entered is greater than `max`. This must be * a valid ISO week format (yyyy-W##). * @param {string=} required Sets `required` validation error key if the value is not entered. * @param {string=} ngRequired Adds `required` attribute and `required` validation constraint to * the element when the ngRequired expression evaluates to true. Use `ngRequired` instead of * `required` when you want to data-bind to the `required` attribute. * @param {string=} ngChange Angular expression to be executed when input changes due to user * interaction with the input element. * * @example <example name=""week-input-directive"" module=""weekExample""> <file name=""index.html""> <script> angular.module('weekExample', []) .controller('DateController', ['$scope', function($scope) { $scope.value = new Date(2013, 0, 3); }]); </script> <form name=""myForm"" ng-controller=""DateController as dateCtrl""> Pick a date between in 2013: <input id=""exampleInput"" type=""week"" name=""input"" ng-model=""value"" placeholder=""YYYY-W##"" min=""2012-W32"" max=""2013-W52"" required /> <span class=""error"" ng-show=""myForm.input.$error.required""> Required!</span> <span class=""error"" ng-show=""myForm.input.$error.week""> Not a valid date!</span> <tt>value = {{value | date: ""yyyy-Www""}}</tt><br/> <tt>myForm.input.$valid = {{myForm.input.$valid}}</tt><br/> <tt>myForm.input.$error = {{myForm.input.$error}}</tt><br/> <tt>myForm.$valid = {{myForm.$valid}}</tt><br/> <tt>myForm.$error.required = {{!!myForm.$error.required}}</tt><br/> </form> </file> <file name=""protractor.js"" type=""protractor""> var value = element(by.binding('value | date: ""yyyy-Www""')); var valid = element(by.binding('myForm.input.$valid')); var input = element(by.model('value')); // currently protractor/webdriver does not support // sending keys to all known HTML5 input controls // for various browsers (https://github.com/angular/protractor/issues/562). function setInput(val) { // set the value of the element and force validation. var scr = ""var ipt = document.getElementById('exampleInput'); "" + ""ipt.value = '"" + val + ""';"" + ""angular.element(ipt).scope().$apply(function(s) { s.myForm[ipt.name].$setViewValue('"" + val + ""'); });""; browser.executeScript(scr); } it('should initialize to model', function() { expect(value.getText()).toContain('2013-W01'); expect(valid.getText()).toContain('myForm.input.$valid = true'); }); it('should be invalid if empty', function() { setInput(''); expect(value.getText()).toEqual('value ='); expect(valid.getText()).toContain('myForm.input.$valid = false'); }); it('should be invalid if over max', function() { setInput('2015-W01'); expect(value.getText()).toContain(''); expect(valid.getText()).toContain('myForm.input.$valid = false'); }); </file> </example> */ 'week': createDateInputType('week', WEEK_REGEXP, weekParser, 'yyyy-Www'), /** * @ngdoc input * @name input[month] * * @description * Input with month validation and transformation. In browsers that do not yet support * the HTML5 month input, a text element will be used. In that case, the text must be entered in a valid ISO-8601 * month format (yyyy-MM), for example: `2009-01`. * * The model must always be a Date object, otherwise Angular will throw an error. * Invalid `Date` objects (dates whose `getTime()` is `NaN`) will be rendered as an empty string. * If the model is not set to the first of the month, the next view to model update will set it * to the first of the month. * * The timezone to be used to read/write the `Date` instance in the model can be defined using * {@link ng.directive:ngModelOptions ngModelOptions}. By default, this is the timezone of the browser. * * @param {string} ngModel Assignable angular expression to data-bind to. * @param {string=} name Property name of the form under which the control is published. * @param {string=} min Sets the `min` validation error key if the value entered is less than `min`. This must be * a valid ISO month format (yyyy-MM). * @param {string=} max Sets the `max` validation error key if the value entered is greater than `max`. This must * be a valid ISO month format (yyyy-MM). * @param {string=} required Sets `required` validation error key if the value is not entered. * @param {string=} ngRequired Adds `required` attribute and `required` validation constraint to * the element when the ngRequired expression evaluates to true. Use `ngRequired` instead of * `required` when you want to data-bind to the `required` attribute. * @param {string=} ngChange Angular expression to be executed when input changes due to user * interaction with the input element. * * @example <example name=""month-input-directive"" module=""monthExample""> <file name=""index.html""> <script> angular.module('monthExample', []) .controller('DateController', ['$scope', function($scope) { $scope.value = new Date(2013, 9, 1); }]); </script> <form name=""myForm"" ng-controller=""DateController as dateCtrl""> Pick a month int 2013: <input id=""exampleInput"" type=""month"" name=""input"" ng-model=""value"" placeholder=""yyyy-MM"" min=""2013-01"" max=""2013-12"" required /> <span class=""error"" ng-show=""myForm.input.$error.required""> Required!</span> <span class=""error"" ng-show=""myForm.input.$error.month""> Not a valid month!</span> <tt>value = {{value | date: ""yyyy-MM""}}</tt><br/> <tt>myForm.input.$valid = {{myForm.input.$valid}}</tt><br/> <tt>myForm.input.$error = {{myForm.input.$error}}</tt><br/> <tt>myForm.$valid = {{myForm.$valid}}</tt><br/> <tt>myForm.$error.required = {{!!myForm.$error.required}}</tt><br/> </form> </file> <file name=""protractor.js"" type=""protractor""> var value = element(by.binding('value | date: ""yyyy-MM""')); var valid = element(by.binding('myForm.input.$valid')); var input = element(by.model('value')); // currently protractor/webdriver does not support // sending keys to all known HTML5 input controls // for various browsers (https://github.com/angular/protractor/issues/562). function setInput(val) { // set the value of the element and force validation. var scr = ""var ipt = document.getElementById('exampleInput'); "" + ""ipt.value = '"" + val + ""';"" + ""angular.element(ipt).scope().$apply(function(s) { s.myForm[ipt.name].$setViewValue('"" + val + ""'); });""; browser.executeScript(scr); } it('should initialize to model', function() { expect(value.getText()).toContain('2013-10'); expect(valid.getText()).toContain('myForm.input.$valid = true'); }); it('should be invalid if empty', function() { setInput(''); expect(value.getText()).toEqual('value ='); expect(valid.getText()).toContain('myForm.input.$valid = false'); }); it('should be invalid if over max', function() { setInput('2015-01'); expect(value.getText()).toContain(''); expect(valid.getText()).toContain('myForm.input.$valid = false'); }); </file> </example> */ 'month': createDateInputType('month', MONTH_REGEXP, createDateParser(MONTH_REGEXP, ['yyyy', 'MM']), 'yyyy-MM'), * The model must always be a number, otherwise Angular will throw an error. * * maxlength. Setting the attribute to a negative or non-numeric value, allows view values of * any length. * @param {string=} pattern Similar to `ngPattern` except that the attribute value is the actual string * that contains the regular expression body that will be converted to a regular expression * as in the ngPattern directive. * @param {string=} ngPattern Sets `pattern` validation error key if the ngModel value does not match * a RegExp found by evaluating the Angular expression given in the attribute value. * If the expression evaluates to a RegExp object then this is used directly. * If the expression is a string then it will be converted to a RegExp after wrapping it in `^` and `$` * characters. For instance, `""abc""` will be converted to `new RegExp('^abc$')`. <example name=""number-input-directive"" module=""numberExample""> angular.module('numberExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.value = 12; }]); <form name=""myForm"" ng-controller=""ExampleController""> * <div class=""alert alert-warning""> * **Note:** `input[url]` uses a regex to validate urls that is derived from the regex * used in Chromium. If you need stricter validation, you can use `ng-pattern` or modify * the built-in validators (see the {@link guide/forms Forms guide}) * </div> * * maxlength. Setting the attribute to a negative or non-numeric value, allows view values of * any length. * @param {string=} pattern Similar to `ngPattern` except that the attribute value is the actual string * that contains the regular expression body that will be converted to a regular expression * as in the ngPattern directive. * @param {string=} ngPattern Sets `pattern` validation error key if the ngModel value does not match * a RegExp found by evaluating the Angular expression given in the attribute value. * If the expression evaluates to a RegExp object then this is used directly. * If the expression is a string then it will be converted to a RegExp after wrapping it in `^` and `$` * characters. For instance, `""abc""` will be converted to `new RegExp('^abc$')`. <example name=""url-input-directive"" module=""urlExample""> angular.module('urlExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.text = 'http://google.com'; }]); <form name=""myForm"" ng-controller=""ExampleController""> * <div class=""alert alert-warning""> * **Note:** `input[email]` uses a regex to validate email addresses that is derived from the regex * used in Chromium. If you need stricter validation (e.g. requiring a top-level domain), you can * use `ng-pattern` or modify the built-in validators (see the {@link guide/forms Forms guide}) * </div> * * maxlength. Setting the attribute to a negative or non-numeric value, allows view values of * any length. * @param {string=} pattern Similar to `ngPattern` except that the attribute value is the actual string * that contains the regular expression body that will be converted to a regular expression * as in the ngPattern directive. * @param {string=} ngPattern Sets `pattern` validation error key if the ngModel value does not match * a RegExp found by evaluating the Angular expression given in the attribute value. * If the expression evaluates to a RegExp object then this is used directly. * If the expression is a string then it will be converted to a RegExp after wrapping it in `^` and `$` * characters. For instance, `""abc""` will be converted to `new RegExp('^abc$')`. <example name=""email-input-directive"" module=""emailExample""> angular.module('emailExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.text = 'me@example.com'; }]); <form name=""myForm"" ng-controller=""ExampleController""> <example name=""radio-input-directive"" module=""radioExample""> angular.module('radioExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.color = 'blue'; $scope.specialValue = { ""id"": ""12345"", ""value"": ""green"" }; }]); <form name=""myForm"" ng-controller=""ExampleController""> * @param {expression=} ngTrueValue The value to which the expression should be set when selected. * @param {expression=} ngFalseValue The value to which the expression should be set when not selected. <example name=""checkbox-input-directive"" module=""checkboxExample""> angular.module('checkboxExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.value1 = true; $scope.value2 = 'YES' }]); <form name=""myForm"" ng-controller=""ExampleController""> ng-true-value=""'YES'"" ng-false-value=""'NO'""> <br/>function stringBasedInputType(ctrl) { ctrl.$formatters.push(function(value) { return ctrl.$isEmpty(value) ? value : value.toString(); }); baseInputType(scope, element, attr, ctrl, $sniffer, $browser); stringBasedInputType(ctrl); } function baseInputType(scope, element, attr, ctrl, $sniffer, $browser) { var type = lowercase(element[0].type); var listener = function(ev) { if (timeout) { $browser.defer.cancel(timeout); timeout = null; } var value = element.val(), event = ev && ev.type; // If input type is 'password', the value is never trimmed if (type !== 'password' && (!attr.ngTrim || attr.ngTrim !== 'false')) { // If a control is suffering from bad input (due to native validators), browsers discard its // value, so it may be necessary to revalidate (by calling $setViewValue again) even if the // control's value is the same empty value twice in a row. if (ctrl.$viewValue !== value || (value === '' && ctrl.$$hasNativeValidators)) { ctrl.$setViewValue(value, event); var deferListener = function(ev, input, origValue) { if (!input || input.value !== origValue) { listener(ev); } deferListener(event, this, this.value);}function weekParser(isoWeek, existingDate) { if (isDate(isoWeek)) { return isoWeek; } if (isString(isoWeek)) { WEEK_REGEXP.lastIndex = 0; var parts = WEEK_REGEXP.exec(isoWeek); if (parts) { var year = +parts[1], week = +parts[2], hours = 0, minutes = 0, seconds = 0, milliseconds = 0, firstThurs = getFirstThursdayOfYear(year), addDays = (week - 1) * 7; if (existingDate) { hours = existingDate.getHours(); minutes = existingDate.getMinutes(); seconds = existingDate.getSeconds(); milliseconds = existingDate.getMilliseconds(); } return new Date(year, 0, firstThurs.getDate() + addDays, hours, minutes, seconds, milliseconds); } } return NaN; } function createDateParser(regexp, mapping) { return function(iso, date) { var parts, map; if (isDate(iso)) { return iso; if (isString(iso)) { // When a date is JSON'ified to wraps itself inside of an extra // set of double quotes. This makes the date parsing code unable // to match the date string and parse it as a date. if (iso.charAt(0) == '""' && iso.charAt(iso.length - 1) == '""') { iso = iso.substring(1, iso.length - 1); } if (ISO_DATE_REGEXP.test(iso)) { return new Date(iso); } regexp.lastIndex = 0; parts = regexp.exec(iso); if (parts) { parts.shift(); if (date) { map = { yyyy: date.getFullYear(), MM: date.getMonth() + 1, dd: date.getDate(), HH: date.getHours(), mm: date.getMinutes(), ss: date.getSeconds(), sss: date.getMilliseconds() / 1000 }; } else { map = { yyyy: 1970, MM: 1, dd: 1, HH: 0, mm: 0, ss: 0, sss: 0 }; } forEach(parts, function(part, index) { if (index < mapping.length) { map[mapping[index]] = +part; } }); return new Date(map.yyyy, map.MM - 1, map.dd, map.HH, map.mm, map.ss || 0, map.sss * 1000 || 0); } } return NaN; }; }function createDateInputType(type, regexp, parseDate, format) { return function dynamicDateInputType(scope, element, attr, ctrl, $sniffer, $browser, $filter) { badInputChecker(scope, element, attr, ctrl); baseInputType(scope, element, attr, ctrl, $sniffer, $browser); var timezone = ctrl && ctrl.$options && ctrl.$options.timezone; var previousDate; ctrl.$$parserName = type; ctrl.$parsers.push(function(value) { if (ctrl.$isEmpty(value)) return null; if (regexp.test(value)) { // Note: We cannot read ctrl.$modelValue, as there might be a different // parser/formatter in the processing chain so that the model // contains some different data format! var parsedDate = parseDate(value, previousDate); if (timezone === 'UTC') { parsedDate.setMinutes(parsedDate.getMinutes() - parsedDate.getTimezoneOffset()); } return parsedDate; } return undefined; }); ctrl.$formatters.push(function(value) { if (value && !isDate(value)) { throw $ngModelMinErr('datefmt', 'Expected `{0}` to be a date', value); } if (isValidDate(value)) { previousDate = value; if (previousDate && timezone === 'UTC') { var timezoneOffset = 60000 * previousDate.getTimezoneOffset(); previousDate = new Date(previousDate.getTime() + timezoneOffset); } return $filter('date')(value, format, timezone); } else { previousDate = null; return ''; } }); if (isDefined(attr.min) || attr.ngMin) { var minVal; ctrl.$validators.min = function(value) { return !isValidDate(value) || isUndefined(minVal) || parseDate(value) >= minVal; }; attr.$observe('min', function(val) { minVal = parseObservedDateValue(val); ctrl.$validate(); }); } if (isDefined(attr.max) || attr.ngMax) { var maxVal; ctrl.$validators.max = function(value) { return !isValidDate(value) || isUndefined(maxVal) || parseDate(value) <= maxVal; }; attr.$observe('max', function(val) { maxVal = parseObservedDateValue(val); ctrl.$validate(); }); } function isValidDate(value) { // Invalid Date: getTime() returns NaN return value && !(value.getTime && value.getTime() !== value.getTime()); } function parseObservedDateValue(val) { return isDefined(val) ? (isDate(val) ? val : parseDate(val)) : undefined; } }; } function badInputChecker(scope, element, attr, ctrl) { var node = element[0]; var nativeValidation = ctrl.$$hasNativeValidators = isObject(node.validity); if (nativeValidation) { ctrl.$parsers.push(function(value) { var validity = element.prop(VALIDITY_STATE_PROPERTY) || {}; // Detect bug in FF35 for input[email] (https://bugzilla.mozilla.org/show_bug.cgi?id=1064430): // - also sets validity.badInput (should only be validity.typeMismatch). // - see http://www.whatwg.org/specs/web-apps/current-work/multipage/forms.html#e-mail-state-(type=email) // - can ignore this case as we can still read out the erroneous email... return validity.badInput && !validity.typeMismatch ? undefined : value; }); badInputChecker(scope, element, attr, ctrl); baseInputType(scope, element, attr, ctrl, $sniffer, $browser); ctrl.$$parserName = 'number'; if (ctrl.$isEmpty(value)) return null; if (NUMBER_REGEXP.test(value)) return parseFloat(value); return undefined; }); ctrl.$formatters.push(function(value) { if (!ctrl.$isEmpty(value)) { if (!isNumber(value)) { throw $ngModelMinErr('numfmt', 'Expected `{0}` to be a number', value); } value = value.toString(); return value; if (attr.min || attr.ngMin) { var minVal; ctrl.$validators.min = function(value) { return ctrl.$isEmpty(value) || isUndefined(minVal) || value >= minVal; attr.$observe('min', function(val) { if (isDefined(val) && !isNumber(val)) { val = parseFloat(val, 10); } minVal = isNumber(val) && !isNaN(val) ? val : undefined; // TODO(matsko): implement validateLater to reduce number of validations ctrl.$validate(); }); if (attr.max || attr.ngMax) { var maxVal; ctrl.$validators.max = function(value) { return ctrl.$isEmpty(value) || isUndefined(maxVal) || value <= maxVal; attr.$observe('max', function(val) { if (isDefined(val) && !isNumber(val)) { val = parseFloat(val, 10); } maxVal = isNumber(val) && !isNaN(val) ? val : undefined; // TODO(matsko): implement validateLater to reduce number of validations ctrl.$validate(); }); // Note: no badInputChecker here by purpose as `url` is only a validation // in browsers, i.e. we can always read out input.value even if it is not valid! baseInputType(scope, element, attr, ctrl, $sniffer, $browser); stringBasedInputType(ctrl); ctrl.$$parserName = 'url'; ctrl.$validators.url = function(modelValue, viewValue) { var value = modelValue || viewValue; return ctrl.$isEmpty(value) || URL_REGEXP.test(value); // Note: no badInputChecker here by purpose as `url` is only a validation // in browsers, i.e. we can always read out input.value even if it is not valid! baseInputType(scope, element, attr, ctrl, $sniffer, $browser); stringBasedInputType(ctrl); ctrl.$$parserName = 'email'; ctrl.$validators.email = function(modelValue, viewValue) { var value = modelValue || viewValue; return ctrl.$isEmpty(value) || EMAIL_REGEXP.test(value); var listener = function(ev) { ctrl.$setViewValue(attr.value, ev && ev.type); }; element.on('click', listener);function parseConstantExpr($parse, context, name, expression, fallback) { var parseFn; if (isDefined(expression)) { parseFn = $parse(expression); if (!parseFn.constant) { throw minErr('ngModel')('constexpr', 'Expected constant expression for `{0}`, but saw ' + '`{1}`.', name, expression); } return parseFn(context); } return fallback; }function checkboxInputType(scope, element, attr, ctrl, $sniffer, $browser, $filter, $parse) { var trueValue = parseConstantExpr($parse, scope, 'ngTrueValue', attr.ngTrueValue, true); var falseValue = parseConstantExpr($parse, scope, 'ngFalseValue', attr.ngFalseValue, false); var listener = function(ev) { ctrl.$setViewValue(element[0].checked, ev && ev.type); }; element.on('click', listener); // Override the standard `$isEmpty` because the $viewValue of an empty checkbox is always set to `false` // This is because of the parser below, which compares the `$modelValue` with `trueValue` to convert // it to a boolean. return value === false; return equals(value, trueValue); * maxlength. Setting the attribute to a negative or non-numeric value, allows view values of any * length. * @param {boolean=} [ngTrim=true] If set to false Angular will not automatically trim the input. * HTML input element control. When used together with {@link ngModel `ngModel`}, it provides data-binding, * input state control, and validation. * Input control follows HTML5 input types and polyfills the HTML5 validation behavior for older browsers. * * <div class=""alert alert-warning""> * **Note:** Not every feature offered is available for all input types. * Specifically, data binding and event handling via `ng-model` is unsupported for `input[file]`. * </div> * maxlength. Setting the attribute to a negative or non-numeric value, allows view values of any * length. * @param {boolean=} [ngTrim=true] If set to false Angular will not automatically trim the input. * This parameter is ignored for input[type=password] controls, which will never trim the * input. <example name=""input-directive"" module=""inputExample""> angular.module('inputExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.user = {name: 'guest', last: 'visitor'}; }]); <div ng-controller=""ExampleController""> var user = element(by.exactBinding('user'));var inputDirective = ['$browser', '$sniffer', '$filter', '$parse', function($browser, $sniffer, $filter, $parse) { require: ['?ngModel'], link: { pre: function(scope, element, attr, ctrls) { if (ctrls[0]) { (inputType[lowercase(attr.type)] || inputType.text)(scope, element, attr, ctrls[0], $sniffer, $browser, $filter, $parse); } DIRTY_CLASS = 'ng-dirty', UNTOUCHED_CLASS = 'ng-untouched', TOUCHED_CLASS = 'ng-touched', PENDING_CLASS = 'ng-pending'; * @property {*} $modelValue The value in the model that the control is bound to. the control reads value from the DOM. The functions are called in array order, each passing its return value through to the next. The last return value is forwarded to the {@link ngModel.NgModelController#$validators `$validators`} collection. Parsers are used to sanitize / convert the {@link ngModel.NgModelController#$viewValue `$viewValue`}. Returning `undefined` from a parser means a parse error occurred. In that case, no {@link ngModel.NgModelController#$validators `$validators`} will run and the `ngModel` will be set to `undefined` unless {@link ngModelOptions `ngModelOptions.allowInvalid`} is set to `true`. The parse error is stored in `ngModel.$error.parse`. the model value changes. The functions are called in reverse array order, each passing the value through to the next. The last return value is used as the actual DOM value. Used to format / convert values for display in the control. * ```js * function formatter(value) { * if (value) { * return value.toUpperCase(); * } * } * ngModel.$formatters.push(formatter); * ``` * * @property {Object.<string, function>} $validators A collection of validators that are applied * whenever the model value changes. The key value within the object refers to the name of the * validator while the function refers to the validation operation. The validation operation is * provided with the model value as an argument and must return a true or false value depending * on the response of that validation. * * ```js * ngModel.$validators.validCharacters = function(modelValue, viewValue) { * var value = modelValue || viewValue; * return /[0-9]+/.test(value) && * /[a-z]+/.test(value) && * /[A-Z]+/.test(value) && * /\W+/.test(value); * }; * ``` * * @property {Object.<string, function>} $asyncValidators A collection of validations that are expected to * perform an asynchronous validation (e.g. a HTTP request). The validation function that is provided * is expected to return a promise when it is run during the model validation process. Once the promise * is delivered then the validation status will be set to true when fulfilled and false when rejected. * When the asynchronous validators are triggered, each of the validators will run in parallel and the model * value will only be updated once all validators have been fulfilled. As long as an asynchronous validator * is unfulfilled, its key will be added to the controllers `$pending` property. Also, all asynchronous validators * will only run once all synchronous validators have passed. * * Please note that if $http is used then it is important that the server returns a success HTTP response code * in order to fulfill the validation and a status level of `4xx` in order to reject the validation. * * ```js * ngModel.$asyncValidators.uniqueUsername = function(modelValue, viewValue) { * var value = modelValue || viewValue; * * // Lookup user by username * return $http.get('/api/users/' + value). * then(function resolved() { * //username exists, this means validation fails * return $q.reject('exists'); * }, function rejected() { * //username does not exist, therefore this validation passes * return true; * }); * }; * ``` * @property {Object} $error An object hash with all failing validator ids as keys. * @property {Object} $pending An object hash with all pending validator ids as keys. * @property {boolean} $untouched True if control has not lost focus yet. * @property {boolean} $touched True if control has lost focus. * @property {string} $name The name attribute of the control. * `NgModelController` provides API for the {@link ngModel `ngModel`} directive. * The controller contains services for data-binding, validation, CSS updates, and value formatting * and parsing. It purposefully does not contain any logic which deals with DOM rendering or * listening to DOM events. * Such DOM related logic should be provided by other directives which make use of * `NgModelController` for data-binding to control elements. * Angular provides this DOM logic for most {@link input `input`} elements. * At the end of this page you can find a {@link ngModel.NgModelController#custom-control-example * custom control example} that uses `ngModelController` to bind to `contenteditable` elements. * @example * ### Custom Control Example * We are using the {@link ng.service:$sce $sce} service here and include the {@link ngSanitize $sanitize} * module to automatically remove ""bad"" content like inline event listener (e.g. `<span onclick=""..."">`). * However, as we are using `$sce` the model can still decide to provide unsafe content if it marks * that content using the `$sce` service. * * <example name=""NgModelController"" module=""customControl"" deps=""angular-sanitize.js""> angular.module('customControl', ['ngSanitize']). directive('contenteditable', ['$sce', function($sce) { if (!ngModel) return; // do nothing if no ng-model element.html($sce.getTrustedHtml(ngModel.$viewValue || '')); scope.$evalAsync(read); if ( attrs.stripBr && html == '<br>' ) { }]);var NgModelController = ['$scope', '$exceptionHandler', '$attrs', '$element', '$parse', '$animate', '$timeout', '$rootScope', '$q', '$interpolate', function($scope, $exceptionHandler, $attr, $element, $parse, $animate, $timeout, $rootScope, $q, $interpolate) { this.$$rawModelValue = undefined; // stores the parsed modelValue / model set from scope regardless of validity. this.$validators = {}; this.$asyncValidators = {}; this.$untouched = true; this.$touched = false; this.$error = {}; // keep invalid keys here this.$$success = {}; // keep valid keys here this.$pending = undefined; // keep pending keys here this.$name = $interpolate($attr.name || '', false)($scope); var parsedNgModel = $parse($attr.ngModel), parsedNgModelAssign = parsedNgModel.assign, ngModelGet = parsedNgModel, ngModelSet = parsedNgModelAssign, pendingDebounce = null, ctrl = this; this.$$setOptions = function(options) { ctrl.$options = options; if (options && options.getterSetter) { var invokeModelGetter = $parse($attr.ngModel + '()'), invokeModelSetter = $parse($attr.ngModel + '($$$p)'); ngModelGet = function($scope) { var modelValue = parsedNgModel($scope); if (isFunction(modelValue)) { modelValue = invokeModelGetter($scope); } return modelValue; }; ngModelSet = function($scope, newValue) { if (isFunction(parsedNgModel($scope))) { invokeModelSetter($scope, {$$$p: ctrl.$modelValue}); } else { parsedNgModelAssign($scope, ctrl.$modelValue); } }; } else if (!parsedNgModel.assign) { throw $ngModelMinErr('nonassign', ""Expression '{0}' is non-assignable. Element: {1}"", $attr.ngModel, startingTag($element)); } }; * * The `$render()` method is invoked in the following situations: * * * `$rollbackViewValue()` is called. If we are rolling back the view value to the last * committed value then `$render()` is called to update the input control. * * The value referenced by `ng-model` is changed programmatically and both the `$modelValue` and * the `$viewValue` are different to last time. * * Since `ng-model` does not do a deep watch, `$render()` is only invoked if the values of * `$modelValue` and `$viewValue` are actually different to their previous value. If `$modelValue` * or `$viewValue` are objects (rather than a string or number) then `$render()` will not be * invoked if you only change a property on the objects. * This is called when we need to determine if the value of an input is empty. * * @param {*} value The value of the input to check for emptiness. * @returns {boolean} True if `value` is ""empty"". currentValidationRunId = 0; * Change the validity state, and notify the form. * This method can be called within $parsers/$formatters or a custom validation implementation. * However, in most cases it should be sufficient to use the `ngModel.$validators` and * `ngModel.$asyncValidators` collections which will call `$setValidity` automatically. * @param {string} validationErrorKey Name of the validator. The `validationErrorKey` will be assigned * to either `$error[validationErrorKey]` or `$pending[validationErrorKey]` * (for unfulfilled `$asyncValidators`), so that it is available for data-binding. * @param {boolean} isValid Whether the current state is valid (true), invalid (false), pending (undefined), * or skipped (null). Pending is used for unfulfilled `$asyncValidators`. * Skipped is used by Angular when validators do not run because of parse errors and * when `$asyncValidators` do not run because any of the `$validators` failed. addSetValidityMethod({ ctrl: this, $element: $element, set: function(object, property) { object[property] = true; }, unset: function(object, property) { delete object[property]; }, parentForm: parentForm, $animate: $animate }); * This method can be called to remove the `ng-dirty` class and set the control to its pristine * state (`ng-pristine` class). A model is considered to be pristine when the control * has not been changed from when first compiled. this.$setPristine = function() { ctrl.$dirty = false; ctrl.$pristine = true; * @name ngModel.NgModelController#$setDirty * * @description * Sets the control to its dirty state. * * This method can be called to remove the `ng-pristine` class and set the control to its dirty * state (`ng-dirty` class). A model is considered to be dirty when the control has been changed * from when first compiled. */ this.$setDirty = function() { ctrl.$dirty = true; ctrl.$pristine = false; $animate.removeClass($element, PRISTINE_CLASS); $animate.addClass($element, DIRTY_CLASS); parentForm.$setDirty(); }; /** * @ngdoc method * @name ngModel.NgModelController#$setUntouched * * @description * Sets the control to its untouched state. * * This method can be called to remove the `ng-touched` class and set the control to its * untouched state (`ng-untouched` class). Upon compilation, a model is set as untouched * by default, however this function can be used to restore that state if the model has * already been touched by the user. */ this.$setUntouched = function() { ctrl.$touched = false; ctrl.$untouched = true; $animate.setClass($element, UNTOUCHED_CLASS, TOUCHED_CLASS); }; /** * @ngdoc method * @name ngModel.NgModelController#$setTouched * * @description * Sets the control to its touched state. * * This method can be called to remove the `ng-untouched` class and set the control to its * touched state (`ng-touched` class). A model is considered to be touched when the user has * first focused the control element and then shifted focus away from the control (blur event). */ this.$setTouched = function() { ctrl.$touched = true; ctrl.$untouched = false; $animate.setClass($element, TOUCHED_CLASS, UNTOUCHED_CLASS); }; /** * @ngdoc method * @name ngModel.NgModelController#$rollbackViewValue * * @description * Cancel an update and reset the input element's value to prevent an update to the `$modelValue`, * which may be caused by a pending debounced event or because the input is waiting for a some * future event. * * If you have an input that uses `ng-model-options` to set up debounced events or events such * as blur you can have a situation where there is a period when the `$viewValue` * is out of synch with the ngModel's `$modelValue`. * * In this case, you can run into difficulties if you try to update the ngModel's `$modelValue` * programmatically before these debounced/future events have resolved/occurred, because Angular's * dirty checking mechanism is not able to tell whether the model has actually changed or not. * * The `$rollbackViewValue()` method should be called before programmatically changing the model of an * input which may have such events pending. This is important in order to make sure that the * input field will be updated with the new model value and any pending operations are cancelled. * * <example name=""ng-model-cancel-update"" module=""cancel-update-example""> * <file name=""app.js""> * angular.module('cancel-update-example', []) * * .controller('CancelUpdateController', ['$scope', function($scope) { * $scope.resetWithCancel = function(e) { * if (e.keyCode == 27) { * $scope.myForm.myInput1.$rollbackViewValue(); * $scope.myValue = ''; * } * }; * $scope.resetWithoutCancel = function(e) { * if (e.keyCode == 27) { * $scope.myValue = ''; * } * }; * }]); * </file> * <file name=""index.html""> * <div ng-controller=""CancelUpdateController""> * <p>Try typing something in each input. See that the model only updates when you * blur off the input. * </p> * <p>Now see what happens if you start typing then press the Escape key</p> * * <form name=""myForm"" ng-model-options=""{ updateOn: 'blur' }""> * <p>With $rollbackViewValue()</p> * <input name=""myInput1"" ng-model=""myValue"" ng-keydown=""resetWithCancel($event)""><br/> * myValue: ""{{ myValue }}"" * * <p>Without $rollbackViewValue()</p> * <input name=""myInput2"" ng-model=""myValue"" ng-keydown=""resetWithoutCancel($event)""><br/> * myValue: ""{{ myValue }}"" * </form> * </div> * </file> * </example> */ this.$rollbackViewValue = function() { $timeout.cancel(pendingDebounce); ctrl.$viewValue = ctrl.$$lastCommittedViewValue; ctrl.$render(); }; /** * @ngdoc method * @name ngModel.NgModelController#$validate * * @description * Runs each of the registered validators (first synchronous validators and then * asynchronous validators). * If the validity changes to invalid, the model will be set to `undefined`, * unless {@link ngModelOptions `ngModelOptions.allowInvalid`} is `true`. * If the validity changes to valid, it will set the model to the last available valid * modelValue, i.e. either the last parsed value or the last value set from the scope. */ this.$validate = function() { // ignore $validate before model is initialized if (isNumber(ctrl.$modelValue) && isNaN(ctrl.$modelValue)) { return; } var viewValue = ctrl.$$lastCommittedViewValue; // Note: we use the $$rawModelValue as $modelValue might have been // set to undefined during a view -> model update that found validation // errors. We can't parse the view here, since that could change // the model although neither viewValue nor the model on the scope changed var modelValue = ctrl.$$rawModelValue; // Check if the there's a parse error, so we don't unset it accidentially var parserName = ctrl.$$parserName || 'parse'; var parserValid = ctrl.$error[parserName] ? false : undefined; var prevValid = ctrl.$valid; var prevModelValue = ctrl.$modelValue; var allowInvalid = ctrl.$options && ctrl.$options.allowInvalid; ctrl.$$runValidators(parserValid, modelValue, viewValue, function(allValid) { // If there was no change in validity, don't update the model // This prevents changing an invalid modelValue to undefined if (!allowInvalid && prevValid !== allValid) { // Note: Don't check ctrl.$valid here, as we could have // external validators (e.g. calculated on the server), // that just call $setValidity and need the model value // to calculate their validity. ctrl.$modelValue = allValid ? modelValue : undefined; if (ctrl.$modelValue !== prevModelValue) { ctrl.$$writeModelToScope(); } } }); }; this.$$runValidators = function(parseValid, modelValue, viewValue, doneCallback) { currentValidationRunId++; var localValidationRunId = currentValidationRunId; // check parser error if (!processParseErrors(parseValid)) { validationDone(false); return; } if (!processSyncValidators()) { validationDone(false); return; } processAsyncValidators(); function processParseErrors(parseValid) { var errorKey = ctrl.$$parserName || 'parse'; if (parseValid === undefined) { setValidity(errorKey, null); } else { setValidity(errorKey, parseValid); if (!parseValid) { forEach(ctrl.$validators, function(v, name) { setValidity(name, null); }); forEach(ctrl.$asyncValidators, function(v, name) { setValidity(name, null); }); return false; } } return true; } function processSyncValidators() { var syncValidatorsValid = true; forEach(ctrl.$validators, function(validator, name) { var result = validator(modelValue, viewValue); syncValidatorsValid = syncValidatorsValid && result; setValidity(name, result); }); if (!syncValidatorsValid) { forEach(ctrl.$asyncValidators, function(v, name) { setValidity(name, null); }); return false; } return true; } function processAsyncValidators() { var validatorPromises = []; var allValid = true; forEach(ctrl.$asyncValidators, function(validator, name) { var promise = validator(modelValue, viewValue); if (!isPromiseLike(promise)) { throw $ngModelMinErr(""$asyncValidators"", ""Expected asynchronous validator to return a promise but got '{0}' instead."", promise); } setValidity(name, undefined); validatorPromises.push(promise.then(function() { setValidity(name, true); }, function(error) { allValid = false; setValidity(name, false); })); }); if (!validatorPromises.length) { validationDone(true); } else { $q.all(validatorPromises).then(function() { validationDone(allValid); }, noop); } } function setValidity(name, isValid) { if (localValidationRunId === currentValidationRunId) { ctrl.$setValidity(name, isValid); } } function validationDone(allValid) { if (localValidationRunId === currentValidationRunId) { doneCallback(allValid); } } }; /** * @ngdoc method * @name ngModel.NgModelController#$commitViewValue * * @description * Commit a pending update to the `$modelValue`. * * Updates may be pending by a debounced event or because the input is waiting for a some future * event defined in `ng-model-options`. this method is rarely needed as `NgModelController` * usually handles calling this in response to input events. */ this.$commitViewValue = function() { var viewValue = ctrl.$viewValue; $timeout.cancel(pendingDebounce); // If the view value has not changed then we should just exit, except in the case where there is // a native validator on the element. In this case the validation state may have changed even though // the viewValue has stayed empty. if (ctrl.$$lastCommittedViewValue === viewValue && (viewValue !== '' || !ctrl.$$hasNativeValidators)) { return; } ctrl.$$lastCommittedViewValue = viewValue; // change to dirty if (ctrl.$pristine) { this.$setDirty(); } this.$$parseAndValidate(); }; this.$$parseAndValidate = function() { var viewValue = ctrl.$$lastCommittedViewValue; var modelValue = viewValue; var parserValid = isUndefined(modelValue) ? undefined : true; if (parserValid) { for (var i = 0; i < ctrl.$parsers.length; i++) { modelValue = ctrl.$parsers[i](modelValue); if (isUndefined(modelValue)) { parserValid = false; break; } } } if (isNumber(ctrl.$modelValue) && isNaN(ctrl.$modelValue)) { // ctrl.$modelValue has not been touched yet... ctrl.$modelValue = ngModelGet($scope); } var prevModelValue = ctrl.$modelValue; var allowInvalid = ctrl.$options && ctrl.$options.allowInvalid; ctrl.$$rawModelValue = modelValue; if (allowInvalid) { ctrl.$modelValue = modelValue; writeToModelIfNeeded(); } // Pass the $$lastCommittedViewValue here, because the cached viewValue might be out of date. // This can happen if e.g. $setViewValue is called from inside a parser ctrl.$$runValidators(parserValid, modelValue, ctrl.$$lastCommittedViewValue, function(allValid) { if (!allowInvalid) { // Note: Don't check ctrl.$valid here, as we could have // external validators (e.g. calculated on the server), // that just call $setValidity and need the model value // to calculate their validity. ctrl.$modelValue = allValid ? modelValue : undefined; writeToModelIfNeeded(); } }); function writeToModelIfNeeded() { if (ctrl.$modelValue !== prevModelValue) { ctrl.$$writeModelToScope(); } } }; this.$$writeModelToScope = function() { ngModelSet($scope, ctrl.$modelValue); forEach(ctrl.$viewChangeListeners, function(listener) { try { listener(); } catch (e) { $exceptionHandler(e); } }); }; /** * @ngdoc method * This method should be called when an input directive want to change the view value; typically, * this is done from within a DOM event handler. * For example {@link ng.directive:input input} calls it when the value of the input changes and * {@link ng.directive:select select} calls it when an option is selected. * * If the new `value` is an object (rather than a string or a number), we should make a copy of the * object before passing it to `$setViewValue`. This is because `ngModel` does not perform a deep * watch of objects, it only looks for a change of identity. If you only change the property of * the object then ngModel will not realise that the object has changed and will not invoke the * `$parsers` and `$validators` pipelines. * * For this reason, you should not change properties of the copy once it has been passed to * `$setViewValue`. Otherwise you may cause the model value on the scope to change incorrectly. * * When this method is called, the new `value` will be staged for committing through the `$parsers` * and `$validators` pipelines. If there are no special {@link ngModelOptions} specified then the staged * value sent directly for processing, finally to be applied to `$modelValue` and then the * **expression** specified in the `ng-model` attribute. * In case the {@link ng.directive:ngModelOptions ngModelOptions} directive is used with `updateOn` * and the `default` trigger is not listed, all those actions will remain pending until one of the * `updateOn` events is triggered on the DOM element. * All these actions will be debounced if the {@link ng.directive:ngModelOptions ngModelOptions} * directive is used with a custom debounce for this particular event. * * @param {string} trigger Event that triggered the update. this.$setViewValue = function(value, trigger) { ctrl.$viewValue = value; if (!ctrl.$options || ctrl.$options.updateOnDefault) { ctrl.$$debounceViewValueCommit(trigger); } }; this.$$debounceViewValueCommit = function(trigger) { var debounceDelay = 0, options = ctrl.$options, debounce; if (options && isDefined(options.debounce)) { debounce = options.debounce; if (isNumber(debounce)) { debounceDelay = debounce; } else if (isNumber(debounce[trigger])) { debounceDelay = debounce[trigger]; } else if (isNumber(debounce['default'])) { debounceDelay = debounce['default']; } $timeout.cancel(pendingDebounce); if (debounceDelay) { pendingDebounce = $timeout(function() { ctrl.$commitViewValue(); }, debounceDelay); } else if ($rootScope.$$phase) { ctrl.$commitViewValue(); } else { $scope.$apply(function() { ctrl.$commitViewValue(); // Note: we cannot use a normal scope.$watch as we want to detect the following: // 1. scope value is 'a' // 2. user enters 'b' // 3. ng-change kicks in and reverts scope value to 'a' // -> scope value did not change since the last digest as // ng-change executes in apply phase // 4. view should be changed back to 'a' var modelValue = ngModelGet($scope); // TODO(perf): why not move this to the action fn? if (modelValue !== ctrl.$modelValue) { ctrl.$modelValue = ctrl.$$rawModelValue = modelValue; var viewValue = modelValue; while (idx--) { viewValue = formatters[idx](viewValue); if (ctrl.$viewValue !== viewValue) { ctrl.$viewValue = ctrl.$$lastCommittedViewValue = viewValue; ctrl.$$runValidators(undefined, modelValue, viewValue, noop); return modelValue; * @priority 1 * - Keeping the state of the control (valid/invalid, dirty/pristine, touched/untouched, validation errors). * - Setting related css classes on the element (`ng-valid`, `ng-invalid`, `ng-dirty`, `ng-pristine`, `ng-touched`, `ng-untouched`) including animations. * - [Understanding Scopes](https://github.com/angular/angular.js/wiki/Understanding-Scopes) * - {@link input[date] date} * - {@link input[datetime-local] datetime-local} * - {@link input[time] time} * - {@link input[month] month} * - {@link input[week] week} * - `ng-valid`: the model is valid * - `ng-invalid`: the model is invalid * - `ng-valid-[key]`: for each valid key added by `$setValidity` * - `ng-invalid-[key]`: for each invalid key added by `$setValidity` * - `ng-pristine`: the control hasn't been interacted with yet * - `ng-dirty`: the control has been interacted with * - `ng-touched`: the control has been blurred * - `ng-untouched`: the control hasn't been blurred * - `ng-pending`: any `$asyncValidators` are unfulfilled * <example deps=""angular-animate.js"" animations=""true"" fixBase=""true"" module=""inputExample""> angular.module('inputExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.val = '1'; }]); <form name=""testForm"" ng-controller=""ExampleController""> * * ## Binding to a getter/setter * * Sometimes it's helpful to bind `ngModel` to a getter/setter function. A getter/setter is a * function that returns a representation of the model when called with zero arguments, and sets * the internal state of a model when called with an argument. It's sometimes useful to use this * for models that have an internal representation that's different than what the model exposes * to the view. * * <div class=""alert alert-success""> * **Best Practice:** It's best to keep getters fast because Angular is likely to call them more * frequently than other parts of your code. * </div> * * You use this behavior by adding `ng-model-options=""{ getterSetter: true }""` to an element that * has `ng-model` attached to it. You can also add `ng-model-options=""{ getterSetter: true }""` to * a `<form>`, which will enable this behavior for all `<input>`s within it. See * {@link ng.directive:ngModelOptions `ngModelOptions`} for more. * * The following example shows how to use `ngModel` with a getter/setter: * * @example * <example name=""ngModel-getter-setter"" module=""getterSetterExample""> <file name=""index.html""> <div ng-controller=""ExampleController""> <form name=""userForm""> Name: <input type=""text"" name=""userName"" ng-model=""user.name"" ng-model-options=""{ getterSetter: true }"" /> </form> <pre>user.name = <span ng-bind=""user.name()""></span></pre> </div> </file> <file name=""app.js""> angular.module('getterSetterExample', []) .controller('ExampleController', ['$scope', function($scope) { var _name = 'Brian'; $scope.user = { name: function(newName) { if (angular.isDefined(newName)) { _name = newName; } return _name; } }; }]); </file> * </example>var ngModelDirective = ['$rootScope', function($rootScope) { restrict: 'A', require: ['ngModel', '^?form', '^?ngModelOptions'], // Prelink needs to run before any input directive // so that we can set the NgModelOptions in NgModelController // before anyone else uses it. priority: 1, compile: function ngModelCompile(element) { // Setup initial state of the control element.addClass(PRISTINE_CLASS).addClass(UNTOUCHED_CLASS).addClass(VALID_CLASS); return { pre: function ngModelPreLink(scope, element, attr, ctrls) { var modelCtrl = ctrls[0], formCtrl = ctrls[1] || nullFormCtrl; modelCtrl.$$setOptions(ctrls[2] && ctrls[2].$options); // notify others, especially parent forms formCtrl.$addControl(modelCtrl); attr.$observe('name', function(newValue) { if (modelCtrl.$name !== newValue) { formCtrl.$$renameControl(modelCtrl, newValue); } }); scope.$on('$destroy', function() { formCtrl.$removeControl(modelCtrl); }); }, post: function ngModelPostLink(scope, element, attr, ctrls) { var modelCtrl = ctrls[0]; if (modelCtrl.$options && modelCtrl.$options.updateOn) { element.on(modelCtrl.$options.updateOn, function(ev) { modelCtrl.$$debounceViewValueCommit(ev && ev.type); }); } element.on('blur', function(ev) { if (modelCtrl.$touched) return; if ($rootScope.$$phase) { scope.$evalAsync(modelCtrl.$setTouched); } else { scope.$apply(modelCtrl.$setTouched); } }); } };}]; * * The `ngChange` expression is only evaluated when a change in the input value causes * a new value to be committed to the model. * * It will not be evaluated: * * if the value returned from the `$parsers` transformation pipeline has not changed * * if the input has continued to be invalid since the model will stay `null` * * if the model is changed programmatically and not by a change to the input value * * <example name=""ngChange-directive"" module=""changeExample""> * angular.module('changeExample', []) * .controller('ExampleController', ['$scope', function($scope) { * $scope.counter = 0; * $scope.change = function() { * $scope.counter++; * }; * }]); * <div ng-controller=""ExampleController""> restrict: 'A', restrict: 'A', ctrl.$validators.required = function(modelValue, viewValue) { return !attr.required || !ctrl.$isEmpty(viewValue); ctrl.$validate();var patternDirective = function() { return { restrict: 'A', require: '?ngModel', link: function(scope, elm, attr, ctrl) { if (!ctrl) return; var regexp, patternExp = attr.ngPattern || attr.pattern; attr.$observe('pattern', function(regex) { if (isString(regex) && regex.length > 0) { regex = new RegExp('^' + regex + '$'); } if (regex && !regex.test) { throw minErr('ngPattern')('noregexp', 'Expected {0} to be a RegExp but was {1}. Element: {2}', patternExp, regex, startingTag(elm)); } regexp = regex || undefined; ctrl.$validate(); }); ctrl.$validators.pattern = function(value) { return ctrl.$isEmpty(value) || isUndefined(regexp) || regexp.test(value); }; } }; }; var maxlengthDirective = function() { return { restrict: 'A', require: '?ngModel', link: function(scope, elm, attr, ctrl) { if (!ctrl) return; var maxlength = -1; attr.$observe('maxlength', function(value) { var intVal = int(value); maxlength = isNaN(intVal) ? -1 : intVal; ctrl.$validate(); }); ctrl.$validators.maxlength = function(modelValue, viewValue) { return (maxlength < 0) || ctrl.$isEmpty(modelValue) || (viewValue.length <= maxlength); }; } }; }; var minlengthDirective = function() { return { restrict: 'A', require: '?ngModel', link: function(scope, elm, attr, ctrl) { if (!ctrl) return; var minlength = 0; attr.$observe('minlength', function(value) { minlength = int(value) || 0; ctrl.$validate(); }); ctrl.$validators.minlength = function(modelValue, viewValue) { return ctrl.$isEmpty(viewValue) || viewValue.length >= minlength; }; } }; }; * Text input that converts between a delimited string and an array of strings. The default * delimiter is a comma followed by a space - equivalent to `ng-list="", ""`. You can specify a custom * delimiter as the value of the `ngList` attribute - for example, `ng-list="" | ""`. * * The behaviour of the directive is affected by the use of the `ngTrim` attribute. * * If `ngTrim` is set to `""false""` then whitespace around both the separator and each * list item is respected. This implies that the user of the directive is responsible for * dealing with whitespace but also allows you to use whitespace as a delimiter, such as a * tab or newline character. * * Otherwise whitespace around the delimiter is ignored when splitting (although it is respected * when joining the list items back together) and whitespace around each list item is stripped * before it is added to the model. * * ### Example with Validation * * <example name=""ngList-directive"" module=""listExample""> * <file name=""app.js""> * angular.module('listExample', []) * .controller('ExampleController', ['$scope', function($scope) { * $scope.names = ['morpheus', 'neo', 'trinity']; * }]); * </file> * <file name=""index.html""> * <form name=""myForm"" ng-controller=""ExampleController""> * List: <input name=""namesInput"" ng-model=""names"" ng-list required> * <span class=""error"" ng-show=""myForm.namesInput.$error.required""> * Required!</span> * <br> * <tt>names = {{names}}</tt><br/> * <tt>myForm.namesInput.$valid = {{myForm.namesInput.$valid}}</tt><br/> * <tt>myForm.namesInput.$error = {{myForm.namesInput.$error}}</tt><br/> * <tt>myForm.$valid = {{myForm.$valid}}</tt><br/> * <tt>myForm.$error.required = {{!!myForm.$error.required}}</tt><br/> * </form> * </file> * <file name=""protractor.js"" type=""protractor""> * var listInput = element(by.model('names')); * var names = element(by.exactBinding('names')); * var valid = element(by.binding('myForm.namesInput.$valid')); * var error = element(by.css('span.error')); * * it('should initialize to model', function() { * expect(names.getText()).toContain('[""morpheus"",""neo"",""trinity""]'); * expect(valid.getText()).toContain('true'); * expect(error.getCssValue('display')).toBe('none'); * }); * * it('should be invalid if empty', function() { * listInput.clear(); * listInput.sendKeys(''); * * expect(names.getText()).toContain(''); * expect(valid.getText()).toContain('false'); * expect(error.getCssValue('display')).not.toBe('none'); * }); * </file> * </example> * * ### Example - splitting on whitespace * <example name=""ngList-directive-newlines""> * <file name=""index.html""> * <textarea ng-model=""list"" ng-list=""&#10;"" ng-trim=""false""></textarea> * <pre>{{ list | json }}</pre> * </file> * <file name=""protractor.js"" type=""protractor""> * it(""should split the text by newlines"", function() { * var listInput = element(by.model('list')); * var output = element(by.binding('list | json')); * listInput.sendKeys('abc\ndef\nghi'); * expect(output.getText()).toContain('[\n ""abc"",\n ""def"",\n ""ghi""\n]'); * }); * </file> * </example> * @param {string=} ngList optional delimiter that should be used to split the value. restrict: 'A', priority: 100, // We want to control whitespace trimming so we use this convoluted approach // to access the ngList attribute, which doesn't pre-trim the attribute var ngList = element.attr(attr.$attr.ngList) || ', '; var trimValues = attr.ngTrim !== 'false'; var separator = trimValues ? trim(ngList) : ngList; if (value) list.push(trimValues ? trim(value) : value); return value.join(ngList); * Binds the given expression to the value of `<option>` or {@link input[radio] `input[radio]`}, * so that when the element is selected, the {@link ngModel `ngModel`} of that element is set to * the bound value. * `ngValue` is useful when dynamically generating lists of radio buttons using * {@link ngRepeat `ngRepeat`}, as shown below. * * Likewise, `ngValue` can be used to generate `<option>` elements for * the {@link select `select`} element. In that case however, only strings are supported * for the `value `attribute, so the resulting `ngModel` will always be a string. * Support for `select` models with non-string values is available via `ngOptions`. <example name=""ngValue-directive"" module=""valueExample""> angular.module('valueExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.names = ['pizza', 'unicorns', 'robots']; $scope.my = { favorite: 'unicorns' }; }]); <form ng-controller=""ExampleController""> restrict: 'A', * @name ngModelOptions * * @description * Allows tuning how model updates are done. Using `ngModelOptions` you can specify a custom list of * events that will trigger a model update and/or a debouncing delay so that the actual update only * takes place when a timer expires; this timer will be reset after another change takes place. * * Given the nature of `ngModelOptions`, the value displayed inside input fields in the view might * be different than the value in the actual model. This means that if you update the model you * should also invoke {@link ngModel.NgModelController `$rollbackViewValue`} on the relevant input field in * order to make sure it is synchronized with the model and that any debounced action is canceled. * * The easiest way to reference the control's {@link ngModel.NgModelController `$rollbackViewValue`} * method is by making sure the input is placed inside a form that has a `name` attribute. This is * important because `form` controllers are published to the related scope under the name in their * `name` attribute. * * Any pending changes will take place immediately when an enclosing form is submitted via the * `submit` event. Note that `ngClick` events will occur before the model is updated. Use `ngSubmit` * to have access to the updated model. * * `ngModelOptions` has an effect on the element it's declared on and its descendants. * * @param {Object} ngModelOptions options to apply to the current model. Valid keys are: * - `updateOn`: string specifying which event should the input be bound to. You can set several * events using an space delimited list. There is a special event called `default` that * matches the default events belonging of the control. * - `debounce`: integer value which contains the debounce model update value in milliseconds. A * value of 0 triggers an immediate update. If an object is supplied instead, you can specify a * custom value for each event. For example: * `ng-model-options=""{ updateOn: 'default blur', debounce: {'default': 500, 'blur': 0} }""` * - `allowInvalid`: boolean value which indicates that the model can be set with values that did * not validate correctly instead of the default behavior of setting the model to undefined. * - `getterSetter`: boolean value which determines whether or not to treat functions bound to `ngModel` as getters/setters. * - `timezone`: Defines the timezone to be used to read/write the `Date` instance in the model for * `<input type=""date"">`, `<input type=""time"">`, ... . Right now, the only supported value is `'UTC'`, * otherwise the default timezone of the browser will be used. * * @example The following example shows how to override immediate updates. Changes on the inputs within the form will update the model only when the control loses focus (blur event). If `escape` key is pressed while the input field is focused, the value is reset to the value in the current model. <example name=""ngModelOptions-directive-blur"" module=""optionsExample""> <file name=""index.html""> <div ng-controller=""ExampleController""> <form name=""userForm""> Name: <input type=""text"" name=""userName"" ng-model=""user.name"" ng-model-options=""{ updateOn: 'blur' }"" ng-keyup=""cancel($event)"" /><br /> Other data: <input type=""text"" ng-model=""user.data"" /><br /> </form> <pre>user.name = <span ng-bind=""user.name""></span></pre> </div> </file> <file name=""app.js""> angular.module('optionsExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.user = { name: 'say', data: '' }; $scope.cancel = function(e) { if (e.keyCode == 27) { $scope.userForm.userName.$rollbackViewValue(); } }; }]); </file> <file name=""protractor.js"" type=""protractor""> var model = element(by.binding('user.name')); var input = element(by.model('user.name')); var other = element(by.model('user.data')); it('should allow custom events', function() { input.sendKeys(' hello'); input.click(); expect(model.getText()).toEqual('say'); other.click(); expect(model.getText()).toEqual('say hello'); }); it('should $rollbackViewValue when model changes', function() { input.sendKeys(' hello'); expect(input.getAttribute('value')).toEqual('say hello'); input.sendKeys(protractor.Key.ESCAPE); expect(input.getAttribute('value')).toEqual('say'); other.click(); expect(model.getText()).toEqual('say'); }); </file> </example> This one shows how to debounce model changes. Model will be updated only 1 sec after last change. If the `Clear` button is pressed, any debounced action is canceled and the value becomes empty. <example name=""ngModelOptions-directive-debounce"" module=""optionsExample""> <file name=""index.html""> <div ng-controller=""ExampleController""> <form name=""userForm""> Name: <input type=""text"" name=""userName"" ng-model=""user.name"" ng-model-options=""{ debounce: 1000 }"" /> <button ng-click=""userForm.userName.$rollbackViewValue(); user.name=''"">Clear</button><br /> </form> <pre>user.name = <span ng-bind=""user.name""></span></pre> </div> </file> <file name=""app.js""> angular.module('optionsExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.user = { name: 'say' }; }]); </file> </example> This one shows how to bind to getter/setters: <example name=""ngModelOptions-directive-getter-setter"" module=""getterSetterExample""> <file name=""index.html""> <div ng-controller=""ExampleController""> <form name=""userForm""> Name: <input type=""text"" name=""userName"" ng-model=""user.name"" ng-model-options=""{ getterSetter: true }"" /> </form> <pre>user.name = <span ng-bind=""user.name()""></span></pre> </div> </file> <file name=""app.js""> angular.module('getterSetterExample', []) .controller('ExampleController', ['$scope', function($scope) { var _name = 'Brian'; $scope.user = { name: function(newName) { return angular.isDefined(newName) ? (_name = newName) : _name; } }; }]); </file> </example> */ var ngModelOptionsDirective = function() { return { restrict: 'A', controller: ['$scope', '$attrs', function($scope, $attrs) { var that = this; this.$options = $scope.$eval($attrs.ngModelOptions); // Allow adding/overriding bound events if (this.$options.updateOn !== undefined) { this.$options.updateOnDefault = false; // extract ""default"" pseudo-event from list of events that can trigger a model update this.$options.updateOn = trim(this.$options.updateOn.replace(DEFAULT_REGEXP, function() { that.$options.updateOnDefault = true; return ' '; })); } else { this.$options.updateOnDefault = true; } }] }; }; // helper methods function addSetValidityMethod(context) { var ctrl = context.ctrl, $element = context.$element, classCache = {}, set = context.set, unset = context.unset, parentForm = context.parentForm, $animate = context.$animate; classCache[INVALID_CLASS] = !(classCache[VALID_CLASS] = $element.hasClass(VALID_CLASS)); ctrl.$setValidity = setValidity; function setValidity(validationErrorKey, state, options) { if (state === undefined) { createAndSet('$pending', validationErrorKey, options); } else { unsetAndCleanup('$pending', validationErrorKey, options); } if (!isBoolean(state)) { unset(ctrl.$error, validationErrorKey, options); unset(ctrl.$$success, validationErrorKey, options); } else { if (state) { unset(ctrl.$error, validationErrorKey, options); set(ctrl.$$success, validationErrorKey, options); } else { set(ctrl.$error, validationErrorKey, options); unset(ctrl.$$success, validationErrorKey, options); } } if (ctrl.$pending) { cachedToggleClass(PENDING_CLASS, true); ctrl.$valid = ctrl.$invalid = undefined; toggleValidationCss('', null); } else { cachedToggleClass(PENDING_CLASS, false); ctrl.$valid = isObjectEmpty(ctrl.$error); ctrl.$invalid = !ctrl.$valid; toggleValidationCss('', ctrl.$valid); } // re-read the state as the set/unset methods could have // combined state in ctrl.$error[validationError] (used for forms), // where setting/unsetting only increments/decrements the value, // and does not replace it. var combinedState; if (ctrl.$pending && ctrl.$pending[validationErrorKey]) { combinedState = undefined; } else if (ctrl.$error[validationErrorKey]) { combinedState = false; } else if (ctrl.$$success[validationErrorKey]) { combinedState = true; } else { combinedState = null; } toggleValidationCss(validationErrorKey, combinedState); parentForm.$setValidity(validationErrorKey, combinedState, ctrl); } function createAndSet(name, value, options) { if (!ctrl[name]) { ctrl[name] = {}; } set(ctrl[name], value, options); } function unsetAndCleanup(name, value, options) { if (ctrl[name]) { unset(ctrl[name], value, options); } if (isObjectEmpty(ctrl[name])) { ctrl[name] = undefined; } } function cachedToggleClass(className, switchValue) { if (switchValue && !classCache[className]) { $animate.addClass($element, className); classCache[className] = true; } else if (!switchValue && classCache[className]) { $animate.removeClass($element, className); classCache[className] = false; } } function toggleValidationCss(validationErrorKey, isValid) { validationErrorKey = validationErrorKey ? '-' + snake_case(validationErrorKey, '-') : ''; cachedToggleClass(VALID_CLASS + validationErrorKey, isValid === true); cachedToggleClass(INVALID_CLASS + validationErrorKey, isValid === false); } } function isObjectEmpty(obj) { if (obj) { for (var prop in obj) { return false; } } return true; } /** * @ngdoc directive * It is preferable to use `ngBind` instead of `{{ expression }}` if a template is momentarily <example module=""bindExample""> angular.module('bindExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.name = 'Whirled'; }]); <div ng-controller=""ExampleController"">var ngBindDirective = ['$compile', function($compile) { return { restrict: 'AC', compile: function ngBindCompile(templateElement) { $compile.$$addBindingClass(templateElement); return function ngBindLink(scope, element, attr) { $compile.$$addBindingInfo(element, attr.ngBind); element = element[0]; scope.$watch(attr.ngBind, function ngBindWatchAction(value) { element.textContent = value === undefined ? '' : value; }); }; } }; }]; <example module=""bindExample""> angular.module('bindExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.salutation = 'Hello'; $scope.name = 'World'; }]); <div ng-controller=""ExampleController"">var ngBindTemplateDirective = ['$interpolate', '$compile', function($interpolate, $compile) { return { compile: function ngBindTemplateCompile(templateElement) { $compile.$$addBindingClass(templateElement); return function ngBindTemplateLink(scope, element, attr) { var interpolateFn = $interpolate(element.attr(attr.$attr.ngBindTemplate)); $compile.$$addBindingInfo(element, interpolateFn.expressions); element = element[0]; attr.$observe('ngBindTemplate', function(value) { element.textContent = value === undefined ? '' : value; }); }; } * Evaluates the expression and inserts the resulting HTML into the element in a secure way. By default, * the resulting HTML content will be sanitized using the {@link ngSanitize.$sanitize $sanitize} service. * To utilize this functionality, ensure that `$sanitize` is available, for example, by including {@link * ngSanitize} in your module's dependencies (not in core Angular). In order to use {@link ngSanitize} * in your module's dependencies, you need to include ""angular-sanitize.js"" in your application. * * You may also bypass sanitization for values you know are safe. To do so, bind to * under {@link ng.$sce#show-me-an-example-using-sce- Strict Contextual Escaping (SCE)}. <example module=""bindHtmlExample"" deps=""angular-sanitize.js""> <div ng-controller=""ExampleController""> angular.module('bindHtmlExample', ['ngSanitize']) .controller('ExampleController', ['$scope', function($scope) { $scope.myHTML = 'I am an <code>HTML</code>string with ' + '<a href=""#"">links!</a> and other <em>stuff</em>'; }]);var ngBindHtmlDirective = ['$sce', '$parse', '$compile', function($sce, $parse, $compile) { return { restrict: 'A', compile: function ngBindHtmlCompile(tElement, tAttrs) { var ngBindHtmlGetter = $parse(tAttrs.ngBindHtml); var ngBindHtmlWatch = $parse(tAttrs.ngBindHtml, function getStringValue(value) { return (value || '').toString(); }); $compile.$$addBindingClass(tElement); return function ngBindHtmlLink(scope, element, attr) { $compile.$$addBindingInfo(element, attr.ngBindHtml); scope.$watch(ngBindHtmlWatch, function ngBindHtmlWatchAction() { // we re-evaluate the expr because we want a TrustedValueHolderType // for $sce, not a string element.html($sce.getTrustedHtml(ngBindHtmlGetter(scope)) || ''); }); }; } if (mod !== (old$index & 1)) { function digestClassCounts(classes, count) { forEach(classes, function(className) { function updateClasses(oldClasses, newClasses) { toRemove = digestClassCounts(toRemove, -1); if (toAdd && toAdd.length) { } if (toRemove && toRemove.length) { $animate.removeClass(element, toRemove); oldVal = shallowCopy(newVal); for (var i = 0; i < tokens1.length; i++) { for (var j = 0; j < tokens2.length; j++) { if (token == tokens2[j]) continue outer; function arrayClasses(classVal) { var classes = []; classes = classes.concat(k.split(' ')); to view the step by step details of {@link ng.$animate#addClass $animate.addClass} and {@link ng.$animate#removeClass $animate.removeClass}. * * Model — Models are the properties of a scope; scopes are attached to the DOM where scope properties * @priority 500 * @param {expression} ngController Name of a constructor function registered with the current * {@link ng.$controllerProvider $controllerProvider} or an {@link guide/expression expression} * that on the current scope evaluates to a constructor function. * * The controller instance can be published into a scope property by specifying * `ng-controller=""as propertyName""`. * * If the current `$controllerProvider` is configured to use globals (via * {@link ng.$controllerProvider#allowGlobals `$controllerProvider.allowGlobals()` }), this may * also be the name of a globally accessible constructor function (not recommended). * easily be called from the angular markup. Any changes to the data are automatically reflected * in the View without the need for a manual update. * * Two different declaration styles are included below: * * * one binds methods and properties directly onto the controller using `this`: * `ng-controller=""SettingsController1 as settings""` * * one injects `$scope` into the controller: * `ng-controller=""SettingsController2""` * * The second option is more common in the Angular community, and is generally used in boilerplates * and in this guide. However, there are advantages to binding properties directly to the controller * and avoiding scope. * * * Using `controller as` makes it obvious which controller you are accessing in the template when * multiple controllers apply to an element. * * If you are writing your controllers as classes you have easier access to the properties and * methods, which will appear on the scope, from inside the controller code. * * Since there is always a `.` in the bindings, you don't have to worry about prototypal * inheritance masking primitives. * * This example demonstrates the `controller as` syntax. * * <example name=""ngControllerAs"" module=""controllerAsExample""> * <file name=""index.html""> * <div id=""ctrl-as-exmpl"" ng-controller=""SettingsController1 as settings""> * Name: <input type=""text"" ng-model=""settings.name""/> * [ <a href="""" ng-click=""settings.greet()"">greet</a> ]<br/> * Contact: * <ul> * <li ng-repeat=""contact in settings.contacts""> * <select ng-model=""contact.type""> * <option>phone</option> * <option>email</option> * </select> * <input type=""text"" ng-model=""contact.value""/> * [ <a href="""" ng-click=""settings.clearContact(contact)"">clear</a> * | <a href="""" ng-click=""settings.removeContact(contact)"">X</a> ] * </li> * <li>[ <a href="""" ng-click=""settings.addContact()"">add</a> ]</li> * </ul> * </div> * </file> * <file name=""app.js""> * angular.module('controllerAsExample', []) * .controller('SettingsController1', SettingsController1); * * function SettingsController1() { * this.name = ""John Smith""; * this.contacts = [ * {type: 'phone', value: '408 555 1212'}, * {type: 'email', value: 'john.smith@example.org'} ]; * } * * SettingsController1.prototype.greet = function() { * alert(this.name); * }; * * SettingsController1.prototype.addContact = function() { * this.contacts.push({type: 'email', value: 'yourname@example.org'}); * }; * * SettingsController1.prototype.removeContact = function(contactToRemove) { * var index = this.contacts.indexOf(contactToRemove); * this.contacts.splice(index, 1); * }; * * SettingsController1.prototype.clearContact = function(contact) { * contact.type = 'phone'; * contact.value = ''; * }; * </file> * <file name=""protractor.js"" type=""protractor""> * it('should check controller as', function() { * var container = element(by.id('ctrl-as-exmpl')); * expect(container.element(by.model('settings.name')) * .getAttribute('value')).toBe('John Smith'); * * var firstRepeat = * container.element(by.repeater('contact in settings.contacts').row(0)); * var secondRepeat = * container.element(by.repeater('contact in settings.contacts').row(1)); * * expect(firstRepeat.element(by.model('contact.value')).getAttribute('value')) * .toBe('408 555 1212'); * * expect(secondRepeat.element(by.model('contact.value')).getAttribute('value')) * .toBe('john.smith@example.org'); * * firstRepeat.element(by.linkText('clear')).click(); * * expect(firstRepeat.element(by.model('contact.value')).getAttribute('value')) * .toBe(''); * * container.element(by.linkText('add')).click(); * * expect(container.element(by.repeater('contact in settings.contacts').row(2)) * .element(by.model('contact.value')) * .getAttribute('value')) * .toBe('yourname@example.org'); * }); * </file> * </example> * * This example demonstrates the ""attach to `$scope`"" style of controller. * * <example name=""ngController"" module=""controllerExample""> * <file name=""index.html""> * <div id=""ctrl-exmpl"" ng-controller=""SettingsController2""> * Name: <input type=""text"" ng-model=""name""/> * [ <a href="""" ng-click=""greet()"">greet</a> ]<br/> * Contact: * <ul> * <li ng-repeat=""contact in contacts""> * <select ng-model=""contact.type""> * <option>phone</option> * <option>email</option> * </select> * <input type=""text"" ng-model=""contact.value""/> * [ <a href="""" ng-click=""clearContact(contact)"">clear</a> * | <a href="""" ng-click=""removeContact(contact)"">X</a> ] * </li> * <li>[ <a href="""" ng-click=""addContact()"">add</a> ]</li> * </ul> * </div> * </file> * <file name=""app.js""> * angular.module('controllerExample', []) * .controller('SettingsController2', ['$scope', SettingsController2]); * * function SettingsController2($scope) { * $scope.name = ""John Smith""; * $scope.contacts = [ * {type:'phone', value:'408 555 1212'}, * {type:'email', value:'john.smith@example.org'} ]; * * $scope.greet = function() { * alert($scope.name); * }; * * $scope.addContact = function() { * $scope.contacts.push({type:'email', value:'yourname@example.org'}); * }; * * $scope.removeContact = function(contactToRemove) { * var index = $scope.contacts.indexOf(contactToRemove); * $scope.contacts.splice(index, 1); * }; * * $scope.clearContact = function(contact) { * contact.type = 'phone'; * contact.value = ''; * }; * } * </file> * <file name=""protractor.js"" type=""protractor""> * it('should check controller', function() { * var container = element(by.id('ctrl-exmpl')); * * expect(container.element(by.model('name')) * .getAttribute('value')).toBe('John Smith'); * * var firstRepeat = * container.element(by.repeater('contact in contacts').row(0)); * var secondRepeat = * container.element(by.repeater('contact in contacts').row(1)); * * expect(firstRepeat.element(by.model('contact.value')).getAttribute('value')) * .toBe('408 555 1212'); * expect(secondRepeat.element(by.model('contact.value')).getAttribute('value')) * .toBe('john.smith@example.org'); * * firstRepeat.element(by.linkText('clear')).click(); * * expect(firstRepeat.element(by.model('contact.value')).getAttribute('value')) * .toBe(''); * * container.element(by.linkText('add')).click(); * * expect(container.element(by.repeater('contact in contacts').row(2)) * .element(by.model('contact.value')) * .getAttribute('value')) * .toBe('yourname@example.org'); * }); * </file> *</example> restrict: 'A', * This is necessary when developing things like Google Chrome Extensions or Universal Windows Apps. * For Angular to be CSP compatible there are only two things that we need to do differently: * * - don't use `Function` constructor to generate optimized value getters * - don't inject custom stylesheet into the document * Angular tries to autodetect if CSP is active and automatically turn on the CSP-safe mode. This * autodetection however triggers a CSP error to be logged in the console: * * ``` * Refused to evaluate a string as JavaScript because 'unsafe-eval' is not an allowed source of * script in the following Content Security Policy directive: ""default-src 'self'"". Note that * 'script-src' was not explicitly set, so 'default-src' is used as a fallback. * ``` * * This error is harmless but annoying. To prevent the error from showing up, put the `ngCsp` * directive on the root element of the application or on the `angular.js` script tag, whichever * appears first in the html document. * @example // Note: the suffix `.csp` in the example name triggers // csp mode in our http server! <example name=""example.csp"" module=""cspExample"" ng-csp=""true""> <file name=""index.html""> <div ng-controller=""MainController as ctrl""> <div> <button ng-click=""ctrl.inc()"" id=""inc"">Increment</button> <span id=""counter""> {{ctrl.counter}} </span> </div> <div> <button ng-click=""ctrl.evil()"" id=""evil"">Evil</button> <span id=""evilError""> {{ctrl.evilError}} </span> </div> </div> </file> <file name=""script.js""> angular.module('cspExample', []) .controller('MainController', function() { this.counter = 0; this.inc = function() { this.counter++; }; this.evil = function() { // jshint evil:true try { eval('1+2'); } catch (e) { this.evilError = e.message; } }; }); </file> <file name=""protractor.js"" type=""protractor""> var util, webdriver; var incBtn = element(by.id('inc')); var counter = element(by.id('counter')); var evilBtn = element(by.id('evil')); var evilError = element(by.id('evilError')); function getAndClearSevereErrors() { return browser.manage().logs().get('browser').then(function(browserLog) { return browserLog.filter(function(logEntry) { return logEntry.level.value > webdriver.logging.Level.WARNING.value; }); }); } function clearErrors() { getAndClearSevereErrors(); } function expectNoErrors() { getAndClearSevereErrors().then(function(filteredLog) { expect(filteredLog.length).toEqual(0); if (filteredLog.length) { console.log('browser console errors: ' + util.inspect(filteredLog)); } }); } function expectError(regex) { getAndClearSevereErrors().then(function(filteredLog) { var found = false; filteredLog.forEach(function(log) { if (log.message.match(regex)) { found = true; } }); if (!found) { throw new Error('expected an error that matches ' + regex); } }); } beforeEach(function() { util = require('util'); webdriver = require('protractor/node_modules/selenium-webdriver'); }); // For now, we only test on Chrome, // as Safari does not load the page with Protractor's injected scripts, // and Firefox webdriver always disables content security policy (#6358) if (browser.params.browser !== 'chrome') { return; } it('should not report errors when the page is loaded', function() { // clear errors so we are not dependent on previous tests clearErrors(); // Need to reload the page as the page is already loaded when // we come here browser.driver.getCurrentUrl().then(function(url) { browser.get(url); }); expectNoErrors(); }); it('should evaluate expressions', function() { expect(counter.getText()).toEqual('0'); incBtn.click(); expect(counter.getText()).toEqual('1'); expectNoErrors(); }); it('should throw and report an error when using ""eval""', function() { evilBtn.click(); expect(evilError.getText()).toMatch(/Content Security Policy/); expectError(/Content Security Policy/); }); </file> </example> */ // ngCsp is not implemented as a proper directive any more, because we need it be processed while we // bootstrap the system (before $parse is instantiated), for this reason we just have // the csp.isActive() fn that looks for ng-csp attribute anywhere in the current doc <span> count: {{count}} </span> * A collection of directives that allows creation of custom event handlers that are defined as * angular expressions and are compiled and executed within the current scope. // For events that might fire synchronously during DOM manipulation // we need to execute their event handlers asynchronously using $evalAsync, // so that they are not executed in an inconsistent state. var forceAsyncEvents = { 'blur': true, 'focus': true }; function(eventName) { var directiveName = directiveNormalize('ng-' + eventName); ngEventDirectives[directiveName] = ['$parse', '$rootScope', function($parse, $rootScope) { restrict: 'A', // We expose the powerful $event object on the scope that provides access to the Window, // etc. that isn't protected by the fast paths in $parse. We explicitly request better // checks at the cost of speed since event handler expressions are not executed as // frequently as regular change detection. var fn = $parse(attr[directiveName], /* interceptorFn */ null, /* expensiveChecks */ true); return function ngEventHandler(scope, element) { element.on(eventName, function(event) { var callback = function() { }; if (forceAsyncEvents[eventName] && $rootScope.$$phase) { scope.$evalAsync(callback); } else { scope.$apply(callback); } <p>Typing in the input box below updates the key count</p> <input ng-keyup=""count = count + 1"" ng-init=""count=0""> key up count: {{count}} <p>Typing in the input box below updates the keycode</p> <input ng-keyup=""event=$event""> <p>event keyCode: {{ event.keyCode }}</p> <p>event altKey: {{ event.altKey }}</p> * <div class=""alert alert-warning""> * **Warning:** Be careful not to cause ""double-submission"" by using both the `ngClick` and * `ngSubmit` handlers together. See the * {@link form#submitting-a-form-and-preventing-the-default-action `form` directive documentation} * for a detailed discussion of when `ngSubmit` may be triggered. * </div> * <example module=""submitExample""> angular.module('submitExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.list = []; $scope.text = 'hello'; $scope.submit = function() { if ($scope.text) { $scope.list.push(this.text); $scope.text = ''; } }; }]); <form ng-submit=""submit()"" ng-controller=""ExampleController""> expect(element(by.model('text')).getAttribute('value')).toBe(''); * Note: As the `focus` event is executed synchronously when calling `input.focus()` * AngularJS executes the expression using `scope.$evalAsync` if the event is fired * during an `$apply` to ensure a consistent state. * * A [blur event](https://developer.mozilla.org/en-US/docs/Web/Events/blur) fires when * an element has lost focus. * * Note: As the `blur` event is executed synchronously also during DOM manipulations * (e.g. removing a focussed input), * AngularJS executes the expression using `scope.$evalAsync` if the event is fired * during an `$apply` to ensure a consistent state. * * [prototypal inheritance](https://github.com/angular/angular.js/wiki/Understanding-Scopes#javascript-prototypal-inheritance). * enter - happens just after the `ngIf` contents change and a new DOM element is created and injected into the `ngIf` container * leave - happens just before the `ngIf` contents are removed from the DOM This is removed when the checkbox is unchecked. multiElement: true, link: function($scope, $element, $attr, ctrl, $transclude) { if (value) { $transclude(function(clone, newScope) { childScope = newScope; // by a directive with templateUrl when its template arrives. if (previousElements) { if (childScope) { if (block) { previousElements = getBlockNodes(block.clone); $animate.leave(previousElements).then(function() { * application document. This is done by calling {@link $sce#getTrustedResourceUrl * {@link $sce#trustAsResourceUrl wrap them} as trusted values. Refer to Angular's {@link <example module=""includeExample"" deps=""angular-animate.js"" animations=""true""> <div ng-controller=""ExampleController""> angular.module('includeExample', ['ngAnimate']) .controller('ExampleController', ['$scope', function($scope) { $scope.templates = [ { name: 'template1.html', url: 'template1.html'}, { name: 'template2.html', url: 'template2.html'} ]; $scope.template = $scope.templates[0]; }]); templateSelect.all(by.css('option')).get(2).click(); templateSelect.all(by.css('option')).get(0).click(); * * @param {Object} angularEvent Synthetic event object. * @param {String} src URL of content to load. * * @param {Object} angularEvent Synthetic event object. * @param {String} src URL of content to load. /** * @ngdoc event * @name ngInclude#$includeContentError * @eventType emit on the scope ngInclude was declared in * @description * Emitted when a template HTTP request yields an erronous response (status < 200 || status > 299) * * @param {Object} angularEvent Synthetic event object. * @param {String} src URL of content to load. */ var ngIncludeDirective = ['$templateRequest', '$anchorScroll', '$animate', '$sce', function($templateRequest, $anchorScroll, $animate, $sce) { if (previousElement) { if (currentScope) { if (currentElement) { $animate.leave(currentElement).then(function() { //set the 2nd param to true to ignore the template request error so that the inner //contents and scope can be cleaned up. $templateRequest(src, true).then(function(response) { $animate.enter(clone, null, $element).then(afterAnimation); currentScope.$emit('$includeContentLoaded', src); }, function() { if (thisChangeId === changeCounter) { cleanupLastIncludeContent(); scope.$emit('$includeContentError', src); } scope.$emit('$includeContentRequested', src); if (/SVG/.test($element[0].toString())) { // WebKit: https://bugs.webkit.org/show_bug.cgi?id=135698 --- SVG elements do not // support innerHTML, so detect this here and try to generate the contents // specially. $element.empty(); $compile(jqLiteBuildFragment(ctrl.template, document).childNodes)(scope, function namespaceAdaptedClone(clone) { $element.append(clone); }, {futureParentElement: $element}); return; } <example module=""initExample""> angular.module('initExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.list = [['a', 'b'], ['c', 'd']]; }]); <div ng-controller=""ExampleController""> * In this case, plural category 'one' is matched and ""John, Mary and one other person are viewing"" <example module=""pluralizeExample""> angular.module('pluralizeExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.person1 = 'Igor'; $scope.person2 = 'Misko'; $scope.personCount = 1; }]); <div ng-controller=""ExampleController""> var BRACE = /{}/g, IS_WHEN = /^when(Minus)?(.+)$/; braceReplacement = startSymbol + numberExp + '-' + offset + endSymbol, watchRemover = angular.noop, lastCount; var tmpMatch = IS_WHEN.exec(attributeName); if (tmpMatch) { var whenKey = (tmpMatch[1] ? '-' : '') + lowercase(tmpMatch[2]); whens[whenKey] = element.attr(attr.$attr[attributeName]); whensExpFns[key] = $interpolate(expression.replace(BRACE, braceReplacement)); scope.$watch(numberExp, function ngPluralizeWatchAction(newVal) { var count = parseFloat(newVal); var countIsNaN = isNaN(count); if (!countIsNaN && !(count in whens)) { // If an explicit number rule such as 1, 2, 3... is defined, just use it. // Otherwise, check it against pluralization rules in $locale service. count = $locale.pluralCat(count - offset); // If both `count` and `lastCount` are NaN, we don't need to re-register a watch. // In JS `NaN !== NaN`, so we have to exlicitly check. if ((count !== lastCount) && !(countIsNaN && isNaN(lastCount))) { watchRemover(); watchRemover = scope.$watch(whensExpFns[count], updateElementText); lastCount = count; } function updateElementText(newText) { element.text(newText || ''); } * For example: `item in items` is equivalent to `item in items track by $id(item)`. This implies that the DOM elements * * `variable in expression as alias_expression` – You can also provide an optional alias expression which will then store the * intermediate results of the repeater after the filters have been applied. Typically this is used to render a special message * when a filter is active on the repeater, but the filtered result set is empty. * * For example: `item in items | filter:x as results` will store the fragment of the repeated items as `results`, but only after * the items have been processed through the filter. * <li class=""animate-repeat"" ng-repeat=""friend in friends | filter:q as results""> <li class=""animate-repeat"" ng-if=""results.length == 0""> <strong>No results found...</strong> </li> var updateScope = function(scope, index, valueIdentifier, value, keyIdentifier, key, arrayLength) { // TODO(perf): generate setters to shave off ~40ms or 1-1.5% scope[valueIdentifier] = value; if (keyIdentifier) scope[keyIdentifier] = key; scope.$index = index; scope.$first = (index === 0); scope.$last = (index === (arrayLength - 1)); scope.$middle = !(scope.$first || scope.$last); // jshint bitwise: false scope.$odd = !(scope.$even = (index&1) === 0); // jshint bitwise: true }; var getBlockStart = function(block) { return block.clone[0]; }; var getBlockEnd = function(block) { return block.clone[block.clone.length - 1]; }; restrict: 'A', multiElement: true, compile: function ngRepeatCompile($element, $attr) { var expression = $attr.ngRepeat; var ngRepeatEndComment = document.createComment(' end ngRepeat: ' + expression + ' '); var match = expression.match(/^\s*([\s\S]+?)\s+in\s+([\s\S]+?)(?:\s+as\s+([\s\S]+?))?(?:\s+track\s+by\s+([\s\S]+?))?\s*$/); if (!match) { throw ngRepeatMinErr('iexp', ""Expected expression in form of '_item_ in _collection_[ track by _id_]' but got '{0}'."", } var lhs = match[1]; var rhs = match[2]; var aliasAs = match[3]; var trackByExp = match[4]; match = lhs.match(/^(?:(\s*[\$\w]+)|\(\s*([\$\w]+)\s*,\s*([\$\w]+)\s*\))$/); if (!match) { throw ngRepeatMinErr('iidexp', ""'_item_' in '_item_ in _collection_' should be an identifier or '(_key_, _value_)' expression, but got '{0}'."", lhs); } var valueIdentifier = match[3] || match[1]; var keyIdentifier = match[2]; if (aliasAs && (!/^[$a-zA-Z_][$a-zA-Z0-9_]*$/.test(aliasAs) || /^(null|undefined|this|\$index|\$first|\$middle|\$last|\$even|\$odd|\$parent)$/.test(aliasAs))) { throw ngRepeatMinErr('badident', ""alias '{0}' is invalid --- must be a valid JS identifier which is not a reserved name."", aliasAs); } var trackByExpGetter, trackByIdExpFn, trackByIdArrayFn, trackByIdObjFn; var hashFnLocals = {$id: hashKey}; if (trackByExp) { trackByExpGetter = $parse(trackByExp); } else { trackByIdArrayFn = function(key, value) { return hashKey(value); }; trackByIdObjFn = function(key) { return key; }; } return function ngRepeatLink($scope, $element, $attr, ctrl, $transclude) { if (trackByExpGetter) { // // We are using no-proto object so that we don't need to guard against inherited props via // hasOwnProperty. var lastBlockMap = createMap(); $scope.$watchCollection(rhs, function ngRepeatAction(collection) { previousNode = $element[0], // node that cloned nodes should be inserted after // initialized to the comment node anchor nextBlockMap = createMap(), collectionLength, nextBlockOrder, if (aliasAs) { $scope[aliasAs] = collection; } for (var itemKey in collection) { if (collection.hasOwnProperty(itemKey) && itemKey.charAt(0) != '$') { collectionKeys.push(itemKey); collectionLength = collectionKeys.length; nextBlockOrder = new Array(collectionLength); for (index = 0; index < collectionLength; index++) { key = (collection === collectionKeys) ? index : collectionKeys[index]; value = collection[key]; trackById = trackByIdFn(key, value, index); if (lastBlockMap[trackById]) { // found previously seen block block = lastBlockMap[trackById]; delete lastBlockMap[trackById]; nextBlockMap[trackById] = block; nextBlockOrder[index] = block; } else if (nextBlockMap[trackById]) { // if collision detected. restore lastBlockMap and throw an error forEach(nextBlockOrder, function(block) { if (block && block.scope) lastBlockMap[block.id] = block; }); throw ngRepeatMinErr('dupes', ""Duplicates in a repeater are not allowed. Use 'track by' expression to specify unique keys. Repeater: {0}, Duplicate key: {1}, Duplicate value: {2}"", expression, trackById, value); } else { // new never before seen block nextBlockOrder[index] = {id: trackById, scope: undefined, clone: undefined}; nextBlockMap[trackById] = true; // remove leftover items for (var blockKey in lastBlockMap) { block = lastBlockMap[blockKey]; elementsToRemove = getBlockNodes(block.clone); $animate.leave(elementsToRemove); if (elementsToRemove[0].parentNode) { // if the element was not removed yet because of pending animation, mark it as deleted // so that we can ignore it later for (index = 0, length = elementsToRemove.length; index < length; index++) { elementsToRemove[index][NG_REMOVED] = true; } } block.scope.$destroy(); } for (index = 0; index < collectionLength; index++) { // skip nodes that are already pending removal via leave animation } while (nextNode && nextNode[NG_REMOVED]); $animate.move(getBlockNodes(block.clone), null, jqLite(previousNode)); updateScope(block.scope, index, valueIdentifier, value, keyIdentifier, key, collectionLength); $transclude(function ngRepeatTransclude(clone, scope) { block.scope = scope; // http://jsperf.com/clone-vs-createcomment var endNode = ngRepeatEndComment.cloneNode(false); clone[clone.length++] = endNode; // TODO(perf): support naked previousNode in `enter` to avoid creation of jqLite wrapper? previousNode = endNode; // by a directive with templateUrl when its template arrives. updateScope(block.scope, index, valueIdentifier, value, keyIdentifier, key, collectionLength); };var NG_HIDE_CLASS = 'ng-hide'; var NG_HIDE_IN_PROGRESS_CLASS = 'ng-hide-animate'; * provided to the `ngShow` attribute. The element is shown or hidden by removing or adding * the `.ng-hide` CSS class onto the element. The `.ng-hide` CSS class is predefined * When the `ngShow` expression evaluates to a falsy value then the `.ng-hide` CSS class is added to the class * attribute on the element causing it to become hidden. When truthy, the `.ng-hide` CSS class is removed * You may be wondering why !important is used for the `.ng-hide` CSS class. This is because the `.ng-hide` selector * ### Overriding `.ng-hide` * By default, the `.ng-hide` class will style the element with `display: none!important`. If you wish to change * the hide behavior with ngShow/ngHide then this can be achieved by restating the styles for the `.ng-hide` * class in CSS: * * /&#42; this is just another form of hiding an element &#42;/ * display: block!important; * position: absolute; * top: -9999px; * left: -9999px; * By default you don't need to override in CSS anything and the animations will work around the display style. * ## A note about animations with `ngShow` * /&#42; this is required as of 1.3x to properly * apply all styling in a show/hide animation &#42;/ * transition: 0s linear all; * } * * .my-element.ng-hide-add-active, * .my-element.ng-hide-remove-active { * /&#42; the transition is defined in the active class &#42;/ * transition: 1s linear all; * Keep in mind that, as of AngularJS version 1.3.0-beta.11, there is no need to change the display * property to block during animation states--ngAnimate will handle the style toggling automatically for you. * * addClass: `.ng-hide` - happens after the `ngShow` expression evaluates to a truthy value and the just before contents are set to visible * removeClass: `.ng-hide` - happens after the `ngShow` expression evaluates to a non truthy value and just before the contents are set to hidden @import url(../../components/bootstrap-3.1.1/css/bootstrap.css); line-height: 20px; opacity: 1; padding: 10px; border: 1px solid black; background: white; .animate-show.ng-hide-add.ng-hide-add-active, .animate-show.ng-hide-remove.ng-hide-remove-active { -webkit-transition: all linear 0.5s; transition: all linear 0.5s; line-height: 0; opacity: 0; padding: 0 10px; padding: 10px; border: 1px solid black; background: white; return { restrict: 'A', multiElement: true, link: function(scope, element, attr) { scope.$watch(attr.ngShow, function ngShowWatchAction(value) { // we're adding a temporary, animation-specific class for ng-hide since this way // we can control when the element is actually displayed on screen without having // to have a global/greedy CSS selector that breaks when other animations are run. // Read: https://github.com/angular/angular.js/issues/9103#issuecomment-58335845 $animate[value ? 'removeClass' : 'addClass'](element, NG_HIDE_CLASS, { tempClasses: NG_HIDE_IN_PROGRESS_CLASS }); }); } * provided to the `ngHide` attribute. The element is shown or hidden by removing or adding * <div ng-hide=""myValue"" class=""ng-hide""></div> * <div ng-hide=""myValue""></div> * When the `ngHide` expression evaluates to a truthy value then the `.ng-hide` CSS class is added to the class * attribute on the element causing it to become hidden. When falsy, the `.ng-hide` CSS class is removed * You may be wondering why !important is used for the `.ng-hide` CSS class. This is because the `.ng-hide` selector * ### Overriding `.ng-hide` * By default, the `.ng-hide` class will style the element with `display: none!important`. If you wish to change * the hide behavior with ngShow/ngHide then this can be achieved by restating the styles for the `.ng-hide` * class in CSS: * * /&#42; this is just another form of hiding an element &#42;/ * display: block!important; * position: absolute; * top: -9999px; * left: -9999px; * By default you don't need to override in CSS anything and the animations will work around the display style. * ## A note about animations with `ngHide` * is true and false. This system works like the animation system present with ngClass, except that the `.ng-hide` * CSS class is added and removed for you instead of your own CSS class. * transition: 0.5s linear all; * Keep in mind that, as of AngularJS version 1.3.0-beta.11, there is no need to change the display * property to block during animation states--ngAnimate will handle the style toggling automatically for you. * * removeClass: `.ng-hide` - happens after the `ngHide` expression evaluates to a truthy value and just before the contents are set to hidden * addClass: `.ng-hide` - happens after the `ngHide` expression evaluates to a non truthy value and just before the contents are set to visible @import url(../../components/bootstrap-3.1.1/css/bootstrap.css); -webkit-transition: all linear 0.5s; transition: all linear 0.5s; line-height: 20px; opacity: 1; padding: 10px; border: 1px solid black; background: white; line-height: 0; opacity: 0; padding: 0 10px; padding: 10px; border: 1px solid black; background: white; return { restrict: 'A', multiElement: true, link: function(scope, element, attr) { scope.$watch(attr.ngHide, function ngHideWatchAction(value) { // The comment inside of the ngShowDirective explains why we add and // remove a temporary class for the show/hide animation $animate[value ? 'addClass' : 'removeClass'](element,NG_HIDE_CLASS, { tempClasses: NG_HIDE_IN_PROGRESS_CLASS }); }); } * @param {expression} ngStyle * * {@link guide/expression Expression} which evals to an * object whose keys are CSS style names and values are corresponding values for those CSS * keys. * * Since some CSS style names are not valid keys for an object, they must be quoted. * See the 'background-color' style in the example below. <input type=""button"" value=""set color"" ng-click=""myStyle={color:'red'}""> <input type=""button"" value=""set background"" ng-click=""myStyle={'background-color':'blue'}""> element(by.css('input[value=\'set color\']')).click(); * * ``` * ``` * @priority 1200 <example module=""switchExample"" deps=""angular-animate.js"" animations=""true""> <div ng-controller=""ExampleController""> angular.module('switchExample', ['ngAnimate']) .controller('ExampleController', ['$scope', function($scope) { $scope.items = ['settings', 'home', 'other']; $scope.selection = $scope.items[0]; }]); select.all(by.css('option')).get(1).click(); select.all(by.css('option')).get(2).click(); selectedTranscludes = [], selectedElements = [], previousLeaveAnimations = [], var spliceFactory = function(array, index) { return function() { array.splice(index, 1); }; }; scope.$watch(watchExpr, function ngSwitchWatchAction(value) { var i, ii; for (i = 0, ii = previousLeaveAnimations.length; i < ii; ++i) { $animate.cancel(previousLeaveAnimations[i]); } previousLeaveAnimations.length = 0; for (i = 0, ii = selectedScopes.length; i < ii; ++i) { var selected = getBlockNodes(selectedElements[i].clone); selectedScopes[i].$destroy(); var promise = previousLeaveAnimations[i] = $animate.leave(selected); promise.then(spliceFactory(previousLeaveAnimations, i)); selectedElements.length = 0; selectedScopes.length = 0; selectedTransclude.transclude(function(caseElement, selectedScope) { selectedScopes.push(selectedScope); caseElement[caseElement.length++] = document.createComment(' end ngSwitchWhen: '); var block = { clone: caseElement }; selectedElements.push(block); priority: 1200, multiElement: true, priority: 1200, multiElement: true, * @restrict EAC <example module=""transcludeExample""> angular.module('transcludeExample', []) '<ng-transclude></ng-transclude>' + }) .controller('ExampleController', ['$scope', function($scope) { $scope.title = 'Lorem Ipsum'; $scope.text = 'Neque porro quisquam est qui dolorem ipsum quia dolor...'; }]); <div ng-controller=""ExampleController""> <input ng-model=""title""> <br/> restrict: 'EAC', * In many cases, `ngRepeat` can be used on `<option>` elements instead of `ngOptions` to achieve a * similar result. However, the `ngOptions` provides some benefits such as reducing memory and * increasing speed by not creating a new scope for each repeated instance, as well as providing * more flexibility in how the `select`'s model is assigned via `select as`. `ngOptions` should be * used when the `select` model needs to be bound to a non-string value. This is because an option * element can only be bound to string values at present. * * **Note:** `ngModel` compares by reference, not value. This is important when binding to an * array of objects. See an example [in this jsfiddle](http://jsfiddle.net/qWzTb/). * ## `select as` * * Using `select as` will bind the result of the `select as` expression to the model, but * the value of the `<select>` and `<option>` html elements will be either the index (for array data sources) * or property name (for object data sources) of the value within the collection. If a `track by` expression * is used, the result of that expression will be set as the value of the `option` and `select` elements. * * ### `select as` with `track by` * * Using `select as` together with `track by` is not recommended. Reasoning: * * - Example: &lt;select ng-options=""item.subItem as item.label for item in values track by item.id"" ng-model=""selected""&gt; * values: [{id: 1, label: 'aLabel', subItem: {name: 'aSubItem'}}, {id: 2, label: 'bLabel', subItem: {name: 'bSubItem'}}], * $scope.selected = {name: 'aSubItem'}; * - track by is always applied to `value`, with the purpose of preserving the selection, * (to `item` in this case) * - to calculate whether an item is selected we do the following: * 1. apply `track by` to the values in the array, e.g. * In the example: [1,2] * 2. apply `track by` to the already selected value in `ngModel`: * In the example: this is not possible, as `track by` refers to `item.id`, but the selected * value from `ngModel` is `{name: aSubItem}`. * * * `label` **`group by`** `group` **`for`** `value` **`in`** `array` * * `label` **`group by`** `group` **`for`** `value` **`in`** `array` **`track by`** `trackexpr` * * `label` **`for`** `value` **`in`** `array` | orderBy:`orderexpr` **`track by`** `trackexpr` * (for including a filter with `track by`) * `value` variable (e.g. `value.propertyName`). With this the selection is preserved * even when the options are recreated (e.g. reloaded from the server). <example module=""selectExample""> angular.module('selectExample', []) .controller('ExampleController', ['$scope', function($scope) { $scope.colors = [ {name:'black', shade:'dark'}, {name:'white', shade:'light'}, {name:'red', shade:'dark'}, {name:'blue', shade:'dark'}, {name:'yellow', shade:'light'} ]; $scope.myColor = $scope.colors[2]; // red }]); <div ng-controller=""ExampleController""> <select ng-model=""myColor"" ng-options=""color.name for color in colors""></select><br> <select ng-model=""myColor"" ng-options=""color.name for color in colors""> <select ng-model=""myColor"" ng-options=""color.name group by color.shade for color in colors""> Select <a href ng-click=""myColor = { name:'not in list', shade: 'other' }"">bogus</a>.<br> Currently selected: {{ {selected_color:myColor} }} ng-style=""{'background-color':myColor.name}""> expect(element(by.binding('{selected_color:myColor}')).getText()).toMatch('red'); element.all(by.model('myColor')).first().click(); element.all(by.css('select[ng-model=""myColor""] option')).first().click(); expect(element(by.binding('{selected_color:myColor}')).getText()).toMatch('black'); element(by.css('.nullable select[ng-model=""myColor""]')).click(); element.all(by.css('.nullable select[ng-model=""myColor""] option')).first().click(); expect(element(by.binding('{selected_color:myColor}')).getText()).toMatch('null');var ngOptionsDirective = valueFn({ restrict: 'A', terminal: true }); self.addOption = function(value, element) { // Workaround for https://code.google.com/p/chromium/issues/detail?id=381459 // Adding an <option selected=""selected""> element to a <select required=""required""> should // automatically select the new element if (element && element[0].hasAttribute('selected')) { element[0].selected = true; } if (ngModelCtrl.$viewValue === value) { renderScheduled = false, for (var i = 0, children = element.children(), ii = children.length; i < ii; i++) { lastView = shallowCopy(ctrl.$viewValue); selectAs = / as /.test(match[0]) && match[1], selectAsFn = selectAs ? $parse(selectAs) : null, trackKeysCache = {}, optionGroupsCache = [[{element: selectElement, label:''}]], //re-usable object to represent option's locals locals = {}; selectElement.on('change', selectionChanged); scope.$watchCollection(valuesFn, scheduleRendering); scope.$watchCollection(getLabels, scheduleRendering); if (multiple) { scope.$watchCollection(function() { return ctrl.$modelValue; }, scheduleRendering); } // ------------------------------------------------------------------ // function callExpression(exprFn, key, value) { locals[valueName] = value; if (keyName) locals[keyName] = key; return exprFn(scope, locals); } function selectionChanged() { scope.$apply(function() { var collection = valuesFn(scope) || []; var viewValue; if (multiple) { viewValue = []; forEach(selectElement.val(), function(selectedKey) { selectedKey = trackFn ? trackKeysCache[selectedKey] : selectedKey; viewValue.push(getViewValue(selectedKey, collection[selectedKey])); }); } else { var selectedKey = trackFn ? trackKeysCache[selectElement.val()] : selectElement.val(); viewValue = getViewValue(selectedKey, collection[selectedKey]); } ctrl.$setViewValue(viewValue); render(); }); } function getViewValue(key, value) { if (key === '?') { return undefined; } else if (key === '') { return null; } else { var viewValueFn = selectAsFn ? selectAsFn : valueFn; return callExpression(viewValueFn, key, value); } } function getLabels() { var values = valuesFn(scope); var toDisplay; if (values && isArray(values)) { toDisplay = new Array(values.length); for (var i = 0, ii = values.length; i < ii; i++) { toDisplay[i] = callExpression(displayFn, i, values[i]); } return toDisplay; } else if (values) { // TODO: Add a test for this case toDisplay = {}; for (var prop in values) { if (values.hasOwnProperty(prop)) { toDisplay[prop] = callExpression(displayFn, prop, values[prop]); } } } return toDisplay; } function createIsSelectedFn(viewValue) { var selectedSet; if (multiple) { if (trackFn && isArray(viewValue)) { selectedSet = new HashMap([]); for (var trackIndex = 0; trackIndex < viewValue.length; trackIndex++) { // tracking by key selectedSet.put(callExpression(trackFn, null, viewValue[trackIndex]), true); } } else { selectedSet = new HashMap(viewValue); } } else if (trackFn) { viewValue = callExpression(trackFn, null, viewValue); } return function isSelected(key, value) { var compareValueFn; if (trackFn) { compareValueFn = trackFn; } else if (selectAsFn) { compareValueFn = selectAsFn; } else { compareValueFn = valueFn; } if (multiple) { return isDefined(selectedSet.remove(callExpression(compareValueFn, key, value))); } else { return viewValue === callExpression(compareValueFn, key, value); } }; } function scheduleRendering() { if (!renderScheduled) { scope.$$postDigest(render); renderScheduled = true; } } /** * A new labelMap is created with each render. * This function is called for each existing option with added=false, * and each new option with added=true. * - Labels that are passed to this method twice, * (once with added=true and once with added=false) will end up with a value of 0, and * will cause no change to happen to the corresponding option. * - Labels that are passed to this method only once with added=false will end up with a * value of -1 and will eventually be passed to selectCtrl.removeOption() * - Labels that are passed to this method only once with added=true will end up with a * value of 1 and will eventually be passed to selectCtrl.addOption() */ function updateLabelMap(labelMap, label, added) { labelMap[label] = labelMap[label] || 0; labelMap[label] += (added ? 1 : -1); } renderScheduled = false; // Temporary location for the option groups before we render them viewValue = ctrl.$viewValue, value, labelMap = {}, isSelected = createIsSelectedFn(viewValue), anySelected = false, label, optionId; trackKeysCache = {}; if (key.charAt(0) === '$') continue; value = values[key]; optionGroupName = callExpression(groupByFn, key, value) || ''; selected = isSelected(key, value); anySelected = anySelected || selected; label = callExpression(displayFn, key, value); // what will be seen by the user optionId = trackFn ? trackFn(scope, locals) : (keyName ? keys[index] : index); if (trackFn) { trackKeysCache[optionId] = key; } id: optionId, if (nullOption || viewValue === null) { optionGroups[''].unshift({id:'', label:'', selected:!anySelected}); } else if (!anySelected) { for (index = 0, length = optionGroup.length; index < length; index++) { if ((existingOption = existingOptions[index + 1])) { updateLabelMap(labelMap, existingOption.label, false); updateLabelMap(labelMap, option.label, true); lastElement.prop('label', existingOption.label); if (lastElement[0].selected !== option.selected) { if (msie) { // See #7692 // The selected item wouldn't visually update on IE without this. // Tested on Win7: IE9, IE10 and IE11. Future IEs should be tested as well lastElement.prop('selected', existingOption.selected); } .prop('selected', option.selected) .prop('label', option.label) updateLabelMap(labelMap, option.label, true); while (existingOptions.length > index) { option = existingOptions.pop(); updateLabelMap(labelMap, option.label, false); option.element.remove(); while (optionGroupsCache.length > groupIndex) { // remove all the labels in the option group optionGroup = optionGroupsCache.pop(); for (index = 1; index < optionGroup.length; ++index) { updateLabelMap(labelMap, optionGroup[index].label, false); } optionGroup[0].element.remove(); forEach(labelMap, function(count, label) { if (count > 0) { selectCtrl.addOption(label); } else if (count < 0) { selectCtrl.removeOption(label); } }); return function(scope, element, attr) { if (!selectCtrl || !selectCtrl.databound) { if (oldVal !== newVal) { selectCtrl.removeOption(oldVal); } selectCtrl.addOption(newVal, element); selectCtrl.addOption(attr.value, element); terminal: false if (!output.length || output.indexOf(name) != -1) { line = line.substring(line.indexOf('@') + 1); line = line.substring(line.indexOf('(') + 1).replace(')', '');(function(fn) { match = function(actualExp) { } else if (typeof value !== 'string') { bindings; if (bindings = element.data('$binding')) { for (var expressions = [], binding, j=0, jj=bindings.length; j < jj; j++) { binding = bindings[j]; if (binding.expressions) { expressions = binding.expressions; } else { expressions = [binding]; for (var scope, expression, i = 0, ii = expressions.length; i < ii; i++) { expression = expressions[i]; if (match(expression)) { scope = scope || element.scope(); push(scope.$eval(expression)); return keys.indexOf(key) !== -1; var evnt; if (/transitionend/.test(eventType)) { if (window.WebKitTransitionEvent) { evnt = new WebKitTransitionEvent(eventType, eventData); evnt.initEvent(eventType, false, true); try { evnt = new TransitionEvent(eventType, eventData); } catch (e) { evnt = document.createEvent('TransitionEvent'); evnt.initTransitionEvent(eventType, null, null, null, eventData.elapsedTime || 0); } else if (/animationend/.test(eventType)) { if (window.WebKitAnimationEvent) { evnt = new WebKitAnimationEvent(eventType, eventData); evnt.initEvent(eventType, false, true); } else { try { evnt = new AnimationEvent(eventType, eventData); } catch (e) { evnt = document.createEvent('AnimationEvent'); evnt.initAnimationEvent(eventType, null, null, null, eventData.elapsedTime || 0); } } } else { evnt = document.createEvent('MouseEvents'); x = x || 0; y = y || 0; evnt.initMouseEvent(eventType, true, true, window, 0, x, y, x, y, pressed('ctrl'), pressed('alt'), pressed('shift'), pressed('meta'), 0, element); } /* we're unable to change the timeStamp value directly so this * is only here to allow for testing where the timeStamp value is * read */ evnt.$manualTimeStamp = eventData.timeStamp; if (!evnt) return; var originalPreventDefault = evnt.preventDefault, appWindow = element.ownerDocument.defaultView, fakeProcessDefault = true, finalProcessDefault, angular = appWindow.angular || {}; // igor: temporary fix for https://bugzilla.mozilla.org/show_bug.cgi?id=684208 angular['ff-684208-preventDefault'] = false; evnt.preventDefault = function() { fakeProcessDefault = false; return originalPreventDefault.apply(evnt, arguments); }; element.dispatchEvent(evnt); finalProcessDefault = !(angular['ff-684208-preventDefault'] || !fakeProcessDefault); delete angular['ff-684208-preventDefault']; return finalProcessDefault; $injector.invoke(function($browser) { this.its[this.its.length - 1].only = true; } catch (e) { * Configures the future to convert its final with a function fn(value) * Configures the future to parse its final value from JSON * Configures the future to convert its final value from objects return this.steps[this.steps.length - 1]; angular.forEach(['[ng-','[data-ng-','[x-ng-'], function(value, index) { } catch (e) { this.selector = _jQuery.trim((this.selector || '') + ' ' + selector); var supportInputEvent = 'oninput' in document.createElement('div') && !(msie && msie <= 11); option = select.find('option').filter(function() { if (href && elements[0].nodeName.toLowerCase() === 'a' && eventProcessDefault) { if (href && elements[0].nodeName.toLowerCase() === 'a' && eventProcessDefault) {!window.angular.$$csp() && window.angular.element(document).find('head').prepend('<style type=""text/css"">@charset ""UTF-8"";\n\n[ng\\:cloak], [ng-cloak], [data-ng-cloak], [x-ng-cloak],\n.ng-cloak, .x-ng-cloak,\n.ng-hide:not(.ng-hide-animate) {\n display: none !important;\n}\n\nng\\:form {\n display: block;\n}\n</style>'); !window.angular.$$csp() && window.angular.element(document).find('head').prepend('<style type=""text/css"">@charset ""UTF-8"";\n/* CSS Document */\n\n/** Structure */\nbody {\n font-family: Arial, sans-serif;\n margin: 0;\n font-size: 14px;\n}\n\n#system-error {\n font-size: 1.5em;\n text-align: center;\n}\n\n#json, #xml {\n display: none;\n}\n\n#header {\n position: fixed;\n width: 100%;\n}\n\n#specs {\n padding-top: 50px;\n}\n\n#header .angular {\n font-family: Courier New, monospace;\n font-weight: bold;\n}\n\n#header h1 {\n font-weight: normal;\n float: left;\n font-size: 30px;\n line-height: 30px;\n margin: 0;\n padding: 10px 10px;\n height: 30px;\n}\n\n#application h2,\n#specs h2 {\n margin: 0;\n padding: 0.5em;\n font-size: 1.1em;\n}\n\n#status-legend {\n margin-top: 10px;\n margin-right: 10px;\n}\n\n#header,\n#application,\n.test-info,\n.test-actions li {\n overflow: hidden;\n}\n\n#application {\n margin: 10px;\n}\n\n#application iframe {\n width: 100%;\n height: 758px;\n}\n\n#application .popout {\n float: right;\n}\n\n#application iframe {\n border: none;\n}\n\n.tests li,\n.test-actions li,\n.test-it li,\n.test-it ol,\n.status-display {\n list-style-type: none;\n}\n\n.tests,\n.test-it ol,\n.status-display {\n margin: 0;\n padding: 0;\n}\n\n.test-info {\n margin-left: 1em;\n margin-top: 0.5em;\n border-radius: 8px 0 0 8px;\n -webkit-border-radius: 8px 0 0 8px;\n -moz-border-radius: 8px 0 0 8px;\n cursor: pointer;\n}\n\n.test-info:hover .test-name {\n text-decoration: underline;\n}\n\n.test-info .closed:before {\n content: \'\\25b8\\00A0\';\n}\n\n.test-info .open:before {\n content: \'\\25be\\00A0\';\n font-weight: bold;\n}\n\n.test-it ol {\n margin-left: 2.5em;\n}\n\n.status-display,\n.status-display li {\n float: right;\n}\n\n.status-display li {\n padding: 5px 10px;\n}\n\n.timer-result,\n.test-title {\n display: inline-block;\n margin: 0;\n padding: 4px;\n}\n\n.test-actions .test-title,\n.test-actions .test-result {\n display: table-cell;\n padding-left: 0.5em;\n padding-right: 0.5em;\n}\n\n.test-actions {\n display: table;\n}\n\n.test-actions li {\n display: table-row;\n}\n\n.timer-result {\n width: 4em;\n padding: 0 10px;\n text-align: right;\n font-family: monospace;\n}\n\n.test-it pre,\n.test-actions pre {\n clear: left;\n color: black;\n margin-left: 6em;\n}\n\n.test-describe {\n padding-bottom: 0.5em;\n}\n\n.test-describe .test-describe {\n margin: 5px 5px 10px 2em;\n}\n\n.test-actions .status-pending .test-title:before {\n content: \'\\00bb\\00A0\';\n}\n\n.scrollpane {\n max-height: 20em;\n overflow: auto;\n}\n\n/** Colors */\n\n#header {\n background-color: #F2C200;\n}\n\n#specs h2 {\n border-top: 2px solid #BABAD1;\n}\n\n#specs h2,\n#application h2 {\n background-color: #efefef;\n}\n\n#application {\n border: 1px solid #BABAD1;\n}\n\n.test-describe .test-describe {\n border-left: 1px solid #BABAD1;\n border-right: 1px solid #BABAD1;\n border-bottom: 1px solid #BABAD1;\n}\n\n.status-display {\n border: 1px solid #777;\n}\n\n.status-display .status-pending,\n.status-pending .test-info {\n background-color: #F9EEBC;\n}\n\n.status-display .status-success,\n.status-success .test-info {\n background-color: #B1D7A1;\n}\n\n.status-display .status-failure,\n.status-failure .test-info {\n background-color: #FF8286;\n}\n\n.status-display .status-error,\n.status-error .test-info {\n background-color: black;\n color: white;\n}\n\n.test-actions .status-success .test-title {\n color: #30B30A;\n}\n\n.test-actions .status-failure .test-title {\n color: #DF0000;\n}\n\n.test-actions .status-error .test-title {\n color: black;\n}\n\n.test-actions .timer-result {\n color: #888;\n}\n</style>');"," * jQuery JavaScript Library v1.10.2 * Copyright 2005, 2013 jQuery Foundation, Inc. and other contributors * Date: 2013-07-03T13:48Z(function( window, undefined ) {'use strict'; // The deferred used on DOM ready readyList, // A central reference to the root jQuery(document) rootjQuery, // Support: IE<10 // For `typeof xmlNode.method` instead of `xmlNode.method !== undefined` core_strundefined = typeof undefined, location = window.location, docElem = document.documentElement, // Map over jQuery in case of overwrite _jQuery = window.jQuery, // Map over the $ in case of overwrite _$ = window.$, // [[Class]] -> type pairs class2type = {}, // List of deleted data cache ids, so we can reuse them core_deletedIds = [], core_version = ""1.10.2"", // Save a reference to some core methods core_concat = core_deletedIds.concat, core_push = core_deletedIds.push, core_slice = core_deletedIds.slice, core_indexOf = core_deletedIds.indexOf, core_toString = class2type.toString, core_hasOwn = class2type.hasOwnProperty, core_trim = core_version.trim, return new jQuery.fn.init( selector, context, rootjQuery ); // Used for matching numbers core_pnum = /[+-]?(?:\d*\.|)\d+(?:[eE][+-]?\d+|)/.source, // Used for splitting on whitespace core_rnotwhite = /\S+/g, // Make sure we trim BOM and NBSP (here's looking at you, Safari 5.0 and IE) // A simple way to check for HTML strings // Prioritize #id over <tag> to avoid XSS via location.hash (#9521) // Strict HTML recognition (#11290: must start with <) rquickExpr = /^(?:\s*(<[\w\W]+>)[^>]*|#([\w-]*))$/, // Match a standalone tag rsingleTag = /^<(\w+)\s*\/?>(?:<\/\1>|)$/, // JSON RegExp rvalidchars = /^[\],:{}\s]*$/, rvalidbraces = /(?:^|:|,)(?:\s*\[)+/g, rvalidescape = /\\(?:[""\\\/bfnrt]|u[\da-fA-F]{4})/g, rvalidtokens = /""[^""\\\r\n]*""|true|false|null|-?(?:\d+\.|)\d+(?:[eE][+-]?\d+|)/g, }, // The ready event handler completed = function( event ) { // readyState === ""complete"" is good enough for us to call the dom ready in oldIE if ( document.addEventListener || event.type === ""load"" || document.readyState === ""complete"" ) { detach(); jQuery.ready(); } }, // Clean-up method for dom ready events detach = function() { if ( document.addEventListener ) { document.removeEventListener( ""DOMContentLoaded"", completed, false ); window.removeEventListener( ""load"", completed, false ); } else { document.detachEvent( ""onreadystatechange"", completed ); window.detachEvent( ""onload"", completed ); } jquery: core_version, init: function( selector, context, rootjQuery ) { var match, elem; // HANDLE: $(""""), $(null), $(undefined), $(false) if ( !selector ) { return this; } // Handle HTML strings if ( typeof selector === ""string"" ) { if ( selector.charAt(0) === ""<"" && selector.charAt( selector.length - 1 ) === "">"" && selector.length >= 3 ) { // Assume that strings that start and end with <> are HTML and skip the regex check match = [ null, selector, null ]; } else { match = rquickExpr.exec( selector ); } // Match html or make sure no context is specified for #id if ( match && (match[1] || !context) ) { // HANDLE: $(html) -> $(array) if ( match[1] ) { context = context instanceof jQuery ? context[0] : context; // scripts is true for back-compat jQuery.merge( this, jQuery.parseHTML( match[1], context && context.nodeType ? context.ownerDocument || context : document, true ) ); // HANDLE: $(html, props) if ( rsingleTag.test( match[1] ) && jQuery.isPlainObject( context ) ) { for ( match in context ) { // Properties of context are called as methods if possible if ( jQuery.isFunction( this[ match ] ) ) { this[ match ]( context[ match ] ); // ...and otherwise set as attributes } else { this.attr( match, context[ match ] ); } } } return this; // HANDLE: $(#id) } else { elem = document.getElementById( match[2] ); // Check parentNode to catch when Blackberry 4.6 returns // nodes that are no longer in the document #6963 if ( elem && elem.parentNode ) { // Handle the case where IE and Opera return items // by name instead of ID if ( elem.id !== match[2] ) { return rootjQuery.find( selector ); } // Otherwise, we inject the element directly into the jQuery object this.length = 1; this[0] = elem; } this.context = document; this.selector = selector; return this; } // HANDLE: $(expr, $(...)) } else if ( !context || context.jquery ) { return ( context || rootjQuery ).find( selector ); // HANDLE: $(expr, context) // (which is just equivalent to: $(context).find(expr) } else { return this.constructor( context ).find( selector ); } // HANDLE: $(DOMElement) } else if ( selector.nodeType ) { this.context = this[0] = selector; this.length = 1; return this; // HANDLE: $(function) // Shortcut for document ready } else if ( jQuery.isFunction( selector ) ) { return rootjQuery.ready( selector ); } if ( selector.selector !== undefined ) { this.selector = selector.selector; this.context = selector.context; } return jQuery.makeArray( selector, this ); }, return core_slice.call( this ); return num == null ? // Return a 'clean' array this.toArray() : // Return just the object ( num < 0 ? this[ this.length + num ] : this[ num ] ); ready: function( fn ) { // Add the callback jQuery.ready.promise().done( fn ); return this; return this.pushStack( core_slice.apply( this, arguments ) ); map: function( callback ) { return this.pushStack( jQuery.map(this, function( elem, i ) { return callback.call( elem, i, elem ); })); }, push: core_push, sort: [].sort, splice: [].splice// Give the init function the jQuery prototype for later instantiation jQuery.fn.init.prototype = jQuery.fn; var src, copyIsArray, copy, name, options, clone, target = arguments[1] || {}; i = 2; if ( length === i ) { --i; // Non-digits removed to match rinlinejQuery expando: ""jQuery"" + ( core_version + Math.random() ).replace( /\D/g, """" ), noConflict: function( deep ) { if ( window.$ === jQuery ) { window.$ = _$; } if ( deep && window.jQuery === jQuery ) { window.jQuery = _jQuery; } return jQuery; // Is the DOM ready to be used? Set to true once it occurs. isReady: false, // A counter to track how many items to wait for before // the ready event fires. See #6781 readyWait: 1, // Hold (or release) the ready event holdReady: function( hold ) { if ( hold ) { jQuery.readyWait++; } else { jQuery.ready( true ); } }, // Handle when the DOM is ready ready: function( wait ) { // Abort if there are pending holds or we're already ready if ( wait === true ? --jQuery.readyWait : jQuery.isReady ) { return; } // Make sure body exists, at least, in case IE gets a little overzealous (ticket #5443). if ( !document.body ) { return setTimeout( jQuery.ready ); } // Remember that the DOM is ready jQuery.isReady = true; // If a normal DOM Ready event fired, decrement, and wait if need be if ( wait !== true && --jQuery.readyWait > 0 ) { return; } // If there are functions bound, to execute readyList.resolveWith( document, [ jQuery ] ); // Trigger any bound ready events if ( jQuery.fn.trigger ) { jQuery( document ).trigger(""ready"").off(""ready""); } }, isArray: Array.isArray || function( obj ) { return jQuery.type(obj) === ""array""; }, /* jshint eqeqeq: false */ return obj != null && obj == obj.window; return !isNaN( parseFloat(obj) ) && isFinite( obj ); }, type: function( obj ) { if ( obj == null ) { return String( obj ); } return typeof obj === ""object"" || typeof obj === ""function"" ? class2type[ core_toString.call(obj) ] || ""object"" : typeof obj; var key; // Must be an Object. // Because of IE, we also have to check the presence of the constructor property. // Make sure that DOM nodes and window objects don't pass through, as well if ( !obj || jQuery.type(obj) !== ""object"" || obj.nodeType || jQuery.isWindow( obj ) ) { try { // Not own constructor property must be Object if ( obj.constructor && !core_hasOwn.call(obj, ""constructor"") && !core_hasOwn.call(obj.constructor.prototype, ""isPrototypeOf"") ) { return false; } } catch ( e ) { // IE8,9 Will throw exceptions on certain host objects #9897 // Support: IE<9 // Handle iteration over inherited properties before own properties. if ( jQuery.support.ownLast ) { for ( key in obj ) { return core_hasOwn.call( obj, key ); } } // Own properties are enumerated firstly, so to speed up, // if last one is own, then all properties are own. for ( key in obj ) {} return key === undefined || core_hasOwn.call( obj, key ); error: function( msg ) { throw new Error( msg ); // data: string of html // context (optional): If specified, the fragment will be created in this context, defaults to document // keepScripts (optional): If true, will include scripts passed in the html string parseHTML: function( data, context, keepScripts ) { if ( !data || typeof data !== ""string"" ) { return null; } if ( typeof context === ""boolean"" ) { keepScripts = context; context = false; } context = context || document; var parsed = rsingleTag.exec( data ), scripts = !keepScripts && []; // Single tag if ( parsed ) { return [ context.createElement( parsed[1] ) ]; } parsed = jQuery.buildFragment( [ data ], context, scripts ); if ( scripts ) { jQuery( scripts ).remove(); } return jQuery.merge( [], parsed.childNodes ); }, parseJSON: function( data ) { // Attempt to parse using the native JSON parser first if ( window.JSON && window.JSON.parse ) { return window.JSON.parse( data ); } if ( data === null ) { return data; } if ( typeof data === ""string"" ) { // Make sure leading/trailing whitespace is removed (IE can't handle it) data = jQuery.trim( data ); if ( data ) { // Make sure the incoming data is actual JSON // Logic borrowed from http://json.org/json2.js if ( rvalidchars.test( data.replace( rvalidescape, ""@"" ) .replace( rvalidtokens, ""]"" ) .replace( rvalidbraces, """")) ) { return ( new Function( ""return "" + data ) )(); } } } jQuery.error( ""Invalid JSON: "" + data ); }, // Cross-browser xml parsing parseXML: function( data ) { var xml, tmp; if ( !data || typeof data !== ""string"" ) { return null; } try { if ( window.DOMParser ) { // Standard tmp = new DOMParser(); xml = tmp.parseFromString( data , ""text/xml"" ); } else { // IE xml = new ActiveXObject( ""Microsoft.XMLDOM"" ); xml.async = ""false""; xml.loadXML( data ); } } catch( e ) { xml = undefined; } if ( !xml || !xml.documentElement || xml.getElementsByTagName( ""parsererror"" ).length ) { jQuery.error( ""Invalid XML: "" + data ); } return xml; }, noop: function() {}, // Workarounds based on findings by Jim Driscoll // http://weblogs.java.net/blog/driscoll/archive/2009/09/08/eval-javascript-global-context globalEval: function( data ) { if ( data && jQuery.trim( data ) ) { // We use execScript on Internet Explorer // We use an anonymous function so that context is window // rather than jQuery in Firefox ( window.execScript || function( data ) { window[ ""eval"" ].call( window, data ); } )( data ); // Use native String.trim function wherever possible trim: core_trim && !core_trim.call(""\uFEFF\xA0"") ? function( text ) { return text == null ? """" : core_trim.call( text ); } : // Otherwise use our own trimming functionality function( text ) { return text == null ? """" : ( text + """" ).replace( rtrim, """" ); }, core_push.call( ret, arr ); var len; if ( arr ) { if ( core_indexOf ) { return core_indexOf.call( arr, elem, i ); } len = arr.length; i = i ? i < 0 ? Math.max( 0, len + i ) : i : 0; for ( ; i < len; i++ ) { // Skip accessing in sparse arrays if ( i in arr && arr[ i ] === elem ) { return i; } } } return -1; var l = second.length, i = first.length, j = 0; if ( typeof l === ""number"" ) { for ( ; j < l; j++ ) { first[ i++ ] = second[ j ]; } } else { while ( second[j] !== undefined ) { first[ i++ ] = second[ j++ ]; } grep: function( elems, callback, inv ) { var retVal, ret = [], length = elems.length; inv = !!inv; retVal = !!callback( elems[ i ], i ); if ( inv !== retVal ) { ret.push( elems[ i ] ); return ret; // Go through the array, translating each of the items to their ret[ ret.length ] = value; ret[ ret.length ] = value; return core_concat.apply( [], ret ); var args, proxy, tmp; args = core_slice.call( arguments, 2 ); return fn.apply( context || this, args.concat( core_slice.call( arguments ) ) ); // Multifunctional method to get and set values of a collection // The value/s can optionally be executed if it's a function access: function( elems, fn, key, value, chainable, emptyGet, raw ) { var i = 0, length = elems.length, bulk = key == null; // Sets many values if ( jQuery.type( key ) === ""object"" ) { chainable = true; for ( i in key ) { jQuery.access( elems, fn, i, key[i], true, emptyGet, raw ); } // Sets one value } else if ( value !== undefined ) { chainable = true; if ( !jQuery.isFunction( value ) ) { raw = true; } if ( bulk ) { // Bulk operations run against the entire set if ( raw ) { fn.call( elems, value ); fn = null; // ...except when executing function values } else { bulk = fn; fn = function( elem, key, value ) { return bulk.call( jQuery( elem ), value ); }; } } if ( fn ) { for ( ; i < length; i++ ) { fn( elems[i], key, raw ? value : value.call( elems[i], i, fn( elems[i], key ) ) ); } } } return chainable ? elems : // Gets bulk ? fn.call( elems ) : length ? fn( elems[0], key ) : emptyGet; }, now: function() { return ( new Date() ).getTime(); }, // A method for quickly swapping in/out CSS properties to get correct calculations. // Note: this method belongs to the css module but it's needed here for the support module. // If support gets modularized, this method should be moved back to the css module. swap: function( elem, options, callback, args ) { var ret, name, old = {}; // Remember the old values, and insert the new ones for ( name in options ) { old[ name ] = elem.style[ name ]; elem.style[ name ] = options[ name ]; } ret = callback.apply( elem, args || [] ); // Revert the old values for ( name in options ) { elem.style[ name ] = old[ name ]; } return ret; }jQuery.ready.promise = function( obj ) { if ( !readyList ) { readyList = jQuery.Deferred(); // Catch cases where $(document).ready() is called after the browser event has already occurred. // we once tried to use readyState ""interactive"" here, but it caused issues like the one // discovered by ChrisS here: http://bugs.jquery.com/ticket/12282#comment:15 if ( document.readyState === ""complete"" ) { // Handle it asynchronously to allow scripts the opportunity to delay ready setTimeout( jQuery.ready ); // Standards-based browsers support DOMContentLoaded } else if ( document.addEventListener ) { // Use the handy event callback document.addEventListener( ""DOMContentLoaded"", completed, false ); // A fallback to window.onload, that will always work window.addEventListener( ""load"", completed, false ); // If IE event model is used } else { // Ensure firing before onload, maybe late but safe also for iframes document.attachEvent( ""onreadystatechange"", completed ); // A fallback to window.onload, that will always work window.attachEvent( ""onload"", completed ); // If IE and not a frame // continually check to see if the document is ready var top = false; try { top = window.frameElement == null && document.documentElement; } catch(e) {} if ( top && top.doScroll ) { (function doScrollCheck() { if ( !jQuery.isReady ) { try { // Use the trick by Diego Perini // http://javascript.nwbox.com/IEContentLoaded/ top.doScroll(""left""); } catch(e) { return setTimeout( doScrollCheck, 50 ); } // detach all dom ready events detach(); // and execute any waiting functions jQuery.ready(); } })(); } } } return readyList.promise( obj ); }; if ( jQuery.isWindow( obj ) ) { return type === ""array"" || type !== ""function"" && ( length === 0 || typeof length === ""number"" && length > 0 && ( length - 1 ) in obj ); // All jQuery objects should point back to these rootjQuery = jQuery(document); * Sizzle CSS Selector Engine v1.10.2 * Date: 2013-07-03(function( window, undefined ) { cachedruns, hasDuplicate = false, return 0; // Acceptable operators http://www.w3.org/TR/selectors/#attribute-selectors attributes = ""\\["" + whitespace + ""*("" + characterEncoding + "")"" + whitespace + ""*(?:([*^$|!~]?=)"" + whitespace + ""*(?:(['\""])((?:\\\\.|[^\\\\])*?)\\3|("" + identifier + "")|)|)"" + whitespace + ""*\\]"", // Prefer arguments quoted, // then not containing pseudos/brackets, // then attribute selectors/non-parenthetical expressions, // then anything else // These preferences are here to reduce the number of selectors // needing tokenize in the PSEUDO preFilter pseudos = "":("" + characterEncoding + "")(?:\\(((['\""])((?:\\\\.|[^\\\\])*?)\\3|((?:\\\\.|[^\\\\()[\\]]|"" + attributes.replace( 3, 8 ) + "")*)|.*)\\)|)"", rsibling = new RegExp( whitespace + ""*[+~]"" ), rattributeQuotes = new RegExp( ""="" + whitespace + ""*([^\\]'\""]*)"" + whitespace + ""*\\]"", ""g"" ), rinputs = /^(?:input|select|textarea|button)$/i, rheader = /^h\d$/i, // Support: Firefox // BMP codepoint // nodes that are no longer in the document #6963 newContext = rsibling.test( selector ) && context.parentNode || context; if ( keys.push( key += "" "" ) > Expr.cacheLength ) { return (cache[ key ] = value); * Detect xml// Expose support vars for convenience support = Sizzle.support = {}; var doc = node ? node.ownerDocument || node : preferredDoc, if ( parent && parent.attachEvent && parent !== parent.top ) { parent.attachEvent( ""onbeforeunload"", function() { setDocument(); }); support.getElementsByClassName = assert(function( div ) { return m && m.parentNode ? [m] : []; div.innerHTML = ""<select><option selected=''></option></select>""; // Support: Opera 10-12/IE8 // ^= $= *= and empty values // Should not select anything // The type attribute is restricted during .innerHTML assignment div.appendChild( input ).setAttribute( ""t"", """" ); if ( div.querySelectorAll(""[t^='']"").length ) { rbuggyQSA.push( ""[*^$]="" + whitespace + ""*(?:''|\""\"")"" ); if ( (support.matchesSelector = rnative.test( (matches = docElem.webkitMatchesSelector || contains = rnative.test( docElem.contains ) || docElem.compareDocumentPosition ? sortOrder = docElem.compareDocumentPosition ? var compare = b.compareDocumentPosition && a.compareDocumentPosition && a.compareDocumentPosition( b ); // Disconnected nodes if ( compare & 1 || (!support.sortDetached && b.compareDocumentPosition( a ) === compare) ) { // Choose the first element that is related to our preferred document if ( a === doc || contains(preferredDoc, a) ) { return -1; } if ( b === doc || contains(preferredDoc, b) ) { return 1; } // Maintain original order return sortInput ? ( indexOf.call( sortInput, a ) - indexOf.call( sortInput, b ) ) : 0; } return compare & 4 ? -1 : 1; // Not directly comparable, sort on existence of method return a.compareDocumentPosition ? -1 : 1; // Exit early if the nodes are identical if ( a === b ) { hasDuplicate = true; return 0; } else if ( !aup || !bup ) { return Sizzle( expr, document, null, [elem] ).length > 0; return val === undefined ? null : val; for ( ; (node = elem[i]); i++ ) { // innerText usage removed for consistency of new lines (see #11153) match[3] = ( match[4] || match[5] || """" ).replace( runescape, funescape ); unquoted = !match[5] && match[2]; if ( match[3] && match[4] !== undefined ) { match[2] = match[4]; // :empty is only affected by element nodes and content nodes(including text(3), cdata(4)), // not comment, processing instructions, or others // Thanks to Diego Perini for the nodeName shortcut // Greater than ""@"" means alpha characters (specifically not starting with ""#"" or ""?"") if ( elem.nodeName > ""@"" || elem.nodeType === 3 || elem.nodeType === 4 ) { // IE6 and 7 will map elem.type to 'text' for new HTML5 types (search, etc) // use getAttribute instead to test this case ( (attr = elem.getAttribute(""type"")) == null || attr.toLowerCase() === elem.type );function tokenize( selector, parseOnly ) { groups.push( tokens = [] );} var data, cache, outerCache, dirkey = dirruns + "" "" + doneName; if ( (cache = outerCache[ dir ]) && cache[0] === dirkey ) { if ( (data = cache[1]) === true || data === cachedruns ) { return data === true; } cache = outerCache[ dir ] = [ dirkey ]; cache[1] = matcher( elem, context, xml ) || cachedruns; if ( cache[1] === true ) { // A counter to specify which element is currently being matched var matcherCachedRuns = 0, bySet = setMatchers.length > 0, superMatcher = function( seed, context, xml, results, expandContext ) { setMatched = [], outermost = expandContext != null, // We must always have either seed elements or context elems = seed || byElement && Expr.find[""TAG""]( ""*"", expandContext && context.parentNode || context ), dirrunsUnique = (dirruns += contextBackup == null ? 1 : Math.random() || 0.1); cachedruns = matcherCachedRuns; for ( ; (elem = elems[i]) != null; i++ ) { cachedruns = ++matcherCachedRuns;compile = Sizzle.compile = function( selector, group /* Internal Use Only */ ) { if ( !group ) { group = tokenize( selector ); i = group.length; cached = matcherFromTokens( group[i] );function multipleContexts( selector, contexts, results ) { var i = 0, len = contexts.length; for ( ; i < len; i++ ) { Sizzle( selector, contexts[i], results ); } return results; } function select( selector, context, results, seed ) { match = tokenize( selector ); if ( !seed ) { // Try to minimize operations if there is only one group if ( match.length === 1 ) { // Take a shortcut and set the context if the root selector is an ID tokens = match[0] = match[0].slice( 0 ); if ( tokens.length > 2 && (token = tokens[0]).type === ""ID"" && support.getById && context.nodeType === 9 && documentIsHTML && Expr.relative[ tokens[1].type ] ) { context = ( Expr.find[""ID""]( token.matches[0].replace(runescape, funescape), context ) || [] )[0]; if ( !context ) { return results; } selector = selector.slice( tokens.shift().value.length ); // Fetch a seed set for right-to-left matching i = matchExpr[""needsContext""].test( selector ) ? 0 : tokens.length; while ( i-- ) { token = tokens[i]; // Abort if we hit a combinator if ( Expr.relative[ (type = token.type) ] ) { break; } if ( (find = Expr.find[ type ]) ) { // Search, expanding context for leading sibling combinators if ( (seed = find( token.matches[0].replace( runescape, funescape ), rsibling.test( tokens[0].type ) && context.parentNode || context )) ) { // If seed is empty or no tokens remain, we can return early tokens.splice( i, 1 ); selector = seed.length && toSelector( tokens ); if ( !selector ) { push.apply( results, seed ); return results; } break; // Compile and execute a filtering function compile( selector, match )( rsibling.test( selector )}support.detectDuplicates = hasDuplicate; return (val = elem.getAttributeNode( name )) && val.specified ? val.value : elem[ name ] === true ? name.toLowerCase() : null;})( window ); jQuery.each( options.match( core_rnotwhite ) || [], function( _, flag ) { var // Flag to know if list is currently firing firing, // Last fire value (for non-forgettable lists) // First callback to fire (used internally by add and fireWith) firingStart, while( ( index = jQuery.inArray( arg, list, index ) ) > -1 ) { var action = tuple[ 0 ], fn = jQuery.isFunction( fns[ i ] ) && fns[ i ]; newDefer[ action + ""With"" ]( this === promise ? newDefer.promise() : this, fn ? [ returned ] : arguments ); resolveValues = core_slice.call( arguments ), values[ i ] = arguments.length > 1 ? core_slice.call( arguments ) : value; if( values === progressValues ) {jQuery.support = (function( support ) { var all, a, input, select, fragment, opt, eventName, isSupported, i, div = document.createElement(""div""); // Setup div.setAttribute( ""className"", ""t"" ); div.innerHTML = "" <link/><table></table><a href='/a'>a</a><input type='checkbox'/>""; // Finish early in limited (non-browser) environments all = div.getElementsByTagName(""*"") || []; a = div.getElementsByTagName(""a"")[ 0 ]; if ( !a || !a.style || !all.length ) { return support; } // First batch of tests select = document.createElement(""select""); opt = select.appendChild( document.createElement(""option"") ); input = div.getElementsByTagName(""input"")[ 0 ]; a.style.cssText = ""top:1px;float:left;opacity:.5""; // Test setAttribute on camelCase class. If it works, we need attrFixes when doing get/setAttribute (ie6/7) support.getSetAttribute = div.className !== ""t""; // IE strips leading whitespace when .innerHTML is used support.leadingWhitespace = div.firstChild.nodeType === 3; // Make sure that tbody elements aren't automatically inserted // IE will insert them into empty tables support.tbody = !div.getElementsByTagName(""tbody"").length; // Make sure that link elements get serialized correctly by innerHTML // This requires a wrapper element in IE support.htmlSerialize = !!div.getElementsByTagName(""link"").length; // Get the style information from getAttribute // (IE uses .cssText instead) support.style = /top/.test( a.getAttribute(""style"") ); // Make sure that URLs aren't manipulated // (IE normalizes it by default) support.hrefNormalized = a.getAttribute(""href"") === ""/a""; // Make sure that element opacity exists // (IE uses filter instead) // Use a regex to work around a WebKit issue. See #5145 support.opacity = /^0.5/.test( a.style.opacity ); // Verify style float existence // (IE uses styleFloat instead of cssFloat) support.cssFloat = !!a.style.cssFloat; // Check the default checkbox/radio value ("""" on WebKit; ""on"" elsewhere) support.checkOn = !!input.value; // Make sure that a selected-by-default option has a working selected property. // (WebKit defaults to false instead of true, IE too, if it's in an optgroup) support.optSelected = opt.selected; // Tests for enctype support on a form (#6743) support.enctype = !!document.createElement(""form"").enctype; // Makes sure cloning an html5 element does not cause problems // Where outerHTML is undefined, this still works support.html5Clone = document.createElement(""nav"").cloneNode( true ).outerHTML !== ""<:nav></:nav>""; // Will be defined later support.inlineBlockNeedsLayout = false; support.shrinkWrapBlocks = false; support.pixelPosition = false; support.deleteExpando = true; support.noCloneEvent = true; support.reliableMarginRight = true; support.boxSizingReliable = true; // Make sure checked status is properly cloned input.checked = true; support.noCloneChecked = input.cloneNode( true ).checked; // Make sure that the options inside disabled selects aren't marked as disabled // (WebKit marks them as disabled) select.disabled = true; support.optDisabled = !opt.disabled; // Support: IE<9 try { delete div.test; } catch( e ) { support.deleteExpando = false; } // Check if we can trust getAttribute(""value"") input = document.createElement(""input""); input.setAttribute( ""value"", """" ); support.input = input.getAttribute( ""value"" ) === """"; // Check if an input maintains its value after becoming a radio input.value = ""t""; input.setAttribute( ""type"", ""radio"" ); support.radioValue = input.value === ""t""; // #11217 - WebKit loses check when the name is after the checked attribute input.setAttribute( ""checked"", ""t"" ); input.setAttribute( ""name"", ""t"" ); fragment = document.createDocumentFragment(); fragment.appendChild( input ); // Check if a disconnected checkbox will retain its checked // value of true after appended to the DOM (IE6/7) support.appendChecked = input.checked; // WebKit doesn't clone checked state correctly in fragments support.checkClone = fragment.cloneNode( true ).cloneNode( true ).lastChild.checked; // Support: IE<9 // Opera does not clone events (and typeof div.attachEvent === undefined). // IE9-10 clones events bound via attachEvent, but they don't trigger with .click() if ( div.attachEvent ) { div.attachEvent( ""onclick"", function() { support.noCloneEvent = false; }); div.cloneNode( true ).click(); } // Support: IE<9 (lack submit/change bubble), Firefox 17+ (lack focusin event) // Beware of CSP restrictions (https://developer.mozilla.org/en/Security/CSP) for ( i in { submit: true, change: true, focusin: true }) { div.setAttribute( eventName = ""on"" + i, ""t"" ); support[ i + ""Bubbles"" ] = eventName in window || div.attributes[ eventName ].expando === false; } div.style.backgroundClip = ""content-box""; div.cloneNode( true ).style.backgroundClip = """"; support.clearCloneStyle = div.style.backgroundClip === ""content-box""; // Support: IE<9 // Iteration over object's inherited properties before its own. for ( i in jQuery( support ) ) { break; } support.ownLast = i !== ""0""; // Run tests that need a body at doc ready jQuery(function() { var container, marginDiv, tds, divReset = ""padding:0;margin:0;border:0;display:block;box-sizing:content-box;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;"", body = document.getElementsByTagName(""body"")[0]; if ( !body ) { // Return for frameset docs that don't have a body container = document.createElement(""div""); container.style.cssText = ""border:0;width:0;height:0;position:absolute;top:0;left:-9999px;margin-top:1px""; body.appendChild( container ).appendChild( div ); // Support: IE8 // Check if table cells still have offsetWidth/Height when they are set // to display:none and there are still other visible table cells in a // table row; if so, offsetWidth/Height are not reliable for use when // determining if an element has been hidden directly using // display:none (it is still safe to use offsets if a parent element is // hidden; don safety goggles and see bug #4512 for more information). div.innerHTML = ""<table><tr><td></td><td>t</td></tr></table>""; tds = div.getElementsByTagName(""td""); tds[ 0 ].style.cssText = ""padding:0;margin:0;border:0;display:none""; isSupported = ( tds[ 0 ].offsetHeight === 0 ); tds[ 0 ].style.display = """"; tds[ 1 ].style.display = ""none""; // Support: IE8 // Check if empty table cells still have offsetWidth/Height support.reliableHiddenOffsets = isSupported && ( tds[ 0 ].offsetHeight === 0 ); // Check box-sizing and margin behavior. div.innerHTML = """"; div.style.cssText = ""box-sizing:border-box;-moz-box-sizing:border-box;-webkit-box-sizing:border-box;padding:1px;border:1px;display:block;width:4px;margin-top:1%;position:absolute;top:1%;""; // Workaround failing boxSizing test due to offsetWidth returning wrong value // with some non-1 values of body zoom, ticket #13543 jQuery.swap( body, body.style.zoom != null ? { zoom: 1 } : {}, function() { support.boxSizing = div.offsetWidth === 4; }); // Use window.getComputedStyle because jsdom on node.js will break without it. if ( window.getComputedStyle ) { support.pixelPosition = ( window.getComputedStyle( div, null ) || {} ).top !== ""1%""; support.boxSizingReliable = ( window.getComputedStyle( div, null ) || { width: ""4px"" } ).width === ""4px""; // Check if div with explicit width and no margin-right incorrectly // gets computed margin-right based on width of container. (#3333) // Fails in WebKit before Feb 2011 nightlies // WebKit Bug 13343 - getComputedStyle returns wrong value for margin-right marginDiv = div.appendChild( document.createElement(""div"") ); marginDiv.style.cssText = div.style.cssText = divReset; marginDiv.style.marginRight = marginDiv.style.width = ""0""; div.style.width = ""1px""; support.reliableMarginRight = !parseFloat( ( window.getComputedStyle( marginDiv, null ) || {} ).marginRight ); if ( typeof div.style.zoom !== core_strundefined ) { // Support: IE<8 // Check if natively block-level elements act like inline-block // elements when setting their display to 'inline' and giving // them layout div.innerHTML = """"; div.style.cssText = divReset + ""width:1px;padding:1px;display:inline;zoom:1""; support.inlineBlockNeedsLayout = ( div.offsetWidth === 3 ); // Support: IE6 // Check if elements with layout shrink-wrap their children div.style.display = ""block""; div.innerHTML = ""<div></div>""; div.firstChild.style.width = ""5px""; support.shrinkWrapBlocks = ( div.offsetWidth !== 3 ); if ( support.inlineBlockNeedsLayout ) { // Prevent IE 6 from affecting layout for positioned elements #11048 // Prevent IE from shrinking the body in IE 7 mode #12869 // Support: IE<8 body.style.zoom = 1; body.removeChild( container ); // Null elements to avoid leaks in IE container = div = tds = marginDiv = null; // Null elements to avoid leaks in IE all = select = fragment = opt = a = input = null; return support; })({}); var rbrace = /(?:\{[\s\S]*\}|\[[\s\S]*\])$/, rmultiDash = /([A-Z])/g; function internalData( elem, name, data, pvt /* Internal Use Only */ ){ if ( !jQuery.acceptData( elem ) ) { return; } var ret, thisCache, internalKey = jQuery.expando, // We have to handle DOM nodes and JS objects differently because IE6-7 // can't GC object references properly across the DOM-JS boundary isNode = elem.nodeType, // Only DOM nodes need the global jQuery cache; JS object data is // attached directly to the object so GC can occur automatically cache = isNode ? jQuery.cache : elem, // Only defining an ID for JS objects if its cache already exists allows // the code to shortcut on the same path as a DOM node with no cache id = isNode ? elem[ internalKey ] : elem[ internalKey ] && internalKey; // Avoid doing any more work than we need to when trying to get data on an // object that has no data at all if ( (!id || !cache[id] || (!pvt && !cache[id].data)) && data === undefined && typeof name === ""string"" ) { return; } if ( !id ) { // Only DOM nodes need a new unique ID for each element since their data // ends up in the global cache if ( isNode ) { id = elem[ internalKey ] = core_deletedIds.pop() || jQuery.guid++; } else { id = internalKey; } } if ( !cache[ id ] ) { // Avoid exposing jQuery metadata on plain JS objects when the object // is serialized using JSON.stringify cache[ id ] = isNode ? {} : { toJSON: jQuery.noop }; } // An object can be passed to jQuery.data instead of a key/value pair; this gets // shallow copied over onto the existing cache if ( typeof name === ""object"" || typeof name === ""function"" ) { if ( pvt ) { cache[ id ] = jQuery.extend( cache[ id ], name ); } else { cache[ id ].data = jQuery.extend( cache[ id ].data, name ); } } thisCache = cache[ id ]; // jQuery data() is stored in a separate object inside the object's internal data // cache in order to avoid key collisions between internal data and user-defined // data. if ( !pvt ) { if ( !thisCache.data ) { thisCache.data = {}; } thisCache = thisCache.data; } if ( data !== undefined ) { thisCache[ jQuery.camelCase( name ) ] = data; } // Check for both converted-to-camel and non-converted data property names // If a data property was specified if ( typeof name === ""string"" ) { // First Try to find as-is property data ret = thisCache[ name ]; // Test for null|undefined property data if ( ret == null ) { // Try to find the camelCased property ret = thisCache[ jQuery.camelCase( name ) ]; } } else { ret = thisCache; } return ret;function internalRemoveData( elem, name, pvt ) { if ( !jQuery.acceptData( elem ) ) { return; } var thisCache, i, isNode = elem.nodeType, // See jQuery.data for more information cache = isNode ? jQuery.cache : elem, id = isNode ? elem[ jQuery.expando ] : jQuery.expando; // If there is already no cache entry for this object, there is no // purpose in continuing if ( !cache[ id ] ) { return; } if ( name ) { thisCache = pvt ? cache[ id ] : cache[ id ].data; if ( thisCache ) { // Support array or space separated string names for data keys if ( !jQuery.isArray( name ) ) { // try the string as a key before any manipulation if ( name in thisCache ) { name = [ name ]; } else { // split the camel cased version by spaces unless a key with the spaces exists name = jQuery.camelCase( name ); if ( name in thisCache ) { name = [ name ]; } else { name = name.split("" ""); } } name = name.concat( jQuery.map( name, jQuery.camelCase ) ); delete thisCache[ name[i] ]; } // If there is no data left in the cache, we want to continue // and let the cache object itself get destroyed if ( pvt ? !isEmptyDataObject(thisCache) : !jQuery.isEmptyObject(thisCache) ) { return; } // See jQuery.data for more information if ( !pvt ) { delete cache[ id ].data; // Don't destroy the parent cache unless the internal data object // had been the only thing left in it if ( !isEmptyDataObject( cache[ id ] ) ) { return; // Destroy the cache if ( isNode ) { jQuery.cleanData( [ elem ], true ); // Use delete when supported for expandos or `cache` is not a window per isWindow (#10080) /* jshint eqeqeq: false */ } else if ( jQuery.support.deleteExpando || cache != cache.window ) { /* jshint eqeqeq: true */ delete cache[ id ]; // When all else fails, null } else { cache[ id ] = null; } }jQuery.extend({ cache: {}, // The following elements throw uncatchable exceptions if you // attempt to add expando properties to them. noData: { ""applet"": true, ""embed"": true, // Ban all objects except for Flash (which handle expandos) ""object"": ""clsid:D27CDB6E-AE6D-11cf-96B8-444553540000"" }, hasData: function( elem ) { elem = elem.nodeType ? jQuery.cache[ elem[jQuery.expando] ] : elem[ jQuery.expando ]; return !!elem && !isEmptyDataObject( elem ); }, data: function( elem, name, data ) { return internalData( elem, name, data ); }, removeData: function( elem, name ) { return internalRemoveData( elem, name ); }, // For internal use only. _data: function( elem, name, data ) { return internalData( elem, name, data, true ); }, _removeData: function( elem, name ) { return internalRemoveData( elem, name, true ); }, // A method for determining if a DOM node can handle the data expando acceptData: function( elem ) { // Do not set data on non-element because it will not be cleared (#8335). if ( elem.nodeType && elem.nodeType !== 1 && elem.nodeType !== 9 ) { return false; } var noData = elem.nodeName && jQuery.noData[ elem.nodeName.toLowerCase() ]; // nodes accept data unless otherwise specified; rejection can be conditional return !noData || noData !== true && elem.getAttribute(""classid"") === noData; } }); jQuery.fn.extend({ data: function( key, value ) { var attrs, name, data = null, i = 0, elem = this[0]; // Special expections of .data basically thwart jQuery.access, // so implement the relevant behavior ourselves // Gets all values if ( key === undefined ) { if ( this.length ) { data = jQuery.data( elem ); if ( elem.nodeType === 1 && !jQuery._data( elem, ""parsedAttrs"" ) ) { attrs = elem.attributes; for ( ; i < attrs.length; i++ ) { name = attrs[i].name; if ( name.indexOf(""data-"") === 0 ) { name = jQuery.camelCase( name.slice(5) ); dataAttr( elem, name, data[ name ] ); } } jQuery._data( elem, ""parsedAttrs"", true ); } } return data; } // Sets multiple values if ( typeof key === ""object"" ) { return this.each(function() { jQuery.data( this, key ); }); } return arguments.length > 1 ? // Sets one value this.each(function() { jQuery.data( this, key, value ); }) : // Gets one value // Try to fetch any internally stored data first elem ? dataAttr( elem, key, jQuery.data( elem, key ) ) : null; }, removeData: function( key ) { return this.each(function() { jQuery.removeData( this, key ); }); } }); var name = ""data-"" + key.replace( rmultiDash, ""-$1"" ).toLowerCase(); data; jQuery.data( elem, key, data ); // checks a cache object for emptiness function isEmptyDataObject( obj ) { var name; for ( name in obj ) { // if the public data object is empty, the private is still empty if ( name === ""data"" && jQuery.isEmptyObject( obj[name] ) ) { continue; } if ( name !== ""toJSON"" ) { return false; } return true; } queue = jQuery._data( elem, type ); if ( !queue || jQuery.isArray(data) ) { queue = jQuery._data( elem, type, jQuery.makeArray(data) ); return jQuery._data( elem, key ) || jQuery._data( elem, key, { jQuery._removeData( elem, type + ""queue"" ); jQuery._removeData( elem, key ); // Based off of the plugin by Clint Helfers, with permission. // http://blindsignals.com/index.php/2009/07/jquery-delay/ delay: function( time, type ) { time = jQuery.fx ? jQuery.fx.speeds[ time ] || time : time; type = type || ""fx""; return this.queue( type, function( next, hooks ) { var timeout = setTimeout( next, time ); hooks.stop = function() { clearTimeout( timeout ); }; }); }, while( i-- ) { tmp = jQuery._data( elements[ i ], type + ""queueHooks"" );var nodeHook, boolHook, rclass = /[\t\r\n\f]/g, rreturn = /\r/g, rfocusable = /^(?:input|select|textarea|button|object)$/i, rclickable = /^(?:a|area)$/i, ruseDefault = /^(?:checked|selected)$/i, getSetAttribute = jQuery.support.getSetAttribute, getSetInput = jQuery.support.input;jQuery.fn.extend({ attr: function( name, value ) { return jQuery.access( this, jQuery.attr, name, value, arguments.length > 1 ); }, removeAttr: function( name ) { return this.each(function() { jQuery.removeAttr( this, name ); }); }, prop: function( name, value ) { return jQuery.access( this, jQuery.prop, name, value, arguments.length > 1 ); }, removeProp: function( name ) { name = jQuery.propFix[ name ] || name; return this.each(function() { // try/catch handles cases where IE balks (such as removing a property on window) try { this[ name ] = undefined; delete this[ name ]; } catch( e ) {} }); }, addClass: function( value ) { var classes, elem, cur, clazz, j, i = 0, len = this.length, proceed = typeof value === ""string"" && value; if ( jQuery.isFunction( value ) ) { return this.each(function( j ) { jQuery( this ).addClass( value.call( this, j, this.className ) ); }); } if ( proceed ) { // The disjunction here is for better compressibility (see removeClass) classes = ( value || """" ).match( core_rnotwhite ) || []; for ( ; i < len; i++ ) { elem = this[ i ]; cur = elem.nodeType === 1 && ( elem.className ? ( "" "" + elem.className + "" "" ).replace( rclass, "" "" ) : "" "" ); if ( cur ) { j = 0; while ( (clazz = classes[j++]) ) { if ( cur.indexOf( "" "" + clazz + "" "" ) < 0 ) { cur += clazz + "" ""; } } elem.className = jQuery.trim( cur ); } } } return this; }, removeClass: function( value ) { var classes, elem, cur, clazz, j, i = 0, len = this.length, proceed = arguments.length === 0 || typeof value === ""string"" && value; if ( jQuery.isFunction( value ) ) { return this.each(function( j ) { jQuery( this ).removeClass( value.call( this, j, this.className ) ); }); } if ( proceed ) { classes = ( value || """" ).match( core_rnotwhite ) || []; for ( ; i < len; i++ ) { elem = this[ i ]; // This expression is here for better compressibility (see addClass) cur = elem.nodeType === 1 && ( elem.className ? ( "" "" + elem.className + "" "" ).replace( rclass, "" "" ) : """" ); if ( cur ) { j = 0; while ( (clazz = classes[j++]) ) { // Remove *all* instances while ( cur.indexOf( "" "" + clazz + "" "" ) >= 0 ) { cur = cur.replace( "" "" + clazz + "" "", "" "" ); } } elem.className = value ? jQuery.trim( cur ) : """"; } } } return this; }, toggleClass: function( value, stateVal ) { var type = typeof value; if ( typeof stateVal === ""boolean"" && type === ""string"" ) { return stateVal ? this.addClass( value ) : this.removeClass( value ); } if ( jQuery.isFunction( value ) ) { return this.each(function( i ) { jQuery( this ).toggleClass( value.call(this, i, this.className, stateVal), stateVal ); }); } return this.each(function() { if ( type === ""string"" ) { // toggle individual class names var className, i = 0, self = jQuery( this ), classNames = value.match( core_rnotwhite ) || []; while ( (className = classNames[ i++ ]) ) { // check each className given, space separated list if ( self.hasClass( className ) ) { self.removeClass( className ); } else { self.addClass( className ); } } // Toggle whole class name } else if ( type === core_strundefined || type === ""boolean"" ) { if ( this.className ) { // store className if set jQuery._data( this, ""__className__"", this.className ); } // If the element has a class name or if we're passed ""false"", // then remove the whole classname (if there was one, the above saved it). // Otherwise bring back whatever was previously saved (if anything), // falling back to the empty string if nothing was stored. this.className = this.className || value === false ? """" : jQuery._data( this, ""__className__"" ) || """"; } }); }, hasClass: function( selector ) { var className = "" "" + selector + "" "", i = 0, l = this.length; for ( ; i < l; i++ ) { if ( this[i].nodeType === 1 && ("" "" + this[i].className + "" "").replace(rclass, "" "").indexOf( className ) >= 0 ) { return true; } } return false; }, val: function( value ) { var ret, hooks, isFunction, elem = this[0]; if ( !arguments.length ) { if ( elem ) { hooks = jQuery.valHooks[ elem.type ] || jQuery.valHooks[ elem.nodeName.toLowerCase() ]; if ( hooks && ""get"" in hooks && (ret = hooks.get( elem, ""value"" )) !== undefined ) { return ret; } ret = elem.value; return typeof ret === ""string"" ? // handle most common string cases ret.replace(rreturn, """") : // handle cases where value is null/undef or number ret == null ? """" : ret; } return; } isFunction = jQuery.isFunction( value ); return this.each(function( i ) { var val; if ( this.nodeType !== 1 ) { return; } if ( isFunction ) { val = value.call( this, i, jQuery( this ).val() ); } else { val = value; } // Treat null/undefined as """"; convert numbers to string if ( val == null ) { val = """"; } else if ( typeof val === ""number"" ) { val += """"; } else if ( jQuery.isArray( val ) ) { val = jQuery.map(val, function ( value ) { return value == null ? """" : value + """"; }); } hooks = jQuery.valHooks[ this.type ] || jQuery.valHooks[ this.nodeName.toLowerCase() ]; // If set returns undefined, fall back to normal setting if ( !hooks || !(""set"" in hooks) || hooks.set( this, val, ""value"" ) === undefined ) { this.value = val; } }); } }); jQuery.extend({ valHooks: { option: { get: function( elem ) { // Use proper attribute retrieval(#6932, #12072) var val = jQuery.find.attr( elem, ""value"" ); return val != null ? val : elem.text; } }, select: { get: function( elem ) { var value, option, options = elem.options, index = elem.selectedIndex, one = elem.type === ""select-one"" || index < 0, values = one ? null : [], max = one ? index + 1 : options.length, i = index < 0 ? max : one ? index : 0; // Loop through all the selected options for ( ; i < max; i++ ) { option = options[ i ]; // oldIE doesn't update selected after form reset (#2551) if ( ( option.selected || i === index ) && // Don't return options that are disabled or in a disabled optgroup ( jQuery.support.optDisabled ? !option.disabled : option.getAttribute(""disabled"") === null ) && ( !option.parentNode.disabled || !jQuery.nodeName( option.parentNode, ""optgroup"" ) ) ) { // Get the specific value for the option value = jQuery( option ).val(); // We don't need an array for one selects if ( one ) { return value; } // Multi-Selects return an array values.push( value ); } } return values; }, set: function( elem, value ) { var optionSet, option, options = elem.options, values = jQuery.makeArray( value ), i = options.length; while ( i-- ) { option = options[ i ]; if ( (option.selected = jQuery.inArray( jQuery(option).val(), values ) >= 0) ) { optionSet = true; } } // force browsers to behave consistently when non-matching value is set if ( !optionSet ) { elem.selectedIndex = -1; } return values; } } }, attr: function( elem, name, value ) { var hooks, ret, nType = elem.nodeType; // don't get/set attributes on text, comment and attribute nodes if ( !elem || nType === 3 || nType === 8 || nType === 2 ) { return; } // Fallback to prop when attributes are not supported if ( typeof elem.getAttribute === core_strundefined ) { return jQuery.prop( elem, name, value ); } // All attributes are lowercase // Grab necessary hook if one is defined if ( nType !== 1 || !jQuery.isXMLDoc( elem ) ) { name = name.toLowerCase(); hooks = jQuery.attrHooks[ name ] || ( jQuery.expr.match.bool.test( name ) ? boolHook : nodeHook ); } if ( value !== undefined ) { if ( value === null ) { jQuery.removeAttr( elem, name ); } else if ( hooks && ""set"" in hooks && (ret = hooks.set( elem, value, name )) !== undefined ) { return ret; } else { elem.setAttribute( name, value + """" ); return value; } } else if ( hooks && ""get"" in hooks && (ret = hooks.get( elem, name )) !== null ) { return ret; } else { ret = jQuery.find.attr( elem, name ); // Non-existent attributes return null, we normalize to undefined return ret == null ? undefined : ret; } }, removeAttr: function( elem, value ) { var name, propName, i = 0, attrNames = value && value.match( core_rnotwhite ); if ( attrNames && elem.nodeType === 1 ) { while ( (name = attrNames[i++]) ) { propName = jQuery.propFix[ name ] || name; // Boolean attributes get special treatment (#10870) if ( jQuery.expr.match.bool.test( name ) ) { // Set corresponding property to false if ( getSetInput && getSetAttribute || !ruseDefault.test( name ) ) { elem[ propName ] = false; // Support: IE<9 // Also clear defaultChecked/defaultSelected (if appropriate) } else { elem[ jQuery.camelCase( ""default-"" + name ) ] = elem[ propName ] = false; } // See #9699 for explanation of this approach (setting first, then removal) } else { jQuery.attr( elem, name, """" ); } elem.removeAttribute( getSetAttribute ? name : propName ); } } }, attrHooks: { type: { set: function( elem, value ) { if ( !jQuery.support.radioValue && value === ""radio"" && jQuery.nodeName(elem, ""input"") ) { // Setting the type on a radio button after the value resets the value in IE6-9 // Reset value to default in case type is set after value during creation var val = elem.value; elem.setAttribute( ""type"", value ); if ( val ) { elem.value = val; } return value; } } } }, propFix: { ""for"": ""htmlFor"", ""class"": ""className"" }, prop: function( elem, name, value ) { var ret, hooks, notxml, nType = elem.nodeType; // don't get/set properties on text, comment and attribute nodes if ( !elem || nType === 3 || nType === 8 || nType === 2 ) { return; } notxml = nType !== 1 || !jQuery.isXMLDoc( elem ); if ( notxml ) { // Fix name and attach hooks name = jQuery.propFix[ name ] || name; hooks = jQuery.propHooks[ name ]; } if ( value !== undefined ) { return hooks && ""set"" in hooks && (ret = hooks.set( elem, value, name )) !== undefined ? ret : ( elem[ name ] = value ); } else { return hooks && ""get"" in hooks && (ret = hooks.get( elem, name )) !== null ? ret : elem[ name ]; } }, propHooks: { tabIndex: { get: function( elem ) { // elem.tabIndex doesn't always return the correct value when it hasn't been explicitly set // http://fluidproject.org/blog/2008/01/09/getting-setting-and-removing-tabindex-values-with-javascript/ // Use proper attribute retrieval(#12072) var tabindex = jQuery.find.attr( elem, ""tabindex"" ); return tabindex ? parseInt( tabindex, 10 ) : rfocusable.test( elem.nodeName ) || rclickable.test( elem.nodeName ) && elem.href ? 0 : -1; } } } }); // Hooks for boolean attributes boolHook = { set: function( elem, value, name ) { if ( value === false ) { // Remove boolean attributes when set to false jQuery.removeAttr( elem, name ); } else if ( getSetInput && getSetAttribute || !ruseDefault.test( name ) ) { // IE<8 needs the *property* name elem.setAttribute( !getSetAttribute && jQuery.propFix[ name ] || name, name ); // Use defaultChecked and defaultSelected for oldIE } else { elem[ jQuery.camelCase( ""default-"" + name ) ] = elem[ name ] = true; } return name; } }; jQuery.each( jQuery.expr.match.bool.source.match( /\w+/g ), function( i, name ) { var getter = jQuery.expr.attrHandle[ name ] || jQuery.find.attr; jQuery.expr.attrHandle[ name ] = getSetInput && getSetAttribute || !ruseDefault.test( name ) ? function( elem, name, isXML ) { var fn = jQuery.expr.attrHandle[ name ], ret = isXML ? undefined : /* jshint eqeqeq: false */ (jQuery.expr.attrHandle[ name ] = undefined) != getter( elem, name, isXML ) ? name.toLowerCase() : null; jQuery.expr.attrHandle[ name ] = fn; return ret; } : function( elem, name, isXML ) { return isXML ? undefined : elem[ jQuery.camelCase( ""default-"" + name ) ] ? name.toLowerCase() : null; }; }); // fix oldIE attroperties if ( !getSetInput || !getSetAttribute ) { jQuery.attrHooks.value = { set: function( elem, value, name ) { if ( jQuery.nodeName( elem, ""input"" ) ) { // Does not return so that setAttribute is also used elem.defaultValue = value; } else { // Use nodeHook if defined (#1954); otherwise setAttribute is fine return nodeHook && nodeHook.set( elem, value, name ); } } }; } // IE6/7 do not support getting/setting some attributes with get/setAttribute if ( !getSetAttribute ) { // Use this for any attribute in IE6/7 // This fixes almost every IE6/7 issue nodeHook = { set: function( elem, value, name ) { // Set the existing or create a new attribute node var ret = elem.getAttributeNode( name ); if ( !ret ) { elem.setAttributeNode( (ret = elem.ownerDocument.createAttribute( name )) ); } ret.value = value += """"; // Break association with cloned elements by also using setAttribute (#9646) return name === ""value"" || value === elem.getAttribute( name ) ? value : undefined; } }; jQuery.expr.attrHandle.id = jQuery.expr.attrHandle.name = jQuery.expr.attrHandle.coords = // Some attributes are constructed with empty-string values when not defined function( elem, name, isXML ) { var ret; return isXML ? undefined : (ret = elem.getAttributeNode( name )) && ret.value !== """" ? ret.value : null; }; jQuery.valHooks.button = { get: function( elem, name ) { var ret = elem.getAttributeNode( name ); return ret && ret.specified ? ret.value : undefined; }, set: nodeHook.set // Set contenteditable to false on removals(#10429) // Setting to empty string throws an error as an invalid value jQuery.attrHooks.contenteditable = { set: function( elem, value, name ) { nodeHook.set( elem, value === """" ? false : value, name ); } }; // Set width and height to auto instead of 0 on empty string( Bug #8150 ) // This is for removals jQuery.each([ ""width"", ""height"" ], function( i, name ) { jQuery.attrHooks[ name ] = { set: function( elem, value ) { if ( value === """" ) { elem.setAttribute( name, ""auto"" ); return value; } } }; }); }// Some attributes require a special call on IE // http://msdn.microsoft.com/en-us/library/ms536429%28VS.85%29.aspx if ( !jQuery.support.hrefNormalized ) { // href/src property should get the full normalized URL (#10299/#12915) jQuery.each([ ""href"", ""src"" ], function( i, name ) { jQuery.propHooks[ name ] = { get: function( elem ) { return elem.getAttribute( name, 4 ); } }; }); }if ( !jQuery.support.style ) { jQuery.attrHooks.style = { get: function( elem ) { // Return undefined in the case of empty string // Note: IE uppercases css property names, but if we were to .toLowerCase() // .cssText, that would destroy case senstitivity in URL's, like in ""background"" return elem.style.cssText || undefined; }, set: function( elem, value ) { return ( elem.style.cssText = value + """" ); } }; }// Safari mis-reports the default selected property of an option // Accessing the parent's selectedIndex property fixes it if ( !jQuery.support.optSelected ) { jQuery.propHooks.selected = { get: function( elem ) { var parent = elem.parentNode; if ( parent ) { parent.selectedIndex; // Make sure that it also works with optgroups, see #5701 if ( parent.parentNode ) { parent.parentNode.selectedIndex; } } return null; } }; }jQuery.each([ ""tabIndex"", ""readOnly"", ""maxLength"", ""cellSpacing"", ""cellPadding"", ""rowSpan"", ""colSpan"", ""useMap"", ""frameBorder"", ""contentEditable"" ], function() { jQuery.propFix[ this.toLowerCase() ] = this; });// IE6/7 call enctype encoding if ( !jQuery.support.enctype ) { jQuery.propFix.enctype = ""encoding""; }// Radios and checkboxes getter/setter jQuery.each([ ""radio"", ""checkbox"" ], function() { jQuery.valHooks[ this ] = { set: function( elem, value ) { if ( jQuery.isArray( value ) ) { return ( elem.checked = jQuery.inArray( jQuery(elem).val(), value ) >= 0 ); } } }; if ( !jQuery.support.checkOn ) { jQuery.valHooks[ this ].get = function( elem ) { // Support: Webkit // """" is returned instead of ""on"" if a value isn't specified return elem.getAttribute(""value"") === null ? ""on"" : elem.value; }; } }); var rformElems = /^(?:input|select|textarea)$/i, rmouseEvent = /^(?:mouse|contextmenu)|click/, var tmp, events, t, handleObjIn, special, eventHandle, handleObj, handlers, type, namespaces, origType, elemData = jQuery._data( elem ); return typeof jQuery !== core_strundefined && (!e || jQuery.event.triggered !== e.type) ? jQuery.event.dispatch.apply( eventHandle.elem, arguments ) : undefined; // Add elem as a property of the handle fn to prevent a memory leak with IE non-native events eventHandle.elem = elem; types = ( types || """" ).match( core_rnotwhite ) || [""""]; // Only use addEventListener/attachEvent if the special events handler returns false // Bind the global event handler to the element } else if ( elem.attachEvent ) { elem.attachEvent( ""on"" + type, eventHandle ); // Nullify elem to prevent memory leaks in IE elem = null; var j, handleObj, tmp, origCount, t, events, special, handlers, type, namespaces, origType, elemData = jQuery.hasData( elem ) && jQuery._data( elem ); types = ( types || """" ).match( core_rnotwhite ) || [""""]; // removeData also checks for emptiness and clears the expando if empty // so use it instead of delete jQuery._removeData( elem, ""events"" ); var handle, ontype, cur, bubbleType, special, tmp, i, type = core_hasOwn.call( event, ""type"" ) ? event.type : event, namespaces = core_hasOwn.call( event, ""namespace"" ) ? event.namespace.split(""."") : []; handle = ( jQuery._data( cur, ""events"" ) || {} )[ event.type ] && jQuery._data( cur, ""handle"" ); if ( handle && jQuery.acceptData( cur ) && handle.apply && handle.apply( cur, data ) === false ) { event.preventDefault(); // Can't use an .isFunction() check here because IE6/7 fails that test. if ( ontype && elem[ type ] && !jQuery.isWindow( elem ) ) { try { elem[ type ](); } catch ( e ) { // IE<9 dies on focus/blur to hidden element (#1486,#12518) // only reproducible on winXP IE8 native, not IE9 in IE8 mode } var i, ret, handleObj, matched, j, args = core_slice.call( arguments ), handlers = ( jQuery._data( this, ""events"" ) || {} )[ event.type ] || [], var sel, handleObj, matches, i, /* jshint eqeqeq: false */ for ( ; cur != this; cur = cur.parentNode || this ) { /* jshint eqeqeq: true */ // Don't check non-elements (#13208) if ( cur.nodeType === 1 && (cur.disabled !== true || event.type !== ""click"") ) { // Support: IE<9 // Fix target property (#1925) event.target = originalEvent.srcElement || document; // Support: Chrome 23+, Safari? // Support: IE<9 // For mouse/key events, metaKey==false if it's undefined (#3368, #11328) event.metaKey = !!event.metaKey; // Includes some event props shared by KeyEvent and MouseEvent props: ""altKey bubbles cancelable ctrlKey currentTarget eventPhase metaKey relatedTarget shiftKey target timeStamp view which"".split("" ""), fixHooks: {}, keyHooks: { props: ""char charCode key keyCode"".split("" ""), filter: function( event, original ) { // Add which for key events if ( event.which == null ) { event.which = original.charCode != null ? original.charCode : original.keyCode; } return event; } }, mouseHooks: { props: ""button buttons clientX clientY fromElement offsetX offsetY pageX pageY screenX screenY toElement"".split("" ""), filter: function( event, original ) { var body, eventDoc, doc, button = original.button, fromElement = original.fromElement; // Calculate pageX/Y if missing and clientX/Y available if ( event.pageX == null && original.clientX != null ) { eventDoc = event.target.ownerDocument || document; doc = eventDoc.documentElement; body = eventDoc.body; event.pageX = original.clientX + ( doc && doc.scrollLeft || body && body.scrollLeft || 0 ) - ( doc && doc.clientLeft || body && body.clientLeft || 0 ); event.pageY = original.clientY + ( doc && doc.scrollTop || body && body.scrollTop || 0 ) - ( doc && doc.clientTop || body && body.clientTop || 0 ); } // Add relatedTarget, if necessary if ( !event.relatedTarget && fromElement ) { event.relatedTarget = fromElement === event.target ? original.toElement : fromElement; } // Add which for click: 1 === left; 2 === middle; 3 === right // Note: button is not normalized, so don't use it if ( !event.which && button !== undefined ) { event.which = ( button & 1 ? 1 : ( button & 2 ? 3 : ( button & 4 ? 2 : 0 ) ) ); } return event; } }, try { this.focus(); return false; } catch ( e ) { // Support: IE<9 // If we error on focus to hidden element (#1486, #12518), // let .trigger() run the handlers } if ( jQuery.nodeName( this, ""input"" ) && this.type === ""checkbox"" && this.click ) { // Even when returnValue equals to undefined Firefox will still show alert if ( event.result !== undefined ) {jQuery.removeEvent = document.removeEventListener ? function( elem, type, handle ) { if ( elem.removeEventListener ) { elem.removeEventListener( type, handle, false ); } } : function( elem, type, handle ) { var name = ""on"" + type; if ( elem.detachEvent ) { // #8545, #7054, preventing memory leaks for custom events in IE6-8 // detachEvent needed property on element, by name of that event, to properly expose it to GC if ( typeof elem[ name ] === core_strundefined ) { elem[ name ] = null; } elem.detachEvent( name, handle ); } }; this.isDefaultPrevented = ( src.defaultPrevented || src.returnValue === false || src.getPreventDefault && src.getPreventDefault() ) ? returnTrue : returnFalse; if ( !e ) { return; } // If preventDefault exists, run it on the original event if ( e.preventDefault ) { // Support: IE // Otherwise set the returnValue property of the original event to false } else { e.returnValue = false; if ( !e ) { return; } // If stopPropagation exists, run it on the original event if ( e.stopPropagation ) { // Support: IE // Set the cancelBubble property of the original event to true e.cancelBubble = true; mouseleave: ""mouseout""// IE submit delegation if ( !jQuery.support.submitBubbles ) { jQuery.event.special.submit = { setup: function() { // Only need this for delegated form submit events if ( jQuery.nodeName( this, ""form"" ) ) { return false; } // Lazy-add a submit handler when a descendant form may potentially be submitted jQuery.event.add( this, ""click._submit keypress._submit"", function( e ) { // Node name check avoids a VML-related crash in IE (#9807) var elem = e.target, form = jQuery.nodeName( elem, ""input"" ) || jQuery.nodeName( elem, ""button"" ) ? elem.form : undefined; if ( form && !jQuery._data( form, ""submitBubbles"" ) ) { jQuery.event.add( form, ""submit._submit"", function( event ) { event._submit_bubble = true; }); jQuery._data( form, ""submitBubbles"", true ); } }); // return undefined since we don't need an event listener }, postDispatch: function( event ) { // If form was submitted by the user, bubble the event up the tree if ( event._submit_bubble ) { delete event._submit_bubble; if ( this.parentNode && !event.isTrigger ) { jQuery.event.simulate( ""submit"", this.parentNode, event, true ); } } }, teardown: function() { // Only need this for delegated form submit events if ( jQuery.nodeName( this, ""form"" ) ) { return false; } // Remove delegated handlers; cleanData eventually reaps submit handlers attached above jQuery.event.remove( this, ""._submit"" ); } }; } // IE change delegation and checkbox/radio fix if ( !jQuery.support.changeBubbles ) { jQuery.event.special.change = { setup: function() { if ( rformElems.test( this.nodeName ) ) { // IE doesn't fire change on a check/radio until blur; trigger it on click // after a propertychange. Eat the blur-change in special.change.handle. // This still fires onchange a second time for check/radio after blur. if ( this.type === ""checkbox"" || this.type === ""radio"" ) { jQuery.event.add( this, ""propertychange._change"", function( event ) { if ( event.originalEvent.propertyName === ""checked"" ) { this._just_changed = true; } }); jQuery.event.add( this, ""click._change"", function( event ) { if ( this._just_changed && !event.isTrigger ) { this._just_changed = false; } // Allow triggered, simulated change events (#11500) jQuery.event.simulate( ""change"", this, event, true ); }); } return false; } // Delegated event; lazy-add a change handler on descendant inputs jQuery.event.add( this, ""beforeactivate._change"", function( e ) { var elem = e.target; if ( rformElems.test( elem.nodeName ) && !jQuery._data( elem, ""changeBubbles"" ) ) { jQuery.event.add( elem, ""change._change"", function( event ) { if ( this.parentNode && !event.isSimulated && !event.isTrigger ) { jQuery.event.simulate( ""change"", this.parentNode, event, true ); } }); jQuery._data( elem, ""changeBubbles"", true ); } }); }, handle: function( event ) { var elem = event.target; // Swallow native change events from checkbox/radio, we already triggered them above if ( this !== elem || event.isSimulated || event.isTrigger || (elem.type !== ""radio"" && elem.type !== ""checkbox"") ) { return event.handleObj.handler.apply( this, arguments ); } }, teardown: function() { jQuery.event.remove( this, ""._change"" ); return !rformElems.test( this.nodeName ); } }; } if ( !jQuery.support.focusinBubbles ) { // Attach a single capturing handler while someone wants focusin/focusout var attaches = 0, handler = function( event ) { if ( attaches++ === 0 ) { document.addEventListener( orig, handler, true ); if ( --attaches === 0 ) { document.removeEventListener( orig, handler, true ); var type, origFn;var isSimple = /^.[^:#\[\.,]*$/, rparentsprev = /^(?:parents|prev(?:Until|All))/, rneedsContext = jQuery.expr.match.needsContext, // methods guaranteed to produce a unique set when starting from a unique set guaranteedUnique = { children: true, contents: true, next: true, prev: true };jQuery.fn.extend({ find: function( selector ) { var i, ret = [], self = this, len = self.length; if ( typeof selector !== ""string"" ) { return this.pushStack( jQuery( selector ).filter(function() { for ( i = 0; i < len; i++ ) { if ( jQuery.contains( self[ i ], this ) ) { return true; } } }) ); } for ( i = 0; i < len; i++ ) { jQuery.find( selector, self[ i ], ret ); } // Needed because $( selector, context ) becomes $( context ).find( selector ) ret = this.pushStack( len > 1 ? jQuery.unique( ret ) : ret ); ret.selector = this.selector ? this.selector + "" "" + selector : selector; return ret; }, has: function( target ) { var i, targets = jQuery( target, this ), len = targets.length; return this.filter(function() { for ( i = 0; i < len; i++ ) { if ( jQuery.contains( this, targets[i] ) ) { return true; } } }); }, not: function( selector ) { return this.pushStack( winnow(this, selector || [], true) ); }, filter: function( selector ) { return this.pushStack( winnow(this, selector || [], false) ); }, is: function( selector ) { return !!winnow( this, // If this is a positional/relative selector, check membership in the returned set // so $(""p:first"").is(""p:last"") won't return true for a doc with two ""p"". typeof selector === ""string"" && rneedsContext.test( selector ) ? jQuery( selector ) : selector || [], false ).length; }, closest: function( selectors, context ) { var cur, i = 0, l = this.length, ret = [], pos = rneedsContext.test( selectors ) || typeof selectors !== ""string"" ? jQuery( selectors, context || this.context ) : 0; for ( ; i < l; i++ ) { for ( cur = this[i]; cur && cur !== context; cur = cur.parentNode ) { // Always skip document fragments if ( cur.nodeType < 11 && (pos ? pos.index(cur) > -1 : // Don't pass non-elements to Sizzle cur.nodeType === 1 && jQuery.find.matchesSelector(cur, selectors)) ) { cur = ret.push( cur ); break; } } } return this.pushStack( ret.length > 1 ? jQuery.unique( ret ) : ret ); }, // Determine the position of an element within // the matched set of elements index: function( elem ) { // No argument, return index in parent if ( !elem ) { return ( this[0] && this[0].parentNode ) ? this.first().prevAll().length : -1; } // index in selector if ( typeof elem === ""string"" ) { return jQuery.inArray( this[0], jQuery( elem ) ); } // Locate the position of the desired element return jQuery.inArray( // If it receives a jQuery object, the first element is used elem.jquery ? elem[0] : elem, this ); }, add: function( selector, context ) { var set = typeof selector === ""string"" ? jQuery( selector, context ) : jQuery.makeArray( selector && selector.nodeType ? [ selector ] : selector ), all = jQuery.merge( this.get(), set ); return this.pushStack( jQuery.unique(all) ); }, addBack: function( selector ) { return this.add( selector == null ? this.prevObject : this.prevObject.filter(selector) ); } }); function sibling( cur, dir ) { do { cur = cur[ dir ]; } while ( cur && cur.nodeType !== 1 ); return cur; } jQuery.each({ parent: function( elem ) { var parent = elem.parentNode; return parent && parent.nodeType !== 11 ? parent : null; }, parents: function( elem ) { return jQuery.dir( elem, ""parentNode"" ); }, parentsUntil: function( elem, i, until ) { return jQuery.dir( elem, ""parentNode"", until ); }, next: function( elem ) { return sibling( elem, ""nextSibling"" ); }, prev: function( elem ) { return sibling( elem, ""previousSibling"" ); }, nextAll: function( elem ) { return jQuery.dir( elem, ""nextSibling"" ); }, prevAll: function( elem ) { return jQuery.dir( elem, ""previousSibling"" ); }, nextUntil: function( elem, i, until ) { return jQuery.dir( elem, ""nextSibling"", until ); }, prevUntil: function( elem, i, until ) { return jQuery.dir( elem, ""previousSibling"", until ); }, siblings: function( elem ) { return jQuery.sibling( ( elem.parentNode || {} ).firstChild, elem ); }, children: function( elem ) { return jQuery.sibling( elem.firstChild ); }, contents: function( elem ) { return jQuery.nodeName( elem, ""iframe"" ) ? elem.contentDocument || elem.contentWindow.document : jQuery.merge( [], elem.childNodes ); } }, function( name, fn ) { jQuery.fn[ name ] = function( until, selector ) { var ret = jQuery.map( this, fn, until ); if ( name.slice( -5 ) !== ""Until"" ) { selector = until; } if ( selector && typeof selector === ""string"" ) { ret = jQuery.filter( selector, ret ); } if ( this.length > 1 ) { // Remove duplicates if ( !guaranteedUnique[ name ] ) { ret = jQuery.unique( ret ); } // Reverse order for parents* and prev-derivatives if ( rparentsprev.test( name ) ) { ret = ret.reverse(); } } return this.pushStack( ret ); }; }); jQuery.extend({ filter: function( expr, elems, not ) { var elem = elems[ 0 ]; if ( not ) { expr = "":not("" + expr + "")""; } return elems.length === 1 && elem.nodeType === 1 ? jQuery.find.matchesSelector( elem, expr ) ? [ elem ] : [] : jQuery.find.matches( expr, jQuery.grep( elems, function( elem ) { return elem.nodeType === 1; })); }, dir: function( elem, dir, until ) { var matched = [], cur = elem[ dir ]; while ( cur && cur.nodeType !== 9 && (until === undefined || cur.nodeType !== 1 || !jQuery( cur ).is( until )) ) { if ( cur.nodeType === 1 ) { matched.push( cur ); } cur = cur[dir]; } return matched; }, sibling: function( n, elem ) { var r = []; for ( ; n; n = n.nextSibling ) { if ( n.nodeType === 1 && n !== elem ) { r.push( n ); } } return r; } }); // Implement the identical functionality for filter and not function winnow( elements, qualifier, not ) { if ( jQuery.isFunction( qualifier ) ) { return jQuery.grep( elements, function( elem, i ) { /* jshint -W018 */ return !!qualifier.call( elem, i, elem ) !== not; }); } if ( qualifier.nodeType ) { return jQuery.grep( elements, function( elem ) { return ( elem === qualifier ) !== not; }); } if ( typeof qualifier === ""string"" ) { if ( isSimple.test( qualifier ) ) { return jQuery.filter( qualifier, elements, not ); } qualifier = jQuery.filter( qualifier, elements ); } return jQuery.grep( elements, function( elem ) { return ( jQuery.inArray( elem, qualifier ) >= 0 ) !== not; }); } function createSafeFragment( document ) { var list = nodeNames.split( ""|"" ), safeFrag = document.createDocumentFragment(); if ( safeFrag.createElement ) { while ( list.length ) { safeFrag.createElement( list.pop() ); } } return safeFrag; } var nodeNames = ""abbr|article|aside|audio|bdi|canvas|data|datalist|details|figcaption|figure|footer|"" + ""header|hgroup|mark|meter|nav|output|progress|section|summary|time|video"", rinlinejQuery = / jQuery\d+=""(?:null|\d+)""/g, rnoshimcache = new RegExp(""<(?:"" + nodeNames + "")[\\s/>]"", ""i""), rleadingWhitespace = /^\s+/, rtbody = /<tbody/i, manipulation_rcheckableType = /^(?:checkbox|radio)$/i, legend: [ 1, ""<fieldset>"", ""</fieldset>"" ], area: [ 1, ""<map>"", ""</map>"" ], param: [ 1, ""<object>"", ""</object>"" ], col: [ 2, ""<table><tbody></tbody><colgroup>"", ""</colgroup></table>"" ], // IE6-8 can't serialize link, script, style, or any html5 (NoScope) tags, // unless wrapped in a div with non-breaking characters in front of it. _default: jQuery.support.htmlSerialize ? [ 0, """", """" ] : [ 1, ""X<div>"", ""</div>"" ] }, safeFragment = createSafeFragment( document ), fragmentDiv = safeFragment.appendChild( document.createElement(""div"") ); return jQuery.access( this, function( value ) { this.empty().append( ( this[0] && this[0].ownerDocument || document ).createTextNode( value ) ); // keepData is for internal use only--do not document remove: function( selector, keepData ) { // Remove element nodes and prevent memory leaks } // Remove any remaining nodes while ( elem.firstChild ) { elem.removeChild( elem.firstChild ); } // If this is a select, ensure that it displays empty (#12336) // Support: IE<9 if ( elem.options && jQuery.nodeName( elem, ""select"" ) ) { elem.options.length = 0; return this.map( function () { return jQuery.access( this, function( value ) { var elem = this[0] || {}, if ( value === undefined ) { return elem.nodeType === 1 ? elem.innerHTML.replace( rinlinejQuery, """" ) : undefined; ( jQuery.support.htmlSerialize || !rnoshimcache.test( value ) ) && ( jQuery.support.leadingWhitespace || !rleadingWhitespace.test( value ) ) && !wrapMap[ ( rtagName.exec( value ) || ["""", """"] )[1].toLowerCase() ] ) { for (; i < l; i++ ) { elem = this[i] || {}; } catch(e) {} var // Snapshot the DOM in case .domManip sweeps something relevant into its fragment args = jQuery.map( this, function( elem ) { return [ elem.nextSibling, elem.parentNode ]; }), i = 0; var next = args[ i++ ], parent = args[ i++ ]; if ( parent ) { // Don't use the snapshot next if it has moved (#13810) if ( next && next.parentNode !== parent ) { next = this.nextSibling; } jQuery( this ).remove(); parent.insertBefore( elem, next ); // Allow new content to include elements from the context set }, true ); return i ? this : this.remove(); domManip: function( args, callback, allowIntersection ) { args = core_concat.apply( [], args ); var first, node, hasScripts, scripts, doc, fragment, value = args[0], if ( isFunction || !( l <= 1 || typeof value !== ""string"" || jQuery.support.checkClone || !rchecked.test( value ) ) ) { args[0] = value.call( this, index, self.html() ); self.domManip( args, callback, allowIntersection ); fragment = jQuery.buildFragment( args, this[ 0 ].ownerDocument, false, !allowIntersection && this ); callback.call( this[i], node, i ); !jQuery._data( node, ""globalEval"" ) && jQuery.contains( doc, node ) ) { // Hope ajax is available... jQuery._evalUrl( node.src ); jQuery.globalEval( ( node.text || node.textContent || node.innerHTML || """" ).replace( rcleanScript, """" ) ); // Fix #11809: Avoid leaking memory fragment = first = null;// Support: IE<8 // Manipulating tables requires a tbody function manipulationTarget( elem, content ) { return jQuery.nodeName( elem, ""table"" ) && jQuery.nodeName( content.nodeType === 1 ? content : content.firstChild, ""tr"" ) ? elem.getElementsByTagName(""tbody"")[0] || elem.appendChild( elem.ownerDocument.createElement(""tbody"") ) : elem; } // Replace/restore the type attribute of script elements for safe DOM manipulation function disableScript( elem ) { elem.type = (jQuery.find.attr( elem, ""type"" ) !== null) + ""/"" + elem.type; return elem; } function restoreScript( elem ) { var match = rscriptTypeMasked.exec( elem.type ); if ( match ) { elem.type = match[1]; } else { elem.removeAttribute(""type""); } return elem; } // Mark scripts as having already been evaluated function setGlobalEval( elems, refElements ) { var elem, i = 0; for ( ; (elem = elems[i]) != null; i++ ) { jQuery._data( elem, ""globalEval"", !refElements || jQuery._data( refElements[i], ""globalEval"" ) ); } } function cloneCopyEvent( src, dest ) { if ( dest.nodeType !== 1 || !jQuery.hasData( src ) ) { return; } var type, i, l, oldData = jQuery._data( src ), curData = jQuery._data( dest, oldData ), events = oldData.events; if ( events ) { delete curData.handle; curData.events = {}; for ( type in events ) { for ( i = 0, l = events[ type ].length; i < l; i++ ) { jQuery.event.add( dest, type, events[ type ][ i ] ); } } } // make the cloned public data object a copy from the original if ( curData.data ) { curData.data = jQuery.extend( {}, curData.data ); } } function fixCloneNodeIssues( src, dest ) { var nodeName, e, data; // We do not need to do anything for non-Elements if ( dest.nodeType !== 1 ) { return; } nodeName = dest.nodeName.toLowerCase(); // IE6-8 copies events bound via attachEvent when using cloneNode. if ( !jQuery.support.noCloneEvent && dest[ jQuery.expando ] ) { data = jQuery._data( dest ); for ( e in data.events ) { jQuery.removeEvent( dest, e, data.handle ); } // Event data gets referenced instead of copied if the expando gets copied too dest.removeAttribute( jQuery.expando ); } // IE blanks contents when cloning scripts, and tries to evaluate newly-set text if ( nodeName === ""script"" && dest.text !== src.text ) { disableScript( dest ).text = src.text; restoreScript( dest ); // IE6-10 improperly clones children of object elements using classid. // IE10 throws NoModificationAllowedError if parent is null, #12132. } else if ( nodeName === ""object"" ) { if ( dest.parentNode ) { dest.outerHTML = src.outerHTML; } // This path appears unavoidable for IE9. When cloning an object // element in IE9, the outerHTML strategy above is not sufficient. // If the src has innerHTML and the destination does not, // copy the src.innerHTML into the dest.innerHTML. #10324 if ( jQuery.support.html5Clone && ( src.innerHTML && !jQuery.trim(dest.innerHTML) ) ) { dest.innerHTML = src.innerHTML; } } else if ( nodeName === ""input"" && manipulation_rcheckableType.test( src.type ) ) { // IE6-8 fails to persist the checked state of a cloned checkbox // or radio button. Worse, IE6-7 fail to give the cloned element // a checked appearance if the defaultChecked value isn't also set dest.defaultChecked = dest.checked = src.checked; // IE6-7 get confused and end up setting the value of a cloned // checkbox/radio button to an empty string instead of ""on"" if ( dest.value !== src.value ) { dest.value = src.value; } // IE6-8 fails to return the selected option to the default selected // state when cloning options } else if ( nodeName === ""option"" ) { dest.defaultSelected = dest.selected = src.defaultSelected; // IE6-8 fails to set the defaultValue to the correct value when // cloning other types of input fields } else if ( nodeName === ""input"" || nodeName === ""textarea"" ) { dest.defaultValue = src.defaultValue; } } i = 0, last = insert.length - 1; elems = i === last ? this : this.clone(true); jQuery( insert[i] )[ original ]( elems ); // Modern browsers can apply jQuery collections as arrays, but oldIE needs a .get() core_push.apply( ret, elems.get() );function getAll( context, tag ) { var elems, elem, i = 0, found = typeof context.getElementsByTagName !== core_strundefined ? context.getElementsByTagName( tag || ""*"" ) : typeof context.querySelectorAll !== core_strundefined ? context.querySelectorAll( tag || ""*"" ) : undefined; if ( !found ) { for ( found = [], elems = context.childNodes || context; (elem = elems[i]) != null; i++ ) { if ( !tag || jQuery.nodeName( elem, tag ) ) { found.push( elem ); } else { jQuery.merge( found, getAll( elem, tag ) ); } } } return tag === undefined || tag && jQuery.nodeName( context, tag ) ? jQuery.merge( [ context ], found ) : found;// Used in buildFragment, fixes the defaultChecked property function fixDefaultChecked( elem ) { if ( manipulation_rcheckableType.test( elem.type ) ) { elem.defaultChecked = elem.checked;jQuery.extend({ clone: function( elem, dataAndEvents, deepDataAndEvents ) { var destElements, node, clone, i, srcElements, inPage = jQuery.contains( elem.ownerDocument, elem ); if ( jQuery.support.html5Clone || jQuery.isXMLDoc(elem) || !rnoshimcache.test( ""<"" + elem.nodeName + "">"" ) ) { clone = elem.cloneNode( true ); // IE<=8 does not properly clone detached, unknown element nodes } else { fragmentDiv.innerHTML = elem.outerHTML; fragmentDiv.removeChild( clone = fragmentDiv.firstChild ); if ( (!jQuery.support.noCloneEvent || !jQuery.support.noCloneChecked) && (elem.nodeType === 1 || elem.nodeType === 11) && !jQuery.isXMLDoc(elem) ) { // We eschew Sizzle here for performance reasons: http://jsperf.com/getall-vs-sizzle/2 destElements = getAll( clone ); srcElements = getAll( elem ); // Fix all IE cloning issues for ( i = 0; (node = srcElements[i]) != null; ++i ) { // Ensure that the destination node is not null; Fixes #9587 if ( destElements[i] ) { fixCloneNodeIssues( node, destElements[i] ); } // Copy the events from the original to the clone if ( dataAndEvents ) { if ( deepDataAndEvents ) { srcElements = srcElements || getAll( elem ); destElements = destElements || getAll( clone ); for ( i = 0; (node = srcElements[i]) != null; i++ ) { cloneCopyEvent( node, destElements[i] ); } } else { cloneCopyEvent( elem, clone ); } } // Preserve script evaluation history destElements = getAll( clone, ""script"" ); if ( destElements.length > 0 ) { setGlobalEval( destElements, !inPage && getAll( elem, ""script"" ) ); } destElements = srcElements = node = null; // Return the cloned set return clone; }, buildFragment: function( elems, context, scripts, selection ) { var j, elem, contains, tmp, tag, tbody, wrap, l = elems.length, // Ensure a safe fragment safe = createSafeFragment( context ), nodes = [], i = 0; for ( ; i < l; i++ ) { elem = elems[ i ]; if ( elem || elem === 0 ) { // Add nodes directly if ( jQuery.type( elem ) === ""object"" ) { jQuery.merge( nodes, elem.nodeType ? [ elem ] : elem ); // Convert non-html into a text node } else if ( !rhtml.test( elem ) ) { nodes.push( context.createTextNode( elem ) ); // Convert html into DOM nodes } else { tmp = tmp || safe.appendChild( context.createElement(""div"") ); // Deserialize a standard representation tag = ( rtagName.exec( elem ) || ["""", """"] )[1].toLowerCase(); wrap = wrapMap[ tag ] || wrapMap._default; tmp.innerHTML = wrap[1] + elem.replace( rxhtmlTag, ""<$1></$2>"" ) + wrap[2]; // Descend through wrappers to the right content j = wrap[0]; while ( j-- ) { tmp = tmp.lastChild; } // Manually add leading whitespace removed by IE if ( !jQuery.support.leadingWhitespace && rleadingWhitespace.test( elem ) ) { nodes.push( context.createTextNode( rleadingWhitespace.exec( elem )[0] ) ); } // Remove IE's autoinserted <tbody> from table fragments if ( !jQuery.support.tbody ) { // String was a <table>, *may* have spurious <tbody> elem = tag === ""table"" && !rtbody.test( elem ) ? tmp.firstChild : // String was a bare <thead> or <tfoot> wrap[1] === ""<table>"" && !rtbody.test( elem ) ? tmp : 0; j = elem && elem.childNodes.length; while ( j-- ) { if ( jQuery.nodeName( (tbody = elem.childNodes[j]), ""tbody"" ) && !tbody.childNodes.length ) { elem.removeChild( tbody ); } } } jQuery.merge( nodes, tmp.childNodes ); // Fix #12392 for WebKit and IE > 9 tmp.textContent = """"; // Fix #12392 for oldIE while ( tmp.firstChild ) { tmp.removeChild( tmp.firstChild ); } // Remember the top-level container for proper cleanup tmp = safe.lastChild; } } } // Fix #11356: Clear elements from fragment if ( tmp ) { safe.removeChild( tmp ); } // Reset defaultChecked for any radios and checkboxes // about to be appended to the DOM in IE 6/7 (#8060) if ( !jQuery.support.appendChecked ) { jQuery.grep( getAll( nodes, ""input"" ), fixDefaultChecked ); } i = 0; while ( (elem = nodes[ i++ ]) ) { // #4087 - If origin and destination elements are the same, and this is // that element, do not do anything if ( selection && jQuery.inArray( elem, selection ) !== -1 ) { continue; } contains = jQuery.contains( elem.ownerDocument, elem ); // Append to fragment tmp = getAll( safe.appendChild( elem ), ""script"" ); // Preserve script evaluation history if ( contains ) { setGlobalEval( tmp ); } // Capture executables if ( scripts ) { j = 0; while ( (elem = tmp[ j++ ]) ) { if ( rscriptType.test( elem.type || """" ) ) { scripts.push( elem ); } } } } tmp = null; return safe; }, cleanData: function( elems, /* internal */ acceptData ) { var elem, type, id, data, i = 0, internalKey = jQuery.expando, cache = jQuery.cache, deleteExpando = jQuery.support.deleteExpando, special = jQuery.event.special; for ( ; (elem = elems[i]) != null; i++ ) { if ( acceptData || jQuery.acceptData( elem ) ) { id = elem[ internalKey ]; data = id && cache[ id ]; if ( data ) { if ( data.events ) { for ( type in data.events ) { if ( special[ type ] ) { jQuery.event.remove( elem, type ); // This is a shortcut to avoid jQuery.event.remove's overhead } else { jQuery.removeEvent( elem, type, data.handle ); } } } // Remove cache only if it was not already removed by jQuery.event.remove if ( cache[ id ] ) { delete cache[ id ]; // IE does not allow us to delete expando properties from nodes, // nor does it have a removeAttribute function on Document nodes; // we must handle all of these cases if ( deleteExpando ) { delete elem[ internalKey ]; } else if ( typeof elem.removeAttribute !== core_strundefined ) { elem.removeAttribute( internalKey ); } else { elem[ internalKey ] = null; } core_deletedIds.push( id ); } } } } }, _evalUrl: function( url ) { return jQuery.ajax({ url: url, type: ""GET"", dataType: ""script"", async: false, global: false, ""throws"": true}); jQuery.fn.extend({ wrapAll: function( html ) { if ( jQuery.isFunction( html ) ) { return this.each(function(i) { jQuery(this).wrapAll( html.call(this, i) ); }); } if ( this[0] ) { // The elements to wrap the target around var wrap = jQuery( html, this[0].ownerDocument ).eq(0).clone(true); if ( this[0].parentNode ) { wrap.insertBefore( this[0] ); } wrap.map(function() { var elem = this; while ( elem.firstChild && elem.firstChild.nodeType === 1 ) { elem = elem.firstChild; } return elem; }).append( this ); } return this; }, wrapInner: function( html ) { if ( jQuery.isFunction( html ) ) { return this.each(function(i) { jQuery(this).wrapInner( html.call(this, i) ); }); } return this.each(function() { var self = jQuery( this ), contents = self.contents(); if ( contents.length ) { contents.wrapAll( html ); } else { self.append( html ); } }); }, wrap: function( html ) { var isFunction = jQuery.isFunction( html ); return this.each(function(i) { jQuery( this ).wrapAll( isFunction ? html.call(this, i) : html ); }); }, unwrap: function() { return this.parent().each(function() { if ( !jQuery.nodeName( this, ""body"" ) ) { jQuery( this ).replaceWith( this.childNodes ); } }).end();}); var iframe, getStyles, curCSS, ralpha = /alpha\([^)]*\)/i, ropacity = /opacity\s*=\s*([^)]*)/, rposition = /^(top|right|bottom|left)$/, rmargin = /^margin/, rnumsplit = new RegExp( ""^("" + core_pnum + "")(.*)$"", ""i"" ), rnumnonpx = new RegExp( ""^("" + core_pnum + "")(?!px)[a-z%]+$"", ""i"" ), rrelNum = new RegExp( ""^([+-])=("" + core_pnum + "")"", ""i"" ), elemdisplay = { BODY: ""block"" }, letterSpacing: 0, fontWeight: 400 cssExpand = [ ""Top"", ""Right"", ""Bottom"", ""Left"" ], var capName = name.charAt(0).toUpperCase() + name.slice(1),function isHidden( elem, el ) { // isHidden might be called from jQuery#filter function; // in that case, element will be second argument elem = el || elem; return jQuery.css( elem, ""display"" ) === ""none"" || !jQuery.contains( elem.ownerDocument, elem ); } function showHide( elements, show ) { var display, elem, hidden, values = [], index = 0, length = elements.length; for ( ; index < length; index++ ) { elem = elements[ index ]; if ( !elem.style ) { continue; } values[ index ] = jQuery._data( elem, ""olddisplay"" ); display = elem.style.display; if ( show ) { // Reset the inline display of this element to learn if it is // being hidden by cascaded rules or not if ( !values[ index ] && display === ""none"" ) { elem.style.display = """"; } // Set elements which have been overridden with display: none // in a stylesheet to whatever the default browser style is // for such an element if ( elem.style.display === """" && isHidden( elem ) ) { values[ index ] = jQuery._data( elem, ""olddisplay"", css_defaultDisplay(elem.nodeName) ); } } else { if ( !values[ index ] ) { hidden = isHidden( elem ); if ( display && display !== ""none"" || !hidden ) { jQuery._data( elem, ""olddisplay"", hidden ? display : jQuery.css( elem, ""display"" ) ); } } } } // Set the display of most of the elements in a second loop // to avoid the constant reflow for ( index = 0; index < length; index++ ) { elem = elements[ index ]; if ( !elem.style ) { continue; } if ( !show || elem.style.display === ""none"" || elem.style.display === """" ) { elem.style.display = show ? values[ index ] || """" : ""none""; } } return elements; } jQuery.fn.extend({ css: function( name, value ) { return jQuery.access( this, function( elem, name, value ) { var len, styles, map = {}, i = 0; if ( jQuery.isArray( name ) ) { styles = getStyles( elem ); len = name.length; for ( ; i < len; i++ ) { map[ name[ i ] ] = jQuery.css( elem, name[ i ], false, styles ); } return map; } return value !== undefined ? jQuery.style( elem, name, value ) : jQuery.css( elem, name ); }, name, value, arguments.length > 1 ); }, show: function() { return showHide( this, true ); }, hide: function() { return showHide( this ); }, toggle: function( state ) { if ( typeof state === ""boolean"" ) { return state ? this.show() : this.hide(); } return this.each(function() { if ( isHidden( this ) ) { jQuery( this ).show(); } else { jQuery( this ).hide(); } }); } }); jQuery.extend({ // Add in style property hooks for overriding the default // behavior of getting and setting a style property cssHooks: { opacity: { get: function( elem, computed ) { if ( computed ) { // We should always get a number back from opacity var ret = curCSS( elem, ""opacity"" ); return ret === """" ? ""1"" : ret; } } } }, // Don't automatically add ""px"" to these possibly-unitless properties cssNumber: { ""columnCount"": true, ""fillOpacity"": true, ""fontWeight"": true, ""lineHeight"": true, ""opacity"": true, ""order"": true, ""orphans"": true, ""widows"": true, ""zIndex"": true, ""zoom"": true }, // Add in properties whose names you wish to fix before // setting or getting the value cssProps: { // normalize float css property ""float"": jQuery.support.cssFloat ? ""cssFloat"" : ""styleFloat"" }, // Get and set the style property on a DOM Node style: function( elem, name, value, extra ) { // Don't set styles on text and comment nodes if ( !elem || elem.nodeType === 3 || elem.nodeType === 8 || !elem.style ) { return; } // Make sure that we're working with the right name var ret, type, hooks, origName = jQuery.camelCase( name ), style = elem.style; name = jQuery.cssProps[ origName ] || ( jQuery.cssProps[ origName ] = vendorPropName( style, origName ) ); // gets hook for the prefixed version // followed by the unprefixed version hooks = jQuery.cssHooks[ name ] || jQuery.cssHooks[ origName ]; // Check if we're setting a value if ( value !== undefined ) { type = typeof value; // convert relative number strings (+= or -=) to relative numbers. #7345 if ( type === ""string"" && (ret = rrelNum.exec( value )) ) { value = ( ret[1] + 1 ) * ret[2] + parseFloat( jQuery.css( elem, name ) ); // Fixes bug #9237 type = ""number""; } // Make sure that NaN and null values aren't set. See: #7116 if ( value == null || type === ""number"" && isNaN( value ) ) { return; } // If a number was passed in, add 'px' to the (except for certain CSS properties) if ( type === ""number"" && !jQuery.cssNumber[ origName ] ) { value += ""px""; } // Fixes #8908, it can be done more correctly by specifing setters in cssHooks, // but it would mean to define eight (for every problematic property) identical functions if ( !jQuery.support.clearCloneStyle && value === """" && name.indexOf(""background"") === 0 ) { style[ name ] = ""inherit""; } // If a hook was provided, use that value, otherwise just set the specified value if ( !hooks || !(""set"" in hooks) || (value = hooks.set( elem, value, extra )) !== undefined ) { // Wrapped to prevent IE from throwing errors when 'invalid' values are provided // Fixes bug #5509 try { style[ name ] = value; } catch(e) {} } } else { // If a hook was provided get the non-computed value from there if ( hooks && ""get"" in hooks && (ret = hooks.get( elem, false, extra )) !== undefined ) { return ret; } // Otherwise just get the value from the style object return style[ name ]; } }, css: function( elem, name, extra, styles ) { var num, val, hooks, origName = jQuery.camelCase( name ); // Make sure that we're working with the right name name = jQuery.cssProps[ origName ] || ( jQuery.cssProps[ origName ] = vendorPropName( elem.style, origName ) ); // gets hook for the prefixed version // followed by the unprefixed version hooks = jQuery.cssHooks[ name ] || jQuery.cssHooks[ origName ]; // If a hook was provided get the computed value from there if ( hooks && ""get"" in hooks ) { val = hooks.get( elem, true, extra ); } // Otherwise, if a way to get the computed value exists, use that if ( val === undefined ) { val = curCSS( elem, name, styles ); } //convert ""normal"" to computed value if ( val === ""normal"" && name in cssNormalTransform ) { val = cssNormalTransform[ name ]; } // Return, converting to number if forced or a qualifier was provided and val looks numeric if ( extra === """" || extra ) { num = parseFloat( val ); return extra === true || jQuery.isNumeric( num ) ? num || 0 : val; } return val; } }); // NOTE: we've included the ""window"" in window.getComputedStyle // because jsdom on node.js will break without it. if ( window.getComputedStyle ) { getStyles = function( elem ) { return window.getComputedStyle( elem, null ); }; curCSS = function( elem, name, _computed ) { var width, minWidth, maxWidth, computed = _computed || getStyles( elem ), // getPropertyValue is only needed for .css('filter') in IE9, see #12537 ret = computed ? computed.getPropertyValue( name ) || computed[ name ] : undefined, style = elem.style; if ( computed ) { if ( ret === """" && !jQuery.contains( elem.ownerDocument, elem ) ) { ret = jQuery.style( elem, name ); } // A tribute to the ""awesome hack by Dean Edwards"" // Chrome < 17 and Safari 5.0 uses ""computed value"" instead of ""used value"" for margin-right // Safari 5.1.7 (at least) returns percentage for a larger set of values, but width seems to be reliably pixels // this is against the CSSOM draft spec: http://dev.w3.org/csswg/cssom/#resolved-values if ( rnumnonpx.test( ret ) && rmargin.test( name ) ) { // Remember the original values width = style.width; minWidth = style.minWidth; maxWidth = style.maxWidth; // Put in the new values to get a computed value out style.minWidth = style.maxWidth = style.width = ret; ret = computed.width; // Revert the changed values style.width = width; style.minWidth = minWidth; style.maxWidth = maxWidth; } } return ret; }; } else if ( document.documentElement.currentStyle ) { getStyles = function( elem ) { return elem.currentStyle; }; curCSS = function( elem, name, _computed ) { var left, rs, rsLeft, computed = _computed || getStyles( elem ), ret = computed ? computed[ name ] : undefined, style = elem.style; // Avoid setting ret to empty string here // so we don't default to auto if ( ret == null && style && style[ name ] ) { ret = style[ name ]; } // From the awesome hack by Dean Edwards // http://erik.eae.net/archives/2007/07/27/18.54.15/#comment-102291 // If we're not dealing with a regular pixel number // but a number that has a weird ending, we need to convert it to pixels // but not position css attributes, as those are proportional to the parent element instead // and we can't measure the parent instead because it might trigger a ""stacking dolls"" problem if ( rnumnonpx.test( ret ) && !rposition.test( name ) ) { // Remember the original values left = style.left; rs = elem.runtimeStyle; rsLeft = rs && rs.left; // Put in the new values to get a computed value out if ( rsLeft ) { rs.left = elem.currentStyle.left; } style.left = name === ""fontSize"" ? ""1em"" : ret; ret = style.pixelLeft + ""px""; // Revert the changed values style.left = left; if ( rsLeft ) { rs.left = rsLeft; } } return ret === """" ? ""auto"" : ret; }; } isBorderBox = jQuery.support.boxSizing && jQuery.css( elem, ""boxSizing"", false, styles ) === ""border-box""; valueIsBorderBox = isBorderBox && ( jQuery.support.boxSizingReliable || val === elem.style[ name ] );// Try to determine the default display value of an element function css_defaultDisplay( nodeName ) { var doc = document, display = elemdisplay[ nodeName ]; if ( !display ) { display = actualDisplay( nodeName, doc ); // If the simple way fails, read from inside an iframe if ( display === ""none"" || !display ) { // Use the already-created iframe if possible iframe = ( iframe || jQuery(""<iframe frameborder='0' width='0' height='0'/>"") .css( ""cssText"", ""display:block !important"" ) ).appendTo( doc.documentElement ); // Always write a new HTML skeleton so Webkit and Firefox don't choke on reuse doc = ( iframe[0].contentWindow || iframe[0].contentDocument ).document; doc.write(""<!doctype html><html><body>""); doc.close(); display = actualDisplay( nodeName, doc ); iframe.detach(); // Store the correct default display elemdisplay[ nodeName ] = display; return display;// Called ONLY from within css_defaultDisplay function actualDisplay( name, doc ) { var elem = jQuery( doc.createElement( name ) ).appendTo( doc.body ), display = jQuery.css( elem[0], ""display"" ); elem.remove(); return display; } return elem.offsetWidth === 0 && rdisplayswap.test( jQuery.css( elem, ""display"" ) ) ? jQuery.support.boxSizing && jQuery.css( elem, ""boxSizing"", false, styles ) === ""border-box"",if ( !jQuery.support.opacity ) { jQuery.cssHooks.opacity = { get: function( elem, computed ) { // IE uses filters for opacity return ropacity.test( (computed && elem.currentStyle ? elem.currentStyle.filter : elem.style.filter) || """" ) ? ( 0.01 * parseFloat( RegExp.$1 ) ) + """" : computed ? ""1"" : """"; }, set: function( elem, value ) { var style = elem.style, currentStyle = elem.currentStyle, opacity = jQuery.isNumeric( value ) ? ""alpha(opacity="" + value * 100 + "")"" : """", filter = currentStyle && currentStyle.filter || style.filter || """"; // IE has trouble with opacity if it does not have layout // Force it by setting the zoom level style.zoom = 1; // if setting opacity to 1, and no other filters exist - attempt to remove filter attribute #6652 // if value === """", then remove inline opacity #12685 if ( ( value >= 1 || value === """" ) && jQuery.trim( filter.replace( ralpha, """" ) ) === """" && style.removeAttribute ) { // Setting style.filter to null, """" & "" "" still leave ""filter:"" in the cssText // if ""filter:"" is present at all, clearType is disabled, we want to avoid this // style.removeAttribute is IE Only, but so apparently is this code path... style.removeAttribute( ""filter"" ); // if there is no filter style applied in a css rule or unset inline opacity, we are done if ( value === """" || currentStyle && !currentStyle.filter ) { return; } } // otherwise, set new filter values style.filter = ralpha.test( filter ) ? filter.replace( ralpha, opacity ) : filter + "" "" + opacity; }; } // These hooks cannot be added until DOM ready because the support test // for it is not run until after DOM ready jQuery(function() { if ( !jQuery.support.reliableMarginRight ) { jQuery.cssHooks.marginRight = { get: function( elem, computed ) { if ( computed ) { // WebKit Bug 13343 - getComputedStyle returns wrong value for margin-right // Work around by temporarily setting element display to inline-block return jQuery.swap( elem, { ""display"": ""inline-block"" }, curCSS, [ elem, ""marginRight"" ] ); } } }; // Webkit bug: https://bugs.webkit.org/show_bug.cgi?id=29084 // getComputedStyle returns percent when specified for top/left/bottom/right // rather than make the css module depend on the offset module, we just check for it here if ( !jQuery.support.pixelPosition && jQuery.fn.position ) { jQuery.each( [ ""top"", ""left"" ], function( i, prop ) { jQuery.cssHooks[ prop ] = { get: function( elem, computed ) { if ( computed ) { computed = curCSS( elem, prop ); // if curCSS returns percentage, fallback to offset return rnumnonpx.test( computed ) ? jQuery( elem ).position()[ prop ] + ""px"" : computed; } } }; }); } }); if ( jQuery.expr && jQuery.expr.filters ) { jQuery.expr.filters.hidden = function( elem ) { // Support: Opera <= 12.12 // Opera reports offsetWidths and offsetHeights less than zero on some elements return elem.offsetWidth <= 0 && elem.offsetHeight <= 0 || (!jQuery.support.reliableHiddenOffsets && ((elem.style && elem.style.display) || jQuery.css( elem, ""display"" )) === ""none""); }; jQuery.expr.filters.visible = function( elem ) { return !jQuery.expr.filters.hidden( elem ); }; }var r20 = /%20/g, rbracket = /\[\]$/, rCRLF = /\r?\n/g, rsubmitterTypes = /^(?:submit|button|image|reset|file)$/i, rsubmittable = /^(?:input|select|textarea|keygen)/i; serialize: function() { return jQuery.param( this.serializeArray() ); }, serializeArray: function() { return this.map(function(){ // Can add propHook for ""elements"" to filter or add form elements var elements = jQuery.prop( this, ""elements"" ); return elements ? jQuery.makeArray( elements ) : this; }) .filter(function(){ var type = this.type; // Use .is("":disabled"") so that fieldset[disabled] works return this.name && !jQuery( this ).is( "":disabled"" ) && rsubmittable.test( this.nodeName ) && !rsubmitterTypes.test( type ) && ( this.checked || !manipulation_rcheckableType.test( type ) ); }) .map(function( i, elem ){ var val = jQuery( this ).val(); return val == null ? null : jQuery.isArray( val ) ? jQuery.map( val, function( val ){ return { name: elem.name, value: val.replace( rCRLF, ""\r\n"" ) }; }) : { name: elem.name, value: val.replace( rCRLF, ""\r\n"" ) }; }).get();//Serialize an array of form elements or a set of //key/values into a query string jQuery.param = function( a, traditional ) { var prefix, s = [], add = function( key, value ) { // If value is a function, invoke it and return its value value = jQuery.isFunction( value ) ? value() : ( value == null ? """" : value ); s[ s.length ] = encodeURIComponent( key ) + ""="" + encodeURIComponent( value ); }; // Set traditional to true for jQuery <= 1.3.2 behavior. if ( traditional === undefined ) { traditional = jQuery.ajaxSettings && jQuery.ajaxSettings.traditional; } // If an array was passed in, assume that it is an array of form elements. if ( jQuery.isArray( a ) || ( a.jquery && !jQuery.isPlainObject( a ) ) ) { // Serialize the form elements jQuery.each( a, function() { add( this.name, this.value ); }); } else { // If traditional, encode the ""old"" way (the way 1.3.2 or older // did it), otherwise encode params recursively. for ( prefix in a ) { buildParams( prefix, a[ prefix ], traditional, add ); } // Return the resulting serialization return s.join( ""&"" ).replace( r20, ""+"" );function buildParams( prefix, obj, traditional, add ) { var name; if ( jQuery.isArray( obj ) ) { // Serialize array item. jQuery.each( obj, function( i, v ) { if ( traditional || rbracket.test( prefix ) ) { // Treat each array item as a scalar. add( prefix, v ); } else { // Item is non-scalar (array or object), encode its numeric index. buildParams( prefix + ""["" + ( typeof v === ""object"" ? i : """" ) + ""]"", v, traditional, add ); }); } else if ( !traditional && jQuery.type( obj ) === ""object"" ) { // Serialize object item. for ( name in obj ) { buildParams( prefix + ""["" + name + ""]"", obj[ name ], traditional, add ); } else { // Serialize scalar item. add( prefix, obj ); ajax_nonce = jQuery.now(), ajax_rquery = /\?/, rheaders = /^(.*?):[ \t]*([^\r\n]*)\r?$/mg, // IE leaves an \r character at EOL rurl = /^([\w.+-]+:)(?:\/\/([^\/?#:]*)(?::(\d+)|)|)/, // Keep a copy of the old load method _load = jQuery.fn.load, dataTypes = dataTypeExpression.toLowerCase().match( core_rnotwhite ) || []; if( typeof dataTypeOrTransport === ""string"" && !seekingTransport && !inspected[ dataTypeOrTransport ] ) { var deep, key,jQuery.fn.load = function( url, params, callback ) { if ( typeof url !== ""string"" && _load ) { return _load.apply( this, arguments ); var selector, response, type, self = this, off = url.indexOf("" ""); if ( off >= 0 ) { selector = url.slice( off, url.length ); url = url.slice( 0, off ); // If it's a function if ( jQuery.isFunction( params ) ) { // We assume that it's the callback callback = params; params = undefined; // Otherwise, build a param string } else if ( params && typeof params === ""object"" ) { type = ""POST""; // If we have elements to modify, make the request if ( self.length > 0 ) { jQuery.ajax({ url: url, // if ""type"" variable is undefined, then ""GET"" method will be used type: type, dataType: ""html"", data: params }).done(function( responseText ) { // Save response for use in complete callback response = arguments; self.html( selector ? // If a selector was specified, locate the right elements in a dummy div // Exclude scripts to avoid IE 'Permission Denied' errors jQuery(""<div>"").append( jQuery.parseHTML( responseText ) ).find( selector ) : // Otherwise use the full result responseText ); }).complete( callback && function( jqXHR, status ) { self.each( callback, response || [ jqXHR.responseText, status, jqXHR ] ); }); return this; };// Attach a bunch of functions for handling common AJAX events jQuery.each( [ ""ajaxStart"", ""ajaxStop"", ""ajaxComplete"", ""ajaxError"", ""ajaxSuccess"", ""ajaxSend"" ], function( i, type ){ jQuery.fn[ type ] = function( fn ){ return this.on( type, fn ); }; }); var // Cross-domain detection vars parts, // Loop variable i, // Response headers as string transport, // Response headers responseHeaders, // Add protocol if not provided (#5866: IE7 issue with protocol-less urls) s.url = ( ( url || s.url || ajaxLocation ) + """" ).replace( rhash, """" ).replace( rprotocol, ajaxLocParts[ 1 ] + ""//"" ); s.dataTypes = jQuery.trim( s.dataType || ""*"" ).toLowerCase().match( core_rnotwhite ) || [""""]; cacheURL = ( s.url += ( ajax_rquery.test( cacheURL ) ? ""&"" : ""?"" ) + s.data ); cacheURL.replace( rts, ""$1_="" + ajax_nonce++ ) : cacheURL + ( ajax_rquery.test( cacheURL ) ? ""&"" : ""?"" ) + ""_="" + ajax_nonce++;/* Handles responses to an ajax request: * - finds the right dataType (mediates between content-type and expected dataType) * - returns the corresponding response */ function ajaxHandleResponses( s, jqXHR, responses ) { var firstDataType, ct, finalDataType, type, contents = s.contents, dataTypes = s.dataTypes; // Remove auto dataType and get content-type in the process while( dataTypes[ 0 ] === ""*"" ) { dataTypes.shift(); if ( ct === undefined ) { ct = s.mimeType || jqXHR.getResponseHeader(""Content-Type""); } // Check if we're dealing with a known content-type if ( ct ) { for ( type in contents ) { if ( contents[ type ] && contents[ type ].test( ct ) ) { dataTypes.unshift( type ); break; } } // Check to see if we have a response for the expected dataType if ( dataTypes[ 0 ] in responses ) { finalDataType = dataTypes[ 0 ]; // Try convertible dataTypes for ( type in responses ) { if ( !dataTypes[ 0 ] || s.converters[ type + "" "" + dataTypes[0] ] ) { finalDataType = type; break; } if ( !firstDataType ) { firstDataType = type; } } // Or just use first one finalDataType = finalDataType || firstDataType; } // If we found a dataType // We add the dataType to the list if needed // and return the corresponding response if ( finalDataType ) { if ( finalDataType !== dataTypes[ 0 ] ) { dataTypes.unshift( finalDataType ); } return responses[ finalDataType ];/* Chain conversions given the request and the original response * Also sets the responseXXX fields on the jqXHR instance */ function ajaxConvert( s, response, jqXHR, isSuccess ) { var conv2, current, conv, tmp, prev, converters = {}, // Work with a copy of dataTypes in case we need to modify it for conversion dataTypes = s.dataTypes.slice(); // Create converters map with lowercased keys if ( dataTypes[ 1 ] ) { for ( conv in s.converters ) { converters[ conv.toLowerCase() ] = s.converters[ conv ]; current = dataTypes.shift(); // Convert to each sequential dataType while ( current ) { if ( s.responseFields[ current ] ) { jqXHR[ s.responseFields[ current ] ] = response; // Apply the dataFilter if provided if ( !prev && isSuccess && s.dataFilter ) { response = s.dataFilter( response, s.dataType ); } prev = current; current = dataTypes.shift(); if ( current ) { // There's only work to do if current dataType is non-auto if ( current === ""*"" ) { current = prev; // Convert response if prev dataType is non-auto and differs from current } else if ( prev !== ""*"" && prev !== current ) { // Seek a direct converter conv = converters[ prev + "" "" + current ] || converters[ ""* "" + current ]; // If none found, seek a pair if ( !conv ) { for ( conv2 in converters ) { // If conv2 outputs current tmp = conv2.split( "" "" ); if ( tmp[ 1 ] === current ) { // If prev can be converted to accepted input conv = converters[ prev + "" "" + tmp[ 0 ] ] || converters[ ""* "" + tmp[ 0 ] ]; if ( conv ) { // Condense equivalence converters if ( conv === true ) { conv = converters[ conv2 ]; // Otherwise, insert the intermediate dataType } else if ( converters[ conv2 ] !== true ) { current = tmp[ 0 ]; dataTypes.unshift( tmp[ 1 ] ); } break; // Apply converter (if not an equivalence) if ( conv !== true ) { // Unless errors are allowed to bubble, catch and return them if ( conv && s[ ""throws"" ] ) { response = conv( response ); } else { try { response = conv( response ); } catch ( e ) { return { state: ""parsererror"", error: conv ? e : ""No conversion from "" + prev + "" to "" + current }; } } } return { state: ""success"", data: response }; }// Handle cache's special case and global s.global = false;jQuery.ajaxTransport( ""script"", function(s) { var script, head = document.head || jQuery(""head"")[0] || document.documentElement; send: function( _, callback ) { script = document.createElement(""script""); script.async = true; if ( s.scriptCharset ) { script.charset = s.scriptCharset; } script.src = s.url; // Attach handlers for all browsers script.onload = script.onreadystatechange = function( _, isAbort ) { if ( isAbort || !script.readyState || /loaded|complete/.test( script.readyState ) ) { // Handle memory leak in IE script.onload = script.onreadystatechange = null; // Remove the script if ( script.parentNode ) { script.parentNode.removeChild( script ); } // Dereference the script script = null; // Callback if not abort if ( !isAbort ) { callback( 200, ""success"" ); }; // Circumvent IE6 bugs with base elements (#2709 and #4378) by prepending // Use native DOM manipulation to avoid our domManip AJAX trickery head.insertBefore( script, head.firstChild ); if ( script ) { script.onload( undefined, true ); var callback = oldCallbacks.pop() || ( jQuery.expando + ""_"" + ( ajax_nonce++ ) ); s.url += ( ajax_rquery.test( s.url ) ? ""&"" : ""?"" ) + s.jsonp + ""="" + callbackName;var xhrCallbacks, xhrSupported, xhrId = 0, // #5280: Internet Explorer will keep connections alive if we don't abort on unload xhrOnUnloadAbort = window.ActiveXObject && function() { // Abort all pending requests var key; for ( key in xhrCallbacks ) { xhrCallbacks[ key ]( undefined, true ); } };// Functions to create xhrs function createStandardXHR() { try { return new window.XMLHttpRequest(); } catch( e ) {} }function createActiveXHR() { try { return new window.ActiveXObject(""Microsoft.XMLHTTP""); } catch( e ) {} }// Create the request object // (This is still attached to ajaxSettings for backward compatibility) jQuery.ajaxSettings.xhr = window.ActiveXObject ? /* Microsoft failed to properly * implement the XMLHttpRequest in IE7 (can't request local files), * so we use the ActiveXObject when it is available * Additionally XMLHttpRequest can be disabled in IE7/IE8 so * we need a fallback. */ function() { return !this.isLocal && createStandardXHR() || createActiveXHR(); } : // For all other browsers, use the standard XMLHttpRequest object createStandardXHR;// Determine support properties xhrSupported = jQuery.ajaxSettings.xhr(); jQuery.support.cors = !!xhrSupported && ( ""withCredentials"" in xhrSupported ); xhrSupported = jQuery.support.ajax = !!xhrSupported; // Create transport if the browser can provide an xhr if ( xhrSupported ) { jQuery.ajaxTransport(function( s ) { // Cross domain only allowed if supported through XMLHttpRequest if ( !s.crossDomain || jQuery.support.cors ) { var callback; return { send: function( headers, complete ) { // Get a new xhr var handle, i, xhr = s.xhr(); // Open the socket // Passing null username, generates a login popup on Opera (#2865) if ( s.username ) { xhr.open( s.type, s.url, s.async, s.username, s.password ); } else { xhr.open( s.type, s.url, s.async ); } // Apply custom fields if provided if ( s.xhrFields ) { for ( i in s.xhrFields ) { xhr[ i ] = s.xhrFields[ i ]; } } // Override mime type if needed if ( s.mimeType && xhr.overrideMimeType ) { xhr.overrideMimeType( s.mimeType ); } // X-Requested-With header // For cross-domain requests, seeing as conditions for a preflight are // akin to a jigsaw puzzle, we simply never set it to be sure. // (it can always be set on a per-request basis or even using ajaxSetup) // For same-domain requests, won't change header if already provided. if ( !s.crossDomain && !headers[""X-Requested-With""] ) { headers[""X-Requested-With""] = ""XMLHttpRequest""; } // Need an extra try/catch for cross domain requests in Firefox 3 try { for ( i in headers ) { xhr.setRequestHeader( i, headers[ i ] ); } } catch( err ) {} // Do send the request // This may raise an exception which is actually // handled in jQuery.ajax (so no try/catch here) xhr.send( ( s.hasContent && s.data ) || null ); // Listener callback = function( _, isAbort ) { var status, responseHeaders, statusText, responses; // Firefox throws exceptions when accessing properties // of an xhr when a network error occurred // http://helpful.knobs-dials.com/index.php/Component_returned_failure_code:_0x80040111_(NS_ERROR_NOT_AVAILABLE) try { // Was never called and is aborted or complete if ( callback && ( isAbort || xhr.readyState === 4 ) ) { // Only called once callback = undefined; // Do not keep as active anymore if ( handle ) { xhr.onreadystatechange = jQuery.noop; if ( xhrOnUnloadAbort ) { delete xhrCallbacks[ handle ]; } } // If it's an abort if ( isAbort ) { // Abort it manually if needed if ( xhr.readyState !== 4 ) { xhr.abort(); } } else { responses = {}; status = xhr.status; responseHeaders = xhr.getAllResponseHeaders(); // When requesting binary data, IE6-9 will throw an exception // on any attempt to access responseText (#11426) if ( typeof xhr.responseText === ""string"" ) { responses.text = xhr.responseText; } // Firefox throws an exception when accessing // statusText for faulty cross-domain requests try { statusText = xhr.statusText; } catch( e ) { // We normalize with Webkit giving an empty statusText statusText = """"; } // Filter status for non standard behaviors // If the request is local and we have data: assume a success // (success with no data won't get notified, that's the best we // can do given current implementations) if ( !status && s.isLocal && !s.crossDomain ) { status = responses.text ? 200 : 404; // IE - #1450: sometimes returns 1223 when it should be 204 } else if ( status === 1223 ) { status = 204; } } } } catch( firefoxAccessException ) { if ( !isAbort ) { complete( -1, firefoxAccessException ); } } // Call complete if needed if ( responses ) { complete( status, statusText, responses, responseHeaders ); } }; if ( !s.async ) { // if we're in sync mode we fire the callback callback(); } else if ( xhr.readyState === 4 ) { // (IE6 & IE7) if it's in cache and has been // retrieved directly we need to fire the callback setTimeout( callback ); } else { handle = ++xhrId; if ( xhrOnUnloadAbort ) { // Create the active xhrs callbacks list if needed // and attach the unload handler if ( !xhrCallbacks ) { xhrCallbacks = {}; jQuery( window ).unload( xhrOnUnloadAbort ); } // Add to list of active xhrs callbacks xhrCallbacks[ handle ] = callback; } xhr.onreadystatechange = callback; } }, abort: function() { if ( callback ) { callback( undefined, true ); } } }; } }); } var fxNow, timerId, rfxtypes = /^(?:toggle|show|hide)$/, rfxnum = new RegExp( ""^(?:([+-])=|)("" + core_pnum + "")([a-z%]*)$"", ""i"" ), rrun = /queueHooks$/, animationPrefilters = [ defaultPrefilter ], tweeners = { ""*"": [function( prop, value ) { var tween = this.createTween( prop, value ), target = tween.cur(), parts = rfxnum.exec( value ), unit = parts && parts[ 3 ] || ( jQuery.cssNumber[ prop ] ? """" : ""px"" ), // Starting value computation is required for potential unit mismatches start = ( jQuery.cssNumber[ prop ] || unit !== ""px"" && +target ) && rfxnum.exec( jQuery.css( tween.elem, prop ) ), scale = 1, maxIterations = 20; if ( start && start[ 3 ] !== unit ) { // Trust units reported by jQuery.css unit = unit || start[ 3 ]; // Make sure we update the tween properties later on parts = parts || []; // Iteratively approximate from a nonzero starting point start = +target || 1; do { // If previous iteration zeroed out, double until we get *something* // Use a string for doubling factor so we don't accidentally see scale as unchanged below scale = scale || "".5""; // Adjust and apply start = start / scale; jQuery.style( tween.elem, prop, start + unit ); // Update scale, tolerating zero or NaN from tween.cur() // And breaking the loop if scale is unchanged or perfect, or if we've just had enough } while ( scale !== (scale = tween.cur() / target) && scale !== 1 && --maxIterations ); } // Update tween properties if ( parts ) { start = tween.start = +start || +target || 0; tween.unit = unit; // If a +=/-= token was provided, we're doing a relative animation tween.end = parts[ 1 ] ? start + ( parts[ 1 ] + 1 ) * parts[ 2 ] : +parts[ 2 ]; } return tween; }] }; // Animations created synchronously will run synchronously function createFxNow() { setTimeout(function() { fxNow = undefined; }); return ( fxNow = jQuery.now() ); } function createTween( value, prop, animation ) { var tween, collection = ( tweeners[ prop ] || [] ).concat( tweeners[ ""*"" ] ), index = 0, length = collection.length; for ( ; index < length; index++ ) { if ( (tween = collection[ index ].call( animation, prop, value )) ) { // we're done with this property return tween; }}function Animation( elem, properties, options ) { var result, stopped, index = 0, length = animationPrefilters.length, deferred = jQuery.Deferred().always( function() { // don't match elem in the :animated selector delete tick.elem; }), tick = function() { if ( stopped ) { return false; } var currentTime = fxNow || createFxNow(), remaining = Math.max( 0, animation.startTime + animation.duration - currentTime ), // archaic crash bug won't allow us to use 1 - ( 0.5 || 0 ) (#12497) temp = remaining / animation.duration || 0, percent = 1 - temp, index = 0, length = animation.tweens.length; for ( ; index < length ; index++ ) { animation.tweens[ index ].run( percent ); } deferred.notifyWith( elem, [ animation, percent, remaining ]); if ( percent < 1 && length ) { return remaining; } else { deferred.resolveWith( elem, [ animation ] ); return false; } }, animation = deferred.promise({ elem: elem, props: jQuery.extend( {}, properties ), opts: jQuery.extend( true, { specialEasing: {} }, options ), originalProperties: properties, originalOptions: options, startTime: fxNow || createFxNow(), duration: options.duration, tweens: [], createTween: function( prop, end ) { var tween = jQuery.Tween( elem, animation.opts, prop, end, animation.opts.specialEasing[ prop ] || animation.opts.easing ); animation.tweens.push( tween ); return tween; }, stop: function( gotoEnd ) { var index = 0, // if we are going to the end, we want to run all the tweens // otherwise we skip this part length = gotoEnd ? animation.tweens.length : 0; if ( stopped ) { return this; } stopped = true; for ( ; index < length ; index++ ) { animation.tweens[ index ].run( 1 ); } // resolve when we played the last frame // otherwise, reject if ( gotoEnd ) { deferred.resolveWith( elem, [ animation, gotoEnd ] ); } else { deferred.rejectWith( elem, [ animation, gotoEnd ] ); } return this; } }), props = animation.props; propFilter( props, animation.opts.specialEasing ); for ( ; index < length ; index++ ) { result = animationPrefilters[ index ].call( animation, elem, props, animation.opts ); if ( result ) { return result; } jQuery.map( props, createTween, animation ); if ( jQuery.isFunction( animation.opts.start ) ) { animation.opts.start.call( elem, animation ); jQuery.fx.timer( jQuery.extend( tick, { elem: elem, anim: animation, queue: animation.opts.queue }) ); // attach callbacks from options return animation.progress( animation.opts.progress ) .done( animation.opts.done, animation.opts.complete ) .fail( animation.opts.fail ) .always( animation.opts.always ); }function propFilter( props, specialEasing ) { var index, name, easing, value, hooks; // camelCase, specialEasing and expand cssHook pass for ( index in props ) { name = jQuery.camelCase( index ); easing = specialEasing[ name ]; value = props[ index ]; if ( jQuery.isArray( value ) ) { easing = value[ 1 ]; value = props[ index ] = value[ 0 ]; } if ( index !== name ) { props[ name ] = value; delete props[ index ]; } hooks = jQuery.cssHooks[ name ]; if ( hooks && ""expand"" in hooks ) { value = hooks.expand( value ); delete props[ name ]; // not quite $.extend, this wont overwrite keys already present. // also - reusing 'index' from above because we have the correct ""name"" for ( index in value ) { if ( !( index in props ) ) { props[ index ] = value[ index ]; specialEasing[ index ] = easing; } } } else { specialEasing[ name ] = easing; }}jQuery.Animation = jQuery.extend( Animation, { tweener: function( props, callback ) { if ( jQuery.isFunction( props ) ) { callback = props; props = [ ""*"" ]; } else { props = props.split("" ""); } var prop, index = 0, length = props.length; for ( ; index < length ; index++ ) { prop = props[ index ]; tweeners[ prop ] = tweeners[ prop ] || []; tweeners[ prop ].unshift( callback ); } }, prefilter: function( callback, prepend ) { if ( prepend ) { animationPrefilters.unshift( callback ); } else { animationPrefilters.push( callback ); }});function defaultPrefilter( elem, props, opts ) { /* jshint validthis: true */ var prop, value, toggle, tween, hooks, oldfire, anim = this, orig = {}, style = elem.style, hidden = elem.nodeType && isHidden( elem ), dataShow = jQuery._data( elem, ""fxshow"" ); // handle queue: false promises if ( !opts.queue ) { hooks = jQuery._queueHooks( elem, ""fx"" ); if ( hooks.unqueued == null ) { hooks.unqueued = 0; oldfire = hooks.empty.fire; hooks.empty.fire = function() { if ( !hooks.unqueued ) { oldfire(); } }; } hooks.unqueued++; anim.always(function() { // doing this makes sure that the complete handler will be called // before this completes anim.always(function() { hooks.unqueued--; if ( !jQuery.queue( elem, ""fx"" ).length ) { hooks.empty.fire(); } }); // height/width overflow pass if ( elem.nodeType === 1 && ( ""height"" in props || ""width"" in props ) ) { // Make sure that nothing sneaks out // Record all 3 overflow attributes because IE does not // change the overflow attribute when overflowX and // overflowY are set to the same value opts.overflow = [ style.overflow, style.overflowX, style.overflowY ]; // Set display property to inline-block for height/width // animations on inline elements that are having width/height animated if ( jQuery.css( elem, ""display"" ) === ""inline"" && jQuery.css( elem, ""float"" ) === ""none"" ) { // inline-level elements accept inline-block; // block-level elements need to be inline with layout if ( !jQuery.support.inlineBlockNeedsLayout || css_defaultDisplay( elem.nodeName ) === ""inline"" ) { style.display = ""inline-block""; } else { style.zoom = 1; } } } if ( opts.overflow ) { style.overflow = ""hidden""; if ( !jQuery.support.shrinkWrapBlocks ) { anim.always(function() { style.overflow = opts.overflow[ 0 ]; style.overflowX = opts.overflow[ 1 ]; style.overflowY = opts.overflow[ 2 ]; }); } } // show/hide pass for ( prop in props ) { value = props[ prop ]; if ( rfxtypes.exec( value ) ) { delete props[ prop ]; toggle = toggle || value === ""toggle""; if ( value === ( hidden ? ""hide"" : ""show"" ) ) { continue; } orig[ prop ] = dataShow && dataShow[ prop ] || jQuery.style( elem, prop ); } } if ( !jQuery.isEmptyObject( orig ) ) { if ( dataShow ) { if ( ""hidden"" in dataShow ) { hidden = dataShow.hidden; } } else { dataShow = jQuery._data( elem, ""fxshow"", {} ); } // store state if its toggle - enables .stop().toggle() to ""reverse"" if ( toggle ) { dataShow.hidden = !hidden; } if ( hidden ) { jQuery( elem ).show(); } else { anim.done(function() { jQuery( elem ).hide(); }); } anim.done(function() { var prop; jQuery._removeData( elem, ""fxshow"" ); for ( prop in orig ) { jQuery.style( elem, prop, orig[ prop ] ); } }); for ( prop in orig ) { tween = createTween( hidden ? dataShow[ prop ] : 0, prop, anim ); if ( !( prop in dataShow ) ) { dataShow[ prop ] = tween.start; if ( hidden ) { tween.end = tween.start; tween.start = prop === ""width"" || prop === ""height"" ? 1 : 0; } } } }function Tween( elem, options, prop, end, easing ) { return new Tween.prototype.init( elem, options, prop, end, easing ); } jQuery.Tween = Tween; Tween.prototype = { constructor: Tween, init: function( elem, options, prop, end, easing, unit ) { this.elem = elem; this.prop = prop; this.easing = easing || ""swing""; this.options = options; this.start = this.now = this.cur(); this.end = end; this.unit = unit || ( jQuery.cssNumber[ prop ] ? """" : ""px"" ); }, cur: function() { var hooks = Tween.propHooks[ this.prop ]; return hooks && hooks.get ? hooks.get( this ) : Tween.propHooks._default.get( this ); }, run: function( percent ) { var eased, hooks = Tween.propHooks[ this.prop ]; if ( this.options.duration ) { this.pos = eased = jQuery.easing[ this.easing ]( percent, this.options.duration * percent, 0, 1, this.options.duration ); } else { this.pos = eased = percent; } this.now = ( this.end - this.start ) * eased + this.start; if ( this.options.step ) { this.options.step.call( this.elem, this.now, this ); } if ( hooks && hooks.set ) { hooks.set( this ); } else { Tween.propHooks._default.set( this ); } return this; } }; Tween.prototype.init.prototype = Tween.prototype; Tween.propHooks = { _default: { get: function( tween ) { var result; if ( tween.elem[ tween.prop ] != null && (!tween.elem.style || tween.elem.style[ tween.prop ] == null) ) { return tween.elem[ tween.prop ]; } // passing an empty string as a 3rd parameter to .css will automatically // attempt a parseFloat and fallback to a string if the parse fails // so, simple values such as ""10px"" are parsed to Float. // complex values such as ""rotate(1rad)"" are returned as is. result = jQuery.css( tween.elem, tween.prop, """" ); // Empty strings, null, undefined and ""auto"" are converted to 0. return !result || result === ""auto"" ? 0 : result; }, set: function( tween ) { // use step hook for back compat - use cssHook if its there - use .style if its // available and use plain properties where available if ( jQuery.fx.step[ tween.prop ] ) { jQuery.fx.step[ tween.prop ]( tween ); } else if ( tween.elem.style && ( tween.elem.style[ jQuery.cssProps[ tween.prop ] ] != null || jQuery.cssHooks[ tween.prop ] ) ) { jQuery.style( tween.elem, tween.prop, tween.now + tween.unit ); } else { tween.elem[ tween.prop ] = tween.now; } } } }; // Support: IE <=9 // Panic based approach to setting things on disconnected nodes Tween.propHooks.scrollTop = Tween.propHooks.scrollLeft = { set: function( tween ) { if ( tween.elem.nodeType && tween.elem.parentNode ) { tween.elem[ tween.prop ] = tween.now; } } }; jQuery.each([ ""toggle"", ""show"", ""hide"" ], function( i, name ) { var cssFn = jQuery.fn[ name ]; jQuery.fn[ name ] = function( speed, easing, callback ) { return speed == null || typeof speed === ""boolean"" ? cssFn.apply( this, arguments ) : this.animate( genFx( name, true ), speed, easing, callback ); }; }); jQuery.fn.extend({ fadeTo: function( speed, to, easing, callback ) { // show any hidden elements after setting opacity to 0 return this.filter( isHidden ).css( ""opacity"", 0 ).show() // animate to the value specified .end().animate({ opacity: to }, speed, easing, callback ); }, animate: function( prop, speed, easing, callback ) { var empty = jQuery.isEmptyObject( prop ), optall = jQuery.speed( speed, easing, callback ), doAnimation = function() { // Operate on a copy of prop so per-property easing won't be lost var anim = Animation( this, jQuery.extend( {}, prop ), optall ); // Empty animations, or finishing resolves immediately if ( empty || jQuery._data( this, ""finish"" ) ) { anim.stop( true ); } }; doAnimation.finish = doAnimation; return empty || optall.queue === false ? this.each( doAnimation ) : this.queue( optall.queue, doAnimation ); }, stop: function( type, clearQueue, gotoEnd ) { var stopQueue = function( hooks ) { var stop = hooks.stop; delete hooks.stop; stop( gotoEnd ); }; if ( typeof type !== ""string"" ) { gotoEnd = clearQueue; clearQueue = type; type = undefined; } if ( clearQueue && type !== false ) { this.queue( type || ""fx"", [] ); } return this.each(function() { var dequeue = true, index = type != null && type + ""queueHooks"", timers = jQuery.timers, data = jQuery._data( this ); if ( index ) { if ( data[ index ] && data[ index ].stop ) { stopQueue( data[ index ] ); } } else { for ( index in data ) { if ( data[ index ] && data[ index ].stop && rrun.test( index ) ) { stopQueue( data[ index ] ); } } } for ( index = timers.length; index--; ) { if ( timers[ index ].elem === this && (type == null || timers[ index ].queue === type) ) { timers[ index ].anim.stop( gotoEnd ); dequeue = false; timers.splice( index, 1 ); } } // start the next in the queue if the last step wasn't forced // timers currently will call their complete callbacks, which will dequeue // but only if they were gotoEnd if ( dequeue || !gotoEnd ) { jQuery.dequeue( this, type ); } }); }, finish: function( type ) { if ( type !== false ) { type = type || ""fx""; } return this.each(function() { var index, data = jQuery._data( this ), queue = data[ type + ""queue"" ], hooks = data[ type + ""queueHooks"" ], timers = jQuery.timers, length = queue ? queue.length : 0; // enable finishing flag on private data data.finish = true; // empty the queue first jQuery.queue( this, type, [] ); if ( hooks && hooks.stop ) { hooks.stop.call( this, true ); } // look for any active animations, and finish them for ( index = timers.length; index--; ) { if ( timers[ index ].elem === this && timers[ index ].queue === type ) { timers[ index ].anim.stop( true ); timers.splice( index, 1 ); } } // look for any animations in the old queue and finish them for ( index = 0; index < length; index++ ) { if ( queue[ index ] && queue[ index ].finish ) { queue[ index ].finish.call( this ); } } // turn off finishing flag delete data.finish; }); } }); // Generate parameters to create a standard animation function genFx( type, includeWidth ) { var which, attrs = { height: type }, i = 0; // if we include width, step value is 1 to do all cssExpand values, // if we don't include width, step value is 2 to skip over Left and Right includeWidth = includeWidth? 1 : 0; for( ; i < 4 ; i += 2 - includeWidth ) { which = cssExpand[ i ]; attrs[ ""margin"" + which ] = attrs[ ""padding"" + which ] = type; } if ( includeWidth ) { attrs.opacity = attrs.width = type; } return attrs; } // Generate shortcuts for custom animations jQuery.each({ slideDown: genFx(""show""), slideUp: genFx(""hide""), slideToggle: genFx(""toggle""), fadeIn: { opacity: ""show"" }, fadeOut: { opacity: ""hide"" }, fadeToggle: { opacity: ""toggle"" } }, function( name, props ) { jQuery.fn[ name ] = function( speed, easing, callback ) { return this.animate( props, speed, easing, callback ); }; }); jQuery.speed = function( speed, easing, fn ) { var opt = speed && typeof speed === ""object"" ? jQuery.extend( {}, speed ) : { complete: fn || !fn && easing || jQuery.isFunction( speed ) && speed, duration: speed, easing: fn && easing || easing && !jQuery.isFunction( easing ) && easing }; opt.duration = jQuery.fx.off ? 0 : typeof opt.duration === ""number"" ? opt.duration : opt.duration in jQuery.fx.speeds ? jQuery.fx.speeds[ opt.duration ] : jQuery.fx.speeds._default; // normalize opt.queue - true/undefined/null -> ""fx"" if ( opt.queue == null || opt.queue === true ) { opt.queue = ""fx""; } // Queueing opt.old = opt.complete; opt.complete = function() { if ( jQuery.isFunction( opt.old ) ) { opt.old.call( this ); } if ( opt.queue ) { jQuery.dequeue( this, opt.queue ); } }; return opt; }; jQuery.easing = { linear: function( p ) { return p; }, swing: function( p ) { return 0.5 - Math.cos( p*Math.PI ) / 2; } }; jQuery.timers = []; jQuery.fx = Tween.prototype.init; jQuery.fx.tick = function() { var timer, timers = jQuery.timers, i = 0; fxNow = jQuery.now(); for ( ; i < timers.length; i++ ) { timer = timers[ i ]; // Checks the timer has not already been removed if ( !timer() && timers[ i ] === timer ) { timers.splice( i--, 1 ); } } if ( !timers.length ) { jQuery.fx.stop(); } fxNow = undefined; }; jQuery.fx.timer = function( timer ) { if ( timer() && jQuery.timers.push( timer ) ) { jQuery.fx.start(); } }; jQuery.fx.interval = 13; jQuery.fx.start = function() { if ( !timerId ) { timerId = setInterval( jQuery.fx.tick, jQuery.fx.interval ); } }; jQuery.fx.stop = function() { clearInterval( timerId ); timerId = null; }; jQuery.fx.speeds = { slow: 600, fast: 200, // Default speed _default: 400 }; // Back Compat <1.8 extension point jQuery.fx.step = {}; if ( jQuery.expr && jQuery.expr.filters ) { jQuery.expr.filters.animated = function( elem ) { return jQuery.grep(jQuery.timers, function( fn ) { return elem === fn.elem; }).length; }; } jQuery.fn.offset = function( options ) { if ( arguments.length ) { return options === undefined ? this : this.each(function( i ) { jQuery.offset.setOffset( this, options, i ); }); } var docElem, win, box = { top: 0, left: 0 }, elem = this[ 0 ], doc = elem && elem.ownerDocument; if ( !doc ) { return; } docElem = doc.documentElement; // Make sure it's not a disconnected DOM node if ( !jQuery.contains( docElem, elem ) ) { return box; } // If we don't have gBCR, just use 0,0 rather than error // BlackBerry 5, iOS 3 (original iPhone) if ( typeof elem.getBoundingClientRect !== core_strundefined ) { box = elem.getBoundingClientRect(); } win = getWindow( doc ); return { top: box.top + ( win.pageYOffset || docElem.scrollTop ) - ( docElem.clientTop || 0 ), left: box.left + ( win.pageXOffset || docElem.scrollLeft ) - ( docElem.clientLeft || 0 ) }; }; var position = jQuery.css( elem, ""position"" ); // set position first, in-case top/left are set even on static elem var curElem = jQuery( elem ), curOffset = curElem.offset(), curCSSTop = jQuery.css( elem, ""top"" ), curCSSLeft = jQuery.css( elem, ""left"" ), calculatePosition = ( position === ""absolute"" || position === ""fixed"" ) && jQuery.inArray(""auto"", [curCSSTop, curCSSLeft]) > -1, props = {}, curPosition = {}, curTop, curLeft; // need to be able to calculate position if either top or left is auto and position is either absolute or fixed parentOffset = { top: 0, left: 0 }, elem = this[ 0 ]; // fixed elements are offset from window (parentOffset = {top:0, left: 0}, because it is it's only offset parent // we assume that getBoundingClientRect is available when computed position is fixed parentOffset.top += jQuery.css( offsetParent[ 0 ], ""borderTopWidth"", true ); // note: when an element has margin: auto the offsetLeft and marginLeft // are the same in Safari causing offset.left to incorrectly be 0 top: offset.top - parentOffset.top - jQuery.css( elem, ""marginTop"", true ), left: offset.left - parentOffset.left - jQuery.css( elem, ""marginLeft"", true) while ( offsetParent && ( !jQuery.nodeName( offsetParent, ""html"" ) && jQuery.css( offsetParent, ""position"") === ""static"" ) ) {jQuery.each( {scrollLeft: ""pageXOffset"", scrollTop: ""pageYOffset""}, function( method, prop ) { var top = /Y/.test( prop ); return jQuery.access( this, function( elem, method, val ) { return win ? (prop in win) ? win[ prop ] : win.document.documentElement[ method ] : elem[ method ]; !top ? val : jQuery( win ).scrollLeft(), top ? val : jQuery( win ).scrollTop()function getWindow( elem ) { return jQuery.isWindow( elem ) ? elem : elem.nodeType === 9 ? elem.defaultView || elem.parentWindow : false; } return jQuery.access( this, function( elem, type, value ) { // Either scroll[Width/Height] or offset[Width/Height] or client[Width/Height], whichever is greatest // unfortunately, this causes bug #3838 in IE6/8 only, but there is currently no good, small way to fix it.// Limit scope pollution from any deprecated API // (function() {// })(); if ( typeof module === ""object"" && module && typeof module.exports === ""object"" ) { // Expose jQuery as module.exports in loaders that implement the Node // module pattern (including browserify). Do not create the global, since // the user will be storing it themselves locally, and globals are frowned // upon in the Node module world. module.exports = jQuery; } else { // Otherwise expose jQuery to the global object as usual window.jQuery = window.$ = jQuery; // Register as a named AMD module, since jQuery can be concatenated with other // files that may use define, but not via a proper concatenation script that // understands anonymous AMD modules. A named AMD is safest and most robust // way to register. Lowercase jquery is used because AMD module names are // derived from file names, and jQuery is normally delivered in a lowercase // file name. Do this after creating the global so that if an AMD module wants // to call noConflict to hide this version of jQuery, it will work. if ( typeof define === ""function"" && define.amd ) { define( ""jquery"", [], function () { return jQuery; } ); }})( window ); * @license AngularJS v1.2.16function minErr(module) { return function () { stringify = function (obj) { if (typeof obj === 'function') { return obj.toString().replace(/ \{[\s\S]*$/, ''); } else if (typeof obj === 'undefined') { return 'undefined'; } else if (typeof obj !== 'string') { return JSON.stringify(obj); } return obj; }, message = prefix + template.replace(/\{\d+\}/g, function (match) { arg = templateArgs[index + 2]; if (typeof arg === 'function') { return arg.toString().replace(/ ?\{[\s\S]*$/, ''); } else if (typeof arg === 'undefined') { return 'undefined'; } else if (typeof arg !== 'string') { return toJson(arg); } return arg; message = message + '\nhttp://errors.angularjs.org/1.2.16/' + message = message + (i == 2 ? '?' : '&') + 'p' + (i-2) + '=' + encodeURIComponent(stringify(arguments[i])); return new Error(message);/* global -angular, -msie, -jqLite, -jQuery, -slice, -push, -toString, -ngMinErr, -_angular, -angularModule, -nodeName_, -uid, -lowercase, -uppercase, -manualLowercase, -manualUppercase, -nodeName_, -isArrayLike, -forEach, -sortedKeys, -forEachSorted, -reverseParams, -nextUid, -setHashKey, -extend, -int, -inherit, -noop, -identity, -valueFn, -isUndefined, -isDefined, -isObject, -isString, -isNumber, -isDate, -isArray, -isFunction, -isRegExp, -isWindow, -isScope, -isFile, -isBlob, -isBoolean, -trim, -isElement, -makeMap, -map, -size, -includes, -indexOf, -arrayRemove, -isLeafNode, -copy, -shallowCopy, -equals, -csp, -concat, -sliceArgs, -bind, -toJsonReplacer, -toJson, -fromJson, -toBoolean, -startingTag, -tryDecodeURIComponent, -parseKeyValue, -toKeyValue, -encodeUriSegment, -encodeUriQuery, -angularInit, -bootstrap, -snake_case, -bindJQuery, -assertArg, -assertArgFn, -assertNotHasOwnProperty, -getter, -getBlockElements, -hasOwnProperty, * @functionvar lowercase = function(string){return isString(string) ? string.toLowerCase() : string;}; * @functionvar uppercase = function(string){return isString(string) ? string.toUpperCase() : string;};var /** holds major version number for IE or NaN for real browsers */ msie, _angular = window.angular, nodeName_, uid = ['0', '0', '0']; * IE 11 changed the format of the UserAgent string. * See http://msdn.microsoft.com/en-us/library/ms537503.aspxmsie = int((/msie (\d+)/.exec(lowercase(navigator.userAgent)) || [])[1]); if (isNaN(msie)) { msie = int((/trident\/.*; rv:(\d+)/.exec(lowercase(navigator.userAgent)) || [])[1]); } if (obj.nodeType === 1 && length) { * @function * object or an array. The `iterator` function is invoked with `iterator(value, key)`, where `value` * is the value of an object property or an array element and `key` is the object property key or * array element index. Specifying a `context` for the function is optional. angular.forEach(values, function(value, key){ var key; if (isFunction(obj)){ iterator.call(context, obj[key], key); obj.forEach(iterator, context); } else if (isArrayLike(obj)) { for (key = 0; key < obj.length; key++) iterator.call(context, obj[key], key); iterator.call(context, obj[key], key); var keys = []; for (var key in obj) { if (obj.hasOwnProperty(key)) { keys.push(key); } } return keys.sort(); for ( var i = 0; i < keys.length; i++) { * A consistent way of creating unique IDs in angular. The ID is a sequence of alpha numeric * characters such as '012ABC'. The reason why we are not using simply a number counter is that * the number string gets longer over time, and it can also overflow, where as the nextId * will grow much slower, it is a string, and it will never overflow. * @returns {string} an unique alpha-numeric string var index = uid.length; var digit; while(index) { index--; digit = uid[index].charCodeAt(0); if (digit == 57 /*'9'*/) { uid[index] = 'A'; return uid.join(''); } if (digit == 90 /*'Z'*/) { uid[index] = '0'; } else { uid[index] = String.fromCharCode(digit + 1); return uid.join(''); } } uid.unshift('0'); return uid.join(''); * @function * Extends the destination object `dst` by copying all of the properties from the `src` object(s) * to `dst`. You can specify multiple `src` objects. forEach(arguments, function(obj){ if (obj !== dst) { forEach(obj, function(value, key){ dst[key] = value; }); } }); setHashKey(dst,h); return extend(new (extend(function() {}, {prototype:parent}))(), extra); * @function * @function * @functionfunction isUndefined(value){return typeof value === 'undefined';} * @functionfunction isDefined(value){return typeof value !== 'undefined';} * @functionfunction isObject(value){return value != null && typeof value === 'object';} * @functionfunction isString(value){return typeof value === 'string';} * @functionfunction isNumber(value){return typeof value === 'number';} * @functionfunction isDate(value){ * @functionfunction isArray(value) { return toString.call(value) === '[object Array]'; } * @functionfunction isFunction(value){return typeof value === 'function';} return obj && obj.document && obj.location && obj.alert && obj.setInterval;var trim = (function() { // native trim is way faster: http://jsperf.com/angular-trim-test // but IE doesn't have it... :-( // TODO: we should move this into IE/ES5 polyfill if (!String.prototype.trim) { return function(value) { return isString(value) ? value.replace(/^\s\s*/, '').replace(/\s\s*$/, '') : value; }; } return function(value) { return isString(value) ? value.trim() : value; }; })(); * @functionfunction makeMap(str){ for ( i = 0; i < items.length; i++ )if (msie < 9) { nodeName_ = function(element) { element = element.nodeName ? element : element[0]; return (element.scopeName && element.scopeName != 'HTML') ? uppercase(element.scopeName + ':' + element.nodeName) : element.nodeName; }; } else { nodeName_ = function(element) { return element.nodeName ? element.nodeName : element[0].nodeName; }; function map(obj, iterator, context) { var results = []; forEach(obj, function(value, index, list) { results.push(iterator.call(context, value, index, list)); }); return results; } /** * @description * Determines the number of elements in an array, the number of properties an object has, or * the length of a string. * * Note: This function is used to augment the Object type in Angular expressions. See * {@link angular.Object} for more information about Angular arrays. * * @param {Object|Array|string} obj Object, array, or string to inspect. * @param {boolean} [ownPropsOnly=false] Count only ""own"" properties in an object * @returns {number} The size of `obj` or `0` if `obj` is neither an object nor an array. */ function size(obj, ownPropsOnly) { var count = 0, key; if (isArray(obj) || isString(obj)) { return obj.length; } else if (isObject(obj)){ for (key in obj) if (!ownPropsOnly || obj.hasOwnProperty(key)) count++; } return count; } return indexOf(array, obj) != -1; } function indexOf(array, obj) { if (array.indexOf) return array.indexOf(obj); for (var i = 0; i < array.length; i++) { if (obj === array[i]) return i; } return -1; var index = indexOf(array, value); if (index >=0)function isLeafNode (node) { if (node) { switch (node.nodeName) { case ""OPTION"": case ""PRE"": case ""TITLE"": return true; } } return false; } * @function <example> <div ng-controller=""Controller""> function Controller($scope) { $scope.master= {}; $scope.update = function(user) { // Example with 1 argument $scope.master= angular.copy(user); }; $scope.reset = function() { // Example with 2 arguments angular.copy($scope.master, $scope.user); }; $scope.reset(); }function copy(source, destination){ destination = copy(source, []); destination = new RegExp(source.source); destination = copy(source, {}); for ( var i = 0; i < source.length; i++) { destination.push(copy(source[i])); forEach(destination, function(value, key){ delete destination[key]; }); for ( var key in source) { destination[key] = copy(source[key]); * Create a shallow copy of an object dst = dst || {}; for(var key in src) { // shallowCopy is only ever called by $compile nodeLinkFn, which has control over src // so we don't need to worry about using our custom hasOwnProperty here if (src.hasOwnProperty(key) && !(key.charAt(0) === '$' && key.charAt(1) === '$')) { dst[key] = src[key]; return dst; * @function * * Both values represent the same regular expression (In JavasScript, for(key=0; key<length; key++) { return isDate(o2) && o1.getTime() == o2.getTime(); for(key in o1) { for(key in o2) {function csp() { return (document.securityPolicy && document.securityPolicy.isActive) || (document.querySelector && !!(document.querySelector('[ng-csp]') || document.querySelector('[data-ng-csp]'))); } * @function ? fn.apply(self, curryArgs.concat(slice.call(arguments, 0))) if (typeof key === 'string' && key.charAt(0) === '$') { * @function * Serializes input into a JSON-formatted string. Properties with leading $ characters will be * @param {boolean=} pretty If set to true, the JSON output will contain newlines and whitespace. return JSON.stringify(obj, toJsonReplacer, pretty ? ' ' : null); * @functionfunction toBoolean(value) { if (typeof value === 'function') { value = true; } else if (value && value.length !== 0) { var v = lowercase("""" + value); value = !(v == 'f' || v == '0' || v == 'false' || v == 'no' || v == 'n' || v == '[]'); } else { value = false; } return value; } } catch(e) {} // As Per DOM Standards var TEXT_NODE = 3; return element[0].nodeType === TEXT_NODE ? lowercase(elemHtml) : } catch(e) { } catch(e) { forEach((keyValue || """").split('&'), function(keyValue){ if ( keyValue ) { key_value = keyValue.split('='); if ( isDefined(key) ) { if (!obj[key]) { } else if(isArray(obj[key])) { var elements = [element], appElement, names = ['ng:app', 'ng-app', 'x-ng-app', 'data-ng-app'], NG_APP_CLASS_REGEXP = /\sng[:\-]app(:\s*([\w\d_]+);?)?\s/; function append(element) { element && elements.push(element); } forEach(names, function(name) { names[name] = true; append(document.getElementById(name)); name = name.replace(':', '\\:'); if (element.querySelectorAll) { forEach(element.querySelectorAll('.' + name), append); forEach(element.querySelectorAll('.' + name + '\\:'), append); forEach(element.querySelectorAll('[' + name + ']'), append); forEach(elements, function(element) { if (!appElement) { var className = ' ' + element.className + ' '; var match = NG_APP_CLASS_REGEXP.exec(className); if (match) { appElement = element; module = (match[2] || '').replace(/\s+/g, ','); } else { forEach(element.attributes, function(attr) { if (!appElement && names[attr.name]) { appElement = element; module = attr.value; } }); } bootstrap(appElement, module ? [module] : []); * Note that ngScenario-based end-to-end tests cannot use this function to bootstrap manually. * each of the subsequent scripts. This prevents strange results in applications, where otherwise * <example name=""multi-bootstrap"" module=""multi-bootstrap""> * <file name=""index.html""> * <script src=""../../../angular.js""></script> * <div ng-controller=""BrokenTable""> * <table> * <tr> * <th ng-repeat=""heading in headings"">{{heading}}</th> * </tr> * <tr ng-repeat=""filling in fillings""> * <td ng-repeat=""fill in filling"">{{fill}}</td> * </tr> * </table> * </file> * <file name=""controller.js""> * var app = angular.module('multi-bootstrap', []) * .controller('BrokenTable', function($scope) { * $scope.headings = ['One', 'Two', 'Three']; * $scope.fillings = [[1, 2, 3], ['A', 'B', 'C'], [7, 8, 9]]; * }); * </file> * <file name=""protractor.js"" type=""protractor""> * it('should only insert one table cell for each item in $scope.fillings', function() { * expect(element.all(by.css('td')).count()) * .toBe(9); * }); * </file> * </example>function bootstrap(element, modules) { throw ngMinErr('btstrpd', ""App Already Bootstrapped with this Element '{0}'"", tag); var injector = createInjector(modules); injector.invoke(['$rootScope', '$rootElement', '$compile', '$injector', '$animate', function(scope, element, compile, injector, animate) {function snake_case(name, separator){ // reset to jQuery or default to us. if (jQuery) { // Method signature: // jqLitePatchJQueryRemove(name, dispatchThis, filterElems, getterIfNoArguments) jqLitePatchJQueryRemove('remove', true, true, false); jqLitePatchJQueryRemove('empty', false, false, false); jqLitePatchJQueryRemove('html', false, false, true); (arg && typeof arg == 'object' ? arg.constructor.name || 'Object' : typeof arg)); * @returns {DOMElement} object containing the elementsfunction getBlockElements(nodes) { var startNode = nodes[0], endNode = nodes[nodes.length - 1]; if (startNode === endNode) { return jqLite(startNode); } var element = startNode; var elements = [element]; element = element.nextSibling; if (!element) break; elements.push(element); } while (element !== endNode); return jqLite(elements); * A module is a collection of services, directives, filters, and configuration information.<<<<<* @param {!Array.<string>=} requires If specified then new module is being created. If >>>>>* unspecified then the module is being retrieved for further configuration. * @param {Function} configFn Optional configuration function for the module. Same as var config = invokeLater('$injector', 'invoke'); * @returns {Array.<string>} List of module names which must be loaded before this module. * @returns {string} Name of the module. * See {@link ngAnimate.$animateProvider#register $animateProvider.register()} and return moduleInstance; function invokeLater(provider, method, insertMethod) { invokeQueue[insertMethod || 'push']([provider, method, arguments]);/* global angularModule: true, version: true, $LocaleProvider, $CompileProvider, htmlAnchorDirective, inputDirective, inputDirective, formDirective, scriptDirective, selectDirective, styleDirective, optionDirective, ngBindDirective, ngBindHtmlDirective, ngBindTemplateDirective, ngClassDirective, ngClassEvenDirective, ngClassOddDirective, ngCspDirective, ngCloakDirective, ngControllerDirective, ngFormDirective, ngHideDirective, ngIfDirective, ngIncludeDirective, ngIncludeFillContentDirective, ngInitDirective, ngNonBindableDirective, ngPluralizeDirective, ngRepeatDirective, ngShowDirective, ngStyleDirective, ngSwitchDirective, ngSwitchWhenDirective, ngSwitchDefaultDirective, ngOptionsDirective, ngTranscludeDirective, ngModelDirective, ngListDirective, ngChangeDirective, requiredDirective, requiredDirective, ngValueDirective, ngAttributeAliasDirectives, ngEventDirectives, $AnchorScrollProvider, $AnimateProvider, $BrowserProvider, $CacheFactoryProvider, $ControllerProvider, $DocumentProvider, $ExceptionHandlerProvider, $FilterProvider, $InterpolateProvider, $IntervalProvider, $HttpProvider, $HttpBackendProvider, $LocationProvider, $LogProvider, $ParseProvider, $RootScopeProvider, $QProvider, $$SanitizeUriProvider, $SceProvider, $SceDelegateProvider, $SnifferProvider, $TemplateCacheProvider, $TimeoutProvider, $$RAFProvider, $$AsyncCallbackProvider, $WindowProvider full: '1.2.16', // all of these placeholder strings will be replaced by grunt's minor: 2, dot: 16, codeName: 'badger-enumeration'function publishExternalAPI(angular){ 'noop':noop, 'bind':bind, 'identity':identity, '$$csp': csp ngValue: ngValueDirective $$asyncCallback : $$AsyncCallbackProvider/* global -JQLitePrototype, -addEventListenerFn, -removeEventListenerFn, -BOOLEAN_ATTR * @function * - [`attr()`](http://api.jquery.com/attr/) * - [`css()`](http://api.jquery.com/css/) * element or its parent. jqName = JQLite.expando = 'ng-' + new Date().getTime(), addEventListenerFn = (window.document.addEventListener ? function(element, type, fn) {element.addEventListener(type, fn, false);} : function(element, type, fn) {element.attachEvent('on' + type, fn);}), removeEventListenerFn = (window.document.removeEventListener ? function(element, type, fn) {element.removeEventListener(type, fn, false); } : function(element, type, fn) {element.detachEvent('on' + type, fn); });var jqData = JQLite._data = function(node) {///////////////////////////////////////////// // jQuery mutation patch // // In conjunction with bindJQuery intercepts all jQuery's DOM destruction apis and fires a // $destroy event on all DOM nodes being removed. // ///////////////////////////////////////////// function jqLitePatchJQueryRemove(name, dispatchThis, filterElems, getterIfNoArguments) { var originalJqFn = jQuery.fn[name]; originalJqFn = originalJqFn.$original || originalJqFn; removePatch.$original = originalJqFn; jQuery.fn[name] = removePatch; function removePatch(param) { // jshint -W040 var list = filterElems && param ? [this.filter(param)] : [this], fireEvent = dispatchThis, set, setIndex, setLength, element, childIndex, childLength, children; if (!getterIfNoArguments || param != null) { while(list.length) { set = list.shift(); for(setIndex = 0, setLength = set.length; setIndex < setLength; setIndex++) { element = jqLite(set[setIndex]); if (fireEvent) { element.triggerHandler('$destroy'); } else { fireEvent = !fireEvent; } for(childIndex = 0, childLength = (children = element.children()).length; childIndex < childLength; childIndex++) { list.push(jQuery(children[childIndex])); } } } } return originalJqFn.apply(this, arguments); } } var elem, tmp, tag, wrap, nodes = [], i, j, jj; tmp = fragment.appendChild(context.createElement('div')); tmp.innerHTML = '<div>&#160;</div>' + wrap[1] + html.replace(XHTML_TAG_REGEXP, ""<$1></$2>"") + wrap[2]; tmp.removeChild(tmp.firstChild); for (j=0, jj=tmp.childNodes.length; j<jj; ++j) nodes.push(tmp.childNodes[j]); return nodes; return jqLiteBuildFragment(html, context); if (isString(element) && element.charAt(0) != '<') { if (isString(element)) { var fragment = jqLite(document.createDocumentFragment()); fragment.append(this);function jqLiteDealoc(element){ jqLiteRemoveData(element); for ( var i = 0, children = element.childNodes || []; i < children.length; i++) { jqLiteDealoc(children[i]); var events = jqLiteExpandoStore(element, 'events'), handle = jqLiteExpandoStore(element, 'handle'); if (isUndefined(type)) { forEach(events, function(eventHandler, type) { removeEventListenerFn(element, type, eventHandler); }); if (isUndefined(fn)) { removeEventListenerFn(element, type, events[type]); delete events[type]; } else { arrayRemove(events[type] || [], fn); var expandoId = element[jqName], expandoStore = jqCache[expandoId]; delete jqCache[expandoId].data[name]; expandoStore.events.$destroy && expandoStore.handle({}, '$destroy'); element[jqName] = undefined; // ie does not allow deletion of attributes on elements.function jqLiteExpandoStore(element, key, value) { var expandoId = element[jqName], expandoStore = jqCache[expandoId || -1]; if (isDefined(value)) { if (!expandoStore) { element[jqName] = expandoId = jqNextId(); expandoStore = jqCache[expandoId] = {}; } expandoStore[key] = value; } else { return expandoStore && expandoStore[key]; var data = jqLiteExpandoStore(element, 'data'), isSetter = isDefined(value), keyDefined = !isSetter && isDefined(key), isSimpleGetter = keyDefined && !isObject(key); if (!data && !isSimpleGetter) { jqLiteExpandoStore(element, 'data', data = {}); } if (isSetter) { data[key] = value; } else { if (keyDefined) { if (isSimpleGetter) { // don't create data in this case. return data && data[key]; } else { extend(data, key); } return data; indexOf( "" "" + selector + "" "" ) > -1); elements = (!elements.nodeName && isDefined(elements.length) && !isWindow(elements)) ? elements : [ elements ]; for(var i=0; i < elements.length; i++) { root.push(elements[i]); return jqLiteInheritedData(element, '$' + (name || 'ngController' ) + 'Controller'); element = jqLite(element); if(element[0].nodeType == 9) { element = element.find('html'); while (element.length) { var node = element[0]; if ((value = element.data(names[i])) !== undefined) return value; element = jqLite(node.parentNode || (node.nodeType === 11 && node.host)); for (var i = 0, childNodes = element.childNodes; i < childNodes.length; i++) { jqLiteDealoc(childNodes[i]); } // check if document already is loaded if (document.readyState === 'complete'){ forEach(this, function(e){ value.push('' + e);}); BOOLEAN_ELEMENTS[uppercase(value)] = true; return booleanAttr && BOOLEAN_ELEMENTS[element.nodeName] && booleanAttr; return jqLite(element).data('$scope') || jqLiteInheritedData(element.parentNode || element, ['$isolateScope', '$scope']); return jqLite(element).data('$isolateScope') || jqLite(element).data('$isolateScopeNoTemplate'); removeAttr: function(element,name) { var val; if (msie <= 8) { // this is some IE specific weirdness that jQuery 1.6.4 does not sure why val = element.currentStyle && element.currentStyle[name]; if (val === '') val = 'auto'; } val = val || element.style[name]; if (msie <= 8) { // jquery weirdness :-/ val = (val === '') ? undefined : val; } return val; attr: function(element, name, value){ (element.attributes.getNamedItem(name)|| noop).specified) var NODE_TYPE_TEXT_PROPERTY = []; if (msie < 9) { NODE_TYPE_TEXT_PROPERTY[1] = 'innerText'; /** Element **/ NODE_TYPE_TEXT_PROPERTY[3] = 'nodeValue'; /** Text **/ } else { NODE_TYPE_TEXT_PROPERTY[1] = /** Element **/ NODE_TYPE_TEXT_PROPERTY[3] = 'textContent'; /** Text **/ } var textProp = NODE_TYPE_TEXT_PROPERTY[element.nodeType]; return textProp ? element[textProp] : ''; element[textProp] = value; if (nodeName_(element) === 'SELECT' && element.multiple) { forEach(element.options, function (option) { for (var i = 0, childNodes = element.childNodes; i < childNodes.length; i++) { jqLiteDealoc(childNodes[i]); }}, function(fn, name){ for (i = 0; i < this.length; i++) { var jj = (value === undefined) ? Math.min(this.length, 1) : this.length; for (i = 0; i < this.length; i++) { var eventHandler = function (event, type) { if (!event.preventDefault) { event.preventDefault = function() { event.returnValue = false; //ie }; } if (!event.stopPropagation) { event.stopPropagation = function() { event.cancelBubble = true; //ie }; } if (!event.target) { event.target = event.srcElement || document; } if (isUndefined(event.defaultPrevented)) { var prevent = event.preventDefault; event.preventDefault = function() { event.defaultPrevented = true; prevent.call(event); }; event.defaultPrevented = false; } return event.defaultPrevented || event.returnValue === false; var eventHandlersCopy = shallowCopy(events[type || event.type] || []); forEach(eventHandlersCopy, function(fn) { fn.call(element, event); }); // Remove monkey-patched methods (IE), // as they would cause memory leaks in IE8. if (msie <= 8) { // IE7/8 does not allow to delete property on native object event.preventDefault = null; event.stopPropagation = null; event.isDefaultPrevented = null; } else { // It shouldn't affect normal browsers (native methods are defined on prototype). delete event.preventDefault; delete event.stopPropagation; delete event.isDefaultPrevented; dealoc: jqLiteDealoc, on: function onFn(element, type, fn, unsupported){ var events = jqLiteExpandoStore(element, 'events'), handle = jqLiteExpandoStore(element, 'handle'); if (!events) jqLiteExpandoStore(element, 'events', events = {}); if (!handle) jqLiteExpandoStore(element, 'handle', handle = createEventHandler(element, events)); forEach(type.split(' '), function(type){ if (type == 'mouseenter' || type == 'mouseleave') { var contains = document.body.contains || document.body.compareDocumentPosition ? function( a, b ) { // jshint bitwise: false var adown = a.nodeType === 9 ? a.documentElement : a, bup = b && b.parentNode; return a === bup || !!( bup && bup.nodeType === 1 && ( adown.contains ? adown.contains( bup ) : a.compareDocumentPosition && a.compareDocumentPosition( bup ) & 16 )); } : function( a, b ) { if ( b ) { while ( (b = b.parentNode) ) { if ( b === a ) { return true; } } } return false; }; events[type] = []; var eventmap = { mouseleave : ""mouseout"", mouseenter : ""mouseover""}; onFn(element, eventmap[type], function(event) { if ( !related || (related !== target && !contains(target, related)) ){ addEventListenerFn(element, type, handle); events[type] = []; }); forEach(new JQLite(replaceNode), function(node){ forEach(element.childNodes, function(element){ if (element.nodeType === 1) forEach(new JQLite(node), function(child){ if (element.nodeType === 1 || element.nodeType === 11) { element.appendChild(child); } }); if (element.nodeType === 1) { forEach(new JQLite(node), function(child){ wrapNode = jqLite(wrapNode)[0]; remove: function(element) { jqLiteDealoc(element); var parent = element.parentNode; if (parent) parent.removeChild(element); forEach(new JQLite(newElement), function(node){ }); forEach(selector.split(' '), function(className){ return parent && parent.nodeType !== 11 ? parent : null; if (element.nextElementSibling) { return element.nextElementSibling; } // IE8 doesn't have nextElementSibling var elm = element.nextSibling; while (elm != null && elm.nodeType !== 1) { elm = elm.nextSibling; } return elm; triggerHandler: function(element, eventName, eventData) { var eventFns = (jqLiteExpandoStore(element, 'events') || {})[eventName]; eventData = eventData || []; var event = [{ preventDefault: noop, stopPropagation: noop }]; forEach(eventFns, function(fn) { fn.apply(element, event.concat(eventData)); });}, function(fn, name){ for(var i=0; i < this.length; i++) {function hashKey(obj) { var objType = typeof obj, key; if (objType == 'object' && obj !== null) { if (typeof (key = obj.$$hashKey) == 'function') { // must invoke on object to keep the right this } else if (key === undefined) { key = obj.$$hashKey = nextUid(); } else { key = obj; return objType + ':' + key;function HashMap(array){ this[hashKey(key)] = value; return this[hashKey(key)]; var value = this[key = hashKey(key)]; * @function * Creates an injector function that can be used for retrieving services as well as for * {@link angular.module}. The `ng` module must be explicitly added. * @returns {function()} Injector function. See {@link auto.$injector $injector}. * $injector.invoke(function($rootScope, $compile, $document){ * application has been bootstrapped. You can do this using extra `injector()` addedfunction annotate(fn) { if (typeof fn == 'function') { forEach(argDecl[1].split(FN_ARG_SPLIT), function(arg){ arg.replace(FN_ARG, function(all, underscore, name){ * @function * expect($injector.invoke(function($injector){ * }).toBe($injector); * can then be parsed and the function arguments can be extracted. *NOTE:* This does not work with * minification, and obfuscation tools since these tools change the argument names. * By adding a `$inject` property onto a function the injection parameters can be specified. * Allows the user to query if the particular service exist. * @param {string} Name of the service to query. * @returns {boolean} returns true if injector has given service. * Create a new instance of JS type. The method takes a constructor function invokes the new * operator and supplies all of the arguments to the constructor function as specified by the * @ngdoc objectfunction createInjector(modulesToLoad) { loadedModules = new HashMap(), createInternalInjector(providerCache, function() { createInternalInjector(instanceCache, function(servicename) { var provider = providerInjector.get(servicename + providerSuffix); return instanceInjector.invoke(provider.$get, provider); function factory(name, factoryFn) { return provider(name, { $get: factoryFn }); } function value(name, val) { return factory(name, valueFn(val)); } function loadModules(modulesToLoad){ var runBlocks = [], moduleFn, invokeQueue, i, ii; for(invokeQueue = moduleFn._invokeQueue, i = 0, ii = invokeQueue.length; i < ii; i++) { var invokeArgs = invokeQueue[i], provider = providerInjector.get(invokeArgs[0]); provider[invokeArgs[1]].apply(provider, invokeArgs[2]); } function getService(serviceName) { throw $injectorMinErr('cdep', 'Circular dependency found: {0}', path.join(' <- ')); return cache[serviceName] = factory(serviceName); function invoke(fn, self, locals){ $inject = annotate(fn), for(i = 0, length = $inject.length; i < length; i++) { : getService(key) if (!fn.$inject) { // this means that we must be an array. function instantiate(Type, locals) { var Constructor = function() {}, instance, returnedValue; Constructor.prototype = (isArray(Type) ? Type[Type.length - 1] : Type).prototype; instance = new Constructor(); returnedValue = invoke(Type, instance, locals); * @ngdoc service * @name $anchorScroll * @kind function * @requires $window * @requires $location * @requires $rootScope * When called, it checks current value of `$location.hash()` and scroll to related element, * according to rules specified in * [Html5 spec](http://dev.w3.org/html5/spec/Overview.html#the-indicated-part-of-the-document). * * It also watches the `$location.hash()` and scrolls whenever it changes to match any anchor. * This can be disabled by calling `$anchorScrollProvider.disableAutoScrolling()`. * * @example <example> <file name=""index.html""> <div id=""scrollArea"" ng-controller=""ScrollCtrl""> <a ng-click=""gotoBottom()"">Go to bottom</a> <a id=""bottom""></a> You're at the bottom! </div> </file> <file name=""script.js""> function ScrollCtrl($scope, $location, $anchorScroll) { $scope.gotoBottom = function (){ // set the location.hash to the id of // the element you wish to scroll to. $location.hash('bottom'); // call $anchorScroll() $anchorScroll(); }; } </file> <file name=""style.css""> #scrollArea { height: 350px; overflow: auto; } #bottom { display: block; margin-top: 2000px; } </file> </example> // helper function to get first anchor from a NodeList // can't use filter.filter, as it accepts only instances of Array // and IE can't convert NodeList to an array using [].slice // TODO(vojta): use filter if we change it to accept lists as well forEach(list, function(element) { if (!result && lowercase(element.nodeName) === 'a') result = element; if (!hash) $window.scrollTo(0, 0); else if ((elm = document.getElementById(hash))) elm.scrollIntoView(); else if ((elm = getFirstAnchor(document.getElementsByName(hash)))) elm.scrollIntoView(); else if (hash === 'top') $window.scrollTo(0, 0); function autoScrollWatchAction() { $rootScope.$evalAsync(scroll); if(arguments.length === 1) { this.$get = ['$timeout', '$$asyncCallback', function($timeout, $$asyncCallback) { function async(fn) { fn && $$asyncCallback(fn); * @function * @description Inserts the element into the DOM either after the `after` element or within * the `parent` element. Once complete, the done() callback will be fired (if provided). * @param {Function=} done callback function that will be called after the element has been * inserted into the DOM enter : function(element, parent, after, done) { if (after) { after.after(element); } else { if (!parent || !parent[0]) { parent = after.parent(); } parent.append(element); } async(done); * @function * @description Removes the element from the DOM. Once complete, the done() callback will be * fired (if provided). * @param {Function=} done callback function that will be called after the element has been * removed from the DOM leave : function(element, done) { async(done); * @function * either after the `after` element or inside of the `parent` element. Once complete, the * done() callback will be fired (if provided). * @param {Function=} done the callback function (if provided) that will be fired after the * element has been moved to its new position move : function(element, parent, after, done) { this.enter(element, parent, after, done); * @function * @description Adds the provided className CSS class value to the provided element. Once * complete, the done() callback will be fired (if provided). * @param {Function=} done the callback function (if provided) that will be fired after the * className value has been added to the element addClass : function(element, className, done) { className = isString(className) ? className : isArray(className) ? className.join(' ') : ''; forEach(element, function (element) { async(done); * @function * Once complete, the done() callback will be fired (if provided). * @param {Function=} done the callback function (if provided) that will be fired after the * className value has been removed from the element removeClass : function(element, className, done) { className = isString(className) ? className : isArray(className) ? className.join(' ') : ''; forEach(element, function (element) { async(done); * @function * Once complete, the done() callback will be fired (if provided). * @param {DOMElement} element the element which will it's CSS classes changed * @param {Function=} done the callback function (if provided) that will be fired after the * CSS classes have been set on the element setClass : function(element, add, remove, done) { forEach(element, function (element) { jqLiteAddClass(element, add); jqLiteRemoveClass(element, remove); }); async(done); enabled : noopfunction $$AsyncCallbackProvider(){ * @param {function()} XHR XMLHttpRequest constructor. * @param {object} $log console.log or an object with the same interface. while(outstandingRequestCallbacks.length) { forEach(pollFns, function(pollFn){ pollFn(); }); forEach(pollFns, function(pollFn){ pollFn(); }); var lastBrowserUrl = location.href, newLocation = null; * @param {boolean=} replace Should new url replace current history record ? self.url = function(url, replace) { if (lastBrowserUrl == url) return; if ($sniffer.history) { if (replace) history.replaceState(null, '', url); else { history.pushState(null, '', url); // Crazy Opera Bug: http://my.opera.com/community/forums/topic.dml?id=1185462 baseElement.attr('href', baseElement.attr('href')); } newLocation = url; } else { // - newLocation is a workaround for an IE7-9 issue with location.replace and location.href // methods not updating location.href synchronously. return newLocation || location.href.replace(/%27/g,""'""); newLocation = null; if (lastBrowserUrl == self.url()) return; listener(self.url()); if ($sniffer.history) jqLite(window).on('popstate', fireUrlChange); if ($sniffer.hashchange) jqLite(window).on('hashchange', fireUrlChange); // polling else self.addPollFn(fireUrlChange); /* global escape: false, unescape: false */ rawDocument.cookie = escape(name) + ""=;path="" + cookiePath + cookieLength = (rawDocument.cookie = escape(name) + '=' + escape(value) + $log.warn(""Cookie '""+ name + ""' possibly not set or overflowed because it was too large (""+ name = unescape(cookie.substring(0, index)); lastCookies[name] = unescape(cookie.substring(index + 1));function $BrowserProvider(){ function( $window, $log, $sniffer, $document){ $scope.cache.put(key, value); $scope.keys.push(key); * @function * @function * @function * @function * @function * @function * Get information about all the of the caches that have been created * the document, but it must be below the `ng-app` definition. * @function * replace: false, * as the order of execution on same `priority` is undefined). * can avoid this behavior using `=?` or `=?attr` in order to flag the property as optional. * pass data from the isolated scope via an expression and to the parent scope, this can be * * `$transclude` - A transclude linking function pre-bound to the correct transclusion scope. * The scope can be overridden by an optional first argument. * `function([scope], cloneLinkingFn)`. * * `^` - Locate the required controller by searching the element's parents. Throw an error if not found. * * `?^` - Attempt to locate the required controller by searching the element's parents or pass `null` to the * `link` fn if not found. * declaration style. If omitted, the default (attributes only) is used. * * `E` - Element name: `<my-directive></my-directive>` * #### `template` * replace the current element with the contents of the HTML. The replacement process * migrates all of the attributes / classes from the old element to the new one. See the * {@link guide/directive#creating-custom-directives_creating-directives_template-expanding-directive * Directives Guide} for an example. * You can specify `template` as a string representing the template or as a function which takes * two arguments `tElement` and `tAttrs` (described in the `compile` function api below) and * returns a string value representing the template. * Same as `template` but the template is loaded from the specified URL. Because * the template loading is asynchronous the compilation/linking is suspended until the template * is loaded. * api/ng.$sce#getTrustedResourceUrl $sce.getTrustedResourceUrl}. * #### `replace` * specify where the template should be inserted. Defaults to `false`. * * `true` - the template will replace the current element. * * `false` - the template will replace the contents of the current element. * compile the content of the element and make it available to the directive. * Typically used with {@link ng.directive:ngTransclude * ngTransclude}. The advantage of transclusion is that the linking function receives a * transclusion function which is pre-bound to the correct scope. In a typical setup the widget * creates an `isolate` scope, but the transclusion is not a child, but a sibling of the `isolate` * scope. This makes it possible for the widget to have private state, and the transclusion to * be bound to the parent (pre-`isolate`) scope. * * `true` - transclude the content of the directive. * * `'element'` - transclude the whole element including any directives defined at lower priority. * template transformation, it is not used often. Examples that require compile functions are * directives that transform template DOM, such as {@link * api/ng.directive:ngRepeat ngRepeat}, or load the contents * asynchronously, such as {@link ngRoute.directive:ngView ngView}. The * compile function takes the following arguments. * The scope can be overridden by an optional first argument. This is the same as the `$transclude` * parameter of directive controllers. * `function([scope], cloneLinkingFn)`. * * Executed after the child elements are linked. It is safe to do DOM transformation in the post-linking function. * <a name=""Attributes""></a> * Below is an example using `$compileProvider`. <example module=""compile""> angular.module('compile', [], function($compileProvider) { }) }); function Ctrl($scope) { } <div ng-controller=""Ctrl""> * @param {function(angular.Scope, cloneAttachFn=)} transclude function available to directives. * @returns {function(scope, cloneAttachFn=)} a link function which is used to bind template * @function COMMENT_DIRECTIVE_REGEXP = /^\s*directive\:\s*([\d\w\-_]+)\s+(.*)$/, CLASS_DIRECTIVE_REGEXP = /(([\d\w\-_]+)(?:\:([^;]+))?;?)/; * @function directive.restrict = directive.restrict || 'A'; * @function * The sanitization is a security measure aimed at prevent XSS attacks via html links. * @function '$injector', '$interpolate', '$exceptionHandler', '$http', '$templateCache', '$parse', function($injector, $interpolate, $exceptionHandler, $http, $templateCache, $parse, var Attributes = function(element, attr) { this.$attr = attr || {}; * @function $addClass : function(classVal) { if(classVal && classVal.length > 0) { * @function $removeClass : function(classVal) { if(classVal && classVal.length > 0) { * @function $updateClass : function(newClasses, oldClasses) { var toRemove = tokenDifference(oldClasses, newClasses); if(toAdd.length === 0) { $animate.removeClass(this.$$element, toRemove); } else if(toRemove.length === 0) { } else { $animate.setClass(this.$$element, toAdd, toRemove); var booleanKey = getBooleanAttrName(this.$$element[0], key), normalizedVal, // sanitize a[href] and img[src] values if ((nodeName === 'A' && key === 'href') || (nodeName === 'IMG' && key === 'src')) { $$observers && forEach($$observers[key], function(fn) { * @function * See the {@link guide/directive#Attributes Directives} guide for more info. * @returns {function()} the `fn` parameter. $$observers = (attrs.$$observers || (attrs.$$observers = {})), if (!listeners.$$inter) { return fn; forEach($compileNodes, function(node, index){ if (node.nodeType == 3 /* text node */ && node.nodeValue.match(/\S+/) /* non-empty */ ) { $compileNodes[index] = node = jqLite(node).wrap('<span></span>').parent()[0]; safeAddClass($compileNodes, 'ng-scope'); return function publicLinkFn(scope, cloneConnectFn, transcludeControllers){ // important!!: we must call our jqLite.clone() since the jQuery one is trying to be smart // and sometimes changes the structure of the DOM. var $linkNode = cloneConnectFn ? JQLitePrototype.clone.call($compileNodes) // IMPORTANT!!! : $compileNodes; forEach(transcludeControllers, function(instance, name) { $linkNode.data('$' + name + 'Controller', instance); }); // Attach scope only to non-text nodes. for(var i = 0, ii = $linkNode.length; i<ii; i++) { var node = $linkNode[i], nodeType = node.nodeType; if (nodeType === 1 /* element */ || nodeType === 9 /* document */) { $linkNode.eq(i).data('$scope', scope); if (compositeLinkFn) compositeLinkFn(scope, $linkNode, $linkNode); function safeAddClass($element, className) { try { $element.addClass(className); } catch(e) { // ignore, since it means that we are trying to set class on // SVG element, where class name is read-only. attrs, directives, nodeLinkFn, childNodes, childLinkFn, linkFnFound; safeAddClass(jqLite(nodeList[i]), 'ng-scope'); nodeLinkFn ? nodeLinkFn.transclude : transcludeFn); linkFns.push(nodeLinkFn, childLinkFn); linkFnFound = linkFnFound || nodeLinkFn || childLinkFn; function compositeLinkFn(scope, nodeList, $rootElement, boundTranscludeFn) { var nodeLinkFn, childLinkFn, node, $node, childScope, childTranscludeFn, i, ii, n; // copy nodeList so that linking doesn't break due to live list updates. var nodeListLength = nodeList.length, stableNodeList = new Array(nodeListLength); for (i = 0; i < nodeListLength; i++) { stableNodeList[i] = nodeList[i]; for(i = 0, n = 0, ii = linkFns.length; i < ii; n++) { node = stableNodeList[n]; $node = jqLite(node); $node.data('$scope', childScope); childTranscludeFn = nodeLinkFn.transclude; if (childTranscludeFn || (!boundTranscludeFn && transcludeFn)) { nodeLinkFn(childLinkFn, childScope, node, $rootElement, createBoundTranscludeFn(scope, childTranscludeFn || transcludeFn) ); nodeLinkFn(childLinkFn, childScope, node, $rootElement, boundTranscludeFn); childLinkFn(scope, node.childNodes, undefined, boundTranscludeFn); function createBoundTranscludeFn(scope, transcludeFn) { return function boundTranscludeFn(transcludedScope, cloneFn, controllers) { var scopeCreated = false; transcludedScope = scope.$new(); scopeCreated = true; var clone = transcludeFn(transcludedScope, cloneFn, controllers); if (scopeCreated) { clone.on('$destroy', bind(transcludedScope, transcludedScope.$destroy)); } return clone; switch(nodeType) { case 1: /* Element */ directiveNormalize(nodeName_(node).toLowerCase()), 'E', maxPriority, ignoreDirective); for (var attr, name, nName, ngAttrName, value, nAttrs = node.attributes, if (!msie || msie >= 8 || attr.specified) { name = attr.name; // support ngAttr attribute binding ngAttrName = directiveNormalize(name); if (NG_ATTR_BINDING.test(ngAttrName)) { name = snake_case(ngAttrName.substr(6), '-'); } var directiveNName = ngAttrName.replace(/(Start|End)$/, ''); nName = directiveNormalize(name.toLowerCase()); attrsMap[nName] = name; attrs[nName] = value = trim(attr.value); if (getBooleanAttrName(node, nName)) { attrs[nName] = true; // presence means true } addAttrInterpolateDirective(node, directives, value, nName); addDirective(directives, nName, 'A', maxPriority, ignoreDirective, attrStartName, attrEndName); case 3: /* Text Node */ case 8: /* Comment */ var startNode = node; if (node.nodeType == 1 /** Element **/) { for(var i = 0, ii = directives.length; i < ii; i++) { newScopeDirective = newScopeDirective || directive; assertNoDuplicate('new/isolated scope', newIsolateScopeDirective, directive, $compileNode); $template = groupScan(compileNode, attrStart, attrEnd); replaceWith(jqCollection, jqLite(sliceArgs($template)), compileNode); $template = jqLite(directiveValue); if ($template.length != 1 || compileNode.nodeType !== 1) { templateAttrs, jqCollection, childTranscludeFn, preLinkFns, postLinkFns, { nodeLinkFn.transclude = hasTranscludeDirective && childTranscludeFn; function getControllers(require, $element, elementControllers) { while((value = require.charAt(0)) == '^' || value == '?') { require = require.substr(1); if (value == '^') { retrievalMethod = 'inheritedData'; } optional = optional || value == '?'; value = elementControllers[require]; value = value || $element[retrievalMethod]('$' + require + 'Controller'); return value; value.push(getControllers(require, $element, elementControllers)); var attrs, $element, i, ii, linkFn, controller, isolateScope, elementControllers = {}, transcludeFn; attrs = shallowCopy(templateAttrs, new Attributes(jqLite(linkNode), templateAttrs.$attr)); $element = attrs.$$element; var LOCAL_REGEXP = /^\s*([@=&])(\??)\s*(\w*)\s*$/; var $linkNode = jqLite(linkNode); if (templateDirective && (templateDirective === newIsolateScopeDirective.$$originalDirective)) { $linkNode.data('$isolateScope', isolateScope) ; } else { $linkNode.data('$isolateScopeNoTemplate', isolateScope); } safeAddClass($linkNode, 'ng-isolate-scope'); forEach(newIsolateScopeDirective.scope, function(definition, scopeName) { var match = definition.match(LOCAL_REGEXP) || [], attrName = match[3] || scopeName, optional = (match[2] == '?'), mode = match[1], // @, =, or & lastValue, parentGet, parentSet, compare; isolateScope.$$isolateBindings[scopeName] = mode + attrName; switch (mode) { case '@': attrs.$observe(attrName, function(value) { isolateScope[scopeName] = value; }); attrs.$$observers[attrName].$$scope = scope; if( attrs[attrName] ) { // If the attribute has been provided then we trigger an interpolation to ensure // the value is there for use in the link fn isolateScope[scopeName] = $interpolate(attrs[attrName])(scope); } break; case '=': if (optional && !attrs[attrName]) { return; } parentGet = $parse(attrs[attrName]); if (parentGet.literal) { compare = equals; } else { compare = function(a,b) { return a === b; }; } parentSet = parentGet.assign || function() { // reset the change, or we will throw this exception on every $digest lastValue = isolateScope[scopeName] = parentGet(scope); throw $compileMinErr('nonassign', ""Expression '{0}' used with directive '{1}' is non-assignable!"", attrs[attrName], newIsolateScopeDirective.name); }; lastValue = isolateScope[scopeName] = parentGet(scope); isolateScope.$watch(function parentValueWatch() { var parentValue = parentGet(scope); if (!compare(parentValue, isolateScope[scopeName])) { // we are out of sync and need to copy if (!compare(parentValue, lastValue)) { // parent changed and it has precedence isolateScope[scopeName] = parentValue; } else { // if the parent can be assigned then do so parentSet(scope, parentValue = isolateScope[scopeName]); } } return lastValue = parentValue; }, null, parentGet.literal); break; case '&': parentGet = $parse(attrs[attrName]); isolateScope[scopeName] = function(locals) { return parentGet(scope, locals); }; break; default: throw $compileMinErr('iscp', ""Invalid isolate scope definition for directive '{0}'."" + "" Definition: {... {1}: '{2}' ...}"", newIsolateScopeDirective.name, scopeName, definition); } }); transcludeFn = boundTranscludeFn && controllersBoundTransclude; controllerInstance = $controller(controller, locals); $element.data('$' + directive.name + 'Controller', controllerInstance); if (directive.controllerAs) { locals.$scope[directive.controllerAs] = controllerInstance; } // PRELINKING for(i = 0, ii = preLinkFns.length; i < ii; i++) { try { linkFn = preLinkFns[i]; linkFn(linkFn.isolateScope ? isolateScope : scope, $element, attrs, linkFn.require && getControllers(linkFn.require, $element, elementControllers), transcludeFn); } catch (e) { $exceptionHandler(e, startingTag($element)); for(i = postLinkFns.length - 1; i >= 0; i--) { try { linkFn = postLinkFns[i]; linkFn(linkFn.isolateScope ? isolateScope : scope, $element, attrs, linkFn.require && getControllers(linkFn.require, $element, elementControllers), transcludeFn); } catch (e) { $exceptionHandler(e, startingTag($element)); } function controllersBoundTransclude(scope, cloneAttachFn) { // no scope passed if (arguments.length < 2) { return boundTranscludeFn(scope, cloneAttachFn, transcludeControllers); for(var directive, directives = $injector.get(name + Suffix), i = 0, ii = directives.length; i<ii; i++) { if ( (maxPriority === undefined || maxPriority > directive.priority) && } catch(e) { $exceptionHandler(e); } if (src[key]) { : origAsyncDirective.templateUrl; $http.get($sce.getTrustedResourceUrl(templateUrl), {cache: $templateCache}). success(function(content) { $template = jqLite(content); if ($template.length != 1 || compileNode.nodeType !== 1) { while(linkQueue.length) { if (afterTemplateNodeLinkFn.transclude) { childBoundTranscludeFn = createBoundTranscludeFn(scope, afterTemplateNodeLinkFn.transclude); }). error(function(response, code, headers, config) { throw $compileMinErr('tpload', 'Failed to load template: {0}', config.url); linkQueue.push(scope); linkQueue.push(node); linkQueue.push(rootElement); linkQueue.push(boundTranscludeFn); afterTemplateNodeLinkFn(afterTemplateChildLinkFn, scope, node, rootElement, boundTranscludeFn); compile: valueFn(function textInterpolateLinkFn(scope, node) { var parent = node.parent(), bindings = parent.data('$binding') || []; bindings.push(interpolateFn); safeAddClass(parent.data('$binding', bindings), 'ng-binding'); scope.$watch(interpolateFn, function interpolateFnWatchAction(value) { node[0].nodeValue = value; }); }) (tag == ""FORM"" && attrNormalizedName == ""action"") || (tag != ""IMG"" && (attrNormalizedName == ""src"" || function addAttrInterpolateDirective(node, directives, value, name) { var interpolateFn = $interpolate(value, true); if (name === ""multiple"" && nodeName_(node) === ""SELECT"") { // we need to interpolate again, in case the attribute value has been updated // (e.g. by another directive's compile function) interpolateFn = $interpolate(attr[name], true, getTrustedContext(node, name)); // TODO(i): this should likely be attr.$set(name, iterpolateFn(scope) so that we reset the // actual attr value if(name === 'class' && newValue != oldValue) { for(i = 0, ii = $rootElement.length; i < ii; i++) { newNode[jqLite.expando] = firstElementToRemove[jqLite.expando];var PREFIX_REGEXP = /^(x[\:\-_]|data[\:\-_])/i; * All of these will become 'myDirective': * my:Directive * my-directive * x-my-directive * data-my:directive * * Also there is special case for Moz prefix starting with upper case letter. * @returns {object} A map of DOM element attribute names to the normalized name. This is * needed to do reverse lookup from normalized name back to actual name. * @function){}){} for(var i = 0; i < tokens1.length; i++) { for(var j = 0; j < tokens2.length; j++) { if(token == tokens2[j]) continue outer; * * check `window[constructor]` on the global `window` object return function(expression, locals) { if(isString(expression)) { identifier = match[3]; : getter(locals.$scope, constructor, true) || getter($window, constructor, true); instance = $injector.instantiate(expression, locals); if (identifier) { if (!(locals && typeof locals.$scope == 'object')) { throw minErr('$controller')('noscp', ""Cannot export controller '{0}' as '{1}'! No $scope object provided via `locals`."", constructor || expression.name, identifier); locals.$scope[identifier] = instance; <example> <div ng-controller=""MainCtrl""> function MainCtrl($scope, $document) { $scope.title = $document[0].title; $scope.windowTitle = angular.element(window.document)[0].title; }function $DocumentProvider(){ this.$get = ['$window', function(window){ * angular.module('exceptionOverride', []).factory('$exceptionHandler', function () { * return function (exception, cause) { var parsed = {}, key, val, i; if (parsed[key]) { parsed[key] += ', ' + val; } else { parsed[key] = val; } return headersObj[lowercase(name)] || null; * @param {function(string=)} headers Http headers getter fn.function transformData(data, headers, fns) { return fns(data, headers); data = fn(data, headers); var JSON_START = /^\s*(\[|\{[^\{])/, JSON_END = /[\}\]]\s*$/, PROTECTION_PREFIX = /^\)\]\}',?\n/, CONTENT_TYPE_APPLICATION_JSON = {'Content-Type': 'application/json;charset=utf-8'}; transformResponse: [function(data) { if (isString(data)) { // strip json vulnerability protection prefix data = data.replace(PROTECTION_PREFIX, ''); if (JSON_START.test(data) && JSON_END.test(data)) data = fromJson(data); } return data; }], return isObject(d) && !isFile(d) && !isBlob(d) ? toJson(d) : d; post: copy(CONTENT_TYPE_APPLICATION_JSON), put: copy(CONTENT_TYPE_APPLICATION_JSON), patch: copy(CONTENT_TYPE_APPLICATION_JSON) * Are ordered by request, i.e. they are applied in the same order as the * array, on request, but reverse order, on response. */ var interceptorFactories = this.interceptors = []; * For historical reasons, response interceptors are ordered by the order in which * they are applied to the response. (This is the opposite of interceptorFactories) */ var responseInterceptorFactories = this.responseInterceptors = []; forEach(responseInterceptorFactories, function(interceptorFactory, index) { var responseFn = isString(interceptorFactory) ? $injector.get(interceptorFactory) : $injector.invoke(interceptorFactory); /** * Response interceptors go before ""around"" interceptors (no real reason, just * had to pick one.) But they are already reversed, so we can't use unshift, hence * the splice. */ reversedInterceptors.splice(index, 0, { response: function(response) { return responseFn($q.when(response)); }, responseError: function(response) { return responseFn($q.reject(response)); } }); }); * # General usage * $http({method: 'GET', url: '/someUrl'}). * # Writing Unit Tests that use $http * # Shortcut methods * # Setting HTTP Headers * # Transforming Requests and Responses * Both requests and responses can be transformed using transform functions. By default, Angular * applies these transformations: * Request transformations: * Response transformations: * To globally augment or override the default transforms, modify the * `$httpProvider.defaults.transformRequest` and `$httpProvider.defaults.transformResponse` * properties. These properties are by default an array of transform functions, which allows you * to `push` or `unshift` a new transformation function into the transformation chain. You can * also decide to completely override any default transformations by assigning your * transformation functions to these properties directly without the array wrapper. These defaults * are again available on the $http factory at run-time, which may be useful if you have run-time * services you wish to be involved in your transformations. * Similarly, to locally override the request/response transforms, augment the * `transformRequest` and/or `transformResponse` properties of the configuration object passed * # Caching * {@link ng.$http#properties_defaults `$http.defaults.cache`} property. All requests who set * # Interceptors * * `request`: interceptors get called with http `config` object. The function is free to * modify the `config` or create a new one. The function needs to return the `config` * directly or as a promise. * modify the `response` or create a new one. The function needs to return the `response` * directly or as a promise. * return config || $q.when(config); * return response || $q.when(response); * # Response interceptors (DEPRECATED) * * Before you start creating interceptors, be sure to understand the * {@link ng.$q $q and deferred/promise APIs}. * * For purposes of global error handling, authentication or any kind of synchronous or * asynchronous preprocessing of received responses, it is desirable to be able to intercept * responses for http requests before they are handed over to the application code that * initiated these requests. The response interceptors leverage the {@link ng.$q * promise apis} to fulfil this need for both synchronous and asynchronous preprocessing. * * The interceptors are service factories that are registered with the $httpProvider by * adding them to the `$httpProvider.responseInterceptors` array. The factory is called and * injected with dependencies (if specified) and returns the interceptor — a function that * takes a {@link ng.$q promise} and returns the original or a new promise. * * ```js * // register the interceptor as a service * $provide.factory('myHttpInterceptor', function($q, dependency1, dependency2) { * return function(promise) { * return promise.then(function(response) { * // do something on success * return response; * }, function(response) { * // do something on error * if (canRecover(response)) { * return responseOrNewPromise * } * return $q.reject(response); * }); * } * }); * * $httpProvider.responseInterceptors.push('myHttpInterceptor'); * * * // register the interceptor via an anonymous factory * $httpProvider.responseInterceptors.push(function($q, dependency1, dependency2) { * return function(promise) { * // same as above * } * }); * ``` * * * # Security Considerations * ## JSON Vulnerability Protection * ## Cross Site Request Forgery (XSRF) Protection * authentication cookie with a [salt](https://en.wikipedia.org/wiki/Salt_(cryptography)) * `{function(data, headersGetter)|Array.<function(data, headersGetter)>}` – * response body and headers and returns its transformed (typically deserialized) version. * - **withCredentials** - `{boolean}` - whether to to set the `withCredentials` flag on the * XHR object. See [requests with credentials]https://developer.mozilla.org/en/http_access_control#section_5<example> <div ng-controller=""FetchCtrl""> 'http://angularjs.org/greet.php?callback=JSON_CALLBACK&name=Super%20Hero')""> ng-click=""updateModel('JSONP', 'http://angularjs.org/doesntexist&callback=JSON_CALLBACK')""> function FetchCtrl($scope, $http, $templateCache) { $scope.method = 'GET'; $scope.url = 'http-hello.html'; $scope.fetch = function() { $scope.code = null; $scope.response = null; $http({method: $scope.method, url: $scope.url, cache: $templateCache}). success(function(data, status) { $scope.status = status; $scope.data = data; }). error(function(data, status) { $scope.data = data || ""Request failed""; $scope.status = status; }); }; $scope.updateModel = function(method, url) { $scope.method = method; $scope.url = url; }; } it('should make a JSONP request to angularjs.org', function() { sampleJsonpBtn.click(); fetchBtn.click(); expect(status.getText()).toMatch('200'); expect(data.getText()).toMatch(/Super Hero!/); }); var config = { }; var headers = mergeHeaders(requestConfig); extend(config, requestConfig); config.headers = headers; var xsrfValue = urlIsSameOrigin(config.url) ? $browser.cookies()[config.xsrfCookieName || defaults.xsrfCookieName] : undefined; if (xsrfValue) { headers[(config.xsrfHeaderName || defaults.xsrfHeaderName)] = xsrfValue; } headers = config.headers; var reqData = transformData(config.data, headersGetter(headers), config.transformRequest); if (isUndefined(config.data)) { return sendReq(config, reqData, headers).then(transformResponse, transformResponse); while(chain.length) { var resp = extend({}, response, { data: transformData(response.data, response.headers, config.transformResponse) }); // execute if header value is function execHeaders(defHeaders); execHeaders(reqHeaders); return reqHeaders; function execHeaders(headers) { var headerContent; forEach(headers, function(headerFn, header) { if (isFunction(headerFn)) { headerContent = headerFn(); if (headerContent != null) { headers[header] = headerContent; } else { delete headers[header]; } } }); } * Should contain `JSON_CALLBACK` string. createShortMethodsWithData('post', 'put'); function sendReq(config, reqData, reqHeaders) { if ((config.cache || defaults.cache) && config.cache !== false && config.method == 'GET') { if (cachedResp.then) { cachedResp.then(removePendingReq, removePendingReq); return cachedResp; resolvePromise(cachedResp[1], cachedResp[0], copy(cachedResp[2]), cachedResp[3]); // if we won't have the response in cache, send the request to the backend resolvePromise(response, status, headersString, statusText); if (!$rootScope.$$phase) $rootScope.$apply(); statusText : statusText var idx = indexOf($http.pendingRequests, config); if (!params) return url; var parts = []; forEachSorted(params, function(value, key) { if (value === null || isUndefined(value)) return; if (!isArray(value)) value = [value]; forEach(value, function(v) { if (isObject(v)) { v = toJson(v); } parts.push(encodeUriQuery(key) + '=' + encodeUriQuery(v)); }); }); if(parts.length > 0) { url += ((url.indexOf('?') == -1) ? '?' : '&') + parts.join('&'); return url; } function createXhr(method) { //if IE and the method is not RFC2616 compliant, or if XMLHttpRequest //is not available, try getting an ActiveXObject. Otherwise, use XMLHttpRequest //if it is available if (msie <= 8 && (!method.match(/^(get|post|head|put|delete|options)$/i) || !window.XMLHttpRequest)) { return new window.ActiveXObject(""Microsoft.XMLHTTP""); } else if (window.XMLHttpRequest) { return new window.XMLHttpRequest(); } throw minErr('$httpBackend')('noxhr', ""This browser does not support XMLHttpRequest.""); var ABORTED = -1; var status; function() { if (callbacks[callbackId].data) { completeRequest(callback, 200, callbacks[callbackId].data); } else { completeRequest(callback, status || -2); } callbacks[callbackId] = angular.noop; var xhr = createXhr(method); // In IE6 and 7, this might be called synchronously when xhr.send below is called and the // response is in the cache. the promise api will ensure that to the app code the api is // always async xhr.onreadystatechange = function() { // onreadystatechange might get called multiple times with readyState === 4 on mobile webkit caused by // xhrs that are resolved while the app is in the background (see #5426). // since calling completeRequest sets the `xhr` variable to null, we just check if it's not null before // continuing // // we can't set xhr.onreadystatechange to undefined or delete it because that breaks IE8 (method=PATCH) and // Safari respectively. if (xhr && xhr.readyState == 4) { var responseHeaders = null, response = null; if(status !== ABORTED) { responseHeaders = xhr.getAllResponseHeaders(); // responseText is the old-school way of retrieving response (supported by IE8 & 9) // response/responseType properties were introduced in XHR Level2 spec (supported by IE10) response = ('response' in xhr) ? xhr.response : xhr.responseText; } completeRequest(callback, status || xhr.status, response, responseHeaders, xhr.statusText || ''); } else if (timeout && timeout.then) { status = ABORTED; timeoutId && $browserDefer.cancel(timeoutId); jsonpDone = xhr = null; // fix status code when it is 0 (0 status is undocumented). // Occurs when accessing file resources or on Android 4.1 stock browser // while retrieving files from application cache. if (status === 0) { status = response ? 200 : urlResolve(url).protocol == 'file' ? 404 : 0; // normalize IE bug (http://bugs.jquery.com/ticket/1450) status = status === 1223 ? 204 : status; statusText = statusText || ''; function jsonpReq(url, done) { var script = rawDocument.createElement('script'), doneWrapper = function() { script.onreadystatechange = script.onload = script.onerror = null; rawDocument.body.removeChild(script); if (done) done(); }; script.type = 'text/javascript'; if (msie && msie <= 8) { script.onreadystatechange = function() { if (/loaded|complete/.test(script.readyState)) { doneWrapper(); }; } else { script.onload = script.onerror = function() { doneWrapper(); }; } return doneWrapper; * @function customInterpolationApp.controller('DemoController', function DemoController() { this.startSymbol = function(value){ this.endSymbol = function(value){ endSymbolLength = endSymbol.length; * @function * * `context`: an object against which any expressions embedded in the strings are evaluated * against. * function $interpolate(text, mustHaveExpression, trustedContext) { parts = [], length = text.length, hasInterpolation = false, fn, concat = []; while(index < length) { if ( ((startIndex = text.indexOf(startSymbol, index)) != -1) && ((endIndex = text.indexOf(endSymbol, startIndex + startSymbolLength)) != -1) ) { (index != startIndex) && parts.push(text.substring(index, startIndex)); parts.push(fn = $parse(exp = text.substring(startIndex + startSymbolLength, endIndex))); fn.exp = exp; hasInterpolation = true; // we did not find anything, so we have to add the remainder to the parts array (index != length) && parts.push(text.substring(index)); index = length; if (!(length = parts.length)) { // we added, nothing, must have been an empty string. parts.push(''); length = 1; } if (trustedContext && parts.length > 1) { if (!mustHaveExpression || hasInterpolation) { concat.length = length; fn = function(context) { try { for(var i = 0, ii = length, part; i<ii; i++) { if (typeof (part = parts[i]) == 'function') { part = part(context); if (trustedContext) { part = $sce.getTrusted(trustedContext, part); } else { part = $sce.valueOf(part); } if (part === null || isUndefined(part)) { part = ''; } else if (typeof part != 'string') { part = toJson(part); } } concat[i] = part; } return concat.join(''); catch(err) { var newErr = $interpolateMinErr('interr', ""Can't interpolate: {0}\n{1}"", text, err.toString()); $exceptionHandler(newErr); } fn.exp = text; fn.parts = parts; return fn; * Use {@link ng.$interpolateProvider#startSymbol $interpolateProvider#startSymbol} to change * Use {@link ng.$interpolateProvider#endSymbol $interpolateProvider#endSymbol} to change this.$get = ['$rootScope', '$window', '$q', function($rootScope, $window, $q) { * <example module=""time""> * <file name=""index.html""> * <script> * function Ctrl2($scope,$interval) { * $scope.format = 'M/d/yy h:mm:ss a'; * $scope.blood_1 = 100; * $scope.blood_2 = 120; * * var stop; * $scope.fight = function() { * // Don't start a new fight if we are already fighting * if ( angular.isDefined(stop) ) return; * * stop = $interval(function() { * if ($scope.blood_1 > 0 && $scope.blood_2 > 0) { * $scope.blood_1 = $scope.blood_1 - 3; * $scope.blood_2 = $scope.blood_2 - 4; * } else { * $scope.stopFight(); * } * }, 100); * }; * * $scope.stopFight = function() { * if (angular.isDefined(stop)) { * $interval.cancel(stop); * stop = undefined; * } * }; * * $scope.resetFight = function() { * } * $scope.$on('$destroy', function() { * // Make sure that the interval is destroyed too * $scope.stopFight(); * }); * } * angular.module('time', []) * // Register the 'myCurrentTime' directive factory method. * // We inject $interval and dateFilter service since the factory method is DI. * .directive('myCurrentTime', function($interval, dateFilter) { * stopTime; // so that we can cancel the time updates * // to prevent updating time ofter the DOM element was removed. * element.bind('$destroy', function() { * }); * </script> * <div> * <div ng-controller=""Ctrl2""> * Date format: <input ng-model=""format""> <hr/> * Current time is: <span my-current-time=""format""></span> * <hr/> * Blood 1 : <font color='red'>{{blood_1}}</font> * Blood 2 : <font color='red'>{{blood_2}}</font> * <button type=""button"" data-ng-click=""fight()"">Fight</button> * <button type=""button"" data-ng-click=""stopFight()"">StopFight</button> * <button type=""button"" data-ng-click=""resetFight()"">resetFight</button> * </div> * </file> deferred = $q.defer(), promise = deferred.promise, skipApply = (isDefined(invokeApply) && !invokeApply); clearInterval(promise.$$intervalId);function $LocaleProvider(){ short: 'M/d/yy h:mm a',function parseAbsoluteUrl(absoluteUrl, locationObj, appBase) { var parsedUrl = urlResolve(absoluteUrl, appBase);function parseAppUrl(relativeUrl, locationObj, appBase) { var match = urlResolve(relativeUrl, appBase); parseAbsoluteUrl(appBase, this, appBase); * @param {string} newAbsoluteUrl HTML5 url parseAppUrl(pathUrl, this, appBase); this.$$rewrite = function(url) { var appUrl, prevAppUrl; if ( (appUrl = beginsWith(appBase, url)) !== undefined ) { prevAppUrl = appUrl; if ( (appUrl = beginsWith(basePrefix, appUrl)) !== undefined ) { return appBaseNoFile + (beginsWith('/', appUrl) || appUrl); } else { return appBase + prevAppUrl; } } else if ( (appUrl = beginsWith(appBaseNoFile, url)) !== undefined ) { return appBaseNoFile + appUrl; } else if (appBaseNoFile == url + '/') { return appBaseNoFile; parseAbsoluteUrl(appBase, this, appBase); var withoutHashUrl = withoutBaseUrl.charAt(0) == '#' ? beginsWith(hashPrefix, withoutBaseUrl) : (this.$$html5) ? withoutBaseUrl : ''; if (!isString(withoutHashUrl)) { throw $locationMinErr('ihshprfx', 'Invalid url ""{0}"", missing hash prefix ""{1}"".', url, hashPrefix); parseAppUrl(withoutHashUrl, this, appBase); function removeWindowsDriveName (path, url, base) { var windowsFilePathExp = /^\/?.*?:(\/.*)/; /* * The input URL intentionally contains a * first path segment that ends with a colon. */ this.$$rewrite = function(url) { if(stripHash(appBase) == stripHash(url)) { return url; this.$$rewrite = function(url) { if ( appBase == stripHash(url) ) { return url; } else if ( (appUrl = beginsWith(appBaseNoFile, url)) ) { return appBase + hashPrefix + appUrl; } else if ( appBaseNoFile === url + '/') { return appBaseNoFile;LocationHashbangInHtml5Url.prototype = LocationHashbangUrl.prototype = LocationHtml5Url.prototype = { * Has any change been replacing ? * @param {string=} replace The path that will be changed url: function(url, replace) { if (match[1]) this.path(decodeURIComponent(match[1])); if (match[2] || match[1]) this.search(match[3] || ''); this.hash(match[5] || '', replace); * @param {string=} path New path * hash object. Hash object may contain an array of values, which will be decoded as duplicates in * the url. * @param {(string|Array<string>)=} paramValue If `search` is a string, then `paramValue` will override only a * single search parameter. If `paramValue` is an array, it will set the parameter as a * comma-separated value. If `paramValue` is `null`, the parameter will be deleted. * @return {string} search if (isString(search)) { * @param {string=} hash New hash fragment hash: locationGetterSetter('$$hash', identity),function $LocationProvider(){ html5Mode = false; * @ngdoc property * @ngdoc property * @param {boolean=} mode Use HTML5 strategy if available. * @returns {*} current value if used as getter or itself (chaining) if used as setter if (isDefined(mode)) { html5Mode = mode; * Broadcasted before a URL will change. This change can be prevented by calling * {@link ng.$location#events_$locationChangeSuccess $locationChangeSuccess} is fired. this.$get = ['$rootScope', '$browser', '$sniffer', '$rootElement', function( $rootScope, $browser, $sniffer, $rootElement) { if (html5Mode) { $location.$$parse($location.$$rewrite(initialUrl)); if (event.ctrlKey || event.metaKey || event.which == 2) return; while (lowercase(elm[0].nodeName) !== 'a') { var rewrittenUrl = $location.$$rewrite(absHref); if (absHref && !elm.attr('target') && rewrittenUrl && !event.isDefaultPrevented()) { event.preventDefault(); if (rewrittenUrl != $browser.url()) { $location.$$parse(rewrittenUrl); $rootScope.$apply(); // hack to work around FF6 bug 684208 when scenario runner clicks on links window.angular['ff-684208-preventDefault'] = true; // update $location when $browser url changes $browser.onUrlChange(function(newUrl) { if ($location.absUrl() != newUrl) { $rootScope.$evalAsync(function() { var oldUrl = $location.absUrl(); $location.$$parse(newUrl); if ($rootScope.$broadcast('$locationChangeStart', newUrl, oldUrl).defaultPrevented) { $location.$$parse(oldUrl); $browser.url(oldUrl); } else { afterLocationChange(oldUrl); } }); if (!$rootScope.$$phase) $rootScope.$digest(); } var changeCounter = 0; var oldUrl = $browser.url(); if (!changeCounter || oldUrl != $location.absUrl()) { changeCounter++; if ($rootScope.$broadcast('$locationChangeStart', $location.absUrl(), oldUrl). defaultPrevented) { $browser.url($location.absUrl(), currentReplace); afterLocationChange(oldUrl); return changeCounter; function afterLocationChange(oldUrl) { $rootScope.$broadcast('$locationChangeSuccess', $location.absUrl(), oldUrl); <example> function LogCtrl($scope, $log) { $scope.$log = $log; $scope.message = 'Hello World!'; } <div ng-controller=""LogCtrl"">function $LogProvider(){ * @ngdoc property this.$get = ['$window', function($window){ debug: (function () {var promiseWarningCache = {}; var promiseWarning;// access to $scope and locals. However, one can obtain the ability to execute arbitrary JS code by// {}.toString.constructor(alert(""evil JS code"")) // // We want to prevent this type of access. For the sake of performance, during the lexing phase we // disallow any ""dotted"" access to any member named ""constructor"". // // For reflective calls (a[b]) we check that the value of the lookup is not the Function constructor // while evaluating the expression, which is a stronger but more expensive test. Since reflective // calls are expensive anyway, this is not such a big deal compared to static dereferencing.// sensitive JavaScript or browser apis on Scope. Exposing such objects on a Scope is never a good// A developer could foil the name check by aliasing the Function constructor under a different // name on the scope. // if (name === ""constructor"") { 'Referencing ""constructor"" field in Angular expressions is disallowed! Expression: {0}', fullExpression); obj.document && obj.location && obj.alert && obj.setInterval) {var OPERATORS = { /* jshint bitwise : false */ 'null':function(){return null;}, 'true':function(){return true;}, 'false':function(){return false;}, undefined:noop, '+':function(self, locals, a,b){ return isDefined(b)?b:undefined;}, '-':function(self, locals, a,b){ return (isDefined(a)?a:0)-(isDefined(b)?b:0); '*':function(self, locals, a,b){return a(self, locals)*b(self, locals);}, '/':function(self, locals, a,b){return a(self, locals)/b(self, locals);}, '%':function(self, locals, a,b){return a(self, locals)%b(self, locals);}, '^':function(self, locals, a,b){return a(self, locals)^b(self, locals);}, '=':noop, '===':function(self, locals, a, b){return a(self, locals)===b(self, locals);}, '!==':function(self, locals, a, b){return a(self, locals)!==b(self, locals);}, '==':function(self, locals, a,b){return a(self, locals)==b(self, locals);}, '!=':function(self, locals, a,b){return a(self, locals)!=b(self, locals);}, '<':function(self, locals, a,b){return a(self, locals)<b(self, locals);}, '>':function(self, locals, a,b){return a(self, locals)>b(self, locals);}, '<=':function(self, locals, a,b){return a(self, locals)<=b(self, locals);}, '>=':function(self, locals, a,b){return a(self, locals)>=b(self, locals);}, '&&':function(self, locals, a,b){return a(self, locals)&&b(self, locals);}, '||':function(self, locals, a,b){return a(self, locals)||b(self, locals);}, '&':function(self, locals, a,b){return a(self, locals)&b(self, locals);}, // '|':function(self, locals, a,b){return a|b;}, '|':function(self, locals, a,b){return b(self, locals)(self, locals, a(self, locals));}, '!':function(self, locals, a){return !a(self, locals);} }; /* jshint bitwise: true */var Lexer = function (options) { lex: function (text) { this.ch = undefined; this.lastCh = ':'; // can start regexp var token; var json = []; this.ch = this.text.charAt(this.index); if (this.is('""\'')) { this.readString(this.ch); } else if (this.isNumber(this.ch) || this.is('.') && this.isNumber(this.peek())) { } else if (this.isIdent(this.ch)) { // identifiers can only be if the preceding char was a { or , if (this.was('{,') && json[0] === '{' && (token = this.tokens[this.tokens.length - 1])) { token.json = token.text.indexOf('.') === -1; } } else if (this.is('(){}[].,;:?')) { this.tokens.push({ index: this.index, text: this.ch, json: (this.was(':[,') && this.is('{[')) || this.is('}]:,') }); if (this.is('{[')) json.unshift(this.ch); if (this.is('}]')) json.shift(); } else if (this.isWhitespace(this.ch)) { continue; var ch2 = this.ch + this.peek(); var fn = OPERATORS[this.ch]; var fn2 = OPERATORS[ch2]; var fn3 = OPERATORS[ch3]; if (fn3) { this.tokens.push({index: this.index, text: ch3, fn: fn3}); this.index += 3; } else if (fn2) { this.tokens.push({index: this.index, text: ch2, fn: fn2}); this.index += 2; } else if (fn) { this.tokens.push({ index: this.index, text: this.ch, fn: fn, json: (this.was('[,:') && this.is('+-')) }); this.index += 1; this.lastCh = this.ch; is: function(chars) { return chars.indexOf(this.ch) !== -1; }, was: function(chars) { return chars.indexOf(this.lastCh) !== -1; return ('0' <= ch && ch <= '9'); number = 1 * number; json: true, fn: function() { return number; } var parser = this; var ident = ''; var lastDot, peekIndex, methodName, ch; ch = this.text.charAt(this.index); if (ch === '.' || this.isIdent(ch) || this.isNumber(ch)) { if (ch === '.') lastDot = this.index; ident += ch; } else { //check if this is not a method invocation and if it is back out to last dot if (lastDot) { peekIndex = this.index; while (peekIndex < this.text.length) { ch = this.text.charAt(peekIndex); if (ch === '(') { methodName = ident.substr(lastDot - start + 1); ident = ident.substr(0, lastDot - start); this.index = peekIndex; break; } if (this.isWhitespace(ch)) { peekIndex++; } else { break; } } } var token = { text: ident }; // OPERATORS is our own object so we don't need to use special hasOwnPropertyFn if (OPERATORS.hasOwnProperty(ident)) { token.fn = OPERATORS[ident]; token.json = OPERATORS[ident]; } else { var getter = getterFn(ident, this.options, this.text); token.fn = extend(function(self, locals) { return (getter(self, locals)); }, { assign: function(self, value) { return setter(self, ident, value, parser.text, parser.options); } }); } this.tokens.push(token); if (methodName) { this.tokens.push({ index:lastDot, text: '.', json: false }); this.tokens.push({ index: lastDot + 1, text: methodName, json: false }); } if (rep) { string += rep; } else { string += ch; } string: string, json: true, fn: function() { return string; }var Parser = function (lexer, $filter, options) {Parser.ZERO = extend(function () { parse: function (text, json) { //TODO(i): strip all the obsolte json stuff from this file this.json = json; if (json) { // The extra level of aliasing is here, just in case the lexer misses something, so that // we prevent any accidental execution in JSON. this.assignment = this.logicalOR; this.functionCall = this.fieldAccess = this.objectIndex = this.filterChain = function() { this.throwError('is not valid json', {text: text, index: 0}); }; } var value = json ? this.primary() : this.statements(); primary: function () { var token = this.expect(); primary = token.fn; if (!primary) { this.throwError('not a primary expression', token); } if (token.json) { primary.constant = true; primary.literal = true; } if (this.tokens.length > 0) { var token = this.tokens[0]; expect: function(e1, e2, e3, e4){ if (this.json && !token.json) { this.throwError('is not valid json', token); } consume: function(e1){ if (!this.expect(e1)) { unaryFn: function(fn, right) { return extend(function(self, locals) { constant:right.constant ternaryFn: function(left, middle, right){ return extend(function(self, locals){ return left(self, locals) ? middle(self, locals) : right(self, locals); }, { constant: left.constant && middle.constant && right.constant }); }, binaryFn: function(left, fn, right) { return extend(function(self, locals) { constant:left.constant && right.constant : function(self, locals) { for (var i = 0; i < statements.length; i++) { var statement = statements[i]; if (statement) { value = statement(self, locals); } while (true) { if ((token = this.expect('|'))) { left = this.binaryFn(left, token.fn, this.filter()); } else { return left; } filter: function() { var token = this.expect(); var fn = this.$filter(token.text); var argsFn = []; while (true) { if ((token = this.expect(':'))) { } else { var fnInvoke = function(self, locals, input) { var args = [input]; for (var i = 0; i < argsFn.length; i++) { args.push(argsFn[i](self, locals)); } return fn.apply(self, args); }; return function() { return fnInvoke; }; return function(scope, locals) { }; middle = this.ternary(); if ((token = this.expect(':'))) { return this.ternaryFn(left, middle, this.ternary()); } else { this.throwError('expected :', token); } else { return left; while (true) { if ((token = this.expect('||'))) { left = this.binaryFn(left, token.fn, this.logicalAND()); } else { return left; } if ((token = this.expect('&&'))) { left = this.binaryFn(left, token.fn, this.logicalAND()); if ((token = this.expect('==','!=','===','!=='))) { left = this.binaryFn(left, token.fn, this.equality()); if ((token = this.expect('<', '>', '<=', '>='))) { left = this.binaryFn(left, token.fn, this.relational()); left = this.binaryFn(left, token.fn, this.multiplicative()); left = this.binaryFn(left, token.fn, this.unary()); return this.binaryFn(Parser.ZERO, token.fn, this.unary()); return this.unaryFn(token.fn, this.unary()); var parser = this; var field = this.expect().text; var getter = getterFn(field, this.options, this.text); return extend(function(scope, locals, self) { return getter(self || object(scope, locals)); return setter(object(scope, locals), field, value, parser.text, parser.options); var parser = this; return extend(function(self, locals) { v, p; v = ensureSafeObject(o[i], parser.text); if (v && v.then && parser.options.unwrapPromises) { p = v; if (!('$$v' in v)) { p.$$v = undefined; p.then(function(val) { p.$$v = val; }); } v = v.$$v; } var key = indexFn(self, locals); var safe = ensureSafeObject(obj(self, locals), parser.text); return safe[key] = value; functionCall: function(fn, contextGetter) { var parser = this; return function(scope, locals) { var args = []; var context = contextGetter ? contextGetter(scope, locals) : scope; for (var i = 0; i < argsFn.length; i++) { args.push(argsFn[i](scope, locals)); var fnPtr = fn(scope, locals, context) || noop; ensureSafeObject(context, parser.text); ensureSafeObject(fnPtr, parser.text); // IE stupidity! (IE doesn't have apply for some native functions) var v = fnPtr.apply ? fnPtr.apply(context, args) : fnPtr(args[0], args[1], args[2], args[3], args[4]); return ensureSafeObject(v, parser.text); }; arrayDeclaration: function () { var allConstant = true; var elementFn = this.expression(); elementFns.push(elementFn); if (!elementFn.constant) { allConstant = false; } return extend(function(self, locals) { for (var i = 0; i < elementFns.length; i++) { constant: allConstant object: function () { var keyValues = []; var allConstant = true; var token = this.expect(), key = token.string || token.text; this.consume(':'); var value = this.expression(); keyValues.push({key: key, value: value}); if (!value.constant) { allConstant = false; return extend(function(self, locals) { for (var i = 0; i < keyValues.length; i++) { var keyValue = keyValues[i]; object[keyValue.key] = keyValue.value(self, locals); constant: allConstantfunction setter(obj, path, setValue, fullExp, options) { //needed? options = options || {}; var propertyObj = obj[key]; if (obj.then && options.unwrapPromises) { promiseWarning(fullExp); if (!(""$$v"" in obj)) { (function(promise) { promise.then(function(val) { promise.$$v = val; }); } )(obj); } if (obj.$$v === undefined) { obj.$$v = {}; } obj = obj.$$v; }var getterFnCache = {};function cspSafeGetterFn(key0, key1, key2, key3, key4, fullExp, options) { return !options.unwrapPromises ? function cspSafeGetter(scope, locals) { var pathVal = (locals && locals.hasOwnProperty(key0)) ? locals : scope; if (pathVal == null) return pathVal; pathVal = pathVal[key0]; if (!key1) return pathVal; if (pathVal == null) return undefined; pathVal = pathVal[key1]; if (!key2) return pathVal; if (pathVal == null) return undefined; pathVal = pathVal[key2]; if (!key3) return pathVal; if (pathVal == null) return undefined; pathVal = pathVal[key3]; if (!key4) return pathVal; if (pathVal == null) return undefined; pathVal = pathVal[key4]; return pathVal; } : function cspSafePromiseEnabledGetter(scope, locals) { var pathVal = (locals && locals.hasOwnProperty(key0)) ? locals : scope, promise; if (pathVal == null) return pathVal; pathVal = pathVal[key0]; if (pathVal && pathVal.then) { promiseWarning(fullExp); if (!(""$$v"" in pathVal)) { promise = pathVal; promise.$$v = undefined; promise.then(function(val) { promise.$$v = val; }); } pathVal = pathVal.$$v; } if (!key1) return pathVal; if (pathVal == null) return undefined; pathVal = pathVal[key1]; if (pathVal && pathVal.then) { promiseWarning(fullExp); if (!(""$$v"" in pathVal)) { promise = pathVal; promise.$$v = undefined; promise.then(function(val) { promise.$$v = val; }); } pathVal = pathVal.$$v; } if (!key2) return pathVal; if (pathVal == null) return undefined; pathVal = pathVal[key2]; if (pathVal && pathVal.then) { promiseWarning(fullExp); if (!(""$$v"" in pathVal)) { promise = pathVal; promise.$$v = undefined; promise.then(function(val) { promise.$$v = val; }); } pathVal = pathVal.$$v; } if (!key3) return pathVal; if (pathVal == null) return undefined; pathVal = pathVal[key3]; if (pathVal && pathVal.then) { promiseWarning(fullExp); if (!(""$$v"" in pathVal)) { promise = pathVal; promise.$$v = undefined; promise.then(function(val) { promise.$$v = val; }); } pathVal = pathVal.$$v; } if (!key4) return pathVal; if (pathVal == null) return undefined; pathVal = pathVal[key4]; if (pathVal && pathVal.then) { promiseWarning(fullExp); if (!(""$$v"" in pathVal)) { promise = pathVal; promise.$$v = undefined; promise.then(function(val) { promise.$$v = val; }); } pathVal = pathVal.$$v; } return pathVal; }; } function simpleGetterFn1(key0, fullExp) { ensureSafeMemberName(key0, fullExp); return function simpleGetterFn1(scope, locals) { if (scope == null) return undefined; return ((locals && locals.hasOwnProperty(key0)) ? locals : scope)[key0];function simpleGetterFn2(key0, key1, fullExp) { ensureSafeMemberName(key0, fullExp); ensureSafeMemberName(key1, fullExp); return function simpleGetterFn2(scope, locals) { if (scope == null) return undefined; scope = ((locals && locals.hasOwnProperty(key0)) ? locals : scope)[key0]; return scope == null ? undefined : scope[key1]; // Check whether the cache has this getter already. // We can use hasOwnProperty directly on the cache because we ensure, // see below, that the cache never stores a path called 'hasOwnProperty' if (getterFnCache.hasOwnProperty(path)) { return getterFnCache[path]; } pathKeysLength = pathKeys.length, fn; // When we have only 1 or 2 tokens, use optimized special case closures. if (!options.unwrapPromises && pathKeysLength === 1) { fn = simpleGetterFn1(pathKeys[0], fullExp); } else if (!options.unwrapPromises && pathKeysLength === 2) { fn = simpleGetterFn2(pathKeys[0], pathKeys[1], fullExp); } else if (options.csp) { fn = cspSafeGetterFn(pathKeys[0], pathKeys[1], pathKeys[2], pathKeys[3], pathKeys[4], fullExp, options); fn = function(scope, locals) { pathKeys[i++], fullExp, options)(scope, locals); var code = 'var p;\n'; code += 'if(s == null) return undefined;\n' + 's='+ (index : '((k&&k.hasOwnProperty(""' + key + '""))?k:s)') + '[""' + key + '""]' + ';\n' + (options.unwrapPromises ? 'if (s && s.then) {\n' + ' pw(""' + fullExp.replace(/([""\r\n])/g, '\\$1') + '"");\n' + ' if (!(""$$v"" in s)) {\n' + ' p=s;\n' + ' p.$$v = undefined;\n' + ' p.then(function(v) {p.$$v=v;});\n' + '}\n' + ' s=s.$$v\n' + '}\n' : ''); var evaledFnGetter = new Function('s', 'k', 'pw', code); // s=scope, k=locals, pw=promiseWarning fn = options.unwrapPromises ? function(scope, locals) { return evaledFnGetter(scope, locals, promiseWarning); } : evaledFnGetter; // Only cache the value if it's not going to mess up the cache object // This is more performant that using Object.prototype.hasOwnProperty.call if (path !== 'hasOwnProperty') { getterFnCache[path] = fn; } * @function var cache = {}; var $parseOptions = { csp: false, unwrapPromises: false, logPromiseWarnings: true }; /** * @deprecated Promise unwrapping via $parse is deprecated and will be removed in the future. * * @ngdoc method * @name $parseProvider#unwrapPromises * @description * * **This feature is deprecated, see deprecation notes below for more info** * * If set to true (default is false), $parse will unwrap promises automatically when a promise is * found at any part of the expression. In other words, if set to true, the expression will always * result in a non-promise value. * * While the promise is unresolved, it's treated as undefined, but once resolved and fulfilled, * the fulfillment value is used in place of the promise while evaluating the expression. * * **Deprecation notice** * * This is a feature that didn't prove to be wildly useful or popular, primarily because of the * dichotomy between data access in templates (accessed as raw values) and controller code * (accessed as promises). * * In most code we ended up resolving promises manually in controllers anyway and thus unifying * the model access there. * * Other downsides of automatic promise unwrapping: * * - when building components it's often desirable to receive the raw promises * - adds complexity and slows down expression evaluation * - makes expression code pre-generation unattractive due to the amount of code that needs to be * generated * - makes IDE auto-completion and tool support hard * * **Warning Logs** * * If the unwrapping is enabled, Angular will log a warning about each expression that unwraps a * promise (to reduce the noise, each expression is logged only once). To disable this logging use * `$parseProvider.logPromiseWarnings(false)` api. * * * @param {boolean=} value New value. * @returns {boolean|self} Returns the current setting when used as getter and self if used as * setter. */ this.unwrapPromises = function(value) { if (isDefined(value)) { $parseOptions.unwrapPromises = !!value; return this; } else { return $parseOptions.unwrapPromises; }; /** * @deprecated Promise unwrapping via $parse is deprecated and will be removed in the future. * * @ngdoc method * @name $parseProvider#logPromiseWarnings * @description * * Controls whether Angular should log a warning on any encounter of a promise in an expression. * * The default is set to `true`. * * This setting applies only if `$parseProvider.unwrapPromises` setting is set to true as well. * * @param {boolean=} value New value. * @returns {boolean|self} Returns the current setting when used as getter and self if used as * setter. */ this.logPromiseWarnings = function(value) { if (isDefined(value)) { $parseOptions.logPromiseWarnings = value; return this; } else { return $parseOptions.logPromiseWarnings; } }; this.$get = ['$filter', '$sniffer', '$log', function($filter, $sniffer, $log) { $parseOptions.csp = $sniffer.csp; promiseWarning = function promiseWarningFn(fullExp) { if (!$parseOptions.logPromiseWarnings || promiseWarningCache.hasOwnProperty(fullExp)) return; promiseWarningCache[fullExp] = true; $log.warn('[$parse] Promise found in the expression `' + fullExp + '`. ' + 'Automatic unwrapping of promises in Angular expressions is deprecated.'); }; return function(exp) { var parsedExpression; if (cache.hasOwnProperty(exp)) { return cache[exp]; var lexer = new Lexer($parseOptions); var parser = new Parser(lexer, $filter, $parseOptions); parsedExpression = parser.parse(exp, false); if (exp !== 'hasOwnProperty') { // Only cache the value if it's not going to mess up the cache object // This is more performant that using Object.prototype.hasOwnProperty.call cache[exp] = parsedExpression; } return parsedExpression; return exp; return noop; * A promise/deferred implementation inspired by [Kris Kowal's Q](https://github.com/kriskowal/q). * // for the purpose of this example let's assume that variables `$q`, `scope` and `okToGreet` * // since this fn executes async in a future turn of the event loop, we need to wrap * // our code into an $apply call so that the model changes are properly observed. * scope.$apply(function() { * deferred.notify('About to greet ' + name + '.'); * if (okToGreet(name)) { * deferred.resolve('Hello, ' + name + '!'); * } else { * deferred.reject('Greeting ' + name + ' is not allowed.'); * } * }); * * `notifyCallback` method. The promise can not be resolved or rejected from the notifyCallback * - `finally(callback)` – allows you to observe either the fulfillment or rejection of a promise, * Because `finally` is a reserved word in JavaScript and reserved keywords are not supported as * property names by ES3, you'll need to invoke the method like `promise['finally'](callback)` to * make your code IE8 and Android 2.x compatible. * * @param {function(Function)} nextTick Function for executing functions in the next turn. * @name $q#defer * @function var pending = [], value, deferred; deferred = { resolve: function(val) { if (pending) { var callbacks = pending; pending = undefined; value = ref(val); if (callbacks.length) { nextTick(function() { var callback; for (var i = 0, ii = callbacks.length; i < ii; i++) { callback = callbacks[i]; value.then(callback[0], callback[1], callback[2]); } }); } } }, reject: function(reason) { deferred.resolve(createInternalRejectedPromise(reason)); }, notify: function(progress) { if (pending) { var callbacks = pending; if (pending.length) { nextTick(function() { var callback; for (var i = 0, ii = callbacks.length; i < ii; i++) { callback = callbacks[i]; callback[2](progress); } }); } } }, promise: { then: function(callback, errback, progressback) { var result = defer(); var wrappedCallback = function(value) { try { result.resolve((isFunction(callback) ? callback : defaultCallback)(value)); } catch(e) { result.reject(e); exceptionHandler(e); } }; var wrappedErrback = function(reason) { try { result.resolve((isFunction(errback) ? errback : defaultErrback)(reason)); } catch(e) { result.reject(e); exceptionHandler(e); } }; var wrappedProgressback = function(progress) { try { result.notify((isFunction(progressback) ? progressback : defaultCallback)(progress)); } catch(e) { exceptionHandler(e); } }; if (pending) { pending.push([wrappedCallback, wrappedErrback, wrappedProgressback]); } else { value.then(wrappedCallback, wrappedErrback, wrappedProgressback); } return result.promise; }, ""catch"": function(callback) { return this.then(null, callback); }, ""finally"": function(callback) { function makePromise(value, resolved) { var result = defer(); if (resolved) { result.resolve(value); } else { result.reject(value); } return result.promise; } function handleCallback(value, isResolved) { var callbackOutput = null; try { callbackOutput = (callback ||defaultCallback)(); } catch(e) { return makePromise(e, false); } if (callbackOutput && isFunction(callbackOutput.then)) { return callbackOutput.then(function() { return makePromise(value, isResolved); }, function(error) { return makePromise(error, false); }); } else { return makePromise(value, isResolved); } } return this.then(function(value) { return handleCallback(value, true); }, function(error) { return handleCallback(error, false); }); } } }; return deferred; var ref = function(value) { if (value && isFunction(value.then)) return value; return { then: function(callback) { var result = defer(); result.resolve(callback(value)); return result.promise; }; * @function var result = defer(); var createInternalRejectedPromise = function(reason) { return { then: function(callback, errback) { var result = defer(); nextTick(function() { try { result.resolve((isFunction(errback) ? errback : defaultErrback)(reason)); } catch(e) { result.reject(e); exceptionHandler(e); } }); return result.promise; } }; * @function var when = function(value, callback, errback, progressback) { var result = defer(), done; var wrappedCallback = function(value) { try { return (isFunction(callback) ? callback : defaultCallback)(value); } catch (e) { exceptionHandler(e); return reject(e); } }; var wrappedErrback = function(reason) { try { return (isFunction(errback) ? errback : defaultErrback)(reason); } catch (e) { exceptionHandler(e); return reject(e); } }; var wrappedProgressback = function(progress) { try { return (isFunction(progressback) ? progressback : defaultCallback)(progress); } catch (e) { exceptionHandler(e); } }; nextTick(function() { ref(value).then(function(value) { if (done) return; done = true; result.resolve(ref(value).then(wrappedCallback, wrappedErrback, wrappedProgressback)); }, function(reason) { if (done) return; done = true; result.resolve(wrappedErrback(reason)); }, function(progress) { if (done) return; result.notify(wrappedProgressback(progress)); }); }); return result.promise; function defaultCallback(value) { return value; } function defaultErrback(reason) { return reject(reason); } * @function var deferred = defer(), ref(promise).then(function(value) { return { defer: defer, reject: reject, when: when, all: allfunction $$RAFProvider(){ //rAF $window.webkitRequestAnimationFrame || $window.mozRequestAnimationFrame; $window.mozCancelAnimationFrame || * items to the array at the beginning (shift) instead of at the end (push)function $RootScopeProvider(){ function( $injector, $exceptionHandler, $parse, $browser) { child.name = ""World""; this['this'] = this.$root = this; this.$$asyncQueue = []; this.$$postDigestQueue = []; this.$$isolateBindings = {}; * @returns {number} Unique scope ID (monotonically increasing alphanumeric sequence) useful for * debugging. * @function * The parent scope will propagate the {@link ng.$rootScope.Scope#$digest $digest()} and * {@link ng.$rootScope.Scope#$digest $digest()} events. The scope can be removed from the * scope hierarchy using {@link ng.$rootScope.Scope#$destroy $destroy()}. $new: function(isolate) { var ChildScope, child; // ensure that there is just one async queue per $rootScope and its children child.$$asyncQueue = this.$$asyncQueue; child.$$postDigestQueue = this.$$postDigestQueue; ChildScope = function() {}; // should be anonymous; This is so that when the minifier munges // the name it does not become random set of chars. This will then show up as class // name in the web inspector. ChildScope.prototype = this; child = new ChildScope(); child.$id = nextUid(); child['this'] = child; child.$$listeners = {}; child.$$listenerCount = {}; child.$parent = this; child.$$watchers = child.$$nextSibling = child.$$childHead = child.$$childTail = null; child.$$prevSibling = this.$$childTail; if (this.$$childHead) { this.$$childTail.$$nextSibling = child; this.$$childTail = child; this.$$childHead = this.$$childTail = child; * @function * see below). The inequality is determined according to * {@link angular.equals} function. To save the value of the object for later comparison, * the {@link angular.copy} function is used. It also means that watching complex options * will have adverse memory and performance implications. * The example below contains an illustration of using a function as your $watch listener // no variable change expect(scope.counter).toEqual(0); expect(scope.counter).toEqual(1); // Using a listener function // This is the listener function // This is the change handler * @param {(function()|string)=} listener Callback called whenever the return value of * the `watchExpression` changes. * - `string`: Evaluated as {@link guide/expression expression} * - `function(newValue, oldValue, scope)`: called with current and previous values as * parameters. * get = compileToFn(watchExp, 'watch'), // in the case user pass string, we need to compile it, do we really need this ? var listenFn = compileToFn(listener || noop, 'listener'); watcher.fn = function(newVal, oldVal, scope) {listenFn(scope);}; } if (typeof watchExp == 'string' && get.constant) { var originalFn = watcher.fn; watcher.fn = function(newVal, oldVal, scope) { originalFn.call(this, newVal, oldVal, scope); arrayRemove(array, watcher); }; return function() { * @function var objGetter = $parse(obj); function $watchCollectionWatch() { newValue = objGetter(self); var newLength, key; var bothNaN = (oldValue[i] !== oldValue[i]) && (newValue[i] !== newValue[i]); if (!bothNaN && (oldValue[i] !== newValue[i])) { oldValue[i] = newValue[i]; if (oldValue.hasOwnProperty(key)) { if (oldValue[key] !== newValue[key]) { oldValue[key] = newValue[key]; oldValue[key] = newValue[key]; for(key in oldValue) { if (oldValue.hasOwnProperty(key) && !newValue.hasOwnProperty(key)) { return this.$watch($watchCollectionWatch, $watchCollectionAction); * @function * a {@link ng.$compileProvider#directive directives}), which will force a `$digest()`. // no variable change expect(scope.counter).toEqual(0); expect(scope.counter).toEqual(1); asyncQueue = this.$$asyncQueue, postDigestQueue = this.$$postDigestQueue, while(asyncQueue.length) { asyncTask.scope.$eval(asyncTask.expression); clearPhase(); : (typeof value == 'number' && typeof last == 'number' watch.last = watch.eq ? copy(value) : value; logMsg = (isFunction(watch.exp)) ? 'fn: ' + (watch.exp.name || watch.exp.toString()) : watch.exp; logMsg += '; newVal: ' + toJson(value) + '; oldVal: ' + toJson(last); watchLog[logIdx].push(logMsg); clearPhase(); while(current !== target && !(next = current.$$nextSibling)) { if((dirty || asyncQueue.length) && !(ttl--)) { TTL, toJson(watchLog)); while(postDigestQueue.length) { * @function forEach(this.$$listenerCount, bind(null, decrementListenerCount, this)); this.$$childTail = this.$root = null; // don't reset these to null in case some async task tries to register a listener/watch/task this.$$listeners = {}; this.$$watchers = this.$$asyncQueue = this.$$postDigestQueue = []; // prevent NPEs since these methods have references to properties we nulled out this.$destroy = this.$digest = this.$apply = noop; this.$on = this.$watch = function() { return noop; }; * @function * @function $evalAsync: function(expr) { if (!$rootScope.$$phase && !$rootScope.$$asyncQueue.length) { if ($rootScope.$$asyncQueue.length) { this.$$asyncQueue.push({scope: this, expression: expr}); $$postDigest : function(fn) { this.$$postDigestQueue.push(fn); * @function * @function * - `currentScope` - `{Scope}`: the current scope which is handling the event. namedListeners[indexOf(namedListeners, listener)] = null; decrementListenerCount(self, 1, name); * @function for (i=0, length=namedListeners.length; i<length; i++) { if (stopPropagation) return event; * @function }, listenerArgs = concat([event], arguments, 1), for (i=0, length = listeners.length; i<length; i++) { } catch(e) { while(current !== target && !(next = current.$$nextSibling)) { function compileToFn(exp, name) { var fn = $parse(exp); assertArgFn(fn, name); return fn; } imgSrcSanitizationWhitelist = /^\s*(https?|ftp|file):|data:image\//; // NOTE: urlResolve() doesn't support IE < 8 so we don't sanitize for that case. if (!msie || msie >= 8 ) { normalizedVal = urlResolve(uri).href; if (normalizedVal !== '' && !normalizedVal.match(regex)) { return 'unsafe:'+normalizedVal; }// Copied from: // http://docs.closure-library.googlecode.com/git/closure_goog_string_string.js.source.html#line962 // Prereq: s is a string. function escapeForRegexp(s) { return s.replace(/([-()\[\]{}+?*.$\^|,:#<!\\])/g, '\\$1'). replace(/\x08/g, '\\x08'); } * @function * <pre class=""prettyprint""> * angular.module('myApp', []).config(function($sceDelegateProvider) { * $sceDelegateProvider.resourceUrlWhitelist([ * // Allow same origin resource loads. * 'self', * // Allow loading from our assets domain. Notice the difference between * and **. * 'http://srv*.assets.example.com/**']); * // The blacklist overrides the whitelist so the open redirect here is blocked. * $sceDelegateProvider.resourceUrlBlacklist([ * 'http://myapp.example.com/clickThru**']); * }); * </pre> * @function this.resourceUrlWhitelist = function (value) { * @function this.resourceUrlBlacklist = function (value) { * @function * Note: When enabled (the default), IE8 in quirks mode is not supported. In this mode, IE8 allows * <pre class=""prettyprint""> * <input ng-model=""userHtml""> * <div ng-bind-html=""userHtml""> * </pre> * ng.$sce#parse $sce.parseAs} rather than `$parse` to watch attribute bindings, which performs the * <pre class=""prettyprint""> * var ngBindHtmlDirective = ['$sce', function($sce) { * return function(scope, element, attr) { * scope.$watch($sce.parseAsHtml(attr.ngBindHtml), function(value) { * element.html(value || ''); * }); * }; * }]; * </pre> * ## This feels like too much overhead for the developer? * | `$sce.HTML` | For HTML that's safe to source into the application. The {@link ng.directive:ngBindHtml ngBindHtml} directive uses this context for bindings. | * not have been the intention.) It's usage at the very end of the path is ok. (e.g. * @example <example module=""mySceApp"" deps=""angular-sanitize.js""> <file name=""index.html""> <div ng-controller=""myAppController as myCtrl""> <i ng-bind-html=""myCtrl.explicitlyTrustedHtml"" id=""explicitlyTrustedHtml""></i><br><br> <b>User comments</b><br> By default, HTML that isn't explicitly trusted (e.g. Alice's comment) is sanitized when $sanitize is available. If $sanitize isn't available, this results in an error instead of an exploit. <div class=""well""> <div ng-repeat=""userComment in myCtrl.userComments""> <b>{{userComment.name}}</b>: <span ng-bind-html=""userComment.htmlComment"" class=""htmlComment""></span> <br> </div> </div> </div> </file> <file name=""script.js""> var mySceApp = angular.module('mySceApp', ['ngSanitize']); mySceApp.controller(""myAppController"", function myAppController($http, $templateCache, $sce) { var self = this; $http.get(""test_data.json"", {cache: $templateCache}).success(function(userComments) { self.userComments = userComments; }); self.explicitlyTrustedHtml = $sce.trustAsHtml( '<span onmouseover=""this.textContent=&quot;Explicitly trusted HTML bypasses ' + 'sanitization.&quot;"">Hover over this text.</span>'); }); </file> <file name=""test_data.json""> [ { ""name"": ""Alice"", ""htmlComment"": ""<span onmouseover='this.textContent=\""PWN3D!\""'>Is <i>anyone</i> reading this?</span>"" }, { ""name"": ""Bob"", ""htmlComment"": ""<i>Yes!</i> Am I the only other one?"" } ] </file> <file name=""protractor.js"" type=""protractor""> describe('SCE doc demo', function() { it('should sanitize untrusted values', function() { expect(element(by.css('.htmlComment')).getInnerHtml()) .toBe('<span>Is <i>anyone</i> reading this?</span>'); }); it('should NOT sanitize explicitly trusted values', function() { expect(element(by.id('explicitlyTrustedHtml')).getInnerHtml()).toBe( '<span onmouseover=""this.textContent=&quot;Explicitly trusted HTML bypasses ' + 'sanitization.&quot;"">Hover over this text.</span>'); }); }); </file> </example> * <pre class=""prettyprint""> * angular.module('myAppWithSceDisabledmyApp', []).config(function($sceProvider) { * // Completely disable SCE. For demonstration purposes only! * // Do not use in new projects. * $sceProvider.enabled(false); * }); * </pre> * @function this.enabled = function (value) { this.$get = ['$parse', '$sniffer', '$sceDelegate', function( $parse, $sniffer, $sceDelegate) { // Prereq: Ensure that we're not running in IE8 quirks mode. In that mode, IE allows if (enabled && $sniffer.msie && $sniffer.msieDocumentMode < 8) { 'Strict Contextual Escaping does not support Internet Explorer version < 9 in quirks ' + var sce = copy(SCE_CONTEXTS); * @function sce.isEnabled = function () { * @name $sce#parse return function sceParseAsTrusted(self, locals) { return sce.getTrusted(type, parsed(self, locals)); }; * {@link ng.$sce#parse `$sce.parseAs($sce.HTML, value)`} * {@link ng.$sce#parse `$sce.parseAs($sce.CSS, value)`} * {@link ng.$sce#parse `$sce.parseAs($sce.URL, value)`} * {@link ng.$sce#parse `$sce.parseAs($sce.RESOURCE_URL, value)`} * {@link ng.$sce#parse `$sce.parseAs($sce.JS, value)`} forEach(SCE_CONTEXTS, function (enumValue, name) { sce[camelCase(""parse_as_"" + lName)] = function (expr) { sce[camelCase(""get_trusted_"" + lName)] = function (value) { sce[camelCase(""trust_as_"" + lName)] = function (value) { * @property {boolean} hashchange Does the browser support hashchange event ? documentMode = document.documentMode, vendorRegex = /^(Moz|webkit|O|ms)(?=[A-Z])/, for(var prop in bodyStyle) { if(match = vendorRegex.exec(prop)) { if(!vendorPrefix) { if (android && (!transitions||!animations)) { hashchange: 'onhashchange' in $window && // IE8 compatible mode lies (!documentMode || documentMode > 7), if (event == 'input' && msie == 9) return false; transitions : transitions, animations : animations, android: android, msie : msie, msieDocumentMode: documentMode this.$get = ['$rootScope', '$browser', '$q', '$exceptionHandler', function($rootScope, $browser, $q, $exceptionHandler) { var deferred = $q.defer(), skipApply = (isDefined(invokeApply) && !invokeApply), } catch(e) {var originUrl = urlResolve(window.location.href, true); * @functionfunction urlResolve(url, base) { <example> function Ctrl($scope, $window) { $scope.greeting = 'Hello, World!'; $scope.doGreeting = function(greeting) { }; } <div ng-controller=""Ctrl"">function $WindowProvider(){/** * @ngdoc method * @name $filterProvider#register * @description * Register filter factory function. * * @param {String} name Name of the filter. * @param {Function} fn The filter factory function which is injectable. */ * @function */ * @name $controllerProvider#register if(isObject(name)) { * @function * as described above. * - `function(value)`: A predicate function can be used to write arbitrary filters. The function is * called for each element of `array`. The final result is an array of those elements that * the predicate returned true for. * - `function(actual, expected)`: * The function will be given the object value and the predicate value to compare and * should return true if the item should be included in filtered result. * - `true`: A shorthand for `function(actual, expected) { return angular.equals(expected, actual)}`. * this is essentially strict comparison of expected and actual. * - `false|undefined`: A short hand for a function which will look for a substring match in case * insensitive way. var comparatorType = typeof(comparator), predicates = []; predicates.check = function(value) { for (var j = 0; j < predicates.length; j++) { if(!predicates[j](value)) { return false; } } return true; }; if (comparatorType !== 'function') { if (comparatorType === 'boolean' && comparator) { comparator = function(obj, text) { return angular.equals(obj, text); }; } else { comparator = function(obj, text) { if (obj && text && typeof obj === 'object' && typeof text === 'object') { for (var objKey in obj) { if (objKey.charAt(0) !== '$' && hasOwnProperty.call(obj, objKey) && comparator(obj[objKey], text[objKey])) { return true; } } return false; } text = (''+text).toLowerCase(); return (''+obj).toLowerCase().indexOf(text) > -1; }; } } var search = function(obj, text){ if (typeof text == 'string' && text.charAt(0) === '!') { return !search(obj, text.substr(1)); } switch (typeof obj) { case ""boolean"": case ""number"": case ""string"": return comparator(obj, text); case ""object"": switch (typeof text) { case ""object"": return comparator(obj, text); default: for ( var objKey in obj) { if (objKey.charAt(0) !== '$' && search(obj[objKey], text)) { return true; } } break; } return false; case ""array"": for ( var i = 0; i < obj.length; i++) { if (search(obj[i], text)) { return true; } } return false; default: return false; } }; case ""boolean"": case ""number"": case ""string"": // Set up expression object and fall through expression = {$:expression}; // jshint -W086 case ""object"": // jshint +W086 for (var key in expression) { (function(path) { if (typeof expression[path] == 'undefined') return; predicates.push(function(value) { return search(path == '$' ? value : (value && value[path]), expression[path]); }); })(key); } break; predicates.push(expression); var filtered = []; for ( var j = 0; j < array.length; j++) { var value = array[j]; if (predicates.check(value)) { filtered.push(value); } } return filtered; * @function <example> function Ctrl($scope) { $scope.amount = 1234.56; } <div ng-controller=""Ctrl""> custom currency identifier (USD$): <span>{{amount | currency:""USD$""}}</span> expect(element(by.binding('amount | currency:""USD$""')).getText()).toBe('USD$1,234.56'); expect(element(by.binding('amount | currency:""USD$""')).getText()).toBe('(USD$1,234.00)'); return function(amount, currencySymbol){ if (isUndefined(currencySymbol)) currencySymbol = formats.CURRENCY_SYM; return formatNumber(amount, formats.PATTERNS[1], formats.GROUP_SEP, formats.DECIMAL_SEP, 2). replace(/\u00A4/g, currencySymbol); * @function <example> function Ctrl($scope) { $scope.val = 1234.56789; } <div ng-controller=""Ctrl""> return formatNumber(number, formats.PATTERNS[0], formats.GROUP_SEP, formats.DECIMAL_SEP, fractionSize); if (number == null || !isFinite(number) || isObject(number)) return ''; numStr = '0'; var pow = Math.pow(10, fractionSize); number = Math.round(number * pow) / pow; if ((pos - i)%group === 0 && i !== 0) { if ((whole.length - i)%lgroup === 0 && i !== 0) { while(fraction.length < fractionSize) { if (fractionSize > 0 && number > -1 && number < 1) { parts.push(isNegative ? pattern.negPre : pattern.posPre); parts.push(formatedText); parts.push(isNegative ? pattern.negSuf : pattern.posSuf); while(num.length < digits) num = '0' + num; if (value === 0 && offset == -12 ) value = 12; Z: timeZoneGettervar DATE_FORMATS_SPLIT = /((?:[^yMdHhmsaZE']+)|(?:'(?:[^']|'')*')|(?:E+|y+|M+|d+|H+|h+|m+|s+|a|Z))(.*)/, * @function * * `'hh'`: Hour in am/pm, padded (01-12) * * `'h'`: Hour in am/pm, (1-12) * * `'a'`: am/pm marker * (e.g. Sep 3, 2010 12:05:08 pm) * * `'short'`: equivalent to `'M/d/yy h:mm a'` for en_US locale (e.g. 9/3/10 12:05 pm) * * `'fullDate'`: equivalent to `'EEEE, MMMM d,y'` for en_US locale * * `'mediumTime'`: equivalent to `'h:mm:ss a'` for en_US locale (e.g. 12:05:08 pm) * * `'shortTime'`: equivalent to `'h:mm a'` for en_US locale (e.g. 12:05 pm) * `format` string can contain literal values. These need to be quoted with single quotes (e.g. * `""h 'in the morning'""`). In order to output single quote, use two single quotes in a sequence * number) or various ISO 8601 datetime string formats (e.g. yyyy-MM-ddTHH:mm:ss.SSSZ and its var h = int(match[4]||0) - tzHour; var m = int(match[5]||0) - tzMin; var s = int(match[6]||0); var ms = Math.round(parseFloat('0.' + (match[7]||0)) * 1000); return function(date, format) { if (NUMBER_STRING.test(date)) { date = int(date); } else { date = jsonStringToDate(date); } while(format) { forEach(parts, function(value){ * @function <pre>{{ {'name':'value'} | json }}</pre> expect(element(by.binding(""{'name':'value'}"")).getText()).toMatch(/\{\n ""name"": ?""value""\n}/); return function(object) { return toJson(object, true); * @function * @function * @function * are taken from either the beginning or the end of the source array or string, as specified by * the value and sign (positive or negative) of `limit`. * @param {Array|string} input Source array or string to be limited. <example> function Ctrl($scope) { $scope.numbers = [1,2,3,4,5,6,7,8,9]; $scope.letters = ""abcdefghi""; $scope.numLimit = 3; $scope.letterLimit = 3; } <div ng-controller=""Ctrl""> Limit {{numbers}} to: <input type=""integer"" ng-model=""numLimit""> Limit {{letters}} to: <input type=""integer"" ng-model=""letterLimit""> it('should update the output when -3 is entered', function() { numLimitInput.clear(); numLimitInput.sendKeys('-3'); letterLimitInput.clear(); letterLimitInput.sendKeys('-3'); expect(limitedNumbers.getText()).toEqual('Output numbers: [7,8,9]'); expect(limitedLetters.getText()).toEqual('Output letters: ghi'); }); */ function limitToFilter(){ limit = int(limit); for (; i<n; i++) { * @function * Orders a specified `array` by the `expression` predicate. * @param {function(*)|string|Array.<(function(*)|string)>} expression A predicate to be * - `string`: An Angular expression which evaluates to an object to order by, such as 'name' * to sort by a property called 'name'. Optionally prefixed with `+` or `-` to control * ascending or descending sort order (for example, +name or -name). <example> function Ctrl($scope) { $scope.friends = [{name:'John', phone:'555-1212', age:10}, {name:'Mary', phone:'555-9876', age:19}, {name:'Mike', phone:'555-4321', age:21}, {name:'Adam', phone:'555-5678', age:35}, {name:'Julie', phone:'555-8765', age:29}] $scope.predicate = '-age'; } <div ng-controller=""Ctrl"">function orderByFilter($parse){ if (!isArray(array)) return array; if (!sortPredicate) return array; sortPredicate = isArray(sortPredicate) ? sortPredicate: [sortPredicate]; sortPredicate = map(sortPredicate, function(predicate){ return reverseComparator(function(a,b) { return reverseComparator(function(a,b){ var arrayCopy = []; for ( var i = 0; i < array.length; i++) { arrayCopy.push(array[i]); } return arrayCopy.sort(reverseComparator(comparator, reverseOrder)); function comparator(o1, o2){ for ( var i = 0; i < sortPredicate.length; i++) { return toBoolean(descending) ? function(a,b){return comp(b,a);} function compare(v1, v2){ if (t1 == t2) { if (t1 == ""string"") { if (msie <= 8) { // turn <a href ng-click="".."">link</a> into a stylable link in IE // but only if it doesn't have name attribute, in which case it's an anchor if (!attr.href && !attr.name) { attr.$set('href', ''); } // add a comment node to anchors to workaround IE bug that causes element content to be reset // to new attribute content if attribute is updated with value containing @ and element also // contains value with @ // see issue #1949 element.append(document.createComment('IE fix')); } element.on('click', function(event){ * and will most likely return a 404 error. * * The `ngHref` directive solves this problem. * <a href=""http://www.gravatar.com/avatar/{{hash}}""/> * <a ng-href=""http://www.gravatar.com/avatar/{{hash}}""/> }, 1000, 'page should navigate to /123'); }, 1000, 'page should navigate to /6'); * The following markup will make the button enabled on Chrome/Firefox but not on IE8 and older IEs: if (!value) return;/* global -nullFormCtrl */ $setPristine: noop }; * @property {Object} $error Is an object hash, containing references to all invalid controls or * forms, where: * - values are arrays of controls or forms that are invalid for given error name. * * `FormController` keeps track of all its controls and nested forms as well as state of them,FormController.$inject = ['$element', '$attrs', '$scope', '$animate']; function FormController(element, attrs, $scope, $animate) { parentForm = element.parent().controller('form') || nullFormCtrl, invalidCount = 0, // used to easily determine if we are valid errors = form.$error = {}, form.$name = attrs.name || attrs.ngForm; // Setup initial state of the control element.addClass(PRISTINE_CLASS); toggleValidCss(true); // convenience method for easy toggling of classes function toggleValidCss(isValid, validationErrorKey) { validationErrorKey = validationErrorKey ? '-' + snake_case(validationErrorKey, '-') : ''; $animate.removeClass(element, (isValid ? INVALID_CLASS : VALID_CLASS) + validationErrorKey); $animate.addClass(element, (isValid ? VALID_CLASS : INVALID_CLASS) + validationErrorKey); } forEach(errors, function(queue, validationToken) { form.$setValidity(validationToken, true, control); form.$setValidity = function(validationToken, isValid, control) { var queue = errors[validationToken]; if (isValid) { if (queue) { arrayRemove(queue, control); if (!queue.length) { invalidCount--; if (!invalidCount) { toggleValidCss(isValid); form.$valid = true; form.$invalid = false; } errors[validationToken] = false; toggleValidCss(true, validationToken); parentForm.$setValidity(validationToken, true, form); } else { if (!invalidCount) { toggleValidCss(isValid); if (queue) { if (includes(queue, control)) return; } else { errors[validationToken] = queue = []; invalidCount++; toggleValidCss(false, validationToken); parentForm.$setValidity(validationToken, false, form); queue.push(control); form.$valid = false; form.$invalid = true; } }; form.$setPristine = function () { $animate.removeClass(element, DIRTY_CLASS); $animate.addClass(element, PRISTINE_CLASS);} * @param {string=} name Name of the form. If specified, the form controller will be published into * related scope, under this name. <example deps=""angular-animate.js"" animations=""true"" fixBase=""true""> function Ctrl($scope) { $scope.userType = 'guest'; } <form name=""myForm"" ng-controller=""Ctrl"" class=""my-form""> compile: function() { pre: function(scope, formElement, attr, controller) { if (!attr.action) { var preventDefaultListener = function(event) { event.preventDefault ? event.preventDefault() : event.returnValue = false; // IE addEventListenerFn(formElement[0], 'submit', preventDefaultListener); removeEventListenerFn(formElement[0], 'submit', preventDefaultListener); var parentFormCtrl = formElement.parent().controller('form'), alias = attr.name || attr.ngForm; } if (parentFormCtrl) { formElement.on('$destroy', function() { parentFormCtrl.$removeControl(controller); if (alias) { setter(scope, alias, undefined, alias); } extend(controller, nullFormCtrl); //stop propagating child destruction handlers upwards/* global -VALID_CLASS, -INVALID_CLASS, -PRISTINE_CLASS, -DIRTY_CLASSvar EMAIL_REGEXP = /^[a-z0-9!#$%&'*+/=?^_`{|}~.-]+@[a-z0-9-]+(\.[a-z0-9-]+)*$/i; * Standard HTML text input with angular data binding. * maxlength. * @param {string=} ngPattern Sets `pattern` validation error key if the value does not match the * RegExp pattern expression. Expected value is `/regexp/` for inline patterns or `regexp` for * patterns defined as scope expressions. <example name=""text-input-directive""> function Ctrl($scope) { $scope.text = 'guest'; $scope.word = /^\s*\w*\s*$/; } <form name=""myForm"" ng-controller=""Ctrl""> * maxlength. * @param {string=} ngPattern Sets `pattern` validation error key if the value does not match the * RegExp pattern expression. Expected value is `/regexp/` for inline patterns or `regexp` for * patterns defined as scope expressions. <example name=""number-input-directive""> function Ctrl($scope) { $scope.value = 12; } <form name=""myForm"" ng-controller=""Ctrl""> * maxlength. * @param {string=} ngPattern Sets `pattern` validation error key if the value does not match the * RegExp pattern expression. Expected value is `/regexp/` for inline patterns or `regexp` for * patterns defined as scope expressions. <example name=""url-input-directive""> function Ctrl($scope) { $scope.text = 'http://google.com'; } <form name=""myForm"" ng-controller=""Ctrl""> * maxlength. * @param {string=} ngPattern Sets `pattern` validation error key if the value does not match the * RegExp pattern expression. Expected value is `/regexp/` for inline patterns or `regexp` for * patterns defined as scope expressions. <example name=""email-input-directive""> function Ctrl($scope) { $scope.text = 'me@example.com'; } <form name=""myForm"" ng-controller=""Ctrl""> <example name=""radio-input-directive""> function Ctrl($scope) { $scope.color = 'blue'; $scope.specialValue = { ""id"": ""12345"", ""value"": ""green"" }; } <form name=""myForm"" ng-controller=""Ctrl""> * @param {string=} ngTrueValue The value to which the expression should be set when selected. * @param {string=} ngFalseValue The value to which the expression should be set when not selected. <example name=""checkbox-input-directive""> function Ctrl($scope) { $scope.value1 = true; $scope.value2 = 'YES' } <form name=""myForm"" ng-controller=""Ctrl""> ng-true-value=""YES"" ng-false-value=""NO""> <br/>// A helper function to call $setValidity and return the value / undefined, // a pattern that is repeated a lot in the input validation logic. function validate(ctrl, validatorName, validity, value){ ctrl.$setValidity(validatorName, validity); return validity ? value : undefined; } function addNativeHtml5Validators(ctrl, validatorName, element) { var validity = element.prop('validity'); if (isObject(validity)) { var validator = function(value) { // Don't overwrite previous validation, don't consider valueMissing to apply (ng-required can // perform the required validation) if (!ctrl.$error[validatorName] && (validity.badInput || validity.customError || validity.typeMismatch) && !validity.valueMissing) { ctrl.$setValidity(validatorName, false); return; } return value; }; ctrl.$parsers.push(validator); } var validity = element.prop('validity'); var listener = function() { var value = element.val(); // e.g. <input ng-model=""foo"" ng-trim=""false""> if (toBoolean(attr.ngTrim || 'T')) { if (ctrl.$viewValue !== value || // If the value is still empty/falsy, and there is no `required` error, run validators // again. This enables HTML5 constraint validation errors to affect Angular validation // even when the first character entered causes an error. (validity && value === '' && !validity.valueMissing)) { if (scope.$$phase) { ctrl.$setViewValue(value); } else { scope.$apply(function() { ctrl.$setViewValue(value); }); } var deferListener = function() { listener(); deferListener(); // pattern validator var pattern = attr.ngPattern, patternValidator, match; if (pattern) { var validateRegex = function(regexp, value) { return validate(ctrl, 'pattern', ctrl.$isEmpty(value) || regexp.test(value), value); }; match = pattern.match(/^\/(.*)\/([gim]*)$/); if (match) { pattern = new RegExp(match[1], match[2]); patternValidator = function(value) { return validateRegex(pattern, value); }; } else { patternValidator = function(value) { var patternObj = scope.$eval(pattern); if (!patternObj || !patternObj.test) { throw minErr('ngPattern')('noregexp', 'Expected {0} to be a RegExp but was {1}. Element: {2}', pattern, patternObj, startingTag(element)); } return validateRegex(patternObj, value); }; ctrl.$formatters.push(patternValidator); ctrl.$parsers.push(patternValidator); } // min length validator if (attr.ngMinlength) { var minlength = int(attr.ngMinlength); var minLengthValidator = function(value) { return validate(ctrl, 'minlength', ctrl.$isEmpty(value) || value.length >= minlength, value); }; ctrl.$parsers.push(minLengthValidator); ctrl.$formatters.push(minLengthValidator); } // max length validator if (attr.ngMaxlength) { var maxlength = int(attr.ngMaxlength); var maxLengthValidator = function(value) { return validate(ctrl, 'maxlength', ctrl.$isEmpty(value) || value.length <= maxlength, value); }; ctrl.$parsers.push(maxLengthValidator); ctrl.$formatters.push(maxLengthValidator); textInputType(scope, element, attr, ctrl, $sniffer, $browser); var empty = ctrl.$isEmpty(value); if (empty || NUMBER_REGEXP.test(value)) { ctrl.$setValidity('number', true); return value === '' ? null : (empty ? value : parseFloat(value)); } else { ctrl.$setValidity('number', false); return undefined; addNativeHtml5Validators(ctrl, 'number', element); ctrl.$formatters.push(function(value) { return ctrl.$isEmpty(value) ? '' : '' + value; }); if (attr.min) { var minValidator = function(value) { var min = parseFloat(attr.min); return validate(ctrl, 'min', ctrl.$isEmpty(value) || value >= min, value); ctrl.$parsers.push(minValidator); ctrl.$formatters.push(minValidator); if (attr.max) { var maxValidator = function(value) { var max = parseFloat(attr.max); return validate(ctrl, 'max', ctrl.$isEmpty(value) || value <= max, value); ctrl.$parsers.push(maxValidator); ctrl.$formatters.push(maxValidator); ctrl.$formatters.push(function(value) { return validate(ctrl, 'number', ctrl.$isEmpty(value) || isNumber(value), value); }); textInputType(scope, element, attr, ctrl, $sniffer, $browser); var urlValidator = function(value) { return validate(ctrl, 'url', ctrl.$isEmpty(value) || URL_REGEXP.test(value), value); ctrl.$formatters.push(urlValidator); ctrl.$parsers.push(urlValidator); textInputType(scope, element, attr, ctrl, $sniffer, $browser); var emailValidator = function(value) { return validate(ctrl, 'email', ctrl.$isEmpty(value) || EMAIL_REGEXP.test(value), value); ctrl.$formatters.push(emailValidator); ctrl.$parsers.push(emailValidator); element.on('click', function() { scope.$apply(function() { ctrl.$setViewValue(attr.value); }); });function checkboxInputType(scope, element, attr, ctrl) { var trueValue = attr.ngTrueValue, falseValue = attr.ngFalseValue; if (!isString(trueValue)) trueValue = true; if (!isString(falseValue)) falseValue = false; element.on('click', function() { scope.$apply(function() { ctrl.$setViewValue(element[0].checked); }); }); // Override the standard `$isEmpty` because a value of `false` means empty in a checkbox. return value !== trueValue; return value === trueValue; * maxlength. * HTML input element control with angular data-binding. Input control follows HTML5 input types * and polyfills the HTML5 validation behavior for older browsers. * maxlength. <example name=""input-directive""> function Ctrl($scope) { $scope.user = {name: 'guest', last: 'visitor'}; } <div ng-controller=""Ctrl""> var user = element(by.binding('{{user}}'));var inputDirective = ['$browser', '$sniffer', function($browser, $sniffer) { require: '?ngModel', link: function(scope, element, attr, ctrl) { if (ctrl) { (inputType[lowercase(attr.type)] || inputType.text)(scope, element, attr, ctrl, $sniffer, $browser); DIRTY_CLASS = 'ng-dirty'; * @property {*} $modelValue The value in the model, that the control is bound to. the control reads value from the DOM. Each function is called, in turn, passing the value through to the next. The last return value is used to populate the model. Used to sanitize / convert the value as well as validation. For validation, the parsers should update the validity state using {@link ngModel.NgModelController#$setValidity $setValidity()}, and return `undefined` for invalid values. the model value changes. Each function is called, in turn, passing the value through to the next. Used to format / convert values for display in the control and validation. * ```js * function formatter(value) { * if (value) { * return value.toUpperCase(); * } * } * ngModel.$formatters.push(formatter); * ``` * @property {Object} $error An object hash with all errors as keys. * `NgModelController` provides API for the `ng-model` directive. The controller contains * services for data-binding, validation, CSS updates, and value formatting and parsing. It * purposefully does not contain any logic which deals with DOM rendering or listening to * DOM events. Such DOM related logic should be provided by other directives which make use of * `NgModelController` for data-binding. * ## Custom Control Example * <example name=""NgModelController"" module=""customControl""> angular.module('customControl', []). directive('contenteditable', function() { if(!ngModel) return; // do nothing if no ng-model element.html(ngModel.$viewValue || ''); scope.$apply(read); if( attrs.stripBr && html == '<br>' ) { });var NgModelController = ['$scope', '$exceptionHandler', '$attrs', '$element', '$parse', '$animate', function($scope, $exceptionHandler, $attr, $element, $parse, $animate) { this.$name = $attr.name; var ngModelGet = $parse($attr.ngModel), ngModelSet = ngModelGet.assign; if (!ngModelSet) { throw minErr('ngModel')('nonassign', ""Expression '{0}' is non-assignable. Element: {1}"", $attr.ngModel, startingTag($element)); } * This is called when we need to determine if the value of the input is empty. * @param {*} value Reference to check. * @returns {boolean} True if `value` is empty. invalidCount = 0, // used to easily determine if we are valid $error = this.$error = {}; // keep invalid keys here // Setup initial state of the control $element.addClass(PRISTINE_CLASS); toggleValidCss(true); // convenience method for easy toggling of classes function toggleValidCss(isValid, validationErrorKey) { validationErrorKey = validationErrorKey ? '-' + snake_case(validationErrorKey, '-') : ''; $animate.removeClass($element, (isValid ? INVALID_CLASS : VALID_CLASS) + validationErrorKey); $animate.addClass($element, (isValid ? VALID_CLASS : INVALID_CLASS) + validationErrorKey); } * Change the validity state, and notifies the form when the control changes validity. (i.e. it * does not notify form if given validator is already marked as invalid). * This method should be called by validators - i.e. the parser or formatter functions. * @param {string} validationErrorKey Name of the validator. the `validationErrorKey` will assign * to `$error[validationErrorKey]=isValid` so that it is available for data-binding. * @param {boolean} isValid Whether the current state is valid (true) or invalid (false). this.$setValidity = function(validationErrorKey, isValid) { // Purposeful use of ! here to cast isValid to boolean in case it is undefined // jshint -W018 if ($error[validationErrorKey] === !isValid) return; // jshint +W018 if (isValid) { if ($error[validationErrorKey]) invalidCount--; if (!invalidCount) { toggleValidCss(true); this.$valid = true; this.$invalid = false; } } else { toggleValidCss(false); this.$invalid = true; this.$valid = false; invalidCount++; } $error[validationErrorKey] = !isValid; toggleValidCss(isValid, validationErrorKey); parentForm.$setValidity(validationErrorKey, isValid, this); }; * This method can be called to remove the 'ng-dirty' class and set the control to its pristine * state (ng-pristine class). this.$setPristine = function () { this.$dirty = false; this.$pristine = true; * This method should be called when the view value changes, typically from within a DOM event handler. * For example {@link ng.directive:input input} and * {@link ng.directive:select select} directives call it. * It will update the $viewValue, then pass this value through each of the functions in `$parsers`, * which includes any validators. The value that comes out of this `$parsers` pipeline, be applied to * `$modelValue` and the **expression** specified in the `ng-model` attribute. this.$setViewValue = function(value) { this.$viewValue = value; // change to dirty if (this.$pristine) { this.$dirty = true; this.$pristine = false; $animate.removeClass($element, PRISTINE_CLASS); $animate.addClass($element, DIRTY_CLASS); parentForm.$setDirty(); forEach(this.$parsers, function(fn) { value = fn(value); }); if (this.$modelValue !== value) { this.$modelValue = value; ngModelSet($scope, value); forEach(this.$viewChangeListeners, function(listener) { try { listener(); } catch(e) { $exceptionHandler(e); } var ctrl = this; var value = ngModelGet($scope); if (ctrl.$modelValue !== value) { ctrl.$modelValue = value; while(idx--) { value = formatters[idx](value); if (ctrl.$viewValue !== value) { ctrl.$viewValue = value; return value; * - Keeping the state of the control (valid/invalid, dirty/pristine, validation errors). * - Setting related css classes on the element (`ng-valid`, `ng-invalid`, `ng-dirty`, `ng-pristine`) including animations. * - [https://github.com/angular/angular.js/wiki/Understanding-Scopes] * - `ng-valid` is set if the model is valid. * - `ng-invalid` is set if the model is invalid. * - `ng-pristine` is set if the model is pristine. * - `ng-dirty` is set if the model is dirty. * <example deps=""angular-animate.js"" animations=""true"" fixBase=""true""> function Ctrl($scope) { $scope.val = '1'; } <form name=""testForm"" ng-controller=""Ctrl"">var ngModelDirective = function() { require: ['ngModel', '^?form'], link: function(scope, element, attr, ctrls) { // notify others, especially parent forms var modelCtrl = ctrls[0], formCtrl = ctrls[1] || nullFormCtrl; formCtrl.$addControl(modelCtrl); scope.$on('$destroy', function() { formCtrl.$removeControl(modelCtrl); });}; * The expression is not evaluated when the value change is coming from the model. * <example name=""ngChange-directive""> * function Controller($scope) { * $scope.counter = 0; * $scope.change = function() { * $scope.counter++; * }; * } * <div ng-controller=""Controller""> var validator = function(value) { if (attr.required && ctrl.$isEmpty(value)) { ctrl.$setValidity('required', false); return; } else { ctrl.$setValidity('required', true); return value; } ctrl.$formatters.push(validator); ctrl.$parsers.unshift(validator); validator(ctrl.$viewValue); * Text input that converts between a delimited string and an array of strings. The delimiter * can be a fixed string (by default a comma) or a regular expression. * @param {string=} ngList optional delimiter that should be used to split the value. If * specified in form `/something/` then the value will be converted into a regular expression. * * @example <example name=""ngList-directive""> <file name=""index.html""> <script> function Ctrl($scope) { $scope.names = ['igor', 'misko', 'vojta']; } </script> <form name=""myForm"" ng-controller=""Ctrl""> List: <input name=""namesInput"" ng-model=""names"" ng-list required> <span class=""error"" ng-show=""myForm.namesInput.$error.required""> Required!</span> <br> <tt>names = {{names}}</tt><br/> <tt>myForm.namesInput.$valid = {{myForm.namesInput.$valid}}</tt><br/> <tt>myForm.namesInput.$error = {{myForm.namesInput.$error}}</tt><br/> <tt>myForm.$valid = {{myForm.$valid}}</tt><br/> <tt>myForm.$error.required = {{!!myForm.$error.required}}</tt><br/> </form> </file> <file name=""protractor.js"" type=""protractor""> var listInput = element(by.model('names')); var names = element(by.binding('{{names}}')); var valid = element(by.binding('myForm.namesInput.$valid')); var error = element(by.css('span.error')); it('should initialize to model', function() { expect(names.getText()).toContain('[""igor"",""misko"",""vojta""]'); expect(valid.getText()).toContain('true'); expect(error.getCssValue('display')).toBe('none'); }); it('should be invalid if empty', function() { listInput.clear(); listInput.sendKeys(''); expect(names.getText()).toContain(''); expect(valid.getText()).toContain('false'); expect(error.getCssValue('display')).not.toBe('none'); }); </file> </example> var match = /\/(.*)\//.exec(attr.ngList), separator = match && new RegExp(match[1]) || attr.ngList || ','; if (value) list.push(trim(value)); return value.join(', '); * Binds the given expression to the value of `input[select]` or `input[radio]`, so * that when the element is selected, the `ngModel` of that element is set to the * bound value. * `ngValue` is useful when dynamically generating lists of radio buttons using `ng-repeat`, as * shown below. <example name=""ngValue-directive""> function Ctrl($scope) { $scope.names = ['pizza', 'unicorns', 'robots']; $scope.my = { favorite: 'unicorns' }; } <form ng-controller=""Ctrl""> * It is preferable to use `ngBind` instead of `{{ expression }}` when a template is momentarily <example> function Ctrl($scope) { $scope.name = 'Whirled'; } <div ng-controller=""Ctrl"">var ngBindDirective = ngDirective(function(scope, element, attr) { element.addClass('ng-binding').data('$binding', attr.ngBind); scope.$watch(attr.ngBind, function ngBindWatchAction(value) { // We are purposefully using == here rather than === because we want to // catch when value is ""null or undefined"" // jshint -W041 element.text(value == undefined ? '' : value); }); }); <example> function Ctrl($scope) { $scope.salutation = 'Hello'; $scope.name = 'World'; } <div ng-controller=""Ctrl"">var ngBindTemplateDirective = ['$interpolate', function($interpolate) { return function(scope, element, attr) { // TODO: move this to scenario runner var interpolateFn = $interpolate(element.attr(attr.$attr.ngBindTemplate)); element.addClass('ng-binding').data('$binding', interpolateFn); attr.$observe('ngBindTemplate', function(value) { element.text(value); }); * Creates a binding that will innerHTML the result of evaluating the `expression` into the current * element in a secure way. By default, the innerHTML-ed content will be sanitized using the {@link * ngSanitize.$sanitize $sanitize} service. To utilize this functionality, ensure that `$sanitize` * is available, for example, by including {@link ngSanitize} in your module's dependencies (not in * core Angular.) You may also bypass sanitization for values you know are safe. To do so, bind to * under {@link ng.$sce#Example Strict Contextual Escaping (SCE)}. Try it here: enter text in text box and watch the greeting change. <example module=""ngBindHtmlExample"" deps=""angular-sanitize.js""> <div ng-controller=""ngBindHtmlCtrl""> angular.module('ngBindHtmlExample', ['ngSanitize']) .controller('ngBindHtmlCtrl', ['$scope', function ngBindHtmlCtrl($scope) { $scope.myHTML = 'I am an <code>HTML</code>string with <a href=""#"">links!</a> and other <em>stuff</em>'; }]);var ngBindHtmlDirective = ['$sce', '$parse', function($sce, $parse) { return function(scope, element, attr) { element.addClass('ng-binding').data('$binding', attr.ngBindHtml); var parsed = $parse(attr.ngBindHtml); function getStringValue() { return (parsed(scope) || '').toString(); } scope.$watch(getStringValue, function ngBindHtmlWatchAction(value) { element.html($sce.getTrustedHtml(parsed(scope)) || ''); }); if (mod !== old$index & 1) { function digestClassCounts (classes, count) { forEach(classes, function (className) { function updateClasses (oldClasses, newClasses) { toRemove = digestClassCounts(toRemove, -1); if (toAdd.length === 0) { $animate.removeClass(element, toRemove); } else if (toRemove.length === 0) { } else { $animate.setClass(element, toAdd, toRemove); oldVal = copy(newVal); for(var i = 0; i < tokens1.length; i++) { for(var j = 0; j < tokens2.length; j++) { if(token == tokens2[j]) continue outer; function arrayClasses (classVal) { var classes = [], i = 0; classes.push(k); to view the step by step details of {@link ngAnimate.$animate#addclass $animate.addClass} and {@link ngAnimate.$animate#removeclass $animate.removeClass}. * * Model — The Model is scope properties; scopes are attached to the DOM where scope properties * @param {expression} ngController Name of a globally accessible constructor function or an * {@link guide/expression expression} that on the current scope evaluates to a * constructor function. The controller instance can be published into a scope property * by specifying `as propertyName`. * easily be called from the angular markup. Notice that the scope becomes the `this` for the * controller's instance. This allows for easy access to the view data from the controller. Also * notice that any changes to the data are automatically reflected in the View without the need * for a manual update. The example is shown in two different declaration styles you may use * according to preference. <example> <file name=""index.html""> <script> function SettingsController1() { this.name = ""John Smith""; this.contacts = [ {type: 'phone', value: '408 555 1212'}, {type: 'email', value: 'john.smith@example.org'} ]; }; SettingsController1.prototype.greet = function() { alert(this.name); }; SettingsController1.prototype.addContact = function() { this.contacts.push({type: 'email', value: 'yourname@example.org'}); }; SettingsController1.prototype.removeContact = function(contactToRemove) { var index = this.contacts.indexOf(contactToRemove); this.contacts.splice(index, 1); }; SettingsController1.prototype.clearContact = function(contact) { contact.type = 'phone'; contact.value = ''; }; </script> <div id=""ctrl-as-exmpl"" ng-controller=""SettingsController1 as settings""> Name: <input type=""text"" ng-model=""settings.name""/> [ <a href="""" ng-click=""settings.greet()"">greet</a> ]<br/> Contact: <ul> <li ng-repeat=""contact in settings.contacts""> <select ng-model=""contact.type""> <option>phone</option> <option>email</option> </select> <input type=""text"" ng-model=""contact.value""/> [ <a href="""" ng-click=""settings.clearContact(contact)"">clear</a> | <a href="""" ng-click=""settings.removeContact(contact)"">X</a> ] </li> <li>[ <a href="""" ng-click=""settings.addContact()"">add</a> ]</li> </ul> </div> </file> <file name=""protractor.js"" type=""protractor""> it('should check controller as', function() { var container = element(by.id('ctrl-as-exmpl')); expect(container.findElement(by.model('settings.name')) .getAttribute('value')).toBe('John Smith'); var firstRepeat = container.findElement(by.repeater('contact in settings.contacts').row(0)); var secondRepeat = container.findElement(by.repeater('contact in settings.contacts').row(1)); expect(firstRepeat.findElement(by.model('contact.value')).getAttribute('value')) .toBe('408 555 1212'); expect(secondRepeat.findElement(by.model('contact.value')).getAttribute('value')) .toBe('john.smith@example.org'); firstRepeat.findElement(by.linkText('clear')).click(); expect(firstRepeat.findElement(by.model('contact.value')).getAttribute('value')) .toBe(''); container.findElement(by.linkText('add')).click(); expect(container.findElement(by.repeater('contact in settings.contacts').row(2)) .findElement(by.model('contact.value')) .getAttribute('value')) .toBe('yourname@example.org'); }); </file> </example> <example> <file name=""index.html""> <script> function SettingsController2($scope) { $scope.name = ""John Smith""; $scope.contacts = [ {type:'phone', value:'408 555 1212'}, {type:'email', value:'john.smith@example.org'} ]; $scope.greet = function() { alert(this.name); }; $scope.addContact = function() { this.contacts.push({type:'email', value:'yourname@example.org'}); }; $scope.removeContact = function(contactToRemove) { var index = this.contacts.indexOf(contactToRemove); this.contacts.splice(index, 1); }; $scope.clearContact = function(contact) { contact.type = 'phone'; contact.value = ''; }; } </script> <div id=""ctrl-exmpl"" ng-controller=""SettingsController2""> Name: <input type=""text"" ng-model=""name""/> [ <a href="""" ng-click=""greet()"">greet</a> ]<br/> Contact: <ul> <li ng-repeat=""contact in contacts""> <select ng-model=""contact.type""> <option>phone</option> <option>email</option> </select> <input type=""text"" ng-model=""contact.value""/> [ <a href="""" ng-click=""clearContact(contact)"">clear</a> | <a href="""" ng-click=""removeContact(contact)"">X</a> ] </li> <li>[ <a href="""" ng-click=""addContact()"">add</a> ]</li> </ul> </div> </file> <file name=""protractor.js"" type=""protractor""> it('should check controller', function() { var container = element(by.id('ctrl-exmpl')); expect(container.findElement(by.model('name')) .getAttribute('value')).toBe('John Smith'); var firstRepeat = container.findElement(by.repeater('contact in contacts').row(0)); var secondRepeat = container.findElement(by.repeater('contact in contacts').row(1)); expect(firstRepeat.findElement(by.model('contact.value')).getAttribute('value')) .toBe('408 555 1212'); expect(secondRepeat.findElement(by.model('contact.value')).getAttribute('value')) .toBe('john.smith@example.org'); firstRepeat.findElement(by.linkText('clear')).click(); expect(firstRepeat.findElement(by.model('contact.value')).getAttribute('value')) .toBe(''); container.findElement(by.linkText('add')).click(); expect(container.findElement(by.repeater('contact in contacts').row(2)) .findElement(by.model('contact.value')) .getAttribute('value')) .toBe('yourname@example.org'); }); </file> </example> * This is necessary when developing things like Google Chrome Extensions. * For us to be compatible, we just need to implement the ""getterFn"" in $parse without violating * any of these restrictions. * In order to use this feature put the `ngCsp` directive on the root element of the application. */// ngCsp is not implemented as a proper directive any more, because we need it be processed while we bootstrap // the system (before $parse is instantiated), for this reason we just have a csp() fn that looks for ng-csp attribute // anywhere in the current doc count: {{count}} * A directive that allows creation of custom onclick handlers that are defined as angular * expressions and are compiled and executed within the current scope. * * Events that are handled via these handler are always configured not to propagate further. function(name) { var directiveName = directiveNormalize('ng-' + name); ngEventDirectives[directiveName] = ['$parse', function($parse) { var fn = $parse(attr[directiveName]); return function(scope, element, attr) { element.on(lowercase(name), function(event) { scope.$apply(function() { }); <input ng-keyup=""count = count + 1"" ng-init=""count=0""> key up count: {{count}} <example> function Ctrl($scope) { $scope.list = []; $scope.text = 'hello'; $scope.submit = function() { if ($scope.text) { $scope.list.push(this.text); $scope.text = ''; } }; } <form ng-submit=""submit()"" ng-controller=""Ctrl""> expect(element(by.input('text')).getAttribute('value')).toBe(''); * [prototypal inheritance](https://github.com/angular/angular.js/wiki/The-Nuances-of-Scope-Prototypal-Inheritance). * enter - happens just after the ngIf contents change and a new DOM element is created and injected into the ngIf container * leave - happens just before the ngIf contents are removed from the DOM I'm removed when the checkbox is unchecked. link: function ($scope, $element, $attr, ctrl, $transclude) { if (toBoolean(value)) { childScope = $scope.$new(); $transclude(childScope, function (clone) { // by a directive with templateUrl when it's template arrives. if(previousElements) { if(childScope) { if(block) { previousElements = getBlockElements(block.clone); $animate.leave(previousElements, function() { * application document. This is done by calling {@link ng.$sce#getTrustedResourceUrl * [wrap them](ng.$sce#trustAsResourceUrl) as trusted values. Refer to Angular's {@link <example module=""ngAnimate"" deps=""angular-animate.js"" animations=""true""> <div ng-controller=""Ctrl""> function Ctrl($scope) { $scope.templates = [ { name: 'template1.html', url: 'template1.html'}, { name: 'template2.html', url: 'template2.html'} ]; $scope.template = $scope.templates[0]; } templateSelect.element.all(by.css('option')).get(2).click(); templateSelect.element.all(by.css('option')).get(0).click();var ngIncludeDirective = ['$http', '$templateCache', '$anchorScroll', '$animate', '$sce', function($http, $templateCache, $anchorScroll, $animate, $sce) { if(previousElement) { if(currentScope) { if(currentElement) { $animate.leave(currentElement, function() { $http.get(src, {cache: $templateCache}).success(function(response) { $animate.enter(clone, null, $element, afterAnimation); currentScope.$emit('$includeContentLoaded'); }).error(function() { if (thisChangeId === changeCounter) cleanupLastIncludeContent(); scope.$emit('$includeContentRequested'); <example> function Ctrl($scope) { $scope.list = [['a', 'b'], ['c', 'd']]; } <div ng-controller=""Ctrl""> * In this case, plural category 'one' is matched and ""John, Marry and one other person are viewing"" <example> function Ctrl($scope) { $scope.person1 = 'Igor'; $scope.person2 = 'Misko'; $scope.personCount = 1; } <div ng-controller=""Ctrl""> var BRACE = /{}/g; isWhen = /^when(Minus)?(.+)$/; if (isWhen.test(attributeName)) { whens[lowercase(attributeName.replace('when', '').replace('Minus', '-'))] = element.attr(attr.$attr[attributeName]); whensExpFns[key] = $interpolate(expression.replace(BRACE, startSymbol + numberExp + '-' + offset + endSymbol)); scope.$watch(function ngPluralizeWatch() { var value = parseFloat(scope.$eval(numberExp)); if (!isNaN(value)) { //if explicit number rule such as 1, 2, 3... is defined, just use it. Otherwise, //check it against pluralization rules in $locale service if (!(value in whens)) value = $locale.pluralCat(value - offset); return whensExpFns[value](scope, element, true); } else { return ''; }, function ngPluralizeWatchAction(newVal) { element.text(newVal); * For example: `item in items` is equivalent to `item in items track by $id(item)'. This implies that the DOM elements <li class=""animate-repeat"" ng-repeat=""friend in friends | filter:q""> link: function($scope, $element, $attr, ctrl, $transclude){ var expression = $attr.ngRepeat; var match = expression.match(/^\s*([\s\S]+?)\s+in\s+([\s\S]+?)(?:\s+track\s+by\s+([\s\S]+?))?\s*$/), trackByExp, trackByExpGetter, trackByIdExpFn, trackByIdArrayFn, trackByIdObjFn, lhs, rhs, valueIdentifier, keyIdentifier, hashFnLocals = {$id: hashKey}; if (!match) { throw ngRepeatMinErr('iexp', ""Expected expression in form of '_item_ in _collection_[ track by _id_]' but got '{0}'."", } lhs = match[1]; rhs = match[2]; trackByExp = match[3]; if (trackByExp) { trackByExpGetter = $parse(trackByExp); } else { trackByIdArrayFn = function(key, value) { return hashKey(value); }; trackByIdObjFn = function(key) { return key; }; match = lhs.match(/^(?:([\$\w]+)|\(([\$\w]+)\s*,\s*([\$\w]+)\))$/); if (!match) { throw ngRepeatMinErr('iidexp', ""'_item_' in '_item_ in _collection_' should be an identifier or '(_key_, _value_)' expression, but got '{0}'."", lhs); } valueIdentifier = match[3] || match[1]; keyIdentifier = match[2]; var lastBlockMap = {}; $scope.$watchCollection(rhs, function ngRepeatAction(collection){ previousNode = $element[0], // current position of the node nextBlockMap = {}, arrayLength, childScope, nextBlockOrder = [], for (key in collection) { if (collection.hasOwnProperty(key) && key.charAt(0) != '$') { collectionKeys.push(key); arrayLength = collectionKeys.length; length = nextBlockOrder.length = collectionKeys.length; for(index = 0; index < length; index++) { key = (collection === collectionKeys) ? index : collectionKeys[index]; value = collection[key]; trackById = trackByIdFn(key, value, index); assertNotHasOwnProperty(trackById, '`track by` id'); if(lastBlockMap.hasOwnProperty(trackById)) { block = lastBlockMap[trackById]; delete lastBlockMap[trackById]; nextBlockMap[trackById] = block; nextBlockOrder[index] = block; } else if (nextBlockMap.hasOwnProperty(trackById)) { // restore lastBlockMap forEach(nextBlockOrder, function(block) { if (block && block.scope) lastBlockMap[block.id] = block; }); // This is a duplicate and we need to throw an error throw ngRepeatMinErr('dupes', ""Duplicates in a repeater are not allowed. Use 'track by' expression to specify unique keys. Repeater: {0}, Duplicate key: {1}"", expression, trackById); } else { // new never before seen block nextBlockOrder[index] = { id: trackById }; nextBlockMap[trackById] = false; } } // remove existing items for (key in lastBlockMap) { // lastBlockMap is our own object so we don't need to use special hasOwnPropertyFn if (lastBlockMap.hasOwnProperty(key)) { block = lastBlockMap[key]; elementsToRemove = getBlockElements(block.clone); $animate.leave(elementsToRemove); forEach(elementsToRemove, function(element) { element[NG_REMOVED] = true; }); block.scope.$destroy(); for (index = 0, length = collectionKeys.length; index < length; index++) { if (nextBlockOrder[index - 1]) previousNode = getBlockEnd(nextBlockOrder[index - 1]); childScope = block.scope; } while(nextNode && nextNode[NG_REMOVED]); $animate.move(getBlockElements(block.clone), null, jqLite(previousNode)); childScope = $scope.$new(); } childScope[valueIdentifier] = value; if (keyIdentifier) childScope[keyIdentifier] = key; childScope.$index = index; childScope.$first = (index === 0); childScope.$last = (index === (arrayLength - 1)); childScope.$middle = !(childScope.$first || childScope.$last); // jshint bitwise: false childScope.$odd = !(childScope.$even = (index&1) === 0); // jshint bitwise: true if (!block.scope) { $transclude(childScope, function(clone) { clone[clone.length++] = document.createComment(' end ngRepeat: ' + expression + ' '); previousNode = clone; block.scope = childScope; // by a directive with templateUrl when it's template arrives. function getBlockStart(block) { return block.clone[0]; } function getBlockEnd(block) { return block.clone[block.clone.length - 1]; } * provided to the ngShow attribute. The element is shown or hidden by removing or adding * the `ng-hide` CSS class onto the element. The `.ng-hide` CSS class is predefined * When the ngShow expression evaluates to false then the ng-hide CSS class is added to the class attribute * on the element causing it to become hidden. When true, the ng-hide CSS class is removed * You may be wondering why !important is used for the .ng-hide CSS class. This is because the `.ng-hide` selector * ### Overriding .ng-hide * If you wish to change the hide behavior with ngShow/ngHide then this can be achieved by * restating the styles for the .ng-hide class in CSS: * //!annotate CSS Specificity|Not to worry, this will override the AngularJS default... * display:block!important; * * //this is just another form of hiding an element * position:absolute; * top:-9999px; * left:-9999px; * Just remember to include the important flag so the CSS override will function. * <div class=""alert alert-warning""> * **Note:** Here is a list of values that ngShow will consider as a falsy value (case insensitive):<br /> * ""f"" / ""0"" / ""false"" / ""no"" / ""n"" / ""[]"" * </div> * * ## A note about animations with ngShow * transition:0.5s linear all; * display:block!important; * addClass: .ng-hide - happens after the ngShow expression evaluates to a truthy value and the just before contents are set to visible * removeClass: .ng-hide - happens after the ngShow expression evaluates to a non truthy value and just before the contents are set to hidden @import url(//netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css); -webkit-transition:all linear 0.5s; transition:all linear 0.5s; line-height:20px; opacity:1; padding:10px; border:1px solid black; background:white; .animate-show.ng-hide-add, .animate-show.ng-hide-remove { display:block!important; line-height:0; opacity:0; padding:0 10px; padding:10px; border:1px solid black; background:white; return function(scope, element, attr) { scope.$watch(attr.ngShow, function ngShowWatchAction(value){ $animate[toBoolean(value) ? 'removeClass' : 'addClass'](element, 'ng-hide'); }); * provided to the ngHide attribute. The element is shown or hidden by removing or adding * <div ng-hide=""myValue""></div> * <div ng-hide=""myValue"" class=""ng-hide""></div> * When the ngHide expression evaluates to true then the .ng-hide CSS class is added to the class attribute * on the element causing it to become hidden. When false, the ng-hide CSS class is removed * You may be wondering why !important is used for the .ng-hide CSS class. This is because the `.ng-hide` selector * ### Overriding .ng-hide * If you wish to change the hide behavior with ngShow/ngHide then this can be achieved by * restating the styles for the .ng-hide class in CSS: * //!annotate CSS Specificity|Not to worry, this will override the AngularJS default... * display:block!important; * * //this is just another form of hiding an element * position:absolute; * top:-9999px; * left:-9999px; * Just remember to include the important flag so the CSS override will function. * <div class=""alert alert-warning""> * **Note:** Here is a list of values that ngHide will consider as a falsy value (case insensitive):<br /> * ""f"" / ""0"" / ""false"" / ""no"" / ""n"" / ""[]"" * </div> * * ## A note about animations with ngHide * is true and false. This system works like the animation system present with ngClass, except that * you must also include the !important flag to override the display property so * that you can perform an animation when the element is hidden during the time of the animation. * transition:0.5s linear all; * display:block!important; * removeClass: .ng-hide - happens after the ngHide expression evaluates to a truthy value and just before the contents are set to hidden * addClass: .ng-hide - happens after the ngHide expression evaluates to a non truthy value and just before the contents are set to visible @import url(//netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css); -webkit-transition:all linear 0.5s; transition:all linear 0.5s; line-height:20px; opacity:1; padding:10px; border:1px solid black; background:white; } .animate-hide.ng-hide-add, .animate-hide.ng-hide-remove { display:block!important; line-height:0; opacity:0; padding:0 10px; padding:10px; border:1px solid black; background:white; return function(scope, element, attr) { scope.$watch(attr.ngHide, function ngHideWatchAction(value){ $animate[toBoolean(value) ? 'addClass' : 'removeClass'](element, 'ng-hide'); }); * @param {expression} ngStyle {@link guide/expression Expression} which evals to an * object whose keys are CSS style names and values are corresponding values for those CSS * keys. <input type=""button"" value=""set"" ng-click=""myStyle={color:'red'}""> element(by.css('input[value=set]')).click(); * @priority 800 <example module=""ngAnimate"" deps=""angular-animate.js"" animations=""true""> <div ng-controller=""Ctrl""> function Ctrl($scope) { $scope.items = ['settings', 'home', 'other']; $scope.selection = $scope.items[0]; } select.element.all(by.css('option')).get(1).click(); select.element.all(by.css('option')).get(2).click(); selectedTranscludes, selectedElements, previousElements, scope.$watch(watchExpr, function ngSwitchWatchAction(value) { var i, ii = selectedScopes.length; if(ii > 0) { if(previousElements) { for (i = 0; i < ii; i++) { previousElements[i].remove(); } previousElements = null; } previousElements = []; for (i= 0; i<ii; i++) { var selected = selectedElements[i]; selectedScopes[i].$destroy(); previousElements[i] = selected; $animate.leave(selected, function() { previousElements.splice(i, 1); if(previousElements.length === 0) { previousElements = null; } }); } selectedElements = []; selectedScopes = []; scope.$eval(attr.change); var selectedScope = scope.$new(); selectedScopes.push(selectedScope); selectedTransclude.transclude(selectedScope, function(caseElement) { selectedElements.push(caseElement); priority: 800, priority: 800, * @restrict AC <example module=""transclude""> function Ctrl($scope) { $scope.title = 'Lorem Ipsum'; $scope.text = 'Neque porro quisquam est qui dolorem ipsum quia dolor...'; } angular.module('transclude', []) '<div ng-transclude></div>' + }); <div ng-controller=""Ctrl""> <input ng-model=""title""><br> // IE is not consistent, in scripts we have to read .text but in other nodes we have to read .textContent * <div class=""alert alert-warning""> * **Note:** `ngModel` compares by reference, not value. This is important when binding to an * array of objects. See an example [in this jsfiddle](http://jsfiddle.net/qWzTb/). * </div> * * **Note:** `ngOptions` provides an iterator facility for the `<option>` element which should be used instead * of {@link ng.directive:ngRepeat ngRepeat} when you want the * `select` model to be bound to a non-string value. This is because an option element can only * be bound to string values at present. * * `label` **`group by`** `group` **`for`** `value` **`in`** `array` * * `select` **`as`** `label` **`group by`** `group` **`for`** `value` **`in`** `array` **`track by`** `trackexpr` * `value` variable (e.g. `value.propertyName`). <example> function MyCntrl($scope) { $scope.colors = [ {name:'black', shade:'dark'}, {name:'white', shade:'light'}, {name:'red', shade:'dark'}, {name:'blue', shade:'dark'}, {name:'yellow', shade:'light'} ]; $scope.color = $scope.colors[2]; // red } <div ng-controller=""MyCntrl""> <select ng-model=""color"" ng-options=""c.name for c in colors""></select><br> <select ng-model=""color"" ng-options=""c.name for c in colors""> <select ng-model=""color"" ng-options=""c.name group by c.shade for c in colors""> Select <a href ng-click=""color={name:'not in list'}"">bogus</a>.<br> Currently selected: {{ {selected_color:color} }} ng-style=""{'background-color':color.name}""> expect(element(by.binding('{selected_color:color}')).getText()).toMatch('red'); element.all(by.select('color')).first().click(); element.all(by.css('select[ng-model=""color""] option')).first().click(); expect(element(by.binding('{selected_color:color}')).getText()).toMatch('black'); element(by.css('.nullable select[ng-model=""color""]')).click(); element.all(by.css('.nullable select[ng-model=""color""] option')).first().click(); expect(element(by.binding('{selected_color:color}')).getText()).toMatch('null');var ngOptionsDirective = valueFn({ terminal: true }); self.addOption = function(value) { if (ngModelCtrl.$viewValue == value) { for(var i = 0, children = element.children(), ii = children.length; i < ii; i++) { lastView = copy(ctrl.$viewValue); optionGroupsCache = [[{element: selectElement, label:''}]]; selectElement.on('change', function() { scope.$apply(function() { var optionGroup, collection = valuesFn(scope) || [], locals = {}, key, value, optionElement, index, groupIndex, length, groupLength, trackIndex; if (multiple) { value = []; for (groupIndex = 0, groupLength = optionGroupsCache.length; groupIndex < groupLength; groupIndex++) { // list of options for that group. (first item has the parent) optionGroup = optionGroupsCache[groupIndex]; for(index = 1, length = optionGroup.length; index < length; index++) { if ((optionElement = optionGroup[index].element)[0].selected) { key = optionElement.val(); if (keyName) locals[keyName] = key; if (trackFn) { for (trackIndex = 0; trackIndex < collection.length; trackIndex++) { locals[valueName] = collection[trackIndex]; if (trackFn(scope, locals) == key) break; } } else { locals[valueName] = collection[key]; } value.push(valueFn(scope, locals)); } } } } else { key = selectElement.val(); if (key == '?') { value = undefined; } else if (key === ''){ value = null; } else { if (trackFn) { for (trackIndex = 0; trackIndex < collection.length; trackIndex++) { locals[valueName] = collection[trackIndex]; if (trackFn(scope, locals) == key) { value = valueFn(scope, locals); break; } } } else { locals[valueName] = collection[key]; if (keyName) locals[keyName] = key; value = valueFn(scope, locals); } } // Update the null option's selected property here so $render cleans it up correctly if (optionGroupsCache[0].length > 1) { if (optionGroupsCache[0][1].id !== key) { optionGroupsCache[0][1].selected = false; } } } ctrl.$setViewValue(value); }); }); // TODO(vojta): can't we optimize this ? scope.$watch(render); // Temporary location for the option groups before we render them modelValue = ctrl.$modelValue, locals = {}, selectedSet = false, // nothing is selected yet label; if (multiple) { if (trackFn && isArray(modelValue)) { selectedSet = new HashMap([]); for (var trackIndex = 0; trackIndex < modelValue.length; trackIndex++) { locals[valueName] = modelValue[trackIndex]; selectedSet.put(trackFn(scope, locals), modelValue[trackIndex]); } } else { selectedSet = new HashMap(modelValue); } } if ( key.charAt(0) === '$' ) continue; locals[keyName] = key; locals[valueName] = values[key]; optionGroupName = groupByFn(scope, locals) || ''; if (multiple) { selected = isDefined( selectedSet.remove(trackFn ? trackFn(scope, locals) : valueFn(scope, locals)) ); } else { if (trackFn) { var modelCast = {}; modelCast[valueName] = modelValue; selected = trackFn(scope, modelCast) === trackFn(scope, locals); } else { selected = modelValue === valueFn(scope, locals); } selectedSet = selectedSet || selected; // see if at least one item is selected } label = displayFn(scope, locals); // what will be seen by the user id: trackFn ? trackFn(scope, locals) : (keyName ? keys[index] : index), if (nullOption || modelValue === null) { optionGroups[''].unshift({id:'', label:'', selected:!selectedSet}); } else if (!selectedSet) { for(index = 0, length = optionGroup.length; index < length; index++) { if ((existingOption = existingOptions[index+1])) { if (existingOption.selected !== option.selected) { while(existingOptions.length > index) { existingOptions.pop().element.remove(); while(optionGroupsCache.length > groupIndex) { optionGroupsCache.pop()[0].element.remove(); return function (scope, element, attr) { if (selectCtrl && selectCtrl.databound) { // For some reason Opera defaults to true and if not overridden this messes up the repeater. // We don't want the view to drive the initialization of the model anyway. element.prop('selected', false); } else { if (newVal !== oldVal) selectCtrl.removeOption(oldVal); selectCtrl.addOption(newVal); selectCtrl.addOption(attr.value); terminal: true if (!output.length || indexOf(output,name) != -1) { line = line.substring(line.indexOf('@')+1); line = line.substring(line.indexOf('(')+1).replace(')', '');(function(fn){ match = function (actualExp) { } else if (typeof value != 'string') { binding; if (binding = element.data('$binding')) { if (typeof binding == 'string') { if (match(binding)) { push(element.scope().$eval(binding)); } else { if (!angular.isArray(binding)) { binding = [binding]; } for(var fns, j=0, jj=binding.length; j<jj; j++) { fns = binding[j]; if (fns.parts) { fns = fns.parts; } else { fns = [fns]; } for (var scope, fn, i = 0, ii = fns.length; i < ii; i++) { if(match((fn = fns[i]).exp)) { push(fn(scope = scope || element.scope())); } var msie = parseInt((/msie (\d+)/.exec(navigator.userAgent.toLowerCase()) || [])[1], 10); function indexOf(array, obj) { if (array.indexOf) return array.indexOf(obj); for ( var i = 0; i < array.length; i++) { if (obj === array[i]) return i; } return -1; } return indexOf(keys, key) !== -1; if (msie < 9) { if (inputType == 'radio' || inputType == 'checkbox') { element.checked = !element.checked; } // WTF!!! Error: Unspecified error. // Don't know why, but some elements when detached seem to be in inconsistent state and // calling .fireEvent() on them will result in very unhelpful error (Error: Unspecified error) // forcing the browser to compute the element position (by reading its CSS) // puts the element in consistent state. element.style.posLeft; // TODO(vojta): create event objects with pressed keys to get it working on IE<9 var ret = element.fireEvent('on' + eventType); if (inputType == 'submit') { while(element) { if (element.nodeName.toLowerCase() == 'form') { element.fireEvent('onsubmit'); break; } element = element.parentNode; } } return ret; } else { var evnt; if(/transitionend/.test(eventType)) { if(window.WebKitTransitionEvent) { evnt = new WebKitTransitionEvent(eventType, eventData); evnt.initEvent(eventType, false, true); } else { try { evnt = new TransitionEvent(eventType, eventData); } catch(e) { evnt = document.createEvent('TransitionEvent'); evnt.initTransitionEvent(eventType, null, null, null, eventData.elapsedTime || 0); } } } else if(/animationend/.test(eventType)) { if(window.WebKitAnimationEvent) { evnt = new WebKitAnimationEvent(eventType, eventData); evnt.initEvent(eventType, false, true); } else { try { evnt = new AnimationEvent(eventType, eventData); } catch(e) { evnt = document.createEvent('AnimationEvent'); evnt.initAnimationEvent(eventType, null, null, null, eventData.elapsedTime || 0); } } evnt = document.createEvent('MouseEvents'); x = x || 0; y = y || 0; evnt.initMouseEvent(eventType, true, true, window, 0, x, y, x, y, pressed('ctrl'), pressed('alt'), pressed('shift'), pressed('meta'), 0, element); /* we're unable to change the timeStamp value directly so this * is only here to allow for testing where the timeStamp value is * read */ evnt.$manualTimeStamp = eventData.timeStamp; if(!evnt) return; var originalPreventDefault = evnt.preventDefault, appWindow = element.ownerDocument.defaultView, fakeProcessDefault = true, finalProcessDefault, angular = appWindow.angular || {}; // igor: temporary fix for https://bugzilla.mozilla.org/show_bug.cgi?id=684208 angular['ff-684208-preventDefault'] = false; evnt.preventDefault = function() { fakeProcessDefault = false; return originalPreventDefault.apply(evnt, arguments); }; element.dispatchEvent(evnt); finalProcessDefault = !(angular['ff-684208-preventDefault'] || !fakeProcessDefault); delete angular['ff-684208-preventDefault']; return finalProcessDefault; $injector.invoke(function($browser){ this.its[this.its.length-1].only = true; } catch(e) { * Configures the future to convert it's final with a function fn(value) * Configures the future to parse it's final value from JSON * Configures the future to convert it's final value from objects return this.steps[this.steps.length-1]; angular.forEach(['[ng-','[data-ng-','[x-ng-'], function(value, index){ } catch(e) { this.selector = _jQuery.trim((this.selector||'') + ' ' + selector); var supportInputEvent = 'oninput' in document.createElement('div') && msie != 9; option = select.find('option').filter(function(){ if (href && elements[0].nodeName.toUpperCase() === 'A' && eventProcessDefault) { if (href && elements[0].nodeName.toUpperCase() === 'A' && eventProcessDefault) {!angular.$$csp() && angular.element(document).find('head').prepend('<style type=""text/css"">@charset ""UTF-8"";\n\n[ng\\:cloak], [ng-cloak], [data-ng-cloak], [x-ng-cloak],\n.ng-cloak, .x-ng-cloak,\n.ng-hide {\n display: none !important;\n}\n\nng\\:form {\n display: block;\n}\n\n.ng-animate-block-transitions {\n transition:0s all!important;\n -webkit-transition:0s all!important;\n}\n</style>'); !angular.$$csp() && angular.element(document).find('head').prepend('<style type=""text/css"">@charset ""UTF-8"";\n/* CSS Document */\n\n/** Structure */\nbody {\n font-family: Arial, sans-serif;\n margin: 0;\n font-size: 14px;\n}\n\n#system-error {\n font-size: 1.5em;\n text-align: center;\n}\n\n#json, #xml {\n display: none;\n}\n\n#header {\n position: fixed;\n width: 100%;\n}\n\n#specs {\n padding-top: 50px;\n}\n\n#header .angular {\n font-family: Courier New, monospace;\n font-weight: bold;\n}\n\n#header h1 {\n font-weight: normal;\n float: left;\n font-size: 30px;\n line-height: 30px;\n margin: 0;\n padding: 10px 10px;\n height: 30px;\n}\n\n#application h2,\n#specs h2 {\n margin: 0;\n padding: 0.5em;\n font-size: 1.1em;\n}\n\n#status-legend {\n margin-top: 10px;\n margin-right: 10px;\n}\n\n#header,\n#application,\n.test-info,\n.test-actions li {\n overflow: hidden;\n}\n\n#application {\n margin: 10px;\n}\n\n#application iframe {\n width: 100%;\n height: 758px;\n}\n\n#application .popout {\n float: right;\n}\n\n#application iframe {\n border: none;\n}\n\n.tests li,\n.test-actions li,\n.test-it li,\n.test-it ol,\n.status-display {\n list-style-type: none;\n}\n\n.tests,\n.test-it ol,\n.status-display {\n margin: 0;\n padding: 0;\n}\n\n.test-info {\n margin-left: 1em;\n margin-top: 0.5em;\n border-radius: 8px 0 0 8px;\n -webkit-border-radius: 8px 0 0 8px;\n -moz-border-radius: 8px 0 0 8px;\n cursor: pointer;\n}\n\n.test-info:hover .test-name {\n text-decoration: underline;\n}\n\n.test-info .closed:before {\n content: \'\\25b8\\00A0\';\n}\n\n.test-info .open:before {\n content: \'\\25be\\00A0\';\n font-weight: bold;\n}\n\n.test-it ol {\n margin-left: 2.5em;\n}\n\n.status-display,\n.status-display li {\n float: right;\n}\n\n.status-display li {\n padding: 5px 10px;\n}\n\n.timer-result,\n.test-title {\n display: inline-block;\n margin: 0;\n padding: 4px;\n}\n\n.test-actions .test-title,\n.test-actions .test-result {\n display: table-cell;\n padding-left: 0.5em;\n padding-right: 0.5em;\n}\n\n.test-actions {\n display: table;\n}\n\n.test-actions li {\n display: table-row;\n}\n\n.timer-result {\n width: 4em;\n padding: 0 10px;\n text-align: right;\n font-family: monospace;\n}\n\n.test-it pre,\n.test-actions pre {\n clear: left;\n color: black;\n margin-left: 6em;\n}\n\n.test-describe {\n padding-bottom: 0.5em;\n}\n\n.test-describe .test-describe {\n margin: 5px 5px 10px 2em;\n}\n\n.test-actions .status-pending .test-title:before {\n content: \'\\00bb\\00A0\';\n}\n\n.scrollpane {\n max-height: 20em;\n overflow: auto;\n}\n\n/** Colors */\n\n#header {\n background-color: #F2C200;\n}\n\n#specs h2 {\n border-top: 2px solid #BABAD1;\n}\n\n#specs h2,\n#application h2 {\n background-color: #efefef;\n}\n\n#application {\n border: 1px solid #BABAD1;\n}\n\n.test-describe .test-describe {\n border-left: 1px solid #BABAD1;\n border-right: 1px solid #BABAD1;\n border-bottom: 1px solid #BABAD1;\n}\n\n.status-display {\n border: 1px solid #777;\n}\n\n.status-display .status-pending,\n.status-pending .test-info {\n background-color: #F9EEBC;\n}\n\n.status-display .status-success,\n.status-success .test-info {\n background-color: #B1D7A1;\n}\n\n.status-display .status-failure,\n.status-failure .test-info {\n background-color: #FF8286;\n}\n\n.status-display .status-error,\n.status-error .test-info {\n background-color: black;\n color: white;\n}\n\n.test-actions .status-success .test-title {\n color: #30B30A;\n}\n\n.test-actions .status-failure .test-title {\n color: #DF0000;\n}\n\n.test-actions .status-error .test-title {\n color: black;\n}\n\n.test-actions .timer-result {\n color: #888;\n}\n</style>');",27908,17452
openstack%2Ftempest~master~I709500fd32bdc86766de4f72e2032591c2f7aaa3,openstack/tempest,master,I709500fd32bdc86766de4f72e2032591c2f7aaa3,Improve error message on exception raised by get_default,MERGED,2014-12-19 23:49:04.000000000,2014-12-22 09:11:35.000000000,2014-12-22 09:11:34.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-19 23:49:04.000000000', 'files': ['tempest/auth.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/ca1d5e927bf5b546b5226fdd42b03a7b7b81b460', 'message': 'Improve error message on exception raised by get_default\n\nThis commit adds a missing message from the InvalidConfiguration\nexception raised by the get_default method in the credentials classes.\nWithout an explanatory message it is very difficult for users to\nidentify the cause of the configuration error.\n\nChange-Id: I709500fd32bdc86766de4f72e2032591c2f7aaa3\n'}]",0,143219,ca1d5e927bf5b546b5226fdd42b03a7b7b81b460,8,4,1,5196,,,0,"Improve error message on exception raised by get_default

This commit adds a missing message from the InvalidConfiguration
exception raised by the get_default method in the credentials classes.
Without an explanatory message it is very difficult for users to
identify the cause of the configuration error.

Change-Id: I709500fd32bdc86766de4f72e2032591c2f7aaa3
",git fetch https://review.opendev.org/openstack/tempest refs/changes/19/143219/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/auth.py'],1,ca1d5e927bf5b546b5226fdd42b03a7b7b81b460,error-message-cleanup," msg = (""The %s credentials are incorrectly set in the config file."" "" Double check that all required values are assigned"" % credentials_type) raise exceptions.InvalidConfiguration(msg)", raise exceptions.InvalidConfiguration(),4,1
openstack%2Fhorizon~master~I611a997de17714d121c334aa6c5bc35a14bb717a,openstack/horizon,master,I611a997de17714d121c334aa6c5bc35a14bb717a,Imported Translations from Transifex,MERGED,2014-12-22 06:06:21.000000000,2014-12-22 09:11:24.000000000,2014-12-22 09:11:22.000000000,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 6610}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-12-22 06:06:21.000000000', 'files': ['openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/7a753811067dacd09b243bca54e9103e574c6c47', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I611a997de17714d121c334aa6c5bc35a14bb717a\n'}]",0,143369,7a753811067dacd09b243bca54e9103e574c6c47,8,4,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I611a997de17714d121c334aa6c5bc35a14bb717a
",git fetch https://review.opendev.org/openstack/horizon refs/changes/69/143369/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po'],1,7a753811067dacd09b243bca54e9103e574c6c47,transifex/translations,"""POT-Creation-Date: 2014-12-20 01:30-0600\n"" ""PO-Revision-Date: 2014-12-21 12:41+0000\n"" ""Last-Translator: Yongbok Kim <ruo91@yongbok.net>\n""msgstr ""보안 그룹 목록을 가져올 수 없습니다.""msgstr ""인스턴스 %s 의 현재 보안 그룹 목록을 가져올 수 없습니다.""msgstr ""%(num_groups_to_modify)d 인스턴스 보안 그룹 수정에 실패했습니다: %(err)s""msgstr ""%d 인스턴스 보안 그룹을 수정하지 못하였습니다.""msgstr ""종류""msgstr ""소스의 네임스페이스를 정의""msgstr ""메타데이터 정의 파일""msgstr ""로컬 메타데이터 정의 파일을 업로드 합니다.""msgstr ""JSON 네임스페이스""msgstr ""파일 및 직접 입력은 모두 지정할 수 없습니다.""msgstr ""%s의 네임스페이스를 가져오는 중에 문제가 발생했습니다""msgstr ""%s의 네임스페이스가 생성 되었습니다.""msgstr ""%s의 새 네임스페이스 만들 수 없습니다.""msgstr ""%s의 네임스페이스 자원 종류를 업데이트 하였습니다.""msgstr ""%s의 네임스페이스 자원 종류 업데이트 중 오류가 발생했습니다.""msgstr ""메타데이터 정의""msgstr ""네임스페이스 가져오기""msgstr[0] ""네임스페이스 삭제""msgstr[0] ""삭제 된 네임스페이스""msgstr ""연관 업데이트""msgstr ""자원 종류""msgstr ""네임스페이스""msgstr ""네임스페이스 개요""msgstr ""네임스페이스의 세부 정보를 찾지 못했습니다.""msgstr ""내용""msgstr ""네임스페이스의 내용을 찾지 못했습니다.""msgstr ""메타데이터 정의를 받는 중에 오류가 발생했습니다.""msgstr ""자원 종류의 관련 된 것을 얻는 중에 오류가 발생했습니다.""msgstr ""가져올 메타 데이터 정의 네임스페이스를 지정합니다.""msgstr ""raw JSON 형식의 정의만 지원합니다.""msgstr ""관리자 참고 : 다음의 CLI 명령을 사용하여 Glance의 기본 정의를 가져올 수 있습니다.""msgstr ""정의되지 않은""msgstr ""네임스페이스""msgstr ""자원 종류의 관련된""msgstr ""등록 대상:""msgstr ""관련된 정의가 없습니다.""msgstr ""자원 종류의 관련된 네임스페이스""msgstr ""메타데이터 네임스페이스 생성""msgstr ""네임스페이스 세부 정보""msgstr ""네임스페이스 세부 정보:""msgstr ""사용 가능한 종류""msgstr ""UP""msgstr ""DOWN""msgstr ""UP""msgstr ""DOWN""msgstr ""볼륨 타입별 연결 QOS 성능""msgstr ""규칙 관리""msgstr ""보안 그룹 규칙 관리: %(security_group)s""msgstr ""보안 그룹 규칙 관리""msgstr ""UP""msgstr ""DOWN""","""POT-Creation-Date: 2014-12-19 15:20-0600\n"" ""PO-Revision-Date: 2014-12-19 21:20+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgstr ""시큐리티 그룹 목록을 가져올 수 없습니다.""msgstr ""인스턴스 %s 의 현재 시큐리티 그룹 목록을 가져올 수 없습니다.""msgstr ""%(num_groups_to_modify)d 인스턴스 시큐리티 그룹 수정에 실패했습니다: %(err)s""msgstr ""%d 인스턴스 시큐리티 그룹을 수정하지 못하였습니다.""msgstr ""타입""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr[0] """"msgstr[0] """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr ""룰 관리""msgstr """"msgstr ""시큐리티 그룹 룰 관리""msgstr """"msgstr """"",54,54
openstack%2Fec2-api~master~I151478b9818564229a5e6b3874883cf861aeafaf,openstack/ec2-api,master,I151478b9818564229a5e6b3874883cf861aeafaf,Keypair Unit tests,ABANDONED,2014-12-21 21:36:56.000000000,2014-12-22 07:58:11.000000000,,"[{'_account_id': 3}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-12-21 21:36:56.000000000', 'files': ['ec2api/tests/test_key_pair.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/aa114aca3a0ee58c344111303a08512be5f2ea27', 'message': 'Keypair Unit tests\n\nChange-Id: I151478b9818564229a5e6b3874883cf861aeafaf\n'}]",1,143319,aa114aca3a0ee58c344111303a08512be5f2ea27,4,3,1,9312,,,0,"Keypair Unit tests

Change-Id: I151478b9818564229a5e6b3874883cf861aeafaf
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/19/143319/1 && git format-patch -1 --stdout FETCH_HEAD,['ec2api/tests/test_key_pair.py'],1,aa114aca3a0ee58c344111303a08512be5f2ea27,,"# Copyright 2014 # The Cloudscaling Group, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import base64 from novaclient import exceptions as nova_exception from ec2api.tests import base from ec2api.tests import fakes from ec2api.tests import matchers from ec2api.tests import tools class KeyPairCase(base.ApiTestCase): def test_create_key_pair(self): self.nova_key_pairs.create.return_value = ( fakes.NovaKeyPair(fakes.OS_KEY_PAIR)) resp = self.execute('CreateKeyPair', {'KeyName': 'keyname'}) self.assertEqual(200, resp['status']) self.assertThat(fakes.EC2_KEY_PAIR, matchers.DictMatches( tools.purge_dict(resp, {'status'}))) self.nova_key_pairs.create.assert_called_once_with('keyname') def test_create_key_pair_invalid(self): self.nova_key_pairs.create.side_effect = ( nova_exception.Conflict(409)) resp = self.execute('CreateKeyPair', {'KeyName': 'keyname'}) self.assertEqual(400, resp['status']) self.assertEqual('InvalidKeyPair.Duplicate', resp['Error']['Code']) resp = self.execute('CreateKeyPair', {'KeyName': 'k' * 256}) self.assertEqual(400, resp['status']) self.assertEqual('InvalidParameterValue', resp['Error']['Code']) self.nova_key_pairs.create.side_effect = ( nova_exception.OverLimit(413)) resp = self.execute('CreateKeyPair', {'KeyName': 'keyname'}) self.assertEqual(400, resp['status']) self.assertEqual('ResourceLimitExceeded', resp['Error']['Code']) def test_import_key_pair(self): self.nova_key_pairs.create.return_value = ( fakes.NovaKeyPair(fakes.OS_KEY_PAIR)) resp = self.execute('ImportKeyPair', {'KeyName': 'keyname', 'PublicKeyMaterial': base64.b64encode( fakes.PUBLIC_KEY)}) self.assertEqual(200, resp['status']) self.assertThat(tools.purge_dict(fakes.EC2_KEY_PAIR, {'keyMaterial'}), matchers.DictMatches(tools.purge_dict(resp, {'status'}))) self.nova_key_pairs.create.assert_called_once_with('keyname', fakes.PUBLIC_KEY) def test_import_key_pair_invalid(self): self.nova_key_pairs.create.side_effect = ( nova_exception.OverLimit(413)) resp = self.execute('ImportKeyPair', {'KeyName': 'keyname', 'PublicKeyMaterial': base64.b64encode( fakes.PUBLIC_KEY)}) self.assertEqual(400, resp['status']) self.assertEqual('ResourceLimitExceeded', resp['Error']['Code']) def test_delete_key_pair(self): self.nova_key_pairs.delete.return_value = True resp = self.execute('DeleteKeyPair', {'KeyName': 'keyname'}) self.assertEqual(200, resp['status']) self.nova_key_pairs.delete.assert_called_once_with('keyname') self.nova_key_pairs.delete.side_effect = nova_exception.NotFound(404) resp = self.execute('DeleteKeyPair', {'KeyName': 'keyname1'}) self.assertEqual(200, resp['status']) self.nova_key_pairs.delete.assert_any_call('keyname1') def test_describe_key_pair(self): self.nova_key_pairs.list.return_value = [fakes.NovaKeyPair( fakes.OS_KEY_PAIR)] resp = self.execute('DescribeKeyPairs', {}) self.assertEqual(200, resp['status']) self.assertThat(resp['keySet'], matchers.ListMatches([ tools.purge_dict(fakes.EC2_KEY_PAIR, {'keyMaterial'})])) self.nova_key_pairs.list.assert_called_once() def test_describe_key_pair_invalid(self): self.nova_key_pairs.list.return_value = [fakes.NovaKeyPair( fakes.OS_KEY_PAIR)] resp = self.execute('DescribeKeyPairs', {'KeyName': 'badname'}) self.assertEqual(404, resp['status']) self.assertEqual('InvalidKeyPair.NotFound', resp['Error']['Code']) self.nova_key_pairs.list.assert_called_once() ",,101,0
openstack%2Ftricircle~master~I5f2fc693e15662dd5173afd40ecb784f7ac26ce4,openstack/tricircle,master,I5f2fc693e15662dd5173afd40ecb784f7ac26ce4,modified README.md for installation cinder-proxy,MERGED,2014-12-22 07:14:12.000000000,2014-12-22 07:16:30.000000000,2014-12-22 07:16:30.000000000,"[{'_account_id': 3}, {'_account_id': 13924}]","[{'number': 1, 'created': '2014-12-22 07:14:12.000000000', 'files': ['cinderproxy/README.md'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/757910ecc82227d579a092b4e6f54ed8e215f305', 'message': 'modified README.md for installation cinder-proxy\n\nChange-Id: I5f2fc693e15662dd5173afd40ecb784f7ac26ce4\n'}]",0,143379,757910ecc82227d579a092b4e6f54ed8e215f305,6,2,1,13924,,,0,"modified README.md for installation cinder-proxy

Change-Id: I5f2fc693e15662dd5173afd40ecb784f7ac26ce4
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/79/143379/1 && git format-patch -1 --stdout FETCH_HEAD,['cinderproxy/README.md'],1,757910ecc82227d579a092b4e6f54ed8e215f305,, voltype_sync_interval=3600 pagination_limit=50 cinder_tenant_id=$CASCADED_ADMIN_ID voltype_sync_interval=3600 pagination_limit=50 cinder_tenant_id=$CASCADED_ADMIN_ID,,6,0
openstack%2Ftricircle~master~I3d6bf4589a0f3523b4e465fa46f590085f8accb3,openstack/tricircle,master,I3d6bf4589a0f3523b4e465fa46f590085f8accb3,modify install script and remove uuid-mapping-patch,MERGED,2014-12-22 06:02:33.000000000,2014-12-22 06:08:06.000000000,2014-12-22 06:08:06.000000000,"[{'_account_id': 3}, {'_account_id': 13924}]","[{'number': 1, 'created': '2014-12-22 06:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/c686c22b6ea9774f0b2e0fb75c94846d93601c9b', 'message': 'modify install.sh for cinderproxy and remove uuid-mapping-patch\n\nChange-Id: I3d6bf4589a0f3523b4e465fa46f590085f8accb3\n'}, {'number': 2, 'created': '2014-12-22 06:07:08.000000000', 'files': ['juno-patches/cinder/uuid-mapping-patch/cinder/db/sqlalchemy/migrate_repo/versions/023_add_mapping_uuid.py', 'juno-patches/cinder/uuid-mapping-patch/installation/uninstall.sh', 'juno-patches/cinder/uuid-mapping-patch/README.md', 'juno-patches/cinder/README.md', 'juno-patches/cinder/uuid-mapping-patch/installation/install.sh', 'juno-patches/cinder/uuid-mapping-patch/cinder/db/sqlalchemy/migrate_repo/versions/024_snapshots_add_mapping_uuid.py', 'juno-patches/cinder/uuid-mapping-patch/cinder/db/sqlalchemy/migrate_repo/versions/025_backup_add_mapping_uuid.py', 'cinderproxy/installation/install.sh', 'cinderproxy/cinder/volume/cinder_proxy.py', 'juno-patches/cinder/uuid-mapping-patch/cinder/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/f5e3a8407b45c401799cb7c19d4e4e1be9c0ff04', 'message': 'modify install script and remove uuid-mapping-patch\n\n\n1.add [cinder_tenant_id] and [pagination_limit] fields for for cinder-proxy\n2.remove uuid-mapping-path\n3.delete README.md for creating volume from image BUG explanation\n\nChange-Id: I3d6bf4589a0f3523b4e465fa46f590085f8accb3\n'}]",0,143368,f5e3a8407b45c401799cb7c19d4e4e1be9c0ff04,8,2,2,13924,,,0,"modify install script and remove uuid-mapping-patch


1.add [cinder_tenant_id] and [pagination_limit] fields for for cinder-proxy
2.remove uuid-mapping-path
3.delete README.md for creating volume from image BUG explanation

Change-Id: I3d6bf4589a0f3523b4e465fa46f590085f8accb3
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/68/143368/1 && git format-patch -1 --stdout FETCH_HEAD,"['juno-patches/cinder/uuid-mapping-patch/cinder/db/sqlalchemy/migrate_repo/versions/023_add_mapping_uuid.py', 'juno-patches/cinder/uuid-mapping-patch/installation/uninstall.sh', 'juno-patches/cinder/README.md', 'juno-patches/cinder/uuid-mapping-patch/README.md', 'juno-patches/cinder/uuid-mapping-patch/installation/install.sh', 'juno-patches/cinder/uuid-mapping-patch/cinder/db/sqlalchemy/migrate_repo/versions/024_snapshots_add_mapping_uuid.py', 'juno-patches/cinder/uuid-mapping-patch/cinder/db/sqlalchemy/migrate_repo/versions/025_backup_add_mapping_uuid.py', 'cinderproxy/cinder/volume/cinder_proxy.py', 'cinderproxy/installation/install.sh', 'juno-patches/cinder/uuid-mapping-patch/cinder/db/sqlalchemy/models.py']",10,c686c22b6ea9774f0b2e0fb75c94846d93601c9b,,,"# Copyright (c) 2011 X.commerce, a business unit of eBay Inc. # Copyright 2010 United States Government as represented by the # Administrator of the National Aeronautics and Space Administration. # Copyright 2011 Piston Cloud Computing, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" SQLAlchemy models for cinder data. """""" from oslo.config import cfg from oslo.db.sqlalchemy import models from sqlalchemy import Column, Integer, String, Text, schema from sqlalchemy.ext.declarative import declarative_base from sqlalchemy import ForeignKey, DateTime, Boolean from sqlalchemy.orm import relationship, backref from cinder.openstack.common import timeutils CONF = cfg.CONF BASE = declarative_base() class CinderBase(models.TimestampMixin, models.ModelBase): """"""Base class for Cinder Models."""""" __table_args__ = {'mysql_engine': 'InnoDB'} # TODO(rpodolyaka): reuse models.SoftDeleteMixin in the next stage # of implementing of BP db-cleanup deleted_at = Column(DateTime) deleted = Column(Boolean, default=False) metadata = None def delete(self, session): """"""Delete this object."""""" self.deleted = True self.deleted_at = timeutils.utcnow() self.save(session=session) class Service(BASE, CinderBase): """"""Represents a running service on a host."""""" __tablename__ = 'services' id = Column(Integer, primary_key=True) host = Column(String(255)) # , ForeignKey('hosts.id')) binary = Column(String(255)) topic = Column(String(255)) report_count = Column(Integer, nullable=False, default=0) disabled = Column(Boolean, default=False) availability_zone = Column(String(255), default='cinder') disabled_reason = Column(String(255)) class ConsistencyGroup(BASE, CinderBase): """"""Represents a consistencygroup."""""" __tablename__ = 'consistencygroups' id = Column(String(36), primary_key=True) user_id = Column(String(255), nullable=False) project_id = Column(String(255), nullable=False) host = Column(String(255)) availability_zone = Column(String(255)) name = Column(String(255)) description = Column(String(255)) volume_type_id = Column(String(255)) status = Column(String(255)) class Cgsnapshot(BASE, CinderBase): """"""Represents a cgsnapshot."""""" __tablename__ = 'cgsnapshots' id = Column(String(36), primary_key=True) consistencygroup_id = Column(String(36)) user_id = Column(String(255), nullable=False) project_id = Column(String(255), nullable=False) name = Column(String(255)) description = Column(String(255)) status = Column(String(255)) consistencygroup = relationship( ConsistencyGroup, backref=""cgsnapshots"", foreign_keys=consistencygroup_id, primaryjoin='Cgsnapshot.consistencygroup_id == ConsistencyGroup.id') class Volume(BASE, CinderBase): """"""Represents a block storage device that can be attached to a vm."""""" __tablename__ = 'volumes' id = Column(String(36), primary_key=True) _name_id = Column(String(36)) # Don't access/modify this directly! @property def name_id(self): return self.id if not self._name_id else self._name_id @name_id.setter def name_id(self, value): self._name_id = value @property def name(self): return CONF.volume_name_template % self.name_id ec2_id = Column(Integer) user_id = Column(String(255)) project_id = Column(String(255)) snapshot_id = Column(String(36)) host = Column(String(255)) # , ForeignKey('hosts.id')) size = Column(Integer) availability_zone = Column(String(255)) # TODO(vish): foreign key? instance_uuid = Column(String(36)) attached_host = Column(String(255)) mountpoint = Column(String(255)) attach_time = Column(String(255)) # TODO(vish): datetime status = Column(String(255)) # TODO(vish): enum? attach_status = Column(String(255)) # TODO(vish): enum migration_status = Column(String(255)) scheduled_at = Column(DateTime) launched_at = Column(DateTime) terminated_at = Column(DateTime) display_name = Column(String(255)) display_description = Column(String(255)) provider_location = Column(String(255)) provider_auth = Column(String(255)) provider_geometry = Column(String(255)) volume_type_id = Column(String(36)) source_volid = Column(String(36)) encryption_key_id = Column(String(36)) consistencygroup_id = Column(String(36)) deleted = Column(Boolean, default=False) bootable = Column(Boolean, default=False) replication_status = Column(String(255)) replication_extended_status = Column(String(255)) replication_driver_data = Column(String(255)) mapping_uuid = Column(String(36)) consistencygroup = relationship( ConsistencyGroup, backref=""volumes"", foreign_keys=consistencygroup_id, primaryjoin='Volume.consistencygroup_id == ConsistencyGroup.id') class VolumeMetadata(BASE, CinderBase): """"""Represents a metadata key/value pair for a volume."""""" __tablename__ = 'volume_metadata' id = Column(Integer, primary_key=True) key = Column(String(255)) value = Column(String(255)) volume_id = Column(String(36), ForeignKey('volumes.id'), nullable=False) volume = relationship(Volume, backref=""volume_metadata"", foreign_keys=volume_id, primaryjoin='and_(' 'VolumeMetadata.volume_id == Volume.id,' 'VolumeMetadata.deleted == False)') class VolumeAdminMetadata(BASE, CinderBase): """"""Represents an administrator metadata key/value pair for a volume."""""" __tablename__ = 'volume_admin_metadata' id = Column(Integer, primary_key=True) key = Column(String(255)) value = Column(String(255)) volume_id = Column(String(36), ForeignKey('volumes.id'), nullable=False) volume = relationship(Volume, backref=""volume_admin_metadata"", foreign_keys=volume_id, primaryjoin='and_(' 'VolumeAdminMetadata.volume_id == Volume.id,' 'VolumeAdminMetadata.deleted == False)') class VolumeTypes(BASE, CinderBase): """"""Represent possible volume_types of volumes offered."""""" __tablename__ = ""volume_types"" id = Column(String(36), primary_key=True) name = Column(String(255)) # A reference to qos_specs entity qos_specs_id = Column(String(36), ForeignKey('quality_of_service_specs.id')) volumes = relationship(Volume, backref=backref('volume_type', uselist=False), foreign_keys=id, primaryjoin='and_(' 'Volume.volume_type_id == VolumeTypes.id, ' 'VolumeTypes.deleted == False)') class VolumeTypeExtraSpecs(BASE, CinderBase): """"""Represents additional specs as key/value pairs for a volume_type."""""" __tablename__ = 'volume_type_extra_specs' id = Column(Integer, primary_key=True) key = Column(String(255)) value = Column(String(255)) volume_type_id = Column(String(36), ForeignKey('volume_types.id'), nullable=False) volume_type = relationship( VolumeTypes, backref=""extra_specs"", foreign_keys=volume_type_id, primaryjoin='and_(' 'VolumeTypeExtraSpecs.volume_type_id == VolumeTypes.id,' 'VolumeTypeExtraSpecs.deleted == False)' ) class QualityOfServiceSpecs(BASE, CinderBase): """"""Represents QoS specs as key/value pairs. QoS specs is standalone entity that can be associated/disassociated with volume types (one to many relation). Adjacency list relationship pattern is used in this model in order to represent following hierarchical data with in flat table, e.g, following structure qos-specs-1 'Rate-Limit' | +------> consumer = 'front-end' +------> total_bytes_sec = 1048576 +------> total_iops_sec = 500 qos-specs-2 'QoS_Level1' | +------> consumer = 'back-end' +------> max-iops = 1000 +------> min-iops = 200 is represented by: id specs_id key value ------ -------- ------------- ----- UUID-1 NULL QoSSpec_Name Rate-Limit UUID-2 UUID-1 consumer front-end UUID-3 UUID-1 total_bytes_sec 1048576 UUID-4 UUID-1 total_iops_sec 500 UUID-5 NULL QoSSpec_Name QoS_Level1 UUID-6 UUID-5 consumer back-end UUID-7 UUID-5 max-iops 1000 UUID-8 UUID-5 min-iops 200 """""" __tablename__ = 'quality_of_service_specs' id = Column(String(36), primary_key=True) specs_id = Column(String(36), ForeignKey(id)) key = Column(String(255)) value = Column(String(255)) specs = relationship( ""QualityOfServiceSpecs"", cascade=""all, delete-orphan"", backref=backref(""qos_spec"", remote_side=id), ) vol_types = relationship( VolumeTypes, backref=backref('qos_specs'), foreign_keys=id, primaryjoin='and_(' 'or_(VolumeTypes.qos_specs_id == ' 'QualityOfServiceSpecs.id,' 'VolumeTypes.qos_specs_id == ' 'QualityOfServiceSpecs.specs_id),' 'QualityOfServiceSpecs.deleted == False)') class VolumeGlanceMetadata(BASE, CinderBase): """"""Glance metadata for a bootable volume."""""" __tablename__ = 'volume_glance_metadata' id = Column(Integer, primary_key=True, nullable=False) volume_id = Column(String(36), ForeignKey('volumes.id')) snapshot_id = Column(String(36), ForeignKey('snapshots.id')) key = Column(String(255)) value = Column(Text) volume = relationship(Volume, backref=""volume_glance_metadata"", foreign_keys=volume_id, primaryjoin='and_(' 'VolumeGlanceMetadata.volume_id == Volume.id,' 'VolumeGlanceMetadata.deleted == False)') class Quota(BASE, CinderBase): """"""Represents a single quota override for a project. If there is no row for a given project id and resource, then the default for the quota class is used. If there is no row for a given quota class and resource, then the default for the deployment is used. If the row is present but the hard limit is Null, then the resource is unlimited. """""" __tablename__ = 'quotas' id = Column(Integer, primary_key=True) project_id = Column(String(255), index=True) resource = Column(String(255)) hard_limit = Column(Integer, nullable=True) class QuotaClass(BASE, CinderBase): """"""Represents a single quota override for a quota class. If there is no row for a given quota class and resource, then the default for the deployment is used. If the row is present but the hard limit is Null, then the resource is unlimited. """""" __tablename__ = 'quota_classes' id = Column(Integer, primary_key=True) class_name = Column(String(255), index=True) resource = Column(String(255)) hard_limit = Column(Integer, nullable=True) class QuotaUsage(BASE, CinderBase): """"""Represents the current usage for a given resource."""""" __tablename__ = 'quota_usages' id = Column(Integer, primary_key=True) project_id = Column(String(255), index=True) resource = Column(String(255)) in_use = Column(Integer) reserved = Column(Integer) @property def total(self): return self.in_use + self.reserved until_refresh = Column(Integer, nullable=True) class Reservation(BASE, CinderBase): """"""Represents a resource reservation for quotas."""""" __tablename__ = 'reservations' id = Column(Integer, primary_key=True) uuid = Column(String(36), nullable=False) usage_id = Column(Integer, ForeignKey('quota_usages.id'), nullable=False) project_id = Column(String(255), index=True) resource = Column(String(255)) delta = Column(Integer) expire = Column(DateTime, nullable=False) usage = relationship( ""QuotaUsage"", foreign_keys=usage_id, primaryjoin='and_(Reservation.usage_id == QuotaUsage.id,' 'QuotaUsage.deleted == 0)') class Snapshot(BASE, CinderBase): """"""Represents a snapshot of volume."""""" __tablename__ = 'snapshots' id = Column(String(36), primary_key=True) @property def name(self): return CONF.snapshot_name_template % self.id @property def volume_name(self): return self.volume.name # pylint: disable=E1101 user_id = Column(String(255)) project_id = Column(String(255)) volume_id = Column(String(36)) cgsnapshot_id = Column(String(36)) status = Column(String(255)) progress = Column(String(255)) volume_size = Column(Integer) display_name = Column(String(255)) display_description = Column(String(255)) encryption_key_id = Column(String(36)) volume_type_id = Column(String(36)) provider_location = Column(String(255)) mapping_uuid = Column(String(36)) volume = relationship(Volume, backref=""snapshots"", foreign_keys=volume_id, primaryjoin='Snapshot.volume_id == Volume.id') cgsnapshot = relationship( Cgsnapshot, backref=""snapshots"", foreign_keys=cgsnapshot_id, primaryjoin='Snapshot.cgsnapshot_id == Cgsnapshot.id') class SnapshotMetadata(BASE, CinderBase): """"""Represents a metadata key/value pair for a snapshot."""""" __tablename__ = 'snapshot_metadata' id = Column(Integer, primary_key=True) key = Column(String(255)) value = Column(String(255)) snapshot_id = Column(String(36), ForeignKey('snapshots.id'), nullable=False) snapshot = relationship(Snapshot, backref=""snapshot_metadata"", foreign_keys=snapshot_id, primaryjoin='and_(' 'SnapshotMetadata.snapshot_id == Snapshot.id,' 'SnapshotMetadata.deleted == False)') class IscsiTarget(BASE, CinderBase): """"""Represents an iscsi target for a given host."""""" __tablename__ = 'iscsi_targets' __table_args__ = (schema.UniqueConstraint(""target_num"", ""host""), {'mysql_engine': 'InnoDB'}) id = Column(Integer, primary_key=True) target_num = Column(Integer) host = Column(String(255)) volume_id = Column(String(36), ForeignKey('volumes.id'), nullable=True) volume = relationship(Volume, backref=backref('iscsi_target', uselist=False), foreign_keys=volume_id, primaryjoin='and_(IscsiTarget.volume_id==Volume.id,' 'IscsiTarget.deleted==False)') class Backup(BASE, CinderBase): """"""Represents a backup of a volume to Swift."""""" __tablename__ = 'backups' id = Column(String(36), primary_key=True) @property def name(self): return CONF.backup_name_template % self.id user_id = Column(String(255), nullable=False) project_id = Column(String(255), nullable=False) volume_id = Column(String(36), nullable=False) host = Column(String(255)) availability_zone = Column(String(255)) display_name = Column(String(255)) display_description = Column(String(255)) container = Column(String(255)) status = Column(String(255)) fail_reason = Column(String(255)) service_metadata = Column(String(255)) service = Column(String(255)) size = Column(Integer) object_count = Column(Integer) mapping_uuid = Column(String(36)) class Encryption(BASE, CinderBase): """"""Represents encryption requirement for a volume type. Encryption here is a set of performance characteristics describing cipher, provider, and key_size for a certain volume type. """""" __tablename__ = 'encryption' cipher = Column(String(255)) key_size = Column(Integer) provider = Column(String(255)) control_location = Column(String(255)) volume_type_id = Column(String(36), ForeignKey('volume_types.id'), primary_key=True) volume_type = relationship( VolumeTypes, backref=""encryption"", foreign_keys=volume_type_id, primaryjoin='and_(' 'Encryption.volume_type_id == VolumeTypes.id,' 'Encryption.deleted == False)' ) class Transfer(BASE, CinderBase): """"""Represents a volume transfer request."""""" __tablename__ = 'transfers' id = Column(String(36), primary_key=True) volume_id = Column(String(36), ForeignKey('volumes.id')) display_name = Column(String(255)) salt = Column(String(255)) crypt_hash = Column(String(255)) expires_at = Column(DateTime) volume = relationship(Volume, backref=""transfer"", foreign_keys=volume_id, primaryjoin='and_(' 'Transfer.volume_id == Volume.id,' 'Transfer.deleted == False)') def register_models(): """"""Register Models and create metadata. Called from cinder.db.sqlalchemy.__init__ as part of loading the driver, it will never need to be called explicitly elsewhere unless the connection is lost and needs to be reestablished. """""" from sqlalchemy import create_engine models = (Backup, Service, Volume, VolumeMetadata, VolumeAdminMetadata, SnapshotMetadata, Transfer, VolumeTypeExtraSpecs, VolumeTypes, VolumeGlanceMetadata, ConsistencyGroup, Cgsnapshot ) engine = create_engine(CONF.database.connection, echo=False) for model in models: model.metadata.create_all(engine) ",2,975
openstack%2Fec2-api~master~I4004c9c1b68bee707122f45016d3a7dbb4a7beec,openstack/ec2-api,master,I4004c9c1b68bee707122f45016d3a7dbb4a7beec,Added absent security groups unit tests and functionality,MERGED,2014-12-20 16:56:36.000000000,2014-12-22 05:55:55.000000000,2014-12-22 05:55:55.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-12-20 16:56:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/8e46a18c184cc848a525de20960269c6098a2a4c', 'message': 'Added absent security groups unit tests and functionality\n\nChange-Id: I4004c9c1b68bee707122f45016d3a7dbb4a7beec\n'}, {'number': 2, 'created': '2014-12-20 17:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/997d7a1a930d7a2eb82e78c7a4bf17c68b799cdc', 'message': 'Added absent security groups unit tests and functionality\n\nChange-Id: I4004c9c1b68bee707122f45016d3a7dbb4a7beec\n'}, {'number': 3, 'created': '2014-12-20 19:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/88d3fa64e32a593ed28d1606c866102fb55701e1', 'message': 'Added absent security groups unit tests and functionality\n\nChange-Id: I4004c9c1b68bee707122f45016d3a7dbb4a7beec\n'}, {'number': 4, 'created': '2014-12-21 11:34:00.000000000', 'files': ['ec2api/db/sqlalchemy/api.py', 'ec2api/tests/fakes.py', 'ec2api/api/ec2utils.py', 'ec2api/exception.py', 'ec2api/api/security_group.py', 'ec2api/tests/test_security_group.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/8053ca77bbf17f1b9f82387a3e2bef3ad1e20ec4', 'message': 'Added absent security groups unit tests and functionality\n\nChange-Id: I4004c9c1b68bee707122f45016d3a7dbb4a7beec\n'}]",6,143276,8053ca77bbf17f1b9f82387a3e2bef3ad1e20ec4,24,4,4,9312,,,0,"Added absent security groups unit tests and functionality

Change-Id: I4004c9c1b68bee707122f45016d3a7dbb4a7beec
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/76/143276/4 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/db/sqlalchemy/api.py', 'ec2api/tests/fakes.py', 'ec2api/api/ec2utils.py', 'ec2api/api/security_group.py', 'ec2api/exception.py', 'ec2api/tests/test_security_group.py']",6,8e46a18c184cc848a525de20960269c6098a2a4c,,"from novaclient import exceptions as nova_exception def test_create_security_group_invalid(self): security_group.security_group_engine = ( security_group.SecurityGroupEngineNeutron()) def check_response(resp, error_code): self.assertEqual(400, resp['status']) self.assertEqual(error_code, resp['Error']['Code']) self.neutron.reset_mock() self.db_api.reset_mock() self.db_api.get_item_by_id.return_value = None resp = self.execute( 'CreateSecurityGroup', {'VpcId': fakes.ID_EC2_VPC_1, 'GroupName': 'groupname', 'GroupDescription': 'Group description'}) self.db_api.get_item_by_id.assert_called_once_with(mock.ANY, 'vpc', fakes.ID_EC2_VPC_1) check_response(resp, 'InvalidVpcID.NotFound') resp = self.execute( 'CreateSecurityGroup', {'VpcId': fakes.ID_EC2_VPC_1, 'GroupName': 'aa #^% -=99', 'GroupDescription': 'Group description'}) check_response(resp, 'ValidationError') resp = self.execute( 'CreateSecurityGroup', {'VpcId': fakes.ID_EC2_VPC_1, 'GroupName': 'groupname', 'GroupDescription': 'aa #^% -=99'}) check_response(resp, 'ValidationError') resp = self.execute( 'CreateSecurityGroup', {'GroupName': 'aa \t\x01\x02\x7f', 'GroupDescription': 'Group description'}) check_response(resp, 'ValidationError') resp = self.execute( 'CreateSecurityGroup', {'GroupName': 'groupname', 'GroupDescription': 'aa \t\x01\x02\x7f'}) check_response(resp, 'ValidationError') resp = self.execute( 'CreateSecurityGroup', {'GroupName': 'x'*256, 'GroupDescription': 'Group description'}) check_response(resp, 'ValidationError') resp = self.execute( 'CreateSecurityGroup', {'GroupName': 'groupname', 'GroupDescription': 'x'*256}) check_response(resp, 'ValidationError') resp = self.execute( 'CreateSecurityGroup', {'GroupName': 'groupname'}) check_response(resp, 'MissingParameter') resp = self.execute( 'CreateSecurityGroup', {'GroupDescription': 'description'}) check_response(resp, 'MissingParameter') def test_create_security_group_over_quota(self): security_group.security_group_engine = ( security_group.SecurityGroupEngineNeutron()) self.nova_security_groups.create.side_effect = ( nova_exception.OverLimit(413)) resp = self.execute( 'CreateSecurityGroup', {'VpcId': fakes.ID_EC2_VPC_1, 'GroupName': 'groupname', 'GroupDescription': 'Group description'}) self.assertEqual(400, resp['status']) self.assertEqual('ResourceLimitExceeded', resp['Error']['Code']) self.nova_security_groups.create.assert_called_once_with( 'groupname', 'Group description') resp = self.execute( 'DeleteSecurityGroup', {'GroupId': fakes.ID_OS_SECURITY_GROUP_2}) self.assertEqual(200, resp['status']) self.assertEqual(True, resp['return']) self.nova_security_groups.delete.assert_any_call( fakes.ID_OS_SECURITY_GROUP_2) def test_delete_security_group_invalid(self): resp = self.execute( 'DeleteSecurityGroup', {'GroupName': 'badname'}) self.assertEqual(400, resp['status']) self.assertEqual('InvalidGroup.NotFound', resp['Error']['Code']) self.assertEqual(0, self.neutron.delete_port.call_count) resp = self.execute( 'DeleteSecurityGroup', {}) self.assertEqual(400, resp['status']) self.assertEqual('MissingParameter', resp['Error']['Code']) self.assertEqual(0, self.neutron.delete_port.call_count) resp = self.execute('DescribeSecurityGroups', {'GroupName.1': 'groupname2'}) self.assertEqual(200, resp['status']) self.assertThat(resp['securityGroupInfo'], matchers.ListMatches( [fakes.EC2_SECURITY_GROUP_2], orderless_lists=True)) self.db_api.get_items_by_ids.return_value = [fakes.DB_SECURITY_GROUP_2] resp = self.execute('DescribeSecurityGroups', {'GroupId.1': fakes.ID_EC2_SECURITY_GROUP_2}) self.assertEqual(200, resp['status']) self.assertThat(resp['securityGroupInfo'], matchers.ListMatches( [fakes.EC2_SECURITY_GROUP_2], orderless_lists=True)) def test_authorize_security_group_invalid(self): security_group.security_group_engine = ( security_group.SecurityGroupEngineNeutron()) def check_response(error_code, protocol, from_port, to_port, cidr, group_id=fakes.ID_EC2_SECURITY_GROUP_2): resp = self.execute( 'AuthorizeSecurityGroupIngress', {'GroupId': group_id, 'IpPermissions.1.FromPort': str(from_port), 'IpPermissions.1.ToPort': str(to_port), 'IpPermissions.1.IpProtocol': protocol, 'IpPermissions.1.IpRanges.1.CidrIp': cidr}) self.assertEqual(400, resp['status']) self.assertEqual(error_code, resp['Error']['Code']) self.neutron.reset_mock() self.db_api.reset_mock() resp = self.execute( 'AuthorizeSecurityGroupIngress', {'GroupId': fakes.ID_EC2_SECURITY_GROUP_2, 'IpPermissions.1.FromPort': '-1', 'IpPermissions.1.ToPort': '-1', 'IpPermissions.1.IpProtocol': 'icmp', 'IpPermissions.1.IpRanges.1.CidrIp': '0.0.0.0/0'}) self.assertEqual(200, resp['status']) # Duplicate rule self.db_api.get_item_by_id.side_effect = copy.deepcopy( fakes.get_db_api_get_item_by_id({ fakes.ID_EC2_SECURITY_GROUP_1: fakes.DB_SECURITY_GROUP_1, fakes.ID_EC2_SECURITY_GROUP_2: fakes.DB_SECURITY_GROUP_2})) self.neutron.create_security_group_rule.side_effect = ( neutron_exception.Conflict) check_response('InvalidPermission.Duplicate', 'icmp', -1, -1, '0.0.0.0/0') # Over quota self.neutron.create_security_group_rule.side_effect = ( neutron_exception.OverQuotaClient) check_response('RulesPerSecurityGroupLimitExceeded', 'icmp', -1, -1, '0.0.0.0/0') # Invalid CIDR address check_response('InvalidParameterValue', 'tcp', 80, 81, '0.0.0.0/0444') # Missing ports check_response('InvalidParameterValue', 'tcp', -1, -1, '0.0.0.0/0') # from port cannot be greater than to port check_response('InvalidParameterValue', 'tcp', 100, 1, '0.0.0.0/0') # For tcp, negative values are not allowed check_response('InvalidParameterValue', 'tcp', -1, 1, '0.0.0.0/0') # For tcp, valid port range 1-65535 check_response('InvalidParameterValue', 'tcp', 1, 65599, '0.0.0.0/0') # Invalid protocol check_response('InvalidParameterValue', 'xyz', 1, 14, '0.0.0.0/0') # Invalid port check_response('InvalidParameterValue', 'tcp', "" "", ""gg"", '0.0.0.0/0') # Invalid icmp port check_response('InvalidParameterValue', 'icmp', "" "", ""gg"", '0.0.0.0/0') # Invalid CIDR Address check_response('InvalidParameterValue', 'icmp', -1, -1, '0.0.0.0') # Invalid CIDR Address check_response('InvalidParameterValue', 'icmp', 5, 10, '0.0.0.0/') # Invalid Cidr ports check_response('InvalidParameterValue', 'icmp', 1, 256, '0.0.0.0/0') # Missing group check_response('MissingParameter', 'tcp', 1, 255, '0.0.0.0/0', None) # Missing cidr check_response('MissingParameter', 'tcp', 1, 255, None) # Invalid remote group resp = self.execute( 'AuthorizeSecurityGroupIngress', {'GroupId': fakes.ID_EC2_SECURITY_GROUP_2, 'IpPermissions.1.IpProtocol': 'icmp', 'IpPermissions.1.Groups.1.GroupName': 'somegroup', 'IpPermissions.1.Groups.1.UserId': 'i-99999999'}) self.assertEqual(400, resp['status']) self.assertEqual('InvalidGroup.NotFound', resp['Error']['Code']) # NOTE(Alex): Openstack extension, AWS-incompability # IPv6 is not supported by Amazon. resp = self.execute( 'AuthorizeSecurityGroupIngress', {'GroupId': fakes.ID_EC2_SECURITY_GROUP_2, 'IpPermissions.1.FromPort': '10', 'IpPermissions.1.ToPort': '10', 'IpPermissions.1.IpProtocol': 'tcp', 'IpPermissions.1.IpRanges.1.CidrIp': '::/0'}) self.assertEqual(200, resp['status']) self.neutron.create_security_group_rule.assert_called_with( {'security_group_rule': tools.patch_dict( fakes.OS_SECURITY_GROUP_RULE_1, {'remote_ip_prefix': '::/0'}, {'id', 'remote_group_id', 'tenant_id'})})", def test_delete_security_group_no_security_group(self):,382,39
openstack%2Ffuel-main~stable%2F6.0~I1dfadebac4f76d18f85ca396a202d3550948042d,openstack/fuel-main,stable/6.0,I1dfadebac4f76d18f85ca396a202d3550948042d,Fixed search Fuel ISO in vbox scripts,MERGED,2014-12-13 05:32:57.000000000,2014-12-22 05:34:44.000000000,2014-12-22 05:34:43.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8786}, {'_account_id': 8797}, {'_account_id': 8967}, {'_account_id': 8971}, {'_account_id': 12200}, {'_account_id': 13274}, {'_account_id': 14036}]","[{'number': 1, 'created': '2014-12-13 05:32:57.000000000', 'files': ['virtualbox/actions/master-node-enable-internet.sh', 'virtualbox/actions/master-node-create-and-install.sh', 'virtualbox/actions/prepare-environment.sh', 'virtualbox/config.sh', 'virtualbox/actions/slave-nodes-create-and-boot.sh', 'virtualbox/actions/create-interfaces.sh', 'virtualbox/actions/clean-previous-installation.sh'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f7defb6ad67e0ff126602e8e3374c0d6c211fd4e', 'message': 'Fixed search Fuel ISO in vbox scripts\n\nFixed relative paths when are invoked other vbox scripts.\nIf we have another config.sh which is located on a different path\nin the variable PATH, we have an error.\n\nChange-Id: I1dfadebac4f76d18f85ca396a202d3550948042d\nCloses-Bug: #1393557\n'}]",0,141536,f7defb6ad67e0ff126602e8e3374c0d6c211fd4e,10,9,1,406,,,0,"Fixed search Fuel ISO in vbox scripts

Fixed relative paths when are invoked other vbox scripts.
If we have another config.sh which is located on a different path
in the variable PATH, we have an error.

Change-Id: I1dfadebac4f76d18f85ca396a202d3550948042d
Closes-Bug: #1393557
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/36/141536/1 && git format-patch -1 --stdout FETCH_HEAD,"['virtualbox/actions/master-node-enable-internet.sh', 'virtualbox/actions/master-node-create-and-install.sh', 'virtualbox/actions/prepare-environment.sh', 'virtualbox/config.sh', 'virtualbox/actions/slave-nodes-create-and-boot.sh', 'virtualbox/actions/create-interfaces.sh', 'virtualbox/actions/clean-previous-installation.sh']",7,f7defb6ad67e0ff126602e8e3374c0d6c211fd4e,,source ./config.sh source ./functions/vm.sh source ./functions/network.sh,source config.sh source functions/vm.sh source functions/network.sh,18,18
openstack%2Fneutron~master~Iea6159c5949a63a0b680818a3fd0928d470115bd,openstack/neutron,master,Iea6159c5949a63a0b680818a3fd0928d470115bd,openvswitch/ofagent: Remove OVS.enable_tunneling option,MERGED,2014-10-24 07:27:06.000000000,2014-12-22 05:31:03.000000000,2014-12-18 09:47:24.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 1561}, {'_account_id': 2592}, {'_account_id': 4149}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6502}, {'_account_id': 6524}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7743}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9911}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10237}, {'_account_id': 10294}, {'_account_id': 10370}, {'_account_id': 10503}, {'_account_id': 11698}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-10-24 07:27:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/063c6d373134d06cd09a1518a097df88c2128506', 'message': 'openvswitch/ofagent: Mention deprecation of enable_tunneling\n\nUpdate the help string to make it clear this option is deprecated.\n\nChange-Id: Iea6159c5949a63a0b680818a3fd0928d470115bd\n'}, {'number': 2, 'created': '2014-10-28 03:14:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7bc8b39671b570757d3ea2c829fb47f6b4d41ada', 'message': 'openvswitch/ofagent: Remove OVS.enable_tunneling option\n\nThe option has been marked deprecated in IceHouce.\nPlease use AGENT.tunnel_types=gre instead.\n\nRelated: blueprint ovs-vxlan-lisp-tunnel\nRelated-Bug: #1195374\nChange-Id: Iea6159c5949a63a0b680818a3fd0928d470115bd\n'}, {'number': 3, 'created': '2014-10-28 05:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/66f375a0e28b067c5b803228b4997afb4d8b3684', 'message': 'openvswitch/ofagent: Remove OVS.enable_tunneling option\n\nThe option has been marked deprecated in IceHouce.\nPlease use AGENT.tunnel_types=gre instead.\n\nRelated: blueprint ovs-vxlan-lisp-tunnel\nRelated-Bug: #1195374\nChange-Id: Iea6159c5949a63a0b680818a3fd0928d470115bd\n'}, {'number': 4, 'created': '2014-10-28 14:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ba7857480e28927974eb698c6572fc638c81fdcb', 'message': 'openvswitch/ofagent: Remove OVS.enable_tunneling option\n\nThe option has been marked deprecated in IceHouce.\nPlease use AGENT.tunnel_types=gre instead.\n\nRelated-Bug: #1195374\nChange-Id: Iea6159c5949a63a0b680818a3fd0928d470115bd\n'}, {'number': 5, 'created': '2014-10-28 23:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/229b839091c01421ad30b03f5aea74cefec8b0b3', 'message': 'openvswitch/ofagent: Remove OVS.enable_tunneling option\n\nThe option has been marked deprecated in IceHouse.\nPlease use AGENT.tunnel_types=gre instead.\n\nRelated-Bug: #1195374\nChange-Id: Iea6159c5949a63a0b680818a3fd0928d470115bd\n'}, {'number': 6, 'created': '2014-11-26 07:46:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/114dcebf7c00aee8e001691d275214ccc948a27d', 'message': 'openvswitch/ofagent: Remove OVS.enable_tunneling option\n\nThe option has been marked deprecated in IceHouse.\nPlease use AGENT.tunnel_types=gre instead.\n\nRelated-Bug: #1195374\nChange-Id: Iea6159c5949a63a0b680818a3fd0928d470115bd\n'}, {'number': 7, 'created': '2014-12-08 06:02:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e45da251ea15facf965dca0c72e9ff276d63335b', 'message': 'openvswitch/ofagent: Remove OVS.enable_tunneling option\n\nThe option has been marked deprecated in IceHouse.\nPlease use AGENT.tunnel_types=gre instead.\n\nRelated-Bug: #1195374\nChange-Id: Iea6159c5949a63a0b680818a3fd0928d470115bd\n'}, {'number': 8, 'created': '2014-12-15 05:14:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f2ec9d8101cc03cac3bd3f5baf978cef4c8fa673', 'message': 'openvswitch/ofagent: Remove OVS.enable_tunneling option\n\nThe option has been marked deprecated in IceHouse.\nPlease use AGENT.tunnel_types=gre instead.\n\nDocImpact\nRelated-Bug: #1195374\nChange-Id: Iea6159c5949a63a0b680818a3fd0928d470115bd\n'}, {'number': 9, 'created': '2014-12-15 05:15:16.000000000', 'files': ['neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/tests/unit/openvswitch/test_ovs_defaults.py', 'neutron/tests/unit/openvswitch/test_ovs_neutron_agent.py', 'neutron/plugins/openvswitch/common/config.py', 'etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/ofagent/test_ofa_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/77860af4831ed34b3b1b2299cf11041aa5573558', 'message': 'openvswitch/ofagent: Remove OVS.enable_tunneling option\n\nThe option has been marked deprecated in IceHouse.\nPlease use AGENT.tunnel_types=gre instead.\n\nDocImpact\nRelated-Bug: #1195374\nChange-Id: Iea6159c5949a63a0b680818a3fd0928d470115bd\n'}]",8,130708,77860af4831ed34b3b1b2299cf11041aa5573558,201,43,9,6854,,,0,"openvswitch/ofagent: Remove OVS.enable_tunneling option

The option has been marked deprecated in IceHouse.
Please use AGENT.tunnel_types=gre instead.

DocImpact
Related-Bug: #1195374
Change-Id: Iea6159c5949a63a0b680818a3fd0928d470115bd
",git fetch https://review.opendev.org/openstack/neutron refs/changes/08/130708/9 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/openvswitch/common/config.py'],1,063c6d373134d06cd09a1518a097df88c2128506,ovs_enable_tunneling," help=_(""Enable tunneling support. Deprecated. "" ""Please use AGENT.tunnel_types instead."")),"," help=_(""Enable tunneling support."")),",2,1
openstack%2Fpbr~feature%2F0.10~I8a83135b979a13f8cd129126a29159e93c147467,openstack/pbr,feature/0.10,I8a83135b979a13f8cd129126a29159e93c147467,_get_revno only returns a commit count,MERGED,2014-12-22 00:25:32.000000000,2014-12-22 05:17:09.000000000,2014-12-22 05:17:09.000000000,"[{'_account_id': 3}, {'_account_id': 3185}, {'_account_id': 5263}, {'_account_id': 6167}]","[{'number': 1, 'created': '2014-12-22 00:25:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/e26e24a0b67416007b0b2a7a3515dd9ffb594936', 'message': 'Return an empty tag if none exists\n\n* pbr/packaging.py(_get_revno_and_last_tag): Always return the same\nnumber of elements from this function.\n\nChange-Id: I8a83135b979a13f8cd129126a29159e93c147467\n'}, {'number': 2, 'created': '2014-12-22 03:00:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/71ff59a9b862209b96b065aef0f7516cd5511219', 'message': ""Return an empty tag if none exists\n\n* pbr/packaging.py(_get_revno): The _get_revno_and_last_tag method\nalways returns the same number of elements, so don't try to treat it\nas an iterable and also rename it to something sensible.\n\nChange-Id: I8a83135b979a13f8cd129126a29159e93c147467\n""}, {'number': 3, 'created': '2014-12-22 03:02:49.000000000', 'files': ['pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/aef4f7ef4faec987d553d1ca40b55951235af0b1', 'message': ""_get_revno only returns a commit count\n\n* pbr/packaging.py(_get_revno): The _get_revno_and_last_tag method\nalways returns the same number of elements, so don't try to treat it\nas an iterable and also rename it to something sensible.\n\nChange-Id: I8a83135b979a13f8cd129126a29159e93c147467\n""}]",0,143337,aef4f7ef4faec987d553d1ca40b55951235af0b1,13,4,3,5263,,,0,"_get_revno only returns a commit count

* pbr/packaging.py(_get_revno): The _get_revno_and_last_tag method
always returns the same number of elements, so don't try to treat it
as an iterable and also rename it to something sensible.

Change-Id: I8a83135b979a13f8cd129126a29159e93c147467
",git fetch https://review.opendev.org/openstack/pbr refs/changes/37/143337/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/packaging.py'],1,e26e24a0b67416007b0b2a7a3515dd9ffb594936,setuptools-8," return """", len(revlist.splitlines()) _get_revno_and_last_tag(git_dir)[1]) return ""0.0.0.post%s"" % _get_revno_and_last_tag(git_dir)[1]"," return len(revlist.splitlines()) _get_revno_and_last_tag(git_dir)[0]) return ""0.0.0.post%s"" % _get_revno_and_last_tag(git_dir)",3,3
openstack%2Ftricircle~master~Iec8700dc336abfc77d49792ed052069cb84980b3,openstack/tricircle,master,Iec8700dc336abfc77d49792ed052069cb84980b3,Modify Readmd for the remove of mapping_uuid patch,MERGED,2014-12-22 05:01:27.000000000,2014-12-22 05:02:08.000000000,2014-12-22 05:02:08.000000000,"[{'_account_id': 3}, {'_account_id': 9684}]","[{'number': 1, 'created': '2014-12-22 05:01:27.000000000', 'files': ['juno-patches/nova/instance_mapping_uuid_patch/README.md', 'minimal_setup_with_glance_cascading.png', 'novaproxy/README.md', 'minimal_setup.png', 'juno-patches/glance/glance_location_patch/README.md', 'README.md'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/ec5f67c91c2e6eae4b7ae59304b2492437eb62e7', 'message': 'Modify Readmd for the remove of mapping_uuid patch\n\nModify Readmd for the remove of mapping_uuid patch, so we modify some\nREADME.md files to keep consistently.\n\nChange-Id: Iec8700dc336abfc77d49792ed052069cb84980b3\n'}]",0,143361,ec5f67c91c2e6eae4b7ae59304b2492437eb62e7,6,2,1,9684,,,0,"Modify Readmd for the remove of mapping_uuid patch

Modify Readmd for the remove of mapping_uuid patch, so we modify some
README.md files to keep consistently.

Change-Id: Iec8700dc336abfc77d49792ed052069cb84980b3
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/61/143361/1 && git format-patch -1 --stdout FETCH_HEAD,"['juno-patches/nova/instance_mapping_uuid_patch/README.md', 'minimal_setup_with_glance_cascading.png', 'minimal_setup.png', 'novaproxy/README.md', 'juno-patches/glance/glance_location_patch/README.md', 'README.md']",6,ec5f67c91c2e6eae4b7ae59304b2492437eb62e7,,"* Support L2 networking(VxLAN) across cascaded OpenStack, but only point2point remote host IP tunneling supported now.L2 networking through L2GW to reduce population traffic and simplify networking topology will be developed in the near future. - Patches for Neutron - neutron_timestamp_cascaded_patch This patch is to make Neutron being able to provide timestamp based port query. Navigate to the folder ``` cd ./tricircle/juno-patches/neutron/neutron_timestamp_cascaded_patch ``` follow README.md instruction to install the patch - Patches for Neutron - neutron_timestamp_cascaded_patch This patch is to make Neutron being able to provide timestamp based port query. Navigate to the folder ``` cd ./tricircle/juno-patches/neutron/neutron_timestamp_cascaded_patch ``` follow README.md instruction to install the patch - Sync image only during first time usage but not uploading or patch location is still in testing phase, may not work properly.","* Support L2 networking(VxLAN) across cascaded OpenStack, but only p2p remote host IP tunneling supported now.L2 networking through L2GW to reduce population traffic and simplify networking topology will be developed in the near future.* Use ""admin"" role to experience these feature first, multi-tenancy has not been tested well. - Patches for Nova - instance_mapping_uuid_patch This patch is to make the Nova proxy being able to translate the cascading level VM's uuid to cascadede level VM's uuid Navigate to the folder ``` cd ./tricircle/juno-patches/nova/instance_mapping_uuid_patch ``` follow README.md instruction to install the patch - Patches for Cinder - Volume/SnapShot/Backup UUID mapping patch This patch is to make the Cinder proxy being able to translate the cascading level (Volume/Snapshot/backup)'s uuid to cascaded level (Volume/Snapshot/backup)'s uuid Navigate to the folder ``` cd ./tricircle/juno-patches/cinder/uuid-mapping-patch ``` follow README.md instruction to install the patch Navigate to the folder ``` cd ./tricircle/icehouse-patches/nova/instance_mapping_uuid_patch/nova/objects cp instance.py $python_installation_path/site-packages/nova/objects/ ``` This file is a patch for instance UUID mapping used in the proxy nodes. Navigate to the folder ``` cd ./tricircle/icehouse-patches/cinder/uuid-mapping-patch/cinder/db/sqlalchemy cp models.py $python_installation_path/site-packages/cinder/db/sqlalchemy ``` This file is a patch for instance UUID mapping used in the proxy nodes. - Sync image only during first time usage but not uploading or patch location can works by just modify the option 'sync_strategy=nova' in /etc/glance-sync.conf file and restart the glance sync service.",27,43
openstack%2Ftempest~master~Iffe57502b8e28b8c483de9f2430c7054fdef3d58,openstack/tempest,master,Iffe57502b8e28b8c483de9f2430c7054fdef3d58,Encap pbr versions for a workaround,ABANDONED,2014-12-22 02:33:53.000000000,2014-12-22 04:58:07.000000000,,"[{'_account_id': 3}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-22 02:33:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ab77b72c9493d9411e201613dad9acc962914ac8', 'message': 'Cap a pbr version for a workaround\n\nSince pbr 0.10.5, _get_version_from_git() has been added.\nHowever, the usage is wrong and TypeError happens in pbr.\nThis patch limits the pbr version for passing the gate test.\n\nChange-Id: Iffe57502b8e28b8c483de9f2430c7054fdef3d58\nRelated-Bug: #1404770\n'}, {'number': 2, 'created': '2014-12-22 02:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d0e3c14e487c4865a53bd14b10d2fba43eb4676b', 'message': 'Cap a pbr version for a workaround\n\nSince pbr 0.10.5, _get_revno_and_last_tag() has been added.\nHowever, the usage is wrong and TypeError happens in pbr.\nThis patch limits the pbr version for passing the gate test.\n\nChange-Id: Iffe57502b8e28b8c483de9f2430c7054fdef3d58\nRelated-Bug: #1404770\n'}, {'number': 3, 'created': '2014-12-22 03:34:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5544faf6416d288c28da5364e451ed714c3ccf51', 'message': 'Cap a pbr version for a workaround\n\nSince pbr 0.10.5, _get_revno_and_last_tag() has been added.\nHowever, the usage is wrong and TypeError happens in pbr.\nThis patch limits the pbr version for passing the gate test.\n\nDepends-On: I815100b9e4b4c854b979dd5edec6b0722e49973f\n\nChange-Id: Iffe57502b8e28b8c483de9f2430c7054fdef3d58\nRelated-Bug: #1404770\n'}, {'number': 4, 'created': '2014-12-22 04:05:56.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1180b94f19ba4402da07e6a3b566282471871b33', 'message': 'Encap pbr versions for a workaround\n\nSince pbr 0.10.5, _get_revno_and_last_tag() has been added.\nHowever, the usage is wrong and TypeError happens in pbr.\nI8a83135b979a13f8cd129126a29159e93c147467 will fix this problem\nand we will be able to avoid this problem since 0.10.7.\nSo this patch limits the pbr versions(0.10.5 and 0.10.6) for\npassing the gate test.\n\nDepends-On: I815100b9e4b4c854b979dd5edec6b0722e49973f\n\nChange-Id: Iffe57502b8e28b8c483de9f2430c7054fdef3d58\nRelated-Bug: #1404770\n'}]",0,143346,1180b94f19ba4402da07e6a3b566282471871b33,8,2,4,6167,,,0,"Encap pbr versions for a workaround

Since pbr 0.10.5, _get_revno_and_last_tag() has been added.
However, the usage is wrong and TypeError happens in pbr.
I8a83135b979a13f8cd129126a29159e93c147467 will fix this problem
and we will be able to avoid this problem since 0.10.7.
So this patch limits the pbr versions(0.10.5 and 0.10.6) for
passing the gate test.

Depends-On: I815100b9e4b4c854b979dd5edec6b0722e49973f

Change-Id: Iffe57502b8e28b8c483de9f2430c7054fdef3d58
Related-Bug: #1404770
",git fetch https://review.opendev.org/openstack/tempest refs/changes/46/143346/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,ab77b72c9493d9411e201613dad9acc962914ac8,bug/1404770,"pbr>=0.6,!=0.7,<0.10.5","pbr>=0.6,!=0.7,<1.0",1,1
openstack%2Frequirements~master~I815100b9e4b4c854b979dd5edec6b0722e49973f,openstack/requirements,master,I815100b9e4b4c854b979dd5edec6b0722e49973f,Encap pbr versions for a workaround,ABANDONED,2014-12-22 03:31:30.000000000,2014-12-22 04:08:28.000000000,,[{'_account_id': 5263}],"[{'number': 1, 'created': '2014-12-22 03:31:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/1813aa6d6f69ecc75d553b9894c35a16d78d0aff', 'message': 'Cap a pbr version for a workaround\n\nSince pbr 0.10.5, _get_revno_and_last_tag() has been added.\nHowever, the usage is wrong and TypeError happens in pbr.\nThis patch limits the pbr version for passing the gate test.\n\nChange-Id: I815100b9e4b4c854b979dd5edec6b0722e49973f\nRelated-Bug: #1404770\n'}, {'number': 2, 'created': '2014-12-22 04:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/93b939df909cb6bfa5f1105994ac321070fb1072', 'message': 'Cap a pbr version for a workaround\n\nSince pbr 0.10.5, _get_revno_and_last_tag() has been added.\nHowever, the usage is wrong and TypeError happens in pbr.\nI8a83135b979a13f8cd129126a29159e93c147467 will fix this problem\nand we will be able to avoid this problem since 0.10.7.\nSo this patch limits the pbr versions(0.10.5 and 0.10.6) for\npassing the gate test.\n\nChange-Id: I815100b9e4b4c854b979dd5edec6b0722e49973f\nRelated-Bug: #1404770\n'}, {'number': 3, 'created': '2014-12-22 04:04:05.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/a171c2268f3df5c14f5f46af6631a9b1bb3272c2', 'message': 'Encap pbr versions for a workaround\n\nSince pbr 0.10.5, _get_revno_and_last_tag() has been added.\nHowever, the usage is wrong and TypeError happens in pbr.\nI8a83135b979a13f8cd129126a29159e93c147467 will fix this problem\nand we will be able to avoid this problem since 0.10.7.\nSo this patch limits the pbr versions(0.10.5 and 0.10.6) for\npassing the gate test.\n\nChange-Id: I815100b9e4b4c854b979dd5edec6b0722e49973f\nRelated-Bug: #1404770\n'}]",0,143351,a171c2268f3df5c14f5f46af6631a9b1bb3272c2,6,1,3,6167,,,0,"Encap pbr versions for a workaround

Since pbr 0.10.5, _get_revno_and_last_tag() has been added.
However, the usage is wrong and TypeError happens in pbr.
I8a83135b979a13f8cd129126a29159e93c147467 will fix this problem
and we will be able to avoid this problem since 0.10.7.
So this patch limits the pbr versions(0.10.5 and 0.10.6) for
passing the gate test.

Change-Id: I815100b9e4b4c854b979dd5edec6b0722e49973f
Related-Bug: #1404770
",git fetch https://review.opendev.org/openstack/requirements refs/changes/51/143351/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,1813aa6d6f69ecc75d553b9894c35a16d78d0aff,bug/1404770,"pbr>=0.6,!=0.7,<0.10.5","pbr>=0.6,!=0.7,<1.0",1,1
openstack%2Fopenstack-manuals~master~I740e9ece1d42bf455828b5bdf56ceafa3227fb1a,openstack/openstack-manuals,master,I740e9ece1d42bf455828b5bdf56ceafa3227fb1a,Add docs for Dell Storage Center Cinder drivers,MERGED,2014-12-19 20:40:08.000000000,2014-12-22 02:27:27.000000000,2014-12-22 02:27:26.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-19 20:40:08.000000000', 'files': ['doc/config-reference/block-storage/section_volume-drivers.xml', 'doc/common/tables/cinder-dellsc.xml', 'tools/autogenerate-config-flagmappings/cinder.headers', 'doc/config-reference/block-storage/drivers/dell-storagecenter-driver.xml', 'tools/autogenerate-config-flagmappings/cinder.flagmappings'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f0b2acf0cc0f9dabc64c2ecd3c53e8a655db581f', 'message': 'Add docs for Dell Storage Center Cinder drivers\n\nThe Dell Storage Center iSCSI and FC driver has recently\nmerged. This patch adds basic documentation for the\nconfiguration options of this set of drivers.\n\nChange-Id: I740e9ece1d42bf455828b5bdf56ceafa3227fb1a\n'}]",0,143184,f0b2acf0cc0f9dabc64c2ecd3c53e8a655db581f,7,3,1,11904,,,0,"Add docs for Dell Storage Center Cinder drivers

The Dell Storage Center iSCSI and FC driver has recently
merged. This patch adds basic documentation for the
configuration options of this set of drivers.

Change-Id: I740e9ece1d42bf455828b5bdf56ceafa3227fb1a
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/84/143184/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/block-storage/section_volume-drivers.xml', 'doc/common/tables/cinder-dellsc.xml', 'tools/autogenerate-config-flagmappings/cinder.headers', 'doc/config-reference/block-storage/drivers/dell-storagecenter-driver.xml', 'tools/autogenerate-config-flagmappings/cinder.flagmappings']",5,f0b2acf0cc0f9dabc64c2ecd3c53e8a655db581f,dell_storagecenter_cinder_driver,dell_sc_api_port dellsc dell_sc_server_folder dellsc dell_sc_ssn dellsc dell_sc_volume_folder dellsc,,162,0
openstack%2Ftaskflow~master~I0a1683cfc22df1888a19f5af10d7a343462d3994,openstack/taskflow,master,I0a1683cfc22df1888a19f5af10d7a343462d3994,Remove less than useful action_engine __str__,MERGED,2014-12-18 00:49:08.000000000,2014-12-22 02:10:38.000000000,2014-12-22 02:10:38.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-18 00:49:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d87a26247ed46d5c31e59af4e8a37760140cf8e7', 'message': 'Remove less than useful action_engine __str__\n\nThe implementation of __str__ does not provide much\nuseful information so instead just prefer the automatically\nprovided one which provides equivalent information in\na more well known format...\n\nChange-Id: I0a1683cfc22df1888a19f5af10d7a343462d3994\n'}, {'number': 2, 'created': '2014-12-18 20:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4a197aaadfa0e1a3c42f25ad05657d6d3bff55e2', 'message': 'Remove less than useful action_engine __str__\n\nThe implementation of __str__ does not provide much\nuseful information so instead just prefer the automatically\nprovided one which provides equivalent information in\na more well known format...\n\nChange-Id: I0a1683cfc22df1888a19f5af10d7a343462d3994\n'}, {'number': 3, 'created': '2014-12-21 23:39:19.000000000', 'files': ['taskflow/engines/action_engine/engine.py', 'doc/source/notifications.rst'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/fce7afbd8db26180816abe7d9566cf65277de376', 'message': 'Remove less than useful action_engine __str__\n\nThe implementation of __str__ does not provide much\nuseful information so instead just prefer the automatically\nprovided one which provides equivalent information in\na more well known format...\n\nChange-Id: I0a1683cfc22df1888a19f5af10d7a343462d3994\n'}]",0,142625,fce7afbd8db26180816abe7d9566cf65277de376,18,2,3,1297,,,0,"Remove less than useful action_engine __str__

The implementation of __str__ does not provide much
useful information so instead just prefer the automatically
provided one which provides equivalent information in
a more well known format...

Change-Id: I0a1683cfc22df1888a19f5af10d7a343462d3994
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/25/142625/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/engines/action_engine/engine.py'],1,d87a26247ed46d5c31e59af4e8a37760140cf8e7,,,"from taskflow.utils import reflection def __str__(self): return ""%s: %s"" % (reflection.get_class_name(self), id(self)) ",0,4
openstack%2Fcinder~master~Ib5b75d6ff38ff6f9571a0fdc30e854e046e66dd7,openstack/cinder,master,Ib5b75d6ff38ff6f9571a0fdc30e854e046e66dd7,Sync request_utils module from oslo-incubator,MERGED,2014-12-20 03:20:30.000000000,2014-12-22 01:57:32.000000000,2014-12-22 01:57:31.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2759}, {'_account_id': 6491}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 14206}]","[{'number': 1, 'created': '2014-12-20 03:20:30.000000000', 'files': ['cinder/openstack/common/request_utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/cc04c2483922fbb3d3f8b0c8daa5d5ae95b67686', 'message': ""Sync request_utils module from oslo-incubator\n\nThe request_utils module hasn't had a sync done since shortly\nafter the module was added.  This patch brings us up to date\nwith the latest oslo-incubator code.\n\nThis sync is needed to enable removal of the old gettextutils\nand i18n code.\n\nCurrent HEAD in OSLO:\n---------------------\ncommit 36b0e8570b449129d6d474c03b02ceb62edb78df\nDate:   Thu Dec 11 11:27:08 2014 +0100\nWe shouldn't replace `oslo-incubator` in comments\n\nChanges being merged with this patch:\n---------------------\n5d40e143 - Remove code that moved to oslo.i18n\n39625e18 - Set pbr 'warnerrors' option for doc build\n\nChange-Id: Ib5b75d6ff38ff6f9571a0fdc30e854e046e66dd7\n""}]",0,143247,cc04c2483922fbb3d3f8b0c8daa5d5ae95b67686,17,13,1,7198,,,0,"Sync request_utils module from oslo-incubator

The request_utils module hasn't had a sync done since shortly
after the module was added.  This patch brings us up to date
with the latest oslo-incubator code.

This sync is needed to enable removal of the old gettextutils
and i18n code.

Current HEAD in OSLO:
---------------------
commit 36b0e8570b449129d6d474c03b02ceb62edb78df
Date:   Thu Dec 11 11:27:08 2014 +0100
We shouldn't replace `oslo-incubator` in comments

Changes being merged with this patch:
---------------------
5d40e143 - Remove code that moved to oslo.i18n
39625e18 - Set pbr 'warnerrors' option for doc build

Change-Id: Ib5b75d6ff38ff6f9571a0fdc30e854e046e66dd7
",git fetch https://review.opendev.org/openstack/cinder refs/changes/47/143247/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/openstack/common/request_utils.py'],1,cc04c2483922fbb3d3f8b0c8daa5d5ae95b67686,sync_request_utils,"from cinder.openstack.common._i18n import _, _LI """"""Links the Request ID from the Source service to the Request ID returned from the Target service. Linkages are logged and emitted as INFO notifications. :params context: context object :params source_id: the Request ID of the source :params target_id: the Request ID of the target :params stage: optional event name extension to indicate which part of the linkage this is. :params target_name: human readable name of the target system you are talking to. :params notifier: notifier object A typical use case is: System A asking System B to perform some action. The linkages might look like this: .. code-block:: python But, it could be as simple as: .. code-block:: python LOG.info(_LI(""Request ID Link: %(event_name)s "" ""'%(source_id)s'%(arrow)s"" ""%(target_name)s%(target_id)s"") % { ""event_name"": event_name, ""source_id"": source_id, ""target_name"": rtarget_name, ""arrow"": arrow, ""target_id"": rtarget_id})","from openstack.common.gettextutils import _ # noqa from cinder.i18n import _LI """"""Links the Request ID from the Source service to the Request ID returned from the Target service. Linkages are logged and emitted as INFO notifications. :params context: context object :params source_id: the Request ID of the source :params target_id: the Request ID of the target :params stage: optional event name extension to indicate which part of the linkage this is. :params target_name: human readable name of the target system you are talking to. :params notifier: notifier object A typical use case is: System A asking System B to perform some action. The linkages might look like this: But, it could be as simple as: LOG.info(_LI(""Request ID Link: %(event_name)s '%(source_id)s'%(arrow)s"" ""%(target_name)s%(target_id)s"") % {""event_name"": event_name, ""source_id"": source_id, ""target_name"": rtarget_name, ""arrow"": arrow, ""target_id"": rtarget_id})",29,24
openstack%2Ftempest~master~I35f55c895dafc4235c9c5a10b1ccf9ebfffd7265,openstack/tempest,master,I35f55c895dafc4235c9c5a10b1ccf9ebfffd7265,Add BaseRestClient class to separate CONF values,ABANDONED,2014-12-11 11:10:32.000000000,2014-12-22 01:27:28.000000000,,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-11 11:10:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a6dc49f6de7cb4f05693b19db6372b5ce8a84cba', 'message': 'Add BaseRestClient class to separate CONF values\n\nTo use a rest client class at different projects, we need to separate\nTempest own config values from a base rest client class.\nThis patch adds a new BaseRestClient class for doing this.\nHowever, BaseRestClient class still contains a few Tempest own config\nvalues because _get_region() and _get_endpoint_type() might be necessary\nto be considered for each project setting and it is better to create\nanother patch for easy review.\n\nChange-Id: I35f55c895dafc4235c9c5a10b1ccf9ebfffd7265\n'}, {'number': 2, 'created': '2014-12-11 11:43:32.000000000', 'files': ['tempest/common/rest_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/593cd2deb0c355c9cf4e8561b84e1e5f01945b5f', 'message': 'Add BaseRestClient class to separate CONF values\n\nTo use a rest client class at different projects, we need to separate\nTempest own config values from a base rest client class.\nThis patch adds a new BaseRestClient class for doing this.\nHowever, BaseRestClient class still contains a few Tempest own config\nvalues because _get_region() and _get_endpoint_type() might be necessary\nto be considered for each project setting and it is better to create\nanother patch for easy review.\n\nChange-Id: I35f55c895dafc4235c9c5a10b1ccf9ebfffd7265\n'}]",0,141014,593cd2deb0c355c9cf4e8561b84e1e5f01945b5f,9,6,2,6167,,,0,"Add BaseRestClient class to separate CONF values

To use a rest client class at different projects, we need to separate
Tempest own config values from a base rest client class.
This patch adds a new BaseRestClient class for doing this.
However, BaseRestClient class still contains a few Tempest own config
values because _get_region() and _get_endpoint_type() might be necessary
to be considered for each project setting and it is better to create
another patch for easy review.

Change-Id: I35f55c895dafc4235c9c5a10b1ccf9ebfffd7265
",git fetch https://review.opendev.org/openstack/tempest refs/changes/14/141014/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/common/rest_client.py'],1,a6dc49f6de7cb4f05693b19db6372b5ce8a84cba,rest-client,"class BaseRestClient(object): def __init__(self, auth_provider, build_interval=1, build_timeout=300, trace_regex="""", disable_ssl_certificate=False, ca_certificates_file=None): self.build_interval = build_interval self.build_timeout = build_timeout self.trace_regex = trace_regex dscv = disable_ssl_certificate ca_certs = ca_certificates_file str_format = (""service:%s, base_url:%s, "" ""filters: %s, build_interval:%s, build_timeout:%s, "" return str_format % (self.service, self.base_url, if self.trace_regex and re.search(self.trace_regex, caller_name):class RestClient(BaseRestClient): """"""Tempest own REST client class. This class is created based on tempest.conf. """""" def __init__(self, auth_provider): dscv = CONF.identity.disable_ssl_certificate_validation ca_certs = CONF.identity.ca_certificates_file super(RestClient, self).__init__( auth_provider, build_interval=CONF.compute.build_interval, build_timeout=CONF.compute.build_timeout, trace_regex=CONF.debug.trace_requests, disable_ssl_certificate=dscv, ca_certificates_file=ca_certs) ","class RestClient(object): def __init__(self, auth_provider): self.build_interval = CONF.compute.build_interval self.build_timeout = CONF.compute.build_timeout dscv = CONF.identity.disable_ssl_certificate_validation ca_certs = CONF.identity.ca_certificates_file str_format = (""config:%s, service:%s, base_url:%s, "" ""filters: %s, build_interval:%s, build_timeout:%s"" return str_format % (CONF, self.service, self.base_url, trace_regex = CONF.debug.trace_requests if trace_regex and re.search(trace_regex, caller_name):",30,11
openstack%2Fpython-magnumclient~master~I18ef5857a4489885c7800cb082a712f7ede9c193,openstack/python-magnumclient,master,I18ef5857a4489885c7800cb082a712f7ede9c193,Add baymodel_id to bay_create,MERGED,2014-12-17 23:08:22.000000000,2014-12-22 01:25:57.000000000,2014-12-22 01:25:57.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-17 23:08:22.000000000', 'files': ['magnumclient/api/bays.py', 'magnumclient/api/shell.py'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/63049a63e316981215aa9d73c7f572a63de25286', 'message': 'Add baymodel_id to bay_create\n\nAdd the option to specify the baymodel id to bay_create\n\nChange-Id: I18ef5857a4489885c7800cb082a712f7ede9c193\n'}]",0,142606,63049a63e316981215aa9d73c7f572a63de25286,6,2,1,2834,,,0,"Add baymodel_id to bay_create

Add the option to specify the baymodel id to bay_create

Change-Id: I18ef5857a4489885c7800cb082a712f7ede9c193
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/06/142606/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnumclient/api/bays.py', 'magnumclient/api/shell.py']",2,63049a63e316981215aa9d73c7f572a63de25286,,"@utils.arg('--baymodel_id', metavar='<baymodel_id>', help='The bay model ID.') opts['baymodel_id'] = args.baymodel_id",,5,1
openstack%2Fpython-magnumclient~master~I5a7479f4a5dbc40ef30f91b500db6aea1f916f9a,openstack/python-magnumclient,master,I5a7479f4a5dbc40ef30f91b500db6aea1f916f9a,Add flavor_id property to baymodel object,MERGED,2014-12-17 22:47:13.000000000,2014-12-22 01:25:24.000000000,2014-12-22 01:25:24.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-17 22:47:13.000000000', 'files': ['magnumclient/api/shell.py'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/db61981078cb49e63d4aca34bd4f8ffef248db7c', 'message': 'Add flavor_id property to baymodel object\n\nThe conductor already has the flavor_id property, just add it to the\nbaymodel object.\n\nChange-Id: I5a7479f4a5dbc40ef30f91b500db6aea1f916f9a\n'}]",0,142602,db61981078cb49e63d4aca34bd4f8ffef248db7c,6,2,1,2834,,,0,"Add flavor_id property to baymodel object

The conductor already has the flavor_id property, just add it to the
baymodel object.

Change-Id: I5a7479f4a5dbc40ef30f91b500db6aea1f916f9a
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/02/142602/1 && git format-patch -1 --stdout FETCH_HEAD,['magnumclient/api/shell.py'],1,db61981078cb49e63d4aca34bd4f8ffef248db7c,,"@utils.arg('--flavor_id', metavar='<flavor_id>', help='The nova flavor id to use when launching the bay.') opts['flavor_id'] = args.flavor_id",,4,0
openstack%2Fopenstack-manuals~master~I371ccdbebe904b344d537f8fc4edc443f0753cd2,openstack/openstack-manuals,master,I371ccdbebe904b344d537f8fc4edc443f0753cd2,"Replace “...” with ""...""",MERGED,2014-12-17 10:08:47.000000000,2014-12-22 01:14:32.000000000,2014-12-22 01:14:30.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 7923}, {'_account_id': 10497}, {'_account_id': 11904}]","[{'number': 1, 'created': '2014-12-17 10:08:47.000000000', 'files': ['doc/config-reference/block-storage/drivers/windows-iscsi-volume-driver.xml', 'doc/config-reference/block-storage/drivers/huawei-storage-driver.xml', 'doc/common/section_objectstorage-account-reaper.xml', 'doc/arch-design/hybrid/section_architecture_hybrid.xml', 'doc/common/section_dashboard_customizing.xml', 'doc/admin-guide-cloud/telemetry/section_telemetry-data-collection.xml', 'doc/config-reference/object-storage/section_object-storage-features.xml', 'doc/config-reference/block-storage/drivers/coraid-driver.xml', 'doc/image-guide/ch_openstack_images.xml', 'doc/config-reference/compute/section_hypervisor_hyper-v.xml', 'doc/admin-guide-cloud/section_object-storage-monitoring.xml', 'doc/admin-guide-cloud/compute/section_compute-networking-nova.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/22f705029642be276d68a966878bbb28c55d56e4', 'message': 'Replace “...” with ""...""\n\nChange-Id: I371ccdbebe904b344d537f8fc4edc443f0753cd2\n'}]",0,142402,22f705029642be276d68a966878bbb28c55d56e4,10,6,1,167,,,0,"Replace “...” with ""...""

Change-Id: I371ccdbebe904b344d537f8fc4edc443f0753cd2
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/02/142402/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/block-storage/drivers/windows-iscsi-volume-driver.xml', 'doc/config-reference/block-storage/drivers/huawei-storage-driver.xml', 'doc/common/section_objectstorage-account-reaper.xml', 'doc/arch-design/hybrid/section_architecture_hybrid.xml', 'doc/common/section_dashboard_customizing.xml', 'doc/admin-guide-cloud/telemetry/section_telemetry-data-collection.xml', 'doc/config-reference/object-storage/section_object-storage-features.xml', 'doc/config-reference/block-storage/drivers/coraid-driver.xml', 'doc/image-guide/ch_openstack_images.xml', 'doc/config-reference/compute/section_hypervisor_hyper-v.xml', 'doc/admin-guide-cloud/section_object-storage-monitoring.xml', 'doc/admin-guide-cloud/compute/section_compute-networking-nova.xml']",12,22f705029642be276d68a966878bbb28c55d56e4,replace_unicode_quotation," supports the following network modes, which are implemented as ""Network Manager"""," supports the following network modes, which are implemented as “Network Manager”",28,28
openstack%2Fopenstack-manuals~master~I1a67db2b6aa6a8e2bfd76cc80db1fb09fa353986,openstack/openstack-manuals,master,I1a67db2b6aa6a8e2bfd76cc80db1fb09fa353986,Fix conflicts with _member_ role creation,MERGED,2014-12-19 23:15:00.000000000,2014-12-22 01:09:41.000000000,2014-12-22 01:09:40.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 612}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-12-19 23:15:00.000000000', 'files': ['doc/install-guide/section_keystone-users.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/14e6c86d5a457dbbb90690d55655a4532919255a', 'message': ""Fix conflicts with _member_ role creation\n\nHistorically, the installation guide manually created the\ninternal _member_ role to resolve issues with horizon.\nHowever, keystone will preferably create the _member_ role\nautomatically if the 'user-create' command includes the\n'--tenant' option.\n\nChange-Id: I1a67db2b6aa6a8e2bfd76cc80db1fb09fa353986\nCloses-Bug: #1403136\nbackport: juno\n""}]",0,143215,14e6c86d5a457dbbb90690d55655a4532919255a,7,4,1,9515,,,0,"Fix conflicts with _member_ role creation

Historically, the installation guide manually created the
internal _member_ role to resolve issues with horizon.
However, keystone will preferably create the _member_ role
automatically if the 'user-create' command includes the
'--tenant' option.

Change-Id: I1a67db2b6aa6a8e2bfd76cc80db1fb09fa353986
Closes-Bug: #1403136
backport: juno
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/15/143215/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_keystone-users.xml'],1,14e6c86d5a457dbbb90690d55655a4532919255a,bug/1403136," <para>OpenStack generates IDs dynamically, so you will see different values from the example command output.</para> <para>Create the <literal>admin</literal> user under the <literal>admin</literal> tenant:</para> <screen><prompt>$</prompt> <userinput>keystone user-create --name admin --tenant admin --pass <replaceable>ADMIN_PASS</replaceable> --email <replaceable>EMAIL_ADDRESS</replaceable></userinput>| tenantId | 6f4c1e4cbfef4d5a8a1345882fbca110 | <para>Add the <literal>admin</literal> role to the <literal>admin</literal> tenant and user:</para> <screen><prompt>$</prompt> <userinput>keystone user-role-add --user admin --tenant admin --role admin</userinput></screen> <para>Create the <literal>demo</literal> user under the <literal>demo</literal> tenant:</para> <screen><prompt>$</prompt> <userinput>keystone user-create --name demo --tenant demo --pass <replaceable>DEMO_PASS</replaceable> --email <replaceable>EMAIL_ADDRESS</replaceable></userinput>| tenantId | 4aa51bb942be4dd0ac0555d7591f80a6 | interact with other services. Each service typically requires creating one or more unique users with the <literal>admin</literal> role under the <literal>service</literal> tenant.</para>"," <para>Because OpenStack generates IDs dynamically, you will see different values from this example command output.</para> <para>Create the <literal>admin</literal> user:</para> <screen><prompt>$</prompt> <userinput>keystone user-create --name admin --pass <replaceable>ADMIN_PASS</replaceable> --email <replaceable>EMAIL_ADDRESS</replaceable></userinput> <para>Add the <literal>admin</literal> tenant and user to the <literal>admin</literal> role:</para> <screen><prompt>$</prompt> <userinput>keystone user-role-add --tenant admin --user admin --role admin</userinput></screen> <note> <para>This command provides no output.</para> </note> </step> <step> <para>By default, the dashboard limits access to users with the <literal>_member_</literal> role.</para> <para>Create the <literal>_member_</literal> role:</para> <screen><prompt>$</prompt> <userinput>keystone role-create --name _member_</userinput> <computeroutput>+----------+----------------------------------+ | Property | Value | +----------+----------------------------------+ | id | 0f198e94ffce416cbcbe344e1843eac8 | | name | _member_ | +----------+----------------------------------+</computeroutput></screen> </step> <step> <para>Add the <literal>admin</literal> tenant and user to the <literal>_member_</literal> role:</para> <screen><prompt>$</prompt> <userinput>keystone user-role-add --tenant admin --user admin --role _member_</userinput></screen> <para>Create the <literal>demo</literal> user:</para> <screen><prompt>$</prompt> <userinput>keystone user-create --name demo --pass <replaceable>DEMO_PASS</replaceable> --email <replaceable>EMAIL_ADDRESS</replaceable></userinput> <step> <para>Add the <literal>demo</literal> tenant and user to the <literal>_member_</literal> role:</para> <screen><prompt>$</prompt> <userinput>keystone user-role-add --tenant demo --user demo --role _member_</userinput></screen> <note> <para>This command provides no output.</para> </note> </step> interact with other services. You will create a user in the <literal>service</literal> tenant for each service that you install.</para>",16,40
openstack%2Fheat~master~Ibd534bafe189b4700ff0293b0501d062dc1a5f10,openstack/heat,master,Ibd534bafe189b4700ff0293b0501d062dc1a5f10,Imported Translations from Transifex,MERGED,2014-12-20 06:01:55.000000000,2014-12-22 01:04:01.000000000,2014-12-22 01:03:59.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4715}]","[{'number': 1, 'created': '2014-12-20 06:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b687032e5b20a7c702f84943142a48088adf5038', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ibd534bafe189b4700ff0293b0501d062dc1a5f10\n'}, {'number': 2, 'created': '2014-12-21 06:02:10.000000000', 'files': ['heat/locale/ko_KR/LC_MESSAGES/heat-log-error.po', 'heat/locale/pt_BR/LC_MESSAGES/heat-log-error.po', 'heat/locale/heat.pot', 'heat/locale/fr/LC_MESSAGES/heat-log-error.po', 'heat/locale/heat-log-warning.pot', 'heat/locale/es/LC_MESSAGES/heat-log-error.po', 'heat/locale/heat-log-error.pot', 'heat/locale/de/LC_MESSAGES/heat-log-error.po'], 'web_link': 'https://opendev.org/openstack/heat/commit/229aac85e36330df1f8b39be59f2ec7936cfeb45', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ibd534bafe189b4700ff0293b0501d062dc1a5f10\n'}]",0,143254,229aac85e36330df1f8b39be59f2ec7936cfeb45,11,3,2,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ibd534bafe189b4700ff0293b0501d062dc1a5f10
",git fetch https://review.opendev.org/openstack/heat refs/changes/54/143254/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/locale/ko_KR/LC_MESSAGES/heat-log-error.po', 'heat/locale/pt_BR/LC_MESSAGES/heat-log-error.po', 'heat/locale/heat.pot', 'heat/locale/fr/LC_MESSAGES/heat-log-error.po', 'heat/locale/heat-log-warning.pot', 'heat/locale/es/LC_MESSAGES/heat-log-error.po', 'heat/locale/heat-log-error.pot', 'heat/locale/de/LC_MESSAGES/heat-log-error.po']",8,b687032e5b20a7c702f84943142a48088adf5038,transifex/translations,"""POT-Creation-Date: 2014-12-20 06:01+0000\n""#: heat/engine/service.py:1308 msgid ""Filtering by namespace/metric not yet supported""#: heat/engine/service_stack_watch.py:69 #, python-format msgid ""Unable to retrieve stack %s for periodic task""#: heat/engine/resources/eip.py:329 heat/engine/resources/eip.py:352","""POT-Creation-Date: 2014-12-18 06:04+0000\n""#: heat/engine/service.py:260 #, python-format msgid ""Unable to retrieve stack %s for periodic task""#: heat/engine/service.py:1389 msgid ""Filtering by namespace/metric not yet supported""#: heat/engine/resources/eip.py:330 heat/engine/resources/eip.py:353",104,108
openstack%2Foperations-guide~master~I5821f0beeb7f1a9d6e1a271d356fd009c65074ff,openstack/operations-guide,master,I5821f0beeb7f1a9d6e1a271d356fd009c65074ff,Fix typo: Change Dissaociating to Disassociating,MERGED,2014-12-20 13:07:05.000000000,2014-12-22 01:02:04.000000000,2014-12-22 01:02:04.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-20 13:07:05.000000000', 'files': ['doc/openstack-ops/ch_ops_network_troubleshooting.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/dfabe532d243cfd1fec88bafcd36e19087acb482', 'message': 'Fix typo: Change Dissaociating to Disassociating\n\nChange-Id: I5821f0beeb7f1a9d6e1a271d356fd009c65074ff\nCloses-Bug: 1404389\n'}]",0,143268,dfabe532d243cfd1fec88bafcd36e19087acb482,7,3,1,10497,,,0,"Fix typo: Change Dissaociating to Disassociating

Change-Id: I5821f0beeb7f1a9d6e1a271d356fd009c65074ff
Closes-Bug: 1404389
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/68/143268/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/ch_ops_network_troubleshooting.xml'],1,dfabe532d243cfd1fec88bafcd36e19087acb482,bug/1404389, <title>Manually Disassociating a Floating IP</title>, <title>Manually Dissaociating a Floating IP</title>,1,1
openstack%2Fheat~master~Ie70d5c75146e81b765edde611edef81805915a0c,openstack/heat,master,Ie70d5c75146e81b765edde611edef81805915a0c,Fix json syntax in inline template,MERGED,2014-12-19 13:17:39.000000000,2014-12-22 00:57:51.000000000,2014-12-22 00:57:50.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 6983}, {'_account_id': 8246}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-19 13:17:39.000000000', 'files': ['heat_integrationtests/functional/test_instance_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/2e3d443168f265fe6b4c378e24573dce9fe85c19', 'message': 'Fix json syntax in inline template\n\nChange-Id: Ie70d5c75146e81b765edde611edef81805915a0c\n'}]",0,143080,2e3d443168f265fe6b4c378e24573dce9fe85c19,13,8,1,6577,,,0,"Fix json syntax in inline template

Change-Id: Ie70d5c75146e81b765edde611edef81805915a0c
",git fetch https://review.opendev.org/openstack/heat refs/changes/80/143080/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/functional/test_instance_group.py'],1,2e3d443168f265fe6b4c378e24573dce9fe85c19,," ""UserData"" : ""jsconfig data"""," ""UserData"" : ""jsconfig data"",",1,1
openstack%2Fheat-cfntools~master~Ifdae966f44f582676b428d49497bb0212fad3e03,openstack/heat-cfntools,master,Ifdae966f44f582676b428d49497bb0212fad3e03,Fix RST syntax errors/warnings in README.rst,MERGED,2014-12-15 17:20:02.000000000,2014-12-22 00:43:18.000000000,2014-12-22 00:43:18.000000000,"[{'_account_id': 3}, {'_account_id': 4715}]","[{'number': 1, 'created': '2014-12-15 17:20:02.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/heat-cfntools/commit/9862bd7477274cd6ce2d45be9111eb9684ebe6d7', 'message': 'Fix RST syntax errors/warnings in README.rst\n\nThe errors were causing the list in the README to show up unformatted on\ngithub.\n\nREADME.rst:8: (ERROR/3) Unexpected indentation.\nREADME.rst:9: (WARNING/2) Block quote ends without a blank line;\nREADME.rst:17: (WARNING/2) Definition list ends without a blank line;\n\nChange-Id: Ifdae966f44f582676b428d49497bb0212fad3e03\n'}]",0,141851,9862bd7477274cd6ce2d45be9111eb9684ebe6d7,6,2,1,12321,,,0,"Fix RST syntax errors/warnings in README.rst

The errors were causing the list in the README to show up unformatted on
github.

README.rst:8: (ERROR/3) Unexpected indentation.
README.rst:9: (WARNING/2) Block quote ends without a blank line;
README.rst:17: (WARNING/2) Definition list ends without a blank line;

Change-Id: Ifdae966f44f582676b428d49497bb0212fad3e03
",git fetch https://review.opendev.org/openstack/heat-cfntools refs/changes/51/141851/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,9862bd7477274cd6ce2d45be9111eb9684ebe6d7,rstSyntax,"cfn-init - Reads the AWS::CloudFormation::Init for the instance resource,cfn-signal - Waits for an application to be ready before continuing, ie:cfn-hup - Handle updates from the UpdateStack CloudFormation API call","cfn-init - Reads the AWS::CloudFormation::Init for the instance resource,cfn-signal - Waits for an application to be ready before continuing, ie:cfn-hup - Handle updates from the UpdateStack CloudFormation API call",7,3
openstack%2Ftaskflow~master~I037439313f9071af23c0859a62832d735f9abcd8,openstack/taskflow,master,I037439313f9071af23c0859a62832d735f9abcd8,Correctly trigger 'on_exit' of starting/initial state,MERGED,2014-12-19 06:23:56.000000000,2014-12-22 00:06:27.000000000,2014-12-22 00:06:25.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-19 06:23:56.000000000', 'files': ['taskflow/types/fsm.py', 'taskflow/tests/unit/test_types.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/dbc890f928ecfea3ee306b5bd0c7053eeb5070c9', 'message': ""Correctly trigger 'on_exit' of starting/initial state\n\nInstead of not calling the 'on_exit' of the initialized\nand/or starting state we should make an attempt to call\nit if a function exists/was provided. This function will\nbe called on the first event to be processed (which will\ncause the state machine to transition out of the starting\nstate to a new stable state).\n\nFixes bug 1404124\n\nChange-Id: I037439313f9071af23c0859a62832d735f9abcd8\n""}]",0,142994,dbc890f928ecfea3ee306b5bd0c7053eeb5070c9,6,2,1,1297,,,0,"Correctly trigger 'on_exit' of starting/initial state

Instead of not calling the 'on_exit' of the initialized
and/or starting state we should make an attempt to call
it if a function exists/was provided. This function will
be called on the first event to be processed (which will
cause the state machine to transition out of the starting
state to a new stable state).

Fixes bug 1404124

Change-Id: I037439313f9071af23c0859a62832d735f9abcd8
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/94/142994/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/types/fsm.py', 'taskflow/tests/unit/test_types.py']",2,dbc890f928ecfea3ee306b5bd0c7053eeb5070c9,bug/1404124," self.assertEqual( [('start', 'beat'), ('down', 'jump'), ('up', 'fall')], exit_transitions)"," self.assertEqual([('down', 'jump'), ('up', 'fall')], exit_transitions)",9,2
openstack%2Fpbr~master~Ic3a4fb1146d6a9735c4f28cf7ddfe186a2b81c15,openstack/pbr,master,Ic3a4fb1146d6a9735c4f28cf7ddfe186a2b81c15,Merge branch 'feature/0.10',ABANDONED,2014-12-18 23:17:30.000000000,2014-12-21 22:30:24.000000000,,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-18 23:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/3e6fe9700e4ac7372efca8673d85a4e421c15faa', 'message': ""Merge branch 'feature/0.10'\n\nMerge the outstanding tags into the master.\n\nChange-Id: Ic3a4fb1146d6a9735c4f28cf7ddfe186a2b81c15\n""}, {'number': 2, 'created': '2014-12-19 01:05:38.000000000', 'files': ['pbr/packaging.py', 'pbr/tests/base.py', 'pbr/util.py', 'pbr/cmd/main.py', 'pbr/builddoc.py', 'setup.cfg', 'pbr/hooks/commands.py', 'pbr/options.py', 'tox.ini', 'pbr/cmd/__init__.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/1425c86a2b28ba93e90a30738573d532da359544', 'message': ""Merge branch 'feature/0.10'\n\nMerge the outstanding tags into the master.\n\nChange-Id: Ic3a4fb1146d6a9735c4f28cf7ddfe186a2b81c15\nCo-Authored-By: Doug Hellmann <doug@doughellmann.com>\n""}]",0,142930,1425c86a2b28ba93e90a30738573d532da359544,15,3,2,2,,,0,"Merge branch 'feature/0.10'

Merge the outstanding tags into the master.

Change-Id: Ic3a4fb1146d6a9735c4f28cf7ddfe186a2b81c15
Co-Authored-By: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/pbr refs/changes/30/142930/2 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/packaging.py', 'pbr/cmd/main.py', 'pbr/tests/base.py', 'pbr/util.py', 'pbr/builddoc.py', 'setup.cfg', 'pbr/hooks/commands.py', 'pbr/options.py', 'tox.ini', 'pbr/cmd/__init__.py']",10,3e6fe9700e4ac7372efca8673d85a4e421c15faa,142930,,,35,539
openstack%2Fpbr~master~I79d67bf41a09d7e5aad8ed32eaf107f139167eb8,openstack/pbr,master,I79d67bf41a09d7e5aad8ed32eaf107f139167eb8,Only import sphinx during hook processing,ABANDONED,2014-12-18 16:46:19.000000000,2014-12-21 22:28:48.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-18 16:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/2dbfe213b242b6722cf2a4bd4e456b0da5e5b980', 'message': ""Only import sphinx during hook processing\n\nWhen pbr is imported to handle writing the egg_info file because of\nthe entry point, it's causing sphinx to get imported. This has a\ncascading effect once docutils is trying to be installed on a\nsystem with pbr installed. If some of the imports fail along the way,\nallow pbr to continue usefully but without the Sphinx extensions\navailable. Eventually, when everything is installed, those extensions\nwill work again when the commands for build_sphinx, etc. are run\nseparately.\n\nAlso slip in a change to reorder the default list of environments run by\ntox so the testr database is created using a dbm format available to all\npython versions.\n\nCloses-bug: #1403510\n(cherry picked from commit 65f4fafd907a16ea1952ab7072676db2e9e0c51d)\n\nConflicts:\n\tpbr/packaging.py\n\ttox.ini\n\nChange-Id: I79d67bf41a09d7e5aad8ed32eaf107f139167eb8\n""}, {'number': 2, 'created': '2014-12-18 21:24:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/e3f5b99876134fc9ea52abbb41b04d61225d814a', 'message': ""Only import sphinx during hook processing\n\nWhen pbr is imported to handle writing the egg_info file because of\nthe entry point, it's causing sphinx to get imported. This has a\ncascading effect once docutils is trying to be installed on a\nsystem with pbr installed. If some of the imports fail along the way,\nallow pbr to continue usefully but without the Sphinx extensions\navailable. Eventually, when everything is installed, those extensions\nwill work again when the commands for build_sphinx, etc. are run\nseparately.\n\nAlso slip in a change to reorder the default list of environments run by\ntox so the testr database is created using a dbm format available to all\npython versions.\n\nCloses-bug: #1403510\n(cherry picked from commit 65f4fafd907a16ea1952ab7072676db2e9e0c51d)\n\nConflicts:\n\tpbr/packaging.py\n\ttox.ini\n\nChange-Id: I79d67bf41a09d7e5aad8ed32eaf107f139167eb8\n""}, {'number': 3, 'created': '2014-12-18 21:36:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/1254dfc3806640ecb712c9d5ab894e358d4f914c', 'message': ""Only import sphinx during hook processing\n\nWhen pbr is imported to handle writing the egg_info file because of\nthe entry point, it's causing sphinx to get imported. This has a\ncascading effect once docutils is trying to be installed on a\nsystem with pbr installed. If some of the imports fail along the way,\nallow pbr to continue usefully but without the Sphinx extensions\navailable. Eventually, when everything is installed, those extensions\nwill work again when the commands for build_sphinx, etc. are run\nseparately.\n\nAlso slip in a change to reorder the default list of environments run by\ntox so the testr database is created using a dbm format available to all\npython versions.\n\nCloses-bug: #1403510\n(cherry picked from commit 65f4fafd907a16ea1952ab7072676db2e9e0c51d)\n\nConflicts:\n\tpbr/packaging.py\n\ttox.ini\n\nChange-Id: I79d67bf41a09d7e5aad8ed32eaf107f139167eb8\n""}, {'number': 4, 'created': '2014-12-18 23:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/80109c54e8e946afde5202c86c572c35858062a8', 'message': ""Only import sphinx during hook processing\n\nWhen pbr is imported to handle writing the egg_info file because of\nthe entry point, it's causing sphinx to get imported. This has a\ncascading effect once docutils is trying to be installed on a\nsystem with pbr installed. If some of the imports fail along the way,\nallow pbr to continue usefully but without the Sphinx extensions\navailable. Eventually, when everything is installed, those extensions\nwill work again when the commands for build_sphinx, etc. are run\nseparately.\n\nAlso slip in a change to reorder the default list of environments run by\ntox so the testr database is created using a dbm format available to all\npython versions.\n\nCloses-bug: #1403510\n(cherry picked from commit 65f4fafd907a16ea1952ab7072676db2e9e0c51d)\n\nConflicts:\n\tpbr/packaging.py\n\ttox.ini\n\nChange-Id: I79d67bf41a09d7e5aad8ed32eaf107f139167eb8\n""}, {'number': 5, 'created': '2014-12-19 01:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/651cb85cb6cba16f1c2496fc68d149b0e59b2ffd', 'message': ""Only import sphinx during hook processing\n\nWhen pbr is imported to handle writing the egg_info file because of\nthe entry point, it's causing sphinx to get imported. This has a\ncascading effect once docutils is trying to be installed on a\nsystem with pbr installed. If some of the imports fail along the way,\nallow pbr to continue usefully but without the Sphinx extensions\navailable. Eventually, when everything is installed, those extensions\nwill work again when the commands for build_sphinx, etc. are run\nseparately.\n\nAlso slip in a change to reorder the default list of environments run by\ntox so the testr database is created using a dbm format available to all\npython versions.\n\nCloses-bug: #1403510\n(cherry picked from commit 65f4fafd907a16ea1952ab7072676db2e9e0c51d)\n\nConflicts:\n\tpbr/packaging.py\n\ttox.ini\n\nChange-Id: I79d67bf41a09d7e5aad8ed32eaf107f139167eb8\n""}, {'number': 6, 'created': '2014-12-19 01:37:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/d8315c36e95f99fcd2ad263d5d7111467087213b', 'message': ""Only import sphinx during hook processing\n\nWhen pbr is imported to handle writing the egg_info file because of\nthe entry point, it's causing sphinx to get imported. This has a\ncascading effect once docutils is trying to be installed on a\nsystem with pbr installed. If some of the imports fail along the way,\nallow pbr to continue usefully but without the Sphinx extensions\navailable. Eventually, when everything is installed, those extensions\nwill work again when the commands for build_sphinx, etc. are run\nseparately.\n\nAlso slip in a change to reorder the default list of environments run by\ntox so the testr database is created using a dbm format available to all\npython versions.\n\nCloses-bug: #1403510\n(cherry picked from commit 65f4fafd907a16ea1952ab7072676db2e9e0c51d)\n\nConflicts:\n\tpbr/packaging.py\n\ttox.ini\n\nChange-Id: I79d67bf41a09d7e5aad8ed32eaf107f139167eb8\n""}, {'number': 7, 'created': '2014-12-19 18:51:20.000000000', 'files': ['pbr/tests/test_setup.py', 'pbr/packaging.py', 'pbr/tests/base.py', 'pbr/tests/test_packaging.py', 'pbr/util.py', 'pbr/builddoc.py', 'pbr/git.py', 'pbr/hooks/commands.py', 'pbr/options.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/907779e8df5f1ee1a99e2d244a441fde4d8b1a36', 'message': ""Only import sphinx during hook processing\n\nWhen pbr is imported to handle writing the egg_info file because of\nthe entry point, it's causing sphinx to get imported. This has a\ncascading effect once docutils is trying to be installed on a\nsystem with pbr installed. If some of the imports fail along the way,\nallow pbr to continue usefully but without the Sphinx extensions\navailable. Eventually, when everything is installed, those extensions\nwill work again when the commands for build_sphinx, etc. are run\nseparately.\n\nAlso slip in a change to reorder the default list of environments run by\ntox so the testr database is created using a dbm format available to all\npython versions.\n\nCloses-bug: #1403510\n(cherry picked from commit 65f4fafd907a16ea1952ab7072676db2e9e0c51d)\n\nConflicts:\n\tpbr/packaging.py\n\ttox.ini\n\nChange-Id: I79d67bf41a09d7e5aad8ed32eaf107f139167eb8\n""}]",0,142840,907779e8df5f1ee1a99e2d244a441fde4d8b1a36,21,4,7,4146,,,0,"Only import sphinx during hook processing

When pbr is imported to handle writing the egg_info file because of
the entry point, it's causing sphinx to get imported. This has a
cascading effect once docutils is trying to be installed on a
system with pbr installed. If some of the imports fail along the way,
allow pbr to continue usefully but without the Sphinx extensions
available. Eventually, when everything is installed, those extensions
will work again when the commands for build_sphinx, etc. are run
separately.

Also slip in a change to reorder the default list of environments run by
tox so the testr database is created using a dbm format available to all
python versions.

Closes-bug: #1403510
(cherry picked from commit 65f4fafd907a16ea1952ab7072676db2e9e0c51d)

Conflicts:
	pbr/packaging.py
	tox.ini

Change-Id: I79d67bf41a09d7e5aad8ed32eaf107f139167eb8
",git fetch https://review.opendev.org/openstack/pbr refs/changes/40/142840/3 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/packaging.py', 'pbr/tests/base.py', 'pbr/util.py', 'pbr/builddoc.py', 'pbr/hooks/commands.py', 'pbr/options.py', 'tox.ini']",7,2dbfe213b242b6722cf2a4bd4e456b0da5e5b980,setuptools-8,# NOTE(dhellmann): List ourself as a dependency first to ensure that # the source being tested is used to install all of the other # dependencies that want to use pbr for installation. deps = . -r{toxinidir}/requirements.txt,deps = -r{toxinidir}/requirements.txt,266,198
openstack%2Fcinder~master~I46dc4855776638a133a65451c7e32269dd09b8d1,openstack/cinder,master,I46dc4855776638a133a65451c7e32269dd09b8d1,Make GPFS driver compliant with logging standards,MERGED,2014-11-26 00:16:40.000000000,2014-12-21 22:20:20.000000000,2014-12-21 22:20:19.000000000,"[{'_account_id': 3}, {'_account_id': 4355}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 7219}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9171}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 12780}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-11-26 00:16:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5cc7a34d162154daa034b567f322adb248b24aab', 'message': ""Make GPFS driver compliant with logging standards\n\nThis patch adds the log level markers (_LI, _LE or _LW) where they\nwere missing.  It also changes the use of '%' to ',' for inserting\nvariables into log messages.  These changes are made based on the\nguidelines in:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nChange-Id: I46dc4855776638a133a65451c7e32269dd09b8d1\nPartial-Bug: 1384312\n""}, {'number': 2, 'created': '2014-11-26 22:56:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a6aa281811940b51c28da950631928539a80412b', 'message': ""Make GPFS driver compliant with logging standards\n\nThis patch adds the log level markers (_LI, _LE or _LW) where they\nwere missing.  It also changes the use of '%' to ',' for inserting\nvariables into log messages.  These changes are made based on the\nguidelines in:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nChange-Id: I46dc4855776638a133a65451c7e32269dd09b8d1\nPartial-Bug: 1384312\n""}, {'number': 3, 'created': '2014-12-02 21:39:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/41630df65210e4ee34fb13e6cba82bda23c9f341', 'message': ""Make GPFS driver compliant with logging standards\n\nThis patch adds the log level markers (_LI, _LE or _LW) where they\nwere missing.  It also changes the use of '%' to ',' for inserting\nvariables into log messages.  These changes are made based on the\nguidelines in:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nChange-Id: I46dc4855776638a133a65451c7e32269dd09b8d1\nPartial-Bug: 1384312\n""}, {'number': 4, 'created': '2014-12-18 01:42:53.000000000', 'files': ['cinder/volume/drivers/ibm/gpfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f98677dae91ae47d57063901bbfd72a8106af14a', 'message': ""Make GPFS driver compliant with logging standards\n\nThis patch adds the log level markers (_LI, _LE or _LW) where they\nwere missing.  It also changes the use of '%' to ',' for inserting\nvariables into log messages.  These changes are made based on the\nguidelines in:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nChange-Id: I46dc4855776638a133a65451c7e32269dd09b8d1\nPartial-Bug: 1384312\n""}]",8,137244,f98677dae91ae47d57063901bbfd72a8106af14a,55,21,4,7198,,,0,"Make GPFS driver compliant with logging standards

This patch adds the log level markers (_LI, _LE or _LW) where they
were missing.  It also changes the use of '%' to ',' for inserting
variables into log messages.  These changes are made based on the
guidelines in:
http://docs.openstack.org/developer/oslo.i18n/guidelines.html

Change-Id: I46dc4855776638a133a65451c7e32269dd09b8d1
Partial-Bug: 1384312
",git fetch https://review.opendev.org/openstack/cinder refs/changes/44/137244/3 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/ibm/gpfs.py'],1,5cc7a34d162154daa034b567f322adb248b24aab,bug/1384312,"from cinder.i18n import _, _LE, _LI LOG.error(_LE('Failed to issue mmgetstate command, error: %s.'), LOG.error(_LE('GPFS is not active. Detailed output: %s.'), out) exception_message = (_('GPFS is not running, state: %s.'), 'error: %(error)s.'), LOG.error(_LE('Failed to issue mmlsconfig command, error: %s.'), 'error: %(error)s'), 'output: %(cmdout)s.'), msg = (_('Invalid storage pool %s requested. Retype failed.'), LOG.info(_LI('Could not update storage pool with mmchattr to ' '%(pool)s, error: %(error)s'), 'error: %(error)s.'), LOG.error(_LE('Failed to issue mmlsconfig command, error: %s.'), 'error: %(error)s.'), 'cannot migrate locally: %s.', info) 'cluster id in location info: %s.', info) msg = (_('Could not find GPFS cluster id: %s.'), msg = (_('Could not find GPFS file system device: %s.'), msg = (_('Invalid storage pool %s specificed.'), 'systems.'), '%(vol)s and %(img)s belong to different filesets.'), 'be at least at level %(min)s.'), msg = (_('%s must be an absolute path.'), directory) msg = (_('%s is not a directory.'), directory) 'at least %(min)s.'), LOG.debug('Update volume attributes with mmchattr to %s.', options) LOG.debug('Image %(img)s not cloneable: %(reas)s.', LOG.debug('Clone image to vol %s using mmclone.', LOG.debug('Clone image to vol %s using copyfile.', LOG.debug('Clone image to vol %s using qemu convert.', LOG.debug('Copy image to vol %s using image_utils fetch_to_raw.', LOG.error(_LE(""Failed to resize volume "" ""%(volume_id)s, error: %(error)s.""), LOG.debug('Begin backup of volume %s.', volume['name']) LOG.debug('Begin restore of backup %s.', backup['id']) LOG.debug('Migrate volume request %(vol)s to %(host)s.', LOG.error(_LE('Driver-based migration of volume %(vol)s failed. ' 'Move from %(src)s to %(dst)s failed with error: ' '%(error)s.'), '(host: %(host)s), diff %(diff)s.', 'use migration: %s %s.', backends) LOG.debug('Retype pool attribute from %s to %s.', pools) LOG.debug('Retype hosts migrate from: %s to %s.', hosts) ""error message was: %(err)s.""), {'vol': volume['name'], 'err': exc.stderr})","from cinder.i18n import _, _LE LOG.error(_LE('Failed to issue mmgetstate command, error: %s.') % LOG.error(_LE('GPFS is not active. Detailed output: %s.') % out) exception_message = (_('GPFS is not running, state: %s.') % 'error: %(error)s.') % LOG.error(_LE('Failed to issue mmlsconfig command, error: %s.') % 'error: %(error)s') % 'output: %(cmdout)s.') % msg = (_('Invalid storage pool %s requested. Retype failed.') % LOG.info('Could not update storage pool with mmchattr to ' '%(pool)s, error: %(error)s' % 'error: %(error)s.') % LOG.error(_LE('Failed to issue mmlsconfig command, error: %s.') % 'error: %(error)s.') % 'cannot migrate locally: %s.' % info) 'cluster id in location info: %s.' % info) msg = (_('Could not find GPFS cluster id: %s.') % msg = (_('Could not find GPFS file system device: %s.') % msg = (_('Invalid storage pool %s specificed.') % 'systems.') % '%(vol)s and %(img)s belong to different filesets.') % 'be at least at level %(min)s.') % msg = (_('%s must be an absolute path.') % directory) msg = (_('%s is not a directory.') % directory) 'at least %(min)s.') % LOG.debug('Update volume attributes with mmchattr to %s.' % options) LOG.debug('Image %(img)s not cloneable: %(reas)s.' % LOG.debug('Clone image to vol %s using mmclone.' % LOG.debug('Clone image to vol %s using copyfile.' % LOG.debug('Clone image to vol %s using qemu convert.' % LOG.debug('Copy image to vol %s using image_utils fetch_to_raw.' % LOG.error(_(""Failed to resize volume "" ""%(volume_id)s, error: %(error)s."") % LOG.debug('Begin backup of volume %s.' % volume['name']) LOG.debug('Begin restore of backup %s.' % backup['id']) LOG.debug('Migrate volume request %(vol)s to %(host)s.' % LOG.error(_('Driver-based migration of volume %(vol)s failed. ' 'Move from %(src)s to %(dst)s failed with error: ' '%(error)s.') % '(host: %(host)s), diff %(diff)s.' % 'use migration: %s %s.' % backends) LOG.debug('Retype pool attribute from %s to %s.' % pools) LOG.debug('Retype hosts migrate from: %s to %s.' % hosts) ""error message was: %(err)s."") % {'vol': volume['name'], 'err': exc.stderr})",45,45
openstack%2Ftaskflow~master~I688df323fb24a7e228f4fa237f2fa772d9c0dc62,openstack/taskflow,master,I688df323fb24a7e228f4fa237f2fa772d9c0dc62,Ensure manager started/shutdown/joined and reset,MERGED,2014-12-21 19:32:41.000000000,2014-12-21 21:46:31.000000000,2014-12-21 21:46:31.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-21 19:32:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ba9a3f291de16fb6b369f889af76d790f9ba6c3a', 'message': 'Ensure manager shutdown/joined and reset\n\nEnsure that when the task executor is started that we\ncorrectly create a new multiprocessing manager (if needed)\nand that on stop we correctly shut that manager down and\njoin it.\n\nAlso does a tiny adjustment to the joinable work item to\nmove the finish logic into its own method and ensures that\nwe have no targets on reset of the dispatcher.\n\nChange-Id: I688df323fb24a7e228f4fa237f2fa772d9c0dc62\n'}, {'number': 2, 'created': '2014-12-21 20:39:33.000000000', 'files': ['taskflow/engines/action_engine/executor.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f897008f5bf817895475e4e799c460082c736d6b', 'message': 'Ensure manager started/shutdown/joined and reset\n\nEnsure that when the task executor is started that we\ncorrectly create a new multiprocessing manager (if needed)\nand that on stop we correctly shut that manager down and\njoin it.\n\nAlso does a tiny adjustment to the joinable work item to\nmove the finish logic into its own method and ensures that\nwe have no targets on reset of the dispatcher.\n\nChange-Id: I688df323fb24a7e228f4fa237f2fa772d9c0dc62\n'}]",0,143311,f897008f5bf817895475e4e799c460082c736d6b,8,2,2,1297,,,0,"Ensure manager started/shutdown/joined and reset

Ensure that when the task executor is started that we
correctly create a new multiprocessing manager (if needed)
and that on stop we correctly shut that manager down and
join it.

Also does a tiny adjustment to the joinable work item to
move the finish logic into its own method and ensures that
we have no targets on reset of the dispatcher.

Change-Id: I688df323fb24a7e228f4fa237f2fa772d9c0dc62
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/11/143311/2 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/engines/action_engine/executor.py'],1,ba9a3f291de16fb6b369f889af76d790f9ba6c3a,,"from multiprocessing import managers_MANAGER_AVAILABLE = (managers.State.INITIAL, managers.State.STARTED) def _on_finish(self): w = timing.StopWatch() w.start() self._queue.join() LOG.blather(""Waited %0.2f seconds until task '%s' emitted"" "" notifications were depleted"", w.elapsed(), self._task) self._on_finish() while self._targets: self.deregister(self._targets.pop()) def _queue_factory(self): return self._manager.JoinableQueue() # TODO(harlowja): do something else here besides accessing a state # of the manager internals (it doesn't seem to expose any way to know # this information)... if self._manager._state.value not in _MANAGER_AVAILABLE: self._manager = multiprocessing.Manager() self._manager.shutdown() self._manager.join()"," w = timing.StopWatch().start() self._queue.join() LOG.blather(""Waited %0.2f seconds until task '%s' emitted"" "" notifications were depleted"", w.elapsed(), self._task) self._queue_factory = lambda: self._manager.JoinableQueue()",22,6
openstack%2Ftaskflow~master~I54b2595af8d58db60843195034d66a623c20277c,openstack/taskflow,master,I54b2595af8d58db60843195034d66a623c20277c,Return the same namedtuple that the future module returns,MERGED,2014-12-20 19:20:35.000000000,2014-12-21 21:44:01.000000000,2014-12-21 21:44:00.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-20 19:20:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e08d5cb42b7099ca2f79002a88e7e71f3cec973e', 'message': 'Return the same namedtuple that the future module returns\n\nInstead of converting the namedtuple that the future wait\nfunction returns into a normal tuple, just have our own\ninternal functions use the futures namedtuple directly instead\nand avoid any coversion to/from that namedtuple into a normal\ntuple.\n\nChange-Id: I54b2595af8d58db60843195034d66a623c20277c\n'}, {'number': 2, 'created': '2014-12-21 19:42:23.000000000', 'files': ['taskflow/utils/async_utils.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f862775c222e889f9945374413b002d8d50072e4', 'message': 'Return the same namedtuple that the future module returns\n\nInstead of converting the namedtuple that the future wait\nfunction returns into a normal tuple, just have our own\ninternal functions use the futures namedtuple directly instead\nand avoid any conversion to/from that namedtuple into a normal\ntuple.\n\nChange-Id: I54b2595af8d58db60843195034d66a623c20277c\n'}]",0,143278,f862775c222e889f9945374413b002d8d50072e4,12,2,2,1297,,,0,"Return the same namedtuple that the future module returns

Instead of converting the namedtuple that the future wait
function returns into a normal tuple, just have our own
internal functions use the futures namedtuple directly instead
and avoid any conversion to/from that namedtuple into a normal
tuple.

Change-Id: I54b2595af8d58db60843195034d66a623c20277c
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/78/143278/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/utils/async_utils.py'],1,e08d5cb42b7099ca2f79002a88e7e71f3cec973e,," return _futures.wait(fs, timeout=timeout, return_when=_futures.FIRST_COMPLETED)def _partition_futures(fs): done = set() not_done = set() for f in fs: if f._state in _DONE_STATES: done.add(f) else: not_done.add(f) return done, not_done with _base._AcquireFutures(fs): done, not_done = _partition_futures(fs) if done: return _base.DoneAndNotDoneFutures(done, not_done) done, not_done = _partition_futures(fs) return _base.DoneAndNotDoneFutures(done, not_done)"," return tuple(_futures.wait(fs, timeout=timeout, return_when=_futures.FIRST_COMPLETED)) def _partition_futures(fs): done = set() not_done = set() for f in fs: if f._state in _DONE_STATES: done.add(f) else: not_done.add(f) return (done, not_done) with _base._AcquireFutures(fs): (done, not_done) = _partition_futures(fs) if done: return (done, not_done) return _partition_futures(fs)",18,15
openstack%2Fpbr~feature%2F0.10~Icc7275261e8fc0df8b0ae99184437ca50b89c13a,openstack/pbr,feature/0.10,Icc7275261e8fc0df8b0ae99184437ca50b89c13a,Integration test PBR commits,MERGED,2014-12-21 16:52:29.000000000,2014-12-21 20:53:30.000000000,2014-12-21 20:53:30.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-21 16:52:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/186b76c5fec9d1d9cc905bf65259a5b36c1be1fc', 'message': 'Integration test PBR commits\n\n* tools/integration.sh: Make sure that if a PBR commit is being\ntested then we install and use that source rather than the latest\nPBR release.\n\nChange-Id: Icc7275261e8fc0df8b0ae99184437ca50b89c13a\n'}, {'number': 2, 'created': '2014-12-21 17:23:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/67a7ca55572f7aa22418d103e62830c0ed96a579', 'message': 'Integration test PBR commits\n\n* tools/integration.sh: Make sure that if a PBR commit is being\ntested then we install and use that source rather than the latest\nPBR release.\n\nChange-Id: Icc7275261e8fc0df8b0ae99184437ca50b89c13a\n'}, {'number': 3, 'created': '2014-12-21 17:38:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/16b9c15da92c9b797195b5811ed6d14fed1b93ec', 'message': 'Integration test PBR commits\n\n* tools/integration.sh: Make sure that if a PBR commit is being\ntested then we install and use that source rather than the latest\nPBR release.\n\nChange-Id: Icc7275261e8fc0df8b0ae99184437ca50b89c13a\n'}, {'number': 4, 'created': '2014-12-21 18:42:08.000000000', 'files': ['tools/integration.sh', 'pbr/packaging.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/pbr/commit/cd7da23937b66fea3ec42fa2f5a128f363a97e7e', 'message': 'Integration test PBR commits\n\n* pbr/packaging.py(_get_version_from_git): Correct a bug which is\ncausing install failures for PBR-based projects with no Git tags.\nThis slipped through because integration testing was using the most\nrecent PBR release rather than the commit being proposed.\n\n* tools/integration.sh: Make sure that if a PBR commit is being\ntested then we install and use that source rather than the latest\nPBR release.\n\n* tox.ini(testenv:pep8): Get rid of the custom deps list for pep8\nand inherit the one from testenv which is already fixed with the\nself-dependency. Without this, pep8 jobs fail when run with\nSetuptools 8.\n\nChange-Id: Icc7275261e8fc0df8b0ae99184437ca50b89c13a\n'}]",0,143305,cd7da23937b66fea3ec42fa2f5a128f363a97e7e,12,3,4,5263,,,0,"Integration test PBR commits

* pbr/packaging.py(_get_version_from_git): Correct a bug which is
causing install failures for PBR-based projects with no Git tags.
This slipped through because integration testing was using the most
recent PBR release rather than the commit being proposed.

* tools/integration.sh: Make sure that if a PBR commit is being
tested then we install and use that source rather than the latest
PBR release.

* tox.ini(testenv:pep8): Get rid of the custom deps list for pep8
and inherit the one from testenv which is already fixed with the
self-dependency. Without this, pep8 jobs fail when run with
Setuptools 8.

Change-Id: Icc7275261e8fc0df8b0ae99184437ca50b89c13a
",git fetch https://review.opendev.org/openstack/pbr refs/changes/05/143305/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/integration.sh'],1,186b76c5fec9d1d9cc905bf65259a5b36c1be1fc,setuptools-8," if [ $ZUUL_PROJECT = ""openstack-dev/pbr"" ] ; then $venv/bin/pip install $pbrsdistdir fiif [ $ZUUL_PROJECT = ""openstack-dev/pbr"" ] ; then git fetch $ZUUL_URL/$ZUUL_PROJECT $ZUUL_REF git reset --hard FETCH_HEAD fi",,7,0
openstack%2Ftaskflow~master~I104fa55e6b511df77464e3b89ee2bad6438482dd,openstack/taskflow,master,I104fa55e6b511df77464e3b89ee2bad6438482dd,Add an example which shows how to send events out from tasks,MERGED,2014-12-16 00:19:56.000000000,2014-12-21 20:22:14.000000000,2014-12-21 20:22:12.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 9608}]","[{'number': 1, 'created': '2014-12-16 00:19:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/10b119d04951dfbaea9961705e28cda151d68d74', 'message': 'Add an example which shows how to send events out from tasks\n\nTasks support a notification like channel that they can use\nto emit information that has occurred internal to then be\nrecieved by any attached listeners. This kind of notification\neven works when ran remotely; so this example shows how to use\nthat system to do something useful.\n\nChange-Id: I104fa55e6b511df77464e3b89ee2bad6438482dd\n'}, {'number': 2, 'created': '2014-12-16 00:21:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/261c42f25459d8f7909472d359945f81098856c1', 'message': 'Add an example which shows how to send events out from tasks\n\nTasks support a notification like channel that they can use\nto emit information that has occurred internal to then be\nrecieved by any attached listeners. This kind of notification\neven works when ran remotely; so this example shows how to use\nthat system to do something useful.\n\nChange-Id: I104fa55e6b511df77464e3b89ee2bad6438482dd\n'}, {'number': 3, 'created': '2014-12-17 19:13:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/297cd81c3b3fa23ebd7c0683e6f1a2e511d7c0db', 'message': 'Add an example which shows how to send events out from tasks\n\nTasks support a notification like channel that they can use\nto emit information that has occurred internal to then be\nreceived by any attached listeners. This kind of notification\neven works when ran remotely; so this example shows how to use\nthat system to do something useful.\n\nPart of blueprint more-examples\n\nChange-Id: I104fa55e6b511df77464e3b89ee2bad6438482dd\n'}, {'number': 4, 'created': '2014-12-19 00:31:52.000000000', 'files': ['taskflow/examples/wbe_event_sender.py', 'doc/source/examples.rst'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2b959daf9e608b176f3af5faa185b7b5888ac269', 'message': 'Add an example which shows how to send events out from tasks\n\nTasks support a notification like channel that they can use\nto emit information that has occurred internal to then be\nreceived by any attached listeners. This kind of notification\neven works when ran remotely; so this example shows how to use\nthat system to do something useful.\n\nPart of blueprint more-examples\n\nChange-Id: I104fa55e6b511df77464e3b89ee2bad6438482dd\n'}]",0,141951,2b959daf9e608b176f3af5faa185b7b5888ac269,18,3,4,1297,,,0,"Add an example which shows how to send events out from tasks

Tasks support a notification like channel that they can use
to emit information that has occurred internal to then be
received by any attached listeners. This kind of notification
even works when ran remotely; so this example shows how to use
that system to do something useful.

Part of blueprint more-examples

Change-Id: I104fa55e6b511df77464e3b89ee2bad6438482dd
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/51/141951/3 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/examples/wbe_event_sender.py', 'doc/source/examples.rst']",2,10b119d04951dfbaea9961705e28cda151d68d74,bp/more-examples,Distributed notification (simple) ================================= .. note:: Full source located at :example:`wbe_event_sender` .. literalinclude:: ../../taskflow/examples/wbe_event_sender.py :language: python :linenos: :lines: 16- ,,148,0
openstack%2Fcongress~master~Iab92489f3af7da8a708aa8cff3e7d67f2114665e,openstack/congress,master,Iab92489f3af7da8a708aa8cff3e7d67f2114665e,Imports not grouped correctly,MERGED,2014-12-20 13:30:26.000000000,2014-12-21 20:18:17.000000000,2014-12-21 19:39:53.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-20 13:30:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/495c6c9ea3c7d95b16b6a3f1c41fdf2e89e0e9a2', 'message': 'Imports not grouped correctly.\n\nEnable: H305\nThough all changes were in place but imports were not\ngrouped at test.utils.py. And also H305 was not enable\nin tox.ini.\n\nChange-Id: Iab92489f3af7da8a708aa8cff3e7d67f2114665e\n'}, {'number': 2, 'created': '2014-12-21 11:09:54.000000000', 'files': ['congress/tests/test_utils.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/congress/commit/09ff95f9c9e41914ceecc792cdc4ef3541b676af', 'message': 'Imports not grouped correctly\n\nEnable: H305\nThough all changes were in place but imports were not\ngrouped at test.utils.py. And also H305 was not enable\nin tox.ini.\n\nChange-Id: Iab92489f3af7da8a708aa8cff3e7d67f2114665e\n'}]",0,143271,09ff95f9c9e41914ceecc792cdc4ef3541b676af,13,3,2,12256,,,0,"Imports not grouped correctly

Enable: H305
Though all changes were in place but imports were not
grouped at test.utils.py. And also H305 was not enable
in tox.ini.

Change-Id: Iab92489f3af7da8a708aa8cff3e7d67f2114665e
",git fetch https://review.opendev.org/openstack/congress refs/changes/71/143271/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/test_utils.py', 'tox.ini']",2,495c6c9ea3c7d95b16b6a3f1c41fdf2e89e0e9a2,bug/1398551,"ignore = H237,H405,H904,H302","# H305 imports not grouped correctlyignore = H237,H305,H405,H904,H302",2,2
openstack%2Fswift~feature%2Fec~I4b4efa6fd8816fc9f059e488ab0e2a0454e0245e,openstack/swift,feature/ec,I4b4efa6fd8816fc9f059e488ab0e2a0454e0245e,Merge master to feature/ec,MERGED,2014-12-21 19:10:55.000000000,2014-12-21 20:15:45.000000000,2014-12-21 20:15:43.000000000,"[{'_account_id': 3}, {'_account_id': 7479}]","[{'number': 1, 'created': '2014-12-21 19:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/50d157601bd50313693c6e2fe49ef63b4c90f833', 'message': 'Mergeter to feature/ec\n\nConflicts:\n\ttest/unit/obj/test_server.py\n\nChange-Id: I4b4efa6fd8816fc9f059e488ab0e2a0454e0245e\n'}, {'number': 2, 'created': '2014-12-21 19:11:25.000000000', 'files': ['doc/source/associated_projects.rst', 'test/unit/obj/test_server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/621089e7be624db011a837b76039fce2d5998470', 'message': 'Merge master to feature/ec\n\nConflicts:\n\ttest/unit/obj/test_server.py\n\nChange-Id: I4b4efa6fd8816fc9f059e488ab0e2a0454e0245e\n'}]",0,143310,621089e7be624db011a837b76039fce2d5998470,7,2,2,7479,,,0,"Merge master to feature/ec

Conflicts:
	test/unit/obj/test_server.py

Change-Id: I4b4efa6fd8816fc9f059e488ab0e2a0454e0245e
",git fetch https://review.opendev.org/openstack/swift refs/changes/10/143310/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/associated_projects.rst', 'test/unit/obj/test_server.py']",2,50d157601bd50313693c6e2fe49ef63b4c90f833,ec_merge,,"<<<<<<< HEAD (fb4f03 Merge ""SAIO updates to support EC development environment."" )======= from swift.common.swob import Request, HeaderKeyDict>>>>>>> BRANCH (922a15 Merge ""fix dlo manifest file getting versioned"")",2,9
openstack%2Ftaskflow~master~Ic436c534103d1d9fafad95299bd2632cc7ee5634,openstack/taskflow,master,Ic436c534103d1d9fafad95299bd2632cc7ee5634,Move the engine scoping test to its engines test folder,MERGED,2014-12-21 00:29:54.000000000,2014-12-21 20:07:46.000000000,2014-12-21 20:07:45.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-21 00:29:54.000000000', 'files': ['taskflow/tests/unit/action_engine/test_scoping.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a170f4bb9efdf6c40989b37ac60afbbaccd4c0df', 'message': 'Move the engine scoping test to its engines test folder\n\nSince the scoping is an action_engine implementation detail\nits test should belong in the action_engine test cases folder\ninstead of being at the top level unit test folder.\n\nChange-Id: Ic436c534103d1d9fafad95299bd2632cc7ee5634\n'}]",0,143284,a170f4bb9efdf6c40989b37ac60afbbaccd4c0df,8,2,1,1297,,,0,"Move the engine scoping test to its engines test folder

Since the scoping is an action_engine implementation detail
its test should belong in the action_engine test cases folder
instead of being at the top level unit test folder.

Change-Id: Ic436c534103d1d9fafad95299bd2632cc7ee5634
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/84/143284/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/tests/unit/action_engine/test_scoping.py'],1,a170f4bb9efdf6c40989b37ac60afbbaccd4c0df,,,,0,0
openstack%2Fcinder~master~Idbfb7f89fe64303d332ddc9a31443d7e85c717e4,openstack/cinder,master,Idbfb7f89fe64303d332ddc9a31443d7e85c717e4,Perform fsync on glance image fetched to tempfile,ABANDONED,2014-12-12 03:28:15.000000000,2014-12-21 19:29:15.000000000,,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12369}, {'_account_id': 12898}]","[{'number': 1, 'created': '2014-12-12 03:28:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e03c2f2046b490a741ed6b7543134e0d7d287410', 'message': 'Perform fsync on glance image fetched to tempfile\n\nThere\'s a known bug where sometimes images downloaded from glance\nto a file prior to conversion into raw format may end up being\ncorrupted.\n\nThe root cause of this is because qemu-img uses fiemap\nto read blocks from said file, but it\'s not using FIEMAP_FLAG_SYNC.\nThe result is that if there are blocks in the kernel page_cache that\nhaven\'t made it to disk yet, they\'re skipped in the conversion.\n\nThis is a workaround that calls fsync.  This also introduces\nTony Breeds\' idea of a ""workaround"" conf group which I really liked,\nthe default behavior is to perform the fsync, however for those that\nhave verified they have the fixed version of qemu they can turn this\noff.\n\nChange-Id: Idbfb7f89fe64303d332ddc9a31443d7e85c717e4\nCloses-Bug: #1368815\nCo-Authored-By: Davanum Srinivas <dims@linux.vnet.ibm.com>\nCo-Authored-By: Tony Breeds <tony@bakeyournoodle.com>\n'}, {'number': 2, 'created': '2014-12-12 03:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7c087250b5899fa638b4e078305354316ee53945', 'message': 'Perform fsync on glance image fetched to tempfile\n\nThere\'s a known bug where sometimes images downloaded from glance\nto a file prior to conversion into raw format may end up being\ncorrupted.\n\nThe root cause of this is because qemu-img uses fiemap\nto read blocks from said file, but it\'s not using FIEMAP_FLAG_SYNC.\nThe result is that if there are blocks in the kernel page_cache that\nhaven\'t made it to disk yet, they\'re skipped in the conversion.\n\nThis is a workaround that calls fsync.  This also introduces\nTony Breeds\' idea of a ""workaround"" conf group which I really liked,\nthe default behavior is to perform the fsync, however for those that\nhave verified they have the fixed version of qemu they can turn this\noff.\n\nDistro status can be tracked at:\n    https://wiki.openstack.org/wiki/Bug1368815\n\nDocImpact\n\nChange-Id: Idbfb7f89fe64303d332ddc9a31443d7e85c717e4\nCloses-Bug: #1368815\nCo-Authored-By: Davanum Srinivas <dims@linux.vnet.ibm.com>\nCo-Authored-By: Tony Breeds <tony@bakeyournoodle.com>\n'}, {'number': 3, 'created': '2014-12-12 17:24:36.000000000', 'files': ['cinder/image/image_utils.py', 'cinder/tests/test_image_utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2ee13dec6389a898827cdf8c2c8ca3301df25132', 'message': 'Perform fsync on glance image fetched to tempfile\n\nThere\'s a known bug where sometimes images downloaded from glance\nto a file prior to conversion into raw format may end up being\ncorrupted.\n\nThe root cause of this is because qemu-img uses fiemap\nto read blocks from said file, but it\'s not using FIEMAP_FLAG_SYNC.\nThe result is that if there are blocks in the kernel page_cache that\nhaven\'t made it to disk yet, they\'re skipped in the conversion.\n\nThis is a workaround that calls fsync.  This also introduces\nTony Breeds\' idea of a ""workaround"" conf group which I really liked,\nthe default behavior is to perform the fsync, however for those that\nhave verified they have the fixed version of qemu they can turn this\noff.\n\nDistro status can be tracked at:\n    https://wiki.openstack.org/wiki/Bug1368815\n\nDocImpact\n\nChange-Id: Idbfb7f89fe64303d332ddc9a31443d7e85c717e4\nCloses-Bug: #1368815\nCo-Authored-By: Davanum Srinivas <dims@linux.vnet.ibm.com>\nCo-Authored-By: Tony Breeds <tony@bakeyournoodle.com>\n'}]",11,141259,2ee13dec6389a898827cdf8c2c8ca3301df25132,25,12,3,2243,,,0,"Perform fsync on glance image fetched to tempfile

There's a known bug where sometimes images downloaded from glance
to a file prior to conversion into raw format may end up being
corrupted.

The root cause of this is because qemu-img uses fiemap
to read blocks from said file, but it's not using FIEMAP_FLAG_SYNC.
The result is that if there are blocks in the kernel page_cache that
haven't made it to disk yet, they're skipped in the conversion.

This is a workaround that calls fsync.  This also introduces
Tony Breeds' idea of a ""workaround"" conf group which I really liked,
the default behavior is to perform the fsync, however for those that
have verified they have the fixed version of qemu they can turn this
off.

Distro status can be tracked at:
    https://wiki.openstack.org/wiki/Bug1368815

DocImpact

Change-Id: Idbfb7f89fe64303d332ddc9a31443d7e85c717e4
Closes-Bug: #1368815
Co-Authored-By: Davanum Srinivas <dims@linux.vnet.ibm.com>
Co-Authored-By: Tony Breeds <tony@bakeyournoodle.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/59/141259/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/image/image_utils.py', 'cinder/tests/test_image_utils.py']",2,e03c2f2046b490a741ed6b7543134e0d7d287410,bug/1368815," mox.StubOutWithMock(image_utils, '_fsync') image_utils._fsync(self.TEST_DEV_PATH).AndReturn(None)",,29,0
openstack%2Ftaskflow~master~I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1,openstack/taskflow,master,I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1,Add a simplistic hello world example,MERGED,2014-12-02 23:23:08.000000000,2014-12-21 19:12:33.000000000,2014-12-21 19:12:32.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 9608}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-12-02 23:23:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ffd19fe2d3cfdad6ad772db85383ce8890a87f84', 'message': 'Add a overly simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 2, 'created': '2014-12-03 00:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a1b2f8e47d4b760078aff27dccc96d34429668cb', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 3, 'created': '2014-12-03 01:02:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/76ef23f72ac3246a8e7dd0802c523e7ca69aff79', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 4, 'created': '2014-12-03 01:13:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0ffdbab782c4497e26d8a1aee213d4890ccdec8e', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 5, 'created': '2014-12-03 07:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f5aaa25ce33cfbf6f0565d451103d083b7adfeaf', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 6, 'created': '2014-12-03 07:12:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/12a85dae208ebf480e5aac6b230bcfbb04ac5831', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 7, 'created': '2014-12-06 23:07:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/db10b94e2547a0d3c3343e3e1085e0eddaa179f7', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 8, 'created': '2014-12-07 00:15:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3e1f1b94afad927668a1cbd6dc38bfd039e8d7a9', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 9, 'created': '2014-12-07 00:19:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/edb911266860bce9ac9f6f5407e1c3b6d32ced32', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 10, 'created': '2014-12-14 05:27:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b62d6e687236bdfa3172520b4b1ea963723fe017', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 11, 'created': '2014-12-14 05:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/298d3d1372d498960915391026200f2b38de4b01', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 12, 'created': '2014-12-14 19:07:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/665315c04e79b803446644ba78f2cde39c92c8cc', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 13, 'created': '2014-12-15 07:19:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d99944949a1fb16902901847c23be9a7fe759a59', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 14, 'created': '2014-12-18 22:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ca95ae74b1657e73fbc7443689d429f246b16d89', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 15, 'created': '2014-12-20 04:55:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4f6a79b65ccfc979e8cd4982c301f785906f6aea', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 16, 'created': '2014-12-20 06:55:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/fddbe8f73241ee0a17c07b6ce9bc52abc287fb41', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 17, 'created': '2014-12-20 07:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/479661432dd1935bb648c0aac2749eefa2ff545a', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 18, 'created': '2014-12-20 08:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/dbc82d8c72dfa4b0e5c312323d1aca14dfb41844', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 19, 'created': '2014-12-20 08:37:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3552d9ac4fe7c7a4bca2f482144d79848a2b5d23', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 20, 'created': '2014-12-20 09:15:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7ef26548a25488de06c1fd253f579fc863483059', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 21, 'created': '2014-12-21 01:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/804aefb954ddbe5f96343d39ea95f5871a677b42', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}, {'number': 22, 'created': '2014-12-21 05:54:23.000000000', 'files': ['doc/source/examples.rst', 'taskflow/examples/hello_world.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6cb9a0cb13cb3f98bdbf573d7af9496471f8dc2d', 'message': 'Add a simplistic hello world example\n\nChange-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1\n'}]",0,138572,6cb9a0cb13cb3f98bdbf573d7af9496471f8dc2d,58,6,22,1297,,,0,"Add a simplistic hello world example

Change-Id: I1d6e6535ab09d7f6c9d9ca3e2663983644b7a8a1
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/72/138572/11 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/examples.rst', 'taskflow/examples/hello_world.py']",2,ffd19fe2d3cfdad6ad772db85383ce8890a87f84,,"# -*- coding: utf-8 -*- # Copyright (C) 2014 Yahoo! Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import logging import os import sys logging.basicConfig(level=logging.ERROR) top_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir, os.pardir)) sys.path.insert(0, top_dir) try: import eventlet # noqa EVENTLET_AVAILABLE = True except ImportError: EVENTLET_AVAILABLE = False from taskflow import engines from taskflow.patterns import linear_flow as lf from taskflow import task from taskflow.types import futures # INTRO: This is the defacto hello world equivalent for taskflow; it shows how # a overly simplistic workflow can be created that runs using different # engines using different styles of execution (all can be used to run in # parallel if a workflow is provided that is parallelizable). class HelloTask(task.Task): def execute(self): print(""Hi from %s"" % self.name) work = lf.Flow(""root"") work.add(HelloTask('a'), HelloTask('b')) # Run in parallel using eventlet green threads... if EVENTLET_AVAILABLE: with futures.GreenThreadPoolExecutor() as executor: e = engines.load(work, executor=executor, engine='parallel') e.run() # Run in parallel using real threads... with futures.ThreadPoolExecutor(max_workers=1) as executor: e = engines.load(work, executor=executor, engine='parallel') e.run() # Run in parallel using external processes... with futures.ProcessPoolExecutor(max_workers=1) as executor: e = engines.load(work, executor=executor, engine='parallel') e.run() ",,83,0
openstack%2Fpbr~feature%2F0.10~I39d9dc6fe203d653960dbc5cc7afd017f05c1d1a,openstack/pbr,feature/0.10,I39d9dc6fe203d653960dbc5cc7afd017f05c1d1a,"Revert ""Move write_pbr_json to avoid issues with nose""",ABANDONED,2014-12-21 17:23:08.000000000,2014-12-21 18:33:02.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-21 17:23:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/7b0f3db4013d98d49b6395ddd993cb735fecf15b', 'message': 'Revert ""Move write_pbr_json to avoid issues with nose""\n\nThis reverts commit 0acee45efb9852599f0604ce1539febc350a50c0.\n\nIt isn\'t quite right for projects without any tags, but a hole in\nour integration testing let this slip through anyway.\n\nChange-Id: I39d9dc6fe203d653960dbc5cc7afd017f05c1d1a\n'}, {'number': 2, 'created': '2014-12-21 17:38:03.000000000', 'files': ['pbr/pbr_json.py', 'pbr/tests/test_setup.py', 'pbr/packaging.py', 'pbr/tests/test_packaging.py', 'pbr/git.py', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/pbr/commit/dec8f1baccca5d43a83ad1f55278ed0a72e2a057', 'message': 'Revert ""Move write_pbr_json to avoid issues with nose""\n\nThis reverts commit 0acee45efb9852599f0604ce1539febc350a50c0.\n\nIt isn\'t quite right for projects without any tags, but a hole in\nour integration testing let this slip through anyway.\n\nAlso remove the separate deps list for testenv:pep8 in tox.ini so\nthat it will pass with Setuptools 8.\n\nChange-Id: I39d9dc6fe203d653960dbc5cc7afd017f05c1d1a\n'}]",0,143307,dec8f1baccca5d43a83ad1f55278ed0a72e2a057,4,1,2,5263,,,0,"Revert ""Move write_pbr_json to avoid issues with nose""

This reverts commit 0acee45efb9852599f0604ce1539febc350a50c0.

It isn't quite right for projects without any tags, but a hole in
our integration testing let this slip through anyway.

Also remove the separate deps list for testenv:pep8 in tox.ini so
that it will pass with Setuptools 8.

Change-Id: I39d9dc6fe203d653960dbc5cc7afd017f05c1d1a
",git fetch https://review.opendev.org/openstack/pbr refs/changes/07/143307/1 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/pbr_json.py', 'pbr/tests/test_setup.py', 'pbr/packaging.py', 'pbr/tests/test_packaging.py', 'pbr/git.py', 'setup.cfg']",6,7b0f3db4013d98d49b6395ddd993cb735fecf15b,setuptools-8, pbr.json = pbr.packaging:write_pbr_json, pbr.json = pbr.pbr_json:write_pbr_json,254,350
openstack%2Fneutron~master~I36900b02bff34269f789956aa324379ff51eb81b,openstack/neutron,master,I36900b02bff34269f789956aa324379ff51eb81b,Add metadata proxy L3 agent driver,MERGED,2014-11-27 16:11:38.000000000,2014-12-21 17:28:20.000000000,2014-12-20 02:37:59.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 13380}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-11-27 16:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/27c370198bc3b4a146f41be287367b71acc16a01', 'message': 'Add metadata proxy L3 agent driver\n\nPartially-implements: blueprint restructure-l3-agent\nChange-Id: I36900b02bff34269f789956aa324379ff51eb81b\n'}, {'number': 2, 'created': '2014-11-27 18:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/871c2bbc70e8a0bf9fb1a62ceb04532438d7dd61', 'message': 'Add metadata proxy L3 agent driver\n\nTo-Do:\n* vArmourL3NATAgent (Before this patch) overrides _spawn/destroy_metadata_proxy\n  with empty stubs. This behavior should be maintained so that the metadata proxy\n  is not created when using vArmourL3NATAgent. It also overrides _router_added\n  and _router_removed, causing L3 agent driver notifications to not send out.\n\nPartially-implements: blueprint restructure-l3-agent\nChange-Id: I36900b02bff34269f789956aa324379ff51eb81b\n'}, {'number': 3, 'created': '2014-11-28 15:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/92a26d37bdaefecb49c1e217581346adaf21e7ba', 'message': 'Add metadata proxy L3 agent driver\n\nTo-Do:\n* vArmourL3NATAgent (Before this patch) overrides _spawn/destroy_metadata_proxy\n  with empty stubs. This behavior should be maintained so that the metadata proxy\n  is not created when using vArmourL3NATAgent. It also overrides _router_added\n  and _router_removed, causing L3 agent driver notifications to not send out.\n\nPartially-implements: blueprint restructure-l3-agent\nChange-Id: I36900b02bff34269f789956aa324379ff51eb81b\n'}, {'number': 4, 'created': '2014-11-28 15:27:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7b79cee7a1d2011f46fe103348ca3d8349ff80ba', 'message': 'Add metadata proxy L3 agent driver\n\nTo-Do:\n* vArmourL3NATAgent (Before this patch) overrides _spawn/destroy_metadata_proxy\n  with empty stubs. This behavior should be maintained so that the metadata proxy\n  is not created when using vArmourL3NATAgent. It also overrides _router_added\n  and _router_removed, causing L3 agent driver notifications to not send out.\n\nPartially-implements: blueprint restructure-l3-agent\nChange-Id: I36900b02bff34269f789956aa324379ff51eb81b\n'}, {'number': 5, 'created': '2014-11-30 15:04:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fd80fc75b1ea0f5b34384ab90c354adbc8b21460', 'message': 'Add metadata proxy L3 agent driver\n\nTo-Do:\n* vArmourL3NATAgent (Before this patch) overrides _spawn/destroy_metadata_proxy\n  with empty stubs. This behavior should be maintained so that the metadata proxy\n  is not created when using vArmourL3NATAgent. It also overrides _router_added\n  and _router_removed, causing L3 agent driver notifications to not send out.\n\nPartially-implements: blueprint restructure-l3-agent\nChange-Id: I36900b02bff34269f789956aa324379ff51eb81b\n'}, {'number': 6, 'created': '2014-12-09 22:26:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/13d4cb3a2b01d5841181c11f327805ee42f75d2d', 'message': 'Add metadata proxy L3 agent driver\n\nTo-Do:\n* vArmourL3NATAgent (Before this patch) overrides _spawn/destroy_metadata_proxy\n  with empty stubs. This behavior should be maintained so that the metadata proxy\n  is not created when using vArmourL3NATAgent. It also overrides _router_added\n  and _router_removed, causing L3 agent driver notifications to not send out.\n\nPartially-implements: blueprint restructure-l3-agent\nChange-Id: I36900b02bff34269f789956aa324379ff51eb81b\n'}, {'number': 7, 'created': '2014-12-12 18:41:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b9a72e91b282dcd2aa00688501dde574e5ff6a69', 'message': 'Add metadata proxy L3 agent driver\n\nTo-Do:\n* vArmourL3NATAgent (Before this patch) overrides _spawn/destroy_metadata_proxy\n  with empty stubs. This behavior should be maintained so that the metadata proxy\n  is not created when using vArmourL3NATAgent. It also overrides _router_added\n  and _router_removed, causing L3 agent driver notifications to not send out.\n\nPartially-implements: blueprint restructure-l3-agent\nChange-Id: I36900b02bff34269f789956aa324379ff51eb81b\n'}, {'number': 8, 'created': '2014-12-12 18:44:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0b24402e3bf9727b60f838676b670b14814a409f', 'message': 'Add metadata proxy L3 agent driver\n\nTo-Do:\n* vArmourL3NATAgent (Before this patch) overrides _spawn/destroy_metadata_proxy\n  with empty stubs. This behavior should be maintained so that the metadata proxy\n  is not created when using vArmourL3NATAgent. It also overrides _router_added\n  and _router_removed, causing L3 agent driver notifications to not send out.\n\nPartially-implements: blueprint restructure-l3-agent\nChange-Id: I36900b02bff34269f789956aa324379ff51eb81b\n'}, {'number': 9, 'created': '2014-12-17 20:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a0293b608334a6998deccfd795d007073ac176ae', 'message': 'Add metadata proxy L3 agent driver\n\nTo-Do:\n* vArmourL3NATAgent (Before this patch) overrides _spawn/destroy_metadata_proxy\n  with empty stubs. This behavior should be maintained so that the metadata proxy\n  is not created when using vArmourL3NATAgent. It also overrides _router_added\n  and _router_removed, causing L3 agent driver notifications to not send out.\n\nPartially-implements: blueprint restructure-l3-agent\nChange-Id: I36900b02bff34269f789956aa324379ff51eb81b\n'}, {'number': 10, 'created': '2014-12-17 21:00:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b70fa3f0ffe629baa8a9309169bd1959794b7c85', 'message': 'Add metadata proxy L3 agent driver\n\nTo-Do:\n* vArmourL3NATAgent (Before this patch) overrides _spawn/destroy_metadata_proxy\n  with empty stubs. This behavior should be maintained so that the metadata proxy\n  is not created when using vArmourL3NATAgent. It also overrides _router_added\n  and _router_removed, causing L3 agent driver notifications to not send out.\n\nPartially-implements: blueprint restructure-l3-agent\nChange-Id: I36900b02bff34269f789956aa324379ff51eb81b\n'}, {'number': 11, 'created': '2014-12-18 12:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dd32b744423d076bbc9e983849f11a236f74237f', 'message': 'Add metadata proxy L3 agent driver\n\nTo-Do:\n* vArmourL3NATAgent (Before this patch) overrides _spawn/destroy_metadata_proxy\n  with empty stubs. This behavior should be maintained so that the metadata proxy\n  is not created when using vArmourL3NATAgent. It also overrides _router_added\n  and _router_removed, causing L3 agent driver notifications to not send out.\n\nPartially-implements: blueprint restructure-l3-agent\nChange-Id: I36900b02bff34269f789956aa324379ff51eb81b\n'}, {'number': 12, 'created': '2014-12-18 12:43:51.000000000', 'files': ['neutron/agent/l3/agent.py', 'neutron/tests/unit/agent/metadata/test_driver.py', 'neutron/agent/metadata/driver.py', 'neutron/tests/unit/agent/metadata/__init__.py', 'neutron/agent/l3/ha.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6b38f29fdbd077434f1f7139466479e81bf4882d', 'message': 'Add metadata proxy L3 agent driver\n\nTo-Do:\n* vArmourL3NATAgent (Before this patch) overrides _spawn/destroy_metadata_proxy\n  with empty stubs. This behavior should be maintained so that the metadata proxy\n  is not created when using vArmourL3NATAgent. It also overrides _router_added\n  and _router_removed, causing L3 agent driver notifications to not send out.\n\nPartially-implements: blueprint restructure-l3-agent\nChange-Id: I36900b02bff34269f789956aa324379ff51eb81b\n'}]",13,137672,6b38f29fdbd077434f1f7139466479e81bf4882d,235,32,12,8873,,,0,"Add metadata proxy L3 agent driver

To-Do:
* vArmourL3NATAgent (Before this patch) overrides _spawn/destroy_metadata_proxy
  with empty stubs. This behavior should be maintained so that the metadata proxy
  is not created when using vArmourL3NATAgent. It also overrides _router_added
  and _router_removed, causing L3 agent driver notifications to not send out.

Partially-implements: blueprint restructure-l3-agent
Change-Id: I36900b02bff34269f789956aa324379ff51eb81b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/72/137672/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/metadata/driver.py', 'neutron/agent/l3_agent.py', 'neutron/agent/l3_ha_agent.py', 'neutron/tests/functional/agent/test_l3_agent.py']",4,27c370198bc3b4a146f41be287367b71acc16a01,bp/restructure-l3-agent," def _create_router(self, agent, router): agent._add_and_or_process_router(router) return agent.router_info[router['id']] router_info = self.generate_router_info(enable_ha) router = self.manage_router(self.agent, router_info) self._delete_router(self.agent, router.router_id)"," def _create_router(self, router): self.agent._add_and_or_process_router(router) return self.agent.router_info[router['id']] router = self.manage_router(enable_ha) self._delete_router(router.router_id)",114,74
openstack%2Fpython-cinderclient~master~I7817c92069d32d1926e185ca0d0ab14e738b8b3d,openstack/python-cinderclient,master,I7817c92069d32d1926e185ca0d0ab14e738b8b3d,Use immutable arg rather mutable arg,MERGED,2014-07-01 08:17:17.000000000,2014-12-21 16:15:42.000000000,2014-12-21 16:15:41.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2759}, {'_account_id': 5538}, {'_account_id': 6491}]","[{'number': 1, 'created': '2014-07-01 08:17:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/119486f80b758b13f9aa783401a33dda2ab39e81', 'message': ""Use immutable arg rather mutable arg\n\nPassing mutable objects as default args is a known Python pitfall.\nWe'd better avoid this. This commit changes mutable default args with\nNone, then use 'arg = arg or []'.\n\nChange-Id: I7817c92069d32d1926e185ca0d0ab14e738b8b3d\n""}, {'number': 2, 'created': '2014-07-03 07:07:04.000000000', 'files': ['cinderclient/tests/fakes.py', 'cinderclient/tests/v1/test_shell.py', 'cinderclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/31a7ae54f67c2b109d60b265dea85b35e31631d4', 'message': ""Use immutable arg rather mutable arg\n\nPassing mutable objects as default args is a known Python pitfall.\nWe'd better avoid this. This commit changes mutable default args with\nNone.\n\nChange-Id: I7817c92069d32d1926e185ca0d0ab14e738b8b3d\n""}]",0,103791,31a7ae54f67c2b109d60b265dea85b35e31631d4,21,6,2,6763,,,0,"Use immutable arg rather mutable arg

Passing mutable objects as default args is a known Python pitfall.
We'd better avoid this. This commit changes mutable default args with
None.

Change-Id: I7817c92069d32d1926e185ca0d0ab14e738b8b3d
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/91/103791/1 && git format-patch -1 --stdout FETCH_HEAD,['cinderclient/tests/fakes.py'],1,119486f80b758b13f9aa783401a33dda2ab39e81,use_immutable_arg,"def assert_has_keys(dict, required=None, optional=None): required = required or [] optional = optional or [] ","def assert_has_keys(dict, required=[], optional=[]):",4,1
openstack%2Fheat~master~Iea454f4201990f65633b644bbefe708e5a216885,openstack/heat,master,Iea454f4201990f65633b644bbefe708e5a216885,Fix SoftwareDeployments validation,MERGED,2014-12-19 22:49:01.000000000,2014-12-21 15:27:29.000000000,2014-12-21 15:27:28.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4571}, {'_account_id': 6983}, {'_account_id': 8246}]","[{'number': 1, 'created': '2014-12-19 22:49:01.000000000', 'files': ['heat/engine/resources/resource_group.py', 'heat/tests/test_software_deployment.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/4834443353fab57315040c9de2c7dac19e8a8b51', 'message': 'Fix SoftwareDeployments validation\n\nFixes a regression caused by https://review.openstack.org/#/c/141444/\n\nInstead of referencing the COUNT property, use _resource_names(),\nwhich is already overridden in the SoftwareDeployments subclass\nand is directly related to the count of created resources in\nboth resources.\n\nChange-Id: Iea454f4201990f65633b644bbefe708e5a216885\nCloses-Bug: #1404399\n'}]",0,143212,4834443353fab57315040c9de2c7dac19e8a8b51,10,5,1,4328,,,0,"Fix SoftwareDeployments validation

Fixes a regression caused by https://review.openstack.org/#/c/141444/

Instead of referencing the COUNT property, use _resource_names(),
which is already overridden in the SoftwareDeployments subclass
and is directly related to the count of created resources in
both resources.

Change-Id: Iea454f4201990f65633b644bbefe708e5a216885
Closes-Bug: #1404399
",git fetch https://review.opendev.org/openstack/heat refs/changes/12/143212/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/resource_group.py', 'heat/tests/test_software_deployment.py']",2,4834443353fab57315040c9de2c7dac19e8a8b51,bug/1404399," def test_validate(self): stack = utils.parse_stack(self.template) snip = stack.t.resource_definitions(stack)['deploy_mysql'] resg = sd.SoftwareDeployments('test', snip, stack) self.assertIsNone(resg.validate())",,10,1
openstack%2Fpython-keystoneclient~master~If473b921c8f13c3fde647dc00bb5f6ce1ef58dbe,openstack/python-keystoneclient,master,If473b921c8f13c3fde647dc00bb5f6ce1ef58dbe,Add sample certificate fixtures,ABANDONED,2014-12-18 15:29:01.000000000,2014-12-21 14:42:02.000000000,,"[{'_account_id': 3}, {'_account_id': 2218}]","[{'number': 1, 'created': '2014-12-18 15:29:01.000000000', 'files': ['keystoneclient/tests/client_fixtures.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/06c8ae6e72096c4b85beb0aab0b704a5f1690825', 'message': 'Add sample certificate fixtures\n\nTests for fetching certificates from the Identity server will\nrequire sample responses. The samples here were generated using\n\n curl http://localhost:5000/v2.0/certificates/ca\n\nor\n\n curl http://localhost:5000/v3/OS-SIMPLE-CERT/ca\n\nfor the CA certificate, and\n\n curl http://localhost:5000/v2.0/certificates/signing\n\nor\n\n curl http://localhost:5000/v3/OS-SIMPLE-CERT/certificates\n\nfor the signing certificate.\n\nChange-Id: If473b921c8f13c3fde647dc00bb5f6ce1ef58dbe\n'}]",0,142817,06c8ae6e72096c4b85beb0aab0b704a5f1690825,4,2,1,6486,,,0,"Add sample certificate fixtures

Tests for fetching certificates from the Identity server will
require sample responses. The samples here were generated using

 curl http://localhost:5000/v2.0/certificates/ca

or

 curl http://localhost:5000/v3/OS-SIMPLE-CERT/ca

for the CA certificate, and

 curl http://localhost:5000/v2.0/certificates/signing

or

 curl http://localhost:5000/v3/OS-SIMPLE-CERT/certificates

for the signing certificate.

Change-Id: If473b921c8f13c3fde647dc00bb5f6ce1ef58dbe
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/17/142817/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/tests/client_fixtures.py'],1,06c8ae6e72096c4b85beb0aab0b704a5f1690825,bp/auth-token-use-client,"# The Identity server returns a document like this when a request is made to # fetch the CA certificate. SAMPLE_CA_CERTIFICATE = """""" -----BEGIN CERTIFICATE----- MIIDgTCCAmmgAwIBAgIJANuBYNj1nL2uMA0GCSqGSIb3DQEBBQUAMFcxCzAJBgNV BAYTAlVTMQ4wDAYDVQQIDAVVbnNldDEOMAwGA1UEBwwFVW5zZXQxDjAMBgNVBAoM BVVuc2V0MRgwFgYDVQQDDA93d3cuZXhhbXBsZS5jb20wHhcNMTQxMjE1MjI1MTU5 WhcNMjQxMjEyMjI1MTU5WjBXMQswCQYDVQQGEwJVUzEOMAwGA1UECAwFVW5zZXQx DjAMBgNVBAcMBVVuc2V0MQ4wDAYDVQQKDAVVbnNldDEYMBYGA1UEAwwPd3d3LmV4 YW1wbGUuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAwaS7cw3T O9RlCEwpih6GmGT2qBmfWHCzjIvnfjU0Gu0gpYTm7JjTbVhsJZGsZlSzlUYORllX u9VJ0Q+6VS9ed0po10JPPC2WuQleBcViifnFeupdtjfkGlGtdCwBnU29wMirK6eA Sm24dyPiW+0/awe+XszXBHK4uHK1yetbHvy+MkD6B3ncQM4TerygYbVHvCeww/Oe VFfOgsWZE07OUe4SJrZM2kpL3BfwoRvDLfUmw2XjjaCHcRNSM4H3RGFyGp0mD0h4 sAjWvWGGRj1Jt59beVrvjqHnooMAM+ZyuJi6j9qnTG70TcQyiOOX7b4iLWXC69Hg e/9ObGBCxdkRBQIDAQABo1AwTjAMBgNVHRMEBTADAQH/MB0GA1UdDgQWBBQmMAa3 K75QAIwXdROhMom3NoBdZTAfBgNVHSMEGDAWgBQmMAa3K75QAIwXdROhMom3NoBd ZTANBgkqhkiG9w0BAQUFAAOCAQEAe4N5gBe3hd0wa5tqyatkZuwPinCsDi8vLArD 7OH3w+oCJ/y+hDg0yqfK65aT9MKtXzgOA4l3p79f78A00rQRLcbl4LmMXVneO3KI vmXng1fx6KjN7REl/gmcOgNQE+6V7NviHBRI6DPDrslLc9Z2OfRAtKF37eq3ifTk BKMoQ6vlglDnJVGdnvB8IDBL51/c+rlcoVHF5rnrnsC/YNZ9NN/Ij5KxGIERVQOQ iF6TiDQzSPDmJ3AO+pi4vWw8te9U8UXN0J8nHptusZawojcoDYEgJDr4AXd+LE8V IaUom2e4nLSlh9Hfn6osmI6EKS7s8okE2jcEr625004NNy33DQ== -----END CERTIFICATE----- """""" # The Identity server returns a document like this when a request is made to # fetch the signing certificate. SAMPLE_SIGNING_CERTIFICATE = """""" Certificate: Data: Version: 3 (0x2) Serial Number: 1 (0x1) Signature Algorithm: sha1WithRSAEncryption Issuer: C=US, ST=Unset, L=Unset, O=Unset, CN=www.example.com Validity Not Before: Dec 15 22:51:59 2014 GMT Not After : Dec 12 22:51:59 2024 GMT Subject: C=US, ST=Unset, O=Unset, CN=www.example.com Subject Public Key Info: Public Key Algorithm: rsaEncryption Public-Key: (2048 bit) Modulus: 00:e2:3b:5d:36:05:f8:ab:db:d0:a0:5a:fd:ed:83: 94:86:5e:e2:77:58:46:58:a3:b3:24:13:3c:f1:91: 97:99:97:76:02:aa:c9:76:93:e3:4b:0d:d8:a4:b1: 0b:09:28:1e:d6:f8:db:d1:3d:65:75:f0:4d:66:45: ae:19:3a:6d:d2:0f:d8:29:7f:5b:f8:b6:53:d7:82: 6f:d5:01:31:92:71:e4:31:03:5d:e5:3e:05:cf:cb: 59:78:68:f0:85:60:f7:4f:b8:e5:01:e6:10:9f:80: 9b:42:70:5e:92:9d:4b:72:44:40:ba:6b:34:3c:46: 51:a6:16:d8:15:8d:d2:1f:c1:0d:7d:90:27:20:ec: 5f:c8:a3:aa:d2:76:b3:fd:df:27:b7:10:33:df:ca: f6:e1:a5:72:b4:c7:86:2d:45:23:2a:1c:0d:ee:7e: 6e:84:eb:43:df:63:ea:c6:6c:21:b8:52:bd:40:c1: 08:c2:ce:8e:b2:7d:fe:5f:87:74:9e:f9:7e:f6:46: e0:81:66:a5:40:5a:56:d5:b2:b7:74:0e:4f:65:3c: 51:ab:2e:cb:f1:d1:ea:22:86:43:6c:31:1e:5b:24: 31:1a:1a:41:3d:36:1e:4a:9d:41:54:3d:04:c5:ff: c1:e6:13:ff:a0:cd:69:08:ca:ef:8e:97:c1:62:80: 15:87 Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Basic Constraints: CA:FALSE X509v3 Subject Key Identifier: 44:07:2D:84:AA:08:AA:49:17:F7:35:CC:35:0C:B2:F6:A7:60:F5:C6 X509v3 Authority Key Identifier: keyid:26:30:06:B7:2B:BE:50:00:8C:17:75:13:A1:32:89:B7:36:80:5D\ :65 Signature Algorithm: sha1WithRSAEncryption bf:23:fa:67:9c:ec:bc:7f:76:ae:fc:5a:bb:0a:e5:e8:26:92: 11:7e:7d:97:1b:d6:a5:e5:97:84:27:bf:1f:70:8d:2a:ff:b6: dc:98:d4:14:02:95:1e:fc:36:08:41:31:e3:bb:d3:90:81:31: ef:9d:c5:2a:dc:a5:23:24:ba:14:fb:35:3d:31:94:fd:af:c0: e4:07:d4:af:aa:67:d1:4a:18:ae:3a:cc:d8:90:72:f0:24:42: 9d:86:7e:3f:b2:2e:15:e8:27:86:7c:3f:30:47:b9:f1:c5:2d: 7b:2c:c2:19:40:b6:af:b6:49:a0:27:8e:c3:c8:40:18:2f:68: 5c:67:01:1b:c8:f3:9e:2a:60:9f:df:44:f2:ae:2f:48:61:f7: 24:0b:47:90:03:c2:78:30:8b:8e:8c:4d:3a:8f:37:d8:17:3e: b9:f8:e8:4e:25:a5:b2:fa:5d:24:a4:d6:42:52:e1:d2:dd:40: 5f:4d:cb:98:10:dd:39:e1:f3:a7:09:dc:51:f1:cf:82:27:26: 56:cc:67:dc:41:da:8f:54:02:25:0e:23:c9:f4:13:63:22:39: 4f:55:b1:c2:6e:67:e2:92:52:f0:b1:06:ed:73:4d:db:f4:d2: 97:a5:75:29:f7:be:20:87:ba:24:b4:95:cd:f1:74:4d:80:56: b7:ed:c9:ea -----BEGIN CERTIFICATE----- MIIDZjCCAk6gAwIBAgIBATANBgkqhkiG9w0BAQUFADBXMQswCQYDVQQGEwJVUzEO MAwGA1UECAwFVW5zZXQxDjAMBgNVBAcMBVVuc2V0MQ4wDAYDVQQKDAVVbnNldDEY MBYGA1UEAwwPd3d3LmV4YW1wbGUuY29tMB4XDTE0MTIxNTIyNTE1OVoXDTI0MTIx MjIyNTE1OVowRzELMAkGA1UEBhMCVVMxDjAMBgNVBAgMBVVuc2V0MQ4wDAYDVQQK DAVVbnNldDEYMBYGA1UEAwwPd3d3LmV4YW1wbGUuY29tMIIBIjANBgkqhkiG9w0B AQEFAAOCAQ8AMIIBCgKCAQEA4jtdNgX4q9vQoFr97YOUhl7id1hGWKOzJBM88ZGX mZd2AqrJdpPjSw3YpLELCSge1vjb0T1ldfBNZkWuGTpt0g/YKX9b+LZT14Jv1QEx knHkMQNd5T4Fz8tZeGjwhWD3T7jlAeYQn4CbQnBekp1LckRAums0PEZRphbYFY3S H8ENfZAnIOxfyKOq0naz/d8ntxAz38r24aVytMeGLUUjKhwN7n5uhOtD32Pqxmwh uFK9QMEIws6Osn3+X4d0nvl+9kbggWalQFpW1bK3dA5PZTxRqy7L8dHqIoZDbDEe WyQxGhpBPTYeSp1BVD0Exf/B5hP/oM1pCMrvjpfBYoAVhwIDAQABo00wSzAJBgNV HRMEAjAAMB0GA1UdDgQWBBREBy2EqgiqSRf3Ncw1DLL2p2D1xjAfBgNVHSMEGDAW gBQmMAa3K75QAIwXdROhMom3NoBdZTANBgkqhkiG9w0BAQUFAAOCAQEAvyP6Z5zs vH92rvxauwrl6CaSEX59lxvWpeWXhCe/H3CNKv+23JjUFAKVHvw2CEEx47vTkIEx 753FKtylIyS6FPs1PTGU/a/A5AfUr6pn0UoYrjrM2JBy8CRCnYZ+P7IuFegnhnw/ MEe58cUteyzCGUC2r7ZJoCeOw8hAGC9oXGcBG8jznipgn99E8q4vSGH3JAtHkAPC eDCLjoxNOo832Bc+ufjoTiWlsvpdJKTWQlLh0t1AX03LmBDdOeHzpwncUfHPgicm Vsxn3EHaj1QCJQ4jyfQTYyI5T1Wxwm5n4pJS8LEG7XNN2/TSl6V1Kfe+IIe6JLSV zfF0TYBWt+3J6g== -----END CERTIFICATE----- """""" ",,110,0
openstack%2Foperations-guide~master~I8db16ba8228cd0aecf035a4ddb7c1c41f1d24741,openstack/operations-guide,master,I8db16ba8228cd0aecf035a4ddb7c1c41f1d24741,Imported Translations from Transifex,MERGED,2014-12-21 06:01:20.000000000,2014-12-21 09:00:23.000000000,2014-12-21 09:00:23.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-21 06:01:20.000000000', 'files': ['doc/openstack-ops/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/46760a2d3363696820b3f6bbcd52cd661116f3ab', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I8db16ba8228cd0aecf035a4ddb7c1c41f1d24741\n'}]",0,143289,46760a2d3363696820b3f6bbcd52cd661116f3ab,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I8db16ba8228cd0aecf035a4ddb7c1c41f1d24741
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/89/143289/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/locale/ja.po'],1,46760a2d3363696820b3f6bbcd52cd661116f3ab,transifex/translations,"""POT-Creation-Date: 2014-12-19 06:54+0000\n"" ""PO-Revision-Date: 2014-12-21 05:50+0000\n"" ""Last-Translator: ykatabam <ykatabam@redhat.com>\n""msgstr ""後に続く要求への対応を容易にするには、環境変数にトークンを保管します。""msgstr ""これで、コマンドラインでトークンを <literal>$TOKEN</literal> として参照できるようになりました。""msgstr ""サービスカタログから、サービスエンドポイント (例: コンピュート) を選択します。要求を試します。例えば、インスタンス (サーバー) の一覧表示を行います。""msgstr ""API 要求の構成方法については、<link href=\""http://developer.openstack.org/api-ref.html\"">OpenStack API Reference</link> を参照してください。jq を使用した応答についての詳しい説明は <link href=\""http://stedolan.github.io/jq/manual/\"">jq Manual</link> を参照してください。""msgstr ""上記の cURL コマンドで使用している <code>-s flag</code> は、進行状況メーターが表示されないようにするために使用します。cURL コマンドの実行で問題が生じた場合には、このオプションを削除してください。また、cURL コマンドのトラブるシューティングを行う場合には、<code>-v</code> フラグを指定してより詳細な出力を表示すると役立ちます。cURL には他にも多数の役立つ機能があります。全オプションは、man ページで参照してください。""msgstr ""管理者は、利用可能な OpenStack を使用して、OpenStack クラウドの全容を確認する方法がいくつかあります。本項では、クラウドの概要、形態、サイズ、現在の状態を確認する方法について説明します。<indexterm class=\""singular\""><primary>サービス</primary><secondary>概要の取得</secondary></indexterm><indexterm class=\""singular\""><primary>サーバー</primary><secondary概要の取得</secondary></indexterm><indexterm class=\""singular\""><primary>クラウドコンピューティング</primary><secondary>クラウドの概観</secondary></indexterm><indexterm class=\""singular\""><primary>コマンドラインツール</primary><secondary>サーバーとサービス</secondary></indexterm>""msgstr ""出力には、5 つのコンピュートノードと 1 つのクラウドコントローラーが表示されています。スマイリーフェイス (<code>:-)</code> など)が見えます。これはサービスが稼働中であることを示しています。サービスがりようできなくなると、<code>:-)</code> のシンボルが <code>XXX</code> に変わります。これは、サービスが停止している理由をトラブルシューティングする必要があることを示しています。""msgstr ""cinder を使用している場合は、次のコマンドを実行して同様の一覧を表示します。""msgstr ""また、Identity Service (keystone) を使用してクラウドで利用可能なサービスと、サービス用に設定済みのエンドポイントを確認することもできます。<indexterm class=\""singular\""><primary>Identity Service</primary><secondary>サービスおよびエンドポイントの表示</secondary></indexterm>""msgstr ""以下のコマンドを実行するには、正しい管理用の変数を設定済みのシェル環境が必要です。""msgstr ""上記の出力は、2 つのサービスのみを表示するように、カットされています。クラウドが提供するサービスごとにサービスブロックが 1 つ表示されているのがわかります。エンドポイントタイプによってエンドポイントドメインが異なる点に注意してください。タイプによってエンドポイントドメインを別にする必要ありませんが、エンドポイントのプライバシーやネットワークトラフィックの分離などの異なる理由で分けることができます。""msgstr ""インストールされている Compute のバージョンを確認するには、<literal>nova-manage</literal><phrase role=\""keep-together\"">command</phrase> を使用することができます: <placeholder-1/>""msgstr ""コンピュートノードの診断""msgstr ""実行中の仮想マシンの CPU 使用状況、メモリー、ディスク I/O、ネットワーク I/O などの追加情報を取得するには、<literal>nova diagnostics</literal> コマンドに<indexterm class=\""singular\""><primary>コンピュートノード</primary><secondary>診断</secondary></indexterm><indexterm class=\""singular\""><primary>コマンドラインツール</primary><secondary>コンピュートノードの診断</secondary></indexterm> サーバー ID を指定して実行します:""msgstr ""ハイパーバイザーによってサポートする属性が異なるため、コマンドの出力はハイパーバイザーによって異なります。<indexterm class=\""singular\""><primary>ハイパーバイザー</primary><secondary>コンピュートノードの診断</secondary></indexterm> 以下の実例は、最もよく使用されている 2 つのハイパーバイザーの間で出力がどのように異なるかを示しています。ハイパーバイザーが Xen の場合の例は以下のようになります: <placeholder-1/>このコマンドは、libvirt によって管理されている任意のハイパーバイザー (例: KVM、QEMU、LXC) で機能しますが、KVM でのみテスト済みです。ハイパーバイザーが KVM の場合の例は以下のようになります""msgstr ""ネットワークの検査""msgstr ""クラウドでどの Fixed IP ネットワークが設定されているかを確認するには、 <literal>nova</literal> コマンドラインクライアントを使用して IP アドレスの範囲を取得することができます:<indexterm class=\""singular\""><primary>ネットワーク</primary><secondary>検査</secondary></indexterm><indexterm class=\""singular\""><primary>作業環境</primary><secondary>ネットワークの検査</secondary></indexterm><placeholder-1/>""msgstr ""<literal>nova-manage</literal> ツールは、追加の情報を提供することが可能です:""msgstr ""この出力は、2 つのネットワークが設定されており、各ネットワークには 255 の IP アドレス ( /24 サブネットが 1 つ) が含まれていることを示しています。1 番目のネットワークは、特定のプロジェクトに割り当てられていますが、2 番目のネットワークはまだ割り当てができる状態です。このネットワークは手動で割り当てることができます。割り当てられていない場合には、プロジェクトで最初のインスタンスが起動されたときに自動で割り当てられます。""msgstr ""クラウドに利用可能な Floating IP アドレスがあるかどうかを確認するには、以下のコマンドを実行します。""msgstr ""この場合は、2 つの Floating IP アドレスが利用可能です。最初の IP アドレスはプロジェクトに確保されていますが、もう一方は確保されていません。""msgstr ""クラウドに追加されたプロジェクトの一覧を確認するには、<indexterm class=\""singular\""><primary>プロジェクト</primary><secondary>現在の一覧の取得</secondary></indexterm><indexterm class=\""singular\""><primary>ユーザー管理</primary><secondary>ユーザーの一覧表示</secondary></indexterm><indexterm class=\""singular\""><primary>作業環境</primary><secondary>users and projects</secondary></indexterm> 以下のコマンドを実行します:""msgstr ""ユーザーおよびグループは、一対一でマッピングされる場合があります。このような状況は cinder、glance、nova、swift などの標準システムアカウントやグループにユーザーが 1 人しかいない場合に発生します。""msgstr ""実行中のインスタンスを確認するには、<indexterm class=\""singular\""><primary>instances</primary><secondary>実行中のリスト</secondary></indexterm><indexterm class=\""singular\""><primary>作業環境</primary><secondary>実行中のインスタンス</secondary></indexterm> 以下のコマンドを実行します:""","""POT-Creation-Date: 2014-12-18 01:41+0000\n"" ""PO-Revision-Date: 2014-12-17 23:31+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"",27,27
openstack%2Fcinder~master~I53945f2864e6cfab756afdaeb17d45dfdac38c02,openstack/cinder,master,I53945f2864e6cfab756afdaeb17d45dfdac38c02,Persist volume uuid on VMAX array,MERGED,2014-12-11 03:56:02.000000000,2014-12-21 06:30:03.000000000,2014-12-21 06:30:01.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 6491}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 13628}, {'_account_id': 13636}, {'_account_id': 14206}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-11 03:56:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e86e24d328aeaf3798fcc9e97ee41d751d463cdf', 'message': 'Persist volume name on VMAX array\n\nThis change saves the volume name (volume-<uuid>) in the\nElementName field of a SMI-S volume object so that it persists\non the array.\n\nChange-Id: I53945f2864e6cfab756afdaeb17d45dfdac38c02\nCloses-Bug: #1395903\n'}, {'number': 2, 'created': '2014-12-11 04:01:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3eeeefa6d5018cab73d96b0a885cd5e956f8bcbc', 'message': 'Persist volume uuid on VMAX array\n\nThis change saves the volume uuid in the ElementName field of\na SMI-S volume object so that it persists on the array.\n\nChange-Id: I53945f2864e6cfab756afdaeb17d45dfdac38c02\nCloses-Bug: #1395903\n'}, {'number': 3, 'created': '2014-12-13 03:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2dfb8615205ce91be08d4fa69fc666e09a745b3f', 'message': 'Persist volume uuid on VMAX array\n\nThis change saves the volume uuid in the ElementName field of\na SMI-S volume object so that it persists on the array.\n\nCloses-Bug: #1395903\nChange-Id: I53945f2864e6cfab756afdaeb17d45dfdac38c02\n'}, {'number': 4, 'created': '2014-12-13 05:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6fe0da3d429c72e1a34d2519ef8cfeae67c6d0a7', 'message': 'Persist volume uuid on VMAX array\n\nThis change saves the volume uuid in the ElementName field of\na SMI-S volume object so that it persists on the array.\n\nCloses-Bug: #1395903\nChange-Id: I53945f2864e6cfab756afdaeb17d45dfdac38c02\n'}, {'number': 5, 'created': '2014-12-17 05:00:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f8fac046c39c4ef87f5a2543990ecc8109a4f8f3', 'message': 'Persist volume uuid on VMAX array\n\nThis change saves the volume uuid in the ElementName field of\na SMI-S volume object so that it persists on the array.\n\nCloses-Bug: #1395903\nChange-Id: I53945f2864e6cfab756afdaeb17d45dfdac38c02\n'}, {'number': 6, 'created': '2014-12-17 23:23:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5cf0b67981d9b35dac083c83ff2ce749215656d3', 'message': 'Persist volume uuid on VMAX array\n\nThis change saves the volume uuid in the ElementName field of\na SMI-S volume object so that it persists on the array.\n\nCloses-Bug: #1395903\nChange-Id: I53945f2864e6cfab756afdaeb17d45dfdac38c02\n'}, {'number': 7, 'created': '2014-12-19 22:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/21ffed05cc3968ecedf693464cb522e4637c2562', 'message': 'Persist volume uuid on VMAX array\n\nThis change saves the volume uuid in the ElementName field of\na SMI-S volume object so that it persists on the array.\n\nCloses-Bug: #1395903\nChange-Id: I53945f2864e6cfab756afdaeb17d45dfdac38c02\n'}, {'number': 8, 'created': '2014-12-19 22:28:58.000000000', 'files': ['cinder/volume/drivers/emc/emc_vmax_provision.py', 'cinder/volume/drivers/emc/emc_vmax_common.py', 'cinder/tests/test_emc_vmax.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/44d95acb744be64f12855032a2f83831374a5632', 'message': 'Persist volume uuid on VMAX array\n\nThis change saves the volume uuid in the ElementName field of\na SMI-S volume object so that it persists on the array.\n\nCloses-Bug: #1395903\nChange-Id: I53945f2864e6cfab756afdaeb17d45dfdac38c02\n'}]",0,140910,44d95acb744be64f12855032a2f83831374a5632,63,20,8,6491,,,0,"Persist volume uuid on VMAX array

This change saves the volume uuid in the ElementName field of
a SMI-S volume object so that it persists on the array.

Closes-Bug: #1395903
Change-Id: I53945f2864e6cfab756afdaeb17d45dfdac38c02
",git fetch https://review.opendev.org/openstack/cinder refs/changes/10/140910/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/emc/emc_vmax_provision.py', 'cinder/volume/drivers/emc/emc_vmax_common.py', 'cinder/tests/test_emc_vmax.py']",3,e86e24d328aeaf3798fcc9e97ee41d751d463cdf,bug/1393555_threadsafe," 'device_id': '1', 'provider_auth': None, 'project_id': 'project', 'display_name': 'vol1', 'display_description': 'test volume', 'volume_type_id': 'abc', 'provider_location': str(provider_location), 'status': 'available', 'host': 'fake-host' } test_volume_v2 = {'name': 'vol1', 'size': 1, 'volume_name': 'vol1', 'id': 'vol1', 'device_id': '1', 'device_id': '4', 'device_id': '99999', 'id': 'vmax-154326', vol['DeviceID'] = vol['device_id'] self.driver.create_volume(self.data.test_volume_v2) self.driver.create_volume(self.data.test_volume_v2) self.driver.create_volume(self.data.test_volume_v2) self.driver.create_volume(self.data.test_volume_v2) self.driver.create_volume(self.data.test_volume_v2) self.driver.create_volume(self.data.test_volume_v2) self.driver.create_volume(self.data.test_volume_v2) self.driver.create_volume(self.data.test_volume_v2)"," vol['DeviceID'] = vol['id'] self.driver.create_volume(self.data.test_volume) self.driver.create_volume(self.data.test_volume) self.driver.create_volume(self.data.test_volume) self.driver.create_volume(self.data.test_volume) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) @mock.patch.object( FakeDB, 'volume_get', return_value=EMCVMAXCommonData.test_source_volume) @mock.patch.object( EMCVMAXFast, 'get_pool_associated_to_policy', return_value=1) @mock.patch.object( EMCVMAXUtils, 'get_volume_meta_head', return_value=[EMCVMAXCommonData.test_volume]) @mock.patch.object( EMCVMAXUtils, 'get_meta_members_capacity_in_bit', return_value=[1234567, 7654321]) @mock.patch.object( EMCVMAXCommon, '_get_pool_and_storage_system', return_value=(None, EMCVMAXCommonData.storage_system)) def test_create_clone_fast_failed(self, mock_volume_type, mock_vol, mock_policy, mock_meta, mock_size, mock_pool): self.data.test_volume['volume_name'] = ""vmax-1234567"" self.driver.common._modify_and_get_composite_volume_instance = ( mock.Mock(return_value=(1L, None))) self.assertRaises(exception.VolumeBackendAPIException, self.driver.create_cloned_volume, self.data.test_volume, EMCVMAXCommonData.test_source_volume) self.driver.create_volume(self.data.test_volume) self.driver.create_volume(self.data.test_volume) self.driver.create_volume(self.data.test_volume) self.driver.create_volume(self.data.test_volume) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) @mock.patch.object( FakeDB, 'volume_get', return_value=EMCVMAXCommonData.test_source_volume) @mock.patch.object( EMCVMAXFast, 'get_pool_associated_to_policy', return_value=1) @mock.patch.object( EMCVMAXUtils, 'get_volume_meta_head', return_value=[EMCVMAXCommonData.test_volume]) @mock.patch.object( EMCVMAXUtils, 'get_meta_members_capacity_in_bit', return_value=[1234567, 7654321]) @mock.patch.object( EMCVMAXCommon, '_get_pool_and_storage_system', return_value=(None, EMCVMAXCommonData.storage_system)) def test_create_clone_fast_failed(self, mock_volume_type, mock_vol, mock_policy, mock_meta, mock_size, mock_pool): self.data.test_volume['volume_name'] = ""vmax-1234567"" self.driver.common._modify_and_get_composite_volume_instance = ( mock.Mock(return_value=(1L, None))) self.assertRaises(exception.VolumeBackendAPIException, self.driver.create_cloned_volume, self.data.test_volume, EMCVMAXCommonData.test_source_volume)",30,76
openstack%2Fneutron~master~I7874493f4a22487abd0930765fbcfbc5780e4be9,openstack/neutron,master,I7874493f4a22487abd0930765fbcfbc5780e4be9,"Revert ""Move contrib directory to base test directory""",ABANDONED,2014-12-19 08:48:44.000000000,2014-12-21 06:29:49.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 9453}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10206}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-19 08:48:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ee8186540c58f9a9a34bb15e06d38bdeefabce1f', 'message': 'Revert ""Move contrib directory to base test directory""\n\nThis reverts commit 7bc56f030c8bf15336a61ac0d3a513059a00a902.\n\npbr is unable to handle the symlink, which prevents setup.py being able to build a package.\n\nChange-Id: I7874493f4a22487abd0930765fbcfbc5780e4be9\ncloses-bug: 1404115\n'}, {'number': 2, 'created': '2014-12-19 08:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2031596f8e6e27e9cdf2af6eef92c758e295a017', 'message': 'Revert ""Move contrib directory to base test directory""\n\nThis reverts commit 7bc56f030c8bf15336a61ac0d3a513059a00a902.\n\npbr is unable to handle the symlink, which prevents setup.py being able to build a package.\n\nChange-Id: I7874493f4a22487abd0930765fbcfbc5780e4be9\ncloses-bug: 1404115\n'}, {'number': 3, 'created': '2014-12-19 19:55:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/88a90a6e4c95f1af34f337653688141764f00480', 'message': 'Revert ""Move contrib directory to base test directory""\n\nThis reverts commit 7bc56f030c8bf15336a61ac0d3a513059a00a902.\n\npbr is unable to handle the symlink, which prevents setup.py being able to build a package.\n\nChange-Id: I7874493f4a22487abd0930765fbcfbc5780e4be9\ncloses-bug: 1404115\n'}, {'number': 4, 'created': '2014-12-20 05:29:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a58da1c42306e295bc2a3ee02659b121599f4c2a', 'message': 'Revert ""Move contrib directory to base test directory""\n\nThis reverts commit 7bc56f030c8bf15336a61ac0d3a513059a00a902.\n\npbr is unable to handle the symlink, which prevents setup.py being able to build a package.\n\nChange-Id: I7874493f4a22487abd0930765fbcfbc5780e4be9\ncloses-bug: 1404115\n'}, {'number': 5, 'created': '2014-12-20 15:21:51.000000000', 'files': ['neutron/tests/functional/contrib/filters.template', 'neutron/tests/functional/contrib/gate_hook.sh', 'neutron/tests/functional/contrib/post_test_hook.sh', 'neutron/tests/functional/contrib/README', 'neutron/tests/functional/contrib'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6bc0651d6a7cae6f0771b34fecfdd41407f7e436', 'message': 'Revert ""Move contrib directory to base test directory""\n\nThis reverts commit 7bc56f030c8bf15336a61ac0d3a513059a00a902.\n\npbr is unable to handle the symlink, which prevents setup.py being able to\nbuild a package.\n\nChange-Id: I7874493f4a22487abd0930765fbcfbc5780e4be9\ncloses-bug: 1404115\n'}]",0,143017,6bc0651d6a7cae6f0771b34fecfdd41407f7e436,111,19,5,9453,,,0,"Revert ""Move contrib directory to base test directory""

This reverts commit 7bc56f030c8bf15336a61ac0d3a513059a00a902.

pbr is unable to handle the symlink, which prevents setup.py being able to
build a package.

Change-Id: I7874493f4a22487abd0930765fbcfbc5780e4be9
closes-bug: 1404115
",git fetch https://review.opendev.org/openstack/neutron refs/changes/17/143017/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/contrib/filters.template', 'neutron/tests/functional/contrib/gate_hook.sh', 'neutron/tests/functional/contrib/post_test_hook.sh', 'neutron/tests/functional/contrib/README', 'neutron/tests/functional/contrib']",5,ee8186540c58f9a9a34bb15e06d38bdeefabce1f,move-contrib,,../contrib/,0,1
openstack%2Ftaskflow~master~I01c83f13186e4be9fa28c32e34e907bb133e8fb3,openstack/taskflow,master,I01c83f13186e4be9fa28c32e34e907bb133e8fb3,Get event/notification sending working correctly,MERGED,2014-11-15 02:59:36.000000000,2014-12-21 06:19:09.000000000,2014-12-21 06:19:09.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-11-15 02:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2b58d8e996476165309b433a378dd4129bd05408', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 2, 'created': '2014-11-15 03:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0ef95e516825f7db5ae33cbfb4a7f6f7d7ff367a', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 3, 'created': '2014-11-15 12:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8333f7c06c187a698baacf66b598dfc5399b37a1', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 4, 'created': '2014-11-17 21:06:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3065b4f55c95c19b07ea4bafb19c04a1d4c1ff52', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 5, 'created': '2014-11-19 19:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1633f4a20979443895cc8c5336e8f3dbd540cec1', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 6, 'created': '2014-12-06 23:05:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6e418bb97b1ddc2fbd8bc6c45607d520319f45e2', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 7, 'created': '2014-12-06 23:07:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2bcef3f07a525aa912c2f65478b4182e6d858727', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 8, 'created': '2014-12-07 00:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/02e350e6b8ebc3c561991d12b6efe40aa85276e8', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 9, 'created': '2014-12-07 00:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/440cbee9239209add5f179eebdeb9babc1f68f7b', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 10, 'created': '2014-12-13 07:08:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c500f8b358b3d630d4894fb5f33748e85c65f5eb', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 11, 'created': '2014-12-14 05:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a43252e2e1ffdad812493bd4b76f651cff887b26', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 12, 'created': '2014-12-14 05:47:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/bfaa3a442948bf7fcb6d9d470db431333edf61b2', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 13, 'created': '2014-12-14 05:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ce25a7f0861fc92e810ef7798a56ed3518c10e5a', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 14, 'created': '2014-12-14 06:03:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/95ee15d1d15fb0d61d9e108801d7ea83f2e1ca85', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 15, 'created': '2014-12-14 19:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/860bdf1f35ae10ac0ec725ac185f4325bc41152f', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 16, 'created': '2014-12-15 07:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/99a269c5271baebfd6292a456d105543bdb445bc', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 17, 'created': '2014-12-18 22:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/677ff43ce6e9f79021fa8abb21e26390dc56afe6', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 18, 'created': '2014-12-20 04:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b3d984223e6dbb6d13a63372df9e98b25a7bd749', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 19, 'created': '2014-12-20 04:53:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e3780d1062aa249bb8ddb8df9ce7f25c2f7e8b76', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 20, 'created': '2014-12-20 06:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3429e6737015cb05db870fd1e5a34f5cb4e1c21c', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 21, 'created': '2014-12-20 07:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e1a92d64c9eeb9b54676e80e0a5fb2d6035a40ca', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 22, 'created': '2014-12-20 07:34:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/537923b823bdd276401307693c43d53b73e57af7', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 23, 'created': '2014-12-20 08:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/11cd57f09c82c2a6d5bef5a3e7174898589ab4e4', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 24, 'created': '2014-12-20 08:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a3a43be7fa5061d021c60472de2ef6597d4e81fa', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 25, 'created': '2014-12-20 09:13:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/adddc08fdd08747e0dcc9c8fdfb4fc98c79122c1', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 26, 'created': '2014-12-20 17:53:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e581d4510bd571238308ed1fb6d07da5499fb131', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 27, 'created': '2014-12-21 00:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a3dfce64851512ace60c1d792b29caffe5b241b5', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 28, 'created': '2014-12-21 01:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e11e234ac646ea5de9f9a98e2a0cc3c349d0d443', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}, {'number': 29, 'created': '2014-12-21 03:49:11.000000000', 'files': ['taskflow/engines/action_engine/engine.py', 'taskflow/utils/lock_utils.py', 'doc/source/examples.rst', 'taskflow/examples/alphabet_soup.py', 'taskflow/engines/action_engine/executor.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e841b5a6c23588fa7058a4b6aa58370d57590200', 'message': 'Get event/notification sending working correctly\n\nIn order to support tasks notifications and progress\nupdates we need to establish a channel & proxy by which\nthose events can be sent from the process executing and\nproducing those events and the originating process that\nrequested that task to be executed.\n\nThis review adds on such a proxy and adjusts a cloned tasks\nnotification callbacks to place messages on a queue that will\nbe picked up by a thread in the originating process for dispatch\nto the original callbacks that were registered with the non-cloned\ntask (therefore making the original callbacks appear to be called\nas they are supposed to be).\n\nPart of blueprint process-executor\n\nChange-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3\n'}]",0,134690,e841b5a6c23588fa7058a4b6aa58370d57590200,64,2,29,1297,,,0,"Get event/notification sending working correctly

In order to support tasks notifications and progress
updates we need to establish a channel & proxy by which
those events can be sent from the process executing and
producing those events and the originating process that
requested that task to be executed.

This review adds on such a proxy and adjusts a cloned tasks
notification callbacks to place messages on a queue that will
be picked up by a thread in the originating process for dispatch
to the original callbacks that were registered with the non-cloned
task (therefore making the original callbacks appear to be called
as they are supposed to be).

Part of blueprint process-executor

Change-Id: I01c83f13186e4be9fa28c32e34e907bb133e8fb3
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/90/134690/10 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/action_engine/engine.py', 'taskflow/examples/alphabet_soup.py', 'taskflow/engines/action_engine/executor.py']",3,2b58d8e996476165309b433a378dd4129bd05408,bp/process-executor,"import functoolsimport multiprocessing import os import pickle import threading from oslo.utils import excutils from oslo.utils import timeutilsfrom six.moves import queue as compat_queuefrom taskflow.types import timing# See http://bugs.python.org/issue1457119 for why this is so complex... _PICKLE_ERRORS = [pickle.PickleError, TypeError] try: import cPickle as _cPickle _PICKLE_ERRORS.append(_cPickle.PickleError) except ImportError: pass _PICKLE_ERRORS = tuple(_PICKLE_ERRORS)class _EventSender(object): """"""Sends event information from a child worker process."""""" _MSG_VERSION = (1, 0, 0) def __init__(self, queue, event): self._queue = queue self._event = event self._pid = None def __call__(self, task, event_data, *args, **kwargs): if self._pid is None: self._pid = os.getpid() message = { 'created_on': timeutils.utcnow(), 'sender': { 'pid': self._pid, }, 'event': self._event, 'body': { 'args': args, 'kwargs': kwargs, }, # Added incase we ever change this and need to retain some # level of backwards compatibility... 'version': self._MSG_VERSION, } try: self._queue.put(message) except _PICKLE_ERRORS: LOG.warn(""Failed serializing message %s"", message, exc_info=True) except (IOError, EOFError): LOG.warn(""Failed sending message %s"", message, exc_info=True) class _EventTarget(object): """"""An immutable helper object that represents a target of an event."""""" __slots__ = [""future"", ""task"", ""queue"", ""lock""] def __init__(self, future, task, queue): self.future = future self.task = task self.queue = queue # This lock is used to ensure there is linearity of events if this # target is processed by many threads at once, which is quite possible # if the dispatcher is dispatching this target and a secondary thread # tries to finish the targets future (which causes the queue to be # drained)... self.lock = threading.Lock() class _EventDispatcher(object): """"""Dispatches event information received from child worker processes."""""" # When the run() method is busy (typically in a thread) we want to set # these so that the thread can know how long to sleep when there is no # active work to dispatch (when there is active targets, there queues # will have amount/count of items removed before returning to work on # the next target...) _SPIN_PERIODICITY = 0.01 _SPIN_DISPATCH_AMOUNT = 1 def __init__(self, periodicity=None): self._dead = tu.Event() if periodicity is None: periodicity = self._SPIN_PERIODICITY self._periodicity = periodicity self._targets = set() self._lock = threading.Lock() def register(self, target): with self._lock: self._targets.add(target) def _dispatch_until_empty(self, target, limit=None): count = 0 while True: if limit is not None and count >= limit: break try: message = target.queue.get_nowait() except compat_queue.Empty: break else: self._dispatch(target.task, message) count += 1 def deregister(self, target): known_target = None with self._lock: try: self._targets.remove(target) except KeyError: pass else: known_target = target if known_target is not None: # NOTE(harlowja): suck off any further messages that this task # may have published before returning, so that we ensure this task # has gotten all its published messages... with known_target.lock: self._dispatch_until_empty(known_target) def reset(self): # NOTE(harlowja): should not be called in a concurrent situation, # call only when the run loop is not running (or not running in a # different thread), and after the owning executor has shutdown and # is not accepting any new submissions... while self._targets: self._dispatch_until_empty(self._targets.pop()) self._dead.clear() def interrupt(self): self._dead.set() def _dispatch(self, task, message): LOG.debug(""Dispatching message %s to task '%s'"", message, task) args = message['body'].get('args', []) kwargs = message['body'].get('kwargs', {}) task.trigger(message['event'], *args, **kwargs) def _dispatch_iter(self, targets): # A generator that yields at certain points to allow the main run() # method to use this to dispatch in iterations (and also allows it # to check if it has been stopped between iterations). for target in targets: if target not in self._targets: # Must of been removed... continue gotten = target.lock.acquire(False) if not gotten: # Someone else must be using it (or deregistering it), # leave it alone... continue try: # NOTE(harlowja): Limits are used here to avoid one # task unequally dispatching, this forces round-robin # like behavior... self._dispatch_until_empty(target, limit=self._SPIN_DISPATCH_AMOUNT) finally: target.lock.release() yield target def run(self): w = timing.StopWatch(duration=self._periodicity) while not self._dead.is_set(): w.restart() with self._lock: targets = self._targets.copy() for _target in self._dispatch_iter(targets): if self._dead.is_set(): break leftover = w.leftover() if leftover: self._dead.wait(leftover) and forth) and that the bound handlers (for progress updating in particular) are proxied correctly from that external process to the one that is alive in the parent process to ensure that callbacks registered in the parent are executed on events in the child. def __init__(self, executor=None, max_workers=None, dispatch_periodicity=None): super(ParallelProcessTaskExecutor, self).__init__( executor=executor, max_workers=max_workers) self._manager = multiprocessing.Manager() self._dispatcher = _EventDispatcher(periodicity=dispatch_periodicity) self._worker = None def start(self): super(ParallelProcessTaskExecutor, self).start() if not tu.is_alive(self._worker): self._dispatcher.reset() self._worker = tu.daemon_thread(target=self._dispatcher.run) self._worker.start() def stop(self): super(ParallelProcessTaskExecutor, self).stop() self._dispatcher.interrupt() if tu.is_alive(self._worker): self._worker.join() self._worker = None self._dispatcher.reset() def _replicate_task(self, task, progress_callback=None): clone = task.copy(retain_listeners=False) queue = self._manager.Queue() proxies = {} for (event_name, listeners) in six.iteritems(task.listeners): if listeners: proxies[event_name] = _EventSender(queue, event_name) if (progress_callback is not None and _UPDATE_PROGRESS not in proxies): proxies[_UPDATE_PROGRESS] = _EventSender(queue, _UPDATE_PROGRESS) for (event_name, proxy) in six.iteritems(proxies): clone.bind(event_name, proxy) return (clone, queue) NOTE(harlowja): Adjust all events to be proxies instead since we want those callbacks to be activated in this process, not in the child, also since typically callbacks are functors (or callables) we can not pickle those in the first place... To make sure people understand how this works, the following is a lengthy description of what is going on here, read at will: So to ensure that we are proxying task triggered events that occur in the executed subprocess (which will be created and used by the thing using the multiprocessing based executor) we need to establish a link between that process and this process that ensures that when a event is triggered in that task in that process that a corresponding event is triggered on the original task that was requested to be ran in this process. To accomplish this we have to create a copy of the task (without any listeners) and then reattach a new set of listeners that will now instead of calling the desired listeners just place messages for this process (a dispatcher thread that is created in this class) to dispatch to the original task (using a per task queue that is used and associated to know which task to proxy back too, since it is possible that there many be *many* subprocess running at the same time, each running a different task). Once the subprocess task has finished execution, the executor will then trigger a callback (``on_done`` in this case) that will remove the task + queue from the dispatcher (which will stop any further proxying back to the original task). progress_callback = kwargs.pop('progress_callback', None) if progress_callback is not None: binder = functools.partial(task.bind, _UPDATE_PROGRESS, progress_callback) unbinder = functools.partial(task.unbind, _UPDATE_PROGRESS, progress_callback) else: binder = unbinder = lambda: None clone, queue = self._replicate_task( task, progress_callback=progress_callback) # Helper function called when future is done (or to do submission # failure cleanup), we use it to remove the proxy and to ensure any # queued messages are proxied as expected. def on_done(fut): self._dispatcher.deregister(target) unbinder() # Ensure the target task (not the clone) is ready and able to receive # dispatched messages (and start the dispatching process by # registering) with the dispatcher. binder() try: fut = super(ParallelProcessTaskExecutor, self)._submit_task( func, clone, *args, **kwargs) except RuntimeError: with excutils.save_and_reraise_exception(): unbinder() # This will trigger the proxying to begin... target = _EventTarget(fut, task, queue) self._dispatcher.register(target) fut.add_done_callback(on_done)"," and forth). NOTE(harlowja): task callbacks/notifications will not currently work (they will be removed before being sent to the target process for execution). kwargs.pop('progress_callback', None) clone = task.copy(retain_listeners=False) fut = super(ParallelProcessTaskExecutor, self)._submit_task( func, clone, *args, **kwargs)",379,8
openstack%2Fneutron~master~I4a15d0ac422457d2286d4b24d9f5067047e81563,openstack/neutron,master,I4a15d0ac422457d2286d4b24d9f5067047e81563,"Minor lbaasv2 things from the feature branch, needed in neutron",MERGED,2014-12-13 02:21:37.000000000,2014-12-21 05:27:18.000000000,2014-12-21 05:27:16.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6951}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-13 02:21:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9455864f17f70c6751753d55fdf001410ca8457f', 'message': 'Minor neutron.conf fix from feature branch until config is moved\n\nChange-Id: I4a15d0ac422457d2286d4b24d9f5067047e81563\nPartially-Implements: blueprint services-split\n'}, {'number': 2, 'created': '2014-12-13 02:37:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/90773bb6e49afeb4f5b57eed4830ce2719e29a91', 'message': 'Minor lbaasv2 things from the feature branch, needed in neutron\n\n- Minor neutron.conf fix from feature branch until config is moved\n- Some extra constants for extension\n\nChange-Id: I4a15d0ac422457d2286d4b24d9f5067047e81563\nPartially-Implements: blueprint services-split\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\n'}, {'number': 3, 'created': '2014-12-13 02:58:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/74a94544894e592b77a26ebfce058aa25aadb51a', 'message': 'Minor lbaasv2 things from the feature branch, needed in neutron\n\n- Minor neutron.conf fix from feature branch until config is moved\n- Some extra constants for extension\n- Jinja template entry in services.conf\n\nChange-Id: I4a15d0ac422457d2286d4b24d9f5067047e81563\nPartially-Implements: blueprint services-split\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\n'}, {'number': 4, 'created': '2014-12-14 05:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0fb9c7e4472aaf2f031d43d5d91f0a3f3f828970', 'message': 'Minor lbaasv2 things from the feature branch, needed in neutron\n\n- Minor neutron.conf fix from feature branch until config is moved\n- Some extra constants for extension\n- Jinja template entry in services.conf\n\nChange-Id: I4a15d0ac422457d2286d4b24d9f5067047e81563\nPartially-Implements: blueprint services-split\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\n'}, {'number': 5, 'created': '2014-12-15 19:55:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/507bc80c483552a7976cdcdc3448f06b09faac66', 'message': 'Minor lbaasv2 things from the feature branch, needed in neutron\n\n- Minor neutron.conf fix from feature branch until config is moved\n- Some extra constants for extension\n- Jinja template entry in services.conf\n\nChange-Id: I4a15d0ac422457d2286d4b24d9f5067047e81563\nPartially-Implements: blueprint services-split\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\n'}, {'number': 6, 'created': '2014-12-15 20:00:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c2a64bb14d9113b6c6a0d3b10de062ea9b42593e', 'message': 'Minor lbaasv2 things from the feature branch, needed in neutron\n\n- Minor neutron.conf fix from feature branch until config is moved\n- Some extra constants for extension\n- Jinja template entry in services.conf\n\nChange-Id: I4a15d0ac422457d2286d4b24d9f5067047e81563\nPartially-Implements: blueprint services-split\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\n'}, {'number': 7, 'created': '2014-12-17 00:33:03.000000000', 'files': ['neutron/plugins/common/constants.py', 'etc/neutron.conf', 'etc/services.conf'], 'web_link': 'https://opendev.org/openstack/neutron/commit/96c34a780fd3f504ea1bef671cc3ed1d9f6bc2ef', 'message': 'Minor lbaasv2 things from the feature branch, needed in neutron\n\n- Minor neutron.conf fix from feature branch until config is moved\n- Some extra constants for extension\n- Jinja template entry in services.conf\n\nChange-Id: I4a15d0ac422457d2286d4b24d9f5067047e81563\nPartially-Implements: blueprint services-split\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\n'}]",7,141533,96c34a780fd3f504ea1bef671cc3ed1d9f6bc2ef,147,22,7,10980,,,0,"Minor lbaasv2 things from the feature branch, needed in neutron

- Minor neutron.conf fix from feature branch until config is moved
- Some extra constants for extension
- Jinja template entry in services.conf

Change-Id: I4a15d0ac422457d2286d4b24d9f5067047e81563
Partially-Implements: blueprint services-split
Co-Authored-By: Brandon Logan <brandon.logan@rackspace.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/33/141533/3 && git format-patch -1 --stdout FETCH_HEAD,['etc/neutron.conf'],1,9455864f17f70c6751753d55fdf001410ca8457f,bp/services-split,# service_provider = LOADBALANCERV2:LoggingNoop:neutron_lbaas.services.loadbalancer.drivers.logging_noop.driver.LoggingNoopLoadBalancerDriver:default,# service_provider = LOADBALANCER:LoggingNoop:neutron_lbaas.services.loadbalancer.drivers.logging_noop.driver.LoggingNoopLoadBalancerDriver:default,1,1
openstack%2Foslo.messaging~master~I53790e5492ebf026e0b331ecb3c294da89603540,openstack/oslo.messaging,master,I53790e5492ebf026e0b331ecb3c294da89603540,Enable IPv6-support in libzmq by default,MERGED,2014-12-01 14:24:22.000000000,2014-12-21 03:48:37.000000000,2014-12-21 03:48:36.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 7805}, {'_account_id': 10068}, {'_account_id': 13290}, {'_account_id': 13686}]","[{'number': 1, 'created': '2014-12-01 14:24:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/97a5980c4a730aa5da83de9f6a4aa0b8b2c5d5d8', 'message': 'Add ability to configure use IPv6 for socket operations.\n\nNote that this is not a dual stacked implementation and this should be\nimrpoved further so it can be enabled by default and work for all\nconfigurations.\n\nWhat this does though is enable the use of ZMQ for installations with a\nIPv6-only OpenStack core.\n\nChange-Id: I53790e5492ebf026e0b331ecb3c294da89603540\nCloses-Bug: 1389137\n'}, {'number': 2, 'created': '2014-12-01 15:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/4346edbb7d26f8cebc0ac6061df34b9a27b423d3', 'message': 'Add ability to configure use IPv6 for socket operations\n\nNote that this is not a dual stacked implementation and this should be\nimrpoved further so it can be enabled by default and work for all\nconfigurations.\n\nWhat this does though is enable the use of ZMQ for installations with a\nIPv6-only OpenStack core.\n\nChange-Id: I53790e5492ebf026e0b331ecb3c294da89603540\nCloses-Bug: 1389137\n'}, {'number': 3, 'created': '2014-12-08 08:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/e769444cd4dc888a06692b87f5c25837c9abc6c4', 'message': 'Enable IPv6-support in libzmq by default\n\nChange-Id: I53790e5492ebf026e0b331ecb3c294da89603540\nCloses-Bug: 1389137\n'}, {'number': 4, 'created': '2014-12-19 08:42:07.000000000', 'files': ['oslo/messaging/_drivers/impl_zmq.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c40ba040a6bd5a69b31b7093702444a07bf9be57', 'message': 'Enable IPv6-support in libzmq by default\n\nChange-Id: I53790e5492ebf026e0b331ecb3c294da89603540\nCloses-Bug: 1389137\n'}]",3,138075,c40ba040a6bd5a69b31b7093702444a07bf9be57,28,8,4,13686,,,0,"Enable IPv6-support in libzmq by default

Change-Id: I53790e5492ebf026e0b331ecb3c294da89603540
Closes-Bug: 1389137
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/75/138075/4 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/impl_zmq.py'],1,97a5980c4a730aa5da83de9f6a4aa0b8b2c5d5d8,bug/1389137," cfg.BoolOpt('rpc_zmq_use_ipv6', default=False, help='Use IPv6 address when binding sockets'), if (CONF.rpc_zmq_use_ipv6): self.sock.ipv6 = True ",,6,0
openstack%2Foslo.concurrency~master~Ic7c2a0111c311e7feeddd7baff0ad7ec636542a4,openstack/oslo.concurrency,master,Ic7c2a0111c311e7feeddd7baff0ad7ec636542a4,Report import warnings where the import occurs,MERGED,2014-12-11 18:51:02.000000000,2014-12-21 03:44:53.000000000,2014-12-21 03:44:52.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 5638}, {'_account_id': 6601}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-12-11 18:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/0a991f6dc557f51ac85eedf90c9a67eaa1b13f41', 'message': 'Report import warnings 2 levels up the stack\n\nRaise the number of levels we look up the stack to report where the\nimport is happening.\n\nChange-Id: Ic7c2a0111c311e7feeddd7baff0ad7ec636542a4\n'}, {'number': 2, 'created': '2014-12-11 19:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/2a48bfd23a1380880afef29bce8030ae78b43ecd', 'message': 'Report import warnings 2 levels up the stack\n\nRaise the number of levels we look up the stack to report where the\nimport is happening.\n\nChange-Id: Ic7c2a0111c311e7feeddd7baff0ad7ec636542a4\n'}, {'number': 3, 'created': '2014-12-11 19:20:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/a4ff0136879dea93f56abd6161b1e46a6a74af23', 'message': 'Report import warnings where the import occurs\n\nRaise the number of levels we look up the stack to report where the\nimport is happening.\n\nChange-Id: Ic7c2a0111c311e7feeddd7baff0ad7ec636542a4\n'}, {'number': 4, 'created': '2014-12-12 19:11:35.000000000', 'files': ['tests/test_warning.py', 'oslo/concurrency/__init__.py'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/093ed4f9abbc850ef51302e5c569629bb11e2a5b', 'message': 'Report import warnings where the import occurs\n\nRaise the number of levels we look up the stack to report where the\nimport is happening.\n\nChange-Id: Ic7c2a0111c311e7feeddd7baff0ad7ec636542a4\n'}]",0,141125,093ed4f9abbc850ef51302e5c569629bb11e2a5b,16,6,4,2472,,,0,"Report import warnings where the import occurs

Raise the number of levels we look up the stack to report where the
import is happening.

Change-Id: Ic7c2a0111c311e7feeddd7baff0ad7ec636542a4
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/25/141125/4 && git format-patch -1 --stdout FETCH_HEAD,['oslo/concurrency/__init__.py'],1,0a991f6dc557f51ac85eedf90c9a67eaa1b13f41,more-stack-levels-in-warning," stacklevel=2,"," stacklevel=1,",1,1
openstack%2Foslo.messaging~master~I1482fd70abbf69f4e2994597c5e95d91fecb815e,openstack/oslo.messaging,master,I1482fd70abbf69f4e2994597c5e95d91fecb815e,Add a thread + futures executor based executor,MERGED,2014-02-04 05:28:56.000000000,2014-12-21 03:44:33.000000000,2014-12-21 03:44:32.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 7536}, {'_account_id': 7763}, {'_account_id': 8415}, {'_account_id': 8871}, {'_account_id': 9107}, {'_account_id': 11279}, {'_account_id': 12000}, {'_account_id': 13290}]","[{'number': 1, 'created': '2014-02-04 05:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c26459d01b174ece06aaf884c23a487608ba4c70', 'message': 'Start adding a futures executor based executor\n\nThe concurrent.futures module seems to be the way\nthat async activities will be done in the future,\nso we should try to work on getting to that future\nby using more futures.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 2, 'created': '2014-02-04 05:37:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/25a728ec20000ce92b8308e266eb34c8354da661', 'message': 'Start adding a futures executor based executor\n\nThe concurrent.futures module seems to be the way\nthat async activities will be done in the future,\nso we should try to work on getting to that future\nby using more futures.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 3, 'created': '2014-03-10 23:23:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/e44d07018e2e55cdea42756b5d3f75a068d7daae', 'message': 'Start adding a futures executor based executor\n\nThe concurrent.futures module seems to be the way\nthat async activities will be done in the future,\nso we should try to work on getting to that future\nby using more futures.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 4, 'created': '2014-03-11 01:05:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/68db5bdbbdcc22268b22c5071eea5eaa2750b367', 'message': 'Start adding a futures executor based executor\n\nThe concurrent.futures module seems to be the way\nthat async activities will be done in the future,\nso we should try to work on getting to that future\nby using more futures.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 5, 'created': '2014-03-11 01:06:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/dfff94316316bb468339103b0d386aa2ec23c947', 'message': 'Start adding a futures executor based executor\n\nThe concurrent.futures module seems to be the way\nthat async activities will be done in the future,\nso we should try to work on getting to that future\nby using more futures.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 6, 'created': '2014-03-11 01:53:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/dad8190b220c83deeb204a39d90905a237e922cd', 'message': 'Start adding a futures executor based executor\n\nThe concurrent.futures module seems to be the way\nthat async activities will be done in the future,\nso we should try to work on getting to that future\nby using more futures.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 7, 'created': '2014-03-11 15:42:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/3c6694ab2b54ff192daaa19ecb1735d32d5930a0', 'message': 'Add a thread + futures executor based executor\n\nThe concurrent.futures module seems to be the way\nthat async activities will be done in the future,\nso we should try to work on getting to that future\nby using more futures. To enable this, add a thread\npool based executor which will process incoming\nmessages using the pool.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 8, 'created': '2014-03-18 15:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/d10ff5dc92c01bd77b4596f2a678864dcb6d9928', 'message': 'Add a thread + futures executor based executor\n\nThe concurrent.futures module is one of the ways\nthat async activities can be done in the future,\nso we should try to work on getting to that future\nby using more futures. To enable this, add a thread\npool based executor which will process incoming\nmessages using the pool.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 9, 'created': '2014-03-20 23:09:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c07467f99fd0d4bb54668364f434253391ea8276', 'message': 'Add a thread + futures executor based executor\n\nThe concurrent.futures module is one of the ways\nthat async activities can be done in the future,\nso we should try to work on getting to that future\nby using more futures. To enable this, add a thread\npool based executor which will process incoming\nmessages using the pool.\n\nBegin adding according docs as well for the different\ntypes of executors that are available.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 10, 'created': '2014-07-01 23:42:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/d498493b21f3cd1f0145de902ef4e5b99b75d86e', 'message': 'Add a thread + futures executor based executor\n\nThe concurrent.futures module is one of the ways\nthat async activities can be done in the future,\nso we should try to work on getting to that future\nby using more futures. To enable this, add a thread\npool based executor which will process incoming\nmessages using the pool.\n\nBegin adding according docs as well for the different\ntypes of executors that are available.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 11, 'created': '2014-07-02 00:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/fe1ac2d0bcfeb0aa70d821957f9408d81ea4a4da', 'message': 'Add a thread + futures executor based executor\n\nThe concurrent.futures module is one of the ways\nthat async activities can be done in the future,\nso we should try to work on getting to that future\nby using more futures. To enable this, add a thread\npool based executor which will process incoming\nmessages using the pool.\n\nBegin adding according docs as well for the different\ntypes of executors that are available.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 12, 'created': '2014-07-03 01:42:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/6c17f18fce3fceed2199094264d6b35708fbe1b5', 'message': 'Add a thread + futures executor based executor\n\nThe concurrent.futures module is one of the ways\nthat async activities can be done in the future,\nso we should try to work on getting to that future\nby using more futures. To enable this, add a thread\npool based executor which will process incoming\nmessages using the pool.\n\nBegin adding according docs as well for the different\ntypes of executors that are available.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 13, 'created': '2014-07-05 01:15:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/efc117d98b9a602b5e36444e3c8c0269057793d4', 'message': 'Add a thread + futures executor based executor\n\nThe concurrent.futures module is one of the ways\nthat async activities can be done in the future,\nso we should try to work on getting to that future\nby using more futures. To enable this, add a thread\npool based executor which will process incoming\nmessages using the pool.\n\nBegin adding according docs as well for the different\ntypes of executors that are available.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 14, 'created': '2014-07-05 16:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/9156997c0e397e0f5184f6349eca8d3cf1f080cb', 'message': 'Add a thread + futures executor based executor\n\nThe concurrent.futures module is one of the ways\nthat async activities can be done in the future,\nso we should try to work on getting to that future\nby using more futures. To enable this, add a thread\npool based executor which will process incoming\nmessages using the pool.\n\nBegin adding according docs as well for the different\ntypes of executors that are available.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 15, 'created': '2014-07-05 17:38:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/ffcf5bbfd2a21325711c6b1bdb7ba652bdd93f50', 'message': 'Add a thread + futures executor based executor\n\nThe concurrent.futures module is one of the ways\nthat async activities can be done in the future,\nso we should try to work on getting to that future\nby using more futures. To enable this, add a thread\npool based executor which will process incoming\nmessages using the pool.\n\nBegin adding according docs as well for the different\ntypes of executors that are available.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 16, 'created': '2014-09-22 02:14:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/f031f0e03e65e1f1c4c15f8bd9617d813ddcf5c9', 'message': 'Add a thread + futures executor based executor\n\nThe concurrent.futures module is one of the ways\nthat async activities can be done in the future,\nso we should try to work on getting to that future\nby using more futures. To enable this, add a thread\npool based executor which will process incoming\nmessages using the pool.\n\nBegin adding according docs as well for the different\ntypes of executors that are available.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 17, 'created': '2014-09-22 02:19:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/949b74f3fcd7782733d8339711dc741338f5b445', 'message': 'Add a thread + futures executor based executor\n\nThe concurrent.futures module is one of the ways\nthat async activities can be done in the future,\nso we should try to work on getting to that future\nby using more futures. To enable this (as well as\nto enable getting off eventlet), add a thread pool\nbased executor which will process incoming messages\nusing the pool.\n\nAlso begins adding according docs as well for the\ndifferent types of executors that are available.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 18, 'created': '2014-09-26 21:50:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/73d84efbdbe2e178b0b3b91e5e419ca984b992e2', 'message': 'Add a thread + futures executor based executor\n\nThe concurrent.futures module is one of the ways\nthat async activities can be done in the future,\nso we should try to work on getting to that future\nby using more futures. To enable this (as well as\nto enable getting off eventlet), add a thread pool\nbased executor which will process incoming messages\nusing the pool.\n\nAlso begins adding according docs as well for the\ndifferent types of executors that are available.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 19, 'created': '2014-11-14 21:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/05f9618cf6f64360b2daab8d25ca69ee45919de6', 'message': 'Add a thread + futures executor based executor\n\nThe concurrent.futures module is one of the ways\nthat async activities can be done in the future,\nso we should try to work on getting to that future\nby using more futures. To enable this (as well as\nto enable getting off eventlet), add a thread pool\nbased executor which will process incoming messages\nusing the pool.\n\nAlso begins adding according docs as well for the\ndifferent types of executors that are available.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 20, 'created': '2014-12-06 00:05:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/d7b7a6ee074c833bf465c1d6081df33cb5e8ef6d', 'message': 'Add a thread + futures executor based executor\n\nThe concurrent.futures module is one of the ways\nthat async activities can be done in the future,\nso we should try to work on getting to that future\nby using more futures. To enable this (as well as\nto enable getting off eventlet), add a thread pool\nbased executor which will process incoming messages\nusing the pool.\n\nAlso begins adding according docs as well for the\ndifferent types of executors that are available.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 21, 'created': '2014-12-10 20:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/0d63b6c4adf6defa822a17c6ceab65faa1bcf12d', 'message': 'Add a thread + futures executor based executor\n\nThe concurrent.futures module is one of the ways\nthat async activities can be done in the future,\nso we should try to work on getting to that future\nby using more futures. To enable this (as well as\nto enable getting off eventlet), add a thread pool\nbased executor which will process incoming messages\nusing the pool.\n\nAlso begins adding according docs as well for the\ndifferent types of executors that are available.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 22, 'created': '2014-12-18 00:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c45d48a8262f31531650a1fa3289c3f8c64faf13', 'message': 'Add a thread + futures executor based executor\n\nThe concurrent.futures module is one of the ways\nthat async activities can be done in the future,\nso we should try to work on getting to that future\nby using more futures. To enable this (as well as\nto enable getting off eventlet), add a thread pool\nbased executor which will process incoming messages\nusing the pool.\n\nAlso begins adding according docs as well for the\ndifferent types of executors that are available.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}, {'number': 23, 'created': '2014-12-19 07:50:05.000000000', 'files': ['doc/source/index.rst', 'requirements.txt', 'oslo/messaging/_cmd/zmq_receiver.py', 'oslo/messaging/_executors/impl_eventlet.py', 'doc/source/executors.rst', 'oslo/messaging/_executors/impl_thread.py', 'tests/executors/test_executor.py', 'oslo/messaging/_drivers/impl_zmq.py', 'oslo/messaging/opts.py', 'oslo/messaging/_executors/base.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/372bc4947e0aecca7df4f4f22a5f52080dc13ac1', 'message': 'Add a thread + futures executor based executor\n\nThe concurrent.futures module is one of the ways\nthat async activities can be done in the future,\nso we should try to work on getting to that future\nby using more futures. To enable this (as well as\nto enable getting off eventlet), add a thread pool\nbased executor which will process incoming messages\nusing the pool.\n\nAlso begins adding according docs as well for the\ndifferent types of executors that are available.\n\nChange-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e\n'}]",36,70914,372bc4947e0aecca7df4f4f22a5f52080dc13ac1,150,13,23,1297,,,0,"Add a thread + futures executor based executor

The concurrent.futures module is one of the ways
that async activities can be done in the future,
so we should try to work on getting to that future
by using more futures. To enable this (as well as
to enable getting off eventlet), add a thread pool
based executor which will process incoming messages
using the pool.

Also begins adding according docs as well for the
different types of executors that are available.

Change-Id: I1482fd70abbf69f4e2994597c5e95d91fecb815e
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/14/70914/23 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'oslo/messaging/_executors/impl_thread.py']",2,c26459d01b174ece06aaf884c23a487608ba4c70,thread-exec-future,"# -*- coding: utf-8 -*- # vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright (C) 2012 Yahoo! Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import threading from concurrent import futures from oslo.messaging._executors import base from oslo.messaging.openstack.common import excutils # TODO(harlowja): this is the same opt as the eventlet impl, how do they share? _pool_opts = [ cfg.IntOpt('rpc_thread_pool_size', default=64, help='Size of RPC thread pool'), ] class ThreadExecutor(base.ExecutorBase): def __init__(self, conf, listener, callback): super(ThreadExecutor, self).__init__(conf, listener, callback) self.conf.register_opts(_pool_opts) self._receiver = None self._executor = None self._tombstone = threading.Event() self._futures = [] self._mutator = threading.Lock() def start(self): if self._receiver is not None: return self._tombstone.clear() pool_size = self.conf.rpc_thread_pool_size self._executor = futures.ThreadPoolExecutor(max_workers=pool_size) def clear_future(fn): with self._mutator: self._futures.remove(fn) @excutils.forever_retry_uncaught_exceptions def _executor_thread(): while not self._tombstone.is_set(): # How does this ever stop, can't this wait forever??? incoming = self.listener.poll() fn = self._executor.submit(self._dispatch, incoming) with self._mutator: self._futures.append(fn) fn.add_done_callback(clear_future) self._receiver = threading.Thread(target=_executor_thread) self._receiver.daemon = True self._receiver.start() def stop(self): if self._receiver is None: return self._tombstone.set() self._receiver.join() self._executor.shutdown() self._receiver = None self._executor = None def wait(self): if self._receiver is None: return with self._mutator: active_futures = list(self._futures) if active_futures: futures.wait(active_futures) ",,87,0
openstack%2Foslo.context~master~Iad8357364ad88961c280096480e8521d873f7c7f,openstack/oslo.context,master,Iad8357364ad88961c280096480e8521d873f7c7f,Activate pep8 check that _ is imported,MERGED,2014-12-11 22:56:53.000000000,2014-12-21 03:42:35.000000000,2014-12-21 03:42:34.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 7191}]","[{'number': 1, 'created': '2014-12-11 22:56:53.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.context/commit/205479f254e2bc90c0c142f1f75df500ae94f916', 'message': ""Activate pep8 check that _ is imported\n\nCurrently translatable messages are not used, so there are no uses\nof _.\n\nThis will ensure if _ is used in the future pep8 won't assume\nit is provided as a builtin.\n\nChange-Id: Iad8357364ad88961c280096480e8521d873f7c7f\n""}]",0,141197,205479f254e2bc90c0c142f1f75df500ae94f916,10,4,1,6601,,,0,"Activate pep8 check that _ is imported

Currently translatable messages are not used, so there are no uses
of _.

This will ensure if _ is used in the future pep8 won't assume
it is provided as a builtin.

Change-Id: Iad8357364ad88961c280096480e8521d873f7c7f
",git fetch https://review.opendev.org/openstack/oslo.context refs/changes/97/141197/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,205479f254e2bc90c0c142f1f75df500ae94f916,i18n_import,,builtins = _,0,1
openstack%2Fmanila~master~I344b3c6e46abbdb6ea4d844c771265eadbeb22f9,openstack/manila,master,I344b3c6e46abbdb6ea4d844c771265eadbeb22f9,Use oslo.context lib,MERGED,2014-12-19 02:41:46.000000000,2014-12-21 03:27:23.000000000,2014-12-21 03:27:22.000000000,"[{'_account_id': 3}, {'_account_id': 6116}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-12-19 02:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/1062c5802a7fc776e9f4d37f368ab85daa3a165e', 'message': 'Use oslo.context lib\n\nThere are exist ""context"" lib in common OSLO code.\nSee: https://github.com/openstack/oslo.context\nWe should use it.\n\nImplements blueprint oslo-context\n\nChange-Id: I344b3c6e46abbdb6ea4d844c771265eadbeb22f9\n'}, {'number': 2, 'created': '2014-12-20 06:38:31.000000000', 'files': ['requirements.txt', 'manila/openstack/common/context.py', 'openstack-common.conf', 'manila/context.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/8ea7ac4913ba21b5f849b46aa13228a41a1b5099', 'message': 'Use oslo.context lib\n\nUse ""context"" code from oslo instead of our own implementation.\nSee: https://github.com/openstack/oslo.context\n\nImplements blueprint oslo-context\n\nChange-Id: I344b3c6e46abbdb6ea4d844c771265eadbeb22f9\n'}]",2,142959,8ea7ac4913ba21b5f849b46aa13228a41a1b5099,12,5,2,6116,,,0,"Use oslo.context lib

Use ""context"" code from oslo instead of our own implementation.
See: https://github.com/openstack/oslo.context

Implements blueprint oslo-context

Change-Id: I344b3c6e46abbdb6ea4d844c771265eadbeb22f9
",git fetch https://review.opendev.org/openstack/manila refs/changes/59/142959/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'manila/openstack/common/context.py', 'manila/context.py']",3,1062c5802a7fc776e9f4d37f368ab85daa3a165e,bp/oslo-context,from oslo_context import context as common_context,from manila.openstack.common import context as common_context,2,127
openstack%2Fmanila~master~I8db2e4ef8ba2ebedd57aefe4ac10c56adfca0d30,openstack/manila,master,I8db2e4ef8ba2ebedd57aefe4ac10c56adfca0d30,Imported Translations from Transifex,MERGED,2014-12-17 06:14:47.000000000,2014-12-21 03:24:57.000000000,2014-12-21 03:24:57.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-12-17 06:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/c8b4e55cefb653d6a5d46bbbadf8d277a60f46e3', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I8db2e4ef8ba2ebedd57aefe4ac10c56adfca0d30\n'}, {'number': 2, 'created': '2014-12-18 06:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ab97ec3806d20e8024e7cfe41359bbc726b9cfb3', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I8db2e4ef8ba2ebedd57aefe4ac10c56adfca0d30\n'}, {'number': 3, 'created': '2014-12-19 06:12:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/1087cbb78b96343aa7a128aafef27565ac7cf8a7', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I8db2e4ef8ba2ebedd57aefe4ac10c56adfca0d30\n'}, {'number': 4, 'created': '2014-12-20 06:12:20.000000000', 'files': ['manila/locale/manila.pot', 'manila/locale/manila-log-info.pot', 'manila/locale/de/LC_MESSAGES/manila-log-error.po', 'manila/locale/manila-log-error.pot'], 'web_link': 'https://opendev.org/openstack/manila/commit/e1a6c0de6c781d0551adc4546febd1aed688ec7f', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I8db2e4ef8ba2ebedd57aefe4ac10c56adfca0d30\n'}]",0,142358,e1a6c0de6c781d0551adc4546febd1aed688ec7f,21,5,4,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I8db2e4ef8ba2ebedd57aefe4ac10c56adfca0d30
",git fetch https://review.opendev.org/openstack/manila refs/changes/58/142358/3 && git format-patch -1 --stdout FETCH_HEAD,"['manila/locale/manila.pot', 'manila/locale/de/LC_MESSAGES/manila-log-error.po', 'manila/locale/manila-log-error.pot']",3,c8b4e55cefb653d6a5d46bbbadf8d277a60f46e3,transifex/translations,"""Project-Id-Version: manila 2015.1.dev136\n""""POT-Creation-Date: 2014-12-17 06:14+0000\n""#: manila/share/manager.py:519#: manila/share/drivers/generic.py:230#: manila/share/drivers/generic.py:237#: manila/share/drivers/glusterfs.py:135#: manila/share/drivers/glusterfs.py:160 #, python-format msgid ""Error in disabling access to the entire GlusterFS volume: %s"" msgstr """" #: manila/share/drivers/glusterfs.py:171 #, python-format msgid ""Error in enabling creation of shares of specific size: %s"" msgstr """" #: manila/share/drivers/glusterfs.py:231#: manila/share/drivers/glusterfs.py:297#: manila/share/drivers/glusterfs.py:311 #, python-format msgid """" ""Cannot cleanup share, %s, that errored out during its creation, but "" ""exists in GlusterFS volume."" msgstr """" #: manila/share/drivers/glusterfs.py:323#: manila/share/drivers/glusterfs.py:382 #, python-format msgid ""Error in gluster volume set: %s"" msgstr """" #: manila/share/drivers/emc/plugins/vnx/connection.py:567#: manila/share/drivers/emc/plugins/vnx/connection.py:689#: manila/share/drivers/emc/plugins/vnx/connection.py:734#: manila/share/drivers/emc/plugins/vnx/connection.py:861","""Project-Id-Version: manila 2015.1.dev114.g2023930\n""""POT-Creation-Date: 2014-12-05 06:11+0000\n""#: manila/share/manager.py:512#: manila/share/drivers/generic.py:226#: manila/share/drivers/generic.py:233#: manila/share/drivers/glusterfs.py:132 manila/share/drivers/glusterfs.py:348 #, python-format msgid ""Error in gluster volume set: %s"" msgstr """" #: manila/share/drivers/glusterfs.py:178#: manila/share/drivers/glusterfs.py:217#: manila/share/drivers/glusterfs.py:275#: manila/share/drivers/glusterfs.py:289#: manila/share/drivers/emc/plugins/vnx/connection.py:568#: manila/share/drivers/emc/plugins/vnx/connection.py:690#: manila/share/drivers/emc/plugins/vnx/connection.py:735#: manila/share/drivers/emc/plugins/vnx/connection.py:862",142,97
openstack%2Foslo-incubator~master~I756ddaa259e55a22e010276c65d797d3c51b4a61,openstack/oslo-incubator,master,I756ddaa259e55a22e010276c65d797d3c51b4a61,Prefer delayed %r formatting over explicit repr use,MERGED,2014-12-11 16:25:44.000000000,2014-12-21 03:23:49.000000000,2014-12-21 03:23:48.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 9796}]","[{'number': 1, 'created': '2014-12-11 16:25:44.000000000', 'files': ['openstack/common/apiclient/exceptions.py', 'openstack/common/loopingcall.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/5985b35f110ddbf584b49a37a79895f7463cbd18', 'message': 'Prefer delayed %r formatting over explicit repr use\n\nThis change replaces the pattern like:\n\n  LOG.info(_LI(""...: %s""), repr(var))\n\nby:\n\n  LOG.info(_LI(""...: %r""), var)\n\nChange-Id: I756ddaa259e55a22e010276c65d797d3c51b4a61\n'}]",0,141089,5985b35f110ddbf584b49a37a79895f7463cbd18,8,4,1,8124,,,0,"Prefer delayed %r formatting over explicit repr use

This change replaces the pattern like:

  LOG.info(_LI(""...: %s""), repr(var))

by:

  LOG.info(_LI(""...: %r""), var)

Change-Id: I756ddaa259e55a22e010276c65d797d3c51b4a61
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/89/141089/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/apiclient/exceptions.py', 'openstack/common/loopingcall.py']",2,5985b35f110ddbf584b49a37a79895f7463cbd18,," LOG.warn(_LW('task %(func_name)r run outlasted ' {'func_name': self.f, 'delay': delay}) LOG.debug('Dynamic looping call %(func_name)r sleeping ' {'func_name': self.f, 'idle': idle})"," LOG.warn(_LW('task %(func_name)s run outlasted ' {'func_name': repr(self.f), 'delay': delay}) LOG.debug('Dynamic looping call %(func_name)s sleeping ' {'func_name': repr(self.f), 'idle': idle})",6,6
openstack%2Fhacking~master~Ib36d84078ecfcdbcb62137b40ab7426738e56a45,openstack/hacking,master,Ib36d84078ecfcdbcb62137b40ab7426738e56a45,Add docstring to is_import_exception,MERGED,2014-12-17 21:48:46.000000000,2014-12-21 03:21:36.000000000,2014-12-21 03:21:34.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5638}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-12-17 21:48:46.000000000', 'files': ['hacking/core.py'], 'web_link': 'https://opendev.org/openstack/hacking/commit/a74b0447193188077f5a1cb6e9f4aa20e00ef734', 'message': 'Add docstring to is_import_exception\n\nClarify what is_import_exception does. Leave the name as\nis_import_exception and no is_import_whitelisted  because\nimport-exceptions is part of the API for hacking (used in the hacking\nsection of tox.ini).\n\nChange-Id: Ib36d84078ecfcdbcb62137b40ab7426738e56a45\n'}]",0,142587,a74b0447193188077f5a1cb6e9f4aa20e00ef734,9,4,1,1849,,,0,"Add docstring to is_import_exception

Clarify what is_import_exception does. Leave the name as
is_import_exception and no is_import_whitelisted  because
import-exceptions is part of the API for hacking (used in the hacking
section of tox.ini).

Change-Id: Ib36d84078ecfcdbcb62137b40ab7426738e56a45
",git fetch https://review.opendev.org/openstack/hacking refs/changes/87/142587/1 && git format-patch -1 --stdout FETCH_HEAD,['hacking/core.py'],1,a74b0447193188077f5a1cb6e9f4aa20e00ef734,doc," """"""Check module name to see if import has been whitelisted. Import based rules should not run on any whitelisted module """"""",,4,0
openstack%2Fcinder~master~Ida7136165b959a9e0d7d50c240b447bf237caa6c,openstack/cinder,master,Ida7136165b959a9e0d7d50c240b447bf237caa6c,Fixed a problem in terminate_connection in VMAX driver,MERGED,2014-12-11 03:52:06.000000000,2014-12-21 01:23:39.000000000,2014-12-21 01:23:38.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11079}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 14206}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-11 03:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/20677c3e303da0ca3831b3e4bd561a497928eb1c', 'message': 'Fixed a problem in terminate_connection in VMAX driver\n\nThe VMAX driver unmaps the volume from the wrong VM in\nterminate_connection during live migration. This patche\nfixed this problem.\n\nChange-Id: Ida7136165b959a9e0d7d50c240b447bf237caa6c\nCloses-Bug: #1395845\n'}, {'number': 2, 'created': '2014-12-11 06:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d46c185339fc5475205c09ebaff7341f220f1e72', 'message': 'Fixed a problem in terminate_connection in VMAX driver\n\nThe VMAX driver unmaps the volume from the wrong VM in\nterminate_connection during live migration. This patche\nfixed this problem.\n\nChange-Id: Ida7136165b959a9e0d7d50c240b447bf237caa6c\nCloses-Bug: #1395845\n'}, {'number': 3, 'created': '2014-12-12 14:49:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d25cef2dde8d7d3a3a31831fc7b0fba52b70c393', 'message': 'Fixed a problem in terminate_connection in VMAX driver\n\nThe VMAX driver unmaps the volume from the wrong VM in\nterminate_connection during live migration. This patche\nfixed this problem.\n\nChange-Id: Ida7136165b959a9e0d7d50c240b447bf237caa6c\nCloses-Bug: #1395845\n'}, {'number': 4, 'created': '2014-12-12 15:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/65d9b67e0746cc77b46f1251f80e02f21c1fc08a', 'message': 'Fixed a problem in terminate_connection in VMAX driver\n\nThe VMAX driver unmaps the volume from the wrong VM in\nterminate_connection during live migration. This patche\nfixed this problem.\n\nChange-Id: Ida7136165b959a9e0d7d50c240b447bf237caa6c\nCloses-Bug: #1395845\n'}, {'number': 5, 'created': '2014-12-15 16:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/408c9413bac7606d7c24dc71f43aa74e11f8b67e', 'message': 'Fixed a problem in terminate_connection in VMAX driver\n\nThe VMAX driver unmaps the volume from the wrong VM in\nterminate_connection during live migration. This patche\nfixed this problem.\n\nCloses-Bug: #1395845\nChange-Id: Ida7136165b959a9e0d7d50c240b447bf237caa6c\n'}, {'number': 6, 'created': '2014-12-15 16:54:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f2b2c4923dba707a4b5a290a1d9aa2688cbb8cd1', 'message': 'Fixed a problem in terminate_connection in VMAX driver\n\nThe VMAX driver unmaps the volume from the wrong VM in\nterminate_connection during live migration. This patche\nfixed this problem.\n\nCloses-Bug: #1395845\nChange-Id: Ida7136165b959a9e0d7d50c240b447bf237caa6c\n'}, {'number': 7, 'created': '2014-12-17 23:23:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/337db546ce82836b38b4989eaa9197652cf80c79', 'message': 'Fixed a problem in terminate_connection in VMAX driver\n\nThe VMAX driver unmaps the volume from the wrong VM in\nterminate_connection during live migration. This patche\nfixed this problem.\n\nCloses-Bug: #1395845\nChange-Id: Ida7136165b959a9e0d7d50c240b447bf237caa6c\n'}, {'number': 8, 'created': '2014-12-19 21:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5f4ff13d8cc25a76068cf55fa57c3254702aa051', 'message': 'Fixed a problem in terminate_connection in VMAX driver\n\nThe VMAX driver unmaps the volume from the wrong VM in\nterminate_connection during live migration. This patche\nfixed this problem.\n\nCloses-Bug: #1395845\nChange-Id: Ida7136165b959a9e0d7d50c240b447bf237caa6c\n'}, {'number': 9, 'created': '2014-12-19 21:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/71aa05391662d48fda9d4ff628c67716b86f6a88', 'message': 'Fixed a problem in terminate_connection in VMAX driver\n\nThe VMAX driver unmaps the volume from the wrong VM in\nterminate_connection during live migration. This patche\nfixed this problem.\n\nCloses-Bug: #1395845\nChange-Id: Ida7136165b959a9e0d7d50c240b447bf237caa6c\n'}, {'number': 10, 'created': '2014-12-19 22:12:23.000000000', 'files': ['cinder/volume/drivers/emc/emc_vmax_common.py', 'cinder/volume/drivers/emc/emc_vmax_masking.py', 'cinder/tests/test_emc_vmax.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d94cc2888c5097306c43de3b2b424b408d52161a', 'message': 'Fixed a problem in terminate_connection in VMAX driver\n\nThe VMAX driver unmaps the volume from the wrong VM in\nterminate_connection during live migration. This patche\nfixed this problem.\n\nCloses-Bug: #1395845\nChange-Id: Ida7136165b959a9e0d7d50c240b447bf237caa6c\n'}]",14,140909,d94cc2888c5097306c43de3b2b424b408d52161a,71,20,10,6491,,,0,"Fixed a problem in terminate_connection in VMAX driver

The VMAX driver unmaps the volume from the wrong VM in
terminate_connection during live migration. This patche
fixed this problem.

Closes-Bug: #1395845
Change-Id: Ida7136165b959a9e0d7d50c240b447bf237caa6c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/09/140909/8 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/emc/emc_vmax_common.py', 'cinder/volume/drivers/emc/emc_vmax_masking.py', 'cinder/tests/test_emc_vmax.py']",3,20677c3e303da0ca3831b3e4bd561a497928eb1c,bug/1395903_volumeuuid," def test_retries_1393568(self): self.assertEqual( None, self.driver.utils._wait_for_job_complete( conn, myjob)) 'SystemName': u'SYMMETRIX+000195900551', 'DeviceID': u'1', 'SystemCreationClassName': u'Symm_StorageSystem'} 'keybindings': keybindings} self.assertEqual( None, self.driver.common._find_lun(volume)) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) @mock.patch.object( EMCVMAXMasking, '_wrap_get_storage_group_from_volume', return_value=None) @mock.patch.object( EMCVMAXCommon, '_wrap_find_device_number', return_value={'storagesystem': EMCVMAXCommonData.storage_system}) @mock.patch.object( EMCVMAXUtils, 'find_storage_masking_group', return_value='value') def test_map_new_masking_view_no_fast_success(self, _mock_volume_type, mock_wrap_group, mock_wrap_device, mock_storage_group): self.driver.initialize_connection(self.data.test_volume, self.data.connector) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) @mock.patch.object( EMCVMAXMasking, '_wrap_get_storage_group_from_volume', return_value=None) @mock.patch.object( EMCVMAXCommon, '_wrap_find_device_number', return_value={'hostlunid': 1, 'storagesystem': EMCVMAXCommonData.storage_system}) @mock.patch.object( EMCVMAXUtils, 'find_storage_masking_group', return_value='value') @mock.patch.object( EMCVMAXCommon, '_is_same_host', return_value=False) def test_map_live_migration_no_fast_success(self, _mock_volume_type, mock_wrap_group, mock_wrap_device, mock_storage_group, mock_same_host): self.driver.initialize_connection(self.data.test_volume, self.data.connector) def test_already_mapped_no_fast_success(self, _mock_volume_type, mock_wrap_group, self, mock_volume_type, mock_volume, volumeDict = {'classname': u'Symm_StorageVolume', def test_create_clone_simple_volume_no_fast_success(self, mock_volume_type, mock_volume, mock_sync_sv, mock_simple_volume): self, mock_volume_type, mock_volume,mock_meta, volumeDict = {'classname': u'Symm_StorageVolume', common = self.driver.common def test_create_clone_simple_volume_fast_success(self, mock_volume_type, mock_volume, mock_sync_sv, mock_simple_volume): def test_create_clone_fast_failed(self, mock_volume_type, mock_vol, mock_policy, mock_meta, mock_size, mock_pool): self, mock_volume_type, mock_volume, mock_meta, volumeDict = {'classname': u'Symm_StorageVolume', def test_create_clone_simple_volume_fast_success(self, mock_volume_type, self.driver.create_cloned_volume(self.data.test_volume, def test_create_clone_fast_failed(self, mock_volume_type, mock_vol,","from cinder.volume.drivers.emc.emc_vmax_utils import Retries def test_wait_for_job_complete_1393568(self): with mock.patch.object(Retries, 'get_retries') as get_retries: with mock.patch.object(self.driver.utils, '_is_job_finished') as is_finished: get_retries.return_value = 0 is_finished.return_value = True rc = self.driver.utils._wait_for_job_complete(conn, myjob) self.assertIsNone(rc) is_finished.assert_called_once_with(conn, myjob) self.assertEqual(True, is_finished.return_value) self.assertEqual(False, get_retries.called) self.assertEqual(0, get_retries.return_value) with mock.patch.object(Retries, 'get_retries') as get_retries: with mock.patch.object(self.driver.utils, '_is_job_finished') as is_finished: get_retries.return_value = 61 is_finished.return_value = False rc = self.driver.utils._wait_for_job_complete(conn, myjob) self.assertIsNone(rc) is_finished.assert_called_once_with(conn, myjob) self.assertEqual(False, is_finished.return_value) self.assertEqual(True, get_retries.called) self.assertEqual(61, get_retries.return_value) with mock.patch.object(Retries, 'set_retries') as set_retries: with mock.patch.object(self.driver.utils, '_is_job_finished') as is_finished: set_retries.side_effect = exception.CinderException get_retries.return_value = 0 is_finished.return_value = False self.assertRaises(exception.VolumeBackendAPIException, self.driver.utils._wait_for_job_complete, conn, myjob) is_finished.assert_called_once_with(conn, myjob) set_retries.assert_called_once_with(1) self.assertEqual(False, is_finished.return_value) self.assertEqual(2, get_retries.call_count) self.assertEqual(0, get_retries.return_value) def test_wait_for_sync_1393568(self): mysync = 'fakesync' conn = self.fake_ecom_connection() with mock.patch.object(Retries, 'get_retries') as get_retries: with mock.patch.object(self.driver.utils, '_is_sync_complete') as is_finished: get_retries.return_value = 0 is_finished.return_value = True rc = self.driver.utils.wait_for_sync(conn, mysync) self.assertIsNone(rc) is_finished.assert_called_once_with(conn, mysync) self.assertEqual(True, is_finished.return_value) self.assertEqual(False, get_retries.called) self.assertEqual(0, get_retries.return_value) with mock.patch.object(Retries, 'get_retries') as get_retries: with mock.patch.object(self.driver.utils, '_is_sync_complete') as is_finished: get_retries.return_value = 61 is_finished.return_value = False rc = self.driver.utils.wait_for_sync(conn, mysync) self.assertIsNone(rc) is_finished.assert_called_once_with(conn, mysync) self.assertEqual(False, is_finished.return_value) self.assertEqual(True, get_retries.called) self.assertEqual(61, get_retries.return_value) with mock.patch.object(Retries, 'set_retries') as set_retries: with mock.patch.object(self.driver.utils, '_is_sync_complete') as is_finished: set_retries.side_effect = exception.CinderException get_retries.return_value = 0 is_finished.return_value = False self.assertRaises(exception.VolumeBackendAPIException, self.driver.utils.wait_for_sync, conn, mysync) is_finished.assert_called_once_with(conn, mysync) set_retries.assert_called_once_with(1) self.assertEqual(False, is_finished.return_value) self.assertEqual(2, get_retries.call_count) self.assertEqual(0, get_retries.return_value) 'SystemName': u'SYMMETRIX+000195900551', 'DeviceID': u'1', 'SystemCreationClassName': u'Symm_StorageSystem'} 'keybindings': keybindings} self.assertIsNone(self.driver.common._find_lun(volume)) def test_map_no_fast_success(self, _mock_volume_type, mock_wrap_group, self, mock_volume_type, mock_volume, volumeDict = {'classname': u'Symm_StorageVolume', def test_create_clone_simple_volume_no_fast_success( self, mock_volume_type, mock_volume, mock_sync_sv, mock_simple_volume): self, mock_volume_type, mock_volume, mock_meta, volumeDict = {'classname': u'Symm_StorageVolume', def test_create_clone_simple_volume_fast_success( self, mock_volume_type, mock_volume, mock_sync_sv, mock_simple_volume): def test_create_clone_fast_failed( self, mock_volume_type, mock_vol, mock_policy, mock_meta, mock_size, mock_pool): self, mock_volume_type, mock_volume, mock_meta, volumeDict = {'classname': u'Symm_StorageVolume', def test_create_clone_simple_volume_fast_success( self, mock_volume_type, self.driver.create_cloned_volume( self.data.test_volume, def test_create_clone_fast_failed( self, mock_volume_type, mock_vol,",190,183
openstack%2Fcinder~master~Id07cdd1e03feac71ff34325d5abc68c5adc48266,openstack/cinder,master,Id07cdd1e03feac71ff34325d5abc68c5adc48266,Add a provider_id column to Volumes and Snapshots,MERGED,2014-12-19 22:20:37.000000000,2014-12-21 01:20:30.000000000,2014-12-21 01:20:29.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 14206}]","[{'number': 1, 'created': '2014-12-19 22:20:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d3babd47968e35731a69e8fa0f24a7ab39a23e67', 'message': ""Add a provider_id column to Volumes\n\nThere are a number of cases where there's some really ugly mapping\nwork in drivers to try and map the backend device-id to the\nCinder ID of a Volume.  Most drivers seem to work around this in\ntheir own creative ways using their own mechanisms (metadata,\nnaming schemes etc).\n\nIt seems like it would be useful for a number of reasons however to\ngo ahead and add a simple column to the Volumes table that could be\nused for storing a backend ID for the Volume.\n\nThis of course could be a slippery slope, the other alternative is\nto go with adding a metadata column that could be utilized in whatever\nway is needed.\n\nChange-Id: Id07cdd1e03feac71ff34325d5abc68c5adc48266\n""}, {'number': 2, 'created': '2014-12-19 22:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3164d376efdfed09b6f0b5bf2c6f25ceae435301', 'message': ""Add a provider_id column to Volumes and Snapshots\n\nThere are a number of cases where there's some really ugly mapping\nwork in drivers to try and map the backend device-id to the\nCinder ID of a Volume or Snapshot.  Most drivers seem to work around this in\ntheir own creative ways using their own mechanisms (metadata,\nnaming schemes etc).\n\nIt seems like it would be useful for a number of reasons however to\ngo ahead and add a simple column to the Volumes table that could be\nused for storing a backend ID for the Volume and Snapshot.\n\nChange-Id: Id07cdd1e03feac71ff34325d5abc68c5adc48266\n""}, {'number': 3, 'created': '2014-12-19 23:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a24c288d6b8f5f9063c3e8d6b6010cbb6be6ef48', 'message': ""Add a provider_id column to Volumes and Snapshots\n\nThere are a number of cases where there's some really ugly mapping\nwork in drivers to try and map the backend device-id to the\nCinder ID of a Volume or Snapshot.  Most drivers seem to work around this in\ntheir own creative ways using their own mechanisms (metadata,\nnaming schemes etc).\n\nIt seems like it would be useful for a number of reasons however to\ngo ahead and add a simple column to the Volumes table that could be\nused for storing a backend ID for the Volume and Snapshot.\n\nChange-Id: Id07cdd1e03feac71ff34325d5abc68c5adc48266\n""}, {'number': 4, 'created': '2014-12-20 00:06:09.000000000', 'files': ['cinder/db/sqlalchemy/migrate_repo/versions/036_add_provider_id_column_to_snapshots.py', 'cinder/db/sqlalchemy/migrate_repo/versions/035_add_provider_id_column.py', 'cinder/tests/test_migrations.py', 'cinder/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9f34d34d0ab92400223e3cc87285d0d4fbdf21f9', 'message': ""Add a provider_id column to Volumes and Snapshots\n\nThere are a number of cases where there's some really ugly mapping\nwork in drivers to try and map the backend device-id to the\nCinder ID of a Volume or Snapshot.  Most drivers seem to work around this in\ntheir own creative ways using their own mechanisms (metadata,\nnaming schemes etc).\n\nIt seems like it would be useful for a number of reasons however to\ngo ahead and add a simple column to the Volumes table that could be\nused for storing a backend ID for the Volume and Snapshot.\n\nChange-Id: Id07cdd1e03feac71ff34325d5abc68c5adc48266\n""}]",3,143205,9f34d34d0ab92400223e3cc87285d0d4fbdf21f9,28,13,4,2243,,,0,"Add a provider_id column to Volumes and Snapshots

There are a number of cases where there's some really ugly mapping
work in drivers to try and map the backend device-id to the
Cinder ID of a Volume or Snapshot.  Most drivers seem to work around this in
their own creative ways using their own mechanisms (metadata,
naming schemes etc).

It seems like it would be useful for a number of reasons however to
go ahead and add a simple column to the Volumes table that could be
used for storing a backend ID for the Volume and Snapshot.

Change-Id: Id07cdd1e03feac71ff34325d5abc68c5adc48266
",git fetch https://review.opendev.org/openstack/cinder refs/changes/05/143205/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/db/sqlalchemy/migrate_repo/versions/035_add_provider_id_column.py', 'cinder/tests/test_migrations.py']",2,d3babd47968e35731a69e8fa0f24a7ab39a23e67,add_provider_id_column_to_volumes," def _check_035(self, engine, data): """"""Test that adding provider_geometry column works correctly."""""" volumes = db_utils.get_table(engine, 'volumes') self.assertIsInstance(volumes.c.provider_id.type, sqlalchemy.types.VARCHAR) def _post_downgrade_035(self, engine): volumes = db_utils.get_table(engine, 'volumes') self.assertNotIn('provider_id', volumes.c) ",,45,0
openstack%2Ftempest~master~I8bbe7a654a548317d0c66fa24506eff7424cf9ef,openstack/tempest,master,I8bbe7a654a548317d0c66fa24506eff7424cf9ef,Add note about build_timeout,MERGED,2014-12-15 09:26:18.000000000,2014-12-21 01:16:26.000000000,2014-12-21 01:16:25.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5803}, {'_account_id': 7217}, {'_account_id': 8859}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-15 09:26:18.000000000', 'files': ['etc/tempest.conf.sample', 'tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5b139ad8e4cec01ad143449deb1dc06bbde35468', 'message': ""Add note about build_timeout\n\nCompute's build_timeout applies to other services that don't define that\nvalue. This patch adds a comment to make that explicit.\n\nChange-Id: I8bbe7a654a548317d0c66fa24506eff7424cf9ef\nCloses-Bug: #1394519\n""}]",0,141752,5b139ad8e4cec01ad143449deb1dc06bbde35468,22,6,1,7217,,,0,"Add note about build_timeout

Compute's build_timeout applies to other services that don't define that
value. This patch adds a comment to make that explicit.

Change-Id: I8bbe7a654a548317d0c66fa24506eff7424cf9ef
Closes-Bug: #1394519
",git fetch https://review.opendev.org/openstack/tempest refs/changes/52/141752/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/tempest.conf.sample', 'tempest/config.py']",2,5b139ad8e4cec01ad143449deb1dc06bbde35468,bug/1394519," help=""Timeout in seconds to wait for an instance to build. "" ""Other services that do not define build_timeout will "" ""inherit this value, for example the image service.""),"," help=""Timeout in seconds to wait for an instance to build.""),",6,2
openstack%2Fkeystonemiddleware~master~If69fbb73bea268b96e4b1e9ad81a736495a2b58a,openstack/keystonemiddleware,master,If69fbb73bea268b96e4b1e9ad81a736495a2b58a,Fix auth_token does version request for no token,MERGED,2014-12-10 16:37:43.000000000,2014-12-21 01:15:10.000000000,2014-12-21 01:15:10.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6486}, {'_account_id': 9101}]","[{'number': 1, 'created': '2014-12-10 16:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/4a6f2416b0807a21444fe77b5237c630261fe5dc', 'message': ""Refactor identity version handling to strategy pattern\n\nThere were 2 subclasses of _IdentityServer in auth_token, one for\nV2 and one for V3. This is excessive since there's only a couple of\nmethods that are needed and not all the _IdentityServer class. Using\nthe pricipal of preferring composition over inheritance, the code to\nhandle V2/V3 is moved into a simpler strategy pattern. This also\nmoves code out of the AuthProtocol class which is too complicated\nalready, and it allows more refactoring since the _IdentityServer\nreference can be created and passed to extracted classes for them\nto use.\n\nChange-Id: If69fbb73bea268b96e4b1e9ad81a736495a2b58a\n""}, {'number': 2, 'created': '2014-12-10 16:47:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/4ad46664d9c8f29d989ef08bc5eec5afbb75d36a', 'message': ""Refactor identity version handling to strategy pattern\n\nThere were 2 subclasses of _IdentityServer in auth_token, one for\nV2 and one for V3. This is excessive since there's only a couple of\nmethods that are needed and not all the _IdentityServer class. Using\nthe pricipal of preferring composition over inheritance, the code to\nhandle V2/V3 is moved into a simpler strategy pattern. This also\nmoves code out of the AuthProtocol class which is too complicated\nalready, and it allows more refactoring since the _IdentityServer\nreference can be created and passed to extracted classes for them\nto use.\n\nChange-Id: If69fbb73bea268b96e4b1e9ad81a736495a2b58a\n""}, {'number': 3, 'created': '2014-12-12 02:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/ef6475d7c6d731345a9b6f4871f92253c7ab8237', 'message': ""Refactor identity version handling to strategy pattern\n\nThere were 2 subclasses of _IdentityServer in auth_token, one for\nV2 and one for V3. This is excessive since there's only a couple of\nmethods that are needed and not all the _IdentityServer class. Using\nthe pricipal of preferring composition over inheritance, the code to\nhandle V2/V3 is moved into a simpler strategy pattern. This also\nmoves code out of the AuthProtocol class which is too complicated\nalready, and it allows more refactoring since the _IdentityServer\nreference can be created and passed to extracted classes for them\nto use.\n\nChange-Id: If69fbb73bea268b96e4b1e9ad81a736495a2b58a\n""}, {'number': 4, 'created': '2014-12-12 02:20:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/c2605f6156617b487c5afdde48626b562b16753e', 'message': ""Refactor identity version handling to strategy pattern\n\nThere were 2 subclasses of _IdentityServer in auth_token, one for\nV2 and one for V3. This is excessive since there's only a couple of\nmethods that are needed and not all the _IdentityServer class. Using\nthe pricipal of preferring composition over inheritance, the code to\nhandle V2/V3 is moved into a simpler strategy pattern. This also\nmoves code out of the AuthProtocol class which is too complicated\nalready, and it allows more refactoring since the _IdentityServer\nreference can be created and passed to extracted classes for them\nto use.\n\nChange-Id: If69fbb73bea268b96e4b1e9ad81a736495a2b58a\n""}, {'number': 5, 'created': '2014-12-19 15:42:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/802a1a0745ba92246ee061fdb6810487dc97f0d7', 'message': ""Refactor identity version handling to strategy pattern\n\nThere were 2 subclasses of _IdentityServer in auth_token, one for\nV2 and one for V3. This is excessive since there's only a couple of\nmethods that are needed and not all the _IdentityServer class. Using\nthe pricipal of preferring composition over inheritance, the code to\nhandle V2/V3 is moved into a simpler strategy pattern. This also\nmoves code out of the AuthProtocol class which is too complicated\nalready, and it allows more refactoring since the _IdentityServer\nreference can be created and passed to extracted classes for them\nto use.\n\nChange-Id: If69fbb73bea268b96e4b1e9ad81a736495a2b58a\n""}, {'number': 6, 'created': '2014-12-19 16:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/d70ec372e8a8e4d56e7949d3c48eb9976adfb1e5', 'message': ""Refactor identity version handling to strategy pattern\n\nThere were 2 subclasses of _IdentityServer in auth_token, one for\nV2 and one for V3. This is excessive since there's only a couple of\nmethods that are needed and not all the _IdentityServer class. Using\nthe pricipal of preferring composition over inheritance, the code to\nhandle V2/V3 is moved into a simpler strategy pattern. This also\nmoves code out of the AuthProtocol class which is too complicated\nalready, and it allows more refactoring since the _IdentityServer\nreference can be created and passed to extracted classes for them\nto use.\n\nCloses-Bug: #1404294\nChange-Id: If69fbb73bea268b96e4b1e9ad81a736495a2b58a\n""}, {'number': 7, 'created': '2014-12-19 16:39:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/cd2ca7048a976c7bc25e265599fc826ee6ee8da7', 'message': ""Refactor identity version handling to strategy pattern\n\nThere were 2 subclasses of _IdentityServer in auth_token, one for\nV2 and one for V3. This is excessive since there's only a couple of\nmethods that are needed and not all the _IdentityServer class. Using\nthe pricipal of preferring composition over inheritance, the code to\nhandle V2/V3 is moved into a simpler strategy pattern. This also\nmoves code out of the AuthProtocol class which is too complicated\nalready, and it allows more refactoring since the _IdentityServer\nreference can be created and passed to extracted classes for them\nto use.\n\nChange-Id: If69fbb73bea268b96e4b1e9ad81a736495a2b58a\n""}, {'number': 8, 'created': '2014-12-19 16:53:12.000000000', 'files': ['keystonemiddleware/auth_token.py', 'keystonemiddleware/tests/test_auth_token_middleware.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/c97be0a9ee778f25e2931aeb1f678c145c2f1d2b', 'message': ""Fix auth_token does version request for no token\n\nWhen a request came in with no token and the auth_token middleware\nwasn't configured with an auth version, a request would be made to\nfetch the versions supported by the server. This causes problems in\nprojects that have unit tests using the auth_token middleware because\nthey didn't expect to have an Identity server running.\n\nThe fix for this is to refactor the identity version handling to a\nstrategy pattern.\n\nThere were 2 subclasses of _IdentityServer in auth_token, one for\nV2 and one for V3. This is excessive since there's only a couple of\nmethods that are needed and not all the _IdentityServer class. Using\nthe pricipal of preferring composition over inheritance, the code to\nhandle V2/V3 is moved into a simpler strategy pattern. This also\nmoves code out of the AuthProtocol class which is too complicated\nalready, and it allows more refactoring since the _IdentityServer\nreference can be created and passed to extracted classes for them\nto use.\n\nCloses-Bug: #1404294\nChange-Id: If69fbb73bea268b96e4b1e9ad81a736495a2b58a\n""}]",0,140765,c97be0a9ee778f25e2931aeb1f678c145c2f1d2b,34,7,8,6486,,,0,"Fix auth_token does version request for no token

When a request came in with no token and the auth_token middleware
wasn't configured with an auth version, a request would be made to
fetch the versions supported by the server. This causes problems in
projects that have unit tests using the auth_token middleware because
they didn't expect to have an Identity server running.

The fix for this is to refactor the identity version handling to a
strategy pattern.

There were 2 subclasses of _IdentityServer in auth_token, one for
V2 and one for V3. This is excessive since there's only a couple of
methods that are needed and not all the _IdentityServer class. Using
the pricipal of preferring composition over inheritance, the code to
handle V2/V3 is moved into a simpler strategy pattern. This also
moves code out of the AuthProtocol class which is too complicated
already, and it allows more refactoring since the _IdentityServer
reference can be created and passed to extracted classes for them
to use.

Closes-Bug: #1404294
Change-Id: If69fbb73bea268b96e4b1e9ad81a736495a2b58a
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/65/140765/2 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/auth_token.py'],1,4a6f2416b0807a21444fe77b5237c630261fe5dc,bug/1404294," self._identity_server = self._create_identity_server() def _create_identity_server(self): # NOTE(jamielennox): Loading Session here should be exactly the # same as calling Session.load_from_conf_options(CONF, GROUP) # however we can't do that because we have to use _conf_get to # support the paste.ini options. sess = session.Session.construct(dict( cert=self._conf_get('certfile'), key=self._conf_get('keyfile'), cacert=self._conf_get('cafile'), insecure=self._conf_get('insecure'), timeout=self._conf_get('http_connect_timeout') )) # NOTE(jamielennox): Loading AuthTokenPlugin here should be exactly # the same as calling _AuthTokenPlugin.load_from_conf_options(CONF, # GROUP) however we can't do that because we have to use _conf_get # to support the paste.ini options. auth_plugin = _AuthTokenPlugin.load_from_options( auth_host=self._conf_get('auth_host'), auth_port=int(self._conf_get('auth_port')), auth_protocol=self._conf_get('auth_protocol'), auth_admin_prefix=self._conf_get('auth_admin_prefix'), admin_user=self._conf_get('admin_user'), admin_password=self._conf_get('admin_password'), admin_tenant_name=self._conf_get('admin_tenant_name'), admin_token=self._conf_get('admin_token'), identity_uri=self._conf_get('identity_uri'), log=self._LOG) adap = adapter.Adapter( sess, auth=auth_plugin, service_type='identity', interface='admin', connect_retries=self._conf_get('http_request_max_retries')) return _IdentityServer(self._LOG, adap, self._include_service_catalog, self._conf_get('auth_uri'), self._conf_get('auth_version')) def __init__(self, log, adap, include_service_catalog=None, auth_uri=None, requested_auth_version=None): self._requested_auth_version = requested_auth_version # Built on-demand with self._request_strategy. self._request_strategy_obj = None @property def _request_strategy(self): if not self._request_strategy_obj: strategy_class = self._get_strategy_class() self._adapter.version = strategy_class.AUTH_VERSION self._request_strategy_obj = strategy_class( self._json_request, self._adapter, include_service_catalog=self._include_service_catalog) return self._request_strategy_obj def _get_strategy_class(self): # FIXME(jamielennox): Checking string equality is bad, but consistent # with the existing code. Fix this to better handle selecting v3. if self._requested_auth_version == 'v3.0': return _V3RequestStrategy elif self._requested_auth_version: return _V2RequestStrategy for klass in _REQUEST_STRATEGIES: if self._adapter.get_endpoint(version=klass.AUTH_VERSION): msg = _LI('Auth Token confirmed use of %s apis') self._LOG.info(msg, self._requested_auth_version) return klass versions = ['v%d.%d' % s.AUTH_VERSION for s in _REQUEST_STRATEGIES] self._LOG.error(_LE('No attempted versions [%s] supported by server') % ', '.join(versions)) msg = _('No compatible apis supported by server') raise ServiceError(msg) response, data = self._request_strategy.verify_token(user_token) response = self._request_strategy.fetch_cert_file(cert_type)class _RequestStrategy(object): AUTH_VERSION = None def __init__(self, json_request, adap, include_service_catalog=None): self._json_request = json_request self._adapter = adap self._include_service_catalog = include_service_catalog def verify_token(self, user_token): pass def fetch_cert_file(self, cert_type): pass class _V2RequestStrategy(_RequestStrategy): def verify_token(self, user_token): def fetch_cert_file(self, cert_type):class _V3RequestStrategy(_RequestStrategy): def verify_token(self, user_token): def fetch_cert_file(self, cert_type):# NOTE(jamielennox): must be defined after request strategy classes _REQUEST_STRATEGIES = [_V3RequestStrategy, _V2RequestStrategy] "," self._identity_server_obj = None @property def _identity_server(self): if not self._identity_server_obj: # NOTE(jamielennox): Loading Session here should be exactly the # same as calling Session.load_from_conf_options(CONF, GROUP) # however we can't do that because we have to use _conf_get to # support the paste.ini options. sess = session.Session.construct(dict( cert=self._conf_get('certfile'), key=self._conf_get('keyfile'), cacert=self._conf_get('cafile'), insecure=self._conf_get('insecure'), timeout=self._conf_get('http_connect_timeout') )) # NOTE(jamielennox): Loading AuthTokenPlugin here should be exactly # the same as calling _AuthTokenPlugin.load_from_conf_options(CONF, # GROUP) however we can't do that because we have to use _conf_get # to support the paste.ini options. auth_plugin = _AuthTokenPlugin.load_from_options( auth_host=self._conf_get('auth_host'), auth_port=int(self._conf_get('auth_port')), auth_protocol=self._conf_get('auth_protocol'), auth_admin_prefix=self._conf_get('auth_admin_prefix'), admin_user=self._conf_get('admin_user'), admin_password=self._conf_get('admin_password'), admin_tenant_name=self._conf_get('admin_tenant_name'), admin_token=self._conf_get('admin_token'), identity_uri=self._conf_get('identity_uri'), log=self._LOG) adap = adapter.Adapter( sess, auth=auth_plugin, service_type='identity', interface='admin', connect_retries=self._conf_get('http_request_max_retries')) server_class = self._get_server_class(adap) adap.version = server_class.AUTH_VERSION self._identity_server_obj = server_class( self._LOG, adap, include_service_catalog=self._include_service_catalog, auth_uri=self._conf_get('auth_uri')) return self._identity_server_obj def _get_server_class(self, adap): # FIXME(jamielennox): Checking string equality is bad, but consistent # with the existing code. Fix this to better handle selecting v3. auth_version = self._conf_get('auth_version') if auth_version == 'v3.0': return _V3IdentityServer elif auth_version: return _V2IdentityServer for klass in _VERSIONS_TO_ATTEMPT: if adap.get_endpoint(version=klass.AUTH_VERSION): msg = _LI('Auth Token confirmed use of %s apis') self._LOG.info(msg, auth_version) return klass versions = ['v%d.%d' % s.AUTH_VERSION for s in _VERSIONS_TO_ATTEMPT] self._LOG.error(_LE('No attempted versions [%s] supported by server') % ', '.join(versions)) msg = _('No compatible apis supported by server') raise ServiceError(msg) def __init__(self, log, adap, include_service_catalog=None, auth_uri=None): response, data = self._do_verify_token(user_token) response = self._do_fetch_cert_file(cert_type)class _V2IdentityServer(_IdentityServer): def _do_verify_token(self, user_token): def _do_fetch_cert_file(self, cert_type):class _V3IdentityServer(_IdentityServer): def _do_verify_token(self, user_token): def _do_fetch_cert_file(self, cert_type):# NOTE(jamielennox): must be defined after identity server classes _VERSIONS_TO_ATTEMPT = [_V3IdentityServer, _V2IdentityServer] ",106,81
openstack%2Fpbr~feature%2F0.10~I1c420fed609bc60bbfdf78eb219e067ccab1a61e,openstack/pbr,feature/0.10,I1c420fed609bc60bbfdf78eb219e067ccab1a61e,Move write_pbr_json to avoid issues with nose,MERGED,2014-12-20 00:47:34.000000000,2014-12-21 01:08:16.000000000,2014-12-21 01:08:16.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 7687}]","[{'number': 1, 'created': '2014-12-20 00:47:34.000000000', 'files': ['pbr/pbr_json.py', 'pbr/tests/test_setup.py', 'pbr/packaging.py', 'pbr/tests/test_packaging.py', 'pbr/git.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/pbr/commit/0acee45efb9852599f0604ce1539febc350a50c0', 'message': 'Move write_pbr_json to avoid issues with nose\n\nPut write_pbr_json in pbr.pbr_json so that you do not need to import\npbr.packaging to use it. This avoids python3 errors with nose where nose\nis imported by pbr before it is converted to python3 by 2to3 under\npython3.\n\nAlso port the pbr.git refactor from the master branch.\n\nCo-Authored-By: Jeremy Stanley <fungi@yuggoth.org>\nChange-Id: I1c420fed609bc60bbfdf78eb219e067ccab1a61e\n(cherry picked from commit 3550e89db42002e226ea70b1d0314a319b2ecd10)\n'}]",0,143228,0acee45efb9852599f0604ce1539febc350a50c0,11,5,1,5263,,,0,"Move write_pbr_json to avoid issues with nose

Put write_pbr_json in pbr.pbr_json so that you do not need to import
pbr.packaging to use it. This avoids python3 errors with nose where nose
is imported by pbr before it is converted to python3 by 2to3 under
python3.

Also port the pbr.git refactor from the master branch.

Co-Authored-By: Jeremy Stanley <fungi@yuggoth.org>
Change-Id: I1c420fed609bc60bbfdf78eb219e067ccab1a61e
(cherry picked from commit 3550e89db42002e226ea70b1d0314a319b2ecd10)
",git fetch https://review.opendev.org/openstack/pbr refs/changes/28/143228/1 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/pbr_json.py', 'pbr/tests/test_setup.py', 'pbr/packaging.py', 'pbr/tests/test_packaging.py', 'pbr/git.py', 'setup.cfg']",6,0acee45efb9852599f0604ce1539febc350a50c0,setuptools-8, pbr.json = pbr.pbr_json:write_pbr_json, pbr.json = pbr.packaging:write_pbr_json,350,254
openstack%2Fneutron~master~I9e56aa34fc560ae3fc749c51788436e32179d0a1,openstack/neutron,master,I9e56aa34fc560ae3fc749c51788436e32179d0a1,Scope dhcp rpc api using a messaging namespace,MERGED,2014-12-09 22:46:35.000000000,2014-12-20 23:07:28.000000000,2014-12-20 23:07:27.000000000,"[{'_account_id': 3}, {'_account_id': 162}, {'_account_id': 1561}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-09 22:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b2ef695b11a7a9d0e64f09488f6fd84772f52a55', 'message': ""Move dhcp rpc api into a namespace\n\nThis patch updates the rpc API used by the DHCP agent to make calls\nback into the neutron plugin to use the 'dhcp' namespace instead of\nthe default namespace.  The reason is that this API is exposed over\nthe 'q-plugin' topic along with several other interfaces.  Without the\nuse of namespaces, all of the interfaces are effectively treated as\none by oslo.messaging.  When a namespace is used, the interface can be\nversioned independently and when a method is called, the only class\nconsidered for fulfilling the request is the one that claims to\nimplement the 'dhcp' namespace.\n\nWhile we're here, add documentation to both the client and server side\nof this interface that indicates where the other side is located.\n\nPart of blueprint rpc-docs-and-namespaces.\n\nChange-Id: I9e56aa34fc560ae3fc749c51788436e32179d0a1\n""}, {'number': 2, 'created': '2014-12-10 03:33:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f2114b4855a0b721e69a981d7fa8c1b793c1fa70', 'message': ""Move dhcp rpc api into a namespace\n\nThis patch updates the rpc API used by the DHCP agent to make calls\nback into the neutron plugin to use the 'dhcp' namespace instead of\nthe default namespace.  The reason is that this API is exposed over\nthe 'q-plugin' topic along with several other interfaces.  Without the\nuse of namespaces, all of the interfaces are effectively treated as\none by oslo.messaging.  When a namespace is used, the interface can be\nversioned independently and when a method is called, the only class\nconsidered for fulfilling the request is the one that claims to\nimplement the 'dhcp' namespace.\n\nWhile we're here, add documentation to both the client and server side\nof this interface that indicates where the other side is located.\n\nPart of blueprint rpc-docs-and-namespaces.\n\nChange-Id: I9e56aa34fc560ae3fc749c51788436e32179d0a1\n""}, {'number': 3, 'created': '2014-12-16 13:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3f523d89abd488773ff17f2d6a520a56c07670f3', 'message': ""Scope dhcp rpc api using a messaging namespace\n\nThis patch updates the rpc API used by the DHCP agent to make calls\nback into the neutron plugin to use the 'dhcp' namespace instead of\nthe default namespace.  The reason is that this API is exposed over\nthe 'q-plugin' topic along with several other interfaces.  Without the\nuse of namespaces, all of the interfaces are effectively treated as\none by oslo.messaging.  When a namespace is used, the interface can be\nversioned independently and when a method is called, the only class\nconsidered for fulfilling the request is the one that claims to\nimplement the 'dhcp' namespace.\n\nWhile we're here, add documentation to both the client and server side\nof this interface that indicates where the other side is located.\n\nPart of blueprint rpc-docs-and-namespaces.\n\nChange-Id: I9e56aa34fc560ae3fc749c51788436e32179d0a1\n""}, {'number': 4, 'created': '2014-12-17 15:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/092df482a690fc9eaa983376b0da3882a2e9f859', 'message': ""Scope dhcp rpc api using a messaging namespace\n\nThis patch updates the rpc API used by the DHCP agent to make calls\nback into the neutron plugin to use the 'dhcp' namespace instead of\nthe default namespace.  The reason is that this API is exposed over\nthe 'q-plugin' topic along with several other interfaces.  Without the\nuse of namespaces, all of the interfaces are effectively treated as\none by oslo.messaging.  When a namespace is used, the interface can be\nversioned independently and when a method is called, the only class\nconsidered for fulfilling the request is the one that claims to\nimplement the 'dhcp' namespace.\n\nWhile we're here, add documentation to both the client and server side\nof this interface that indicates where the other side is located.\n\nPart of blueprint rpc-docs-and-namespaces.\n\nChange-Id: I9e56aa34fc560ae3fc749c51788436e32179d0a1\n""}, {'number': 5, 'created': '2014-12-19 13:35:12.000000000', 'files': ['neutron/common/constants.py', 'neutron/api/rpc/handlers/dhcp_rpc.py', 'neutron/agent/dhcp_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4a69b69e58cddddf8ab8ef607b12eb9e1c0709ab', 'message': ""Scope dhcp rpc api using a messaging namespace\n\nThis patch updates the rpc API used by the DHCP agent to make calls\nback into the neutron plugin to use the 'dhcp' namespace instead of\nthe default namespace.  The reason is that this API is exposed over\nthe 'q-plugin' topic along with several other interfaces.  Without the\nuse of namespaces, all of the interfaces are effectively treated as\none by oslo.messaging.  When a namespace is used, the interface can be\nversioned independently and when a method is called, the only class\nconsidered for fulfilling the request is the one that claims to\nimplement the 'dhcp' namespace.\n\nWhile we're here, add documentation to both the client and server side\nof this interface that indicates where the other side is located.\n\nPart of blueprint rpc-docs-and-namespaces.\n\nChange-Id: I9e56aa34fc560ae3fc749c51788436e32179d0a1\n""}]",8,140511,4a69b69e58cddddf8ab8ef607b12eb9e1c0709ab,120,29,5,1561,,,0,"Scope dhcp rpc api using a messaging namespace

This patch updates the rpc API used by the DHCP agent to make calls
back into the neutron plugin to use the 'dhcp' namespace instead of
the default namespace.  The reason is that this API is exposed over
the 'q-plugin' topic along with several other interfaces.  Without the
use of namespaces, all of the interfaces are effectively treated as
one by oslo.messaging.  When a namespace is used, the interface can be
versioned independently and when a method is called, the only class
considered for fulfilling the request is the one that claims to
implement the 'dhcp' namespace.

While we're here, add documentation to both the client and server side
of this interface that indicates where the other side is located.

Part of blueprint rpc-docs-and-namespaces.

Change-Id: I9e56aa34fc560ae3fc749c51788436e32179d0a1
",git fetch https://review.opendev.org/openstack/neutron refs/changes/11/140511/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/common/constants.py', 'neutron/api/rpc/handlers/dhcp_rpc.py', 'neutron/agent/dhcp_agent.py']",3,b2ef695b11a7a9d0e64f09488f6fd84772f52a55,bp/rpc-docs-and-namespaces," This class implements the client side of an rpc interface. The server side of this interface can be found in neutron.api.rpc.handers.dhcp_rpc.DhcpRpcCallback. For more information about changing rpc interfaces, see doc/source/devref/rpc_api.rst. target = messaging.Target(topic=topic, namespace=constants.RPC_NAMESPACE_DHCP, version='1.0')"," target = messaging.Target(topic=topic, version='1.0')",19,3
openstack%2Fneutron~master~I683009b1c5b3520e5f9f2c17a9a0dabefdeebe45,openstack/neutron,master,I683009b1c5b3520e5f9f2c17a9a0dabefdeebe45,Copy the contrib directory instead of moving it,MERGED,2014-12-19 18:13:36.000000000,2014-12-20 22:09:17.000000000,2014-12-20 22:09:16.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 5263}, {'_account_id': 6524}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 14208}]","[{'number': 1, 'created': '2014-12-19 18:13:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/85cd47c8386baee8152a66735f75ca638f44596c', 'message': 'Copy the contrib directory instead of moving it\n\nThis is necessary because pbr is stupid enough not to be\nable to handle symlinks. The initial symlink was necessary to\navoid breaking the functional job. Once change [1] merges we\ncan drop the old contrib directory.\n\n[1] https://review.openstack.org/#/c/142603/\n\nChange-Id: I683009b1c5b3520e5f9f2c17a9a0dabefdeebe45\n'}, {'number': 2, 'created': '2014-12-20 17:40:59.000000000', 'files': ['neutron/tests/functional/contrib/filters.template', 'neutron/tests/functional/contrib/gate_hook.sh', 'neutron/tests/functional/contrib/post_test_hook.sh', 'neutron/tests/functional/contrib/README', 'neutron/tests/functional/contrib'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e4fd24d0459a708cfeed4494f177e3123e842b3f', 'message': 'Copy the contrib directory instead of moving it\n\nThis is necessary because pbr is stupid enough not to be\nable to handle symlinks. The initial symlink was necessary to\navoid breaking the functional job. Once change [1] merges we\ncan drop the old contrib directory.\n\n[1] https://review.openstack.org/#/c/142603/\n\nChange-Id: I683009b1c5b3520e5f9f2c17a9a0dabefdeebe45\n'}]",1,143152,e4fd24d0459a708cfeed4494f177e3123e842b3f,42,16,2,748,,,0,"Copy the contrib directory instead of moving it

This is necessary because pbr is stupid enough not to be
able to handle symlinks. The initial symlink was necessary to
avoid breaking the functional job. Once change [1] merges we
can drop the old contrib directory.

[1] https://review.openstack.org/#/c/142603/

Change-Id: I683009b1c5b3520e5f9f2c17a9a0dabefdeebe45
",git fetch https://review.opendev.org/openstack/neutron refs/changes/52/143152/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/contrib/README', 'neutron/tests/contrib/gate_hook.sh', 'neutron/tests/contrib/filters.template', 'neutron/tests/contrib/post_test_hook.sh']",4,85cd47c8386baee8152a66735f75ca638f44596c,copy-contrib2,"#!/bin/bash set -xe NEUTRON_DIR=""$BASE/new/neutron"" SCRIPTS_DIR=""/usr/local/jenkins/slave_scripts"" venv=dsvm-functional function generate_testr_results { # Give job user rights to access tox logs sudo -H -u stack chmod o+rw -R . if [ -f "".testrepository/0"" ] ; then .tox/$venv/bin/subunit-1to2 < .testrepository/0 > ./testrepository.subunit .tox/$venv/bin/python $SCRIPTS_DIR/subunit2html.py ./testrepository.subunit testr_results.html gzip -9 ./testrepository.subunit gzip -9 ./testr_results.html sudo mv ./*.gz /opt/stack/logs/ fi } # Run tests as the stack user to allow sudo+rootwrap. sudo chown -R stack:stack $NEUTRON_DIR cd $NEUTRON_DIR echo ""Running neutron functional test suite"" set +e sudo -H -u stack tox -e $venv testr_exit_code=$? set -e generate_testr_results exit $testr_exit_code ",,104,0
openstack%2Fneutron-vpnaas~master~Ic78aa4522ea7ee2d583bff78cffb791207e47a9c,openstack/neutron-vpnaas,master,Ic78aa4522ea7ee2d583bff78cffb791207e47a9c,Added __init__.py so migrations can work,MERGED,2014-12-19 23:18:40.000000000,2014-12-20 21:34:24.000000000,2014-12-20 21:34:22.000000000,"[{'_account_id': 3}, {'_account_id': 6659}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-19 23:18:40.000000000', 'files': ['neutron_vpnaas/db/migration/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/cc592ac6492103f9cf51c7d6136e576d117834d2', 'message': 'Added __init__.py so migrations can work\n\nChange-Id: Ic78aa4522ea7ee2d583bff78cffb791207e47a9c\n'}]",0,143216,cc592ac6492103f9cf51c7d6136e576d117834d2,8,3,1,6951,,,0,"Added __init__.py so migrations can work

Change-Id: Ic78aa4522ea7ee2d583bff78cffb791207e47a9c
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/16/143216/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_vpnaas/db/migration/__init__.py'],1,cc592ac6492103f9cf51c7d6136e576d117834d2,,,,0,0
openstack%2Fhorizon~master~Ibee85cdcf505e90d9faeb54dbab7216fc24c1b2c,openstack/horizon,master,Ibee85cdcf505e90d9faeb54dbab7216fc24c1b2c,Fix Firewalls panel to override the right method,MERGED,2014-12-18 06:33:50.000000000,2014-12-20 18:48:03.000000000,2014-12-20 18:48:02.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 4428}, {'_account_id': 6610}, {'_account_id': 6763}, {'_account_id': 7634}, {'_account_id': 13086}, {'_account_id': 13785}, {'_account_id': 14307}]","[{'number': 1, 'created': '2014-12-18 06:33:50.000000000', 'files': ['openstack_dashboard/dashboards/admin/aggregates/panel.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/9fae45cde101188c6541a951df78fb4e17c13822', 'message': 'Fix Firewalls panel to override the right method\n\nInstead of overriding can_acess(), the panel check should\nbe overriding allowed() method instead. Overriding can_access()\nwill disable caching for the method.\n\nChange-Id: Ibee85cdcf505e90d9faeb54dbab7216fc24c1b2c\nCloses-Bug: #1403701\n'}]",0,142687,9fae45cde101188c6541a951df78fb4e17c13822,19,10,1,1941,,,0,"Fix Firewalls panel to override the right method

Instead of overriding can_acess(), the panel check should
be overriding allowed() method instead. Overriding can_access()
will disable caching for the method.

Change-Id: Ibee85cdcf505e90d9faeb54dbab7216fc24c1b2c
Closes-Bug: #1403701
",git fetch https://review.opendev.org/openstack/horizon refs/changes/87/142687/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/admin/aggregates/panel.py'],1,9fae45cde101188c6541a951df78fb4e17c13822,bug/1403701," def allowed(self, context): return super(Aggregates, self).allowed(context)"," def can_access(self, context): return super(Aggregates, self).can_access(context)",2,2
openstack%2Fdevstack~master~I2b2d61673c3c95f60c56978b5a81016603fef252,openstack/devstack,master,I2b2d61673c3c95f60c56978b5a81016603fef252,Fix typo errors in devstack documentation,MERGED,2014-12-19 12:11:39.000000000,2014-12-20 17:19:39.000000000,2014-12-20 17:19:38.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-19 12:11:39.000000000', 'files': ['doc/source/local.conf.rst', 'doc/source/contributing.rst', 'doc/source/faq.rst', 'doc/source/openrc.rst', 'doc/source/exerciserc.rst'], 'web_link': 'https://opendev.org/openstack/devstack/commit/933827cccea4d0866ecac9513a5f3ebeb90749ff', 'message': 'Fix typo errors in devstack documentation\n\nThis submission fixes typo errors in following files\n  1. contributing.rst\n  2. exerciserc.rst\n  3. faq.rst\n  4. local.conf.rst\n  5. openrc.rst\n\nChange-Id: I2b2d61673c3c95f60c56978b5a81016603fef252\n'}]",0,143065,933827cccea4d0866ecac9513a5f3ebeb90749ff,11,3,1,1037,,,0,"Fix typo errors in devstack documentation

This submission fixes typo errors in following files
  1. contributing.rst
  2. exerciserc.rst
  3. faq.rst
  4. local.conf.rst
  5. openrc.rst

Change-Id: I2b2d61673c3c95f60c56978b5a81016603fef252
",git fetch https://review.opendev.org/openstack/devstack refs/changes/65/143065/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/local.conf.rst', 'doc/source/contributing.rst', 'doc/source/faq.rst', 'doc/source/openrc.rst', 'doc/source/exerciserc.rst']",5,933827cccea4d0866ecac9513a5f3ebeb90749ff,separate/devstack_doc_changes,The values shown below are the default values. These can all be,The values shown below are the default values. Thse can all be,5,5
openstack%2Ftraining-guides~master~I552f79eaee23d8ba07812a4b20d6b7a231b979b1,openstack/training-guides,master,I552f79eaee23d8ba07812a4b20d6b7a231b979b1,Imported Translations from Transifex,MERGED,2014-12-15 06:00:17.000000000,2014-12-20 16:56:28.000000000,2014-12-20 16:56:28.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-12-15 06:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/cc4c90801a4a0bfa918db85c857a0ad4c0caa565', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I552f79eaee23d8ba07812a4b20d6b7a231b979b1\n'}, {'number': 2, 'created': '2014-12-16 06:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/9f0b12a6a331b469b2a6af5867cb9489b364f5cb', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I552f79eaee23d8ba07812a4b20d6b7a231b979b1\n'}, {'number': 3, 'created': '2014-12-19 06:00:53.000000000', 'files': ['doc/training-guides/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/70061b590b846251a33e645d86dfa97d44b35d31', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I552f79eaee23d8ba07812a4b20d6b7a231b979b1\n'}]",0,141718,70061b590b846251a33e645d86dfa97d44b35d31,11,3,3,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I552f79eaee23d8ba07812a4b20d6b7a231b979b1
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/18/141718/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/locale/ja.po'],1,cc4c90801a4a0bfa918db85c857a0ad4c0caa565,transifex/translations,"""POT-Creation-Date: 2014-12-14 22:48+0000\n"" ""PO-Revision-Date: 2014-12-15 01:10+0000\n""msgstr ""ユーザーストーリーの外部コンテンツの取り込み、バージョン 1.3""msgstr ""SSH と FTP をインストールすることにより便利になります。VirtualBox の画面から仮想マシンの tty を使用するより便利に、マシンにログインするためにリモートシェルを使用して、ターミナルを使用できるようになります。仮想マシンを直接できないような、リモートターミナルにコマンドをコピーと貼り付けするなどの追加機能を利用できます。""msgstr ""FTP は、ローカルマシンと仮想マシンでファイルを転送するためです。SFTP を使用することもできます。また、ホストと仮想マシンの両方に FTPD をインストールすることもできます。""msgstr ""SSH と FTP のインストールおよび設定手順は、このガイドの範囲外です。""msgstr ""マシンから SSH と FTP を実行する前に、仮想マシン内からネットワークを設定します。""msgstr ""オペレーティングシステムのインストール中に、個別にインストールするソフトウェアを確認されます。与えられたオプションを何も選択せずに <keycap>Enter</keycap> キーを押して、この手順をスキップできます。""msgstr ""この手順に慣れている方以外は、以下に示されたパッケージ以外のパッケージを何もインストールしないでください。""msgstr ""適切なメモリー量を選択します。コントローラーノードは、512 MB メモリーが最小です。他はデフォルトを使用します。ディスク容量は 8 GB にします。""msgstr ""(ここでは、IP アドレスを無視します。仮想マシンの中から設定します。)""msgstr ""インストールする個別ソフトウェアを確認されたとき、SSH サーバーをインストールします。(高度なユーザーでなければ) 残りのパッケージは必要ありません。DNS サーバーなどは、OpenStack パッケージに合わせてインストールされるかもしれません。""msgstr ""最小メモリーの 512 MB で新規仮想マシンを作成します。残りは、デフォルトのままにしておきます。最小ディスク容量は 8 GB です。""msgstr ""インストールする個別ソフトウェアを確認されたとき、SSH サーバーをインストールします。残りのパッケージは必要ありません。DNS サーバーなどは、OpenStack パッケージに合わせてインストールされるかもしれません。""msgstr ""少なくとも 1,000 MB メモリーと 8 GB ディスクを持つ仮想マシンを作成します。他の設定は、デフォルトのままにしておきます。""msgstr ""インストールする個別ソフトウェアを確認されたとき、SSH サーバーをインストールします。残りのパッケージは必要ありません。DNS サーバーなどは、OpenStack パッケージに合わせてインストールされるかもしれません。""msgstr ""おめでとうございます。これで OpenStack を導入するための基盤がセットアップされました。Ubuntu Server がここまでにセットアップした VirtualBox 仮想マシンにきちんとインストールされていること確認します。次のセクションにおいて、この仮想マシンを使用して OpenStack を導入していきます。""msgstr ""GitHub のユーザー名とパスワードを追加します。""msgstr ""ローカルリポジトリーの場所を設定します。""msgstr ""RPC コール""msgstr ""RPC コール""msgstr ""AMQP ブローカーロード""msgstr ""オープンソースです。""msgstr ""プロジェクトの歴史とリリースの概要。""","""POT-Creation-Date: 2014-12-08 10:05+0000\n"" ""PO-Revision-Date: 2014-12-13 11:10+0000\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"",24,24
openstack%2Ftraining-guides~master~I4cc99cd7f00bdd8bb2bceac2ff6648558323e181,openstack/training-guides,master,I4cc99cd7f00bdd8bb2bceac2ff6648558323e181,Updated from openstack-manuals,MERGED,2014-12-15 06:43:47.000000000,2014-12-20 16:55:47.000000000,2014-12-20 16:55:46.000000000,"[{'_account_id': 3}, {'_account_id': 7007}]","[{'number': 1, 'created': '2014-12-15 06:43:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/54364262b39db9d8e368bc012033e9c01eb2b0a7', 'message': 'Updated from openstack-manuals\n\nChange-Id: I4cc99cd7f00bdd8bb2bceac2ff6648558323e181\n'}, {'number': 2, 'created': '2014-12-16 07:29:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/77b2c0243520feedaead2476daa9de99559f8f15', 'message': 'Updated from openstack-manuals\n\nChange-Id: I4cc99cd7f00bdd8bb2bceac2ff6648558323e181\n'}, {'number': 3, 'created': '2014-12-19 06:37:19.000000000', 'files': ['doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/771ff418471025ac408ea93b1d9597d8c3f7a03a', 'message': 'Updated from openstack-manuals\n\nChange-Id: I4cc99cd7f00bdd8bb2bceac2ff6648558323e181\n'}]",0,141733,771ff418471025ac408ea93b1d9597d8c3f7a03a,10,2,3,11131,,,0,"Updated from openstack-manuals

Change-Id: I4cc99cd7f00bdd8bb2bceac2ff6648558323e181
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/33/141733/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/locale/ja.po'],1,54364262b39db9d8e368bc012033e9c01eb2b0a7,openstack/openstack-manuals,"""POT-Creation-Date: 2014-12-15 00:16+0000\n"" ""PO-Revision-Date: 2014-12-15 01:50+0000\n""msgstr ""認証局。暗号において、電子証明書を発行するエンティティー。電子証明書は、証明書の発行先の名前により公開鍵の所有者を証明する。これにより、他の信頼される機関が証明書を信頼できるようになる。また、証明された公開鍵に対応する秘密鍵による表明を信頼できるようになる。この信頼関係のモデルにおいて、CA は証明書の発行先と証明書を信頼している機関の両方に対する信頼された第三者機関である。CA は、多くの公開鍵基盤 (PKI) スキームの特徴である。""msgstr ""cloud-init 同様のゲスト初期化機能を提供する Windows プロジェクト。""msgstr ""サーバーの再起動時に有効なままになる Compute の RabbitMQ メッセージ交換。""msgstr ""ホストの起動時にネットワークを自動的に設定する方式。Networking と Compute により提供される。""msgstr ""別々のルーティングテーブルとインターフェースを持つ単一のホストにおいて、独立した仮想ネットワークインターフェースを提供する Linux カーネル機能。物理ネットワーク環境における仮想ルーティングおよびフォワーディング (VRF) サービスと似ている。""msgstr ""ルーター通知デーモン。仮想マシンインスタンスにルーティングサービスを提供するために、Compute の VLAN マネージャーと FlatDHCP マネージャーにより使用される。""msgstr ""自動的にカタログに登録するために、Compute などのサービスを有効化する、Identity の機能。""msgstr ""Identity と安全に通信するために Compute により使用される、管理者により定義されたトークン。""msgstr ""複数の仮想マシンを使用して、物理ネットワーク上にオーバーレイされる、スイッチング、ルーティング、負荷分散、セキュリティなどのネットワーク機能の仮想化に関する一般的な用語。""","""POT-Creation-Date: 2014-12-12 04:44+0000\n"" ""PO-Revision-Date: 2014-12-12 04:50+0000\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"",11,11
openstack%2Fcinder-specs~master~Id3a30750c71a6013e131939c9b77f6e0fbed6f01,openstack/cinder-specs,master,Id3a30750c71a6013e131939c9b77f6e0fbed6f01,Allow cinder-volume to manage LVM on separate host,ABANDONED,2014-07-04 10:41:49.000000000,2014-12-20 16:18:52.000000000,,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 7219}]","[{'number': 1, 'created': '2014-07-04 10:41:49.000000000', 'files': ['specs/juno/remote-lvm-driver.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/ecbc069ce9653d94eec8758e8bf92095a08f58e1', 'message': 'Allow cinder-volume to manage LVM on separate host\n\nCurrently the LVM driver requires cinder-volume to be located on the\nsame hardware as the volumes themselves. This blueprint proposes\nproviding the option to decouple the two so that cinder-volume can be on\none host and the LVM backend on another.\n\nblueprint remote-lvm-driver\n\nChange-Id: Id3a30750c71a6013e131939c9b77f6e0fbed6f01\n'}]",0,104864,ecbc069ce9653d94eec8758e8bf92095a08f58e1,8,3,1,7219,,,0,"Allow cinder-volume to manage LVM on separate host

Currently the LVM driver requires cinder-volume to be located on the
same hardware as the volumes themselves. This blueprint proposes
providing the option to decouple the two so that cinder-volume can be on
one host and the LVM backend on another.

blueprint remote-lvm-driver

Change-Id: Id3a30750c71a6013e131939c9b77f6e0fbed6f01
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/64/104864/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/remote-lvm-driver.rst'],1,ecbc069ce9653d94eec8758e8bf92095a08f58e1,bp/proposes,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Remote LVM driver ========================================== https://blueprints.launchpad.net/cinder/+spec/remote-lvm-driver Currently the LVM driver requires cinder-volume to be located on the same hardware as the volumes themselves. This blueprint proposes providing the option to decouple the two so that cinder-volume can be on one host and the LVM backend on another. Problem description =================== The current implementation of the LVM driver requires that the storage be on the same host as the cinder-volume service. This contrasts with vendor drivers where the two are separate. This makes using the LVM driver a less flexible option in terms of deploying and manageing the cinder-volume service. * if cinder-volume is wholey defined by its configuration files different strategies can be employed to manage the service. For example, the service could be containerised. Upgrading the service could be as simple as replacing the container. * used in conjunction with multi-backend would allow one cinder-volume service to manage multiple LVM hosts * there are proposals to replace the file lock mechanism, this would allow the cinder-volume service to be completely decoupled from a specific LVM host when used in conjunction with the changes proposed here. Proposed change =============== I believe the appropriate course of action would be to extend the LVMVolumeDriver. A configuration option would specify whether the driver was managing LVM locally or remotely. The remote management would be done via SSH. The brick code would need to include additional code to support managing LVM and iSCSI over SSH. Mostly this involves making sure that the execute function used throughout the code can always be overriden. I have also found a number of file operations that are done directly using python, these would need to be reworked. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- * SSH access to a remote host, therefore management of key or password. * Sudo access on the remote host. * I don't believe cinder-rootwrap is compatible with running commands remotely. Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ There will be additional latency due to the cinder-volume service now having to manage a remote system. This should not have any noticeable impact and should no greater that that seen with vendor systems. Other deployer impact --------------------- Configuration options will be required to specify that the LVM driver will be managing a remote system as well as to allow details of the host and SSH credentials. Existing deployments will be unaffected because default LVM behaviour will not change. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: git-harry Work Items ---------- * Extend brick code to support remote management * Extend LVMVolumeDriver to support remote management Dependencies ============ None Testing ======= My understanding of tempest is that the test is on a single host, this means that addtional tests can be added but will not be able to completely guarantee that the code is not running some things locally. Documentation Impact ==================== The new configuration options will need documenting. There should be limited additional impact because this feature is an extension of the existing functionality. References ========== None ",,145,0
openstack%2Foslotest~master~I445c2a24850059897b4e76ff29ef77f3baf84021,openstack/oslotest,master,I445c2a24850059897b4e76ff29ef77f3baf84021,Fix for mktemp failure on osx,MERGED,2014-12-20 00:38:36.000000000,2014-12-20 15:01:13.000000000,2014-12-20 15:01:13.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-12-20 00:38:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslotest/commit/661f1b10bce6bf39e86429cbe0de55edb6ef62cc', 'message': 'Fix for mktemp failure on osx\n\nChange-Id: I445c2a24850059897b4e76ff29ef77f3baf84021\n'}, {'number': 2, 'created': '2014-12-20 00:43:33.000000000', 'files': ['tools/oslo_debug_helper'], 'web_link': 'https://opendev.org/openstack/oslotest/commit/baf76c59866daab6829046bea22f1e38b7602b79', 'message': 'Fix for mktemp failure on osx\n\nCloses-Bug: #1404422\nChange-Id: I445c2a24850059897b4e76ff29ef77f3baf84021\n'}]",0,143227,baf76c59866daab6829046bea22f1e38b7602b79,7,2,2,5638,,,0,"Fix for mktemp failure on osx

Closes-Bug: #1404422
Change-Id: I445c2a24850059897b4e76ff29ef77f3baf84021
",git fetch https://review.opendev.org/openstack/oslotest refs/changes/27/143227/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/oslo_debug_helper'],1,661f1b10bce6bf39e86429cbe0de55edb6ef62cc,bug/1404422,TMP_DIR=`mktemp -d debug-$$-XXX` || exit 1,TMP_DIR=`mktemp -d` || exit 1,1,1
openstack%2Fheat-translator~master~Ife4e88a48a4b4336590d168682e6f75dd39d15bd,openstack/heat-translator,master,Ife4e88a48a4b4336590d168682e6f75dd39d15bd,Sort TOSCA relation output for a match to expected test result,MERGED,2014-12-20 00:28:36.000000000,2014-12-20 14:37:15.000000000,2014-12-20 14:37:15.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 6460}]","[{'number': 1, 'created': '2014-12-20 00:28:36.000000000', 'files': ['translator/toscalib/tests/test_toscatpl.py'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/2b3c3b045490d94d78c5f46d59ac72877ae6de3f', 'message': 'Sort TOSCA relation output for a match to expected test result\n\nThe TOSCA parser test test_template_requirements fails assertEqual due\nto an unsorted output list.\n\nChange-Id: Ife4e88a48a4b4336590d168682e6f75dd39d15bd\nCloses-Bug: #1404420\n'}]",0,143225,2b3c3b045490d94d78c5f46d59ac72877ae6de3f,7,3,1,6456,,,0,"Sort TOSCA relation output for a match to expected test result

The TOSCA parser test test_template_requirements fails assertEqual due
to an unsorted output list.

Change-Id: Ife4e88a48a4b4336590d168682e6f75dd39d15bd
Closes-Bug: #1404420
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/25/143225/1 && git format-patch -1 --stdout FETCH_HEAD,['translator/toscalib/tests/test_toscatpl.py'],1,2b3c3b045490d94d78c5f46d59ac72877ae6de3f,," ('tosca.relationships.ConnectsTo', 'mysql_database'), ('tosca.relationships.HostedOn', 'my_webserver')] actual_relationship = sorted([ relation, node in node_tpl.relationship.items()])"," ('tosca.relationships.HostedOn', 'my_webserver'), ('tosca.relationships.ConnectsTo', 'mysql_database')] actual_relationship = [ relation, node in node_tpl.relationship.items()]",4,4
openstack%2Fcinder~master~I43a11c065799efe6f5b81dc15e1f7232c80d1070,openstack/cinder,master,I43a11c065799efe6f5b81dc15e1f7232c80d1070,Mock leaked _execute() calls in driver tests,MERGED,2014-12-19 23:46:50.000000000,2014-12-20 13:55:31.000000000,2014-12-20 06:44:48.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 6491}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 14206}]","[{'number': 1, 'created': '2014-12-19 23:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7abe1bd78e8a36086ba639b901ff6df85dc0bc4c', 'message': 'Mock leaked _execute() calls in driver tests\n\nSome drivers have _execute() calls being linked, causing tests to prompt\nfor password and eventual fail for time out. This prevents those\n\t_execute calls from happening.\n\nCloses-Bug: #1404414\nChange-Id: I43a11c065799efe6f5b81dc15e1f7232c80d1070\n'}, {'number': 2, 'created': '2014-12-19 23:48:17.000000000', 'files': ['cinder/tests/test_huaweistorac.py', 'cinder/tests/test_zfssa.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b5d6e297382f832a8896c9f045a65ecef0fe139e', 'message': 'Mock leaked _execute() calls in driver tests\n\nSome drivers have _execute() calls being linked, causing tests to prompt\nfor password and eventual fail for time out. This prevents those\n_execute calls from happening.\n\nCloses-Bug: #1404414\nChange-Id: I43a11c065799efe6f5b81dc15e1f7232c80d1070\n'}]",0,143218,b5d6e297382f832a8896c9f045a65ecef0fe139e,17,11,2,170,,,0,"Mock leaked _execute() calls in driver tests

Some drivers have _execute() calls being linked, causing tests to prompt
for password and eventual fail for time out. This prevents those
_execute calls from happening.

Closes-Bug: #1404414
Change-Id: I43a11c065799efe6f5b81dc15e1f7232c80d1070
",git fetch https://review.opendev.org/openstack/cinder refs/changes/18/143218/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_huaweistorac.py', 'cinder/tests/test_zfssa.py']",2,7abe1bd78e8a36086ba639b901ff6df85dc0bc4c,bug/1404414,from cinder.tests import fake_utils iscsi.ZFSSAISCSIDriver._execute = fake_utils.fake_execute self.drv._execute = fake_utils.fake_execute,,7,1
openstack%2Fcinder~master~I010be0c70589459a488cdef7cd83380eab27c61c,openstack/cinder,master,I010be0c70589459a488cdef7cd83380eab27c61c,LVM: Volume is deleted unexpectedly during volume migration,MERGED,2014-12-18 22:48:28.000000000,2014-12-20 12:59:50.000000000,2014-12-20 07:04:55.000000000,"[{'_account_id': 3}, {'_account_id': 1773}, {'_account_id': 2243}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 9176}, {'_account_id': 10115}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 14206}]","[{'number': 1, 'created': '2014-12-18 22:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1266722e20f8702ab95c512031dd4654d442886d', 'message': 'LVM: Volume is deleted unexpectedly during volume migration\n\nWhen using LVMISCSIDriver, a volume is unexpectedly deleted during\nvolume migration operation. This problem only occurs when the\nvolume_group of backend A and backend B is same value such as\nmisconfiguration. Even if the configuration is wrong, cinder should\nnot delete the volume unexpectedly for user.\n\nCloses-Bug #1404013\nChange-Id: I010be0c70589459a488cdef7cd83380eab27c61c\n'}, {'number': 2, 'created': '2014-12-18 23:18:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/10b1df7de706ec9c91577e91dbe7b22ba0318ed6', 'message': 'LVM: Volume is deleted unexpectedly during volume migration\n\nWhen using LVMISCSIDriver, a volume is unexpectedly deleted during\nvolume migration operation. This problem only occurs when the\nvolume_group of backend A and backend B is same value such as\nmisconfiguration. Even if the configuration is wrong, cinder should\nnot delete the volume unexpectedly for user.\n\nCloses-Bug: 1404013\nChange-Id: I010be0c70589459a488cdef7cd83380eab27c61c\n'}, {'number': 3, 'created': '2014-12-19 16:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/382bf24416bc08f9a905dca45f1a56e97f314f77', 'message': 'LVM: Volume is deleted unexpectedly during volume migration\n\nWhen using LVMISCSIDriver, a volume is unexpectedly deleted during\nvolume migration operation. This problem only occurs when the\nvolume_group of backend A and backend B is same value such as\nmisconfiguration. Even if the configuration is wrong, cinder should\nnot delete the volume unexpectedly for user.\n\nCloses-Bug: 1404013\nChange-Id: I010be0c70589459a488cdef7cd83380eab27c61c\n'}, {'number': 4, 'created': '2014-12-19 21:22:49.000000000', 'files': ['cinder/tests/test_volume.py', 'cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/37e35047062b66321f9af6393b2b1c609af54e1a', 'message': 'LVM: Volume is deleted unexpectedly during volume migration\n\nWhen using LVMISCSIDriver, a volume is unexpectedly deleted during\nvolume migration operation. This problem only occurs when the\nvolume_group of backend A and backend B is same value such as\nmisconfiguration. Even if the configuration is wrong, cinder should\nnot delete the volume unexpectedly for user.\n\nCloses-Bug: 1404013\nChange-Id: I010be0c70589459a488cdef7cd83380eab27c61c\n'}]",6,142922,37e35047062b66321f9af6393b2b1c609af54e1a,41,17,4,10115,,,0,"LVM: Volume is deleted unexpectedly during volume migration

When using LVMISCSIDriver, a volume is unexpectedly deleted during
volume migration operation. This problem only occurs when the
volume_group of backend A and backend B is same value such as
misconfiguration. Even if the configuration is wrong, cinder should
not delete the volume unexpectedly for user.

Closes-Bug: 1404013
Change-Id: I010be0c70589459a488cdef7cd83380eab27c61c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/22/142922/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/lvm.py'],1,1266722e20f8702ab95c512031dd4654d442886d,bug/1404013," volutils.copy_volume(self.local_path(volume), self.local_path(volume, vg=dest_vg), volume['size'], self.configuration.volume_dd_blocksize, execute=self._execute) self._delete_volume(volume) model_update = self._create_export(ctxt, volume, vg=dest_vg) return (True, model_update) else: message = (_LW(""Source and Destination Volume Groups are same "" ""on the same host. VG:%s."") % self.vg.vg_name) LOG.warning(message) return false_ret"," volutils.copy_volume(self.local_path(volume), self.local_path(volume, vg=dest_vg), volume['size'], self.configuration.volume_dd_blocksize, execute=self._execute) self._delete_volume(volume) model_update = self._create_export(ctxt, volume, vg=dest_vg) return (True, model_update)",14,8
openstack%2Frally~master~Ia38c8fc2d692a09719d3e068d332647d4b0da47f,openstack/rally,master,Ia38c8fc2d692a09719d3e068d332647d4b0da47f,Cover Rally with docstrings & Test this coverage,MERGED,2014-10-09 10:29:59.000000000,2014-12-20 12:35:40.000000000,2014-12-20 12:35:38.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 8367}, {'_account_id': 8507}, {'_account_id': 9545}, {'_account_id': 10475}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-10-09 10:29:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/13a98bdc86fd4403b649693956466a7bef03b4ec', 'message': 'Test that Rally is covered with docstrings\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 2, 'created': '2014-10-09 10:30:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/326288b58643352e6dff7c86d9b1d7784bd51959', 'message': 'Test that Rally is covered with docstrings\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 3, 'created': '2014-10-09 10:31:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d6de684868878d1dfac2bf834ef6ad098e3c1202', 'message': 'Test that Rally is covered with docstrings\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 4, 'created': '2014-10-09 10:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/744813e1d9597be1e48024a42ed79218ea3247ad', 'message': 'Test that Rally is covered with docstrings\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 5, 'created': '2014-10-09 10:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5ffe186755d2a4b5c484bdc6bf041593fcd4efbc', 'message': 'Test that Rally is covered with docstrings\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 6, 'created': '2014-10-09 11:20:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/67d0817bacc3beae8f76366fecb290add2ac64b4', 'message': 'Test that Rally is covered with docstrings\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 7, 'created': '2014-10-13 08:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0160cffb37dbb2b32023b91801132957e27eeb60', 'message': 'Test that Rally is covered with docstrings\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 8, 'created': '2014-10-13 08:14:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/11b72b4b5674ba3acdfbc4025c916e1b2bdcd13e', 'message': 'Test that Rally is covered with docstrings\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 9, 'created': '2014-10-13 08:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/eac1107bb9a07263c77fe6da899db6edce3ac9e6', 'message': 'Test that Rally is covered with docstrings\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 10, 'created': '2014-10-13 09:21:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e5cb2be0ffd0d63ba0af61b8e5476470491d1a7c', 'message': 'Test that Rally is covered with docstrings\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 11, 'created': '2014-10-13 10:07:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4fdd2c0c687a56eadcac949d272eb7ac9febdb1c', 'message': 'Test that Rally is covered with docstrings\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 12, 'created': '2014-11-15 13:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b69dbe97a6d919261327f33437f9256a75acdacc', 'message': 'Test that Rally is covered with docstrings\n\nTODO: Complete all docstrings so that these tests pass (in this patch).\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 13, 'created': '2014-11-16 10:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/60b45f8139db0619ffd6c67e6fa5b3e822616ef0', 'message': 'Cover Rally with docstrings & Test this coverage (WIP)\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 14, 'created': '2014-12-04 11:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/00dd6c30a69ecc2bc1709754fdbef5988648acc5', 'message': 'Cover Rally with docstrings & Test this coverage (WIP)\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 15, 'created': '2014-12-04 13:42:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d5bb4954e7fc11a93d5fae4fdd5f8fcd5fcad79f', 'message': 'Cover Rally with docstrings & Test this coverage (WIP)\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 16, 'created': '2014-12-04 15:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1800d1b3b427cb10af13c7d006c9f34bae5b6717', 'message': 'Cover Rally with docstrings & Test this coverage (WIP)\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 17, 'created': '2014-12-04 16:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ebb94ecedd0745afae16a1455848e962609061db', 'message': 'Cover Rally with docstrings & Test this coverage (WIP)\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 18, 'created': '2014-12-04 19:57:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/01808e543107b27b8a55074c2cc34b5e9582f475', 'message': 'Cover Rally with docstrings & Test this coverage (WIP)\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 19, 'created': '2014-12-04 19:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/333b1975c7ee13038ac9df710d94f942a1fe71e4', 'message': 'Cover Rally with docstrings & Test this coverage (WIP)\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 20, 'created': '2014-12-04 20:10:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ed8d02fe255624efba8f79bca54af0023fd5829d', 'message': 'Cover Rally with docstrings & Test this coverage (WIP)\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 21, 'created': '2014-12-04 21:35:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/be12048deee36e24f7050175ec6955a8845f832b', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 22, 'created': '2014-12-04 21:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3e32553f3124117b89f1d673466c8b3b4a7d9ba9', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 23, 'created': '2014-12-04 22:44:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5f1dff2a632820f6b50f2d3010902955e9310b0d', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 24, 'created': '2014-12-05 08:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/42b270a9e802b210ae2c3e32777e3c0373c42320', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 25, 'created': '2014-12-05 08:37:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/16825b1079e127a1e184a2858ec9a1ec5de45866', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 26, 'created': '2014-12-08 11:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ab06f4a1a9ed901256f145fe447e0d449a4662c8', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 27, 'created': '2014-12-08 11:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/dc684587e9f3f3e110b188b931cc5c90f9692159', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 28, 'created': '2014-12-11 12:14:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a8adba505f41125ec14936f4dffee6b2df90bd23', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 29, 'created': '2014-12-12 22:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/caad7f4e0c04c404577ede36ddba4d3373a4bb6f', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 30, 'created': '2014-12-15 21:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c8f102e5ef153c6dbceb40fb0f8758205931db9a', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 31, 'created': '2014-12-15 23:08:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3661d954a2a8454938140d2557a92302a93c63c5', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 32, 'created': '2014-12-16 09:26:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f160ceaa08b4329a7d6f79ca67840c2b91b8415e', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 33, 'created': '2014-12-18 13:58:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d8c87eb7bfa6dc45efea9246082d40852e32b123', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 34, 'created': '2014-12-18 13:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a375932bc12012661f982caee246afb057fb3a31', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 35, 'created': '2014-12-18 15:06:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1ad5a241a1a9555291c4fa4e773d3dbee4b02c4d', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 36, 'created': '2014-12-18 17:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/186f3e3ac9481f08ea35b828d12b734b30e7747c', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 37, 'created': '2014-12-18 18:45:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/caaa3318716e322c1c9dc3df4588ef7a12e15af5', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 38, 'created': '2014-12-18 19:38:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0bec88eee5ab6794581c430fade1ae50e3eb6c13', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 39, 'created': '2014-12-19 10:38:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b81560f7c1b2fbc27590ae2e7afe82a21713b7e0', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nWe also change the interface of the following benchmark scenarios\n(for the sake of unification):\n* CinderVolumes.create_and_attach_volume\n* CinderVolumes.create_snapshot_and_attach_volume\n* CinderVolumes.create_nested_snapshots_and_attach_volume\n\nFinally, we refactor a bit NovaServers.boot_and_bounce_server.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 40, 'created': '2014-12-19 10:59:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/363db583ab7f15dd0924c8cf722a08772d87e58c', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nWe also change the interface of the following benchmark scenarios\n(for the sake of unification):\n* CinderVolumes.create_and_attach_volume\n* CinderVolumes.create_snapshot_and_attach_volume\n* CinderVolumes.create_nested_snapshots_and_attach_volume\n\nFinally, we refactor a bit NovaServers.boot_and_bounce_server.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 41, 'created': '2014-12-20 11:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5b9acbe60e672c5f711eb9615404d619966390c4', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nWe also change the interface of the following benchmark scenarios\n(for the sake of unification):\n* CinderVolumes.create_and_attach_volume\n* CinderVolumes.create_snapshot_and_attach_volume\n* CinderVolumes.create_nested_snapshots_and_attach_volume\n\nFinally, we refactor a bit NovaServers.boot_and_bounce_server.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 42, 'created': '2014-12-20 11:12:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3162e16a53b017a7425d809b130dde889267cc7d', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nWe also change the interface of the following benchmark scenarios\n(for the sake of unification):\n* CinderVolumes.create_and_attach_volume\n* CinderVolumes.create_snapshot_and_attach_volume\n* CinderVolumes.create_nested_snapshots_and_attach_volume\n\nFinally, we refactor a bit NovaServers.boot_and_bounce_server.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}, {'number': 43, 'created': '2014-12-20 11:14:13.000000000', 'files': ['tests/unit/deploy/serverprovider/test_provider.py', 'rally/benchmark/scenarios/heat/stacks.py', 'rally/benchmark/scenarios/sahara/jobs.py', 'rally/benchmark/scenarios/zaqar/utils.py', 'rally/benchmark/scenarios/ceilometer/queries.py', 'rally/benchmark/scenarios/cinder/utils.py', 'rally/benchmark/scenarios/dummy/dummy.py', 'doc/samples/tasks/scenarios/cinder/create-snapshot-and-attach-volume.json', 'rally/benchmark/scenarios/cinder/volumes.py', 'rally/benchmark/scenarios/glance/utils.py', 'rally/benchmark/scenarios/ceilometer/utils.py', 'doc/samples/tasks/scenarios/cinder/create_nested_snapshots_and_attach_volume.yaml', 'rally-jobs/rally.yaml', 'rally/benchmark/scenarios/vm/utils.py', 'rally/benchmark/scenarios/sahara/node_group_templates.py', 'rally/benchmark/scenarios/zaqar/basic.py', 'rally/benchmark/scenarios/sahara/clusters.py', 'rally-jobs/plugins/fake_plugin.py', 'rally/benchmark/scenarios/neutron/utils.py', 'rally/benchmark/scenarios/requests/http_requests.py', 'rally/benchmark/scenarios/keystone/utils.py', 'doc/samples/tasks/scenarios/cinder/create-and-attach-volume.json', 'tests/unit/benchmark/scenarios/nova/test_servers.py', 'rally/benchmark/scenarios/glance/images.py', 'rally/benchmark/scenarios/authenticate/authenticate.py', 'rally/benchmark/scenarios/nova/security_group.py', 'rally/benchmark/scenarios/quotas/utils.py', 'rally/utils.py', 'rally/benchmark/scenarios/sahara/utils.py', 'doc/samples/tasks/scenarios/cinder/create-snapshot-and-attach-volume.yaml', 'rally/benchmark/scenarios/heat/utils.py', 'rally/benchmark/scenarios/ceilometer/resources.py', 'rally/benchmark/scenarios/vm/vmtasks.py', 'rally/benchmark/scenarios/keystone/basic.py', 'rally/benchmark/scenarios/quotas/quotas.py', 'rally/benchmark/scenarios/designate/basic.py', 'rally/benchmark/scenarios/ceilometer/alarms.py', 'doc/samples/plugins/scenario/scenario_plugin.py', 'rally/aas/rest/app.py', 'rally/benchmark/scenarios/ceilometer/meters.py', 'rally/benchmark/scenarios/nova/utils.py', 'doc/samples/tasks/scenarios/cinder/create_nested_snapshots_and_attach_volume.json', 'rally/benchmark/scenarios/nova/servers.py', 'rally/sshutils.py', 'doc/samples/tasks/scenarios/cinder/create-and-attach-volume.yaml', 'rally/benchmark/scenarios/neutron/network.py', 'tests/unit/benchmark/sla/test_base.py', 'tests/unit/fakes.py', 'tests/unit/test_docstrings.py', 'tests/unit/deploy/test_engine.py', 'rally/benchmark/scenarios/designate/utils.py', 'rally/benchmark/scenarios/ceilometer/stats.py', 'rally/benchmark/scenarios/tempest/tempest.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/07bbc3094d9b8838bdebcb42dbcc43cc515bc582', 'message': 'Cover Rally with docstrings & Test this coverage\n\nRally should have detailed docstrings for:\n* Benchmark scenario classes\n* Benchmark scenarios\n* Deploy engines\n* Server providers\n* SLA\n\nHere we add such docstrings and also add a test suite that checks\nthat Rally is 100% covered with docstrings and that these docstrings\nare correctly formed.\n\nWe also change the interface of the following benchmark scenarios\n(for the sake of unification):\n* CinderVolumes.create_and_attach_volume\n* CinderVolumes.create_snapshot_and_attach_volume\n* CinderVolumes.create_nested_snapshots_and_attach_volume\n\nFinally, we refactor a bit NovaServers.boot_and_bounce_server.\n\nChange-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f\n'}]",193,127192,07bbc3094d9b8838bdebcb42dbcc43cc515bc582,114,7,43,8507,,,0,"Cover Rally with docstrings & Test this coverage

Rally should have detailed docstrings for:
* Benchmark scenario classes
* Benchmark scenarios
* Deploy engines
* Server providers
* SLA

Here we add such docstrings and also add a test suite that checks
that Rally is 100% covered with docstrings and that these docstrings
are correctly formed.

We also change the interface of the following benchmark scenarios
(for the sake of unification):
* CinderVolumes.create_and_attach_volume
* CinderVolumes.create_snapshot_and_attach_volume
* CinderVolumes.create_nested_snapshots_and_attach_volume

Finally, we refactor a bit NovaServers.boot_and_bounce_server.

Change-Id: Ia38c8fc2d692a09719d3e068d332647d4b0da47f
",git fetch https://review.opendev.org/openstack/rally refs/changes/92/127192/9 && git format-patch -1 --stdout FETCH_HEAD,['tests/unit/test_docstrings.py'],1,13a98bdc86fd4403b649693956466a7bef03b4ec,docstrings,"# Copyright 2014: Mirantis Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import traceback import mock from rally.benchmark.scenarios import base from rally import utils from rally import consts from rally import exceptions from tests.unit import fakes from tests.unit import test class ScenarioDocstringsTestCase(test.TestCase): def test_all_scenarios_have_docstrings(self): for scenario_group in utils.itersubclasses(base.Scenario): for method in dir(scenario_group): if Scenario.is_scenario(scenario_group, method): scenario = getattr(scenario_group, method) self.assertIsNotNone(scenario.__doc__) def test_get_by_name_not_found(self): self.assertRaises(exceptions.NoSuchScenario, base.Scenario.get_by_name, ""non existing scenario"") def test_get_scenario_by_name(self): scenario_method = base.Scenario.get_scenario_by_name(""Dummy.dummy"") self.assertEqual(dummy.Dummy.dummy, scenario_method) def test_get_scenario_by_name_shortened(self): scenario_method = base.Scenario.get_scenario_by_name(""dummy"") self.assertEqual(dummy.Dummy.dummy, scenario_method) def test_get_scenario_by_name_shortened_not_found(self): self.assertRaises(exceptions.NoSuchScenario, base.Scenario.get_scenario_by_name, ""dumy"") def test_get_scenario_by_name_bad_group_name(self): self.assertRaises(exceptions.NoSuchScenario, base.Scenario.get_scenario_by_name, ""Dumy.dummy"") def test_get_scenario_by_name_bad_scenario_name(self): self.assertRaises(exceptions.NoSuchScenario, base.Scenario.get_scenario_by_name, ""Dummy.dumy"") def test__validate_helper(self): validators = [ mock.MagicMock(return_value=validation.ValidationResult()), mock.MagicMock(return_value=validation.ValidationResult()) ] clients = mock.MagicMock() config = {""a"": 1, ""b"": 2} task = mock.MagicMock() base.Scenario._validate_helper(validators, clients, config, task) for validator in validators: validator.assert_called_with(config, clients=clients, task=task) def test__validate_helper_somethingwent_wrong(self): validator = mock.MagicMock() validator.side_effect = Exception() self.assertRaises(exceptions.InvalidScenarioArgument, base.Scenario._validate_helper, [validator], ""cl"", ""config"", ""task"") validator.assert_called_once_with(""config"", clients=""cl"", task=""task"") def test__validate_helper__no_valid(self): validators = [ mock.MagicMock(return_value=validation.ValidationResult()), mock.MagicMock( return_value=validation.ValidationResult(is_valid=False) ) ] clients = mock.MagicMock() args = {""a"": 1, ""b"": 2} self.assertRaises(exceptions.InvalidScenarioArgument, base.Scenario._validate_helper, validators, clients, args, 'fake_uuid') @mock.patch(""rally.benchmark.scenarios.base.Scenario.get_by_name"") def test_validate__no_validators(self, mock_base_get_by_name): class FakeScenario(fakes.FakeScenario): pass FakeScenario.do_it = mock.MagicMock() FakeScenario.do_it.validators = [] mock_base_get_by_name.return_value = FakeScenario base.Scenario.validate(""FakeScenario.do_it"", {""a"": 1, ""b"": 2}) mock_base_get_by_name.assert_called_once_with(""FakeScenario"") @mock.patch(""rally.benchmark.scenarios.base.Scenario._validate_helper"") @mock.patch(""rally.benchmark.scenarios.base.Scenario.get_by_name"") def test_validate__admin_validators(self, mock_base_get_by_name, mock_validate_helper): class FakeScenario(fakes.FakeScenario): pass FakeScenario.do_it = mock.MagicMock() mock_base_get_by_name.return_value = FakeScenario validators = [mock.MagicMock(), mock.MagicMock()] for validator in validators: validator.permission = consts.EndpointPermission.ADMIN FakeScenario.do_it.validators = validators task = mock.MagicMock() args = {""a"": 1, ""b"": 2} base.Scenario.validate( ""FakeScenario.do_it"", args, admin=""admin"", task=task) mock_validate_helper.assert_called_once_with(validators, ""admin"", args, task) @mock.patch(""rally.benchmark.scenarios.base.Scenario._validate_helper"") @mock.patch(""rally.benchmark.scenarios.base.Scenario.get_by_name"") def test_validate_user_validators(self, mock_base_get_by_name, mock_validate_helper): class FakeScenario(fakes.FakeScenario): pass FakeScenario.do_it = mock.MagicMock() mock_base_get_by_name.return_value = FakeScenario validators = [mock.MagicMock(), mock.MagicMock()] for validator in validators: validator.permission = consts.EndpointPermission.USER FakeScenario.do_it.validators = validators args = {""a"": 1, ""b"": 2} base.Scenario.validate( ""FakeScenario.do_it"", args, users=[""u1"", ""u2""]) mock_validate_helper.assert_has_calls([ mock.call(validators, ""u1"", args, None), mock.call(validators, ""u2"", args, None) ]) def test_meta_string_returns_non_empty_list(self): class MyFakeScenario(fakes.FakeScenario): pass attr_name = 'preprocessors' preprocessors = [mock.MagicMock(), mock.MagicMock()] MyFakeScenario.do_it.__dict__[attr_name] = preprocessors scenario = MyFakeScenario() self.assertEqual(scenario.meta(cls=""MyFakeScenario.do_it"", attr_name=attr_name), preprocessors) def test_meta_class_returns_non_empty_list(self): class MyFakeScenario(fakes.FakeScenario): pass attr_name = 'preprocessors' preprocessors = [mock.MagicMock(), mock.MagicMock()] MyFakeScenario.do_it.__dict__[attr_name] = preprocessors scenario = MyFakeScenario() self.assertEqual(scenario.meta(cls=MyFakeScenario, method_name=""do_it"", attr_name=attr_name), preprocessors) def test_meta_string_returns_empty_list(self): class MyFakeScenario(fakes.FakeScenario): pass empty_list = [] scenario = MyFakeScenario() self.assertEqual(scenario.meta(cls=""MyFakeScenario.do_it"", attr_name=""foo"", default=empty_list), empty_list) def test_meta_class_returns_empty_list(self): class MyFakeScenario(fakes.FakeScenario): pass empty_list = [] scenario = MyFakeScenario() self.assertEqual(scenario.meta(cls=MyFakeScenario, method_name=""do_it"", attr_name=""foo"", default=empty_list), empty_list) def test_sleep_between_invalid_args(self): scenario = base.Scenario() self.assertRaises(exceptions.InvalidArgumentsException, scenario.sleep_between, 15, 5) self.assertRaises(exceptions.InvalidArgumentsException, scenario.sleep_between, -1, 0) self.assertRaises(exceptions.InvalidArgumentsException, scenario.sleep_between, 0, -2) def test_sleep_between(self): scenario = base.Scenario() scenario.sleep_between(0.001, 0.002) self.assertTrue(0.001 <= scenario.idle_duration() <= 0.002) def test_sleep_beetween_multi(self): scenario = base.Scenario() scenario.sleep_between(0.001, 0.001) scenario.sleep_between(0.004, 0.004) self.assertEqual(scenario.idle_duration(), 0.005) @mock.patch(""rally.benchmark.scenarios.base.time.sleep"") @mock.patch(""rally.benchmark.scenarios.base.random.uniform"") def test_sleep_between_internal(self, mock_uniform, mock_sleep): scenario = base.Scenario() mock_uniform.return_value = 1.5 scenario.sleep_between(1, 2) mock_sleep.assert_called_once_with(mock_uniform.return_value) self.assertEqual(scenario.idle_duration(), mock_uniform.return_value) def test_context(self): context = mock.MagicMock() scenario = base.Scenario(context=context) self.assertEqual(context, scenario.context()) def test_clients(self): clients = fakes.FakeClients() scenario = base.Scenario(clients=clients) self.assertEqual(clients.nova(), scenario.clients(""nova"")) self.assertEqual(clients.glance(), scenario.clients(""glance"")) def test_admin_clients(self): clients = fakes.FakeClients() scenario = base.Scenario(admin_clients=clients) self.assertEqual(clients.nova(), scenario.admin_clients(""nova"")) self.assertEqual(clients.glance(), scenario.admin_clients(""glance"")) def test_scenario_context_are_valid(self): scenarios = base.Scenario.list_benchmark_scenarios() for scenario in scenarios: cls_name, method_name = scenario.split(""."", 1) cls = base.Scenario.get_by_name(cls_name) context = getattr(cls, method_name).context try: base_ctx.ContextManager.validate(context) except Exception: print(traceback.format_exc()) self.assertTrue(False, ""Scenario `%s` has wrong context"" % scenario) def test_RESOURCE_NAME_PREFIX(self): self.assertTrue(isinstance(base.Scenario.RESOURCE_NAME_PREFIX, basestring)) def test_RESOURCE_NAME_LENGTH(self): self.assertTrue( isinstance(base.Scenario.RESOURCE_NAME_LENGTH, int)) self.assertTrue(base.Scenario.RESOURCE_NAME_LENGTH > 4) @mock.patch( ""rally.benchmark.scenarios.base."" ""Scenario.RESOURCE_NAME_PREFIX"", ""prefix_"") def test_generate_random_name(self): set_by_length = lambda lst: set(map(len, lst)) len_by_prefix = (lambda lst, prefix: len(filter(bool, map(lambda i: i.startswith(prefix), lst)))) range_num = 50 # Defaults result = [base.Scenario._generate_random_name() for i in range(range_num)] self.assertEqual(len(result), len(set(result))) self.assertEqual( set_by_length(result), set([(len( base.Scenario.RESOURCE_NAME_PREFIX) + base.Scenario.RESOURCE_NAME_LENGTH)])) self.assertEqual( len_by_prefix(result, base.Scenario.RESOURCE_NAME_PREFIX), range_num) # Custom prefix prefix = ""another_prefix_"" result = [base.Scenario._generate_random_name(prefix) for i in range(range_num)] self.assertEqual(len(result), len(set(result))) self.assertEqual( set_by_length(result), set([len(prefix) + base.Scenario.RESOURCE_NAME_LENGTH])) self.assertEqual( len_by_prefix(result, prefix), range_num) # Custom length name_length = 12 result = [ base.Scenario._generate_random_name(length=name_length) for i in range(range_num)] self.assertEqual(len(result), len(set(result))) self.assertEqual( set_by_length(result), set([len( base.Scenario.RESOURCE_NAME_PREFIX) + name_length])) self.assertEqual( len_by_prefix(result, base.Scenario.RESOURCE_NAME_PREFIX), range_num) class AtomicActionTestCase(test.TestCase): def test__init__(self): fake_scenario_instance = fakes.FakeScenario() c = base.AtomicAction(fake_scenario_instance, 'asdf') self.assertEqual(c.scenario_instance, fake_scenario_instance) self.assertEqual(c.name, 'asdf') @mock.patch('tests.unit.fakes.FakeScenario._add_atomic_actions') @mock.patch('rally.utils.time') def test__exit__(self, mock_time, mock__add_atomic_actions): fake_scenario_instance = fakes.FakeScenario() self.start = mock_time.time() with base.AtomicAction(fake_scenario_instance, ""asdf""): pass duration = mock_time.time() - self.start mock__add_atomic_actions.assert_called_once_with('asdf', duration) ",,349,0
openstack%2Fcinder~master~I66fd66650a7106b8d20e4fc483dabb91184922f9,openstack/cinder,master,I66fd66650a7106b8d20e4fc483dabb91184922f9,Sync install_venv_common from oslo-incubator,MERGED,2014-12-19 20:51:50.000000000,2014-12-20 12:10:10.000000000,2014-12-20 02:42:46.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 5997}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 14206}]","[{'number': 1, 'created': '2014-12-19 20:51:50.000000000', 'files': ['tools/install_venv_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6539eacb7d07c99a1e560ccc2442ebbd21c06db0', 'message': ""Sync install_venv_common from oslo-incubator\n\nThe install_venv_common modules hasn't had a sync done\nsince early in the icehouse release.  This sync brings\nCinder's version up to date with the latest code.\n\nCurrent HEAD in OSLO:\n---------------------\ncommit 36b0e8570b449129d6d474c03b02ceb62edb78df\nDate:   Thu Dec 11 11:27:08 2014 +0100\nWe shouldn't replace `oslo-incubator` in comments\n\nChange being merged with this patch:\n---------------------\nfe3389e5 - Improve help strings\n\nChange-Id: I66fd66650a7106b8d20e4fc483dabb91184922f9\n""}]",0,143187,6539eacb7d07c99a1e560ccc2442ebbd21c06db0,15,11,1,7198,,,0,"Sync install_venv_common from oslo-incubator

The install_venv_common modules hasn't had a sync done
since early in the icehouse release.  This sync brings
Cinder's version up to date with the latest code.

Current HEAD in OSLO:
---------------------
commit 36b0e8570b449129d6d474c03b02ceb62edb78df
Date:   Thu Dec 11 11:27:08 2014 +0100
We shouldn't replace `oslo-incubator` in comments

Change being merged with this patch:
---------------------
fe3389e5 - Improve help strings

Change-Id: I66fd66650a7106b8d20e4fc483dabb91184922f9
",git fetch https://review.opendev.org/openstack/cinder refs/changes/87/143187/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/install_venv_common.py'],1,6539eacb7d07c99a1e560ccc2442ebbd21c06db0,sync_install_venv," # setuptools and pbr self.pip_install('pip>=1.4') self.pip_install('pbr') self.pip_install('-r', self.requirements, '-r', self.test_requirements) ""install."")"," # setuptools. self.pip_install('pip>=1.3') self.pip_install('-r', self.requirements) self.pip_install('-r', self.test_requirements) ""install"")",5,5
openstack%2Fhorizon~master~Ica75da4538406fcc77971a9c32e79d5fbd2af3ee,openstack/horizon,master,Ica75da4538406fcc77971a9c32e79d5fbd2af3ee,Imported Translations from Transifex,MERGED,2014-12-20 06:06:42.000000000,2014-12-20 11:50:29.000000000,2014-12-20 11:50:28.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}]","[{'number': 1, 'created': '2014-12-20 06:06:42.000000000', 'files': ['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0d04486cfd5d156f4fa7864b226f10f2a7ae7938', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ica75da4538406fcc77971a9c32e79d5fbd2af3ee\n'}]",0,143255,0d04486cfd5d156f4fa7864b226f10f2a7ae7938,7,3,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ica75da4538406fcc77971a9c32e79d5fbd2af3ee
",git fetch https://review.opendev.org/openstack/horizon refs/changes/55/143255/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po']",17,0d04486cfd5d156f4fa7864b226f10f2a7ae7938,transifex/translations,"""POT-Creation-Date: 2014-12-19 15:20-0600\n"" ""PO-Revision-Date: 2014-12-19 21:20+0000\n""#: dashboards/admin/volumes/volume_types/tables.py:137 #: dashboards/admin/volumes/volume_types/tables.py:219#: dashboards/admin/volumes/volume_types/tables.py:154#: dashboards/admin/volumes/volume_types/tables.py:222#: dashboards/admin/volumes/volume_types/tables.py:180#: dashboards/admin/volumes/volume_types/tables.py:94 msgid ""Delete Encryption"" msgid_plural ""Delete Encryptions"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/volumes/volume_types/tables.py:102 msgid ""Deleted Encryption"" msgid_plural ""Deleted Encryptions"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/volumes/volume_types/tables.py:122#: dashboards/admin/volumes/volume_types/tables.py:139#: dashboards/admin/volumes/volume_types/tables.py:141#: dashboards/admin/volumes/volume_types/tables.py:166#: dashboards/admin/volumes/volume_types/tables.py:191#: dashboards/admin/volumes/volume_types/tables.py:199#: dashboards/admin/volumes/volume_types/tables.py:211#: dashboards/admin/volumes/volume_types/tables.py:220#: dashboards/admin/volumes/volume_types/tables.py:235#: dashboards/project/access_and_security/security_groups/views.py:126#: dashboards/project/access_and_security/security_groups/views.py:85#: dashboards/project/access_and_security/security_groups/views.py:69#: dashboards/project/access_and_security/security_groups/views.py:133","""POT-Creation-Date: 2014-12-18 06:58-0600\n"" ""PO-Revision-Date: 2014-12-18 12:57+0000\n""#: dashboards/admin/volumes/volume_types/tables.py:107 #: dashboards/admin/volumes/volume_types/tables.py:188#: dashboards/admin/volumes/volume_types/tables.py:124#: dashboards/admin/volumes/volume_types/tables.py:191#: dashboards/admin/volumes/volume_types/tables.py:149#: dashboards/admin/volumes/volume_types/tables.py:92#: dashboards/admin/volumes/volume_types/tables.py:109#: dashboards/admin/volumes/volume_types/tables.py:111#: dashboards/admin/volumes/volume_types/tables.py:135#: dashboards/admin/volumes/volume_types/tables.py:160#: dashboards/admin/volumes/volume_types/tables.py:168#: dashboards/admin/volumes/volume_types/tables.py:180#: dashboards/admin/volumes/volume_types/tables.py:189#: dashboards/admin/volumes/volume_types/tables.py:204#: dashboards/project/access_and_security/security_groups/views.py:124#: dashboards/project/access_and_security/security_groups/views.py:83#: dashboards/project/access_and_security/security_groups/views.py:66#: dashboards/project/access_and_security/security_groups/views.py:131",544,340
openstack%2Ffuel-main~master~I28a84f8e2a304e18cf54eb7d08b24f0ef67503f5,openstack/fuel-main,master,I28a84f8e2a304e18cf54eb7d08b24f0ef67503f5,Wait for Keystone start after master node reset,MERGED,2014-12-11 22:51:27.000000000,2014-12-20 11:48:01.000000000,2014-12-12 09:56:10.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}]","[{'number': 1, 'created': '2014-12-11 22:51:27.000000000', 'files': ['fuelweb_test/models/environment.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4a00e4565b879f110ff56a3c941c0bd81efa7086', 'message': 'Wait for Keystone start after master node reset\n\nUse protected Nailgun API URL to check that Keystone\nis up and works fine before running tests.\n\nChange-Id: I28a84f8e2a304e18cf54eb7d08b24f0ef67503f5\nCloses-bug: #1401692\n'}]",0,141194,4a00e4565b879f110ff56a3c941c0bd81efa7086,12,6,1,11081,,,0,"Wait for Keystone start after master node reset

Use protected Nailgun API URL to check that Keystone
is up and works fine before running tests.

Change-Id: I28a84f8e2a304e18cf54eb7d08b24f0ef67503f5
Closes-bug: #1401692
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/94/141194/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/environment.py'],1,4a00e4565b879f110ff56a3c941c0bd81efa7086,bug/1401692," _wait(self._fuel_web.client.get_releases, timeout=120)"," _wait(self._fuel_web.get_nailgun_version, timeout=120)",1,1
openstack%2Fcinder~master~Ib52cbe16ed426392c3b296b56b4d2592b4808e65,openstack/cinder,master,Ib52cbe16ed426392c3b296b56b4d2592b4808e65,Fix files in Cinder with execute bit set,MERGED,2014-12-11 00:50:52.000000000,2014-12-20 10:37:15.000000000,2014-12-20 01:44:20.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 8247}, {'_account_id': 9003}, {'_account_id': 9008}, {'_account_id': 9171}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11459}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 13636}, {'_account_id': 14206}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-11 00:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/63b4b7b921d2b2b7fd0dfdbcbc35818ec872f05a', 'message': ""Fix files with execute bit set\n\nI noticed there were a number of files in the cinder/volume\ndirectory tree that have the execute bit set for no apparent\nreason.  I think in all cases it was because that was just\nthey way the permissions on the file were originally set based\non the user's umask settings.\n\nThis patch changes the permissions to be consistent with the other\npython files in the cinder/volume directory.\n\nChange-Id: Ib52cbe16ed426392c3b296b56b4d2592b4808e65\n""}, {'number': 2, 'created': '2014-12-12 05:31:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/de1a225527446955c73a4b353ceca7017a0d451f', 'message': ""Fix files with execute bit set\n\nI noticed there were a number of files in the cinder/volume\ndirectory tree that have the execute bit set for no apparent\nreason.  I think in all cases it was because that was just\nthe way the permissions on the file were originally set based\non the user's umask settings.\n\nThis patch changes the permissions to be consistent with the other\npython files in the cinder/volume directory.\n\nChange-Id: Ib52cbe16ed426392c3b296b56b4d2592b4808e65\n""}, {'number': 3, 'created': '2014-12-15 20:04:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bfe002944a6e36ddcd2b6916df7f61cb3dfa2273', 'message': ""Fix files with execute bit set\n\nI noticed there were a number of files in the cinder/volume\ndirectory tree that have the execute bit set for no apparent\nreason.  I think in all cases it was because that was just\nthey way the permissions on the file were originally set based\non the user's umask settings.\n\nThis patch changes the permissions to be consistent with the other\npython files in the cinder/volume directory.\n\nChange-Id: Ib52cbe16ed426392c3b296b56b4d2592b4808e65\n""}, {'number': 4, 'created': '2014-12-17 20:45:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/56677c905dbbbd59f302cb0f1ac7da9852debee6', 'message': ""Fix files with execute bit set\n\nI noticed there were a number of files in the cinder/volume\ndirectory tree that have the execute bit set for no apparent\nreason.  I think in all cases it was because that was just\nthey way the permissions on the file were originally set based\non the user's umask settings.\n\nThis patch changes the permissions to be consistent with the other\npython files in the cinder/volume directory.\n\nChange-Id: Ib52cbe16ed426392c3b296b56b4d2592b4808e65\n""}, {'number': 5, 'created': '2014-12-18 22:03:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1b23c6a641b5f89584aad31e01a6f9818561e11f', 'message': ""Fix files with execute bit set\n\nI noticed there were a number of files in the cinder/volume\ndirectory tree that have the execute bit set for no apparent\nreason.  I think in all cases it was because that was just\nthey way the permissions on the file were originally set based\non the user's umask settings.\n\nThis patch changes the permissions to be consistent with the other\npython files in the cinder/volume directory.\n\nChange-Id: Ib52cbe16ed426392c3b296b56b4d2592b4808e65\n""}, {'number': 6, 'created': '2014-12-18 22:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a5cd2b6414f7e19e8e91d842842fcb2d5056a1a2', 'message': ""Fix files in Cinder with execute bit set\n\nI noticed there were a number of files in the cinder/volume\ndirectory tree that have the execute bit set for no apparent\nreason.  I think in all cases it was because that was just\nthey way the permissions on the file were originally set based\non the user's umask settings.\n\nThis patch changes the permissions to be consistent with the other\npython files in the cinder/volume directory.\n\nChange-Id: Ib52cbe16ed426392c3b296b56b4d2592b4808e65\n""}, {'number': 7, 'created': '2014-12-19 15:38:27.000000000', 'files': ['cinder/cmd/volume_usage_audit.py', 'cinder/cmd/volume.py', 'cinder/volume/drivers/ibm/flashsystem.py', 'cinder/db/sqlalchemy/migrate_repo/manage.py', 'cinder/cmd/api.py', 'cinder/cmd/scheduler.py', 'cinder/cmd/manage.py', 'cinder/tests/test_ibm_flashsystem.py', 'cinder/tests/test_cmd.py', 'cinder/volume/driver.py', 'cinder/cmd/all.py', 'cinder/volume/drivers/xio.py', 'cinder/exception.py', 'cinder/tests/test_xio.py', 'cinder/cmd/rtstool.py', 'cinder/cmd/backup.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2cde43d8add629e82c139fb2265a11372908c43e', 'message': ""Fix files in Cinder with execute bit set\n\nI noticed there were a number of files in the cinder/volume\ndirectory tree that have the execute bit set for no apparent\nreason.  I think in all cases it was because that was just\nthey way the permissions on the file were originally set based\non the user's umask settings.\n\nThis patch changes the permissions to be consistent with the other\npython files in the cinder/volume directory.\n\nChange-Id: Ib52cbe16ed426392c3b296b56b4d2592b4808e65\n""}]",1,140882,2cde43d8add629e82c139fb2265a11372908c43e,86,24,7,7198,,,0,"Fix files in Cinder with execute bit set

I noticed there were a number of files in the cinder/volume
directory tree that have the execute bit set for no apparent
reason.  I think in all cases it was because that was just
they way the permissions on the file were originally set based
on the user's umask settings.

This patch changes the permissions to be consistent with the other
python files in the cinder/volume directory.

Change-Id: Ib52cbe16ed426392c3b296b56b4d2592b4808e65
",git fetch https://review.opendev.org/openstack/cinder refs/changes/82/140882/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/driver.py', 'cinder/volume/drivers/ibm/flashsystem.py', 'cinder/volume/drivers/xio.py']",3,63b4b7b921d2b2b7fd0dfdbcbc35818ec872f05a,fix_exe_permisions,,,0,0
openstack%2Frally~master~Ie862b541f468286bf4380f6e8d19014229beef91,openstack/rally,master,Ie862b541f468286bf4380f6e8d19014229beef91,Sahara auto_security_group parameter added,MERGED,2014-12-16 10:30:49.000000000,2014-12-20 10:28:31.000000000,2014-12-20 10:28:31.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7132}, {'_account_id': 7369}, {'_account_id': 8367}, {'_account_id': 9545}, {'_account_id': 9601}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-16 10:30:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b1c9e87780d8eb15247dfdf9b2b2fba2b64eb2ea', 'message': 'Sahara auto_security_group parameter added\n\nThe auto_security_group is now enabled for all Node Groups in all\nClusters. This is required for setiing up a security group with a list\nof TCP port for Hadoop operations.\n\nSahara does both creating and removig security groups automatically.\n\nChange-Id: Ie862b541f468286bf4380f6e8d19014229beef91\n'}, {'number': 2, 'created': '2014-12-17 09:16:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/106e7a2c928d4a0f1652ab25c495c5edbbb16af2', 'message': 'Sahara auto_security_group parameter added\n\nThe auto_security_group is now enabled for all Node Groups in all\nClusters. This is required for setting up a security group with a list\nof TCP port for Hadoop operations.\n\nSahara does both creating and removig security groups automatically.\n\nChange-Id: Ie862b541f468286bf4380f6e8d19014229beef91'}, {'number': 3, 'created': '2014-12-19 09:32:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c263d9eeabcb305001d78bf6585668a806cc9372', 'message': 'Sahara auto_security_group parameter added\n\nThe auto_security_group is now enabled by default for all Node Groups in all\nClusters. This is required for setting up a security group with a list\nof TCP port for Hadoop operations.\n\nSahara does both creating and removig security groups automatically.\n\nChange-Id: Ie862b541f468286bf4380f6e8d19014229beef91\n'}, {'number': 4, 'created': '2014-12-19 14:23:23.000000000', 'files': ['doc/samples/tasks/scenarios/sahara/jobs/dfsio_job_sequence_scaling.yaml', 'doc/samples/tasks/scenarios/sahara/create_scale_delete_cluster.json', 'rally/benchmark/scenarios/sahara/clusters.py', 'doc/samples/tasks/scenarios/sahara/jobs/dfsio_job_sequence_scaling.json', 'rally/benchmark/scenarios/sahara/utils.py', 'tests/unit/benchmark/scenarios/sahara/test_utils.py', 'doc/samples/tasks/scenarios/sahara/create_and_delete_cluster.json', 'doc/samples/tasks/scenarios/sahara/jobs/pig_script_job.json', 'rally/benchmark/context/sahara/sahara_cluster.py', 'doc/samples/tasks/scenarios/sahara/create_scale_delete_cluster.yaml', 'doc/samples/tasks/scenarios/sahara/jobs/dfsio_job_sequence.json', 'doc/samples/tasks/scenarios/sahara/jobs/java_action_job.yaml', 'doc/samples/tasks/scenarios/sahara/create_and_delete_cluster.yaml', 'doc/samples/tasks/scenarios/sahara/jobs/pig_script_job.yaml', 'tests/unit/benchmark/context/sahara/test_sahara_cluster.py', 'doc/samples/tasks/scenarios/sahara/jobs/dfsio_job_sequence.yaml', 'doc/samples/tasks/scenarios/sahara/jobs/java_action_job.json', 'tests/unit/benchmark/scenarios/sahara/test_clusters.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/0f051b1df470d8ec4fe9fb5d2764b79653486c9c', 'message': 'Sahara auto_security_group parameter added\n\nThe auto_security_group is now enabled by default for all Node Groups in all\nClusters. This is required for setting up a security group with a list\nof TCP port for Hadoop operations.\n\nSahara does both creating and removig security groups automatically.\n\nChange-Id: Ie862b541f468286bf4380f6e8d19014229beef91\n'}]",2,142057,0f051b1df470d8ec4fe9fb5d2764b79653486c9c,25,8,4,7132,,,0,"Sahara auto_security_group parameter added

The auto_security_group is now enabled by default for all Node Groups in all
Clusters. This is required for setting up a security group with a list
of TCP port for Hadoop operations.

Sahara does both creating and removig security groups automatically.

Change-Id: Ie862b541f468286bf4380f6e8d19014229beef91
",git fetch https://review.opendev.org/openstack/rally refs/changes/57/142057/3 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/scenarios/sahara/utils.py', 'tests/unit/benchmark/scenarios/sahara/test_utils.py']",2,b1c9e87780d8eb15247dfdf9b2b2fba2b64eb2ea,," ""node_configs"": {""HDFS"": {""local_config"": ""local_value""}}, ""auto_security_group"": True ""node_configs"": {""HDFS"": {""local_config"": ""local_value""}}, ""auto_security_group"": True"," ""node_configs"": {""HDFS"": {""local_config"": ""local_value""}} ""node_configs"": {""HDFS"": {""local_config"": ""local_value""}}",8,4
openstack%2Fcinder~master~I3f6ded20cd8cf1902347f58f91c05446739b48f5,openstack/cinder,master,I3f6ded20cd8cf1902347f58f91c05446739b48f5,encryption_id needs to be non-nullable,MERGED,2014-12-19 16:29:26.000000000,2014-12-20 10:25:50.000000000,2014-12-20 02:43:11.000000000,"[{'_account_id': 3}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 14206}]","[{'number': 1, 'created': '2014-12-19 16:29:26.000000000', 'files': ['cinder/db/sqlalchemy/migrate_repo/versions/033_add_encryption_unique_key.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/bb1c2b28f8bf4a100dbd8252b558154018dd4c3b', 'message': ""encryption_id needs to be non-nullable\n\nDB2 10.5 doesn't support primary key constraints over\nnullable columns, so we have to make this column\nnon-nullable.\n\nChange-Id: I3f6ded20cd8cf1902347f58f91c05446739b48f5\nCloses-Bug: #1404303\n""}]",0,143129,bb1c2b28f8bf4a100dbd8252b558154018dd4c3b,14,10,1,7930,,,0,"encryption_id needs to be non-nullable

DB2 10.5 doesn't support primary key constraints over
nullable columns, so we have to make this column
non-nullable.

Change-Id: I3f6ded20cd8cf1902347f58f91c05446739b48f5
Closes-Bug: #1404303
",git fetch https://review.opendev.org/openstack/cinder refs/changes/29/143129/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/db/sqlalchemy/migrate_repo/versions/033_add_encryption_unique_key.py'],1,bb1c2b28f8bf4a100dbd8252b558154018dd4c3b,primary-key," encryption_id_column_kwargs = {} if migrate_engine.name == 'ibm_db_sa': # NOTE(junxiebj): DB2 10.5 doesn't support primary key # constraints over nullable columns, so we have to # make the column non-nullable in the DB2 case. encryption_id_column_kwargs['nullable'] = False encryption_id = Column('encryption_id', String(36), **encryption_id_column_kwargs)"," encryption_id = Column('encryption_id', String(36))",8,1
openstack%2Fpython-cinderclient~master~I92150e79f76559f90dd0341fdd6f5b0fa2d54e32,openstack/python-cinderclient,master,I92150e79f76559f90dd0341fdd6f5b0fa2d54e32,Add CONTRIBUTING.rst,MERGED,2014-07-01 06:53:57.000000000,2014-12-20 10:19:39.000000000,2014-12-20 10:19:38.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 5538}, {'_account_id': 6491}, {'_account_id': 6763}]","[{'number': 1, 'created': '2014-07-01 06:53:57.000000000', 'files': ['CONTRIBUTING.md'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/05d92328f005b4e6bfd667ba2ad16eb4bdea6982', 'message': 'Add CONTRIBUTING.rst\n\nThere is no CONTRIBUTING.rst file, so i add it.\n\nChange-Id: I92150e79f76559f90dd0341fdd6f5b0fa2d54e32\n'}]",0,103754,05d92328f005b4e6bfd667ba2ad16eb4bdea6982,19,6,1,6763,,,0,"Add CONTRIBUTING.rst

There is no CONTRIBUTING.rst file, so i add it.

Change-Id: I92150e79f76559f90dd0341fdd6f5b0fa2d54e32
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/54/103754/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.md'],1,05d92328f005b4e6bfd667ba2ad16eb4bdea6982,add_contributing_md,"If you would like to contribute to the development of OpenStack, you must follow the steps in the ""If you're a developer"" section of this page: [http://wiki.openstack.org/HowToContribute](http://wiki.openstack.org/HowToContribute#If_you.27re_a_developer:) Once those steps have been completed, changes to OpenStack should be submitted for review via the Gerrit tool, following the workflow documented at [http://wiki.openstack.org/GerritWorkflow](http://wiki.openstack.org/GerritWorkflow). Pull requests submitted through GitHub will be ignored. Bugs should be filed [on Launchpad](https://bugs.launchpad.net/python-cinderclient), not in GitHub's issue tracker. ",,12,0
openstack%2Fopenstack-manuals~master~I464c7b29dd14c70fd59ace55b55378c37e4e2dbc,openstack/openstack-manuals,master,I464c7b29dd14c70fd59ace55b55378c37e4e2dbc,Update CLI reference for python-keystoneclient 1.0.0,MERGED,2014-12-20 07:50:41.000000000,2014-12-20 09:21:43.000000000,2014-12-20 09:21:43.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-20 07:50:41.000000000', 'files': ['doc/cli-reference/generated/ch_cli_keystone_commands.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b827c7dd8845d9413528e0de9beb03350ee3953b', 'message': 'Update CLI reference for python-keystoneclient 1.0.0\n\nChange-Id: I464c7b29dd14c70fd59ace55b55378c37e4e2dbc\n'}]",0,143259,b827c7dd8845d9413528e0de9beb03350ee3953b,6,2,1,167,,,0,"Update CLI reference for python-keystoneclient 1.0.0

Change-Id: I464c7b29dd14c70fd59ace55b55378c37e4e2dbc
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/59/143259/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/generated/ch_cli_keystone_commands.xml'],1,b827c7dd8845d9413528e0de9beb03350ee3953b,update_client_keystone, <literal>1.0.0</literal>., <literal>0.11.2</literal>.,1,1
openstack%2Fcinder~master~Iddb6639ebdbb5facdf47800fc783330d674bff2f,openstack/cinder,master,Iddb6639ebdbb5facdf47800fc783330d674bff2f,Fix typo that escaped review in connector.py,MERGED,2014-12-18 23:18:42.000000000,2014-12-20 09:17:01.000000000,2014-12-19 11:04:03.000000000,"[{'_account_id': 3}, {'_account_id': 4355}, {'_account_id': 6043}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 13636}]","[{'number': 1, 'created': '2014-12-18 23:18:42.000000000', 'files': ['cinder/brick/initiator/connector.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f03ecd20bdad341677de23cb8c3124754e729c17', 'message': ""Fix typo that escaped review in connector.py\n\nThere was a typo (cann't) that escaped review of the\nHuawei SDSHypervisor connector.  This patch fixes that\ntypo.\n\nIt also adds a period to one of the log messages to be\nconsistent with the rest of the messages.\n\nChange-Id: Iddb6639ebdbb5facdf47800fc783330d674bff2f\n""}]",0,142932,f03ecd20bdad341677de23cb8c3124754e729c17,18,11,1,7198,,,0,"Fix typo that escaped review in connector.py

There was a typo (cann't) that escaped review of the
Huawei SDSHypervisor connector.  This patch fixes that
typo.

It also adds a period to one of the log messages to be
consistent with the rest of the messages.

Change-Id: Iddb6639ebdbb5facdf47800fc783330d674bff2f
",git fetch https://review.opendev.org/openstack/cinder refs/changes/32/142932/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/brick/initiator/connector.py'],1,f03ecd20bdad341677de23cb8c3124754e729c17,fix_typo_brick_init_connector," 'HuaweiStorHyperConnector init failed.')) ""can't execute SDS command."")"," 'HuaweiStorHyperConnector init failed')) ""cann't execute SDS command."")",2,2
openstack%2Fneutron~master~Ibcc577ade490663820f0a4f599afc6127a6e52e6,openstack/neutron,master,Ibcc577ade490663820f0a4f599afc6127a6e52e6,"Revert ""Add metadata proxy L3 agent driver""",MERGED,2014-12-20 05:08:43.000000000,2014-12-20 09:09:06.000000000,2014-12-20 07:10:01.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 14208}]","[{'number': 1, 'created': '2014-12-20 05:08:43.000000000', 'files': ['neutron/agent/l3/agent.py', 'neutron/tests/unit/agent/metadata/test_driver.py', 'neutron/agent/metadata/driver.py', 'neutron/tests/unit/agent/metadata/__init__.py', 'neutron/agent/l3/ha.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/658dc9d30cfb337159df40fdd62c50de182d83aa', 'message': 'Revert ""Add metadata proxy L3 agent driver""\n\nThis reverts commit 6b38f29fdbd077434f1f7139466479e81bf4882d.\n\nBecause it broke the functional job.\n\nChange-Id: Ibcc577ade490663820f0a4f599afc6127a6e52e6\n'}]",0,143253,658dc9d30cfb337159df40fdd62c50de182d83aa,18,15,1,6524,,,0,"Revert ""Add metadata proxy L3 agent driver""

This reverts commit 6b38f29fdbd077434f1f7139466479e81bf4882d.

Because it broke the functional job.

Change-Id: Ibcc577ade490663820f0a4f599afc6127a6e52e6
",git fetch https://review.opendev.org/openstack/neutron refs/changes/53/143253/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/agent.py', 'neutron/tests/unit/agent/metadata/test_driver.py', 'neutron/agent/metadata/driver.py', 'neutron/tests/unit/agent/metadata/__init__.py', 'neutron/agent/l3/ha.py', 'neutron/tests/unit/test_l3_agent.py']",6,658dc9d30cfb337159df40fdd62c50de182d83aa,bp/restructure-l3-agent," def test_ha_router_keepalived_config(self): agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) router = prepare_router_data(enable_ha=True) router['routes'] = [ {'destination': '8.8.8.8/32', 'nexthop': '35.4.0.10'}, {'destination': '8.8.4.4/32', 'nexthop': '35.4.0.11'}] ri = l3router.RouterInfo(router['id'], self.conf.root_helper, router=router) ri.router = router with contextlib.nested(mock.patch.object(agent, '_spawn_metadata_proxy'), mock.patch('neutron.agent.linux.' 'utils.replace_file'), mock.patch('neutron.agent.linux.' 'utils.execute'), mock.patch('os.makedirs')): agent.process_ha_router_added(ri) agent.process_router(ri) config = ri.keepalived_manager.config ha_iface = agent.get_ha_device_name(ri.ha_port['id']) ex_iface = agent.get_external_device_name(ri.ex_gw_port['id']) int_iface = agent.get_internal_device_name( ri.internal_ports[0]['id']) expected = """"""vrrp_sync_group VG_1 { group { VR_1 } } vrrp_instance VR_1 { state BACKUP interface %(ha_iface)s virtual_router_id 1 priority 50 nopreempt advert_int 2 track_interface { %(ha_iface)s } virtual_ipaddress { 19.4.4.4/24 dev %(ex_iface)s } virtual_ipaddress_excluded { 35.4.0.4/24 dev %(int_iface)s } virtual_routes { 0.0.0.0/0 via 19.4.4.1 dev %(ex_iface)s 8.8.8.8/32 via 35.4.0.10 8.8.4.4/32 via 35.4.0.11 } }"""""" % {'ha_iface': ha_iface, 'ex_iface': ex_iface, 'int_iface': int_iface} self.assertEqual(expected, config.get_config_str()) router = {'id': _uuid(), agent, '_destroy_metadata_proxy') as destroy_proxy: agent, '_spawn_metadata_proxy') as spawn_proxy: agent._router_added(router_id, router) if enableflag: spawn_proxy.assert_called_with(router_id, mock.ANY) destroy_proxy.assert_called_with(mock.ANY, mock.ANY) def test_metadata_nat_rules(self): self.conf.set_override('enable_metadata_proxy', False) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) self.assertEqual([], agent.metadata_nat_rules()) self.conf.set_override('metadata_port', '8775') self.conf.set_override('enable_metadata_proxy', True) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) rules = ('PREROUTING', '-s 0.0.0.0/0 -d 169.254.169.254/32 ' '-p tcp -m tcp --dport 80 -j REDIRECT --to-port 8775') self.assertEqual([rules], agent.metadata_nat_rules()) def test_metadata_filter_rules(self): self.conf.set_override('enable_metadata_proxy', False) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) self.assertEqual([], agent.metadata_filter_rules()) self.conf.set_override('metadata_port', '8775') self.conf.set_override('enable_metadata_proxy', True) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) rules = ('INPUT', '-s 0.0.0.0/0 -d 127.0.0.1 ' '-p tcp -m tcp --dport 8775 -j ACCEPT') self.assertEqual([rules], agent.metadata_filter_rules()) class TestL3AgentEventHandler(base.BaseTestCase): def setUp(self): super(TestL3AgentEventHandler, self).setUp() cfg.CONF.register_opts(l3_agent.L3NATAgent.OPTS) cfg.CONF.register_opts(ha.OPTS) agent_config.register_interface_driver_opts_helper(cfg.CONF) agent_config.register_use_namespaces_opts_helper(cfg.CONF) cfg.CONF.set_override( 'interface_driver', 'neutron.agent.linux.interface.NullDriver' ) cfg.CONF.set_override('use_namespaces', True) cfg.CONF.set_override('verbose', False) agent_config.register_root_helper(cfg.CONF) device_exists_p = mock.patch( 'neutron.agent.linux.ip_lib.device_exists') device_exists_p.start() utils_exec_p = mock.patch( 'neutron.agent.linux.utils.execute') utils_exec_p.start() drv_cls_p = mock.patch('neutron.agent.linux.interface.NullDriver') driver_cls = drv_cls_p.start() mock_driver = mock.MagicMock() mock_driver.DEV_NAME_LEN = ( interface.LinuxInterfaceDriver.DEV_NAME_LEN) driver_cls.return_value = mock_driver l3_plugin_p = mock.patch( 'neutron.agent.l3.agent.L3PluginApi') l3_plugin_cls = l3_plugin_p.start() l3_plugin_cls.return_value = mock.MagicMock() self.external_process_p = mock.patch( 'neutron.agent.linux.external_process.ProcessManager' ) self.external_process_p.start() looping_call_p = mock.patch( 'neutron.openstack.common.loopingcall.FixedIntervalLoopingCall') looping_call_p.start() self.agent = l3_agent.L3NATAgent(HOSTNAME) def test_spawn_metadata_proxy(self): router_id = _uuid() metadata_port = 8080 ip_class_path = 'neutron.agent.linux.ip_lib.IPWrapper' cfg.CONF.set_override('metadata_port', metadata_port) cfg.CONF.set_override('log_file', 'test.log') cfg.CONF.set_override('debug', True) self.external_process_p.stop() ri = l3router.RouterInfo(router_id, None, None) with mock.patch(ip_class_path) as ip_mock: self.agent._spawn_metadata_proxy(ri.router_id, ri.ns_name) ip_mock.assert_has_calls([ mock.call('sudo', ri.ns_name), mock.call().netns.execute([ 'neutron-ns-metadata-proxy', mock.ANY, mock.ANY, '--router_id=%s' % router_id, mock.ANY, '--metadata_port=%s' % metadata_port, '--debug', '--log-file=neutron-ns-metadata-proxy-%s.log' % router_id ], addl_env=None) ])","from neutron.agent.metadata import driver as metadata_driverfrom neutron.openstack.common import log self.conf.register_cli_opts(log.common_cli_opts) self.conf.register_cli_opts(log.logging_cli_opts) router = {'id': router_id, driver = metadata_driver.MetadataDriver driver, '_destroy_metadata_proxy') as destroy_proxy: driver, '_spawn_metadata_proxy') as spawn_proxy: agent._process_added_router(router) if enableflag: spawn_proxy.assert_called_with(router_id, mock.ANY, mock.ANY) destroy_proxy.assert_called_with(router_id, mock.ANY, mock.ANY)",226,206
openstack%2Fhorizon~master~I483dcbf12af57cc7b0f389d0c92b8dcd56922ad9,openstack/horizon,master,I483dcbf12af57cc7b0f389d0c92b8dcd56922ad9,Nav submenu font size smaller,MERGED,2014-12-16 21:21:48.000000000,2014-12-20 07:28:57.000000000,2014-12-20 07:28:56.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 8040}, {'_account_id': 13086}]","[{'number': 1, 'created': '2014-12-16 21:21:48.000000000', 'files': ['openstack_dashboard/static/dashboard/scss/_accordion_nav.scss'], 'web_link': 'https://opendev.org/openstack/horizon/commit/f4d1d6ab55022d3d64efac6290a2d17033f9a41b', 'message': 'Nav submenu font size smaller\n\nThe accordian navigation submenu font sizes (13px) are now the same as the parent menu.\n\nChange-Id: I483dcbf12af57cc7b0f389d0c92b8dcd56922ad9\nCloses-Bug: #1398929\n'}]",0,142225,f4d1d6ab55022d3d64efac6290a2d17033f9a41b,9,5,1,13785,,,0,"Nav submenu font size smaller

The accordian navigation submenu font sizes (13px) are now the same as the parent menu.

Change-Id: I483dcbf12af57cc7b0f389d0c92b8dcd56922ad9
Closes-Bug: #1398929
",git fetch https://review.opendev.org/openstack/horizon refs/changes/25/142225/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/dashboard/scss/_accordion_nav.scss'],1,f4d1d6ab55022d3d64efac6290a2d17033f9a41b,bug/1398929,, font-size: 1.2em;,0,1
openstack%2Fcinder~master~Ibf3d3f7520f0e6d30081e98bdcbf1a07ebdb44ab,openstack/cinder,master,Ibf3d3f7520f0e6d30081e98bdcbf1a07ebdb44ab,Remove redundant args for clone_image method,MERGED,2014-12-18 16:28:44.000000000,2014-12-20 07:09:59.000000000,2014-12-19 00:02:07.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 4355}, {'_account_id': 9003}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}]","[{'number': 1, 'created': '2014-12-18 16:28:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e7c7a5937180177c4973e8b0bdfcececcfaeda4d', 'message': ""Remove redundant args for clone_image method\n\nThe clone_image method takes both image_id and image_meta\nas arguments.  No big deal, except the image id is included\nin the image_meta; so there's really no reason to have both.\n\nThis patch removes the image_id argument and updates those\ndrivers that implement clone_image to extract the image ID\nfrom the provided image_metadata.\n\nChange-Id: Ibf3d3f7520f0e6d30081e98bdcbf1a07ebdb44ab\n""}, {'number': 2, 'created': '2014-12-18 16:47:23.000000000', 'files': ['cinder/volume/drivers/rbd.py', 'cinder/volume/drivers/ibm/gpfs.py', 'cinder/tests/test_netapp_nfs.py', 'cinder/tests/test_huaweistorac.py', 'cinder/tests/test_gpfs.py', 'cinder/tests/test_volume.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/volume/driver.py', 'cinder/volume/drivers/netapp/dataontap/nfs_base.py', 'cinder/tests/test_rbd.py', 'cinder/volume/drivers/scality.py', 'cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/baedb8c6c1642c0551675e311a1b3f869cecfc57', 'message': ""Remove redundant args for clone_image method\n\nThe clone_image method takes both image_id and image_meta\nas arguments.  No big deal, except the image id is included\nin the image_meta; so there's really no reason to have both.\n\nThis patch removes the image_id argument and updates those\ndrivers that implement clone_image to extract the image ID\nfrom the provided image_metadata.\n\nChange-Id: Ibf3d3f7520f0e6d30081e98bdcbf1a07ebdb44ab\n""}]",0,142830,baedb8c6c1642c0551675e311a1b3f869cecfc57,17,12,2,2243,,,0,"Remove redundant args for clone_image method

The clone_image method takes both image_id and image_meta
as arguments.  No big deal, except the image id is included
in the image_meta; so there's really no reason to have both.

This patch removes the image_id argument and updates those
drivers that implement clone_image to extract the image ID
from the provided image_metadata.

Change-Id: Ibf3d3f7520f0e6d30081e98bdcbf1a07ebdb44ab
",git fetch https://review.opendev.org/openstack/cinder refs/changes/30/142830/1 && git format-patch -1 --stdout FETCH_HEAD,"['pbr-0.10.4-py2.7.egg/pbr/tests/testpackage/setup.py', 'pbr-0.10.4-py2.7.egg/pbr/extra_files.py', 'pbr-0.10.4-py2.7.egg/EGG-INFO/entry_points.txt', 'pbr-0.10.4-py2.7.egg/pbr/hooks/metadata.py', 'pbr-0.10.4-py2.7.egg/pbr/cmd/__init__.py', 'pbr-0.10.4-py2.7.egg/pbr/util.py', 'pbr-0.10.4-py2.7.egg/pbr/hooks/backwards.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/test_version.py', 'cinder/volume/drivers/netapp/dataontap/nfs_base.py', 'pbr-0.10.4-py2.7.egg/pbr/core.py', 'pbr-0.10.4-py2.7.egg/pbr/find_package.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/test_core.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/testpackage/LICENSE.txt', 'pbr-0.10.4-py2.7.egg/pbr/packaging.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/testpackage/pbr_testpackage/_setup_hooks.py', 'cinder/volume/drivers/rbd.py', 'cinder/tests/test_netapp_nfs.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/testpackage/data_files/b.txt', 'cinder/tests/test_huaweistorac.py', 'cinder/tests/test_gpfs.py', 'pbr-0.10.4-py2.7.egg/pbr/hooks/base.py', 'pbr-0.10.4-py2.7.egg/EGG-INFO/not-zip-safe', 'pbr-0.10.4-py2.7.egg/pbr/tests/test_commands.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/testpackage/pbr_testpackage/cmd.py', 'pbr-0.10.4-py2.7.egg/pbr/testr_command.py', 'pbr-0.10.4-py2.7.egg/EGG-INFO/requires.txt', 'cinder/volume/flows/manager/create_volume.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/testpackage/data_files/c.rst', 'pbr-0.10.4-py2.7.egg/pbr/tests/util.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/testpackage/pbr_testpackage/__init__.py', 'cinder/tests/test_rbd.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/testpackage/data_files/a.txt', 'cinder/volume/drivers/scality.py', 'pbr-0.10.4-py2.7.egg/pbr/hooks/__init__.py', 'pbr-0.10.4-py2.7.egg/pbr/cmd/main.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/testpackage/MANIFEST.in', 'pbr-0.10.4-py2.7.egg/pbr/tests/test_files.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/testpackage/pbr_testpackage/package_data/2.txt', 'pbr-0.10.4-py2.7.egg/EGG-INFO/dependency_links.txt', 'pbr-0.10.4-py2.7.egg/pbr/tests/testpackage/CHANGES.txt', 'pbr-0.10.4-py2.7.egg/pbr/__init__.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/base.py', 'cinder/tests/test_volume.py', 'pbr-0.10.4-py2.7.egg/pbr/hooks/commands.py', 'pbr-0.10.4-py2.7.egg/EGG-INFO/SOURCES.txt', 'pbr-0.10.4-py2.7.egg/EGG-INFO/pbr.json', 'pbr-0.10.4-py2.7.egg/pbr/tests/__init__.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/test_hooks.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/testpackage/pbr_testpackage/package_data/1.txt', 'pbr-0.10.4-py2.7.egg/pbr/tests/testpackage/extra-file.txt', 'pbr-0.10.4-py2.7.egg/pbr/options.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/testpackage/README.txt', 'pbr-0.10.4-py2.7.egg/pbr/tests/testpackage/git-extra-file.txt', 'cinder/volume/drivers/lvm.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/testpackage/setup.cfg', 'cinder/volume/drivers/ibm/gpfs.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/test_setup.py', 'pbr-0.10.4-py2.7.egg/pbr/version.py', 'pbr-0.10.4-py2.7.egg/EGG-INFO/top_level.txt', 'pbr-0.10.4-py2.7.egg/pbr/tests/testpackage/src/testext.c', 'pbr-0.10.4-py2.7.egg/pbr/hooks/files.py', 'pbr-0.10.4-py2.7.egg/EGG-INFO/PKG-INFO', 'cinder/volume/driver.py', 'pbr-0.10.4-py2.7.egg/pbr/builddoc.py', 'pbr-0.10.4-py2.7.egg/pbr/tests/test_packaging.py']",65,e7c7a5937180177c4973e8b0bdfcececcfaeda4d,remove_redundant_clone_image_args,"# Copyright (c) 2013 New Dream Network, LLC (DreamHost) # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. # # Copyright (C) 2013 Association of Universities for Research in Astronomy # (AURA) # # Redistribution and use in source and binary forms, with or without # modification, are permitted provided that the following conditions are met: # # 1. Redistributions of source code must retain the above copyright # notice, this list of conditions and the following disclaimer. # # 2. Redistributions in binary form must reproduce the above # copyright notice, this list of conditions and the following # disclaimer in the documentation and/or other materials provided # with the distribution. # # 3. The name of AURA and its representatives may not be used to # endorse or promote products derived from this software without # specific prior written permission. # # THIS SOFTWARE IS PROVIDED BY AURA ``AS IS'' AND ANY EXPRESS OR IMPLIED # WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF # MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE # DISCLAIMED. IN NO EVENT SHALL AURA BE LIABLE FOR ANY DIRECT, INDIRECT, # INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, # BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS import os import tempfile import fixtures import mock from pbr import packaging from pbr.tests import base class TestRepo(fixtures.Fixture): """"""A git repo for testing with. Use of TempHomeDir with this fixture is strongly recommended as due to the lack of config --local in older gits, it will write to the users global configuration without TempHomeDir. """""" def __init__(self, basedir): super(TestRepo, self).__init__() self._basedir = basedir def setUp(self): super(TestRepo, self).setUp() base._run_cmd(['git', 'init', '.'], self._basedir) base._run_cmd( ['git', 'config', '--global', 'user.email', 'example@example.com'], self._basedir) base._run_cmd(['git', 'add', '.'], self._basedir) def commit(self): base._run_cmd(['git', 'commit', '-m', 'test commit'], self._basedir) class TestPackagingInGitRepoWithCommit(base.BaseTestCase): def setUp(self): super(TestPackagingInGitRepoWithCommit, self).setUp() repo = self.useFixture(TestRepo(self.package_dir)) repo.commit() self.run_setup('sdist', allow_fail=False) def test_authors(self): # One commit, something should be in the authors list with open(os.path.join(self.package_dir, 'AUTHORS'), 'r') as f: body = f.read() self.assertNotEqual(body, '') def test_changelog(self): with open(os.path.join(self.package_dir, 'ChangeLog'), 'r') as f: body = f.read() # One commit, something should be in the ChangeLog list self.assertNotEqual(body, '') class TestPackagingInGitRepoWithoutCommit(base.BaseTestCase): def setUp(self): super(TestPackagingInGitRepoWithoutCommit, self).setUp() self.useFixture(TestRepo(self.package_dir)) self.run_setup('sdist', allow_fail=False) def test_authors(self): # No commits, no authors in list with open(os.path.join(self.package_dir, 'AUTHORS'), 'r') as f: body = f.read() self.assertEqual(body, '\n') def test_changelog(self): # No commits, nothing should be in the ChangeLog list with open(os.path.join(self.package_dir, 'ChangeLog'), 'r') as f: body = f.read() self.assertEqual(body, 'CHANGES\n=======\n\n') class TestPackagingInPlainDirectory(base.BaseTestCase): def setUp(self): super(TestPackagingInPlainDirectory, self).setUp() self.run_setup('sdist', allow_fail=False) def test_authors(self): # Not a git repo, no AUTHORS file created filename = os.path.join(self.package_dir, 'AUTHORS') self.assertFalse(os.path.exists(filename)) def test_changelog(self): # Not a git repo, no ChangeLog created filename = os.path.join(self.package_dir, 'ChangeLog') self.assertFalse(os.path.exists(filename)) class TestPresenceOfGit(base.BaseTestCase): def testGitIsInstalled(self): with mock.patch.object(packaging, '_run_shell_command') as _command: _command.return_value = 'git version 1.8.4.1' self.assertEqual(True, packaging._git_is_installed()) def testGitIsNotInstalled(self): with mock.patch.object(packaging, '_run_shell_command') as _command: _command.side_effect = OSError self.assertEqual(False, packaging._git_is_installed()) class TestNestedRequirements(base.BaseTestCase): def test_nested_requirement(self): tempdir = tempfile.mkdtemp() requirements = os.path.join(tempdir, 'requirements.txt') nested = os.path.join(tempdir, 'nested.txt') with open(requirements, 'w') as f: f.write('-r ' + nested) with open(nested, 'w') as f: f.write('pbr') result = packaging.parse_requirements([requirements]) self.assertEqual(result, ['pbr']) ",,4329,28
openstack%2Ftricircle~master~I07ff47b59d45f9efbaf2f62332b83db8add25357,openstack/tricircle,master,I07ff47b59d45f9efbaf2f62332b83db8add25357,resolve sync image execption handle in nova,MERGED,2014-12-20 07:02:50.000000000,2014-12-20 07:03:24.000000000,2014-12-20 07:03:24.000000000,"[{'_account_id': 3}, {'_account_id': 9684}]","[{'number': 1, 'created': '2014-12-20 07:02:50.000000000', 'files': ['novaproxy/nova/compute/manager_proxy.py', 'novaproxy/nova/compute/clients.py', 'novaproxy/nova/image/sync/drivers/filesystem.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/909968edec71ff2b02fe9d5335a8ca71f9685e15', 'message': 'resolve sync image execption handle in nova\n\nresolve sync image execption handle in nova when using sync the image\nate the first time lauching instance.\n\nChange-Id: I07ff47b59d45f9efbaf2f62332b83db8add25357\n'}]",0,143257,909968edec71ff2b02fe9d5335a8ca71f9685e15,6,2,1,9684,,,0,"resolve sync image execption handle in nova

resolve sync image execption handle in nova when using sync the image
ate the first time lauching instance.

Change-Id: I07ff47b59d45f9efbaf2f62332b83db8add25357
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/57/143257/1 && git format-patch -1 --stdout FETCH_HEAD,"['novaproxy/nova/compute/manager_proxy.py', 'novaproxy/nova/compute/clients.py', 'novaproxy/nova/image/sync/drivers/filesystem.py']",3,909968edec71ff2b02fe9d5335a8ca71f9685e15,, msg = _('ssh login failed to %(user)s:%(passwd)s %(host)s' %," msg = _('ssh login failed to %(user):%(passwd)@%(host)',",3,2
openstack%2Fnova~master~Id19436f4226bb60baef65974a62641095e334b1f,openstack/nova,master,Id19436f4226bb60baef65974a62641095e334b1f,network:Separate the translatable messages into different catalogs,MERGED,2014-08-05 06:57:14.000000000,2014-12-20 06:39:02.000000000,2014-12-20 06:38:59.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 7730}, {'_account_id': 8412}, {'_account_id': 8574}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 9796}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-05 06:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/189683dc7cf3845f9155794964ac4dc23c833fd3', 'message': ""network:Separate the translatable messages into different catalogs\n\noslo.i18n uses different marker functions to separate the\ntranslatable messages into different catalogs, which the translation\nteams can prioritize translating.  For details, please refer to:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html#guidelines-for-use-in-openstack\n\nThere were not marker fuctions some places in directory network.\nThis commit makes changes:\n* Add missing marker functions\n* Use LOG.warn instead of LOG.warning\n* Use ',' instead of '%' while adding variables to log messages\n\nChange-Id: Id19436f4226bb60baef65974a62641095e334b1f\n""}, {'number': 2, 'created': '2014-08-05 08:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d37a2f1f4cf4e2b7094020fedbca025f4dcc1444', 'message': ""network:Separate the translatable messages into different catalogs\n\noslo.i18n uses different marker functions to separate the\ntranslatable messages into different catalogs, which the translation\nteams can prioritize translating.  For details, please refer to:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html#guidelines-for-use-in-openstack\n\nThere were not marker fuctions some places in directory network.\nThis commit makes changes:\n* Add missing marker functions\n* Use LOG.warn instead of LOG.warning\n* Use ',' instead of '%' while adding variables to log messages\n\nChange-Id: Id19436f4226bb60baef65974a62641095e334b1f\n""}, {'number': 3, 'created': '2014-08-18 02:35:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5cf242333ad21416146c6190589792f7ddf14ed5', 'message': ""network:Separate the translatable messages into different catalogs\n\noslo.i18n uses different marker functions to separate the\ntranslatable messages into different catalogs, which the translation\nteams can prioritize translating.  For details, please refer to:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html#guidelines-for-use-in-openstack\n\nThere were not marker fuctions some places in directory network.\nThis commit makes changes:\n* Add missing marker functions\n* Use ',' instead of '%' while adding variables to log messages\n\nChange-Id: Id19436f4226bb60baef65974a62641095e334b1f\n""}, {'number': 4, 'created': '2014-08-18 09:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/85110ed2712be113e57f37bc687aaa4d5f816654', 'message': ""network:Separate the translatable messages into different catalogs\n\noslo.i18n uses different marker functions to separate the\ntranslatable messages into different catalogs, which the translation\nteams can prioritize translating.  For details, please refer to:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html#guidelines-for-use-in-openstack\n\nThere were not marker fuctions some places in directory network.\nThis commit makes changes:\n* Add missing marker functions\n* Use ',' instead of '%' while adding variables to log messages\n\nChange-Id: Id19436f4226bb60baef65974a62641095e334b1f\n""}, {'number': 5, 'created': '2014-08-28 02:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b937e19f597cbe3d551fba9543d41d5c2121fc57', 'message': ""network:Separate the translatable messages into different catalogs\n\noslo.i18n uses different marker functions to separate the\ntranslatable messages into different catalogs, which the translation\nteams can prioritize translating.  For details, please refer to:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html#guidelines-for-use-in-openstack\n\nThere were not marker fuctions some places in directory network.\nThis commit makes changes:\n* Add missing marker functions\n* Use ',' instead of '%' while adding variables to log messages\n\nChange-Id: Id19436f4226bb60baef65974a62641095e334b1f\n""}, {'number': 6, 'created': '2014-09-14 03:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/21f45a7123a9d617b6c2d176181d3c8c26bab625', 'message': ""network:Separate the translatable messages into different catalogs\n\noslo.i18n uses different marker functions to separate the\ntranslatable messages into different catalogs, which the translation\nteams can prioritize translating.  For details, please refer to:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html#guidelines-for-use-in-openstack\n\nThere were not marker fuctions some places in directory network.\nThis commit makes changes:\n* Add missing marker functions\n* Use ',' instead of '%' while adding variables to log messages\n\nChange-Id: Id19436f4226bb60baef65974a62641095e334b1f\n""}, {'number': 7, 'created': '2014-09-18 02:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2fa5a656357e3f6dcf359bab9bf0792eae9ca844', 'message': ""network:Separate the translatable messages into different catalogs\n\noslo.i18n uses different marker functions to separate the\ntranslatable messages into different catalogs, which the translation\nteams can prioritize translating.  For details, please refer to:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html#guidelines-for-use-in-openstack\n\nThere were not marker fuctions some places in directory network.\nThis commit makes changes:\n* Add missing marker functions\n* Use ',' instead of '%' while adding variables to log messages\n\nChange-Id: Id19436f4226bb60baef65974a62641095e334b1f\n""}, {'number': 8, 'created': '2014-09-28 02:19:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/69bfbb62bd47e3dceebfba586f669ef3d477eb62', 'message': ""network:Separate the translatable messages into different catalogs\n\noslo.i18n uses different marker functions to separate the\ntranslatable messages into different catalogs, which the translation\nteams can prioritize translating.  For details, please refer to:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html#guidelines-for-use-in-openstack\n\nThere were not marker fuctions some places in directory network.\nThis commit makes changes:\n* Add missing marker functions\n* Use ',' instead of '%' while adding variables to log messages\n\nChange-Id: Id19436f4226bb60baef65974a62641095e334b1f\n""}, {'number': 9, 'created': '2014-10-08 11:35:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7b43dab425196c4f2019852f31c0b10496392768', 'message': ""network:Separate the translatable messages into different catalogs\n\noslo.i18n uses different marker functions to separate the\ntranslatable messages into different catalogs, which the translation\nteams can prioritize translating.  For details, please refer to:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html#guidelines-for-use-in-openstack\n\nThere were not marker fuctions some places in directory network.\nThis commit makes changes:\n* Add missing marker functions\n* Use ',' instead of '%' while adding variables to log messages\n\nChange-Id: Id19436f4226bb60baef65974a62641095e334b1f\n""}, {'number': 10, 'created': '2014-10-31 11:42:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0c1983b1cb137786b5c44c038a4ef83211519ced', 'message': ""network:Separate the translatable messages into different catalogs\n\noslo.i18n uses different marker functions to separate the\ntranslatable messages into different catalogs, which the translation\nteams can prioritize translating.  For details, please refer to:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html#guidelines-for-use-in-openstack\n\nThere were not marker fuctions some places in directory network.\nThis commit makes changes:\n* Add missing marker functions\n* Use ',' instead of '%' while adding variables to log messages\n\nChange-Id: Id19436f4226bb60baef65974a62641095e334b1f\n""}, {'number': 11, 'created': '2014-12-09 13:20:57.000000000', 'files': ['nova/network/neutronv2/api.py', 'nova/network/manager.py', 'nova/network/linux_net.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0d066981d814e04dc37a33ccee1f9938194d6831', 'message': ""network:Separate the translatable messages into different catalogs\n\noslo.i18n uses different marker functions to separate the\ntranslatable messages into different catalogs, which the translation\nteams can prioritize translating.  For details, please refer to:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html#guidelines-for-use-in-openstack\n\nThere were not marker fuctions some places in directory network.\nThis commit makes changes:\n* Add missing marker functions\n* Use ',' instead of '%' while adding variables to log messages\n\nChange-Id: Id19436f4226bb60baef65974a62641095e334b1f\n""}]",10,111933,0d066981d814e04dc37a33ccee1f9938194d6831,116,16,11,9796,,,0,"network:Separate the translatable messages into different catalogs

oslo.i18n uses different marker functions to separate the
translatable messages into different catalogs, which the translation
teams can prioritize translating.  For details, please refer to:
http://docs.openstack.org/developer/oslo.i18n/guidelines.html#guidelines-for-use-in-openstack

There were not marker fuctions some places in directory network.
This commit makes changes:
* Add missing marker functions
* Use ',' instead of '%' while adding variables to log messages

Change-Id: Id19436f4226bb60baef65974a62641095e334b1f
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/111933/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/network/api.py', 'nova/network/base_api.py', 'nova/network/ldapdns.py', 'nova/network/manager.py', 'nova/network/linux_net.py', 'nova/network/minidns.py', 'nova/network/security_group/neutron_driver.py', 'nova/network/driver.py', 'nova/network/floating_ips.py']",10,189683dc7cf3845f9155794964ac4dc23c833fd3,translate_network,"from nova.i18n import _LE from nova.i18n import _LI from nova.i18n import _LW LOG.info(_LI(""Floating IP %s is not associated. Ignore.""), LOG.warn(_LW('Address |%(address)s| is not allocated'), {'address': floating_ip.address}) LOG.warn(_LW('Address |%(address)s| is not allocated to your ' 'project |%(project)s|'), {'address': floating_ip.address, 'project': context.project_id}) LOG.warn(_LW(""Quota exceeded for %s, tried to allocate "" ""floating IP""), context.project_id) LOG.exception(_LE(""Failed to update usages deallocating "" ""floating IP"")) LOG.warn(_LW('Failed to disassociated floating ' 'address: %s'), floating_address) LOG.error(_LE('Interface %s not found'), interface) LOG.info(_LI(""Starting migration network for instance %s""), LOG.warn(_LW(""Floating ip address |%(address)s| no longer "" ""belongs to instance %(instance_uuid)s. Will not "" ""migrate it ""), LOG.info(_LI(""Finishing migration network for instance %s""), LOG.warn(_LW(""Floating ip address |%(address)s| no longer "" ""belongs to instance %(instance_uuid)s. Will not"" ""setup it.""), LOG.warn(_LW('Database inconsistency: DNS domain |%s| is ' 'registered in the Nova db but not visible to ' 'either the floating or instance DNS driver. It ' 'will be ignored.'), dns_domain.domain) LOG.warn(_LW('Domain |%(domain)s| already exists, ' 'changing zone to |%(av_zone)s|.'), {'domain': domain, 'av_zone': av_zone}) LOG.warn(_LW('Domain |%(domain)s| already exists, ' 'changing project to |%(project)s|.'), {'domain': domain, 'project': project})"," LOG.info(_(""Floating IP %s is not associated. Ignore.""), LOG.warn(_('Address |%(address)s| is not allocated'), {'address': floating_ip.address}) LOG.warn(_('Address |%(address)s| is not allocated to your ' 'project |%(project)s|'), {'address': floating_ip.address, 'project': context.project_id}) LOG.warn(_(""Quota exceeded for %s, tried to allocate "" ""floating IP""), context.project_id) LOG.exception(_(""Failed to update usages deallocating "" ""floating IP"")) LOG.warn(_('Failed to disassociated floating ' 'address: %s'), floating_address) LOG.error(_('Interface %s not found'), interface) LOG.info(_(""Starting migration network for instance %s""), LOG.warn(_(""Floating ip address |%(address)s| no longer "" ""belongs to instance %(instance_uuid)s. Will not "" ""migrate it ""), LOG.info(_(""Finishing migration network for instance %s""), LOG.warn(_(""Floating ip address |%(address)s| no longer "" ""belongs to instance %(instance_uuid)s. Will not"" ""setup it.""), LOG.warn(_('Database inconsistency: DNS domain |%s| is ' 'registered in the Nova db but not visible to ' 'either the floating or instance DNS driver. It ' 'will be ignored.'), dns_domain.domain) LOG.warn(_('Domain |%(domain)s| already exists, ' 'changing zone to |%(av_zone)s|.'), {'domain': domain, 'av_zone': av_zone}) LOG.warn(_('Domain |%(domain)s| already exists, ' 'changing project to |%(project)s|.'), {'domain': domain, 'project': project})",148,125
openstack%2Fcinder~master~Id61fe3319172c8ff19ed421ead618e583a8d9263,openstack/cinder,master,Id61fe3319172c8ff19ed421ead618e583a8d9263,Add Oracle ZFSSA NFS Cinder Driver Support,MERGED,2014-12-08 17:20:31.000000000,2014-12-20 06:35:12.000000000,2014-12-18 18:57:44.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 13059}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-08 17:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/24309a802b57d82573cadd2e209ddce4982c7799', 'message': 'Add Oracle ZFSSA NFS Cinder Driver Support\n\nThis change will add a new Oracle ZFSSA NFS Driver to Cinder.\nThis driver supports all minimun features required by a driver for the kilo release.\nThis driver uses the base nfs driver methods for creating and deleting volumes.\n\nCertification test results: https://bugs.launchpad.net/cinder/+bug/1400406\n\nChange-Id: Id61fe3319172c8ff19ed421ead618e583a8d9263\nImplements: blueprint oracle-zfssa-nfs-cinder-driver\n'}, {'number': 2, 'created': '2014-12-08 19:30:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/aa903d978925382f52d1a0675603380a0e7474a3', 'message': 'Add Oracle ZFSSA NFS Cinder Driver Support\n\nThis change will add a new Oracle ZFSSA NFS Driver to Cinder.\nThis driver supports all minimun features required by a driver for the kilo release.\nThis driver uses the base nfs driver methods for creating and deleting volumes.\n\nCertification test results: https://bugs.launchpad.net/cinder/+bug/1400406\n\nChange-Id: Id61fe3319172c8ff19ed421ead618e583a8d9263\nImplements: blueprint oracle-zfssa-nfs-cinder-driver\n'}, {'number': 3, 'created': '2014-12-08 21:35:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4687452b2e4df2faa2a5d3b3c87c28c5cc0acbbe', 'message': 'Add Oracle ZFSSA NFS Cinder Driver Support\n\nThis change will add a new Oracle ZFSSA NFS Driver to Cinder.\nThis driver supports all minimun features required by a driver for the kilo release.\nThis driver uses the base nfs driver methods for creating and deleting volumes.\n\nCertification test results: https://bugs.launchpad.net/cinder/+bug/1400406\n\nChange-Id: Id61fe3319172c8ff19ed421ead618e583a8d9263\nImplements: blueprint oracle-zfssa-nfs-cinder-driver\n'}, {'number': 4, 'created': '2014-12-09 15:07:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a0d63a5992e5909eb7a3329a72f1074af014d80a', 'message': 'Add Oracle ZFSSA NFS Cinder Driver Support\n\nThis change will add a new Oracle ZFSSA NFS Driver to Cinder.\nThis driver supports all minimun features required by a driver for the kilo release.\nThis driver uses the base nfs driver methods for creating and deleting volumes.\n\nCertification test results: https://bugs.launchpad.net/cinder/+bug/1400406\n\nChange-Id: Id61fe3319172c8ff19ed421ead618e583a8d9263\nImplements: blueprint oracle-zfssa-nfs-cinder-driver\n'}, {'number': 5, 'created': '2014-12-09 19:56:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9702df10367dc42c279b8784f19a290d71a1db92', 'message': 'Add Oracle ZFSSA NFS Cinder Driver Support\n\nThis change will add a new Oracle ZFSSA NFS Driver to Cinder.\nThis driver supports all minimun features required by a driver for the kilo release.\nThis driver uses the base nfs driver methods for creating and deleting volumes.\n\nCertification test results: https://bugs.launchpad.net/cinder/+bug/1400406\n\nChange-Id: Id61fe3319172c8ff19ed421ead618e583a8d9263\nImplements: blueprint oracle-zfssa-nfs-cinder-driver\n'}, {'number': 6, 'created': '2014-12-09 22:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/484a36090b3025d4e814ecdf239241e3fa338cc1', 'message': 'Add Oracle ZFSSA NFS Cinder Driver Support\n\nThis change will add a new Oracle ZFSSA NFS Driver to Cinder.\nThis driver supports all minimum features required by a driver for the kilo release.\nThis driver uses the base nfs driver methods for creating and deleting volumes.\n\nCertification test results: https://bugs.launchpad.net/cinder/+bug/1400406\n\nChange-Id: Id61fe3319172c8ff19ed421ead618e583a8d9263\nImplements: blueprint oracle-zfssa-nfs-cinder-driver\n'}, {'number': 7, 'created': '2014-12-09 22:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/59c5e8301bf46c47512683eb5c92c39f5a611c19', 'message': 'Add Oracle ZFSSA NFS Cinder Driver Support\n\nThis change will add a new Oracle ZFSSA NFS Driver to Cinder.\nThis driver supports all minimum features required by a driver for the kilo release.\nThis driver uses the base nfs driver methods for creating and deleting volumes.\n\nCertification test results: https://bugs.launchpad.net/cinder/+bug/1400406\n\nChange-Id: Id61fe3319172c8ff19ed421ead618e583a8d9263\nImplements: blueprint oracle-zfssa-nfs-cinder-driver\n'}, {'number': 8, 'created': '2014-12-15 20:07:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/30cb08e7e39ff1677aee6a7f0e073ee6c8bfd50b', 'message': 'Add Oracle ZFSSA NFS Cinder Driver Support\n\nThis change will add a new Oracle ZFSSA NFS Driver to Cinder.\nThis driver supports all minimum features required by a driver for the kilo release.\nThis driver uses the base nfs driver methods for creating and deleting volumes.\n\nCertification test results: https://bugs.launchpad.net/cinder/+bug/1400406\n\nChange-Id: Id61fe3319172c8ff19ed421ead618e583a8d9263\nImplements: blueprint oracle-zfssa-nfs-cinder-driver\n'}, {'number': 9, 'created': '2014-12-16 14:48:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1f7e60b0d6184e0e83cdafeeddc7c6a92d6cc92c', 'message': 'Add Oracle ZFSSA NFS Cinder Driver Support\n\nThis change will add a new Oracle ZFSSA NFS Driver to Cinder.\nThis driver supports all minimum features required by a driver for the kilo release.\nThis driver uses the base nfs driver methods for creating and deleting volumes.\n\nCertification test results: https://bugs.launchpad.net/cinder/+bug/1400406\n\nChange-Id: Id61fe3319172c8ff19ed421ead618e583a8d9263\nImplements: blueprint oracle-zfssa-nfs-cinder-driver\n'}, {'number': 10, 'created': '2014-12-16 22:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cd20c72f8c0f8d12ef1bdc17268e61722f1ae936', 'message': 'Add Oracle ZFSSA NFS Cinder Driver Support\n\nThis change will add a new Oracle ZFSSA NFS Driver to Cinder.\nThis driver supports all minimum features required by a driver for the kilo release.\nThis driver uses the base nfs driver methods for creating and deleting volumes.\n\nCertification test results: https://bugs.launchpad.net/cinder/+bug/1400406\n\nChange-Id: Id61fe3319172c8ff19ed421ead618e583a8d9263\nImplements: blueprint oracle-zfssa-nfs-cinder-driver\n'}, {'number': 11, 'created': '2014-12-17 20:41:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e6fe2f70615fb9f997a98b8e2b938511285ff4f4', 'message': 'Add Oracle ZFSSA NFS Cinder Driver Support\n\nThis change will add a new Oracle ZFSSA NFS Driver to Cinder.\nThis driver supports all minimum features required by a driver for the kilo release.\nThis driver uses the base nfs driver methods for creating and deleting volumes.\n\nCertification test results: https://bugs.launchpad.net/cinder/+bug/1400406\n\nChange-Id: Id61fe3319172c8ff19ed421ead618e583a8d9263\nImplements: blueprint oracle-zfssa-nfs-cinder-driver\n'}, {'number': 12, 'created': '2014-12-17 22:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7f6ec6db83bef2382c7138a71c427020d117e9b7', 'message': 'Add Oracle ZFSSA NFS Cinder Driver Support\n\nThis change will add a new Oracle ZFSSA NFS Driver to Cinder.\nThis driver supports all minimum features required by a driver for the kilo release.\nThis driver uses the base nfs driver methods for creating and deleting volumes.\n\nCertification test results: https://bugs.launchpad.net/cinder/+bug/1400406\n\nChange-Id: Id61fe3319172c8ff19ed421ead618e583a8d9263\nImplements: blueprint oracle-zfssa-nfs-cinder-driver\n'}, {'number': 13, 'created': '2014-12-17 22:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cfa0b0980a7c5a7ed85189cf77fa2d89684a8234', 'message': 'Add Oracle ZFSSA NFS Cinder Driver Support\n\nThis change will add a new Oracle ZFSSA NFS Driver to Cinder.\nThis driver supports all minimum features required by a driver for the kilo release.\nThis driver uses the base nfs driver methods for creating and deleting volumes.\n\nCertification test results: https://bugs.launchpad.net/cinder/+bug/1400406\n\nChange-Id: Id61fe3319172c8ff19ed421ead618e583a8d9263\nImplements: blueprint oracle-zfssa-nfs-cinder-driver\n'}, {'number': 14, 'created': '2014-12-18 14:26:35.000000000', 'files': ['cinder/exception.py', 'cinder/volume/drivers/zfssa/zfssarest.py', 'cinder/volume/drivers/zfssa/zfssanfs.py', 'cinder/tests/test_zfssa.py', 'cinder/volume/drivers/zfssa/webdavclient.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/da4759b6bcb099552db9a938f9068cc9d0899eb1', 'message': 'Add Oracle ZFSSA NFS Cinder Driver Support\n\nThis change will add a new Oracle ZFSSA NFS Driver to Cinder.\nThis driver supports all minimum features required by a driver for the kilo release.\nThis driver uses the base nfs driver methods for creating and deleting volumes.\n\nCertification test results: https://bugs.launchpad.net/cinder/+bug/1400406\n\nChange-Id: Id61fe3319172c8ff19ed421ead618e583a8d9263\nImplements: blueprint oracle-zfssa-nfs-cinder-driver\n'}]",60,140082,da4759b6bcb099552db9a938f9068cc9d0899eb1,110,19,14,13059,,,0,"Add Oracle ZFSSA NFS Cinder Driver Support

This change will add a new Oracle ZFSSA NFS Driver to Cinder.
This driver supports all minimum features required by a driver for the kilo release.
This driver uses the base nfs driver methods for creating and deleting volumes.

Certification test results: https://bugs.launchpad.net/cinder/+bug/1400406

Change-Id: Id61fe3319172c8ff19ed421ead618e583a8d9263
Implements: blueprint oracle-zfssa-nfs-cinder-driver
",git fetch https://review.opendev.org/openstack/cinder refs/changes/82/140082/6 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/zfssa/zfssarest.py', 'cinder/volume/drivers/zfssa/zfssanfs.py', 'cinder/tests/test_zfssa.py', 'cinder/volume/drivers/zfssa/webdavclient.py']",4,24309a802b57d82573cadd2e209ddce4982c7799,bp/oracle-zfssa-nfs-cinder-driver,"# Copyright (c) 2014, Oracle and/or its affiliates. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" ZFS Storage Appliance WebDAV Client """""" import httplib import time import urllib2 from cinder.i18n import _ from cinder.openstack.common import log LOG = log.getLogger(__name__) bad_gateway_err = _('Check the state of the http service. Also ensure that' 'the https port number is the same as the one specified ' 'in cinder.conf. Source Volume name: %s , Destination ' 'Volume name: %s, Method: %s') WebDAVErrors = { httplib.UNAUTHORIZED: _('User not authorized to perform WebDAV ' 'operations. Source Volume name: %s, Destination ' 'volume name: %s, Method: %s'), httplib.BAD_GATEWAY: bad_gateway_err, httplib.FORBIDDEN: _('Check access permissions for the ZFS share assigned ' 'to this driver. Source Volume name: %s, Destination ' 'Volume name: %s, Method: %s'), httplib.NOT_FOUND: _('The source volume for this WebDAV operation not ' 'found. Source Volume name: %s, Destination Volume ' 'name: %s, Method: %s'), httplib.INSUFFICIENT_STORAGE: _('Not enough storage space in the zfs ' 'share to perform this operation. Source ' 'Volume name: %s, Destination Volume ' 'name: %s, Method: %s'), 'BadStatusLine': _('http service may have been abrupted disabled or put ' 'to maintenance state in the middle of this operation. ' 'Source Volume name: %s, Destination Volume name: %s, ' 'Method: %s'), 'Bad_Gateway': bad_gateway_err } class WebDAVClientError(Exception): """"""Exception for ZFS WebDAV client errors"""""" def __init__(self, code, reason, src_vol, dst_vol, method): """"""Create a WebDAV Response exception :param code: HTTP response code :param reason: The reason returned by the HTTP error :param vol: The volume name for which the WebDAV request failed :param method: The WebDAV method """""" super(WebDAVClientError, self).__init__(reason) self.code = code self.reason = reason self.msg = '' if code in httplib.responses: self.msg = httplib.responses[code] if code in WebDAVErrors: self.msg = WebDAVErrors[code] % (src_vol, dst_vol, method) LOG.error(self.msg) def __str__(self): return ""HTTP Error:%d %s %s"" % (self.code, self.reason, self.msg) class ZFSSAWebDAVClient(object): def __init__(self, url, auth_str, **kwargs): """"""Initialize WebDAV Client """""" self.https_path = url self.auth_str = auth_str def request(self, src_file="""", dst_file="""", method="""", maxretries=10): retry = 0 src_url = self.https_path + ""/"" + src_file dst_url = self.https_path + ""/"" + dst_file request = urllib2.Request(src_url) if dst_file != """": request.add_header('Destination', dst_url) request.add_header(""Authorization"", ""Basic %s"" % self.auth_str) request.get_method = lambda: method LOG.debug('Sending WebDAV request:%s %s %s %s' % (method, src_url, dst_url, self.auth_str)) while retry < maxretries: try: response = urllib2.urlopen(request, timeout=None) except urllib2.HTTPError as err: LOG.error(_('WebDAV returned with %(code)s error during ' '%(method)s call') % {'code': err.code, 'method': method}) if err.code == httplib.INTERNAL_SERVER_ERROR: exception_msg = (_('WebDAV operation failed with ' 'error code: %(code)s ' 'reason: %(reason)s ' 'Retry attempt %(retry)s in progress') % {'code': err.code, 'reason': err.reason, 'retry': retry}) LOG.error(exception_msg) if retry < maxretries: retry += 1 time.sleep(1) continue raise WebDAVClientError(err.code, err.reason, src_file, dst_file, method) except httplib.BadStatusLine as err: raise WebDAVClientError('BadStatusLine', 'httplib.BadStatusLine', src_file, dst_file, method) except urllib2.URLError as err: reason = '' if getattr(err, 'reason'): reason = err.reason raise WebDAVClientError('Bad_Gateway', reason, src_file, dst_file, method) break return response ",,857,0
openstack%2Fcinder~master~I554a67a2e19edb2e09c12febc339522719dfbe00,openstack/cinder,master,I554a67a2e19edb2e09c12febc339522719dfbe00,Fix HNAS driver initialization,MERGED,2014-12-15 18:16:47.000000000,2014-12-20 06:23:45.000000000,2014-12-19 02:01:59.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2759}, {'_account_id': 7198}, {'_account_id': 10058}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 13636}, {'_account_id': 13900}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-15 18:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/92bf7e44cefb2a9e97cd2daa9886ddb38bb134e4', 'message': 'Fix HNAS driver initialization\n\nIn iSCSI driver, when CHAP authentication is enabled, the driver would throw\nan error message in the attempt to create the first volume after the driver\ninitialization. This is fixed by passing the right value to set_targetsecret.\n\nCloses-Bug: #1402773\nChange-Id: I554a67a2e19edb2e09c12febc339522719dfbe00\n'}, {'number': 2, 'created': '2014-12-18 13:45:13.000000000', 'files': ['cinder/volume/drivers/hds/iscsi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2d86d870f6fe49f17b9c891d9d402b0b308f3e30', 'message': 'Fix HNAS driver initialization\n\nIn iSCSI driver, when CHAP authentication is enabled, the driver would throw\nan error message in the attempt to create the first volume after the driver\ninitialization. This is fixed by passing the right value to set_targetsecret.\n\nCloses-Bug: #1402773\nChange-Id: I554a67a2e19edb2e09c12febc339522719dfbe00\n'}]",0,141869,2d86d870f6fe49f17b9c891d9d402b0b308f3e30,30,16,2,10058,,,0,"Fix HNAS driver initialization

In iSCSI driver, when CHAP authentication is enabled, the driver would throw
an error message in the attempt to create the first volume after the driver
initialization. This is fixed by passing the right value to set_targetsecret.

Closes-Bug: #1402773
Change-Id: I554a67a2e19edb2e09c12febc339522719dfbe00
",git fetch https://review.opendev.org/openstack/cinder refs/changes/69/141869/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/hds/iscsi.py'],1,92bf7e44cefb2a9e97cd2daa9886ddb38bb134e4,fix-parser-error-3," 'cinder-' + label,"," svc['iscsi_target'],",1,1
openstack%2Ftaskflow~master~I966ae01d390c7217b858db3feb2db949ce5c08d1,openstack/taskflow,master,I966ae01d390c7217b858db3feb2db949ce5c08d1,Get the basics of a process executor working,MERGED,2014-09-13 02:13:56.000000000,2014-12-20 06:04:02.000000000,2014-12-20 06:04:00.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 8792}]","[{'number': 1, 'created': '2014-09-13 02:13:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5b6b8f78200013015ade634a8a0f856a667f0ff0', 'message': 'Work on getting a process executor working (WIP)\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased on so it would be great to support this where we can.\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 2, 'created': '2014-09-13 03:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c016f37ea36e247f023fd735351e46118ef86a95', 'message': 'Work on getting a process executor working (WIP)\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased on so it would be great to support this where we can.\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 3, 'created': '2014-09-13 03:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/362f8e78a27f29e0a881c5c64380c61d3c235ee9', 'message': 'Work on getting a process executor working (WIP)\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased on so it would be great to support this where we can.\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 4, 'created': '2014-09-13 04:05:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/48c5b9b578ae22c9aaa1591997e8a058f8be91bb', 'message': 'Work on getting a process executor working (WIP)\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased on so it would be great to support this where we can.\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 5, 'created': '2014-09-13 09:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/cacf5f67e61109f956b17760c70a36a514bf4db7', 'message': 'Work on getting a process executor working (WIP)\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased on so it would be great to support this where we can.\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 6, 'created': '2014-09-13 18:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/cd88d31a5bea643cdfa6807b80760d0790f2488c', 'message': 'Work on getting a process executor working (WIP)\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased on so it would be great to support this where we can.\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 7, 'created': '2014-09-13 23:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0921631dbc0b210fbce3c96142c62a1773d18c26', 'message': 'Work on getting a process executor working (WIP)\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased on so it would be great to support this where we can.\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 8, 'created': '2014-09-13 23:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/34eccc7b0215e9ddc7eeab92f61b5360b0f2121c', 'message': 'Work on getting a process executor working (WIP)\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased on so it would be great to support this where we can.\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 9, 'created': '2014-09-14 00:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/21c042f81cfa287ae5f50644e9ecc5802f532d41', 'message': 'Work on getting a process executor working (WIP)\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased on so it would be great to support this where we can.\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 10, 'created': '2014-09-14 00:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/725288c256c07f4ff863db0dce81450a7a09e379', 'message': 'Work on getting a process executor working (WIP)\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased on so it would be great to support this where we can.\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 11, 'created': '2014-09-14 01:21:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9985ba3db420cbb415246024e7fcc7995ad8e5fb', 'message': 'Work on getting a process executor working (WIP)\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased on so it would be great to support this where we can.\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 12, 'created': '2014-09-14 07:22:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5648c550990f126ed1d0d5ed4baa160009367c5e', 'message': 'Work on getting a process executor working (WIP)\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased on so it would be great to support this where we can.\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 13, 'created': '2014-09-14 17:22:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c32744ecf608353a6220beea6e9f7f5baf0967db', 'message': 'Work on getting a process executor working (WIP)\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased on so it would be great to support this where we can.\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 14, 'created': '2014-09-14 22:29:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8e3eb244513a45444e934f580ebd937150f60043', 'message': 'Work on getting a process executor working (WIP)\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased on so it would be great to support this where we can.\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 15, 'created': '2014-09-14 22:52:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a27c24fc44d6625d836e290b515e05cedaf7f643', 'message': 'Work on getting a process executor working (WIP)\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 16, 'created': '2014-09-15 00:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ae637b31f91f59a6e1d1f6f71b954a6aa1f25c97', 'message': ""Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently not going to work:\n * Custom registered task event handlers (we currently only\n   proxy 'update_progress' events).\n * Non-pickleable tasks (tasks with attributes that can not\n   be pickled...)\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n""}, {'number': 17, 'created': '2014-09-15 00:41:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a76d1e2817c62c84a31a20d4899786c89b2fcfa7', 'message': ""Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently not going to work:\n * Custom registered task event handlers (we currently only\n   proxy 'update_progress' events).\n * Non-pickleable tasks (tasks with attributes that can not\n   be pickled...)\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n""}, {'number': 18, 'created': '2014-09-15 03:32:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7f2b29e389c486f0bc8ae59759abc2b328bad3e9', 'message': ""Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently not going to work:\n * Custom registered task event handlers (we currently only\n   proxy 'update_progress' events).\n * Non-pickleable tasks (tasks with attributes that can not\n   be pickled...)\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n""}, {'number': 19, 'created': '2014-09-15 04:42:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/761757ef0e7ea0565d5a5e7d891069e3e7a67d7f', 'message': ""Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently not going to work:\n * Custom registered task event handlers (we currently only\n   proxy 'update_progress' events).\n * Non-pickleable tasks (tasks with attributes that can not\n   be pickled...)\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n""}, {'number': 20, 'created': '2014-09-15 19:29:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2b62abafc08f0dbac8cf60ecf5f805b86e3ec44c', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently not going to work:\n\n * Non-pickleable/copyable tasks\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 21, 'created': '2014-09-15 19:33:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ab5e6bb0b21e611cdd83e945f0368d73c2aa76bd', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently not going to work:\n\n * Non-pickleable/copyable tasks\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 22, 'created': '2014-09-15 19:35:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/50cf4396f3a297cf0ba3a1bd52929031cd231b28', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently not going to work:\n\n * Non-pickleable/copyable tasks\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 23, 'created': '2014-09-15 19:46:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d2789c73120f84bdc0d546a4dccdee01a9f81313', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently not going to work:\n\n * Non-pickleable/copyable tasks\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 24, 'created': '2014-09-15 23:34:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f2d944d9c03232d745068b413194e68beeb7c037', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 25, 'created': '2014-09-16 00:26:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3d6d7c52e210c810a1550cc009de565290633481', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 26, 'created': '2014-09-16 00:45:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4da6ac0d5732b617c817690fd865d7f35dfb340c', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 27, 'created': '2014-09-16 00:49:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/fcdc27fafeb3ed336eeea5f48063791db31a9953', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 28, 'created': '2014-09-16 00:49:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/cf957965440e3b59077c5930615623a41dd9fc59', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 29, 'created': '2014-09-16 19:17:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9490a8295869839349d059c9e94e8747958abb05', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 30, 'created': '2014-09-16 19:29:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/101c75a9310e6ccb60d4e3f6230596d66422ed0a', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 31, 'created': '2014-09-16 19:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9960caa34c6740395145cb2305e65d6c780a3c2d', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 32, 'created': '2014-09-17 22:11:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/335384f4b9253f9dc4074e53384e4ca71fdfcacd', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 33, 'created': '2014-09-18 22:23:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1f961f2e74ca421660377b7564a2481cc2fd38f9', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 34, 'created': '2014-09-18 23:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/24e91027c75f3a2579fbad2a10804da48f845c30', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 35, 'created': '2014-09-19 20:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ed6deb8afd7e9adc02620bdb8f1d0b0fdf14008b', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 36, 'created': '2014-09-23 03:20:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ed2525e0bb51a0d4b616aa461306a92e5e39e1fa', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 37, 'created': '2014-09-26 20:55:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/48a3f23680ca084124fc1d1af51c4c9435e1cb37', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 38, 'created': '2014-10-15 00:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0e9fec0bf6b4b234b358fc18a322fa1445bd0b37', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 39, 'created': '2014-10-15 01:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/af45a38a083ce97a02e22bd4e63b280b1cf97c7e', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 40, 'created': '2014-10-19 04:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/165303282e1b3fc8db63cf0e47acb049c8719cf3', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 41, 'created': '2014-10-19 06:51:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5d7e86fcb2b441de78c647a4bdb55d8a07093bf5', 'message': 'Get the basics of a process executor working (WIP)\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 42, 'created': '2014-10-23 02:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/df4f0f819a8f383d3bf8b91665fd3a544663ae9b', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 43, 'created': '2014-10-23 04:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3576070f4c9d05a3121961109f418b742855cdec', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 44, 'created': '2014-10-23 04:35:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b9079399945096ea116574f9cb7193e661f5ed6a', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 45, 'created': '2014-10-23 23:00:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6cb6bdd12c7c20961831dd5579ab7b98d77828ea', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 46, 'created': '2014-10-26 03:13:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f82a859a8c87084123c26c5f284c4cadbfe48db9', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 47, 'created': '2014-10-28 02:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3ecb6a6c28313908a0197fb6bc8dc6b3bbdb7673', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 48, 'created': '2014-10-28 03:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/388e0dffca7aa71b7da2dbb454b56d71d6057047', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 49, 'created': '2014-10-29 01:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/216d31932ea13fa1f97164519b8c133924eb19e8', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 50, 'created': '2014-10-29 01:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9bee95406ed28277c452ed145b9a2fcb4d718900', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 51, 'created': '2014-10-30 04:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/59ae7476875ace019e319337ed30044dc1d7af82', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 52, 'created': '2014-11-01 00:58:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9e4d32270e5f15c6768aed84d18d1d53b934042a', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 53, 'created': '2014-11-01 04:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a0032eb7a6665d892ad379fe24eeabccc338f69e', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 54, 'created': '2014-11-01 04:33:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f4b993f874123ffab17ec317f223c698617b8fb8', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 55, 'created': '2014-11-04 09:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7c6a6afc2c2492377472efb5c458f44b2158cb92', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 56, 'created': '2014-11-04 10:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2857faacdac0dad4b2a628c6571340e939200764', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 57, 'created': '2014-11-15 02:53:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ca3601287318ab4a8c60cc4b0c7f27e6f41fd0bb', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 58, 'created': '2014-11-15 03:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/20fe34b16bebe426304f84499cafad76eb7ea18c', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 59, 'created': '2014-11-15 12:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9818f804185ac9ed6b6c3092a2a32df87f063fda', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 60, 'created': '2014-11-17 20:52:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8d1ce1f1319a7283478dfbd918434a74be038671', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 61, 'created': '2014-11-19 19:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/73f0dae023e41362b7f5a137caf713027382c89f', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 62, 'created': '2014-12-06 23:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b9cbe21ef3d8a6325b14f6cca280450e9c865c18', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 63, 'created': '2014-12-13 07:08:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1f48b1b67c4bc7f6f0edb68975a140cb76cd6f53', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 64, 'created': '2014-12-14 04:50:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e529959b086994135378ec62167ede200d03976b', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 65, 'created': '2014-12-14 04:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e918c40826bc76fce45081a64f8279d226ac2fd1', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 66, 'created': '2014-12-14 04:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3b8eefd27f06375321ad5735abe67986f819810d', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 67, 'created': '2014-12-15 07:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/fd3404f32ff136e39aa0b94a38efdaca162448ef', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 68, 'created': '2014-12-18 22:49:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5747e3c057bdc98778714a0d87e52e03ca4ad184', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}, {'number': 69, 'created': '2014-12-20 04:48:24.000000000', 'files': ['taskflow/engines/worker_based/engine.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/engines/worker_based/executor.py', 'doc/source/engines.rst', 'taskflow/tests/unit/test_engines.py', 'taskflow/utils/threading_utils.py', 'doc/source/conf.py', 'taskflow/engines/action_engine/executor.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2a8fde1798dbcaab53d0a1aba9740f729ba64f83', 'message': 'Get the basics of a process executor working\n\nSince we support various executors (threaded and distributed)\nthe next best executor when a threaded executor will not perform\nand a distributed one requires to much setup is a local process\nbased one so it would be great to support this where we can.\n\nThings that are currently (likely never) not going to work:\n\n * Non-pickleable/non-copyable tasks\n * Tasks that return non-pickleable/non-copyable results\n * Tasks that use non-pickleable/non-copyable args/kwargs\n\nPart of blueprint process-executor\n\nChange-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1\n'}]",0,121280,2a8fde1798dbcaab53d0a1aba9740f729ba64f83,153,3,69,1297,,,0,"Get the basics of a process executor working

Since we support various executors (threaded and distributed)
the next best executor when a threaded executor will not perform
and a distributed one requires to much setup is a local process
based one so it would be great to support this where we can.

Things that are currently (likely never) not going to work:

 * Non-pickleable/non-copyable tasks
 * Tasks that return non-pickleable/non-copyable results
 * Tasks that use non-pickleable/non-copyable args/kwargs

Part of blueprint process-executor

Change-Id: I966ae01d390c7217b858db3feb2db949ce5c08d1
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/80/121280/31 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/task.py', 'taskflow/tests/unit/worker_based/test_protocol.py', 'taskflow/tests/unit/worker_based/test_pipeline.py', 'taskflow/engines/worker_based/endpoint.py', 'taskflow/engines/action_engine/task_action.py', 'taskflow/engines/action_engine/executor.py', 'taskflow/engines/action_engine/runner.py', 'taskflow/engines/action_engine/retry_action.py', 'taskflow/engines/worker_based/protocol.py']",9,5b6b8f78200013015ade634a8a0f856a667f0ff0,bp/process-executor," self.result.atom = task self.result.set_result((self._event, result))"," self.result.set_result((self._task, self._event, result))",49,28
openstack%2Ffuel-docs~stable%2F5.1~Id36b2aa4c6bd46c6115175f01cde1ca84a146dd8,openstack/fuel-docs,stable/5.1,Id36b2aa4c6bd46c6115175f01cde1ca84a146dd8,Adds Murano w/a for RN 5.1.1,MERGED,2014-12-18 12:59:23.000000000,2014-12-20 05:51:24.000000000,2014-12-19 20:32:51.000000000,"[{'_account_id': 3}, {'_account_id': 7613}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 10014}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-12-18 12:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/ef5a11ab69f7554c2a896a2a2acf5e4f11922f18', 'message': 'Adds Murano w/a for RN 5.1.1\n\nAccording to Igor Yozhikov request, I added w/a for an issue with Murano\n(https://bugs.launchpad.net/bugs/1401503)\n\nChange-Id: Id36b2aa4c6bd46c6115175f01cde1ca84a146dd8\nPartial-Bug: 1401503\n'}, {'number': 2, 'created': '2014-12-18 13:03:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/7853b9c090f581dc412a82506991c45b29a4e6f7', 'message': 'Adds Murano w/a for RN 5.1.1\n\nAccording to Igor Yozhikov request, I added w/a for an issue with Murano\n(https://bugs.launchpad.net/bugs/1401503)\n\nChange-Id: Id36b2aa4c6bd46c6115175f01cde1ca84a146dd8\nPartial-Bug: 1401503\n'}, {'number': 3, 'created': '2014-12-18 16:57:58.000000000', 'files': ['pages/release-notes/v5-1/050-known-issues.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/ac76778f52dec919eb2703b749fa6018f65730d5', 'message': 'Adds Murano w/a for RN 5.1.1\n\nAccording to Igor Yozhikov request, I added w/a for an issue with Murano\n(https://bugs.launchpad.net/bugs/1401503)\n\nChange-Id: Id36b2aa4c6bd46c6115175f01cde1ca84a146dd8\nPartial-Bug: 1401503\n'}]",4,142761,ac76778f52dec919eb2703b749fa6018f65730d5,19,6,3,13082,,,0,"Adds Murano w/a for RN 5.1.1

According to Igor Yozhikov request, I added w/a for an issue with Murano
(https://bugs.launchpad.net/bugs/1401503)

Change-Id: Id36b2aa4c6bd46c6115175f01cde1ca84a146dd8
Partial-Bug: 1401503
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/61/142761/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v5-1/050-known-issues.rst'],1,ef5a11ab69f7554c2a896a2a2acf5e4f11922f18,bug/1401503,"Enabled Murano prevents the controller from redeployment -------------------------------------------------------- When Murano is deployed at CentOS, redeployment of the controller might fail. To work this problem around, follow these steps: #. Deploy the Fuel Master node. #. Log into the Fuel Master node as root. #. Install patch package: :: yum install patch -y #. Download the patch from `LP1401503 <https://bugs.launchpad.net/bugs/1401503>`_. and apply it: :: patch --verbos -p0 < apps-upload-check.patch ",,23,0
openstack%2Fglance~master~Id1dd51c4e2fa2adfdb42837f470a9484f12ea2b1,openstack/glance,master,Id1dd51c4e2fa2adfdb42837f470a9484f12ea2b1,"v1 API: allow fetching of images in ""pending_delete"" state",ABANDONED,2014-05-13 19:05:27.000000000,2014-12-20 05:50:40.000000000,,"[{'_account_id': 3}, {'_account_id': 5202}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-05-13 19:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/891c56a356bf894269f21eb58dd69848b22aaf29', 'message': 'v1 API: allow fetching of images in ""pending_delete"" state\n\nImages in a ""pending_delete"" state are deemed ""recoverable"", and\nthe image metadata is available, but the image data is not.  This\nmakes things in Nova like ""live migrations of instances spawned\nfrom deleted images"" not work, as it wants to use Glance to reconstruct\nall the files it expects to see in its imagecache, and Glance won\'t\ngive them up.\n\nAlter the API to return the image data if it is asked for by name.\npending_delete images still do not show up in lists, etc. so this\nin minimally-impacting\n\nChange-Id: Id1dd51c4e2fa2adfdb42837f470a9484f12ea2b1\n'}, {'number': 2, 'created': '2014-05-13 19:06:32.000000000', 'files': ['glance/api/v1/controller.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/af3acce7abbddd5586dd98065d07fd489652bbaf', 'message': 'v1 API: allow fetching of images in ""pending_delete"" state\n\nImages in a ""pending_delete"" state are deemed ""recoverable"", and\nthe image metadata is available, but the image data is not.  This\nmakes things in Nova like ""live migrations of instances spawned\nfrom deleted images"" not work, as it wants to use Glance to reconstruct\nall the files it expects to see in its imagecache, and Glance won\'t\ngive them up.\n\nAlter the API to return the image data if it is asked for by name.\npending_delete images still do not show up in lists, etc. so this\nin minimally-impacting\n\nCloses-Bug: 1319150\nChange-Id: Id1dd51c4e2fa2adfdb42837f470a9484f12ea2b1\n'}]",2,93486,af3acce7abbddd5586dd98065d07fd489652bbaf,9,3,2,5280,,,0,"v1 API: allow fetching of images in ""pending_delete"" state

Images in a ""pending_delete"" state are deemed ""recoverable"", and
the image metadata is available, but the image data is not.  This
makes things in Nova like ""live migrations of instances spawned
from deleted images"" not work, as it wants to use Glance to reconstruct
all the files it expects to see in its imagecache, and Glance won't
give them up.

Alter the API to return the image data if it is asked for by name.
pending_delete images still do not show up in lists, etc. so this
in minimally-impacting

Closes-Bug: 1319150
Change-Id: Id1dd51c4e2fa2adfdb42837f470a9484f12ea2b1
",git fetch https://review.opendev.org/openstack/glance refs/changes/86/93486/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/api/v1/controller.py'],1,891c56a356bf894269f21eb58dd69848b22aaf29,bug/1319150," image isn't 'active' or 'pending_delete'. if image['status'] not in ('active', 'pending_delete'):", image isn't 'active'. if image['status'] != 'active':,2,2
openstack%2Fcinder~master~I90b81f0c11fa7e7d0bb9a0e24dd9c9a4dd90de34,openstack/cinder,master,I90b81f0c11fa7e7d0bb9a0e24dd9c9a4dd90de34,Updated from global requirements,MERGED,2014-12-11 07:12:57.000000000,2014-12-20 05:26:00.000000000,2014-12-18 11:42:48.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 4523}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 13900}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-11 07:12:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c034dd3e55c0e1d1cb531f0a5b2b3eb49818c4bc', 'message': 'Updated from global requirements\n\nChange-Id: I90b81f0c11fa7e7d0bb9a0e24dd9c9a4dd90de34\n'}, {'number': 2, 'created': '2014-12-12 22:13:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fd123e5e14c7c9e7103b0742802450e05673b8e4', 'message': 'Updated from global requirements\n\nChange-Id: I90b81f0c11fa7e7d0bb9a0e24dd9c9a4dd90de34\n'}, {'number': 3, 'created': '2014-12-16 19:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9b5c1a135ad1eb8b95aa9584c8474d1d9c84d168', 'message': 'Updated from global requirements\n\nChange-Id: I90b81f0c11fa7e7d0bb9a0e24dd9c9a4dd90de34\n'}, {'number': 4, 'created': '2014-12-17 04:04:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/75344bdb4bbc77b66c024cec173714ea00c7bb10', 'message': 'Updated from global requirements\n\nChange-Id: I90b81f0c11fa7e7d0bb9a0e24dd9c9a4dd90de34\n'}, {'number': 5, 'created': '2014-12-18 01:21:16.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d4e59908713b0c3e09f744cf3be4d8eed1b88e3c', 'message': 'Updated from global requirements\n\nChange-Id: I90b81f0c11fa7e7d0bb9a0e24dd9c9a4dd90de34\n'}]",0,140938,d4e59908713b0c3e09f744cf3be4d8eed1b88e3c,42,15,5,11131,,,0,"Updated from global requirements

Change-Id: I90b81f0c11fa7e7d0bb9a0e24dd9c9a4dd90de34
",git fetch https://review.opendev.org/openstack/cinder refs/changes/38/140938/3 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c034dd3e55c0e1d1cb531f0a5b2b3eb49818c4bc,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Fcinder~master~I444b961a6543886da35fb44127b1cf7c509ce8d8,openstack/cinder,master,I444b961a6543886da35fb44127b1cf7c509ce8d8,Fixed wait for job completion in VMAX driver,MERGED,2014-12-03 22:08:26.000000000,2014-12-20 05:14:14.000000000,2014-12-18 10:47:46.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 4355}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12780}, {'_account_id': 14084}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-03 22:08:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7aa5ee7c0b629f80fa02a4062d9b6b490bb2079e', 'message': 'Fixed wait for job completion in VMAX driver\n\nChange-Id: I444b961a6543886da35fb44127b1cf7c509ce8d8\nCloses-Bug: #1393568\n'}, {'number': 2, 'created': '2014-12-07 20:08:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bfc541e7ed50db27a2326d6aac3b6b4d3f62b681', 'message': 'Fixed wait for job completion in VMAX driver\n\nThe VMAX driver used non-thread-safe variables in the wait for job\ncompletion routines, resulting in failures or timeouts during concurrent\noperations. This patch fixed the problem.\n\nCloses-Bug: #1393568\nChange-Id: I444b961a6543886da35fb44127b1cf7c509ce8d8\n'}, {'number': 3, 'created': '2014-12-07 21:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e864f18d23cd4e3092b70e4337e57f45ab1cb117', 'message': 'Fixed wait for job completion in VMAX driver\n\nThe VMAX driver used non-thread-safe variables in the wait for job\ncompletion routines, resulting in failures or timeouts during concurrent\noperations. This patch fixed the problem.\n\nCloses-Bug: #1393568\nChange-Id: I444b961a6543886da35fb44127b1cf7c509ce8d8\n'}, {'number': 4, 'created': '2014-12-10 06:04:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/067a35e779e47de0fdf13421046c2c4758cd9eb8', 'message': 'Fixed wait for job completion in VMAX driver\n\nThe VMAX driver used non-thread-safe variables in the wait for job\ncompletion routines, resulting in failures or timeouts during concurrent\noperations. This patch fixed the problem.\n\nCloses-Bug: #1393568\nChange-Id: I444b961a6543886da35fb44127b1cf7c509ce8d8\n'}, {'number': 5, 'created': '2014-12-15 05:14:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d0416308e9700b7f5fced83798fc735007de4061', 'message': 'Fixed wait for job completion in VMAX driver\n\nThe VMAX driver used non-thread-safe variables in the wait for job\ncompletion routines, resulting in failures or timeouts during concurrent\noperations. This patch fixed the problem.\n\nCloses-Bug: #1393568\nChange-Id: I444b961a6543886da35fb44127b1cf7c509ce8d8\n'}, {'number': 6, 'created': '2014-12-17 23:23:15.000000000', 'files': ['cinder/volume/drivers/emc/emc_vmax_utils.py', 'cinder/tests/test_emc_vmax.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e845c1182dde5aa8858290c2719b017fb5ca5915', 'message': 'Fixed wait for job completion in VMAX driver\n\nThe VMAX driver used non-thread-safe variables in the wait for job\ncompletion routines, resulting in failures or timeouts during concurrent\noperations. This patch fixed the problem.\n\nCloses-Bug: #1393568\nChange-Id: I444b961a6543886da35fb44127b1cf7c509ce8d8\n'}]",1,138878,e845c1182dde5aa8858290c2719b017fb5ca5915,64,18,6,6491,,,0,"Fixed wait for job completion in VMAX driver

The VMAX driver used non-thread-safe variables in the wait for job
completion routines, resulting in failures or timeouts during concurrent
operations. This patch fixed the problem.

Closes-Bug: #1393568
Change-Id: I444b961a6543886da35fb44127b1cf7c509ce8d8
",git fetch https://review.opendev.org/openstack/cinder refs/changes/78/138878/6 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/emc/emc_vmax_provision.py', 'cinder/volume/drivers/emc/emc_vmax_common.py', 'cinder/volume/drivers/emc/emc_vmax_fc.py', 'cinder/volume/drivers/emc/emc_vmax_utils.py', 'cinder/volume/drivers/emc/emc_vmax_masking.py', 'cinder/volume/drivers/emc/emc_vmax_fast.py', 'cinder/tests/test_emc_vmax.py']",7,7aa5ee7c0b629f80fa02a4062d9b6b490bb2079e,bp/emc-vmax-driver-kilo-update," SyncType=None, SourceElement=None, TargetElement=None, def _getinstance_syncsvsv(self, objectpath): svInstance = {} svInstance['SyncedElement'] = 'SyncedElement' svInstance['SystemElement'] = 'SystemElement' svInstance['PercentSynced'] = 100 return svInstance EMCVMAXUtils, 'get_volume_meta_head', return_value=[EMCVMAXCommonData.test_volume]) @mock.patch.object( EMCVMAXUtils, 'get_meta_members_capacity_in_bit', return_value=[1234567, 7654321]) @mock.patch.object( '_get_pool_and_storage_system', return_value=(None, EMCVMAXCommonData.storage_system)) def test_create_snapshot_different_sizes_meta_no_fast_success( self, mock_volume_type, mock_volume, mock_meta, mock_size, mock_pool): common = self.driver.common volumeDict = {'classname': u'Symm_StorageVolume', 'keybindings': EMCVMAXCommonData.keybindings} common.provision.create_volume_from_pool = ( mock.Mock(return_value=(volumeDict, 0L))) common.provision.get_volume_dict_from_job = ( mock.Mock(return_value=volumeDict)) @mock.patch.object( EMCVMAXUtils, 'get_volume_meta_head', return_value=[EMCVMAXCommonData.test_volume]) @mock.patch.object( EMCVMAXUtils, 'get_meta_members_capacity_in_bit', return_value=[1234567]) def test_create_volume_from_same_size_meta_snapshot( self, mock_volume_type, mock_sync_sv, mock_meta, mock_size): self.data.test_volume, self.data.test_volume) @mock.patch.object( EMCVMAXUtils, 'get_volume_meta_head', return_value=None) def test_create_clone_simple_volume_no_fast_success(self, mock_volume_type, mock_volume, mock_sync_sv, mock_simple_volume): return_value={'volume_backend_name': 'ISCSIFAST'}) EMCVMAXFast, 'get_pool_associated_to_policy', 'get_volume_meta_head', return_value=[EMCVMAXCommonData.test_volume]) @mock.patch.object( EMCVMAXUtils, 'get_meta_members_capacity_in_bit', return_value=[1234567, 7654321]) '_get_pool_and_storage_system', return_value=(None, EMCVMAXCommonData.storage_system)) def test_create_snapshot_different_sizes_meta_fast_success( self, mock_volume_type, mock_volume,mock_meta, mock_size, mock_pool, mock_policy): common = self.driver.common volumeDict = {'classname': u'Symm_StorageVolume', 'keybindings': EMCVMAXCommonData.keybindings} common.provision.create_volume_from_pool = ( mock.Mock(return_value=(volumeDict, 0L))) common.provision.get_volume_dict_from_job = ( mock.Mock(return_value=volumeDict)) common.fast.is_volume_in_default_SG = ( mock.Mock(return_value=True)) return_value={'volume_backend_name': 'ISCSIFAST'}) 'get_volume_meta_head', return_value=[EMCVMAXCommonData.test_volume]) 'get_meta_members_capacity_in_bit', return_value=[1234567]) def test_create_volume_from_same_size_meta_snapshot( self, mock_volume_type, mock_sync_sv, mock_meta, mock_size): common = self.driver.common self.driver.common.utils.find_storage_configuration_service = ( mock.Mock(return_value=EMCVMAXCommonData.storage_system)) self.driver.common._get_or_create_default_storage_group = ( mock.Mock(return_value=EMCVMAXCommonData.default_storage_group)) self.driver.common.fast.is_volume_in_default_SG = ( mock.Mock(return_value=True)) self.data.test_volume, self.data.test_volume) @mock.patch.object( EMCVMAXUtils, 'get_volume_meta_head', return_value=None) self, mock_type, mock_rep_service, mock_sync_sv, mock_meta): return_value={'volume_backend_name': 'ISCSIFAST'}) 'get_volume_meta_head', return_value=None) def test_create_clone_simple_volume_fast_success(self, mock_volume_type, mock_volume, mock_sync_sv, mock_simple_volume): self.driver.common.utils.find_storage_configuration_service = ( mock.Mock(return_value=EMCVMAXCommonData.storage_system)) self.driver.common._get_or_create_default_storage_group = ( mock.Mock(return_value=EMCVMAXCommonData.default_storage_group)) self.driver.common.fast.is_volume_in_default_SG = ( mock.Mock(return_value=True)) return_value={'volume_backend_name': 'ISCSIFAST'}) @mock.patch.object( FakeDB, 'volume_get', return_value=EMCVMAXCommonData.test_source_volume) @mock.patch.object( EMCVMAXFast, 'get_pool_associated_to_policy', return_value=1) @mock.patch.object( EMCVMAXUtils, 'get_volume_meta_head', return_value=[EMCVMAXCommonData.test_volume]) @mock.patch.object( EMCVMAXUtils, 'get_meta_members_capacity_in_bit', return_value=[1234567, 7654321]) '_get_pool_and_storage_system', return_value=(None, EMCVMAXCommonData.storage_system)) def test_create_clone_fast_failed(self, mock_volume_type, mock_vol, mock_policy, mock_meta, mock_size, mock_pool): self.driver.common._modify_and_get_composite_volume_instance = ( mock.Mock(return_value=(1L, None))) return_value={'volume_backend_name': 'FCFAST'}) EMCVMAXFast, 'get_pool_associated_to_policy', 'get_volume_meta_head', return_value=[EMCVMAXCommonData.test_volume]) @mock.patch.object( EMCVMAXUtils, 'get_meta_members_capacity_in_bit', return_value=[1234567, 7654321]) '_get_pool_and_storage_system', return_value=(None, EMCVMAXCommonData.storage_system)) def test_create_snapshot_different_sizes_meta_fast_success( self, mock_volume_type, mock_volume, mock_meta, mock_size, mock_pool, mock_policy): common = self.driver.common volumeDict = {'classname': u'Symm_StorageVolume', 'keybindings': EMCVMAXCommonData.keybindings} common.provision.create_volume_from_pool = ( mock.Mock(return_value=(volumeDict, 0L))) common.provision.get_volume_dict_from_job = ( mock.Mock(return_value=volumeDict)) common.fast.is_volume_in_default_SG = ( mock.Mock(return_value=True)) return_value={'volume_backend_name': 'FCFAST'}) 'get_volume_meta_head', def test_create_clone_simple_volume_fast_success(self, mock_volume_type, mock_volume, mock_sync_sv, mock_meta): self.driver.common.utils.find_storage_configuration_service = ( mock.Mock(return_value=EMCVMAXCommonData.storage_system)) self.driver.common._get_or_create_default_storage_group = ( mock.Mock(return_value=EMCVMAXCommonData.default_storage_group)) self.driver.common.fast.is_volume_in_default_SG = ( mock.Mock(return_value=True)) EMCVMAXCommonData.test_source_volume) FakeDB, 'volume_get', return_value=EMCVMAXCommonData.test_source_volume) @mock.patch.object( EMCVMAXFast, 'get_pool_associated_to_policy', return_value=1) @mock.patch.object( 'get_volume_meta_head', return_value=[EMCVMAXCommonData.test_volume]) @mock.patch.object( EMCVMAXUtils, 'get_meta_members_capacity_in_bit', return_value=[1234567, 7654321]) '_get_pool_and_storage_system', return_value=(None, EMCVMAXCommonData.storage_system)) def test_create_clone_fast_failed(self, mock_volume_type, mock_vol, mock_policy, mock_meta, mock_size, mock_pool): self.driver.common._modify_and_get_composite_volume_instance = ( mock.Mock(return_value=(1L, None)))"," SyncType=None, SourceElement=None, '_find_storage_sync_sv_sv', return_value=(None, None)) def test_create_snapshot_no_fast_success( self, mock_volume_type, mock_volume, mock_sync_sv): FakeDB, 'volume_get', return_value=EMCVMAXCommonData.test_source_volume) @mock.patch.object( def test_create_volume_from_snapshot_no_fast_success( self, mock_volume_type, mock_volume, mock_sync_sv): self.data.test_volume, EMCVMAXCommonData.test_source_volume) def test_create_clone_no_fast_success(self, mock_volume_type, mock_volume, mock_sync_sv): return_value={'volume_backend_name': 'ISCSIFAST', 'FASTPOLICY': 'FC_GOLD1'}) @mock.patch.object( EMCVMAXUtils, 'find_storage_masking_group', return_value=EMCVMAXCommonData.storagegroupname) EMCVMAXCommon, '_find_storage_sync_sv_sv', return_value=(None, None)) @mock.patch.object( EMCVMAXUtils, 'find_storage_configuration_service', 'find_controller_configuration_service', return_value=1) '_get_or_create_default_storage_group', return_value=1) def test_create_snapshot_fast_success( self, mock_volume_type, mock_storage_group, mock_volume, mock_sync_sv, mock_storage_config_service, mock_controller_service, mock_default_sg): return_value={'volume_backend_name': 'ISCSIFAST', 'FASTPOLICY': 'FC_GOLD1'}) @mock.patch.object( EMCVMAXUtils, 'find_storage_masking_group', return_value=EMCVMAXCommonData.storagegroupname) @mock.patch.object( FakeDB, 'volume_get', return_value=EMCVMAXCommonData.test_source_volume) 'find_storage_configuration_service', return_value=1) 'find_controller_configuration_service', return_value=1) @mock.patch.object( EMCVMAXCommon, '_get_or_create_default_storage_group', return_value=1) def test_create_volume_from_snapshot_fast_success( self, mock_volume_type, mock_storage_group, mock_volume, mock_sync_sv, mock_storage_config_service, mock_controller_service, mock_default_sg): self.data.test_volume, EMCVMAXCommonData.test_source_volume) self, mock_volume_type, mock_rep_service, mock_sync_sv): return_value={'volume_backend_name': 'ISCSIFAST', 'FASTPOLICY': 'FC_GOLD1'}) @mock.patch.object( EMCVMAXUtils, 'find_storage_masking_group', return_value=EMCVMAXCommonData.storagegroupname) 'find_storage_configuration_service', return_value=1) @mock.patch.object( EMCVMAXUtils, 'find_controller_configuration_service', return_value=1) @mock.patch.object( EMCVMAXCommon, '_get_or_create_default_storage_group', return_value=1) def test_create_clone_fast_success(self, mock_volume_type, mock_storage_group, mock_volume, mock_sync_sv, mock_storage_config_service, mock_controller_service, mock_default_sg): return_value={'volume_backend_name': 'ISCSIFAST', 'FASTPOLICY': 'FC_GOLD1'}) '_find_storage_sync_sv_sv', return_value=(None, None)) def test_create_clone_fast_failed(self, mock_volume_type, mock_sync_sv): @mock.patch.object( FakeDB, 'volume_get', return_value=EMCVMAXCommonData.test_source_volume) @mock.patch.object( EMCVMAXCommon, '_find_storage_sync_sv_sv', return_value=(None, None)) def test_create_snapshot_no_fast_success( self, mock_volume_type, mock_volume, mock_sync_sv): self.data.test_volume['volume_name'] = ""vmax-1234567"" self.driver.create_snapshot(self.data.test_volume) def test_create_snapshot_no_fast_failed(self): self.data.test_volume['volume_name'] = ""vmax-1234567"" self.assertRaises(exception.VolumeBackendAPIException, self.driver.create_snapshot, self.data.test_volume) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) @mock.patch.object( FakeDB, 'volume_get', return_value=EMCVMAXCommonData.test_source_volume) @mock.patch.object( EMCVMAXCommon, '_find_storage_sync_sv_sv', return_value=(None, None)) def test_create_volume_from_snapshot_no_fast_success( self, mock_volume_type, mock_volume, mock_sync_sv): self.data.test_volume['volume_name'] = ""vmax-1234567"" self.driver.create_volume_from_snapshot( self.data.test_volume, EMCVMAXCommonData.test_source_volume) def test_create_volume_from_snapshot_no_fast_failed(self): self.data.test_volume['volume_name'] = ""vmax-1234567"" self.assertRaises(exception.VolumeBackendAPIException, self.driver.create_volume_from_snapshot, self.data.test_volume, EMCVMAXCommonData.test_source_volume) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) @mock.patch.object( FakeDB, 'volume_get', return_value=EMCVMAXCommonData.test_source_volume) @mock.patch.object( EMCVMAXCommon, '_find_storage_sync_sv_sv', return_value=(None, None)) def test_create_clone_no_fast_success(self, mock_volume_type, mock_volume, mock_sync_sv): self.data.test_volume['volume_name'] = ""vmax-1234567"" self.driver.create_cloned_volume(self.data.test_volume, EMCVMAXCommonData.test_source_volume) def test_create_clone_no_fast_failed(self): self.data.test_volume['volume_name'] = ""vmax-1234567"" self.assertRaises(exception.VolumeBackendAPIException, self.driver.create_cloned_volume, self.data.test_volume, EMCVMAXCommonData.test_source_volume) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) return_value={'volume_backend_name': 'FCFAST', 'FASTPOLICY': 'FC_GOLD1'}) @mock.patch.object( EMCVMAXUtils, 'find_storage_masking_group', return_value=EMCVMAXCommonData.storagegroupname) EMCVMAXCommon, '_find_storage_sync_sv_sv', return_value=(None, None)) @mock.patch.object( EMCVMAXUtils, 'find_storage_configuration_service', 'find_controller_configuration_service', return_value=1) '_get_or_create_default_storage_group', return_value=1) def test_create_snapshot_fast_success(self, mock_volume_type, mock_storage_group, mock_volume, mock_sync_sv, mock_storage_config_service, mock_controller_config_service, mock_default_sg): return_value={'volume_backend_name': 'FCFAST', 'FASTPOLICY': 'FC_GOLD1'}) @mock.patch.object( EMCVMAXUtils, 'find_storage_masking_group', return_value=EMCVMAXCommonData.storagegroupname) 'find_storage_configuration_service', return_value=1) @mock.patch.object( EMCVMAXUtils, 'find_controller_configuration_service', return_value=1) @mock.patch.object( EMCVMAXCommon, '_get_or_create_default_storage_group', return_value=1) def test_create_volume_from_snapshot_fast_success( self, mock_volume_type, mock_storage_group, mock_volume, mock_sync_sv, mock_storage_config_service, mock_controller_config_service, mock_default_sg): self.data.test_volume['volume_name'] = ""vmax-1234567"" self.driver.create_volume_from_snapshot( self.data.test_volume, EMCVMAXCommonData.test_source_volume) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'storagetype: pool': 'gold', 'volume_backend_name': 'FCFAST'}) @mock.patch.object( EMCVMAXUtils, 'find_replication_service', @mock.patch.object( EMCVMAXCommon, '_find_storage_sync_sv_sv', return_value=(None, None)) def test_create_volume_from_snapshot_fast_failed(self, mock_volume_type, mock_rep_service, mock_sync_sv): self.assertRaises(exception.VolumeBackendAPIException, self.driver.create_volume_from_snapshot, self.data.test_volume, EMCVMAXCommonData.test_source_volume) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST', 'FASTPOLICY': 'FC_GOLD1'}) @mock.patch.object( EMCVMAXUtils, 'find_storage_masking_group', return_value=EMCVMAXCommonData.storagegroupname) @mock.patch.object( FakeDB, 'volume_get', return_value=EMCVMAXCommonData.test_source_volume) @mock.patch.object( EMCVMAXCommon, '_find_storage_sync_sv_sv', return_value=(None, None)) @mock.patch.object( EMCVMAXUtils, 'find_storage_configuration_service', return_value=1) @mock.patch.object( EMCVMAXUtils, 'find_controller_configuration_service', return_value=1) @mock.patch.object( EMCVMAXCommon, '_get_or_create_default_storage_group', return_value=1) def test_create_clone_fast_success(self, mock_volume_type, mock_storage_group, mock_volume, mock_sync_sv, mock_storage_config_service, mock_controller_config_service, mock_default_sg): self.data.test_volume['volume_name'] = ""vmax-1234567"" EMCVMAXCommonData.test_source_volume) 'find_replication_service', return_value=None) '_find_storage_sync_sv_sv', return_value=(None, None)) def test_create_clone_fast_failed(self, mock_volume_type, mock_rep_service, mock_sync_sv):",638,514
openstack%2Fcinder~master~Ia3b79ffa1d9f812848d9b00837b0f92fb16619f5,openstack/cinder,master,Ia3b79ffa1d9f812848d9b00837b0f92fb16619f5,"Logging updates to properly use ',' instead of '%'",MERGED,2014-12-02 21:42:07.000000000,2014-12-20 04:51:07.000000000,2014-12-18 17:10:45.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7860}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 12780}, {'_account_id': 13636}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-12-02 21:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/71d257abbdc905615afd401432323c91439ec3fb', 'message': ""Logging updates to properly use ',' instead of '%'\n\nThe i18n logging standards recommend using ',' for\nthe addition of variables to log strings.  This patch\nimplements that change for the ibmnas driver.\n\nChange-Id: Ia3b79ffa1d9f812848d9b00837b0f92fb16619f5\n""}, {'number': 2, 'created': '2014-12-17 21:04:11.000000000', 'files': ['cinder/volume/drivers/ibm/ibmnas.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/49aaa1c8ad4bf88adf5a6ca0d95616c634ae286f', 'message': ""Logging updates to properly use ',' instead of '%'\n\nThe i18n logging standards recommend using ',' for\nthe addition of variables to log strings.  This patch\nimplements that change for the ibmnas driver.\n\nChange-Id: Ia3b79ffa1d9f812848d9b00837b0f92fb16619f5\n""}]",8,138554,49aaa1c8ad4bf88adf5a6ca0d95616c634ae286f,42,23,2,7198,,,0,"Logging updates to properly use ',' instead of '%'

The i18n logging standards recommend using ',' for
the addition of variables to log strings.  This patch
implements that change for the ibmnas driver.

Change-Id: Ia3b79ffa1d9f812848d9b00837b0f92fb16619f5
",git fetch https://review.opendev.org/openstack/cinder refs/changes/54/138554/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/ibm/ibmnas.py'],1,71d257abbdc905615afd401432323c91439ec3fb,fix_L_ibmnas," LOG.debug(""Enter _get_provider_location: volume_id %s"", volume_id) LOG.debug(""Enter _get_export_path: volume_id %s"", volume_id) LOG.debug(""Enter _create_ibmnas_snap: src %(src)s, dest %(dest)s"", {'src': src, 'dest': dest}) 'snap %(snap)s', {'src': src, 'dest': dest, 'snap': snap}) LOG.debug(""Resizing file to %sG."", new_size) LOG.debug(""Extending volume %s"", volume['name']) 'mount_point %(mount_point)s', {'fchild': fchild, 'mount_point': mount_point}) msg = (_(""Failed in _delete_snapfiles. Error: %s""), e.stderr)"," LOG.debug(""Enter _get_provider_location: volume_id %s"" % volume_id) LOG.debug(""Enter _get_export_path: volume_id %s"" % volume_id) LOG.debug(""Enter _create_ibmnas_snap: src %(src)s, dest %(dest)s"" % {'src': src, 'dest': dest}) 'snap %(snap)s' % {'src': src, 'dest': dest, 'snap': snap}) LOG.debug(""Resizing file to %sG."" % new_size) LOG.debug(""Extending volume %s"" % volume['name']) 'mount_point %(mount_point)s' % {'fchild': fchild, 'mount_point': mount_point}) msg = (_(""Failed in _delete_snapfiles. Error: %s"") % e.stderr)",13,13
openstack%2Fcinder~master~Ia446615e0c03b91fc1da75489855e77c29639efa,openstack/cinder,master,Ia446615e0c03b91fc1da75489855e77c29639efa,Add support for Purity Protection Groups to PureISCSIDriver,MERGED,2014-12-05 22:31:49.000000000,2014-12-20 04:39:29.000000000,2014-12-20 02:59:08.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 2861}, {'_account_id': 6491}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12780}, {'_account_id': 12924}, {'_account_id': 13461}, {'_account_id': 13868}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-05 22:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/30b8a3a4e643cb82427526eecfa8915e10637b0c', 'message': 'Add support for Purity Protection Groups to PureISCSIDriver\n\nWe will be needing access to the Protection Group features of Purity to\nenable features like Replication and Consistency Groups. To do this we\nneed to add new helpers for the FlashArray object for the required REST\nAPI methods.\n\nTo bring in this support we will need to bump up the required REST API\nversion to 1.2+ and remove support for 1.0 and 1.1\n\nImplements: blueprint pure-iscsi-add-pgroup-support\nChange-Id: Ia446615e0c03b91fc1da75489855e77c29639efa'}, {'number': 2, 'created': '2014-12-06 00:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7017e88d6a9852951b327493a4b6569298014bf6', 'message': 'Add support for Purity Protection Groups to PureISCSIDriver\n\nWe will be needing access to the Protection Group features of Purity to\nenable features like Replication and Consistency Groups. To do this we\nneed to add new helpers for the FlashArray object for the required REST\nAPI methods.\n\nTo bring in this support we will need to bump up the required REST API\nversion to 1.2+ and remove support for 1.0 and 1.1\n\nImplements: blueprint pure-iscsi-add-pgroup-support\nChange-Id: Ia446615e0c03b91fc1da75489855e77c29639efa'}, {'number': 3, 'created': '2014-12-06 01:03:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/21a99ff239e2677c1aee118a5e0eca2129d59297', 'message': 'Add support for Purity Protection Groups to PureISCSIDriver\n\nWe will be needing access to the Protection Group features of Purity to\nenable features like Replication and Consistency Groups. To do this we\nneed to add new helpers for the FlashArray object for the required REST\nAPI methods.\n\nTo bring in this support we will need to bump up the required REST API\nversion to 1.2+ and remove support for 1.0 and 1.1\n\nImplements: blueprint pure-iscsi-add-pgroup-support\nChange-Id: Ia446615e0c03b91fc1da75489855e77c29639efa'}, {'number': 4, 'created': '2014-12-15 23:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2412fe475ffc29945bed585a3eeb3740affb6c85', 'message': 'Add support for Purity Protection Groups to PureISCSIDriver\n\nWe will be needing access to the Protection Group features of Purity to\nenable features like Replication and Consistency Groups. To do this we\nneed to add new helpers for the FlashArray object for the required REST\nAPI methods.\n\nDocImpact: To bring in pgroup support we will need to bump up the \nrequired REST API version to 1.2+ and remove support for 1.0 and 1.1\n\nImplements: blueprint pure-iscsi-add-pgroup-support\nChange-Id: Ia446615e0c03b91fc1da75489855e77c29639efa'}, {'number': 5, 'created': '2014-12-15 23:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/eda678d41239607da02a8e88702d629e4e3ebea6', 'message': 'Add support for Purity Protection Groups to PureISCSIDriver\n\nWe will be needing access to the Protection Group features of Purity to\nenable features like Replication and Consistency Groups. To do this we\nneed to add new helpers for the FlashArray object for the required REST\nAPI methods.\n\nDocImpact: To bring in pgroup support we will need to bump up the\nrequired REST API version to 1.2+ and remove support for 1.0 and 1.1\n\nImplements: blueprint pure-iscsi-add-pgroup-support\nChange-Id: Ia446615e0c03b91fc1da75489855e77c29639efa'}, {'number': 6, 'created': '2014-12-17 19:20:10.000000000', 'files': ['cinder/volume/drivers/pure.py', 'cinder/tests/test_pure.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/55857055fed82d9b599d0485cd980ee312d00269', 'message': 'Add support for Purity Protection Groups to PureISCSIDriver\n\nWe will be needing access to the Protection Group features of Purity to\nenable features like Replication and Consistency Groups. To do this we\nneed to add new helpers for the FlashArray object for the required REST\nAPI methods.\n\nDocImpact: To bring in pgroup support we will need to bump up the\nrequired REST API version to 1.2+ and remove support for 1.0 and 1.1\n\nImplements: blueprint pure-iscsi-add-pgroup-support\nChange-Id: Ia446615e0c03b91fc1da75489855e77c29639efa'}]",17,139740,55857055fed82d9b599d0485cd980ee312d00269,56,20,6,12924,,,0,"Add support for Purity Protection Groups to PureISCSIDriver

We will be needing access to the Protection Group features of Purity to
enable features like Replication and Consistency Groups. To do this we
need to add new helpers for the FlashArray object for the required REST
API methods.

DocImpact: To bring in pgroup support we will need to bump up the
required REST API version to 1.2+ and remove support for 1.0 and 1.1

Implements: blueprint pure-iscsi-add-pgroup-support
Change-Id: Ia446615e0c03b91fc1da75489855e77c29639efa",git fetch https://review.opendev.org/openstack/cinder refs/changes/40/139740/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/pure.py', 'cinder/tests/test_pure.py']",2,30b8a3a4e643cb82427526eecfa8915e10637b0c,bp/pure-iscsi-add-pgroup-support," self.assertEqual(result, ""1.3"") self.response.read.return_value = '{""version"": [""0.1"", ""1.1""]}' def test_create_pgroup(self, mock_req): mock_req.return_value = self.result pgroup_name = ""cgroup_id"" result = self.array.create_pgroup(pgroup_name) self.assertEqual(result, self.result) req_url = ""pgroup/"" + pgroup_name mock_req.assert_called_with(self.array, ""POST"", req_url) self.assert_error_propagates([mock_req], self.array.create_pgroup, pgroup_name) def test_delete_pgroup(self, mock_req): mock_req.return_value = self.result pgroup_name = ""cgroup_id"" result = self.array.delete_pgroup(pgroup_name) self.assertEqual(result, self.result) req_url = ""pgroup/"" + pgroup_name mock_req.assert_called_with(self.array, ""DELETE"", req_url) self.assert_error_propagates([mock_req], self.array.delete_pgroup, pgroup_name) def test_create_pgroup_snapshot(self, mock_req): mock_req.return_value = self.result pgroup_name = ""cgroup_id"" snap_suffix = ""snap_suffix"" result = self.array.create_pgroup_snapshot(pgroup_name, snap_suffix) self.assertEqual(result, self.result) expected_params = { ""snap"": True, ""suffix"": snap_suffix, ""source"": [pgroup_name] } mock_req.assert_called_with(self.array, ""POST"", ""pgroup"", expected_params) self.assert_error_propagates([mock_req], self.array.create_pgroup_snapshot, pgroup_name, snap_suffix) def test_delete_pgroup_snapshot(self, mock_req): mock_req.return_value = self.result snapshot_name = ""snap1"" result = self.array.delete_pgroup_snapshot(snapshot_name) self.assertEqual(result, self.result) req_url = ""pgroup/"" + snapshot_name mock_req.assert_called_with(self.array, ""DELETE"", req_url) self.assert_error_propagates([mock_req], self.array.delete_pgroup_snapshot, snapshot_name) def test_add_volume_to_pgroup(self, mock_req): mock_req.return_value = self.result pgroup_name = ""cgroup_id"" volume_name = ""myvol-1"" expected_params = {""addvollist"": [volume_name]} result = self.array.add_volume_to_pgroup(pgroup_name, volume_name) self.assertEqual(result, self.result) req_url = ""pgroup/"" + pgroup_name mock_req.assert_called_with(self.array, ""PUT"", req_url, expected_params) self.assert_error_propagates([mock_req], self.array.add_volume_to_pgroup, pgroup_name, volume_name) "," self.assertEqual(result, ""1.1"") self.response.read.return_value = '{""version"": [""0.1"", ""1.3""]}'",99,8
openstack%2Fneutron~master~I0717f955b0f787c2951cb9db44ea5decc5d3dff0,openstack/neutron,master,I0717f955b0f787c2951cb9db44ea5decc5d3dff0,Remove NSX 'service' plugin,MERGED,2014-12-17 17:35:36.000000000,2014-12-20 04:36:24.000000000,2014-12-20 02:43:19.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7249}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-17 17:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d87b8dad9d980d242bdf7aca3f547d725679cc1f', 'message': ""Remove NSX 'service' plugin\n\nFollowing the spin-off for Neutron advanced services, this plugin\nhas become non-functional.\nThis patch removes the plugin, the service drivers, the database\nmodels which kept tracking of resource associations, exceptions,\nand obviously unit tests.\n\nAs there were some extensions which were leverage only by this\nplugin, they are being removed as well. In particular, one of\nthese extensions, 'routed-service-insertion' was in the\nneutron.extensions package rather than neutron.plugins.vmware\npackage. This was for historical reasons. As no other plugin is\nusing this extension, it is being removed as well with this\npatch.\n\nBy removing this plugin vmware the temporary skip applied to\nneutron unit tests can be lifted. This patch does that.\n\nCloses-Bug: #1403585\n\nChange-Id: I0717f955b0f787c2951cb9db44ea5decc5d3dff0\n""}, {'number': 2, 'created': '2014-12-17 22:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc2097de8e72f4cc09e88e2d57ef3ce909dfd681', 'message': ""Remove NSX 'service' plugin\n\nFollowing the spin-off for Neutron advanced services, this plugin\nhas become non-functional.\nThis patch removes the plugin, the service drivers, the database\nmodels which kept tracking of resource associations, exceptions,\nand obviously unit tests.\n\nAs there were some extensions which were leveraged only by this\nplugin, they are being removed as well. In particular, one of\nthese extensions, 'routed-service-insertion' was in the\nneutron.extensions package rather than neutron.plugins.vmware\npackage. This was for historical reasons. As no other plugin is\nusing this extension, it is being removed as well with this\npatch.\n\nBy removing this plugin vmware the temporary skips applied to\nneutron unit tests can be lifted. This patch does this.\n\nCloses-Bug: #1403585\n\nChange-Id: I0717f955b0f787c2951cb9db44ea5decc5d3dff0\n""}, {'number': 3, 'created': '2014-12-18 15:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e7f2ec253e4f6bcc22503998ead8bbc9a2eca14', 'message': ""Remove NSX 'service' plugin\n\nFollowing the spin-off for Neutron advanced services, this plugin\nhas become non-functional.\nThis patch removes the plugin, the service drivers, the database\nmodels which kept tracking of resource associations, exceptions,\nand obviously unit tests.\n\nAs there were some extensions which were leveraged only by this\nplugin, they are being removed as well. In particular, one of\nthese extensions, 'routed-service-insertion' was in the\nneutron.extensions package rather than neutron.plugins.vmware\npackage. This was for historical reasons. As no other plugin is\nusing this extension, it is being removed as well with this\npatch.\n\nBy removing this plugin vmware the temporary skips applied to\nneutron unit tests can be lifted. This patch does this.\n\nCloses-Bug: #1403585\n\nChange-Id: I0717f955b0f787c2951cb9db44ea5decc5d3dff0\n""}, {'number': 4, 'created': '2014-12-18 19:10:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2168d93f85979ef3c7fe343d1200fb1e3ecfc7cf', 'message': ""Remove NSX 'service' plugin\n\nFollowing the spin-off for Neutron advanced services, this plugin\nhas become non-functional.\nThis patch removes the plugin, the service drivers, the database\nmodels which kept tracking of resource associations, exceptions,\nand obviously unit tests.\n\nAs there were some extensions which were leveraged only by this\nplugin, they are being removed as well. In particular, one of\nthese extensions, 'routed-service-insertion' was in the\nneutron.extensions package rather than neutron.plugins.vmware\npackage. This was for historical reasons. As no other plugin is\nusing this extension, it is being removed as well with this\npatch.\n\nBy removing this plugin vmware the temporary skips applied to\nneutron unit tests can be lifted. This patch does this.\n\nCloses-Bug: #1403585\n\nChange-Id: I0717f955b0f787c2951cb9db44ea5decc5d3dff0\n""}, {'number': 5, 'created': '2014-12-18 22:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8852f3c464cf328b242950cca97b84d56e5d40c3', 'message': ""Remove NSX 'service' plugin\n\nFollowing the spin-off for Neutron advanced services, this plugin\nhas become non-functional.\nThis patch removes the plugin, the service drivers, the database\nmodels which kept tracking of resource associations, exceptions,\nand obviously unit tests.\n\nAs there were some extensions which were leveraged only by this\nplugin, they are being removed as well. In particular, one of\nthese extensions, 'routed-service-insertion' was in the\nneutron.extensions package rather than neutron.plugins.vmware\npackage. This was for historical reasons. As no other plugin is\nusing this extension, it is being removed as well with this\npatch.\n\nBy removing this plugin vmware the temporary skips applied to\nneutron unit tests can be lifted. This patch does this.\n\nCloses-Bug: #1403585\n\nChange-Id: I0717f955b0f787c2951cb9db44ea5decc5d3dff0\n""}, {'number': 6, 'created': '2014-12-19 09:19:15.000000000', 'files': ['neutron/plugins/vmware/dbexts/vcns_models.py', 'neutron/plugins/vmware/extensions/servicerouter.py', 'neutron/plugins/vmware/vshield/edge_loadbalancer_driver.py', 'neutron/plugins/vmware/vshield/edge_ipsecvpn_driver.py', 'neutron/tests/unit/vmware/skip_this_dir__init__.py', 'neutron/tests/unit/vmware/vshield/test_firewall_driver.py', 'neutron/db/routedserviceinsertion_db.py', 'neutron/tests/unit/vmware/vshield/test_loadbalancer_driver.py', 'neutron/tests/functional/db/test_migrations.py', 'neutron/plugins/vmware/vshield/edge_firewall_driver.py', 'neutron/db/migration/alembic_migrations/versions/57086602ca0a_scrap_nsx_adv_svcs_models.py', 'neutron/plugins/vmware/plugins/service.py', 'neutron/plugins/vmware/dbexts/servicerouter.py', 'neutron/tests/unit/vmware/vshield/test_fwaas_plugin.py', 'neutron/plugins/vmware/dbexts/vcns_db.py', 'neutron/tests/unit/vmware/vshield/test_lbaas_plugin.py', 'neutron/db/migration/models/head.py', 'neutron/tests/unit/vmware/vshield/test_vpnaas_plugin.py', 'neutron/db/routerservicetype_db.py', 'neutron/tests/unit/vmware/vshield/test_edge_router.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/plugins/vmware/vshield/vcns_driver.py', 'neutron/plugins/vmware/plugin.py', 'neutron/plugins/vmware/common/exceptions.py', 'neutron/extensions/routedserviceinsertion.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5981b9c11651589a0ed0ae4844f9284da84bab27', 'message': ""Remove NSX 'service' plugin\n\nFollowing the spin-off for Neutron advanced services, this plugin\nhas become non-functional.\nThis patch removes the plugin, the service drivers, the database\nmodels which kept tracking of resource associations, exceptions,\nand obviously unit tests.\n\nAs there were some extensions which were leveraged only by this\nplugin, they are being removed as well. In particular, one of\nthese extensions, 'routed-service-insertion' was in the\nneutron.extensions package rather than neutron.plugins.vmware\npackage. This was for historical reasons. As no other plugin is\nusing this extension, it is being removed as well with this\npatch.\n\nBy removing this plugin vmware the temporary skips applied to\nneutron unit tests can be lifted. This patch does this.\n\nCloses-Bug: #1403585\n\nChange-Id: I0717f955b0f787c2951cb9db44ea5decc5d3dff0\n""}]",10,142515,5981b9c11651589a0ed0ae4844f9284da84bab27,124,22,6,261,,,0,"Remove NSX 'service' plugin

Following the spin-off for Neutron advanced services, this plugin
has become non-functional.
This patch removes the plugin, the service drivers, the database
models which kept tracking of resource associations, exceptions,
and obviously unit tests.

As there were some extensions which were leveraged only by this
plugin, they are being removed as well. In particular, one of
these extensions, 'routed-service-insertion' was in the
neutron.extensions package rather than neutron.plugins.vmware
package. This was for historical reasons. As no other plugin is
using this extension, it is being removed as well with this
patch.

By removing this plugin vmware the temporary skips applied to
neutron unit tests can be lifted. This patch does this.

Closes-Bug: #1403585

Change-Id: I0717f955b0f787c2951cb9db44ea5decc5d3dff0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/15/142515/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/vmware/dbexts/vcns_db.py', 'neutron/plugins/vmware/dbexts/vcns_models.py', 'neutron/plugins/vmware/extensions/servicerouter.py', 'neutron/tests/unit/vmware/vshield/test_lbaas_plugin.py', 'neutron/db/migration/models/head.py', 'neutron/tests/unit/vmware/vshield/test_vpnaas_plugin.py', 'neutron/plugins/vmware/vshield/edge_loadbalancer_driver.py', 'neutron/tests/unit/vmware/vshield/test_edge_router.py', 'neutron/plugins/vmware/vshield/vcns_driver.py', 'neutron/plugins/vmware/vshield/edge_ipsecvpn_driver.py', 'neutron/tests/unit/vmware/skip_this_dir__init__.py', 'neutron/tests/unit/vmware/vshield/test_firewall_driver.py', 'neutron/plugins/vmware/plugin.py', 'neutron/db/routedserviceinsertion_db.py', 'neutron/tests/unit/vmware/vshield/test_loadbalancer_driver.py', 'neutron/plugins/vmware/common/exceptions.py', 'neutron/extensions/routedserviceinsertion.py', 'neutron/plugins/vmware/vshield/edge_firewall_driver.py', 'neutron/plugins/vmware/plugins/service.py', 'neutron/plugins/vmware/dbexts/servicerouter.py', 'neutron/tests/unit/vmware/vshield/test_fwaas_plugin.py']",21,d87b8dad9d980d242bdf7aca3f547d725679cc1f,bug/1403585,,"# Copyright 2013 VMware, Inc # All Rights Reserved # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # import contextlib import copy import webob.exc from neutron.api.v2 import attributes from neutron import context from neutron.extensions import firewall from neutron import manager from neutron.openstack.common import uuidutils from neutron.plugins.common import constants as const from neutron.tests.unit.db.firewall import test_db_firewall from neutron.tests.unit.vmware.vshield import test_edge_router _uuid = uuidutils.generate_uuid FW_PLUGIN_CLASS = ""neutron.plugins.vmware.plugin.NsxServicePlugin"" class FirewallTestExtensionManager( test_edge_router.ServiceRouterTestExtensionManager): def get_resources(self): # If l3 resources have been loaded and updated by main API # router, update the map in the l3 extension so it will load # the same attributes as the API router resources = super(FirewallTestExtensionManager, self).get_resources() firewall_attr_map = copy.deepcopy(firewall.RESOURCE_ATTRIBUTE_MAP) for res in firewall.RESOURCE_ATTRIBUTE_MAP.keys(): attr_info = attributes.RESOURCE_ATTRIBUTE_MAP.get(res) if attr_info: firewall.RESOURCE_ATTRIBUTE_MAP[res] = attr_info fw_resources = firewall.Firewall.get_resources() # restore the original resources once the controllers are created firewall.RESOURCE_ATTRIBUTE_MAP = firewall_attr_map resources.extend(fw_resources) return resources def get_actions(self): return [] def get_request_extensions(self): return [] class FirewallPluginTestCase(test_db_firewall.FirewallPluginDbTestCase, test_edge_router.ServiceRouterTest): def vcns_firewall_patch(self): self.vcns_instance.return_value.update_firewall.side_effect = ( self.fc2.update_firewall) self.vcns_instance.return_value.delete_firewall.side_effect = ( self.fc2.delete_firewall) self.vcns_instance.return_value.update_firewall_rule.side_effect = ( self.fc2.update_firewall_rule) self.vcns_instance.return_value.delete_firewall_rule.side_effect = ( self.fc2.delete_firewall_rule) self.vcns_instance.return_value.add_firewall_rule_above.side_effect = ( self.fc2.add_firewall_rule_above) self.vcns_instance.return_value.add_firewall_rule.side_effect = ( self.fc2.add_firewall_rule) self.vcns_instance.return_value.get_firewall.side_effect = ( self.fc2.get_firewall) self.vcns_instance.return_value.get_firewall_rule.side_effect = ( self.fc2.get_firewall_rule) def setUp(self): # Save the global RESOURCE_ATTRIBUTE_MAP self.saved_attr_map = {} for resource, attrs in attributes.RESOURCE_ATTRIBUTE_MAP.iteritems(): self.saved_attr_map[resource] = attrs.copy() super(FirewallPluginTestCase, self).setUp( ext_mgr=FirewallTestExtensionManager(), fw_plugin=FW_PLUGIN_CLASS) self.vcns_firewall_patch() self.plugin = manager.NeutronManager.get_plugin() def tearDown(self): super(FirewallPluginTestCase, self).tearDown() # Restore the global RESOURCE_ATTRIBUTE_MAP attributes.RESOURCE_ATTRIBUTE_MAP = self.saved_attr_map self.ext_api = None self.plugin = None def _create_and_get_router(self): req = self._create_router(self.fmt, self._tenant_id) res = self.deserialize(self.fmt, req) return res['router']['id'] def _create_firewall(self, fmt, name, description, firewall_policy_id, admin_state_up=True, expected_res_status=None, **kwargs): data = {'firewall': {'name': name, 'description': description, 'firewall_policy_id': firewall_policy_id, 'router_id': kwargs.get('router_id'), 'admin_state_up': admin_state_up, 'tenant_id': self._tenant_id}} firewall_req = self.new_create_request('firewalls', data, fmt) firewall_res = firewall_req.get_response(self.ext_api) if expected_res_status: self.assertEqual(firewall_res.status_int, expected_res_status) return firewall_res def test_create_firewall(self): name = ""new_fw"" attrs = self._get_test_firewall_attrs(name) with self.firewall_policy() as fwp: fwp_id = fwp['firewall_policy']['id'] attrs['firewall_policy_id'] = fwp_id attrs['router_id'] = self._create_and_get_router() with self.firewall( name=name, firewall_policy_id=fwp_id, router_id=attrs['router_id'], admin_state_up=test_db_firewall.ADMIN_STATE_UP, expected_res_status=201 ) as fw: attrs = self._replace_firewall_status( attrs, const.PENDING_CREATE, const.ACTIVE) for k, v in attrs.iteritems(): self.assertEqual(fw['firewall'][k], v) def test_create_firewall_without_policy(self): name = ""new_fw"" attrs = self._get_test_firewall_attrs(name) attrs['router_id'] = self._create_and_get_router() with self.firewall( name=name, router_id=attrs['router_id'], admin_state_up=test_db_firewall.ADMIN_STATE_UP, expected_res_status=201 ) as fw: attrs = self._replace_firewall_status( attrs, const.PENDING_CREATE, const.ACTIVE) for k, v in attrs.iteritems(): self.assertEqual(fw['firewall'][k], v) def test_update_firewall(self): name = ""new_fw"" attrs = self._get_test_firewall_attrs(name) attrs['router_id'] = self._create_and_get_router() with self.firewall_policy() as fwp: fwp_id = fwp['firewall_policy']['id'] attrs['firewall_policy_id'] = fwp_id with self.firewall( firewall_policy_id=fwp_id, router_id=attrs['router_id'], admin_state_up=test_db_firewall.ADMIN_STATE_UP) as fw: fw_id = fw['firewall']['id'] new_data = {'firewall': {'name': name}} req = self.new_update_request('firewalls', new_data, fw_id) res = req.get_response(self.ext_api) self.assertEqual(res.status_int, 200) res_json = self.deserialize( self.fmt, res) attrs = self._replace_firewall_status( attrs, const.PENDING_CREATE, const.ACTIVE) for k, v in attrs.iteritems(): self.assertEqual(res_json['firewall'][k], v) def test_delete_firewall(self): ctx = context.get_admin_context() with self.firewall_policy() as fwp: fwp_id = fwp['firewall_policy']['id'] with self.firewall( firewall_policy_id=fwp_id, router_id=self._create_and_get_router(), admin_state_up=test_db_firewall.ADMIN_STATE_UP, do_delete=False) as fw: fw_id = fw['firewall']['id'] with ctx.session.begin(subtransactions=True): req = self.new_delete_request('firewalls', fw_id) res = req.get_response(self.ext_api) self.assertEqual(res.status_int, 204) self.assertRaises( firewall.FirewallNotFound, self.plugin.get_firewall, ctx, fw_id) def test_delete_router_in_use_by_fwservice(self): router_id = self._create_and_get_router() with self.firewall_policy() as fwp: fwp_id = fwp['firewall_policy']['id'] with self.firewall( name='fw', firewall_policy_id=fwp_id, router_id=router_id, admin_state_up=test_db_firewall.ADMIN_STATE_UP, expected_res_status=201 ): self._delete('routers', router_id, expected_code=webob.exc.HTTPConflict.code) def test_show_firewall(self): name = ""firewall1"" attrs = self._get_test_firewall_attrs(name) attrs['router_id'] = self._create_and_get_router() with self.firewall_policy() as fwp: fwp_id = fwp['firewall_policy']['id'] attrs['firewall_policy_id'] = fwp_id with self.firewall( name=name, firewall_policy_id=fwp_id, router_id=attrs['router_id'], admin_state_up=test_db_firewall.ADMIN_STATE_UP) as firewall: req = self.new_show_request('firewalls', firewall['firewall']['id'], fmt=self.fmt) res = self.deserialize(self.fmt, req.get_response(self.ext_api)) attrs = self._replace_firewall_status( attrs, const.PENDING_CREATE, const.ACTIVE) for k, v in attrs.iteritems(): self.assertEqual(res['firewall'][k], v) def test_list_firewalls(self): keys_list = [] for i in range(3): keys_list.append({'name': ""fw"" + str(i), 'router_id': self._create_and_get_router(), 'admin_state_up': True, 'status': ""ACTIVE""}) with contextlib.nested( self.firewall( name='fw0', router_id=keys_list[0]['router_id'], admin_state_up=True, description='fw'), self.firewall( name='fw1', router_id=keys_list[1]['router_id'], admin_state_up=True, description='fw'), self.firewall( name='fw2', router_id=keys_list[2]['router_id'], admin_state_up=True, description='fw'), ) as (fw1, fw2, fw3): self._test_list_resources( 'firewall', (fw1, fw2, fw3), query_params='description=fw') req = self.new_list_request('firewalls') res = self.deserialize( self.fmt, req.get_response(self.ext_api)) self.assertEqual(len(res['firewalls']), 3) for index in range(len(res['firewalls'])): for k, v in keys_list[index].items(): self.assertEqual(res['firewalls'][index][k], v) def test_create_firewall_with_rules(self): ctx = context.get_admin_context() with contextlib.nested(self.firewall_rule(name='fwr1'), self.firewall_rule(name='fwr2'), self.firewall_rule(name='fwr3')) as fr: with self.firewall_policy() as fwp: fwp_id = fwp['firewall_policy']['id'] fw_rule_ids = [r['firewall_rule']['id'] for r in fr] data = {'firewall_policy': {'firewall_rules': fw_rule_ids}} req = self.new_update_request( 'firewall_policies', data, fwp_id) req.get_response(self.ext_api) attrs = self._get_test_firewall_attrs() attrs['firewall_policy_id'] = fwp_id with self.firewall( firewall_policy_id=fwp_id, router_id=self._create_and_get_router(), admin_state_up=test_db_firewall.ADMIN_STATE_UP) as fw: rule_list = ( self.plugin._make_firewall_rule_list_by_policy_id( ctx, fw['firewall']['firewall_policy_id'])) self._compare_firewall_rule_lists( fwp_id, fr, rule_list) def test_update_firewall_policy_with_no_firewall(self): name = ""new_firewall_policy1"" attrs = self._get_test_firewall_policy_attrs(name, audited=False) with self.firewall_policy(shared=test_db_firewall.SHARED, firewall_rules=None, audited=test_db_firewall.AUDITED) as fwp: data = {'firewall_policy': {'name': name}} req = self.new_update_request('firewall_policies', data, fwp['firewall_policy']['id']) res = self.deserialize(self.fmt, req.get_response(self.ext_api)) for k, v in attrs.iteritems(): self.assertEqual(res['firewall_policy'][k], v) def test_update_firewall_policy_with_firewall(self): name = ""new_firewall_policy1"" attrs = self._get_test_firewall_policy_attrs(name, audited=False) with self.firewall_policy(shared=test_db_firewall.SHARED, firewall_rules=None, audited=test_db_firewall.AUDITED) as fwp: fwp_id = fwp['firewall_policy']['id'] with self.firewall( firewall_policy_id=fwp_id, router_id=self._create_and_get_router(), admin_state_up=test_db_firewall.ADMIN_STATE_UP ): data = {'firewall_policy': {'name': name}} req = self.new_update_request( 'firewall_policies', data, fwp['firewall_policy']['id']) res = self.deserialize( self.fmt, req.get_response(self.ext_api)) for k, v in attrs.iteritems(): self.assertEqual(res['firewall_policy'][k], v) def test_update_firewall_rule_with_no_firewall(self): name = ""new_firewall_rule1"" attrs = self._get_test_firewall_rule_attrs(name) attrs['source_port'] = '10:20' attrs['destination_port'] = '30:40' with self.firewall_rule() as fwr: data = {'firewall_rule': {'name': name, 'source_port': '10:20', 'destination_port': '30:40'}} req = self.new_update_request( 'firewall_rules', data, fwr['firewall_rule']['id']) res = self.deserialize( self.fmt, req.get_response(self.ext_api)) for k, v in attrs.iteritems(): self.assertEqual(res['firewall_rule'][k], v) attrs['source_port'] = '10000' attrs['destination_port'] = '80' with self.firewall_rule() as fwr: data = {'firewall_rule': {'name': name, 'source_port': 10000, 'destination_port': 80}} req = self.new_update_request('firewall_rules', data, fwr['firewall_rule']['id']) res = self.deserialize(self.fmt, req.get_response(self.ext_api)) for k, v in attrs.iteritems(): self.assertEqual(res['firewall_rule'][k], v) attrs['source_port'] = None attrs['destination_port'] = None with self.firewall_rule() as fwr: data = {'firewall_rule': {'name': name, 'source_port': None, 'destination_port': None}} req = self.new_update_request( 'firewall_rules', data, fwr['firewall_rule']['id']) res = self.deserialize( self.fmt, req.get_response(self.ext_api)) for k, v in attrs.iteritems(): self.assertEqual(res['firewall_rule'][k], v) def test_update_firewall_rule_with_firewall(self): name = ""new_firewall_rule1"" attrs = self._get_test_firewall_rule_attrs(name) with self.firewall_rule() as fwr: with self.firewall_policy() as fwp: fwp_id = fwp['firewall_policy']['id'] attrs['firewall_policy_id'] = fwp_id with self.firewall( firewall_policy_id=fwp_id, router_id=self._create_and_get_router(), admin_state_up=test_db_firewall.ADMIN_STATE_UP ): fwr_id = fwr['firewall_rule']['id'] data = {'firewall_policy': {'firewall_rules': [fwr_id]}} req = self.new_update_request( 'firewall_policies', data, fwp['firewall_policy']['id']) req.get_response(self.ext_api) data = {'firewall_rule': {'name': name}} req = self.new_update_request( 'firewall_rules', data, fwr['firewall_rule']['id']) res = self.deserialize( self.fmt, req.get_response(self.ext_api)) attrs['firewall_policy_id'] = fwp_id for k, v in attrs.iteritems(): self.assertEqual(res['firewall_rule'][k], v) def test_insert_rule_with_no_firewall(self): attrs = self._get_test_firewall_policy_attrs() attrs['audited'] = False attrs['firewall_list'] = [] with contextlib.nested(self.firewall_rule(name='fwr0'), self.firewall_rule(name='fwr1'), self.firewall_rule(name='fwr2'), self.firewall_rule(name='fwr3'), self.firewall_rule(name='fwr4'), self.firewall_rule(name='fwr5'), self.firewall_rule(name='fwr6')) as fwr: with self.firewall_policy() as fwp: fwp_id = fwp['firewall_policy']['id'] attrs['id'] = fwp_id # test insert when rule list is empty fwr0_id = fwr[0]['firewall_rule']['id'] attrs['firewall_rules'].insert(0, fwr0_id) self._rule_action('insert', fwp_id, fwr0_id, insert_before=None, insert_after=None, expected_code=webob.exc.HTTPOk.code, expected_body=attrs) # test insert at top of rule list, insert_before and # insert_after not provided fwr1_id = fwr[1]['firewall_rule']['id'] attrs['firewall_rules'].insert(0, fwr1_id) insert_data = {'firewall_rule_id': fwr1_id} self._rule_action('insert', fwp_id, fwr0_id, expected_code=webob.exc.HTTPOk.code, expected_body=attrs, body_data=insert_data) # test insert at top of list above existing rule fwr2_id = fwr[2]['firewall_rule']['id'] attrs['firewall_rules'].insert(0, fwr2_id) self._rule_action('insert', fwp_id, fwr2_id, insert_before=fwr1_id, insert_after=None, expected_code=webob.exc.HTTPOk.code, expected_body=attrs) # test insert at bottom of list fwr3_id = fwr[3]['firewall_rule']['id'] attrs['firewall_rules'].append(fwr3_id) self._rule_action('insert', fwp_id, fwr3_id, insert_before=None, insert_after=fwr0_id, expected_code=webob.exc.HTTPOk.code, expected_body=attrs) # test insert in the middle of the list using # insert_before fwr4_id = fwr[4]['firewall_rule']['id'] attrs['firewall_rules'].insert(1, fwr4_id) self._rule_action('insert', fwp_id, fwr4_id, insert_before=fwr1_id, insert_after=None, expected_code=webob.exc.HTTPOk.code, expected_body=attrs) # test insert in the middle of the list using # insert_after fwr5_id = fwr[5]['firewall_rule']['id'] attrs['firewall_rules'].insert(1, fwr5_id) self._rule_action('insert', fwp_id, fwr5_id, insert_before=None, insert_after=fwr2_id, expected_code=webob.exc.HTTPOk.code, expected_body=attrs) # test insert when both insert_before and # insert_after are set fwr6_id = fwr[6]['firewall_rule']['id'] attrs['firewall_rules'].insert(1, fwr6_id) self._rule_action('insert', fwp_id, fwr6_id, insert_before=fwr5_id, insert_after=fwr5_id, expected_code=webob.exc.HTTPOk.code, expected_body=attrs) def test_insert_rule_with_firewall(self): attrs = self._get_test_firewall_policy_attrs() attrs['audited'] = False attrs['firewall_list'] = [] with contextlib.nested(self.firewall_rule(name='fwr0'), self.firewall_rule(name='fwr1'), self.firewall_rule(name='fwr2'), self.firewall_rule(name='fwr3'), self.firewall_rule(name='fwr4'), self.firewall_rule(name='fwr5'), self.firewall_rule(name='fwr6')) as fwr: with self.firewall_policy() as fwp: fwp_id = fwp['firewall_policy']['id'] attrs['id'] = fwp_id with self.firewall(router_id=self._create_and_get_router(), firewall_policy_id=fwp_id) as fw: # test insert when rule list is empty fwr0_id = fwr[0]['firewall_rule']['id'] attrs['firewall_rules'].insert(0, fwr0_id) attrs['firewall_list'].insert(0, fw['firewall']['id']) self._rule_action('insert', fwp_id, fwr0_id, insert_before=None, insert_after=None, expected_code=webob.exc.HTTPOk.code, expected_body=attrs) # test insert at top of rule list, insert_before and # insert_after not provided fwr1_id = fwr[1]['firewall_rule']['id'] attrs['firewall_rules'].insert(0, fwr1_id) insert_data = {'firewall_rule_id': fwr1_id} self._rule_action( 'insert', fwp_id, fwr0_id, expected_code=webob.exc.HTTPOk.code, expected_body=attrs, body_data=insert_data) # test insert at top of list above existing rule fwr2_id = fwr[2]['firewall_rule']['id'] attrs['firewall_rules'].insert(0, fwr2_id) self._rule_action('insert', fwp_id, fwr2_id, insert_before=fwr1_id, insert_after=None, expected_code=webob.exc.HTTPOk.code, expected_body=attrs) # test insert at bottom of list fwr3_id = fwr[3]['firewall_rule']['id'] attrs['firewall_rules'].append(fwr3_id) self._rule_action('insert', fwp_id, fwr3_id, insert_before=None, insert_after=fwr0_id, expected_code=webob.exc.HTTPOk.code, expected_body=attrs) # test insert in the middle of the list using # insert_before fwr4_id = fwr[4]['firewall_rule']['id'] attrs['firewall_rules'].insert(1, fwr4_id) self._rule_action('insert', fwp_id, fwr4_id, insert_before=fwr1_id, insert_after=None, expected_code=webob.exc.HTTPOk.code, expected_body=attrs) # test insert in the middle of the list using # insert_after fwr5_id = fwr[5]['firewall_rule']['id'] attrs['firewall_rules'].insert(1, fwr5_id) self._rule_action('insert', fwp_id, fwr5_id, insert_before=None, insert_after=fwr2_id, expected_code=webob.exc.HTTPOk.code, expected_body=attrs) # test insert when both insert_before and # insert_after are set fwr6_id = fwr[6]['firewall_rule']['id'] attrs['firewall_rules'].insert(1, fwr6_id) self._rule_action('insert', fwp_id, fwr6_id, insert_before=fwr5_id, insert_after=fwr5_id, expected_code=webob.exc.HTTPOk.code, expected_body=attrs) def test_remove_rule_with_no_firewall(self): attrs = self._get_test_firewall_policy_attrs() attrs['audited'] = False attrs['firewall_list'] = [] with self.firewall_policy() as fwp: fwp_id = fwp['firewall_policy']['id'] attrs['id'] = fwp_id with contextlib.nested(self.firewall_rule(name='fwr1'), self.firewall_rule(name='fwr2'), self.firewall_rule(name='fwr3')) as fr1: fw_rule_ids = [r['firewall_rule']['id'] for r in fr1] attrs['firewall_rules'] = fw_rule_ids[:] data = {'firewall_policy': {'firewall_rules': fw_rule_ids}} req = self.new_update_request('firewall_policies', data, fwp_id) req.get_response(self.ext_api) # test removing a rule from a policy that does not exist self._rule_action('remove', '123', fw_rule_ids[1], expected_code=webob.exc.HTTPNotFound.code, expected_body=None) # test removing a rule in the middle of the list attrs['firewall_rules'].remove(fw_rule_ids[1]) self._rule_action('remove', fwp_id, fw_rule_ids[1], expected_body=attrs) # test removing a rule at the top of the list attrs['firewall_rules'].remove(fw_rule_ids[0]) self._rule_action('remove', fwp_id, fw_rule_ids[0], expected_body=attrs) # test removing remaining rule in the list attrs['firewall_rules'].remove(fw_rule_ids[2]) self._rule_action('remove', fwp_id, fw_rule_ids[2], expected_body=attrs) # test removing rule that is not associated with the policy self._rule_action('remove', fwp_id, fw_rule_ids[2], expected_code=webob.exc.HTTPBadRequest.code, expected_body=None) def test_remove_rule_with_firewall(self): attrs = self._get_test_firewall_policy_attrs() attrs['audited'] = False attrs['firewall_list'] = [] with self.firewall_policy() as fwp: fwp_id = fwp['firewall_policy']['id'] attrs['id'] = fwp_id with self.firewall(router_id=self._create_and_get_router(), firewall_policy_id=fwp_id) as fw: attrs['firewall_list'].insert(0, fw['firewall']['id']) with contextlib.nested(self.firewall_rule(name='fwr1'), self.firewall_rule(name='fwr2'), self.firewall_rule(name='fwr3')) as fr1: fw_rule_ids = [r['firewall_rule']['id'] for r in fr1] attrs['firewall_rules'] = fw_rule_ids[:] data = {'firewall_policy': {'firewall_rules': fw_rule_ids}} req = self.new_update_request( 'firewall_policies', data, fwp_id) req.get_response(self.ext_api) # test removing a rule from a policy that does not exist self._rule_action( 'remove', '123', fw_rule_ids[1], expected_code=webob.exc.HTTPNotFound.code, expected_body=None) # test removing a rule in the middle of the list attrs['firewall_rules'].remove(fw_rule_ids[1]) self._rule_action('remove', fwp_id, fw_rule_ids[1], expected_body=attrs) # test removing a rule at the top of the list attrs['firewall_rules'].remove(fw_rule_ids[0]) self._rule_action('remove', fwp_id, fw_rule_ids[0], expected_body=attrs) # test removing remaining rule in the list attrs['firewall_rules'].remove(fw_rule_ids[2]) self._rule_action('remove', fwp_id, fw_rule_ids[2], expected_body=attrs) # test removing rule that is not #associated with the policy self._rule_action( 'remove', fwp_id, fw_rule_ids[2], expected_code=webob.exc.HTTPBadRequest.code, expected_body=None) def test_remove_rule_with_firewalls(self): attrs = self._get_test_firewall_policy_attrs() attrs['audited'] = False attrs['firewall_list'] = [] with self.firewall_policy() as fwp: fwp_id = fwp['firewall_policy']['id'] attrs['id'] = fwp_id with contextlib.nested( self.firewall(router_id=self._create_and_get_router(), firewall_policy_id=fwp_id), self.firewall(router_id=self._create_and_get_router(), firewall_policy_id=fwp_id)) as (fw1, fw2): attrs['firewall_list'].insert(0, fw1['firewall']['id']) attrs['firewall_list'].insert(1, fw2['firewall']['id']) with contextlib.nested(self.firewall_rule(name='fwr1'), self.firewall_rule(name='fwr2'), self.firewall_rule(name='fwr3')) as fr1: fw_rule_ids = [r['firewall_rule']['id'] for r in fr1] attrs['firewall_rules'] = fw_rule_ids[:] data = {'firewall_policy': {'firewall_rules': fw_rule_ids}} req = self.new_update_request( 'firewall_policies', data, fwp_id) req.get_response(self.ext_api) # test removing a rule from a policy that does not exist self._rule_action( 'remove', '123', fw_rule_ids[1], expected_code=webob.exc.HTTPNotFound.code, expected_body=None) # test removing a rule in the middle of the list attrs['firewall_rules'].remove(fw_rule_ids[1]) self._rule_action('remove', fwp_id, fw_rule_ids[1], expected_body=attrs) # test removing a rule at the top of the list attrs['firewall_rules'].remove(fw_rule_ids[0]) self._rule_action('remove', fwp_id, fw_rule_ids[0], expected_body=attrs) # test removing remaining rule in the list attrs['firewall_rules'].remove(fw_rule_ids[2]) self._rule_action('remove', fwp_id, fw_rule_ids[2], expected_body=attrs) # test removing rule that is not #associated with the policy self._rule_action( 'remove', fwp_id, fw_rule_ids[2], expected_code=webob.exc.HTTPBadRequest.code, expected_body=None) ",1,5973
openstack%2Fcinder~master~Ibe010b62bb2518685753dd515326e56ffcc99cea,openstack/cinder,master,Ibe010b62bb2518685753dd515326e56ffcc99cea,Remove iscsi_helper calls from base iscsi driver,MERGED,2014-12-14 19:09:44.000000000,2014-12-20 04:28:01.000000000,2014-12-18 09:47:49.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 7198}, {'_account_id': 8247}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11968}, {'_account_id': 12016}, {'_account_id': 12369}, {'_account_id': 13628}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-14 19:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f0a77e2303d86a30e60de11d0569b26eb7f6e783', 'message': ""Remove iscsi_helper calls from base iscsi driver\n\nThere are a number of drivers that inherit from the base\niscsi driver and don't have things liek iscsi_helper defined.\n\nWe've kept all iscsi_helper specific code in the tgt helpers\nthemeselves, or in the the various versions of the LVM driver\nwhich is where they belong.\n\nOver time however there have been some iscsi_helper specific\ncalls that have crept in to the base volume.driver:ISCSIDriver\nclass.  These were LIO specific calls and as a result when a\nconfiguration is set with multi-backend to use lioadm as the\ntarget helper, or even if it's not used but the default iscsi_helper\nis set to lioadm the initialize_connection and terminate_connection\ncalls will try and access the LIO specific calls and raise because\nthe drivers inheriting from this class don't have target_helper\nmembers.\n\nThis went unnoticed mostly becuase there's no signficant LIO testing\nin place and there were no distros setting LIO as the default iscsi_helper,\nit appears that this has changed however.\n\nThis patch moves the LIO specific calls back where they belong\nand keeps the base ISCSIDriver generic.  I've also added a test\ncase for this in the SolidFire driver because it's impacted by\nthis.\n\nChange-Id: Ibe010b62bb2518685753dd515326e56ffcc99cea\nCloses-Bug: #1400804\n""}, {'number': 2, 'created': '2014-12-14 21:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4aae69bf59dcf01ad69ede7b1d6ac20c5acf0290', 'message': ""Remove iscsi_helper calls from base iscsi driver\n\nThere are a number of drivers that inherit from the base\niscsi driver, using the base implementation of initialize_connection\nand terminate_connection.  These drivers also don't have iscsi_helper\ndefined.\n\nWe've kept all iscsi_helper specific code in the tgt helpers\nthemeselves, or in the the various versions of the LVM driver\nwhich is where they belong.\n\nOver time however there have been some iscsi_helper specific\ncalls that have crept in to the base volume.driver:ISCSIDriver\nclass.  These were LIO specific calls and as a result when a\nconfiguration is set with multi-backend to use lioadm as the\ntarget helper, or even if it's not used but the default iscsi_helper\nis set to lioadm the initialize_connection and terminate_connection\ncalls will try and access the LIO specific calls and raise because\nthe drivers inheriting from this class don't have target_helper\nmembers.\n\nThis went unnoticed mostly becuase there's no signficant LIO testing\nin place and there were no distros setting LIO as the default iscsi_helper,\nit appears that this has changed however.\n\nThis patch moves the LIO specific calls back where they belong\nand keeps the base ISCSIDriver generic.  I've also added a test\ncase for this in the SolidFire driver because it's impacted by\nthis.\n\nChange-Id: Ibe010b62bb2518685753dd515326e56ffcc99cea\nCloses-Bug: #1400804\n""}, {'number': 3, 'created': '2014-12-15 03:49:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9c0ad8689a83e478242bd179bc35e0ab8c56f9c9', 'message': ""Remove iscsi_helper calls from base iscsi driver\n\nThere are a number of drivers that inherit from the base\niscsi driver, using the base implementation of initialize_connection\nand terminate_connection.  These drivers also don't have iscsi_helper\ndefined.\n\nWe've kept all iscsi_helper specific code in the tgt helpers\nthemselves, or in the the various versions of the LVM driver\nwhich is where they belong.\n\nOver time however there have been some iscsi_helper specific\ncalls that have crept in to the base volume.driver:ISCSIDriver\nclass.  These were LIO specific calls and as a result when a\nconfiguration is set with multi-backend to use lioadm as the\ntarget helper, or even if it's not used but the default iscsi_helper\nis set to lioadm the initialize_connection and terminate_connection\ncalls will try and access the LIO specific calls and raise because\nthe drivers inheriting from this class don't have target_helper\nmembers.\n\nThis went unnoticed mostly because there's no signficant LIO testing\nin place and there were no distros setting LIO as the default iscsi_helper,\nit appears that this has changed however.\n\nThis patch moves the LIO specific calls back where they belong\nand keeps the base ISCSIDriver generic.  I've also added a test\ncase for this in the SolidFire driver because it's impacted by\nthis.\n\nChange-Id: Ibe010b62bb2518685753dd515326e56ffcc99cea\nCloses-Bug: #1400804\n""}, {'number': 4, 'created': '2014-12-15 04:09:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a7825a84dd53af0209157edb547ab3f9af233a37', 'message': ""Remove iscsi_helper calls from base iscsi driver\n\nThere are a number of drivers that inherit from the base\niscsi driver, using the base implementation of initialize_connection\nand terminate_connection.  These drivers also don't have iscsi_helper\ndefined.\n\nWe've kept all iscsi_helper specific code in the tgt helpers\nthemselves, or in the various versions of the LVM driver\nwhich is where they belong.\n\nOver time however there have been some iscsi_helper specific\ncalls that have crept in to the base volume.driver:ISCSIDriver\nclass.  These were LIO specific calls and as a result when a\nconfiguration is set with multi-backend to use lioadm as the\ntarget helper, or even if it's not used but the default iscsi_helper\nis set to lioadm the initialize_connection and terminate_connection\ncalls will try and access the LIO specific calls and raise because\nthe drivers inheriting from this class don't have target_helper\nmembers.\n\nThis went unnoticed mostly because there's no signficant LIO testing\nin place and there were no distros setting LIO as the default iscsi_helper,\nit appears that this has changed however.\n\nThis patch moves the LIO specific calls back where they belong\nand keeps the base ISCSIDriver generic.  I've also added a test\ncase for this in the SolidFire driver because it's impacted by\nthis.\n\nChange-Id: Ibe010b62bb2518685753dd515326e56ffcc99cea\nCloses-Bug: #1400804\n""}, {'number': 5, 'created': '2014-12-15 20:19:10.000000000', 'files': ['cinder/volume/driver.py', 'cinder/tests/test_solidfire.py', 'cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/7095e1c5a7477ca77c8698d96a969a7d78090a18', 'message': ""Remove iscsi_helper calls from base iscsi driver\n\nThere are a number of drivers that inherit from the base\niscsi driver, using the base implementation of initialize_connection\nand terminate_connection.  These drivers also don't have iscsi_helper\ndefined.\n\nWe've kept all iscsi_helper specific code in the tgt helpers\nthemselves, or in the various versions of the LVM driver\nwhich is where they belong.\n\nOver time however there have been some iscsi_helper specific\ncalls that have crept in to the base volume.driver:ISCSIDriver\nclass.  These were LIO specific calls and as a result when a\nconfiguration is set with multi-backend to use lioadm as the\ntarget helper, or even if it's not used but the default iscsi_helper\nis set to lioadm the initialize_connection and terminate_connection\ncalls will try and access the LIO specific calls and raise because\nthe drivers inheriting from this class don't have target_helper\nmembers.\n\nThis went unnoticed mostly because there's no significant LIO testing\nin place and there were no distros setting LIO as the default iscsi_helper,\nit appears that this has changed however.\n\nThis patch moves the LIO specific calls back where they belong\nand keeps the base ISCSIDriver generic.  I've also added a test\ncase for this in the SolidFire driver because it's impacted by\nthis.\n\nChange-Id: Ibe010b62bb2518685753dd515326e56ffcc99cea\nCloses-Bug: #1400804\n""}]",4,141660,7095e1c5a7477ca77c8698d96a969a7d78090a18,50,16,5,2243,,,0,"Remove iscsi_helper calls from base iscsi driver

There are a number of drivers that inherit from the base
iscsi driver, using the base implementation of initialize_connection
and terminate_connection.  These drivers also don't have iscsi_helper
defined.

We've kept all iscsi_helper specific code in the tgt helpers
themselves, or in the various versions of the LVM driver
which is where they belong.

Over time however there have been some iscsi_helper specific
calls that have crept in to the base volume.driver:ISCSIDriver
class.  These were LIO specific calls and as a result when a
configuration is set with multi-backend to use lioadm as the
target helper, or even if it's not used but the default iscsi_helper
is set to lioadm the initialize_connection and terminate_connection
calls will try and access the LIO specific calls and raise because
the drivers inheriting from this class don't have target_helper
members.

This went unnoticed mostly because there's no significant LIO testing
in place and there were no distros setting LIO as the default iscsi_helper,
it appears that this has changed however.

This patch moves the LIO specific calls back where they belong
and keeps the base ISCSIDriver generic.  I've also added a test
case for this in the SolidFire driver because it's impacted by
this.

Change-Id: Ibe010b62bb2518685753dd515326e56ffcc99cea
Closes-Bug: #1400804
",git fetch https://review.opendev.org/openstack/cinder refs/changes/60/141660/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/driver.py', 'cinder/tests/test_solidfire.py', 'cinder/volume/drivers/lvm.py']",3,f0a77e2303d86a30e60de11d0569b26eb7f6e783,bug/1400804," def initialize_connection(self, volume, connector): """"""Initializes the connection and returns connection info. """""" # We have a special case for lioadm here, that's fine, we can # keep the call in the parent class (driver:ISCSIDriver) generic # and still use it throughout, just override and call super here # no duplication, same effect but doesn't break things # see bug: #1400804 if self.configuration.iscsi_helper == 'lioadm': self.target_helper.initialize_connection(volume, connector) return super(LVMISCSIDriver, self).initialize_connection(volume, connector) def terminate_connection(self, volume, connector, **kwargs): if self.configuration.iscsi_helper == 'lioadm': self.target_helper.terminate_connection(volume, connector) ",,94,10
openstack%2Fcinder~master~I9e3cd24dc978e7c7672bf1eb09626428d2ba144d,openstack/cinder,master,I9e3cd24dc978e7c7672bf1eb09626428d2ba144d,Isolate Cinder Attach and Connect in Base Driver,MERGED,2014-12-15 23:03:22.000000000,2014-12-20 04:04:03.000000000,2014-12-19 00:44:56.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 6491}, {'_account_id': 6542}, {'_account_id': 8247}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 13900}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-15 23:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/273f847b269c3d543c1d697210f0218e5e316510', 'message': 'Isolate Cinder Attach and Connect in Base Driver\n\nThe base Cinder Driver combines the Attach process and the\nactual Connect process all under the Attach method.  This makes\nsense, but the method can be split between the parts that perform\nthings like DB updates and RPC calls and those that just take iqn\ninfo and actually make connections to the Cinder Volume Node.\n\nThis would allow Drivers to utilize the connector portion of the\ncode to add enhancements of their own.\n\nChange-Id: I9e3cd24dc978e7c7672bf1eb09626428d2ba144d\n'}, {'number': 2, 'created': '2014-12-17 16:02:00.000000000', 'files': ['cinder/volume/driver.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/eac97df4dd0c3937afaf38583ee53b6bbf4bfd7d', 'message': 'Isolate Cinder Attach and Connect in Base Driver\n\nThe base Cinder Driver combines the Attach process and the\nactual Connect process all under the Attach method.  This makes\nsense, but the method can be split between the parts that perform\nthings like DB updates and RPC calls and those that just take iqn\ninfo and actually make connections to the Cinder Volume Node.\n\nThis would allow Drivers to utilize the connector portion of the\ncode to add enhancements of their own.\n\nChange-Id: I9e3cd24dc978e7c7672bf1eb09626428d2ba144d\n'}]",3,141931,eac97df4dd0c3937afaf38583ee53b6bbf4bfd7d,49,18,2,2243,,,0,"Isolate Cinder Attach and Connect in Base Driver

The base Cinder Driver combines the Attach process and the
actual Connect process all under the Attach method.  This makes
sense, but the method can be split between the parts that perform
things like DB updates and RPC calls and those that just take iqn
info and actually make connections to the Cinder Volume Node.

This would allow Drivers to utilize the connector portion of the
code to add enhancements of their own.

Change-Id: I9e3cd24dc978e7c7672bf1eb09626428d2ba144d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/31/141931/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/driver.py'],1,273f847b269c3d543c1d697210f0218e5e316510,isolate_connect_and_attach_in_base_driver," return self._connect_device(conn) def _connect_device(self, conn):",,2,0
openstack%2Fmanila~master~I4985700997a81bf38b627bbc39193ef75a62667f,openstack/manila,master,I4985700997a81bf38b627bbc39193ef75a62667f,Add missing imports for sample config generation,MERGED,2014-12-19 11:32:03.000000000,2014-12-20 04:01:26.000000000,2014-12-20 04:01:25.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-12-19 11:32:03.000000000', 'files': ['manila/opts.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/b80436781955b8d3de2d59241feee0744e663844', 'message': 'Add missing imports for sample config generation\n\nFix for the following 2 exceptions when generating the sample\nconfiguration with ""tox -egenconfig"":\n\nmanila.share.drivers.ibm.gpfs.gpfs_share_opts,\nAttributeError: \'module\' object has no attribute \'ibm\'\n\nmanila.share.drivers.zfssa.zfssashare.ZFSSA_OPTS,\nAttributeError: \'module\' object has no attribute \'zfssa\'\n\nChange-Id: I4985700997a81bf38b627bbc39193ef75a62667f\n'}]",0,143047,b80436781955b8d3de2d59241feee0744e663844,9,4,1,7102,,,0,"Add missing imports for sample config generation

Fix for the following 2 exceptions when generating the sample
configuration with ""tox -egenconfig"":

manila.share.drivers.ibm.gpfs.gpfs_share_opts,
AttributeError: 'module' object has no attribute 'ibm'

manila.share.drivers.zfssa.zfssashare.ZFSSA_OPTS,
AttributeError: 'module' object has no attribute 'zfssa'

Change-Id: I4985700997a81bf38b627bbc39193ef75a62667f
",git fetch https://review.opendev.org/openstack/manila refs/changes/47/143047/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/opts.py'],1,b80436781955b8d3de2d59241feee0744e663844,,import manila.share.drivers.ibm.gpfsimport manila.share.drivers.zfssa.zfssashare,,2,0
openstack%2Fcinder~master~Ia1a809ba10e0595e6c255fde683f7c252377ac09,openstack/cinder,master,Ia1a809ba10e0595e6c255fde683f7c252377ac09,Uncouple scheduler stats from volume creation,MERGED,2014-12-17 06:18:18.000000000,2014-12-20 03:52:07.000000000,2014-12-18 09:46:20.000000000,"[{'_account_id': 3}, {'_account_id': 1773}, {'_account_id': 2759}, {'_account_id': 6043}, {'_account_id': 6825}, {'_account_id': 7198}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 13636}]","[{'number': 1, 'created': '2014-12-17 06:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/88bebe27c9a018390a1ffae552b41f95de751f73', 'message': 'Uncouple scheduler stats from volume creation\n\nCapture and report scheduler stats independently from volume creation.\nWithout this scheduler stats were not reported until the first volume\ncreation and were subsequently only updated each time a volume was\ncreated.\n\nChange-Id: Ia1a809ba10e0595e6c255fde683f7c252377ac09\nFixes-bug: 1402790\nFixes-bug: 1402806\n'}, {'number': 2, 'created': '2014-12-17 15:45:29.000000000', 'files': ['cinder/tests/scheduler/test_host_manager.py', 'cinder/scheduler/host_manager.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b0d99edf3a241cdb87a3b4ab7b588e2aff236be5', 'message': 'Uncouple scheduler stats from volume creation\n\nCapture and report scheduler stats independently from volume creation.\nWithout this scheduler stats were not reported until the first volume\ncreation and were subsequently only updated each time a volume was\ncreated.\n\nChange-Id: Ia1a809ba10e0595e6c255fde683f7c252377ac09\nFixes-bug: 1402790\nFixes-bug: 1402806\n'}]",1,142361,b0d99edf3a241cdb87a3b4ab7b588e2aff236be5,35,15,2,6825,,,0,"Uncouple scheduler stats from volume creation

Capture and report scheduler stats independently from volume creation.
Without this scheduler stats were not reported until the first volume
creation and were subsequently only updated each time a volume was
created.

Change-Id: Ia1a809ba10e0595e6c255fde683f7c252377ac09
Fixes-bug: 1402790
Fixes-bug: 1402806
",git fetch https://review.opendev.org/openstack/cinder refs/changes/61/142361/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/scheduler/test_host_manager.py', 'cinder/scheduler/host_manager.py']",2,88bebe27c9a018390a1ffae552b41f95de751f73,bug/1402806," def _update_host_state_map(self, context): def get_all_host_states(self, context): """"""Returns a dict of all the hosts the HostManager knows about. Each of the consumable resources in HostState are populated with capabilities scheduler received from RPC. For example: {'192.168.1.100': HostState(), ...} """""" self._update_host_state_map(context) for host, state in self.host_state_map.items(): self._update_host_state_map(context) "," def get_all_host_states(self, context): """"""Returns a dict of all the hosts the HostManager knows about. Each of the consumable resources in HostState are populated with capabilities scheduler received from RPC. For example: {'192.168.1.100': HostState(), ...} """""" for host in active_hosts: state = self.host_state_map[host]",65,14
openstack%2Fcinder~master~I9f62fe79e892cff01abdb02dbd95be8e432f8ab7,openstack/cinder,master,I9f62fe79e892cff01abdb02dbd95be8e432f8ab7,Fibrechannel and iSCSI for Violin Memory 6000 Series Arrays,MERGED,2014-12-06 11:39:33.000000000,2014-12-20 03:28:37.000000000,2014-12-18 04:19:58.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 7860}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 12780}]","[{'number': 1, 'created': '2014-12-06 11:39:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d7d4162e03b7ee09a3d66e66101f24ddeec751f7', 'message': 'Fibrechannel and iSCSI for Violin Memory 6000 Series Arrays\n\nThis patch adds both Fibrechannel and iSCSI driver support for Violin\nMemory 6000 Series All-Flash Arrays.\n\nChange-Id: I9f62fe79e892cff01abdb02dbd95be8e432f8ab7\nImplements: blueprint violinmemory-v6000-storage-drivers\n'}, {'number': 2, 'created': '2014-12-08 11:31:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4ee5a79067e29089ca46174b8a51d18c8aaf3ce6', 'message': 'Fibrechannel and iSCSI for Violin Memory 6000 Series Arrays\n\nThis patch adds both Fibrechannel and iSCSI driver support for Violin\nMemory 6000 Series All-Flash Arrays.\n\nChange-Id: I9f62fe79e892cff01abdb02dbd95be8e432f8ab7\nImplements: blueprint violinmemory-v6000-storage-drivers\n'}, {'number': 3, 'created': '2014-12-08 20:47:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/84d6850634f98465988d7d798ccc27cd9d3bba0d', 'message': 'Fibrechannel and iSCSI for Violin Memory 6000 Series Arrays\n\nThis patch adds both Fibrechannel and iSCSI driver support for Violin\nMemory 6000 Series All-Flash Arrays.\n\nChange-Id: I9f62fe79e892cff01abdb02dbd95be8e432f8ab7\nImplements: blueprint violinmemory-v6000-storage-drivers\n'}, {'number': 4, 'created': '2014-12-08 22:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/76a2eaf306c8d86edd1e62200cae5521fec6c82d', 'message': 'Fibrechannel and iSCSI for Violin Memory 6000 Series Arrays\n\nThis patch adds both Fibrechannel and iSCSI driver support for Violin\nMemory 6000 Series All-Flash Arrays.\n\nChange-Id: I9f62fe79e892cff01abdb02dbd95be8e432f8ab7\nImplements: blueprint violinmemory-v6000-storage-drivers\n'}, {'number': 5, 'created': '2014-12-11 10:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f86d0072c25f878b8280c2aa564664ab1b12554b', 'message': 'Fibrechannel and iSCSI for Violin Memory 6000 Series Arrays\n\nThis patch adds both Fibrechannel and iSCSI driver support for Violin\nMemory 6000 Series All-Flash Arrays.\n\nChange-Id: I9f62fe79e892cff01abdb02dbd95be8e432f8ab7\nImplements: blueprint violinmemory-v6000-storage-drivers\n'}, {'number': 6, 'created': '2014-12-16 11:17:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5e37ba30d7ad7c37fea6d9cc4e196fb50191024c', 'message': 'Fibrechannel and iSCSI for Violin Memory 6000 Series Arrays\n\nThis patch adds both Fibrechannel and iSCSI driver support for Violin\nMemory 6000 Series All-Flash Arrays.\n\nCertification results posted at:\nhttps://bugs.launchpad.net/cinder/+bug/1399911\n\nChange-Id: I9f62fe79e892cff01abdb02dbd95be8e432f8ab7\nImplements: blueprint violinmemory-v6000-storage-drivers\n'}, {'number': 7, 'created': '2014-12-17 12:56:03.000000000', 'files': ['cinder/tests/fake_vmem_xgtools_client.py', 'cinder/volume/drivers/violin/__init__.py', 'cinder/volume/drivers/violin/v6000_fcp.py', 'cinder/volume/drivers/violin/v6000_iscsi.py', 'cinder/exception.py', 'cinder/tests/test_v6000_fcp.py', 'cinder/tests/test_v6000_iscsi.py', 'cinder/tests/test_v6000_common.py', 'cinder/volume/drivers/violin/v6000_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4a679cc7f1cd8ed93eef30b35e7dd1ebe043ae8d', 'message': 'Fibrechannel and iSCSI for Violin Memory 6000 Series Arrays\n\nThis patch adds both Fibrechannel and iSCSI driver support for Violin\nMemory 6000 Series All-Flash Arrays.\n\nCertification results posted at:\nhttps://bugs.launchpad.net/cinder/+bug/1399911\n\nChange-Id: I9f62fe79e892cff01abdb02dbd95be8e432f8ab7\nImplements: blueprint violinmemory-v6000-storage-drivers\n'}]",158,139793,4a679cc7f1cd8ed93eef30b35e7dd1ebe043ae8d,88,23,7,7860,,,0,"Fibrechannel and iSCSI for Violin Memory 6000 Series Arrays

This patch adds both Fibrechannel and iSCSI driver support for Violin
Memory 6000 Series All-Flash Arrays.

Certification results posted at:
https://bugs.launchpad.net/cinder/+bug/1399911

Change-Id: I9f62fe79e892cff01abdb02dbd95be8e432f8ab7
Implements: blueprint violinmemory-v6000-storage-drivers
",git fetch https://review.opendev.org/openstack/cinder refs/changes/93/139793/5 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/fake_vmem_xgtools_client.py', 'cinder/volume/drivers/violin/version.py', 'etc/cinder/cinder.conf.sample', 'cinder/volume/drivers/violin/__init__.py', 'cinder/volume/drivers/violin/v6000_fcp.py', 'cinder/volume/drivers/violin/v6000_iscsi.py', 'cinder/tests/test_v6000_fcp.py', 'cinder/tests/test_v6000_iscsi.py', 'cinder/tests/test_v6000_common.py', 'cinder/volume/drivers/violin/v6000_common.py']",10,d7d4162e03b7ee09a3d66e66101f24ddeec751f7,bp/violinmemory-v6000-storage-drivers,"# Copyright 2014 Violin Memory, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Violin Memory 6000 Series All-Flash Array Common Driver for Openstack Cinder Provides common (ie., non-protocol specific) management functions for V6000 series flash arrays. Backend array communication is handled via VMEM's python library called 'xg-tools'. """""" import re import time from oslo.config import cfg from oslo.utils import importutils from cinder import context from cinder import exception from cinder.i18n import _ from cinder.openstack.common import log as logging from cinder import utils from cinder.volume.drivers.san import san from cinder.volume import volume_types LOG = logging.getLogger(__name__) vxg = importutils.try_import(""vxg"") if vxg: LOG.debug(""Running with xg-tools version: %s"", vxg.__version__) # version vmos versions V6.3.0.4 or newer # support vmos versions V6.3.1 or newer VMOS_SUPPORTED_VERSION_PATTERNS = ['V6.3.0.[4-9]', 'V6.3.[1-9].?[0-9]?'] violin_opts = [ cfg.StrOpt('gateway_mga', default='', help='IP address or hostname of mg-a'), cfg.StrOpt('gateway_mgb', default='', help='IP address or hostname of mg-b'), cfg.BoolOpt('use_igroups', default=False, help='Use igroups to manage targets and initiators'), ] CONF = cfg.CONF CONF.register_opts(violin_opts) class InvalidBackendConfig(exception.CinderException): message = _(""Volume backend config is invalid: %(reason)s"") class RequestRetryTimeout(exception.CinderException): message = _(""Backend service retry timeout hit: %(timeout)s sec"") class ViolinBackendErr(exception.CinderException): message = _(""Backend reports: %(message)s"") class ViolinBackendErrExists(exception.CinderException): message = _(""Backend reports: item already exists"") class ViolinBackendErrNotFound(exception.CinderException): message = _(""Backend reports: item not found"") class V6000CommonDriver(san.SanDriver): """"""Executes common commands relating to Violin Memory Arrays."""""" def __init__(self, *args, **kwargs): super(V6000CommonDriver, self).__init__(*args, **kwargs) self.request_timeout = 300 self.vmem_vip = None self.vmem_mga = None self.vmem_mgb = None self.container = """" self.stats = {} self.config = kwargs.get('configuration', None) self.context = None self.lun_tracker = LunIdList(self.db) if self.config: self.config.append_config_values(violin_opts) def do_setup(self, context): """"""Any initialization the driver does while starting."""""" if not self.config.san_ip: raise exception.InvalidInput( reason=_('Gateway VIP is not set')) if not self.config.gateway_mga: raise exception.InvalidInput( reason=_('Gateway IP for mg-a is not set')) if not self.config.gateway_mgb: raise exception.InvalidInput( reason=_('Gateway IP for mg-b is not set')) self.vmem_vip = vxg.open(self.config.san_ip, self.config.san_login, self.config.san_password, keepalive=True) self.vmem_mga = vxg.open(self.config.gateway_mga, self.config.san_login, self.config.san_password, keepalive=True) self.vmem_mgb = vxg.open(self.config.gateway_mgb, self.config.san_login, self.config.san_password, keepalive=True) self.context = context vip = self.vmem_vip.basic ret_dict = vip.get_node_values(""/vshare/state/local/container/*"") if ret_dict: self.container = ret_dict.items()[0][1] ret_dict = vip.get_node_values( ""/vshare/state/local/container/%s/lun/*"" % self.container) if ret_dict: self.lun_tracker.update_from_volume_ids(ret_dict.values()) ret_dict = vip.get_node_values( ""/vshare/state/snapshot/container/%s/lun/*"" % self.container) if ret_dict: for vol_id in ret_dict.values(): snaps = vip.get_node_values( ""/vshare/state/snapshot/container/%s/lun/%s/snap/*"" % (self.container, vol_id)) self.lun_tracker.update_from_snapshot_ids(snaps.values()) def check_for_setup_error(self): """"""Returns an error if prerequisites aren't met."""""" vip = self.vmem_vip.basic if len(self.container) == 0: raise InvalidBackendConfig(reason=_('container is missing')) if not self._is_supported_vmos_version(self.vmem_vip.version): msg = _('VMOS version is not supported') raise InvalidBackendConfig(reason=msg) bn1 = (""/vshare/state/local/container/%s/threshold/usedspace"" ""/threshold_hard_val"" % self.container) bn2 = (""/vshare/state/local/container/%s/threshold/provision"" ""/threshold_hard_val"" % self.container) ret_dict = vip.get_node_values([bn1, bn2]) for node in ret_dict: # The infrastructure does not support space reclamation so # ensure it is disabled. When used space exceeds the hard # limit, snapshot space reclamation begins. Default is 0 # => no space reclamation. # if node.endswith('/usedspace/threshold_hard_val'): if ret_dict[node] != 0: msg = _('space reclamation threshold is enabled') raise InvalidBackendConfig(reason=msg) # The infrastructure does not support overprovisioning so # ensure it is disabled. When provisioned space exceeds # the hard limit, further provisioning is stopped. # Default is 100 => provisioned space equals usable space. # elif node.endswith('/provision/threshold_hard_val'): if ret_dict[node] != 100: msg = _('provisioned space threshold not equal to ' 'usable space') raise InvalidBackendConfig(reason=msg) def create_volume(self, volume): """"""Creates a volume."""""" self._create_lun(volume) def delete_volume(self, volume): """"""Deletes a volume."""""" self._delete_lun(volume) def create_snapshot(self, snapshot): """"""Creates a snapshot from an existing volume."""""" self._create_lun_snapshot(snapshot) def delete_snapshot(self, snapshot): """"""Deletes a snapshot."""""" self._delete_lun_snapshot(snapshot) def create_volume_from_snapshot(self, volume, snapshot): """"""Creates a volume from a snapshot."""""" snapshot['size'] = snapshot['volume']['size'] self._create_lun(volume) self.copy_volume_data(self.context, snapshot, volume) def create_cloned_volume(self, volume, src_vref): """"""Creates a full clone of the specified volume."""""" self._create_lun(volume) self.copy_volume_data(self.context, src_vref, volume) def extend_volume(self, volume, new_size): """"""Extend an existing volume's size. The equivalent CLI command is ""lun resize container <container_name> name <lun_name> size <gb>"" Arguments: volume -- volume object provided by the Manager new_size -- new (increased) size in GB to be applied """""" v = self.vmem_vip LOG.debug(""Extending lun %(id)s, from %(size)s to %(new_size)s GB"" % {'id': volume['id'], 'size': volume['size'], 'new_size': new_size}) try: self._send_cmd(v.lun.resize_lun, 'Success', self.container, volume['id'], new_size) except Exception: LOG.exception(_(""LUN extend failed!"")) raise @utils.synchronized('vmem-lun') def _create_lun(self, volume): """"""Creates a new lun. The equivalent CLI command is ""lun create container <container_name> name <lun_name> size <gb>"" Arguments: volume -- volume object provided by the Manager """""" lun_type = '0' v = self.vmem_vip LOG.debug(""Creating LUN %(name)s, %(size)s GB"" % {'name': volume['name'], 'size': volume['size']}) if self.config.san_thin_provision: lun_type = '1' # using the defaults for fields: quantity, nozero, # readonly, startnum, blksize, naca, alua, preferredport # try: self._send_cmd(v.lun.create_lun, 'LUN create: success!', self.container, volume['id'], volume['size'], 1, '0', lun_type, 'w', 1, 512, False, False, None) except ViolinBackendErrExists: LOG.debug(""Lun %s already exists, continuing"", volume['id']) except Exception: LOG.warn(_(""Lun create failed!"")) raise @utils.synchronized('vmem-lun') def _delete_lun(self, volume): """"""Deletes a lun. The equivalent CLI command is ""no lun create container <container_name> name <lun_name>"" Arguments: volume -- volume object provided by the Manager """""" v = self.vmem_vip success_msgs = ['lun deletion started', ''] LOG.debug(""Deleting lun %s"", volume['id']) try: self._send_cmd(v.lun.bulk_delete_luns, success_msgs, self.container, volume['id']) except ViolinBackendErrNotFound: LOG.debug(""Lun %s already deleted, continuing"", volume['id']) except ViolinBackendErrExists: LOG.warn(_(""Lun %s has dependent snapshots, skipping""), volume['id']) raise exception.VolumeIsBusy(volume_name=volume['id']) except Exception: LOG.exception(_(""Lun delete failed!"")) raise self.lun_tracker.free_lun_id_for_volume(volume) @utils.synchronized('vmem-snap') def _create_lun_snapshot(self, snapshot): """"""Creates a new snapshot for a lun. The equivalent CLI command is ""snapshot create container <container> lun <volume_name> name <snapshot_name>"" Arguments: snapshot -- snapshot object provided by the Manager """""" v = self.vmem_vip LOG.debug(""Creating snapshot %s"", snapshot['id']) try: self._send_cmd(v.snapshot.create_lun_snapshot, 'Snapshot create: success!', self.container, snapshot['volume_id'], snapshot['id']) except ViolinBackendErrExists: LOG.debug(""Snapshot %s already exists, continuing"", snapshot['id']) except Exception: LOG.exception(_(""LUN snapshot create failed!"")) raise @utils.synchronized('vmem-snap') def _delete_lun_snapshot(self, snapshot): """"""Deletes an existing snapshot for a lun. The equivalent CLI command is ""no snapshot create container <container> lun <volume_name> name <snapshot_name>"" Arguments: snapshot -- snapshot object provided by the Manager """""" v = self.vmem_vip LOG.debug(""Deleting snapshot %s"", snapshot['id']) try: self._send_cmd(v.snapshot.delete_lun_snapshot, 'Snapshot delete: success!', self.container, snapshot['volume_id'], snapshot['id']) except ViolinBackendErrNotFound: LOG.debug(""Snapshot %s already deleted, continuing"", snapshot['id']) except Exception: LOG.exception(_(""LUN snapshot delete failed!"")) raise self.lun_tracker.free_lun_id_for_snapshot(snapshot) def _send_cmd(self, request_func, success_msgs, *args): """"""Run an XG request function, and retry until the request returns a success message, a failure message, or the global request timeout is hit. This wrapper is meant to deal with backend requests that can fail for any variety of reasons, for instance, when the system is already busy handling other LUN requests. It is also smart enough to give up if clustering is down (eg no HA available), there is no space left, or other ""fatal"" errors are returned (see _fatal_error_code() for a list of all known error conditions). Arguments: request_func -- XG api method to call success_msgs -- Success messages expected from the backend *args -- argument array to be passed to the request_func Returns: The response dict from the last XG call. """""" resp = {} start = time.time() done = False if isinstance(success_msgs, basestring): success_msgs = [success_msgs] while not done: if time.time() - start >= self.request_timeout: raise RequestRetryTimeout(timeout=self.request_timeout) resp = request_func(*args) if not resp['message']: # XG requests will return None for a message if no message # string is passed int the raw response resp['message'] = '' for msg in success_msgs: if not resp['code'] and msg in resp['message']: done = True break self._fatal_error_code(resp) return resp def _send_cmd_and_verify(self, request_func, verify_func, request_success_msgs, rargs=None, vargs=None): """"""Run an XG request function, and verify success using an additional verify function. If the verification fails, then retry the request/verify cycle until both functions are successful, the request function returns a failure message, or the global request timeout is hit. This wrapper is meant to deal with backend requests that can fail for any variety of reasons, for instance, when the system is already busy handling other LUN requests. It is also smart enough to give up if clustering is down (eg no HA available), there is no space left, or other ""fatal"" errors are returned (see _fatal_error_code() for a list of all known error conditions). Arguments: request_func -- XG api method to call verify_func -- function to call to verify request was completed successfully (eg for export) request_success_msg -- Success message expected from the backend for the request_func rargs -- argument array to be passed to the request_func vargs -- argument array to be passed to the verify_func Returns: The response dict from the last XG call. """""" resp = {} start = time.time() request_needed = True verify_needed = True if isinstance(request_success_msgs, basestring): request_success_msgs = [request_success_msgs] if rargs is None: rargs = [] if vargs is None: vargs = [] while request_needed or verify_needed: if time.time() - start >= self.request_timeout: raise RequestRetryTimeout(timeout=self.request_timeout) if request_needed: resp = request_func(*rargs) if not resp['message']: # XG requests will return None for a message if no message # string is passed int the raw response resp['message'] = '' for msg in request_success_msgs: if not resp['code'] and msg in resp['message']: # XG request func was completed request_needed = False break self._fatal_error_code(resp) elif verify_needed: success = verify_func(*vargs) if success: # XG verify func was completed verify_needed = False else: # try sending the request again request_needed = True return resp def _get_igroup(self, volume, connector): """"""Gets the igroup that should be used when configuring a volume. Arguments: volume -- volume object used to determine the igroup name Returns: igroup_name -- name of igroup (for configuring targets & initiators) """""" v = self.vmem_vip # Use the connector's primary hostname and use that as the # name of the igroup. The name must follow syntax rules # required by the array: ""must contain only alphanumeric # characters, dashes, and underscores. The first character # must be alphanumeric"". # igroup_name = re.sub(r'[\W]', '_', connector['host']) # verify that the igroup has been created on the backend, and # if it doesn't exist, create it! # bn = ""/vshare/config/igroup/%s"" % igroup_name resp = v.basic.get_node_values(bn) if not len(resp): v.igroup.create_igroup(igroup_name) return igroup_name def _get_volume_type_extra_spec(self, volume, spec_key): """"""Parse data stored in a volume_type's extra_specs table. Code adapted from examples in cinder/volume/drivers/solidfire.py and cinder/openstack/common/scheduler/filters/capabilities_filter.py. Arguments: volume -- volume object containing volume_type to query spec_key -- the metadata key to search for Returns: spec_value -- string value associated with spec_key """""" spec_value = None ctxt = context.get_admin_context() typeid = volume['volume_type_id'] if typeid: volume_type = volume_types.get_volume_type(ctxt, typeid) volume_specs = volume_type.get('extra_specs') for key, val in volume_specs.iteritems(): # Havana release altered extra_specs to require a # prefix on all non-host-capability related extra # specs, so that prefix is stripped here before # checking the key. # if ':' in key: scope = key.split(':') key = scope[1] if key == spec_key: spec_value = val break return spec_value def _wait_for_exportstate(self, volume_name, state=False): """"""Polls backend to verify volume's export configuration. XG sets/queries following a request to create or delete a lun export may fail on the backend if vshared is still processing the export action (or times out). We can check whether it is done by polling the export binding for a lun to ensure it is created or deleted. This function will try to verify the creation or removal of export state on both gateway nodes of the array every 5 seconds for up to 30 seconds. Arguments: volume_name -- name of volume to be polled state -- True to poll for existence, False for lack of Returns: True if the export state was correctly added or removed (depending on 'state' param) """""" status = [False, False] mg_conns = [self.vmem_mga.basic, self.vmem_mgb.basic] success = False bn = ""/vshare/config/export/container/%s/lun/%s"" \ % (self.container, volume_name) for i in xrange(6): for node_id in xrange(2): if not status[node_id]: resp = mg_conns[node_id].get_node_values(bn) if state and len(resp.keys()): status[node_id] = True elif (not state) and (not len(resp.keys())): status[node_id] = True if status[0] and status[1]: success = True break else: time.sleep(5) return success def _is_supported_vmos_version(self, version_string): """"""Check that the version of VMOS running on the gateways is valid for use with the OpenStack drivers. """""" for pattern in VMOS_SUPPORTED_VERSION_PATTERNS: if re.match(pattern, version_string): LOG.debug(""Verified VMOS version %s is supported"" % version_string) return True return False def _fatal_error_code(self, response): """"""Check the error code in a XG response for a fatal error, and returns an appropriate exception. Error codes extracted from vdmd_mgmt.c. Arguments: response -- a response dict result from an XG request """""" # known non-fatal response codes: # 1024: 'lun deletion in progress, try again later' # 14032: 'lc_err_lock_busy' if response['code'] == 14000: # lc_generic_error raise ViolinBackendErr(message=response['message']) elif response['code'] == 14002: # lc_err_assertion_failed raise ViolinBackendErr(message=response['message']) elif response['code'] == 14004: # lc_err_not_found raise ViolinBackendErrNotFound() elif response['code'] == 14005: # lc_err_exists raise ViolinBackendErrExists() elif response['code'] == 14008: # lc_err_unexpected_arg raise ViolinBackendErr(message=response['message']) elif response['code'] == 14014: # lc_err_io_error raise ViolinBackendErr(message=response['message']) elif response['code'] == 14016: # lc_err_io_closed raise ViolinBackendErr(message=response['message']) elif response['code'] == 14017: # lc_err_io_timeout raise ViolinBackendErr(message=response['message']) elif response['code'] == 14021: # lc_err_unexpected_case raise ViolinBackendErr(message=response['message']) elif response['code'] == 14025: # lc_err_no_fs_space raise ViolinBackendErr(message=response['message']) elif response['code'] == 14035: # lc_err_range raise ViolinBackendErr(message=response['message']) elif response['code'] == 14036: # lc_err_invalid_param raise ViolinBackendErr(message=response['message']) elif response['code'] == 14121: # lc_err_cancelled_err raise ViolinBackendErr(message=response['message']) elif response['code'] == 512: # Not enough free space in container (vdmd bug) raise ViolinBackendErr(message=response['message']) elif response['code'] == 1 and 'LUN ID conflict' \ in response['message']: # lun id conflict while attempting to export raise ViolinBackendErr(message=response['message']) class LunIdList(object): """"""Tracks available lun_ids for use when exporting a new lun for the first time. After instantiating a new LunIdList object, it should be updated (basically quiescing volumes/snapshot lun ID allocation between the array and the corresponding Openstack DB metadata). After that, the object can be queried to capture the next 'available' lun ID for use with exporting a new volume or snapshot. Only when the volume/snapshot is deleted entirely, the lun ID should be freed. Lun IDs are montonically increasing up to a max value of 16k, after which the selection will loop around to lun ID 1 and will continue to increment until an available ID is found. """""" def __init__(self, db, *args, **kwargs): self.max_lun_id = 16000 self.lun_id_list = [0] * self.max_lun_id self.lun_id_list[0] = 1 self.prev_index = 1 self.free_index = 1 self.context = context.get_admin_context() self.db = db def update_from_volume_ids(self, id_list=None): """"""Walk a list of volumes collected that the array knows about and check for any saved lun_id metadata for each of those volumes to fully sync the list. Note that the metadata keys are stored as strings. Arguments: id_list -- array containing names of volumes that exist on the backend (volume 'names' are UUIDs if they were made via the VMEM driver API) """""" if id_list is None: id_list = [] for item in id_list: try: metadata = self.db.volume_metadata_get(self.context, item) except exception.VolumeNotFound: LOG.warn(_(""No db state for lun %s, skipping lun_id update""), item) else: if metadata and 'lun_id' in metadata: index = int(metadata['lun_id']) self.lun_id_list[index] = 1 LOG.debug(""Set lun_id=%d for volume_id=%s"" % (index, item)) self.update_free_index(index) def update_from_snapshot_ids(self, id_list=None): """"""Walk a list of snapshots collected that the array knows about and check for any saved lun_id metadata for each of those snapshots to fully sync the list. Note that the metadata keys are stored as strings. Arguments: id_list -- array containing names of snapshots that exist on the backend (snapshot 'names' are UUIDs if they were made via the VMEM driver API) """""" if id_list is None: id_list = [] for item in id_list: try: metadata = self.db.snapshot_metadata_get(self.context, item) except exception.SnapshotNotFound: LOG.warn(_(""No db state for snap %s, skipping lun_id update""), item) else: if metadata and 'lun_id' in metadata: index = int(metadata['lun_id']) self.lun_id_list[index] = 1 LOG.debug(""Set lun_id=%d for snapshot_id=%s"" % (index, item)) self.update_free_index(index) def get_lun_id_for_volume(self, volume): """"""Allocate a free a lun ID to a volume and create a lun_id tag in the volume's metadata. Arguments: volume -- the volume object to allocate a lun_id to """""" metadata = self.db.volume_metadata_get(self.context, volume['id']) if not metadata or 'lun_id' not in metadata: metadata = {} metadata['lun_id'] = self.get_next_lun_id_str() self.db.volume_metadata_update(self.context, volume['id'], metadata, False) LOG.debug(""Assigned lun_id %s to volume %s"" % (metadata['lun_id'], volume['id'])) return metadata['lun_id'] def get_lun_id_for_snapshot(self, snapshot): """"""Allocate a free a lun ID to a snapshot and create a lun_id tag in the snapshot's metadata. Arguments: snapshot -- the snapshot object to allocate a lun_id to """""" metadata = self.db.snapshot_metadata_get(self.context, snapshot['id']) if not metadata or 'lun_id' not in metadata: metadata = {} metadata['lun_id'] = self.get_next_lun_id_str() self.db.snapshot_metadata_update(self.context, snapshot['id'], metadata, False) LOG.debug(""Assigned lun_id %s to volume %s"" % (metadata['lun_id'], snapshot['id'])) return metadata['lun_id'] def free_lun_id_for_volume(self, volume): """"""Remove the lun_id tag saved in the volume's metadata and free the lun ID in the internal tracking array. Arguments: volume -- the volume object with a lun ID to be free'd """""" metadata = self.db.volume_metadata_get(self.context, volume['id']) if metadata and 'lun_id' in metadata: self.free_lun_id_str(metadata['lun_id']) def free_lun_id_for_snapshot(self, snapshot): """"""Remove the lun_id tag saved in the snapshot's metadata and free the lun ID in the internal tracking array. Arguments: snapshot -- the snapshot object with a lun ID to be free'd """""" metadata = self.db.snapshot_metadata_get(self.context, snapshot['id']) if metadata and 'lun_id' in metadata: self.free_lun_id_str(metadata['lun_id']) def get_next_lun_id_str(self): """"""Mark the next available lun_id as allocated and return it to the caller. Returns: next_id -- the lun ID that being allocated to the caller """""" next_id = self.free_index self.lun_id_list[next_id] = 1 self.update_free_index() return str(next_id) def free_lun_id_str(self, value_str): """"""Mark a lun_id as now available, as if the lun was de-allocated. Arguments: value_str -- lun ID to free (in string format) """""" value = int(value_str) self.lun_id_list[value] = 0 self.update_free_index() def update_free_index(self, index=None): """"""Update the free index, monotonically increasing, and looping back to 1 after the max lun ID value is hit. Arguments: index -- assume that all values below this number may be already allocated, so start searching at that value if it is higher than the free_index """""" i = 0 count = 0 max_size = len(self.lun_id_list) if index and index > self.free_index: i = index + 1 else: i = self.free_index # avoid possibility of indexError if i >= max_size: i = 1 while self.lun_id_list[i] == 1 and count < max_size: count += 1 i += 1 if i >= max_size: i = 1 self.free_index = i if count == max_size: raise exception.Error(""Cannot find free lun_id, giving up!"") ",,3621,0
openstack%2Fcinder~master~Ied72c5568875eae2387cf6271f31ddc5eebcc4bb,openstack/cinder,master,Ied72c5568875eae2387cf6271f31ddc5eebcc4bb,Implement Huawei SDSHypervisor driver,MERGED,2014-09-23 08:25:50.000000000,2014-12-20 03:17:04.000000000,2014-12-18 04:22:17.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 5538}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 8846}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10503}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11047}, {'_account_id': 11538}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 12780}, {'_account_id': 12924}, {'_account_id': 13203}, {'_account_id': 13628}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-09-23 08:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5cb161ec953c6336ec4aff35b4634aef1fc7660a', 'message': 'Add code to Cinder K1 version for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 2, 'created': '2014-09-23 09:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f7ca3e8448611695737c1b66e8d535724440b12e', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 3, 'created': '2014-09-28 07:48:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/89b3221b17696e2fae36ce527e8cefc45eb76e14', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 4, 'created': '2014-09-28 09:29:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/55d253798d6461991854bde4153335d31f399397', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 5, 'created': '2014-09-29 01:51:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4ebbdb88705bfd55582f1f355e3218f96851c64b', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 6, 'created': '2014-10-25 07:16:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c3f68a0e3ddbd0a9381b33111082e7654661ecc8', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 7, 'created': '2014-10-25 07:33:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/443ac68e6fd5b295a555371fb952ab2d13aea1d3', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 8, 'created': '2014-10-25 07:35:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/df4177b2c2b6c90214317f4445075deffefa19cc', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 9, 'created': '2014-10-27 02:34:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/16d9436f7c17acebf5b3197175bb5652395c79ce', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 10, 'created': '2014-10-28 03:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f71c0764b47e299818d9626aee3130be0167c294', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 11, 'created': '2014-11-03 03:37:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/96faaeb23c91a87ed4714bbc3e1f72eab2e92fff', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 12, 'created': '2014-11-03 03:53:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1cc83bb3b335cb8beaea638032e05238eed98809', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 13, 'created': '2014-11-07 08:10:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/21c4d647c092601b6d4f2ded6ec5416ab78be490', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 14, 'created': '2014-11-07 09:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2bdecfb4ad52e4563863a13e22b08268d4407138', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 15, 'created': '2014-11-10 03:31:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/21576d1dc2cdc148addc46d2e7230dc8fa8d455d', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 16, 'created': '2014-11-21 03:13:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1ba0cb04a6353e4800c2fd744d5a6adfd14652e7', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 17, 'created': '2014-11-24 02:36:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d6b9910df71c0e12405a217323a12495a42f071c', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 18, 'created': '2014-11-26 04:12:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7c6639b6ed7bd820f6063babd28e8a1278b937ad', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 19, 'created': '2014-11-27 02:42:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6f3428d85964641435acc43e83c5b9c1d8ffdfc0', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 20, 'created': '2014-11-27 04:21:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/01d091f3364dcb1fbb75502acb00a2052302c519', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 21, 'created': '2014-11-28 08:53:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/139a26ba205495c1672d99dd395600bfedaf3a46', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 22, 'created': '2014-11-28 15:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8a01ab547b859b53b5f564cf92fd7ceee8a6d097', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 23, 'created': '2014-11-29 07:01:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e85ab1fc00ff39ca072674773db2e5c8726c05fe', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 24, 'created': '2014-12-04 08:51:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/73234adec862c7a29540ef0bb79dd12d56d72b6a', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 25, 'created': '2014-12-04 13:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/49b1321158dec9b66c13bfb3d60f9f9615e0b231', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\nImplements: blueprint huawei-sdshypervisor-driver\n\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 26, 'created': '2014-12-05 03:28:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/70b993584db3129e040ffa3deda6b1b8124e04f1', 'message': 'Add code for Huawei SDSHypervisor driver and connector\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\n\nImplements: blueprint huawei-sdshypervisor-driver\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 27, 'created': '2014-12-05 08:36:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/12144d47435a72cfe7cd43544b9185f9979b8a2b', 'message': 'Add code for Huawei SDSHypervisor driver\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\n\nImplements: blueprint huawei-sdshypervisor-driver\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 28, 'created': '2014-12-09 04:13:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/860786c7a6cd40faa66094201457103f044f7889', 'message': 'Add code for Huawei SDSHypervisor driver\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\n\nImplements: blueprint huawei-sdshypervisor-driver\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 29, 'created': '2014-12-09 11:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4de201891ff177210ba46a08a4e6b63c814c217c', 'message': 'Implement Huawei SDSHypervisor driver\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\n\nImplements: blueprint huawei-sdshypervisor-driver\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 30, 'created': '2014-12-11 09:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/57192499b85e16392ecd2792edbf4afae8755cdb', 'message': 'Implement Huawei SDSHypervisor driver\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\n\nImplements: blueprint huawei-sdshypervisor-driver\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 31, 'created': '2014-12-15 17:13:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/90b75f0e09f6cab4d8e1272e426a357924a46b50', 'message': 'Implement Huawei SDSHypervisor driver\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\n\nImplements: blueprint huawei-sdshypervisor-driver\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 32, 'created': '2014-12-15 17:18:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/50f64cb0e3393ad3918769a4489a61c78b3cdb8f', 'message': 'Implement Huawei SDSHypervisor driver\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\n\nImplements: blueprint huawei-sdshypervisor-driver\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 33, 'created': '2014-12-16 07:23:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bac401c1b408420d1550ff7db0fb4d7df8deb5ea', 'message': 'Implement Huawei SDSHypervisor driver\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\n\nImplements: blueprint huawei-sdshypervisor-driver\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 34, 'created': '2014-12-17 04:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f5625c2b56269e0f2a35fb55718ab8d0a4fcf846', 'message': 'Implement Huawei SDSHypervisor driver\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\n\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\n\nImplements: blueprint huawei-sdshypervisor-driver\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 35, 'created': '2014-12-17 10:11:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cd4be36f104ec75f96c978dbe51a26b36f76ea8d', 'message': 'Implement Huawei SDSHypervisor driver\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\n\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\n\nImplements: blueprint huawei-sdshypervisor-driver\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}, {'number': 36, 'created': '2014-12-17 12:06:21.000000000', 'files': ['cinder/volume/drivers/huaweistorhyper/huaweistorac.py', 'cinder/volume/drivers/huaweistorhyper/cinder_huawei_storac_conf.xml', 'cinder/volume/drivers/huaweistorhyper/__init__.py', 'cinder/volume/drivers/huaweistorhyper/vbs_client.py', 'cinder/tests/test_huaweistorac.py', 'cinder/volume/drivers/huaweistorhyper/utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/1a849a42645c053122b3aed779707d95e64194ea', 'message': 'Implement Huawei SDSHypervisor driver\n\nIt uses socket and CLI to communicate with SDSHypervisor\nto perform the following:\n* Create/Delete Volume\n* Extend Volume\n* Create/Delete Snapshot\n* Create Volume from Snapshot\n* Delete Volume Snapshot\n* Attach/Detach Volume\n* Get Volume Stats\n* Clone Volume\n\nCertification test result for Huawei SDSHypervisor:\nhttps://bugs.launchpad.net/cinder/+bug/1368064\n\nImplements: blueprint huawei-sdshypervisor-driver\nChange-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb\n'}]",197,123394,1a849a42645c053122b3aed779707d95e64194ea,313,33,36,11538,,,0,"Implement Huawei SDSHypervisor driver

It uses socket and CLI to communicate with SDSHypervisor
to perform the following:
* Create/Delete Volume
* Extend Volume
* Create/Delete Snapshot
* Create Volume from Snapshot
* Delete Volume Snapshot
* Attach/Detach Volume
* Get Volume Stats
* Clone Volume

Certification test result for Huawei SDSHypervisor:
https://bugs.launchpad.net/cinder/+bug/1368064

Implements: blueprint huawei-sdshypervisor-driver
Change-Id: Ied72c5568875eae2387cf6271f31ddc5eebcc4bb
",git fetch https://review.opendev.org/openstack/cinder refs/changes/94/123394/36 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/brick/test_brick_connector.py', 'cinder/volume/drivers/huaweistorhyper/huaweistorac.py', 'cinder/volume/manager.py', 'cinder/volume/drivers/huaweistorhyper/cinder_huawei_storac_conf.xml', 'cinder/volume/drivers/huaweistorhyper/__init__.py', 'cinder/volume/drivers/huaweistorhyper/vbs_client.py', 'etc/cinder/cinder.conf.sample', 'cinder/brick/initiator/connector.py', 'cinder/tests/test_huaweistorac.py', 'cinder/volume/drivers/huaweistorhyper/utils.py']",10,5cb161ec953c6336ec4aff35b4634aef1fc7660a,bp/huawei-sdshypervisor-driver,"# Copyright (c) 2014 Huawei Technologies Co., Ltd. # Copyright (c) 2012 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Utils for Huawei SDSHypervisor systems. """""" import re import socket from xml.etree import ElementTree from cinder.i18n import _ from cinder.openstack.common import log as logging LOG = logging.getLogger(__name__) def serialize(title, para): para_list = ['[' + title + ']\n'] if len(para) > 0: for key, value in para.items(): if isinstance(value, list): for item in value: para_list.append(key + ""="" + str(item) + ""\n"") else: para_list.append(key + ""="" + value + ""\n"") LOG.debug('key=%(key)s value=%(value)s' % {'key': key, 'value': value}) return ''.join(para_list) def deserialize(rsp_str, delimiter='\n'): LOG.debug('Calling deserialize: %s' % rsp_str) rsp = {} if len(rsp_str) > 0: lines = re.split(delimiter, rsp_str) for line in lines: LOG.debug('line = %s' % line) if re.search('=', line): paras = re.split('=', line, 1) key = paras[0].replace('=', '') value = paras[1].replace('\n', '').replace('\x00', '') rsp[key] = value.strip() return rsp def parse_xml_file(file_path): """"""Get root of xml file."""""" try: tree = ElementTree.parse(file_path) root = tree.getroot() return root except IOError as err: LOG.error(_('Parse_xml_file: %s'), exc_info=True) raise err def check_ipv4(ip_string): """"""Check if ip(v4) valid."""""" try: socket.inet_aton(ip_string) return True except Exception: return False def get_valid_ip_list(ip_list): valid_ip_list = [] for ip in ip_list: ip = ip.replace('\n', '') LOG.debug('IP=%s' % ip) if not check_ipv4(ip): LOG.warn(_('Invalid ip ,ip address is: %s') % ip) else: valid_ip_list.append(ip) return valid_ip_list def get_ip_and_port(config_file): root = parse_xml_file(config_file) vbs_url = root.findtext('controller/vbs_url').strip() LOG.debug('VbsClient vbs_url=%s' % vbs_url) vbs_port = root.findtext('controller/vbs_port').strip() LOG.debug('VbsClient vbs_port=%s' % vbs_port) valid_ip_list = get_valid_ip_list(re.split(',', vbs_url)) port = int(vbs_port) return valid_ip_list, port def log_dict(result): if result: for key, value in result.items(): LOG.debug('key=%(key)s value=%(value)s' % {'key': key, 'value': value}) def generate_dict_from_result(result): LOG.debug(result) result = result.replace('[', '').replace(']', '') result = deserialize(result, delimiter=',') log_dict(result) return result",,1816,1
openstack%2Fcinder~master~Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e,openstack/cinder,master,Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e,Add Scality SRB driver,MERGED,2014-07-29 08:55:23.000000000,2014-12-20 03:05:15.000000000,2014-12-18 04:19:53.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 7350}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9171}, {'_account_id': 9751}, {'_account_id': 10503}, {'_account_id': 10621}, {'_account_id': 11737}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12499}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13049}, {'_account_id': 13628}, {'_account_id': 13777}]","[{'number': 1, 'created': '2014-07-29 08:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4404b5eb694669da5419ebbf7066e0a204ed2fbb', 'message': 'Implements blueprint restblock-driver\n\nAdd the driver to control a native REST block driver through /sys\nwhich uses LVM for snapshot management\n\nWork In Progress\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n'}, {'number': 2, 'created': '2014-08-05 14:09:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a24c37a19e3962510030609f23d9266e50243464', 'message': ""Add a driver using a native REST block driver\n\nImplements blueprint restblock-driver\n\nAdd the driver to control a native REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nWork In Progress\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 3, 'created': '2014-08-07 14:24:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8d1640e2da5465802fe01e5487d23a27a8a99436', 'message': ""Add a driver using a native REST block driver\n\nImplements blueprint restblock-driver\n\nAdd the driver to control a native REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nLVM+Volume groupe management done by using temporary LVM objects.\n\nWork In Progress\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 4, 'created': '2014-08-07 15:03:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8cb8a827d18a12a712ad53c004f8db1628804a66', 'message': ""Add a driver using a native REST block driver\n\nImplements blueprint restblock-driver,\nnamed restblock.py for name differentiation from Ceph's rbd\n\nAdd the driver to control a native REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nLVM+Volume groupe management done by using temporary LVM objects.\n\nWork In Progress\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 5, 'created': '2014-08-07 15:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/45bd1a894499881babc8be76b691e44a6ec91dcc', 'message': ""Add a driver using a native REST block driver\n\nImplements blueprint restblock-driver,\nnamed restblock.py for name differentiation from Ceph's rbd\n\nAdd the driver to control a native REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nLVM+Volume groupe management done by using temporary LVM objects.\n\nWork In Progress\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 6, 'created': '2014-08-08 16:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f8f79f96ffd40e7dc4497c68c80cd9d3bdb04c1a', 'message': ""Add a driver using a native REST block driver\n\nImplements blueprint restblock-driver,\nnamed restblock.py for name differentiation from Ceph's rbd\n\nAdd the driver to control a native REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nLVM+Volume groupe management done by using temporary LVM objects.\n\nWork In Progress\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 7, 'created': '2014-08-12 14:35:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/90fce292b604edd0cd397ea6d5a103ec6a37382f', 'message': ""Add a driver using a native REST block driver\n\nImplements blueprint restblock-driver,\nnamed restblock.py for name differentiation from Ceph's rbd\n\nAdd the driver to control a native REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nLVM+Volume groupe management done by using temporary LVM objects.\n\nWork In Progress\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 8, 'created': '2014-08-18 10:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7f3053f30b4834fc049e07bf58beb893e0d1bb01', 'message': ""Add a driver using a native REST block driver\n\nImplements blueprint restblock-driver,\nnamed restblock.py for name differentiation from Ceph's rbd\n\nAdd the driver to control a native REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nLVM+Volume group management done by using temporary LVM objects.\n\nWork In Progress\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 9, 'created': '2014-08-25 17:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/51b841ab83ef01c97af8ec121366218f8831b4e6', 'message': ""Add a driver using a native REST block driver\n\nImplements blueprint restblock-driver,\nnamed restblock.py for name differentiation from Ceph's rbd\n\nAdd the driver to control a native REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nWork In Progress\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 10, 'created': '2014-08-26 09:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3d07a3c2c31890dbbad5068b2f6b57ddf4d4844f', 'message': ""Add a driver using a native REST block driver\n\nImplements blueprint restblock-driver,\nnamed restblock.py for name differentiation from Ceph's rbd\n\nAdd the driver to control a native REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nWork In Progress\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 11, 'created': '2014-08-26 12:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5922ec517f4d7fd667caff8a5cf9b24be553b73d', 'message': ""Add a driver using a native REST block driver\n\nImplements blueprint restblock-driver,\nnamed restblock.py for name differentiation from Ceph's rbd\n\nAdd the driver to control a native REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nWork In Progress\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 12, 'created': '2014-08-27 17:17:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6b1d476a6913272e2f579178ac9ad1359fa809a1', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 13, 'created': '2014-08-28 16:19:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cead23a7dff8f2c761b648b342045d89c39dff04', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds a destroy() method to brick/local_dev/lvm.py as a dep.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 14, 'created': '2014-09-01 16:17:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/efd591f560bd716af57f02d7ddaceb78de33d54e', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds a destroy() method to brick/local_dev/lvm.py as a dep,\nwith the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 15, 'created': '2014-09-02 18:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2151c2f337704d5bc871c81a55ea92196a52224c', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 16, 'created': '2014-09-03 12:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8dccf8b31ce70eb0749b500e01660146081ce932', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 17, 'created': '2014-09-03 14:34:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ad5d2cc857c5b1654c2ea63384df9172f2e64c4a', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 18, 'created': '2014-09-05 17:28:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2c849c9406bcd44bdaef4da6be31d9d1aeaad31a', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 19, 'created': '2014-09-06 14:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0f65e3c79222ae81ca3656df5079e1208dbe987b', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 20, 'created': '2014-09-23 16:42:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b4c468a5887870ccec9e1395b07d23c6262902e9', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 21, 'created': '2014-09-24 10:33:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9bd454f362eb5b9d3c4679d5239772c21a2964ce', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 22, 'created': '2014-09-24 11:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2b5974376e2cf02ec2624d3aa62d6f7c188a17e3', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 23, 'created': '2014-09-24 13:56:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e0b745610980985b797c5aa9539d515eba9b9b36', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 24, 'created': '2014-09-25 15:22:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4ca91068b127be627dcaabdd4200527448808b91', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nNote: this driver also defines it own retry decorator, as well as\nmonkey-patches the brick's LVM activate_lv method for its own needs.\nIt is open to discussion whether those ways are the right ones or not,\nbut it at least allows going forward for this driver.\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 25, 'created': '2014-09-25 16:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/89dd69570b4bcdac3d084a41ef75602d27fb53c1', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nNote: this driver also defines it own retry decorator, as well as\nmonkey-patches the brick's LVM activate_lv method for its own needs.\nIt is open to discussion whether those ways are the right ones or not,\nbut it at least allows going forward for this driver.\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 26, 'created': '2014-09-26 12:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2df0bad843a5aba6d6f89a6e365035d101a7c9b4', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nNote: this driver also defines it own retry decorator, as well as\nmonkey-patches the brick's LVM activate_lv method for its own needs.\nIt is open to discussion whether those ways are the right ones or not,\nbut it at least allows going forward for this driver.\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 27, 'created': '2014-09-26 15:37:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/39e43d25018aa65691929cb116379978eb16670d', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nNote: this driver also defines it own retry decorator, as well as\nmonkey-patches the brick's LVM activate_lv method for its own needs.\nIt is open to discussion whether those ways are the right ones or not,\nbut it at least allows going forward for this driver.\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 28, 'created': '2014-09-26 16:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bfa3c54bcc700e4162bd1ca94f599832c2b3cfc7', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nNote: this driver also defines it own retry decorator, as well as\nmonkey-patches the brick's LVM activate_lv method for its own needs.\nIt is open to discussion whether those ways are the right ones or not,\nbut it at least allows going forward for this driver.\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 29, 'created': '2014-09-30 14:05:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b0d54fbbb34c6bf6050e2fb574850dd81cbabd3b', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nNote: this driver also defines it own retry decorator, as well as\nmonkey-patches the brick's LVM activate_lv method for its own needs.\nIt is open to discussion whether those ways are the right ones or not,\nbut it at least allows going forward for this driver.\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 30, 'created': '2014-09-30 15:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f818e377985164dfa60da1a00fb2ef05da73a939', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nNote: this driver also defines it own retry decorator, as well as\nmonkey-patches the brick's LVM activate_lv method for its own needs.\nIt is open to discussion whether those ways are the right ones or not,\nbut it at least allows going forward for this driver.\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 31, 'created': '2014-10-10 10:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f5c71a06b07ac8fd9b0225f63d135be86d6a7c12', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nNote: this driver also defines it own retry decorator, as well as\nmonkey-patches the brick's LVM activate_lv method for its own needs.\nIt is open to discussion whether those ways are the right ones or not,\nbut it at least allows going forward for this driver.\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 32, 'created': '2014-10-10 13:03:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c300945c5d825808041d5c8aa772186914876712', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nNote: this driver also defines it own retry decorator, as well as\nmonkey-patches the brick's LVM activate_lv method for its own needs.\nIt is open to discussion whether those ways are the right ones or not,\nbut it at least allows going forward for this driver.\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 33, 'created': '2014-11-04 14:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/345e441c4430b8831ad5af1c366dc3b0bbcf4e61', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nNote: this driver also defines it own retry decorator, as well as\nmonkey-patches the brick's LVM activate_lv method for its own needs.\nIt is open to discussion whether those ways are the right ones or not,\nbut it at least allows going forward for this driver.\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 34, 'created': '2014-11-04 17:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3bbdded7751d4b3900791e8deaf7d6d885c79610', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nNote: this driver also defines it own retry decorator, as well as\nmonkey-patches the brick's LVM activate_lv method for its own needs.\nIt is open to discussion whether those ways are the right ones or not,\nbut it at least allows going forward for this driver.\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 35, 'created': '2014-11-07 16:30:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e3337a8ddcea7925a13fc18df4c59b73526b29a0', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nNote: this driver also defines it own retry decorator, as well as\nmonkey-patches the brick's LVM activate_lv method for its own needs.\nIt is open to discussion whether those ways are the right ones or not,\nbut it at least allows going forward for this driver.\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 36, 'created': '2014-11-07 16:35:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9ab488337755a2d99f0d9f5d1fb60cc8e67f1d56', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nNote: this driver also defines it own retry decorator, as well as\nmonkey-patches the brick's LVM activate_lv method for its own needs.\nIt is open to discussion whether those ways are the right ones or not,\nbut it at least allows going forward for this driver.\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 37, 'created': '2014-11-12 10:33:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8ba90563aca7e6d708a526db6007f17b1e67335e', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nNote: this driver also defines it own retry decorator, as well as\nmonkey-patches the brick's LVM activate_lv method for its own needs.\nIt is open to discussion whether those ways are the right ones or not,\nbut it at least allows going forward for this driver.\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 38, 'created': '2014-11-19 16:31:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9418537c0ac54b55be6973f0b7d9894bf2c61d7d', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nNote: this driver also defines it own retry decorator, as well as\nmonkey-patches the brick's LVM activate_lv method for its own needs.\nIt is open to discussion whether those ways are the right ones or not,\nbut it at least allows going forward for this driver.\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 39, 'created': '2014-11-25 16:50:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/86efc934d6ed4788f11e768441e6a2137cc4b710', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nNote: this driver also defines it own retry decorator, as well as\nmonkey-patches the brick's LVM activate_lv method for its own needs.\nIt is open to discussion whether those ways are the right ones or not,\nbut it at least allows going forward for this driver.\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 40, 'created': '2014-11-25 17:46:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2bc6cc62b71211f2055f350806819b4a7a609992', 'message': ""Adding Scality Rest Block driver\n\nImplements blueprint srb-driver,\nnamed srb.py for <Scality Rest Block>. It is a similar approach as\nCeph's RBD in the way it provides Block devices to the system.\n\nAdd the driver to control a kernel REST block driver through /sys\nwhich uses LVM for snapshot management. The native block driver talks\nthrough a REST API to Scality's Storage (support file system semantics),\nand might support more vendors in the future.\n\nIncidentally adds methods destroy_vg(), extend_thinpool(), pv_resize()\nto brick/local_dev/lvm.py as a dep, with the associated test update.\n\nLVM+Volume group management done by using temporary LVM objects.\niSCSI for export to nova (Future plans: add a own transport 'protocol')\n\nNote: this driver also defines it own retry decorator, as well as\nmonkey-patches the brick's LVM activate_lv method for its own needs.\nIt is open to discussion whether those ways are the right ones or not,\nbut it at least allows going forward for this driver.\n\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 41, 'created': '2014-12-08 13:06:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c8a092daf9da82e8ff2f1aad92077db794f5cbee', 'message': ""Add Scality SRB driver\n\nThis patch implements the `srb-driver` blueprint. It uses a similar\napproach as Ceph's RBD in the way it exposes a block device to the\nsystem.\n\nThe driver controls the SRB Linux kernel driver through a sysfs\ninterface and leverages LVM for snapshot management. The native block\ndriver talks to Scality's storage system (or any other vendor exposing\na compatible CDMI interface) through a HTTP-based RESTful protocol.\n\niSCSI export to Nova is provided.\n\nThis driver depends on the extensions to the LVM brick proposed in\nhttps://review.openstack.org/#/c/138348/\n\nImplements: blueprint srb-driver\nSee: https://blueprints.launchpad.net/cinder/+spec/srb-driver\nCo-Authored-By: Nicolas Trangez <ikke@nicolast.be>\nCo-Authored-By: JordanP <jordan.pittier@scality.com>\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 42, 'created': '2014-12-08 14:17:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/62eb001394d60bb7b1e5b60b5182501a5ec140da', 'message': ""Add Scality SRB driver\n\nThis patch implements the `srb-driver` blueprint. It uses a similar\napproach as Ceph's RBD in the way it exposes a block device to the\nsystem.\n\nThe driver controls the SRB Linux kernel driver through a sysfs\ninterface and leverages LVM for snapshot management. The native block\ndriver talks to Scality's storage system (or any other vendor exposing\na compatible CDMI interface) through a HTTP-based RESTful protocol.\n\niSCSI export to Nova is provided.\n\nDriver cert results are provided in bug #1400327.\n\nThis driver depends on the extensions to the LVM brick proposed in\nhttps://review.openstack.org/#/c/138348/\n\nImplements: blueprint srb-driver\nSee: https://blueprints.launchpad.net/cinder/+spec/srb-driver\nRelated-Bug: #1400327\nSee: https://bugs.launchpad.net/cinder/+bug/1400327\nCo-Authored-By: Nicolas Trangez <ikke@nicolast.be>\nCo-Authored-By: JordanP <jordan.pittier@scality.com>\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 43, 'created': '2014-12-16 20:47:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/30c3a5465a3e69ab418b81d8022db019834c0683', 'message': ""Add Scality SRB driver\n\nThis patch implements the `srb-driver` blueprint. It uses a similar\napproach as Ceph's RBD in the way it exposes a block device to the\nsystem.\n\nThe driver controls the SRB Linux kernel driver through a sysfs\ninterface and leverages LVM for snapshot management. The native block\ndriver talks to Scality's storage system (or any other vendor exposing\na compatible CDMI interface) through a HTTP-based RESTful protocol.\n\niSCSI export to Nova is provided.\n\nDriver cert results are provided in bug #1400327.\n\nImplements: blueprint srb-driver\nSee: https://blueprints.launchpad.net/cinder/+spec/srb-driver\nRelated-Bug: #1400327\nSee: https://bugs.launchpad.net/cinder/+bug/1400327\nCo-Authored-By: Nicolas Trangez <ikke@nicolast.be>\nCo-Authored-By: JordanP <jordan.pittier@scality.com>\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 44, 'created': '2014-12-16 21:04:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e75f9dc9008c26091033bdde7809d593d7aac621', 'message': ""Add Scality SRB driver\n\nThis patch implements the `srb-driver` blueprint. It uses a similar\napproach as Ceph's RBD in the way it exposes a block device to the\nsystem.\n\nThe driver controls the SRB Linux kernel driver through a sysfs\ninterface and leverages LVM for snapshot management. The native block\ndriver talks to Scality's storage system (or any other vendor exposing\na compatible CDMI interface) through a HTTP-based RESTful protocol.\n\niSCSI export to Nova is provided.\n\nDriver cert results are provided in bug #1400327.\n\nImplements: blueprint srb-driver\nSee: https://blueprints.launchpad.net/cinder/+spec/srb-driver\nRelated-Bug: #1400327\nSee: https://bugs.launchpad.net/cinder/+bug/1400327\nCo-Authored-By: Nicolas Trangez <ikke@nicolast.be>\nCo-Authored-By: JordanP <jordan.pittier@scality.com>\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}, {'number': 45, 'created': '2014-12-17 12:10:55.000000000', 'files': ['etc/cinder/rootwrap.d/volume.filters', 'cinder/tests/test_srb.py', 'cinder/volume/drivers/srb.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a23f17f8cebe5e1e57f675aedf6272257257d1b7', 'message': ""Add Scality SRB driver\n\nThis patch implements the `srb-driver` blueprint. It uses a similar\napproach as Ceph's RBD in the way it exposes a block device to the\nsystem.\n\nThe driver controls the SRB Linux kernel driver through a sysfs\ninterface and leverages LVM for snapshot management. The native block\ndriver talks to Scality's storage system (or any other vendor exposing\na compatible CDMI interface) through a HTTP-based RESTful protocol.\n\niSCSI export to Nova is provided.\n\nDriver cert results are provided in bug #1400327.\n\nImplements: blueprint srb-driver\nSee: https://blueprints.launchpad.net/cinder/+spec/srb-driver\nRelated-Bug: #1400327\nSee: https://bugs.launchpad.net/cinder/+bug/1400327\nCo-Authored-By: Nicolas Trangez <ikke@nicolast.be>\nCo-Authored-By: JordanP <jordan.pittier@scality.com>\nChange-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e\n""}]",172,110236,a23f17f8cebe5e1e57f675aedf6272257257d1b7,293,32,45,11737,,,0,"Add Scality SRB driver

This patch implements the `srb-driver` blueprint. It uses a similar
approach as Ceph's RBD in the way it exposes a block device to the
system.

The driver controls the SRB Linux kernel driver through a sysfs
interface and leverages LVM for snapshot management. The native block
driver talks to Scality's storage system (or any other vendor exposing
a compatible CDMI interface) through a HTTP-based RESTful protocol.

iSCSI export to Nova is provided.

Driver cert results are provided in bug #1400327.

Implements: blueprint srb-driver
See: https://blueprints.launchpad.net/cinder/+spec/srb-driver
Related-Bug: #1400327
See: https://bugs.launchpad.net/cinder/+bug/1400327
Co-Authored-By: Nicolas Trangez <ikke@nicolast.be>
Co-Authored-By: JordanP <jordan.pittier@scality.com>
Change-Id: Id8d00df9db4004d5aeb8c0269d114ef50e0b8f8e
",git fetch https://review.opendev.org/openstack/cinder refs/changes/36/110236/12 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/rest_block_device.py'],1,4404b5eb694669da5419ebbf7066e0a204ed2fbb,bug/1400327,"# Copyright (c) 2014 Scality # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Rest-based Block Device Volume Driver. """""" from oslo.config import cfg from cinder.volume import driver from cinder import exception from cinder.image import image_utils from cinder.openstack.common import log as logging from cinder.brick.local_dev import lvm from cinder.openstack.common import putils from cinder import units from cinder.volume import utils as volutils LOG = logging.getLogger(__name__) volume_opts = [ cfg.StrOpt('rest_debug', default=False, help='Boolean to activate or deactivate by-device debug'), cfg.StrOpt('rest_base_urls', default=None, help='Coma-separated list of REST servers to connect to'), ] CONF = cfg.CONF CONF.register_opts(volume_opts) class RestBlockDriver(driver.VolumeDriver): """"""REST Block Driver's cinder driver. Creates and manages volume files on a REST-based storage service for hypervisors to use as block devices through a native linux Loadable Kernel Module. """""" VERSION = '0.1.0' class TempSnapshot(object): def __init__(self, drv, volume, src_vref): self.__driver = drv self.__dst = volume self.__src = src_vref self.__snap = {'volume_name': self.__src['name'], 'size': self.__src['size'], 'volume_size': self.__src['size'], 'name': 'clone-snap-%s' % self.__dst['id'], 'id': 'tmp-snap-%s' % self.__dst['id']} def __enter__(self): self.__driver.create_snapshot(self.__snap) def get_snap(self): return self.__snap def __leave__(self): self.__driver.delete_snapshot(self.__snap) def __init__(self, vg_obj=None, *args, **kwargs): super().__init__(*args, **kwargs) self.stats = {} self.configuration.append_config_values(volume_opts) self.backend_name =\ (self.configuration.safe_get('volume_backend_name') or 'RestBlockDriver') urls = self.configuration.safe_get('rest_base_urls') self.base_urls = [url for url in urls.split(',')] self.mirrors_setup = False def _setup_mirrors(self): if len(self.base_urls) == 0: return try: putils.execute('echo', self.base_urls, '>', '/sys/class/dewb/add_mirrors') self.mirrors_setup = True except putils.ProcessExecutionError as err: LOG.debug(_('Error creating Volume')) LOG.debug(_('Cmd :%s') % err.cmd) LOG.debug(_('Exit Code :%s') % err.exit_code) LOG.debug(_('StdOut :%s') % err.stdout) LOG.debug(_('StdErr :%s') % err.stderr) msg = _('Could not create volume on any configured REST server') LOG.error(msg) def do_setup(self, context): """"""Any initialization the volume driver does while starting."""""" self._setup_mirrors() def check_for_setup_error(self): """"""Returns an error if prerequisites aren't met."""""" if len(self.base_urls) == 0: msg = _(""Configuration variable rest_base_urls not set or empty."") LOG.warn(msg) raise exception.VolumeBackendAPIException(data=msg) if self.mirrors_setup == False: msg = _(""Could not setup mirrors properly"") def _size_bytes(self, size_in_g): if int(size_in_g) == 0: return 100 * units.MiB return int(size_in_g) * units.GiB def _set_device_path(self, volume): volume['provider_location'] = ""/dev/dewb/"" + volume['name'] + ""/device"" return { 'provider_location': volume['provider_location'], } def _create_file(self, volume): try: args = volume['name'] + ' ' + self._size_bytes(volume['size']) putils.execute('echo', args, '>', '/sys/class/dewb/create', run_as_root=True) except putils.ProcessExecutionError as err: LOG.debug(_('Error creating Volume')) LOG.debug(_('Cmd :%s') % err.cmd) LOG.debug(_('Exit Code :%s') % err.exit_code) LOG.debug(_('StdOut :%s') % err.stdout) LOG.debug(_('StdErr :%s') % err.stderr) msg = _('Could not create volume on any configured REST server') LOG.error(msg) raise exception.VolumeBackendAPIException(msg) return self._set_device_path(volume) def _extend_file(self, volume, new_size): try: args = volume['name'] + ' ' + self._size_bytes(new_size) putils.execute('echo', args, '>', '/sys/class/dewb/create', run_as_root=True) volume['size'] = new_size except putils.ProcessExecutionError as err: LOG.debug(_('Error creating Volume')) LOG.debug(_('Cmd :%s') % err.cmd) LOG.debug(_('Exit Code :%s') % err.exit_code) LOG.debug(_('StdOut :%s') % err.stdout) LOG.debug(_('StdErr :%s') % err.stderr) msg = _('Could not create volume on any configured REST server') LOG.error(msg) raise exception.VolumeBackendAPIException(msg) def _destroy_file(self, volume): try: putils.execute('echo', volume['name'], '>', '/sys/class/dewb/destroy', run_as_root=True) except putils.ProcessExecutionError as err: LOG.debug(_('Error destroying Volume')) LOG.debug(_('Cmd :%s') % err.cmd) LOG.debug(_('Exit Code :%s') % err.exit_code) LOG.debug(_('StdOut :%s') % err.stdout) LOG.debug(_('StdErr :%s') % err.stderr) msg = _('Could not destroy volume on any configured REST server') LOG.error(msg) raise exception.VolumeBackendAPIException(msg) def _get_lvm_vg(self, volume, create_vg=False): # NOTE(joachim): One-device volume group to manage thin snapshots physical_volumes = [volume['provider_location']] return lvm.LVM(volume['name'], putils.get_root_helper(), create_vg=create_vg, physical_volumes=physical_volumes, lvm_type='thin') def _setup_lvm(self, volume): # NOTE(joachim): One-device volume group to manage thin snapshots vg = self._get_lvm_vg(volume, create_vg=True) vg.create_volume(volume['name'], self._size_byte(volume['size']), lv_type='thin') def _volume_not_present(self, volume_name): # Used to avoid failing to delete a volume for which # the create operation partly failed return self.vg.get_volume(volume_name) is None def _escape_snapshot(self, snapshot_name): # Linux LVM reserves name that starts with snapshot, so that # such volume name can't be created. Mangle it. if not snapshot_name.startswith('snapshot'): return snapshot_name return '_' + snapshot_name def _create_volume(self, volume): """"""Creates the file + Add as a device using the native driver."""""" updates = self._create_file(volume) self._setup_lvm(volume) return updates def _delete_volume(self, volume): vg = self._get_lvm_vg(volume) if vg.lv_has_snapshot(volume['name']): LOG.error(_('Unabled to delete due to existing snapshot ' 'for volume: %s') % volume['name']) raise exception.VolumeIsBusy(volume_name=volume['name']) self._destroy_file(volume) def _create_n_copy_volume(self, dstvol, srcvol, is_snapshot=False): """"""Creates a volume from a snapshot."""""" updates = self._create_volume(dstvol) # Some configurations of LVM do not automatically activate # ThinLVM snapshot LVs. vg = self._get_lvm_vg(srcvol) vg.activate_lv(srcvol['name'], is_snapshot) # copy_volume expects sizes in MiB, we store integer GiB # be sure to convert before passing in volutils.copy_volume(self.local_path(srcvol), self.local_path(dstvol), srcvol['volume_size'] * units.KiB, self.configuration.volume_dd_blocksize, execute=self._execute) return updates def create_volume(self, volume): """"""Creates a volume. Can optionally return a Dictionary of changes to the volume object to be persisted. """""" return self._create_volume(volume) def create_volume_from_snapshot(self, volume, snapshot): updates = self._create_n_copy_volume(volume, snapshot, is_snapshot=True) return updates def create_cloned_volume(self, volume, src_vref): """"""Creates a clone of the specified volume."""""" LOG.info(_('Creating clone of volume: %s') % src_vref['id']) updates = None with self.TempSnapshot(self, volume, src_vref) as temp: updates = self._create_n_copy_volume(volume, temp.get_snap()) return updates def delete_volume(self, volume): """"""Deletes a volume."""""" self._delete_volume(volume) def create_snapshot(self, snapshot): """"""Creates a snapshot."""""" self.vg.create_lv_snapshot(self._escape_snapshot(snapshot['name']), snapshot['volume_name'], self.configuration.lvm_type) def delete_snapshot(self, snapshot): """"""Deletes a snapshot."""""" if self._volume_not_present(self._escape_snapshot(snapshot['name'])): # If the snapshot isn't present, then don't attempt to delete LOG.warning(_(""snapshot: %s not found, "" ""skipping delete operations"") % snapshot['name']) return self.vg.delete(self._escape_snapshot(snapshot['name'])) def local_path(self, volume): # NOTE(vish): stops deprecation warning escaped_group = volume['name'].replace('-', '--') escaped_name = self._escape_snapshot(volume['name']).replace('-', '--') return ""/dev/mapper/%s-%s"" % (escaped_group, escaped_name) def get_volume_stats(self, refresh=False): """"""Return the current state of the volume service. If 'refresh' is True, run the update first. """""" stats = { 'vendor_name': 'Scality - Open Source', 'driver_version': self.VERSION, 'storage_protocol': 'REST Block Device', 'total_capacity_gb': 'infinite', 'free_capacity_gb': 'infinite', 'reserved_percentage': 0, 'volume_backend_name' : self.backend_name, } return stats def copy_image_to_volume(self, context, volume, image_service, image_id): """"""Fetch the image from image_service and write it to the volume."""""" image_utils.fetch_to_raw(context, image_service, image_id, self.local_path(volume), self.configuration.volume_dd_blocksize, size=volume['size']) def copy_volume_to_image(self, context, volume, image_service, image_meta): """"""Copy the volume to the specified image."""""" image_utils.upload_volume(context, image_service, image_meta, self.local_path(volume)) def extend_volume(self, volume, new_size): self._extend_file(volume, new_size) ",,318,0
openstack%2Fneutron-fwaas~master~I2fbe139ef78a8fb528b8ac67f00852ce7a29e4ae,openstack/neutron-fwaas,master,I2fbe139ef78a8fb528b8ac67f00852ce7a29e4ae,Do not list neutron in requirements.txt,MERGED,2014-12-19 21:43:03.000000000,2014-12-20 03:00:02.000000000,2014-12-20 03:00:00.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6659}, {'_account_id': 7448}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-19 21:43:03.000000000', 'files': ['requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/211bbc8d20f84fe0732ec781f81b84d3dfb3974f', 'message': 'Do not list neutron in requirements.txt\n\nIt does not play nicely with openstack/requirements\n\nPartially-Implements: blueprint services-split\n\nChange-Id: I2fbe139ef78a8fb528b8ac67f00852ce7a29e4ae\n'}]",0,143200,211bbc8d20f84fe0732ec781f81b84d3dfb3974f,10,5,1,10980,,,0,"Do not list neutron in requirements.txt

It does not play nicely with openstack/requirements

Partially-Implements: blueprint services-split

Change-Id: I2fbe139ef78a8fb528b8ac67f00852ce7a29e4ae
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/00/143200/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'tox.ini']",2,211bbc8d20f84fe0732ec781f81b84d3dfb3974f,bp/services-split,install_command = pip install -U {opts} {packages} deps = -egit+https://git.openstack.org/openstack/neutron#egg=neutron -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt,install_command = pip install -r requirements.txt -U {opts} {packages} deps = -r{toxinidir}/test-requirements.txt,8,3
openstack%2Fcinder~master~I69c32ef3225c23881be522eac451b8855805e35d,openstack/cinder,master,I69c32ef3225c23881be522eac451b8855805e35d,Update volume driver for Huawei storage system,MERGED,2014-11-07 10:35:11.000000000,2014-12-20 02:53:33.000000000,2014-12-18 04:19:17.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 2861}, {'_account_id': 5538}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 8067}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9533}, {'_account_id': 9624}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11538}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 12780}, {'_account_id': 12924}, {'_account_id': 13203}, {'_account_id': 13628}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-11-07 10:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cf1d4bac48c9921341c54b477c916e0367b2d4bc', 'message': 'Add volume driver for Huawei storage system\n\nHuawei OceanStor series enterprise storage system is an optimum\nstorage platform for next-generation data centers that feature\nvirtualization, hybrid cloud, simplified IT, and low carbon footprints.\n\nThis patch add an iSCSI driver and a FC driver for Huawei storage\nsystem, using REST. We define a common module for both iSCSI driver and\nFC driver.\n\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\nImplements: blueprint huawei-storage-drivers\n'}, {'number': 2, 'created': '2014-11-07 10:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/08c66dffe6e911a56919d65840d7f636aa3e753a', 'message': 'Add volume driver for Huawei storage system\n\nHuawei OceanStor series enterprise storage system is an optimum\nstorage platform for next-generation data centers that feature\nvirtualization, hybrid cloud, simplified IT, and low carbon footprints.\n\nThis patch add an iSCSI driver and a FC driver for Huawei storage\nsystem, using REST. We define a common module for both iSCSI driver and\nFC driver.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 3, 'created': '2014-11-08 07:01:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bbc012ed087d642d15d9f9ec452988481beeab28', 'message': 'Add volume driver for Huawei storage system\n\nHuawei OceanStor series enterprise storage system is an optimum\nstorage platform for next-generation data centers that feature\nvirtualization, hybrid cloud, simplified IT, and low carbon footprints.\n\nThis patch add an iSCSI driver and a FC driver for Huawei storage\nsystem, using REST. We define a common module for both iSCSI driver and\nFC driver.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 4, 'created': '2014-11-10 09:07:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2e402f1035468d172a13a30ac1ca8f5623a84a49', 'message': 'Add volume driver for Huawei  storage system\n\nHuawei OceanStor series enterprise storage system is an optimum\nstorage platform for next-generation data centers that feature\nvirtualization, hybrid cloud, simplified IT, and low carbon footprints.\n\nThis patch add an iSCSI driver and a FC driver for Huawei storage\nsystem, using REST. We define a common module for both iSCSI driver and\nFC driver.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 5, 'created': '2014-11-10 12:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f92702c7af44b3840f77082996e8a492e714e022', 'message': 'Add volume driver for Huawei  storage system\n\nHuawei OceanStor series enterprise storage system is an optimum\nstorage platform for next-generation data centers that feature\nvirtualization, hybrid cloud, simplified IT, and low carbon footprints.\n\nThis patch add an iSCSI driver and a FC driver for Huawei storage\nsystem, using REST. We define a common module for both iSCSI driver and\nFC driver.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 6, 'created': '2014-11-11 09:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c785ead315e3df20a5c4ce60d0b6e9007239677c', 'message': 'Add volume driver for Huawei  storage system\n\nHuawei OceanStor series enterprise storage system is an optimum\nstorage platform for next-generation data centers that feature\nvirtualization, hybrid cloud, simplified IT, and low carbon footprints.\n\nThis patch add an iSCSI driver and a FC driver for Huawei storage\nsystem, using REST. We define a common module for both iSCSI driver and\nFC driver.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 7, 'created': '2014-11-12 02:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8f33315ee18687b69de04cfac487b6310cfefc44', 'message': 'Add volume driver for Huawei  storage system\n\nHuawei OceanStor series enterprise storage system is an optimum\nstorage platform for next-generation data centers that feature\nvirtualization, hybrid cloud, simplified IT, and low carbon footprints.\n\nThis patch add an iSCSI driver and a FC driver for Huawei storage\nsystem, using REST. We define a common module for both iSCSI driver and\nFC driver.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 8, 'created': '2014-11-14 02:37:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/34f08240156bbc3b346e6d061035d1fdf722a488', 'message': 'Add volume driver for Huawei  storage system\n\nHuawei OceanStor series enterprise storage system is an optimum\nstorage platform for next-generation data centers that feature\nvirtualization, hybrid cloud, simplified IT, and low carbon footprints.\n\nThis patch add an iSCSI driver and a FC driver for Huawei storage\nsystem, using REST. We define a common module for both iSCSI driver and\nFC driver.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 9, 'created': '2014-11-14 08:30:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/89da791bc5d32d8a44c46e02c48c97e9dfe83805', 'message': 'Temporarily remove support for qos function\n\nThis commit temporarily removed support for qos function and\nhave improved the compatibility for difference Huawei storage series.\nWe also renamed the ""hvs"" to ""18000"" for product reason.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 10, 'created': '2014-11-17 01:57:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dfbbe319915f6768ef8757cc31c14e4cb542aaf5', 'message': 'Temporarily remove support for qos function\n\nThis patch temporarily removed support for qos function and\nhave improved the compatibility for different Huawei storage series.\nWe also renamed the ""hvs"" to ""18000"" for product reason.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 11, 'created': '2014-11-18 01:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8a80b14d2a1ebddf2dc05b196ebe8dfd3f4b7fd0', 'message': 'Explicitly imported _, _LE, _LI and _LW\n\nThis patch explicitly imported _ and replace str() to six.text_type().\nWe also renamed the ""hvs"" to ""18000"" for product reason.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 12, 'created': '2014-11-18 06:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5f72130666c29a25bf039eb262d52d84233fa2cb', 'message': 'Explicitly imported _ and replace str() to six.text_type()\n\nThis patch explicitly imported _ and replace str() to six.text_type().\nWe also renamed the ""hvs"" to ""18000"" for product reason.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 13, 'created': '2014-11-19 06:30:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b2f4ea427c90ef841fc5b53a52d2e7bb6dddd2ea', 'message': 'Changed the qos implementation\n\nThis patch contains following changes:\n1. Explicitly imported ""_"" and replace str() to six.text_type().\n2. Renamed the ""hvs"" to ""18000"" for product reason.\n3. Removed smart tier support because that our product does not\n   support smart tier any more.\n4. Changed qos implementation to fit Cinder qos.\n\nMost of the changes in this patch is related to the change\nof qos implementation.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 14, 'created': '2014-11-21 09:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8e921fbda3c883af3e48d58cc9dfdcff25a909aa', 'message': 'Changed the qos implementation\n\nThis patch contains following changes:\n1. Explicitly imported ""_"" and replace str() to six.text_type().\n2. Renamed the ""hvs"" to ""18000"" for product reason.\n3. Removed smart tier support because that our product does not\n   support smart tier any more.\n4. Changed qos implementation to fit Cinder qos.\n\nMost of the changes in this patch is related to the change\nof qos implementation.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 15, 'created': '2014-11-21 10:01:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b1121186072417b7fb8c2e03bd753e333cbf3760', 'message': 'Add volume driver for Huawei storage system\n\nThis driver is similar to the previous one, but contains\nthe following differences:\n1. Explicitly imported ""_"" and replace str() to six.text_type().\n2. Removed smart tier support because that our product does not\n   support smart tier any more. 18000 does not support smart\n   tier, so this has no problem with 18000 series.\n3. Updated qos support implementation.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 16, 'created': '2014-11-24 02:31:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4b5344334ed312374b3b8e5415ac513a0c5b4e97', 'message': 'Add volume driver for Huawei storage system\n\nThis driver is similar to the previous one, but contains\nthe following differences:\n1. Explicitly imported ""_"" and replace str() to six.text_type().\n2. Removed smart tier support because that our product does not\n   support smart tier any more. 18000 does not support smart\n   tier, so this has no problem with 18000 series.\n3. Updated qos support implementation.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 17, 'created': '2014-11-24 07:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8183ed8b92e401dbdfa9696713bedd42d86148d6', 'message': 'Update volume driver for Huawei storage system\n\nThis driver is similar to the previous one, but contains\nthe following differences:\n1. Explicitly imported ""_"" and replace str() to six.text_type().\n2. Removed smart tier support because that our product does not\n   support smart tier any more. 18000 does not support smart\n   tier, so this has no problem with 18000 series.\n3. Updated qos support implementation.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 18, 'created': '2014-11-25 04:29:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/46ec1d838ec28f89ef12c17ed24f32531a893b93', 'message': 'Update volume driver for Huawei storage system\n\nThis driver is similar to the previous one, but contains\nthe following differences:\n1. Explicitly imported ""_"" and replace str() to six.text_type().\n2. Removed smart tier support because that our product does not\n   support smart tier any more. 18000 does not support smart\n   tier, so this has no problem with 18000 series.\n3. Updated qos support implementation.\n4. Add synchronization because that our tests show that when we\n   create volumes or snapshots in batch in a shell script with cli\n   command, our array may occur error.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 19, 'created': '2014-11-26 11:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b107bb60f63f0dc8edebc2e8b8e22efb2f5d0279', 'message': 'Update volume driver for Huawei storage system\n\nThis driver is similar to the previous one, but contains\nthe following differences:\n1. Explicitly imported ""_"" and replace str() to six.text_type().\n2. Removed smart tier support because that our product does not\n   support smart tier any more. 18000 does not support smart\n   tier, so this has no problem with 18000 series.\n3. Updated qos support implementation.\n4. Add synchronization because that our tests show that when we\n   create volumes or snapshots in batch in a shell script with cli\n   command, our array may occur error.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 20, 'created': '2014-11-27 08:29:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cc6b42a33f42a356c5ca76399d6efbcf1702eca7', 'message': 'Update volume driver for Huawei storage system\n\nThis driver is similar to the previous one, but contains\nthe following differences:\n1. Move the code from __init__.py into huawei_volume_driver.py\n   and leave __init__.py empty.\n2. Remove smart tier support because that our product does not\n   support smart tier any more. 18000 does not support smart\n   tier, so this has no problem with 18000 series.\n3. Update qos support implementation.\n4. Add synchronization because that our tests show that when we\n   create volumes or snapshots in batch in a shell script with cli\n   command, our array may occur error.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 21, 'created': '2014-11-28 02:53:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/317173696f3f3524fa9f9d87607dc8ff8bb451d7', 'message': 'Update volume driver for Huawei storage system\n\nThis driver is similar to the previous one, but contains\nthe following differences:\n1. Remove smart tier support because that our product does not\n   support smart tier any more. 18000 does not support smart\n   tier, so this has no problem with 18000 series.\n2. Update qos support implementation.\n3. Add synchronization because that our tests show that when we\n   create volumes or snapshots in batch in a shell script with cli\n   command, our array may occur error.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 22, 'created': '2014-12-01 12:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/855277441d73845755ddf9255d05b430a0cb898f', 'message': 'Update volume driver for Huawei storage system\n\nThis driver is similar to the previous one, but contains\nthe following differences:\n1. Remove smart tier support because that our product does not\n   support smart tier any more. 18000 does not support smart\n   tier, so this has no problem with 18000 series.\n2. Update qos support implementation.\n3. Add synchronization because that our tests show that when we\n   create volumes or snapshots in batch in a shell script with cli\n   command, our array may occur error.\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 23, 'created': '2014-12-11 02:43:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cc80d4b67cb80af0a5b7cf58739f88ad8b8f60ea', 'message': 'Update volume driver for Huawei storage system\n\nThis driver is similar to the previous one, but contains\nthe following differences:\n1. Remove smart tier support because that our product does not\n   support smart tier any more. 18000 does not support smart\n   tier, so this has no problem with 18000 series.\n2. Update qos support implementation.\n3. Add synchronization because that our tests show that when we\n   create volumes or snapshots in batch in a shell script with cli\n   command, our array may occur error.\nCertification test result for Huawei storage drivers:\nhttps://bugs.launchpad.net/cinder/+bug/1399038\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 24, 'created': '2014-12-15 09:32:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3d5025a2188690b1aa85c07ae8a8eb11cd4a54c5', 'message': 'Update volume driver for Huawei storage system\n\nThis driver is similar to the previous one, but contains\nthe following differences:\n1. Remove smart tier support because that our product does not\n   support smart tier any more. 18000 does not support smart\n   tier, so this has no problem with 18000 series.\n2. Update qos support implementation.\n3. Add synchronization because that our tests show that when we\n   create volumes or snapshots in batch in a shell script with cli\n   command, our array may occur error.\nCertification test result for Huawei storage drivers:\nhttps://bugs.launchpad.net/cinder/+bug/1399038\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 25, 'created': '2014-12-15 12:15:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/236cc8b369d04e1422e3e967f0f18a90dec43c0b', 'message': 'Update volume driver for Huawei storage system\n\nThis driver is similar to the previous one, but contains\nthe following differences:\n1. Remove smart tier support because that our product does not\n   support smart tier any more. 18000 does not support smart\n   tier, so this has no problem with 18000 series.\n2. Update qos support implementation.\n3. Add synchronization because that our tests show that when we\n   create volumes or snapshots in batch in a shell script with cli\n   command, our array may occur error.\nCertification test result for Huawei storage drivers:\nhttps://bugs.launchpad.net/cinder/+bug/1399038\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 26, 'created': '2014-12-16 04:22:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/701d4d9c3fc76adeafe2e7dfc05aa420b0ef3399', 'message': 'Update volume driver for Huawei storage system\n\nThis driver is similar to the previous one, but contains\nthe following differences:\n1. Remove smart tier support because that our product does not\n   support smart tier any more. 18000 does not support smart\n   tier, so this has no problem with 18000 series.\n2. Update qos support implementation.\n3. Add synchronization because that our tests show that when we\n   create volumes or snapshots in batch in a shell script with cli\n   command, our array may occur error.\nCertification test result for Huawei storage drivers:\nhttps://bugs.launchpad.net/cinder/+bug/1399038\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 27, 'created': '2014-12-16 07:48:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/49e739c2fffc8137eb9333560b713d7ade3a0251', 'message': 'Update volume driver for Huawei storage system\n\nThis driver is similar to the previous one, but contains\nthe following differences:\n1. Remove smart tier support because that our product does not\n   support smart tier any more. 18000 does not support smart\n   tier, so this has no problem with 18000 series.\n2. Update qos support implementation.\n3. Add synchronization because that our tests show that when we\n   create volumes or snapshots in batch in a shell script with cli\n   command, our array may occur error.\nCertification test result for Huawei storage drivers:\nhttps://bugs.launchpad.net/cinder/+bug/1399038\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}, {'number': 28, 'created': '2014-12-17 12:07:52.000000000', 'files': ['cinder/tests/test_huawei_18000.py', 'cinder/volume/manager.py', 'cinder/volume/drivers/huawei/huawei_hvs.py', 'cinder/tests/test_huawei_hvs.py', 'cinder/volume/drivers/huawei/rest_common.py', 'cinder/tests/test_huawei_drivers_compatibility.py', 'cinder/volume/drivers/huawei/huawei_18000.py', 'cinder/volume/drivers/huawei/__init__.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/837ba79d876a685b5870c7b3c0ffb2b37407ac80', 'message': 'Update volume driver for Huawei storage system\n\nThis driver is similar to the previous one, but contains\nthe following differences:\n1. Remove smart tier support because that our product does not\n   support smart tier any more. 18000 does not support smart\n   tier, so this has no problem with 18000 series.\n2. Update qos support implementation.\n3. Add synchronization because that our tests show that when we\n   create volumes or snapshots in batch in a shell script with cli\n   command, our array may occur error.\nCertification test result for Huawei storage drivers:\nhttps://bugs.launchpad.net/cinder/+bug/1399038\n\nImplements: blueprint huawei-storage-drivers\nChange-Id: I69c32ef3225c23881be522eac451b8855805e35d\n'}]",179,133193,837ba79d876a685b5870c7b3c0ffb2b37407ac80,239,32,28,13203,,,0,"Update volume driver for Huawei storage system

This driver is similar to the previous one, but contains
the following differences:
1. Remove smart tier support because that our product does not
   support smart tier any more. 18000 does not support smart
   tier, so this has no problem with 18000 series.
2. Update qos support implementation.
3. Add synchronization because that our tests show that when we
   create volumes or snapshots in batch in a shell script with cli
   command, our array may occur error.
Certification test result for Huawei storage drivers:
https://bugs.launchpad.net/cinder/+bug/1399038

Implements: blueprint huawei-storage-drivers
Change-Id: I69c32ef3225c23881be522eac451b8855805e35d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/93/133193/10 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_huawei_18000.py', 'cinder/volume/drivers/huawei/huawei_hvs.py', 'cinder/tests/test_huawei_hvs.py']",3,cf1d4bac48c9921341c54b477c916e0367b2d4bc,bp/huawei-storage-drivers,," # Copyright (c) 2013 Huawei Technologies Co., Ltd. # Copyright (c) 2013 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Unit Tests for Huawei HVS volume drivers. """""" import json import os import shutil import tempfile import time from xml.dom.minidom import Document import mox from cinder import exception from cinder import test from cinder.volume import configuration as conf from cinder.volume.drivers.huawei import huawei_hvs from cinder.volume.drivers.huawei import rest_common test_volume = {'name': 'volume-21ec7341-9256-497b-97d9-ef48edcf0635', 'size': 2, 'volume_name': 'vol1', 'id': '21ec7341-9256-497b-97d9-ef48edcf0635', 'volume_id': '21ec7341-9256-497b-97d9-ef48edcf0635', 'provider_auth': None, 'project_id': 'project', 'display_name': 'vol1', 'display_description': 'test volume', 'volume_type_id': None} test_snap = {'name': 'volume-21ec7341-9256-497b-97d9-ef48edcf0635', 'size': 1, 'volume_name': 'vol1', 'id': '21ec7341-9256-497b-97d9-ef48edcf0635', 'volume_id': '21ec7341-9256-497b-97d9-ef48edcf0635', 'provider_auth': None, 'project_id': 'project', 'display_name': 'vol1', 'display_description': 'test volume', 'volume_type_id': None} FakeConnector = {'initiator': 'iqn.1993-08.debian:01:ec2bff7ac3a3', 'wwpns': ['10000090fa0d6754'], 'wwnns': ['10000090fa0d6755'], 'host': 'fakehost', 'ip': '10.10.0.1'} volume_size = 3 def Fake_sleep(time): pass class FakeHVSCommon(rest_common.HVSCommon): def __init__(self, configuration): rest_common.HVSCommon.__init__(self, configuration) self.test_normal = True self.other_flag = True self.deviceid = None self.lun_id = None self.snapshot_id = None self.luncopy_id = None self.termin_flag = False def _parse_volume_type(self, volume): self._get_lun_conf_params() poolinfo = self._find_pool_info() volume_size = self._get_volume_size(poolinfo, volume) params = {'LUNType': 0, 'WriteType': '1', 'PrefetchType': '3', 'qos_level': 'Qos-high', 'StripUnitSize': '64', 'PrefetchValue': '0', 'PrefetchTimes': '0', 'qos': 'OpenStack_Qos_High', 'MirrorSwitch': '1', 'tier': 'Tier_high'} params['volume_size'] = volume_size params['pool_id'] = poolinfo['ID'] return params def _change_file_mode(self, filepath): # NOTE(flaper87): Changing file permissions is # not needed since we're using a tempfile created # within this test. pass def call(self, url=False, data=None, method=None): # noqa url = url.replace('http://100.115.10.69:8082/deviceManager/rest', '') url = url.replace('/210235G7J20000000000/', '') data = None if self.test_normal: if url == ""/xx/sessions"": data = """"""{""error"":{""code"":0}, ""data"":{""username"":""admin"", ""deviceid"":""210235G7J20000000000"" }}"""""" if url == ""sessions"": data = """"""{""error"":{""code"":0}, ""data"":{""ID"":11}}"""""" if url == ""storagepool"": data = """"""{""error"":{""code"":0}, ""data"":[{""ID"":""0"", ""NAME"":""OpenStack_Pool"", ""USERFREECAPACITY"":""985661440"", ""USERTOTALCAPACITY"":""985661440"" }]}"""""" if url == ""lun"": if method is None: data = """"""{""error"":{""code"":0}, ""data"":{""ID"":""1"", ""NAME"":""5mFHcBv4RkCcD+JyrWc0SA""}}"""""" self.lun_id = ""0"" if method == 'GET': data = """"""{""error"":{""code"":0}, ""data"":[{""ID"":""1"", ""NAME"":""IexzQZJWSXuX2e9I7c8GNQ""}]}"""""" if url == ""lungroup"": if method is None: data = """"""{""error"":{""code"":0}, ""data"":{""NAME"":""5mFHcBv4RkCcD+JyrWc0SA"", ""DESCRIPTION"":""5mFHcBv4RkCcD"", ""ID"":""11"", ""TYPE"":256}}"""""" if method == ""GET"": data = """"""{""error"":{""code"":0}, ""data"":[{""NAME"":""IexzQZJWSXuX2e9I7c8GNQ"", ""DESCRIPTION"":""5mFHcBv4RkCcD"", ""ID"":""11"", ""TYPE"":256}]}"""""" if method == ""DELETE"": data = """"""{""error"":{""code"":0}, ""data"":[{""NAME"":""IexzQZJWSXuX2e9I7c8GNQ"", ""DESCRIPTION"":""5mFHcBv4RkCcD+JyrWc0SA"", ""ID"":""11"", ""TYPE"":256}]}"""""" if url == ""lungroup/associate"": data = """"""{""error"":{""code"":0}, ""data"":{""NAME"":""5mFHcBv4RkCcD+JyrWc0SA"", ""DESCRIPTION"":""5mFHcBv4RkCcD+JyrWc0SA"", ""ID"":""11"", ""TYPE"":256}}"""""" if url == ""snapshot"": if method is None: data = """"""{""error"":{""code"":0}, ""data"":{""ID"":11}}"""""" self.snapshot_id = ""3"" if method == ""GET"": data = """"""{""error"":{""code"":0}, ""data"":[{""ID"":11,""NAME"":""SDFAJSDFLKJ""}, {""ID"":12,""NAME"":""SDFAJSDFLKJ""}]}"""""" if url == ""snapshot/activate"": data = """"""{""error"":{""code"":0}}"""""" if url == (""lungroup/associate?ID=11"" ""&ASSOCIATEOBJTYPE=11&ASSOCIATEOBJID=1""): data = """"""{""error"":{""code"":0}}"""""" if url == ""LUNGroup/11"": data = """"""{""error"":{""code"":0}}"""""" if url == 'lun/1': data = """"""{""error"":{""code"":0}}"""""" self.lun_id = None if url == 'snapshot': if method == ""GET"": data = """"""{""error"":{""code"":0}, ""data"":[{""PARENTTYPE"":11, ""NAME"":""IexzQZJWSXuX2e9I7c8GNQ"", ""WWN"":""60022a11000a2a3907ce96cb00000b"", ""ID"":""11"", ""CONSUMEDCAPACITY"":""0""}]}"""""" if url == ""snapshot/stop"": data = """"""{""error"":{""code"":0}}"""""" if url == ""snapshot/11"": data = """"""{""error"":{""code"":0}}"""""" self.snapshot_id = None if url == ""luncopy"": data = """"""{""error"":{""code"":0}, ""data"":{""COPYSTOPTIME"":""-1"", ""HEALTHSTATUS"":""1"", ""NAME"":""w1PSNvu6RumcZMmSh4/l+Q=="", ""RUNNINGSTATUS"":""36"", ""DESCRIPTION"":""w1PSNvu6RumcZMmSh4/l+Q=="", ""ID"":""0"",""LUNCOPYTYPE"":""1"", ""COPYPROGRESS"":""0"",""COPYSPEED"":""2"", ""TYPE"":219,""COPYSTARTTIME"":""-1""}}"""""" self.luncopy_id = ""7"" if url == ""LUNCOPY/start"": data = """"""{""error"":{""code"":0}}"""""" if url == ""LUNCOPY?range=[0-100000]"": data = """"""{""error"":{""code"":0}, ""data"":[{""COPYSTOPTIME"":""1372209335"", ""HEALTHSTATUS"":""1"", ""NAME"":""w1PSNvu6RumcZMmSh4/l+Q=="", ""RUNNINGSTATUS"":""40"", ""DESCRIPTION"":""w1PSNvu6RumcZMmSh4/l+Q=="", ""ID"":""0"",""LUNCOPYTYPE"":""1"", ""COPYPROGRESS"":""100"", ""COPYSPEED"":""2"", ""TYPE"":219, ""COPYSTARTTIME"":""1372209329""}]}"""""" if url == ""LUNCOPY/0"": data = '{""error"":{""code"":0}}' if url == ""eth_port"": data = """"""{""error"":{""code"":0}, ""data"":[{""PARENTTYPE"":209, ""MACADDRESS"":""00:22:a1:0a:79:57"", ""ETHNEGOTIATE"":""-1"",""ERRORPACKETS"":""0"", ""IPV4ADDR"":""100.115.10.68"", ""IPV6GATEWAY"":"""",""IPV6MASK"":""0"", ""OVERFLOWEDPACKETS"":""0"",""ISCSINAME"":""P0"", ""HEALTHSTATUS"":""1"",""ETHDUPLEX"":""2"", ""ID"":""16909568"",""LOSTPACKETS"":""0"", ""TYPE"":213,""NAME"":""P0"",""INIORTGT"":""4"", ""RUNNINGSTATUS"":""10"",""IPV4GATEWAY"":"""", ""BONDNAME"":"""",""STARTTIME"":""1371684218"", ""SPEED"":""1000"",""ISCSITCPPORT"":""0"", ""IPV4MASK"":""255.255.0.0"",""IPV6ADDR"":"""", ""LOGICTYPE"":""0"",""LOCATION"":""ENG0.B5.P0"", ""MTU"":""1500"",""PARENTID"":""1.5""}]}"""""" if url == ""iscsidevicename"": data = """"""{""error"":{""code"":0}, ""data"":[{""CMO_ISCSI_DEVICE_NAME"": ""iqn.2006-08.com.huawei:oceanstor:21000022a10a2a39:iscsinametest""}]}"""""" if url == ""hostgroup"": if method is None: data = """"""{""error"":{""code"":0}, ""data"":{""NAME"":""ubuntuc"", ""DESCRIPTION"":"""", ""ID"":""0"", ""TYPE"":14}}"""""" if method == ""GET"": data = """"""{""error"":{""code"":0}, ""data"":[{""NAME"":""ubuntuc"", ""DESCRIPTION"":"""", ""ID"":""0"", ""TYPE"":14}]}"""""" if url == ""host"": if method is None: data = """"""{""error"":{""code"":0}, ""data"":{""PARENTTYPE"":245, ""NAME"":""Default Host"", ""DESCRIPTION"":"""", ""RUNNINGSTATUS"":""1"", ""IP"":"""",""PARENTNAME"":""0"", ""OPERATIONSYSTEM"":""1"",""LOCATION"":"""", ""HEALTHSTATUS"":""1"",""MODEL"":"""", ""ID"":""0"",""PARENTID"":""0"", ""NETWORKNAME"":"""",""TYPE"":21}} """""" if method == ""GET"": data = """"""{""error"":{""code"":0}, ""data"":[{""PARENTTYPE"":245, ""NAME"":""ubuntuc"", ""DESCRIPTION"":"""", ""RUNNINGSTATUS"":""1"", ""IP"":"""",""PARENTNAME"":"""", ""OPERATIONSYSTEM"":""0"", ""LOCATION"":"""", ""HEALTHSTATUS"":""1"", ""MODEL"":"""", ""ID"":""1"",""PARENTID"":"""", ""NETWORKNAME"":"""",""TYPE"":21}, {""PARENTTYPE"":245, ""NAME"":""ubuntu"", ""DESCRIPTION"":"""", ""RUNNINGSTATUS"":""1"", ""IP"":"""",""PARENTNAME"":"""", ""OPERATIONSYSTEM"":""0"", ""LOCATION"":"""", ""HEALTHSTATUS"":""1"", ""MODEL"":"""",""ID"":""2"", ""PARENTID"":"""", ""NETWORKNAME"":"""",""TYPE"":21}]} """""" if url == ""host/associate"": if method is None: data = """"""{""error"":{""code"":0}}"""""" if method == ""GET"": data = """"""{""error"":{""code"":0}}"""""" if url == ""iscsi_initiator/iqn.1993-08.debian:01:ec2bff7ac3a3"": data = """"""{""error"":{""code"":0}, ""data"":{""ID"":""iqn.1993-08.win:01:ec2bff7ac3a3"", ""NAME"":""iqn.1993-08.win:01:ec2bff7ac3a3"", ""ISFREE"":""True""}}"""""" if url == ""iscsi_initiator/"": data = """"""{""error"":{""code"":0}}"""""" if url == ""iscsi_initiator"": data = """"""{""error"":{""code"":0}}"""""" if url == ""mappingview"": self.termin_flag = True if method is None: data = """"""{""error"":{""code"":0}, ""data"":{""WORKMODE"":""255"", ""HEALTHSTATUS"":""1"", ""NAME"":""mOWtSXnaQKi3hpB3tdFRIQ"", ""RUNNINGSTATUS"":""27"",""DESCRIPTION"":"""", ""ENABLEINBANDCOMMAND"":""true"", ""ID"":""1"",""INBANDLUNWWN"":"""", ""TYPE"":245}}"""""" if method == ""GET"": if self.other_flag: data = """"""{""error"":{""code"":0}, ""data"":[{""WORKMODE"":""255"", ""HEALTHSTATUS"":""1"", ""NAME"":""mOWtSXnaQKi3hpB3tdFRIQ"", ""RUNNINGSTATUS"":""27"", ""DESCRIPTION"":"""", ""ENABLEINBANDCOMMAND"": ""true"",""ID"":""1"", ""INBANDLUNWWN"":"""", ""TYPE"":245}, {""WORKMODE"":""255"", ""HEALTHSTATUS"":""1"", ""NAME"":""YheUoRwbSX2BxN767nvLSw"", ""RUNNINGSTATUS"":""27"", ""DESCRIPTION"":"""", ""ENABLEINBANDCOMMAND"":""true"", ""ID"":""2"", ""INBANDLUNWWN"":"""", ""TYPE"":245}]}"""""" else: data = """"""{""error"":{""code"":0}, ""data"":[{""WORKMODE"":""255"", ""HEALTHSTATUS"":""1"", ""NAME"":""IexzQZJWSXuX2e9I7c8GNQ"", ""RUNNINGSTATUS"":""27"", ""DESCRIPTION"":"""", ""ENABLEINBANDCOMMAND"":""true"", ""ID"":""1"", ""INBANDLUNWWN"":"""", ""TYPE"":245}, {""WORKMODE"":""255"", ""HEALTHSTATUS"":""1"", ""NAME"":""YheUoRwbSX2BxN767nvLSw"", ""RUNNINGSTATUS"":""27"", ""DESCRIPTION"":"""", ""ENABLEINBANDCOMMAND"":""true"", ""ID"":""2"", ""INBANDLUNWWN"":"""", ""TYPE"":245}]}"""""" if url == ""MAPPINGVIEW/CREATE_ASSOCIATE"": data = """"""{""error"":{""code"":0}}"""""" if url == (""lun/associate?TYPE=11&"" ""ASSOCIATEOBJTYPE=21&ASSOCIATEOBJID=0""): data = """"""{""error"":{""code"":0}}"""""" if url == ""fc_initiator?ISFREE=true&range=[0-1000]"": data = """"""{""error"":{""code"":0}, ""data"":[{""HEALTHSTATUS"":""1"", ""NAME"":"""", ""MULTIPATHTYPE"":""1"", ""ISFREE"":""true"", ""RUNNINGSTATUS"":""27"", ""ID"":""10000090fa0d6754"", ""OPERATIONSYSTEM"":""255"", ""TYPE"":223}, {""HEALTHSTATUS"":""1"", ""NAME"":"""", ""MULTIPATHTYPE"":""1"", ""ISFREE"":""true"", ""RUNNINGSTATUS"":""27"", ""ID"":""10000090fa0d6755"", ""OPERATIONSYSTEM"":""255"", ""TYPE"":223}]}"""""" if url == ""host_link?INITIATOR_TYPE=223&INITIATOR_PORT_WWN=""\ ""10000090fa0d6754"": data = """"""{""error"":{""code"":0}, ""data"":[{""PARENTTYPE"":21, ""TARGET_ID"":""0000000000000000"", ""INITIATOR_NODE_WWN"":""20000090fa0d6754"", ""INITIATOR_TYPE"":""223"", ""RUNNINGSTATUS"":""27"", ""PARENTNAME"":""ubuntuc"", ""INITIATOR_ID"":""10000090fa0d6754"", ""TARGET_PORT_WWN"":""24000022a10a2a39"", ""HEALTHSTATUS"":""1"", ""INITIATOR_PORT_WWN"":""10000090fa0d6754"", ""ID"":""010000090fa0d675-0000000000110400"", ""TARGET_NODE_WWN"":""21000022a10a2a39"", ""PARENTID"":""1"",""CTRL_ID"":""0"", ""TYPE"":255,""TARGET_TYPE"":""212""}]}"""""" if url == (""mappingview/associate?TYPE=245&"" ""ASSOCIATEOBJTYPE=14&ASSOCIATEOBJID=0""): data = """"""{""error"":{""code"":0}, ""data"":[{""ID"":11,""NAME"":""test""}]}"""""" if url == (""mappingview/associate?TYPE=245&"" ""ASSOCIATEOBJTYPE=256&ASSOCIATEOBJID=11""): data = """"""{""error"":{""code"":0}, ""data"":[{""ID"":11,""NAME"":""test""}]}"""""" if url == ""fc_initiator/10000090fa0d6754"": data = """"""{""error"":{""code"":0}}"""""" if url == ""mappingview/REMOVE_ASSOCIATE"": data = """"""{""error"":{""code"":0}}"""""" self.termin_flag = True if url == ""mappingview/1"": data = """"""{""error"":{""code"":0}}"""""" if url == ""ioclass"": data = """"""{""error"":{""code"":0}, ""data"":[{""NAME"":""OpenStack_Qos_High"", ""ID"":""0"", ""LUNLIST"":""[]"", ""TYPE"":230}]}"""""" if url == ""ioclass/0"": data = """"""{""error"":{""code"":0}}"""""" if url == ""lun/expand"": data = """"""{""error"":{""code"":0}}"""""" self.lun_id = '0' else: data = """"""{""error"":{""code"":31755596}}"""""" res_json = json.loads(data) return res_json class FakeHVSiSCSIStorage(huawei_hvs.HuaweiHVSISCSIDriver): def __init__(self, configuration): super(FakeHVSiSCSIStorage, self).__init__(configuration) self.configuration = configuration def do_setup(self, context): self.common = FakeHVSCommon(configuration=self.configuration) class FakeHVSFCStorage(huawei_hvs.HuaweiHVSFCDriver): def __init__(self, configuration): super(FakeHVSFCStorage, self).__init__(configuration) self.configuration = configuration def do_setup(self, context): self.common = FakeHVSCommon(configuration=self.configuration) class HVSRESTiSCSIDriverTestCase(test.TestCase): def setUp(self): super(HVSRESTiSCSIDriverTestCase, self).setUp() self.tmp_dir = tempfile.mkdtemp() self.addCleanup(shutil.rmtree, self.tmp_dir) self.fake_conf_file = self.tmp_dir + '/cinder_huawei_conf.xml' self.addCleanup(os.remove, self.fake_conf_file) self.create_fake_conf_file() self.configuration = mox.MockObject(conf.Configuration) self.configuration.cinder_huawei_conf_file = self.fake_conf_file self.configuration.append_config_values(mox.IgnoreArg()) self.stubs.Set(time, 'sleep', Fake_sleep) #self.stubs.Set(greenthread, 'sleep', Fake_sleep) self.driver = FakeHVSiSCSIStorage(configuration=self.configuration) self.driver.do_setup({}) self.driver.common.test_normal = True def test_log_in_success(self): deviceid = self.driver.common.login() self.assertIsNotNone(deviceid) def test_log_out_success(self): self.driver.common.login() self.driver.common.login_out() def test_create_volume_success(self): self.driver.common.login() self.driver.create_volume(test_volume) self.assertEqual(self.driver.common.lun_id, ""0"") def test_extend_volume_success(self): self.driver.common.login() self.driver.extend_volume(test_volume, volume_size) self.assertEqual(self.driver.common.lun_id, ""0"") def test_create_snapshot_success(self): self.driver.common.login() self.driver.create_snapshot(test_volume) self.assertEqual(self.driver.common.snapshot_id, ""3"") def test_delete_volume_success(self): self.driver.common.login() self.driver.delete_volume(test_volume) self.assertIsNone(self.driver.common.lun_id) def test_delete_snapshot_success(self): self.driver.common.login() self.driver.delete_snapshot(test_snap) self.assertIsNone(self.driver.common.snapshot_id) def test_colone_volume_success(self): self.driver.common.login() self.driver.create_cloned_volume(test_volume, test_volume) self.assertEqual(self.driver.common.luncopy_id, ""7"") def test_create_volume_from_snapshot_success(self): self.driver.common.login() self.driver.create_volume_from_snapshot(test_volume, test_volume) self.assertEqual(self.driver.common.luncopy_id, ""7"") def test_initialize_connection_success(self): self.driver.common.login() conn = self.driver.initialize_connection(test_volume, FakeConnector) self.assertEqual(conn['data']['target_lun'], 1) def test_terminate_connection_success(self): self.driver.common.login() self.driver.terminate_connection(test_volume, FakeConnector) self.assertEqual(self.driver.common.termin_flag, True) def test_initialize_connection_no_view_success(self): self.driver.common.login() self.driver.common.other_flag = False conn = self.driver.initialize_connection(test_volume, FakeConnector) self.assertEqual(conn['data']['target_lun'], 1) def test_terminate_connectio_no_view_success(self): self.driver.common.login() self.driver.common.other_flag = False self.driver.terminate_connection(test_volume, FakeConnector) self.assertEqual(self.driver.common.termin_flag, True) def test_get_volume_stats(self): self.driver.common.login() status = self.driver.get_volume_stats() self.assertIsNotNone(status['free_capacity_gb']) def test_create_snapshot_fail(self): self.driver.common.login() self.driver.common.test_normal = False self.assertRaises(exception.CinderException, self.driver.create_snapshot, test_volume) def test_create_volume_fail(self): self.driver.common.login() self.driver.common.test_normal = False self.assertRaises(exception.CinderException, self.driver.create_volume, test_volume) def test_delete_volume_fail(self): self.driver.common.login() self.driver.common.test_normal = False self.assertRaises(exception.CinderException, self.driver.delete_volume, test_volume) def test_delete_snapshot_fail(self): self.driver.common.login() self.driver.common.test_normal = False self.assertRaises(exception.CinderException, self.driver.delete_snapshot, test_volume) def test_initialize_connection_fail(self): self.driver.common.login() self.driver.common.test_normal = False self.assertRaises(exception.CinderException, self.driver.initialize_connection, test_volume, FakeConnector) def create_fake_conf_file(self): doc = Document() config = doc.createElement('config') doc.appendChild(config) storage = doc.createElement('Storage') config.appendChild(storage) product = doc.createElement('Product') product_text = doc.createTextNode('HVS') product.appendChild(product_text) storage.appendChild(product) protocol = doc.createElement('Protocol') protocol_text = doc.createTextNode('iSCSI') protocol.appendChild(protocol_text) storage.appendChild(protocol) username = doc.createElement('UserName') username_text = doc.createTextNode('admin') username.appendChild(username_text) storage.appendChild(username) userpassword = doc.createElement('UserPassword') userpassword_text = doc.createTextNode('Admin@storage') userpassword.appendChild(userpassword_text) storage.appendChild(userpassword) url = doc.createElement('HVSURL') url_text = doc.createTextNode('http://100.115.10.69:8082/' 'deviceManager/rest/') url.appendChild(url_text) storage.appendChild(url) lun = doc.createElement('LUN') config.appendChild(lun) storagepool = doc.createElement('StoragePool') pool_text = doc.createTextNode('OpenStack_Pool') storagepool.appendChild(pool_text) lun.appendChild(storagepool) luntype = doc.createElement('LUNType') luntype_text = doc.createTextNode('Thick') luntype.appendChild(luntype_text) lun.appendChild(luntype) writetype = doc.createElement('WriteType') writetype_text = doc.createTextNode('1') writetype.appendChild(writetype_text) lun.appendChild(writetype) prefetchType = doc.createElement('Prefetch') prefetchType.setAttribute('Type', '2') prefetchType.setAttribute('Value', '20') lun.appendChild(prefetchType) iscsi = doc.createElement('iSCSI') config.appendChild(iscsi) defaulttargetip = doc.createElement('DefaultTargetIP') defaulttargetip_text = doc.createTextNode('100.115.10.68') defaulttargetip.appendChild(defaulttargetip_text) iscsi.appendChild(defaulttargetip) initiator = doc.createElement('Initiator') initiator.setAttribute('Name', 'iqn.1993-08.debian:01:ec2bff7ac3a3') initiator.setAttribute('TargetIP', '100.115.10.68') iscsi.appendChild(initiator) newefile = open(self.fake_conf_file, 'w') newefile.write(doc.toprettyxml(indent='')) newefile.close() class HVSRESTFCDriverTestCase(test.TestCase): def setUp(self): super(HVSRESTFCDriverTestCase, self).setUp() self.tmp_dir = tempfile.mkdtemp() self.addCleanup(shutil.rmtree, self.tmp_dir) self.fake_conf_file = self.tmp_dir + '/cinder_huawei_conf.xml' self.addCleanup(os.remove, self.fake_conf_file) self.create_fake_conf_file() self.configuration = mox.MockObject(conf.Configuration) self.configuration.cinder_huawei_conf_file = self.fake_conf_file self.configuration.append_config_values(mox.IgnoreArg()) self.stubs.Set(time, 'sleep', Fake_sleep) self.driver = FakeHVSFCStorage(configuration=self.configuration) self.driver.do_setup({}) self.driver.common.test_normal = True def test_log_in_Success(self): deviceid = self.driver.common.login() self.assertIsNotNone(deviceid) def test_create_volume_success(self): self.driver.common.login() self.driver.create_volume(test_volume) self.assertEqual(self.driver.common.lun_id, ""0"") def test_extend_volume_success(self): self.driver.common.login() self.driver.extend_volume(test_volume, volume_size) self.assertEqual(self.driver.common.lun_id, ""0"") def test_create_snapshot_success(self): self.driver.common.login() self.driver.create_snapshot(test_volume) self.assertEqual(self.driver.common.snapshot_id, ""3"") def test_delete_volume_success(self): self.driver.common.login() self.driver.delete_volume(test_volume) self.assertIsNone(self.driver.common.lun_id) def test_delete_snapshot_success(self): self.driver.common.login() self.driver.delete_snapshot(test_snap) self.assertIsNone(self.driver.common.snapshot_id) def test_colone_volume_success(self): self.driver.common.login() self.driver.create_cloned_volume(test_volume, test_volume) self.assertEqual(self.driver.common.luncopy_id, ""7"") def test_create_volume_from_snapshot_success(self): self.driver.common.login() self.driver.create_volume_from_snapshot(test_volume, test_volume) self.assertEqual(self.driver.common.luncopy_id, ""7"") def test_initialize_connection_success(self): self.driver.common.login() conn = self.driver.initialize_connection(test_volume, FakeConnector) self.assertEqual(conn['data']['target_lun'], 1) def test_terminate_connection_success(self): self.driver.common.login() self.driver.terminate_connection(test_volume, FakeConnector) self.assertEqual(self.driver.common.termin_flag, True) def test_initialize_connection_no_view_success(self): self.driver.common.login() self.driver.common.other_flag = False conn = self.driver.initialize_connection(test_volume, FakeConnector) self.assertEqual(conn['data']['target_lun'], 1) def test_terminate_connection_no_viewn_success(self): self.driver.common.login() self.driver.common.other_flag = False self.driver.terminate_connection(test_volume, FakeConnector) self.assertEqual(self.driver.common.termin_flag, True) def test_get_volume_stats(self): self.driver.common.login() status = self.driver.get_volume_stats() self.assertIsNotNone(status['free_capacity_gb']) def test_create_snapshot_fail(self): self.driver.common.login() self.driver.common.test_normal = False self.assertRaises(exception.CinderException, self.driver.create_snapshot, test_volume) def test_create_volume_fail(self): self.driver.common.login() self.driver.common.test_normal = False self.assertRaises(exception.CinderException, self.driver.create_volume, test_volume) def test_delete_volume_fail(self): self.driver.common.login() self.driver.common.test_normal = False self.assertRaises(exception.CinderException, self.driver.delete_volume, test_volume) def test_delete_snapshot_fail(self): self.driver.common.login() self.driver.common.test_normal = False self.assertRaises(exception.CinderException, self.driver.delete_snapshot, test_volume) def create_fake_conf_file(self): doc = Document() config = doc.createElement('config') doc.appendChild(config) storage = doc.createElement('Storage') config.appendChild(storage) product = doc.createElement('Product') product_text = doc.createTextNode('HVS') product.appendChild(product_text) storage.appendChild(product) protocol = doc.createElement('Protocol') protocol_text = doc.createTextNode('FC') protocol.appendChild(protocol_text) storage.appendChild(protocol) username = doc.createElement('UserName') username_text = doc.createTextNode('admin') username.appendChild(username_text) storage.appendChild(username) userpassword = doc.createElement('UserPassword') userpassword_text = doc.createTextNode('Admin@storage') userpassword.appendChild(userpassword_text) storage.appendChild(userpassword) url = doc.createElement('HVSURL') url_text = doc.createTextNode('http://100.115.10.69:8082/' 'deviceManager/rest/') url.appendChild(url_text) storage.appendChild(url) lun = doc.createElement('LUN') config.appendChild(lun) storagepool = doc.createElement('StoragePool') pool_text = doc.createTextNode('OpenStack_Pool') storagepool.appendChild(pool_text) lun.appendChild(storagepool) luntype = doc.createElement('LUNType') luntype_text = doc.createTextNode('Thick') luntype.appendChild(luntype_text) lun.appendChild(luntype) writetype = doc.createElement('WriteType') writetype_text = doc.createTextNode('1') writetype.appendChild(writetype_text) lun.appendChild(writetype) prefetchType = doc.createElement('Prefetch') prefetchType.setAttribute('Type', '2') prefetchType.setAttribute('Value', '20') lun.appendChild(prefetchType) newfile = open(self.fake_conf_file, 'w') newfile.write(doc.toprettyxml(indent='')) newfile.close() ",761,1036
openstack%2Fneutron-lbaas~master~I9a38a3eee82314bdbed94089798d51794fa96e60,openstack/neutron-lbaas,master,I9a38a3eee82314bdbed94089798d51794fa96e60,Fixing HEAD file to have correct migration,MERGED,2014-12-19 22:47:43.000000000,2014-12-20 02:44:14.000000000,2014-12-20 02:44:13.000000000,"[{'_account_id': 3}, {'_account_id': 6951}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-19 22:47:43.000000000', 'files': ['neutron_lbaas/db/migration/alembic_migrations/versions/HEAD'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/d6588467ca78f6588f4db15d5ddd9a82ce09720f', 'message': 'Fixing HEAD file to have correct migration\n\nChange-Id: I9a38a3eee82314bdbed94089798d51794fa96e60\n'}]",0,143210,d6588467ca78f6588f4db15d5ddd9a82ce09720f,9,3,1,6951,,,0,"Fixing HEAD file to have correct migration

Change-Id: I9a38a3eee82314bdbed94089798d51794fa96e60
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/10/143210/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/db/migration/alembic_migrations/versions/HEAD'],1,d6588467ca78f6588f4db15d5ddd9a82ce09720f,,start_neutron_lbaas,465b2dcea7c,1,1
openstack%2Fneutron-vpnaas~master~I6a1a3a3e2e34ba92e5740b6fa0592c357b74141c,openstack/neutron-vpnaas,master,I6a1a3a3e2e34ba92e5740b6fa0592c357b74141c,Fix gitignore of egg files properly,MERGED,2014-12-19 21:52:07.000000000,2014-12-20 02:44:07.000000000,2014-12-20 02:44:07.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6659}]","[{'number': 1, 'created': '2014-12-19 21:52:07.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/ccb9a24f790fbadf1f71663ae29a2a4b30a48beb', 'message': 'Fix gitignore of egg files properly\n\nChange-Id: I6a1a3a3e2e34ba92e5740b6fa0592c357b74141c\n'}]",0,143202,ccb9a24f790fbadf1f71663ae29a2a4b30a48beb,8,3,1,10980,,,0,"Fix gitignore of egg files properly

Change-Id: I6a1a3a3e2e34ba92e5740b6fa0592c357b74141c
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/02/143202/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,ccb9a24f790fbadf1f71663ae29a2a4b30a48beb,fit_gitignore,neutron_vpnaas.egg-info/,neutron-vpnaas.egg-info/,1,1
openstack%2Fneutron-vpnaas~master~Ibbd973efd7e5133579d1efaf4eec30797b2b04d5,openstack/neutron-vpnaas,master,Ibbd973efd7e5133579d1efaf4eec30797b2b04d5,Do not list neutron in requirements.txt,MERGED,2014-12-19 21:43:43.000000000,2014-12-20 02:43:32.000000000,2014-12-20 02:43:32.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6659}]","[{'number': 1, 'created': '2014-12-19 21:43:43.000000000', 'files': ['requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/7c256214324d42197e32fce58c4bd9a36c9c1fcc', 'message': 'Do not list neutron in requirements.txt\n\nIt does not play nicely with openstack/requirements\n\nPartially-Implements: blueprint services-split\n\nChange-Id: Ibbd973efd7e5133579d1efaf4eec30797b2b04d5\n'}]",0,143201,7c256214324d42197e32fce58c4bd9a36c9c1fcc,7,3,1,10980,,,0,"Do not list neutron in requirements.txt

It does not play nicely with openstack/requirements

Partially-Implements: blueprint services-split

Change-Id: Ibbd973efd7e5133579d1efaf4eec30797b2b04d5
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/01/143201/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'tox.ini']",2,7c256214324d42197e32fce58c4bd9a36c9c1fcc,bp/services-split,install_command = pip install -U {opts} {packages} deps = -egit+https://git.openstack.org/openstack/neutron#egg=neutron -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt,install_command = pip install -r requirements.txt -U {opts} {packages} deps = -r{toxinidir}/test-requirements.txt,8,3
openstack%2Fneutron-lbaas~master~I9ac3c2bacdde7be45aa8c9f76e2a6d86508608d2,openstack/neutron-lbaas,master,I9ac3c2bacdde7be45aa8c9f76e2a6d86508608d2,Do not list neutron in requirements.txt,MERGED,2014-12-19 18:20:14.000000000,2014-12-20 02:43:04.000000000,2014-12-20 02:43:03.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 7448}, {'_account_id': 9656}, {'_account_id': 10273}, {'_account_id': 10980}, {'_account_id': 13051}]","[{'number': 1, 'created': '2014-12-19 18:20:14.000000000', 'files': ['requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/eb41ab78b87f1589fada5fca0c9189fa361d6289', 'message': 'Do not list neutron in requirements.txt\n\nIt does not play nicely with openstack/requirements\n\nChange-Id: I9ac3c2bacdde7be45aa8c9f76e2a6d86508608d2\nPartially-Implements: blueprint services-split\n'}]",5,143153,eb41ab78b87f1589fada5fca0c9189fa361d6289,14,7,1,10980,,,0,"Do not list neutron in requirements.txt

It does not play nicely with openstack/requirements

Change-Id: I9ac3c2bacdde7be45aa8c9f76e2a6d86508608d2
Partially-Implements: blueprint services-split
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/53/143153/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'tox.ini']",2,eb41ab78b87f1589fada5fca0c9189fa361d6289,bp/services-split,install_command = pip install -U {opts} {packages} deps = -egit+https://git.openstack.org/openstack/neutron#egg=neutron -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt,install_command = pip install -r requirements.txt -U {opts} {packages} deps = -r{toxinidir}/test-requirements.txt,8,3
openstack%2Fneutron-fwaas~master~I5abacda42074ed23a005939256fbb606cecb9cc6,openstack/neutron-fwaas,master,I5abacda42074ed23a005939256fbb606cecb9cc6,Re-enable UT for neutron-fwaas for services split,MERGED,2014-12-11 18:51:56.000000000,2014-12-20 02:42:39.000000000,2014-12-20 02:42:37.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 6659}, {'_account_id': 6995}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-11 18:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/5d7cdc2e66c45600317fb555819eb761bb18f313', 'message': 'Re-enable UT for neutron-fwaas for services split\n\n- Renable UT along with some minor fixes for import issues.\n\nChange-Id: I5abacda42074ed23a005939256fbb606cecb9cc6\nPartially-Implements: blueprint services-split\n'}, {'number': 2, 'created': '2014-12-19 18:31:40.000000000', 'files': ['neutron_fwaas/tests/unit/services/firewall/agents/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/l3reference/__init__.py', 'neutron_fwaas/tests.skip/unit/__init__.py', 'neutron_fwaas/tests/unit/db/firewall/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/varmour/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/test_fwaas_plugin.py', 'neutron_fwaas/tests/unit/services/firewall/agents/l3reference/test_firewall_l3_agent.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/linux/test_iptables_fwaas.py', 'neutron_fwaas/tests/unit/services/__init__.py', 'neutron_fwaas/tests/base.py', 'neutron_fwaas/tests/unit/services/firewall/agents/test_firewall_agent_api.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/varmour/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/__init__.py', 'neutron_fwaas/tests.skip/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/linux/__init__.py', 'neutron_fwaas/tests/unit/test_true.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/varmour/test_varmour_fwaas.py', 'neutron_fwaas/tests/unit/db/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/varmour/test_varmour_router.py', 'neutron_fwaas/tests/unit/db/firewall/test_db_firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/ea07947830ebde275b0b37030ac761d92b3a71d9', 'message': 'Re-enable UT for neutron-fwaas for services split\n\n- Renable UT along with some minor fixes for import issues.\n\nChange-Id: I5abacda42074ed23a005939256fbb606cecb9cc6\nPartially-Implements: blueprint services-split\n'}]",0,141127,ea07947830ebde275b0b37030ac761d92b3a71d9,17,6,2,6995,,,0,"Re-enable UT for neutron-fwaas for services split

- Renable UT along with some minor fixes for import issues.

Change-Id: I5abacda42074ed23a005939256fbb606cecb9cc6
Partially-Implements: blueprint services-split
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/27/141127/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas/tests/unit/services/firewall/agents/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/l3reference/__init__.py', 'neutron_fwaas/tests.skip/unit/__init__.py', 'neutron_fwaas/tests/unit/db/firewall/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/varmour/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/test_fwaas_plugin.py', 'neutron_fwaas/tests/unit/services/firewall/agents/l3reference/test_firewall_l3_agent.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/linux/test_iptables_fwaas.py', 'neutron_fwaas/tests/unit/services/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/test_firewall_agent_api.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/varmour/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/__init__.py', 'neutron_fwaas/tests.skip/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/linux/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/varmour/test_varmour_fwaas.py', 'neutron_fwaas/tests/unit/db/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/varmour/test_varmour_router.py', 'neutron_fwaas/tests/unit/db/firewall/test_db_firewall.py']",19,5d7cdc2e66c45600317fb555819eb761bb18f313,bp/services-split," ""neutron_fwaas.db.firewall.firewall_db.Firewall_db_mixin""FWAAS_PLUGIN = 'neutron_fwaas.services.firewall.fwaas_plugin'"," ""neutron.db.firewall.firewall_db.Firewall_db_mixin""FWAAS_PLUGIN = 'neutron.services.firewall.fwaas_plugin'",5,24
openstack%2Ffuel-docs~master~Ia7faa53dea892ec0f635c5fb52cc4ee2196f6135,openstack/fuel-docs,master,Ia7faa53dea892ec0f635c5fb52cc4ee2196f6135,"Capitalized ""Quotas""",MERGED,2014-12-18 13:06:45.000000000,2014-12-20 02:15:07.000000000,2014-12-20 02:15:07.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 10014}, {'_account_id': 14342}]","[{'number': 1, 'created': '2014-12-18 13:06:45.000000000', 'files': ['pages/terminology/q/quotas.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/0b65f28e3bd659c15505b19a2d4251cee48b2148', 'message': 'Capitalized ""Quotas""\n\nChange-Id: Ia7faa53dea892ec0f635c5fb52cc4ee2196f6135\n'}]",0,142766,0b65f28e3bd659c15505b19a2d4251cee48b2148,10,5,1,12866,,,0,"Capitalized ""Quotas""

Change-Id: Ia7faa53dea892ec0f635c5fb52cc4ee2196f6135
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/66/142766/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/terminology/q/quotas.rst'],1,0b65f28e3bd659c15505b19a2d4251cee48b2148,correct-spelling-mistake-quota-terminology,Quotas,quotas,1,1
openstack%2Ffuel-docs~master~I1f3f1aff728dfa12e14b041d72f089edaebc06bd,openstack/fuel-docs,master,I1f3f1aff728dfa12e14b041d72f089edaebc06bd,Replace screenshot for nova-network,MERGED,2014-12-03 07:43:34.000000000,2014-12-20 02:14:53.000000000,2014-12-20 02:14:53.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 11427}, {'_account_id': 12139}, {'_account_id': 12199}, {'_account_id': 13082}, {'_account_id': 14046}, {'_account_id': 14342}]","[{'number': 1, 'created': '2014-12-03 07:43:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/5a4107166e7a3d5b01a912f441c604fb3dee5908', 'message': ""Replace screenshot for nova-network\n\nSince UI message is changed, let's update the screenshot.\nThere us also one minor change for the text.\n\nChange-Id: I1f3f1aff728dfa12e14b041d72f089edaebc06bd\n""}, {'number': 2, 'created': '2014-12-05 08:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/099167f7ecc5115c395f3b5f9f3947248e98ab7c', 'message': ""Replace screenshot for nova-network\n\nSince UI message is changed, let's update the screenshot.\nThere us also one minor change for the text.\n\nChange-Id: I1f3f1aff728dfa12e14b041d72f089edaebc06bd\n""}, {'number': 3, 'created': '2014-12-08 07:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/2ce7e13e4fbb3f0e72c7c57e24e6ed4fc37a8017', 'message': ""Replace screenshot for nova-network\n\nSince UI message is changed, let's update the screenshot.\nThere is also one minor change for the text.\n\nChange-Id: I1f3f1aff728dfa12e14b041d72f089edaebc06bd\n""}, {'number': 4, 'created': '2014-12-08 11:46:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/d6d1f78b599f0d18b716d6f87d990fbf907690cf', 'message': ""Replace screenshot for nova-network\n\nSince UI message is changed, let's update the screenshot.\nThere is also one minor change for the text.\n\nChange-Id: I1f3f1aff728dfa12e14b041d72f089edaebc06bd\n""}, {'number': 5, 'created': '2014-12-11 13:57:48.000000000', 'files': ['pages/user-guide/7300-vcenter.rst', '_images/user_screen_shots/vcenter-networking.png'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/29a34eec7a05f4b659722ce74c706f98560764be', 'message': ""Replace screenshot for nova-network\n\nSince UI message is changed, let's update the screenshot.\nThere is also one minor change for the text.\n\nChange-Id: I1f3f1aff728dfa12e14b041d72f089edaebc06bd\n""}]",11,138660,29a34eec7a05f4b659722ce74c706f98560764be,46,12,5,13082,,,0,"Replace screenshot for nova-network

Since UI message is changed, let's update the screenshot.
There is also one minor change for the text.

Change-Id: I1f3f1aff728dfa12e14b041d72f089edaebc06bd
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/60/138660/2 && git format-patch -1 --stdout FETCH_HEAD,"['pages/user-guide/7300-vcenter.rst', '_images/user_screen_shots/vcenter-networking.png']",2,5a4107166e7a3d5b01a912f441c604fb3dee5908,nova-vlan-screen,,,2,3
openstack%2Ffuel-docs~master~I0d4a763fd28e4b8905bc8f25892383e9914c8347,openstack/fuel-docs,master,I0d4a763fd28e4b8905bc8f25892383e9914c8347,Update Storage Backends screenshot,ABANDONED,2014-12-11 14:05:55.000000000,2014-12-20 02:14:16.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 10014}, {'_account_id': 14342}]","[{'number': 1, 'created': '2014-12-11 14:05:55.000000000', 'files': ['_images/user_screen_shots/cinder-storage-backend.png'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4ff3f54a647aa5869a627264f1906fe95d293c52', 'message': 'Update Storage Backends screenshot\n\nChange-Id: I0d4a763fd28e4b8905bc8f25892383e9914c8347\n'}]",0,141054,4ff3f54a647aa5869a627264f1906fe95d293c52,7,4,1,13082,,,0,"Update Storage Backends screenshot

Change-Id: I0d4a763fd28e4b8905bc8f25892383e9914c8347
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/54/141054/1 && git format-patch -1 --stdout FETCH_HEAD,['_images/user_screen_shots/cinder-storage-backend.png'],1,4ff3f54a647aa5869a627264f1906fe95d293c52,storage-backend-screen,,,0,0
openstack%2Ffuel-docs~master~Ic8f5b6932e3b769c92f5fa0f91c25d63e22c0c2a,openstack/fuel-docs,master,Ic8f5b6932e3b769c92f5fa0f91c25d63e22c0c2a,"Replace ""Storage backend"" screen",MERGED,2014-11-12 00:37:01.000000000,2014-12-20 02:13:04.000000000,2014-12-20 02:12:52.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 13082}, {'_account_id': 14342}]","[{'number': 1, 'created': '2014-11-12 00:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/c3bc48c7e8c94dcae5c3f9f75d4f4973988d326e', 'message': 'Replace ""Storage backend"" screen\n\n6.0 screens add a vCenter/ESXi option\n\nChange-Id: Ic8f5b6932e3b769c92f5fa0f91c25d63e22c0c2a\n'}, {'number': 2, 'created': '2014-11-17 12:03:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/28a8a0bb3c392b5b07607d19e9b5b9e40b537bf6', 'message': 'Replace ""Storage backend"" screen\n\n6.0 screens add a vCenter/ESXi option\n\nChange-Id: Ic8f5b6932e3b769c92f5fa0f91c25d63e22c0c2a\n'}, {'number': 3, 'created': '2014-12-20 01:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/33e9bb937cfa01c04e51bd3ec14027242748cff0', 'message': 'Replace ""Storage backend"" screen\n\n6.0 screens add a vCenter/ESXi option\n\nChange-Id: Ic8f5b6932e3b769c92f5fa0f91c25d63e22c0c2a\n'}, {'number': 4, 'created': '2014-12-20 02:08:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/ad139a0619d6162ac1bf2f89013a61d2ae157793', 'message': 'Replace ""Storage backend"" screen\n\n6.0 screens add a vCenter/ESXi option\n\nChange-Id: Ic8f5b6932e3b769c92f5fa0f91c25d63e22c0c2a\n'}, {'number': 5, 'created': '2014-12-20 02:11:44.000000000', 'files': ['pages/user-guide/create-environment/3500-cinder-glance-backend.rst', '_images/user_screen_shots/cinder-storage-backend.png'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a4920e7a354f0ebbb560b35e83cb780d5a5b4e9a', 'message': 'Replace ""Storage backend"" screen\n\n6.0 screens add a vCenter/ESXi option\n\nChange-Id: Ic8f5b6932e3b769c92f5fa0f91c25d63e22c0c2a\n'}]",7,133867,a4920e7a354f0ebbb560b35e83cb780d5a5b4e9a,35,8,5,10014,,,0,"Replace ""Storage backend"" screen

6.0 screens add a vCenter/ESXi option

Change-Id: Ic8f5b6932e3b769c92f5fa0f91c25d63e22c0c2a
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/67/133867/5 && git format-patch -1 --stdout FETCH_HEAD,"['pages/user-guide/create-environment/3500-cinder-glance-backend.rst', '_images/user_screen_shots/cinder-storage-backend.png']",2,c3bc48c7e8c94dcae5c3f9f75d4f4973988d326e,user-storage,,,8,0
openstack%2Fcinder~master~I91c7a24d5da37735787e8fc0da544c8ba8204884,openstack/cinder,master,I91c7a24d5da37735787e8fc0da544c8ba8204884,Fix HNAS driver confusing error message,MERGED,2014-12-15 18:16:47.000000000,2014-12-20 02:06:01.000000000,2014-12-17 08:45:10.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 7198}, {'_account_id': 10058}, {'_account_id': 10621}, {'_account_id': 11079}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 13636}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-15 18:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/82654e82a6d6e27ca8d4e46e10544b7336c80bea', 'message': ""Fix HNAS driver confusing error message\n\nThe error message shown when the parser finds a parser error\nsays, 'file not found' which causes confusion on the user when\nhe/she needs to debug the real cause o the problem. This patch fix\nthis by testing first if the file exist and then throwing a\nproper error message.\n\nCloses-Bug: #1402775\nChange-Id: I91c7a24d5da37735787e8fc0da544c8ba8204884\n""}, {'number': 2, 'created': '2014-12-15 19:41:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/21200d30ad64ab1f01fbe3c8786f47300ddcf603', 'message': ""Fix HNAS driver confusing error message\n\nThe error message shown when the parser finds a parser error\nsays, 'file not found' which causes confusion on the user when\nhe/she needs to debug the real cause of the problem. This patch fix\nthis by testing first if the file exist and then throwing a\nproper error message.\n\nCloses-Bug: #1402775\nChange-Id: I91c7a24d5da37735787e8fc0da544c8ba8204884\n""}, {'number': 3, 'created': '2014-12-15 20:23:42.000000000', 'files': ['cinder/volume/drivers/hds/nfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6cc497b468ec909d5261c464826b704007fca2ee', 'message': ""Fix HNAS driver confusing error message\n\nThe error message shown when the parser finds a parser error\nsays, 'file not found' which causes confusion on the user when\nhe/she needs to debug the real cause o the problem. This patch fix\nthis by testing first if the file exist and then throwing a\nproper error message.\n\nCloses-Bug: #1402775\nChange-Id: I91c7a24d5da37735787e8fc0da544c8ba8204884\n""}]",6,141870,6cc497b468ec909d5261c464826b704007fca2ee,27,15,3,10058,,,0,"Fix HNAS driver confusing error message

The error message shown when the parser finds a parser error
says, 'file not found' which causes confusion on the user when
he/she needs to debug the real cause o the problem. This patch fix
this by testing first if the file exist and then throwing a
proper error message.

Closes-Bug: #1402775
Change-Id: I91c7a24d5da37735787e8fc0da544c8ba8204884
",git fetch https://review.opendev.org/openstack/cinder refs/changes/70/141870/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/hds/nfs.py'],1,82654e82a6d6e27ca8d4e46e10544b7336c80bea,fix-parser-error-1," if not os.access(xml_config_file, os.R_OK): raise exception.NotFound(message='config file not found: ' + xml_config_file) raise exception.ConfigNotFound(message='error parsing config file: ' + xml_config_file)", raise exception.NotFound(message='config file not found: ' + xml_config_file),6,2
openstack%2Ffuel-docs~master~I87a3dcdf5e3e926f737933a00c7597065e4f80ee,openstack/fuel-docs,master,I87a3dcdf5e3e926f737933a00c7597065e4f80ee,implement spell checking targets to aid tech writers and documentation contributors,MERGED,2014-10-17 16:32:18.000000000,2014-12-20 02:00:28.000000000,2014-12-20 02:00:28.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 11427}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-10-17 16:32:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/0465f3cd6dd9bb8d53de1bd265231d3bbd9c2e81', 'message': ""implement spell checking targets to aid tech writers\n\n- add two new targets to our Makefile: `spell' and `spell_all'\n- we rely on `aspell' spell checking tool (http://aspell.net/), it must\n  be installed in system\n- `spell' target trigges aspell to check files that were touched by\n  current commit; suggest workflow:\n  * create new branch\n  * edit or add new files\n  * git commit -a\n  * run `make spell'\n  * git commit --amend\n  * git review\n- `spell_all' target will run aspell against all .rst files found in\n  pages/ directory\n- provide aspel wordlist `aspell_en.wordlist', so that would not ask you\n  each time when it finds unknown word or acronym\n- mention `aspell' in README.md\n\nChange-Id: I87a3dcdf5e3e926f737933a00c7597065e4f80ee\n""}, {'number': 2, 'created': '2014-10-23 13:29:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/b75eebe6e4344acb72cc057fc399e242620f300d', 'message': ""implement spell checking targets to aid tech writers\n\n- add two new targets to our Makefile: `spell' and `spell_all'\n- we rely on `aspell' spell checking tool (http://aspell.net/), it must\n  be installed in system\n- `spell' target trigges aspell to check files that were touched by\n  current commit; suggested workflow:\n  * create new branch\n  * edit or add new files\n  * git commit -a\n  * run `make spell'\n  * git commit --amend\n  * git review\n- `spell_all' target will run aspell against all .rst files found in\n  pages/ directory\n- provide aspel wordlist `aspell_en.wordlist', so that would not ask you\n  each time when it finds unknown word or acronym\n- mention `aspell' in README.md\n\nChange-Id: I87a3dcdf5e3e926f737933a00c7597065e4f80ee\n""}, {'number': 3, 'created': '2014-10-28 08:52:37.000000000', 'files': ['Makefile', '.aspell_en.wordlist', 'README.md'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/27a011e04bfdfa56b526c9fa24c757b57b9755bc', 'message': ""implement spell checking targets to aid tech writers and documentation contributors\n\n- add two new targets to our Makefile: `spell' and `spell_all'\n- we rely on `aspell' spell checking tool (http://aspell.net/), it must\n  be installed in system\n- `spell' target triggers aspell to check files that were touched by\n  current commit; suggested workflow:\n  * git checkout -b release-notes-vX.Y\n  * edit files with your favourite editor\n  * git commit -a\n  * make spell\n  * git commit --amend\n  * git review\n- `spell_all' target will run aspell against all .rst files found in\n  pages/ directory\n- provide aspell wordlist `.aspell_en.wordlist', so that aspell would\n  not ask you each time when it finds unknown word or acronym (e.g.\n  VLAN, PXE, DHCP, etc)\n- mention `aspell' in README.md\n\nChange-Id: I87a3dcdf5e3e926f737933a00c7597065e4f80ee\n""}]",0,129323,27a011e04bfdfa56b526c9fa24c757b57b9755bc,22,7,3,11427,,,0,"implement spell checking targets to aid tech writers and documentation contributors

- add two new targets to our Makefile: `spell' and `spell_all'
- we rely on `aspell' spell checking tool (http://aspell.net/), it must
  be installed in system
- `spell' target triggers aspell to check files that were touched by
  current commit; suggested workflow:
  * git checkout -b release-notes-vX.Y
  * edit files with your favourite editor
  * git commit -a
  * make spell
  * git commit --amend
  * git review
- `spell_all' target will run aspell against all .rst files found in
  pages/ directory
- provide aspell wordlist `.aspell_en.wordlist', so that aspell would
  not ask you each time when it finds unknown word or acronym (e.g.
  VLAN, PXE, DHCP, etc)
- mention `aspell' in README.md

Change-Id: I87a3dcdf5e3e926f737933a00c7597065e4f80ee
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/23/129323/3 && git format-patch -1 --stdout FETCH_HEAD,"['Makefile', 'aspell_en.wordlist', 'README.md']",3,0465f3cd6dd9bb8d53de1bd265231d3bbd9c2e81,makefile-spell-targets, sudo apt-get install git python-pip python-dev make imagemagick libjpeg-dev inkscape aspell sudo yum install git python-pip python-devel make ImageMagick libjpeg-turbo-devel inkscape aspell, sudo apt-get install git python-pip python-dev make imagemagick libjpeg-dev inkscape sudo yum install git python-pip python-devel make ImageMagick libjpeg-turbo-devel inkscape,249,4
openstack%2Ffuel-docs~master~If1208f75a79c622431800fdc45f5ab12620d537f,openstack/fuel-docs,master,If1208f75a79c622431800fdc45f5ab12620d537f,Move descriptive info from Release Notes to index.rst,ABANDONED,2014-11-13 00:22:19.000000000,2014-12-20 01:54:21.000000000,,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9147}, {'_account_id': 9788}, {'_account_id': 12866}, {'_account_id': 13082}, {'_account_id': 14342}]","[{'number': 1, 'created': '2014-11-13 00:22:19.000000000', 'files': ['pages/release-notes/v5-1/010-what-is-mirantis-openstack.rst', 'pages/release-notes/v5-1-icehouse-full.rst', 'index.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/458c5d29ef7d8b41d0c8fe165870eb6ec0d5bb60', 'message': 'Move descriptive info from Release Notes to index.rst\n\nChange-Id: If1208f75a79c622431800fdc45f5ab12620d537f\nPartial-Bug: 1392111\n'}]",0,134087,458c5d29ef7d8b41d0c8fe165870eb6ec0d5bb60,10,8,1,10014,,,0,"Move descriptive info from Release Notes to index.rst

Change-Id: If1208f75a79c622431800fdc45f5ab12620d537f
Partial-Bug: 1392111
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/87/134087/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/release-notes/v5-1/010-what-is-mirantis-openstack.rst', 'pages/release-notes/v5-1-icehouse-full.rst', 'index.rst']",3,458c5d29ef7d8b41d0c8fe165870eb6ec0d5bb60,bug/1392111,"Mirantis OpenStack is made up of three components: * Mirantis OpenStack hardened packages * Fuel for OpenStack * Mirantis Support Mirantis OpenStack hardened packages ------------------------------------ These packages include the core OpenStack projects, updated with each stable release of OpenStack, and supporting a broad range of operating systems, hypervisors, and deployment topologies. Also included are: * Packages to ensure High Availability. * Fixes for defects reported by our customers that may not yet have been merged into the community source. * Mirantis-driven premium OpenStack projects such as Sahara (which provides a simple means to provision a Hadoop cluster on top of OpenStack) and Murano (an application catalog that can be used to publish apps and compose reliable environments out of them.) * Mirantis-certified partner plug-ins, drivers, and integrations. Fuel for OpenStack ------------------ Fuel is a life cycle management application that deploys multiple `OpenStack <https://www.openstack.org/>`_ clouds from a single interface and then enables you to manage those clouds post deployment. You can add nodes, remove nodes, or even remove clouds, restoring those resources to the available resources pool. Fuel also eases the complexities of network and storage configurations through a simple-to-use graphical user experience. Baked into Fuel are: * Mirantis reference architectures that we have tested and certified to ensure that your deployed clouds are scalable, reliable, and production quality. * An open and flexible library that enables customers to make configuration changes that may be more advanced or focused than the default choices within Fuel. This library also empowers organizations to fold additional drivers or integrations into the deployed environment. Mirantis OpenStack, by default, enables those features in the Fuel Project that Mirantis has certified and confirmed as production ready. However, it also includes some newer features that are marked as ""experimental""; they are less-hardened but are integrated into the product for customers who can tolerate some risk. These experimental features can be enabled for Mirantis OpenStack any time after you have a running Fuel Master Node; see :ref:`experimental-features-op`. Mirantis Support ---------------- Mirantis OpenStack offers a subscription to our world-class support with defined service level agreements based on the severity of your issue. For example, the premium support guarantees a one-hour response for severity 1 issues. ",,64,67
openstack%2Ffuel-docs~master~I4a38fbc6bd284ec35e686ba97fbb2856c6d87dd9,openstack/fuel-docs,master,I4a38fbc6bd284ec35e686ba97fbb2856c6d87dd9,Floating IP article,MERGED,2014-12-03 23:29:27.000000000,2014-12-20 01:50:43.000000000,2014-12-20 01:50:42.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 13335}]","[{'number': 1, 'created': '2014-12-03 23:29:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/8719f5a708447b93945b3137c54f036857749855', 'message': 'Floating IP article\n\nNew Terminology article, based on source provided by Stephan.\n\nChange-Id: I4a38fbc6bd284ec35e686ba97fbb2856c6d87dd9\n'}, {'number': 2, 'created': '2014-12-05 03:20:38.000000000', 'files': ['pages/terminology/f/floating-ip.rst', 'pages/terminology/allterms.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/0fced44ac3f71ba29f51ae0ce8258611eff0df39', 'message': 'Floating IP article\n\nNew Terminology article, based on source provided by Stephan.\n\nChange-Id: I4a38fbc6bd284ec35e686ba97fbb2856c6d87dd9\n'}]",0,138900,0fced44ac3f71ba29f51ae0ce8258611eff0df39,13,5,2,10014,,,0,"Floating IP article

New Terminology article, based on source provided by Stephan.

Change-Id: I4a38fbc6bd284ec35e686ba97fbb2856c6d87dd9
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/00/138900/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/terminology/f/floating-ip.rst', 'pages/terminology/allterms.rst']",2,8719f5a708447b93945b3137c54f036857749855,floating-ip,.. include:: /pages/terminology/f/floating-ip.rst,,56,0
openstack%2Fcinder~master~I4fa3306df982347afb5fb8e5d4d14612024b643a,openstack/cinder,master,I4fa3306df982347afb5fb8e5d4d14612024b643a,Implement Huawei SDSHypervisor connector,MERGED,2014-12-04 08:43:46.000000000,2014-12-20 01:41:50.000000000,2014-12-18 04:22:07.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 5538}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11538}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12779}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-04 08:43:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3816382c7cd0beae5035b66f742c3cc55d67da31', 'message': 'Add code for Huawei SDSHypervisor connector\n\nChange-Id: I4fa3306df982347afb5fb8e5d4d14612024b643a\nImplements: blueprint huawei-sdshypervisor-driver\n'}, {'number': 2, 'created': '2014-12-05 02:34:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0fa5c028e0ae1797c76d02841d40ad2f16a31c98', 'message': 'Add code for Huawei SDSHypervisor connector\n\nHuawei SDSHypervisor uses a private key-valye data protocal,\nso we add a new connector inherited from InitiatorConnector\nand implement connect_volume and disconnect_volume.\n\nChange-Id: I4fa3306df982347afb5fb8e5d4d14612024b643a\nImplements: blueprint huawei-sdshypervisor-driver\n'}, {'number': 3, 'created': '2014-12-05 03:28:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/baef14af23c9a307b3620e0e45a89238ef21522a', 'message': 'Add code for Huawei SDSHypervisor connector\n\nHuawei SDSHypervisor uses a private key-valye data protocal,\nso we add a new connector inherited from InitiatorConnector\nand implement connect_volume and disconnect_volume.\n\nChange-Id: I4fa3306df982347afb5fb8e5d4d14612024b643a\nImplements: blueprint huawei-sdshypervisor-driver\n'}, {'number': 4, 'created': '2014-12-09 03:39:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ce3b27b228ecd8bfa7a5f84aab1571a0bf951473', 'message': 'Add code for Huawei SDSHypervisor connector\n\nHuawei SDSHypervisor uses a private key-valye data protocal,\nso we add a new connector inherited from InitiatorConnector\nand implement connect_volume and disconnect_volume.\n\nThe connecotr uses sds_cli cmd to implement attach/detach/querydev vol,\nsds_cli will be put to a specific dir and the path is registered as a\nsystem environment variable when sds is installed.\n\nChange-Id: I4fa3306df982347afb5fb8e5d4d14612024b643a\nImplements: blueprint huawei-sdshypervisor-driver\n'}, {'number': 5, 'created': '2014-12-09 03:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a0ba635a2c3427021ff2cdb5032f984b746671c3', 'message': 'Add code for Huawei SDSHypervisor connector\n\nHuawei SDSHypervisor uses a private key-valye data protocal,\nso we add a new connector inherited from InitiatorConnector\nand implement connect_volume and disconnect_volume.\n\nThe connecotr uses sds_cli cmd to implement attach/detach/querydev vol,\nsds_cli will be put to a specific dir and the path is registered as a\nsystem environment variable when sds is installed.\n\nChange-Id: I4fa3306df982347afb5fb8e5d4d14612024b643a\nImplements: blueprint huawei-sdshypervisor-driver\n'}, {'number': 6, 'created': '2014-12-09 11:02:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4491018579f7e38a2b9cd01636f9b04e84c04eba', 'message': 'Implement Huawei SDSHypervisor connector\n\nHuawei SDSHypervisor uses a private key-value data protocal,\nso we add a new connector inherited from InitiatorConnector\nand implement connect_volume and disconnect_volume.\n\nThe connector uses sds_cli cmd to implement attach/detach/querydev vol,\nsds_cli will be put to a specific dir and the path is registered as a\nsystem environment variable when sds is installed.\n\nChange-Id: I4fa3306df982347afb5fb8e5d4d14612024b643a\nImplements: blueprint huawei-sdshypervisor-driver\n'}, {'number': 7, 'created': '2014-12-11 09:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9bbf69a288fd2f493fa9b4149de7ff18951d5777', 'message': 'Implement Huawei SDSHypervisor connector\n\nHuawei SDSHypervisor uses a private key-value data protocal,\nso we add a new connector inherited from InitiatorConnector\nand implement connect_volume and disconnect_volume.\n\nThe connector uses sds_cli cmd to implement attach/detach/querydev vol,\nsds_cli will be put to a specific dir and the path is registered as a\nsystem environment variable when sds is installed.\n\nChange-Id: I4fa3306df982347afb5fb8e5d4d14612024b643a\nImplements: blueprint huawei-sdshypervisor-driver\n'}, {'number': 8, 'created': '2014-12-15 02:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5cce948bc85edf760a3ad6d2eb04c515e881e74c', 'message': 'Implement Huawei SDSHypervisor connector\n\nHuawei SDSHypervisor uses a private key-value data protocal,\nso we add a new connector inherited from InitiatorConnector\nand implement connect_volume and disconnect_volume.\n\nThe connector uses sds_cli cmd to implement attach/detach/querydev vol,\nsds_cli will be put to a specific dir and the path is registered as a\nsystem environment variable when sds is installed.\n\nChange-Id: I4fa3306df982347afb5fb8e5d4d14612024b643a\nImplements: blueprint huawei-sdshypervisor-driver\n'}, {'number': 9, 'created': '2014-12-15 02:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/16cf494359124929b1825973b1ad03a91b40659a', 'message': 'Implement Huawei SDSHypervisor connector\n\nHuawei SDSHypervisor uses a private key-value data protocal,\nso we add a new connector inherited from InitiatorConnector\nand implement connect_volume and disconnect_volume.\n\nThe connector uses sds_cli cmd to implement attach/detach/querydev vol,\nsds_cli will be put to a specific dir and the path is registered as a\nsystem environment variable when sds is installed.\n\nChange-Id: I4fa3306df982347afb5fb8e5d4d14612024b643a\nImplements: blueprint huawei-sdshypervisor-driver\n'}, {'number': 10, 'created': '2014-12-15 17:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1b0a7177aa7cb0907380d4ea98d68237bd03f1cf', 'message': 'Implement Huawei SDSHypervisor connector\n\nHuawei SDSHypervisor uses a private key-value data protocal,\nso we add a new connector inherited from InitiatorConnector\nand implement connect_volume and disconnect_volume.\n\nThe connector uses sds_cli cmd to implement attach/detach/querydev vol,\nsds_cli will be put to a specific dir and the path is registered as a\nsystem environment variable when sds is installed.\n\nChange-Id: I4fa3306df982347afb5fb8e5d4d14612024b643a\nImplements: blueprint huawei-sdshypervisor-driver\n'}, {'number': 11, 'created': '2014-12-17 02:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/412cf1b64aa69453b118ab7b3e51400515e004ba', 'message': 'Implement Huawei SDSHypervisor connector\n\nHuawei SDSHypervisor uses a private key-value data protocal,\nso we add a new connector inherited from InitiatorConnector\nand implement connect_volume and disconnect_volume.\n\nThe connector uses sds_cli cmd to implement attach/detach/querydev vol,\nsds_cli will be put to a specific dir and the path is registered as a\nsystem environment variable when sds is installed.\n\nChange-Id: I4fa3306df982347afb5fb8e5d4d14612024b643a\nImplements: blueprint huawei-sdshypervisor-driver\n'}, {'number': 12, 'created': '2014-12-17 03:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2449a1cc5f5494112409312f3244c8ca962db1bb', 'message': 'Implement Huawei SDSHypervisor connector\n\nHuawei SDSHypervisor uses a private key-value data protocal,\nso we add a new connector inherited from InitiatorConnector\nand implement connect_volume and disconnect_volume.\n\nThe connector uses sds_cli cmd to implement attach/detach/querydev vol,\nsds_cli will be put to a specific dir and the path is registered as a\nsystem environment variable when sds is installed.\n\nChange-Id: I4fa3306df982347afb5fb8e5d4d14612024b643a\nImplements: blueprint huawei-sdshypervisor-driver\n'}, {'number': 13, 'created': '2014-12-17 03:37:14.000000000', 'files': ['cinder/tests/brick/test_brick_connector.py', 'cinder/brick/initiator/connector.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f6343dfc4fa460dc2e301e73b66c07f08826cd03', 'message': 'Implement Huawei SDSHypervisor connector\n\nHuawei SDSHypervisor uses a private key-value data protocal,\nso we add a new connector inherited from InitiatorConnector\nand implement connect_volume and disconnect_volume.\n\nThe connector uses sds_cli cmd to implement attach/detach/querydev vol,\nsds_cli will be put to a specific dir and the path is registered as a\nsystem environment variable when sds is installed.\n\nChange-Id: I4fa3306df982347afb5fb8e5d4d14612024b643a\nImplements: blueprint huawei-sdshypervisor-driver\n'}]",23,138988,f6343dfc4fa460dc2e301e73b66c07f08826cd03,105,21,13,11538,,,0,"Implement Huawei SDSHypervisor connector

Huawei SDSHypervisor uses a private key-value data protocal,
so we add a new connector inherited from InitiatorConnector
and implement connect_volume and disconnect_volume.

The connector uses sds_cli cmd to implement attach/detach/querydev vol,
sds_cli will be put to a specific dir and the path is registered as a
system environment variable when sds is installed.

Change-Id: I4fa3306df982347afb5fb8e5d4d14612024b643a
Implements: blueprint huawei-sdshypervisor-driver
",git fetch https://review.opendev.org/openstack/cinder refs/changes/88/138988/12 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/brick/test_brick_connector.py', 'cinder/brick/initiator/connector.py']",2,3816382c7cd0beae5035b66f742c3cc55d67da31,bp/huawei-sdshypervisor-driver," elif protocol == ""HUAWEISDSHYPERVISOR"": return HuaweiStorHyperConnector(root_helper=root_helper, driver=driver, execute=execute, device_scan_attempts= device_scan_attempts, *args, **kwargs) class HuaweiStorHyperConnector(InitiatorConnector): """"""""Connector class to attach/detach SDSHypervisor volumes."""""" attached_success_code = 0 has_been_attached_code = 50151401 attach_mnid_done_code = 50151405 vbs_unnormal_code = 50151209 not_mount_node_code = 50155007 def __init__(self, root_helper, driver=None, execute=putils.execute, *args, **kwargs): self.cli_path = os.getenv('HUAWEISDSHYPERVISORCLI_PATH') if self.cli_path is None: self.cli_path = '/usr/local/bin/sds/sds_cli' LOG.debug(""CLI path is not configured, using default %s."" % self.cli_path) if not os.path.isfile(self.cli_path): LOG.error(_LE('SDS CLI file is not exist,' 'HuaweiStorHyperConnector init failed')) super(HuaweiStorHyperConnector, self).__init__(root_helper, driver=driver, execute=execute, *args, **kwargs) @synchronized('connect_volume') def connect_volume(self, connection_properties): """"""Connect to a volume."""""" LOG.debug(""Connect_volume connection properties: %s."" % connection_properties) out = self._attach_volume(connection_properties['volume_id']) if not out or int(out['ret_code']) not in (self.attached_success_code, self.has_been_attached_code, self.attach_mnid_done_code): msg = (_(""Attach volume failed, "" ""error code is %s"") % out['ret_code']) raise exception.BrickException(msg=msg) out = self._query_attached_volume( connection_properties['volume_id']) if not out or int(out['ret_code']) != 0: msg = (_(""query attached volume failed or volume not attached."")) raise exception.BrickException(msg=msg) device_info = {'type': 'block', 'path': out['dev_addr']} return device_info @synchronized('connect_volume') def disconnect_volume(self, connection_properties, device_info): """"""Disconnect a volume from the local host."""""" LOG.debug(""Disconnect_volume: %s."" % connection_properties) out = self._detach_volume(connection_properties['volume_id']) if not out or int(out['ret_code']) not in (self.attached_success_code, self.vbs_unnormal_code, self.not_mount_node_code): msg = (_(""Disconnect_volume failed, "" ""error code is %s"") % out['ret_code']) raise exception.BrickException(msg=msg) def is_volume_connected(self, volume_name): """"""Check if volume already connected to host"""""" LOG.debug('Check if volume %s already connected to a host.' % volume_name) out = self._query_attached_volume(volume_name) if out: return int(out['ret_code']) == 0 return False def _attach_volume(self, volume_name): return self._cli_cmd(self.cli_path, 'attach', volume_name) def _detach_volume(self, volume_name): return self._cli_cmd(self.cli_path, 'detach', volume_name) def _query_attached_volume(self, volume_name): return self._cli_cmd(self.cli_path, 'querydev', volume_name) def _cli_cmd(self, path, method, volume_name): LOG.debug(""Enter into _cli_cmd."") if not method or volume_name is None: return cmd = [path, '-c', method, '-v', volume_name] out, err = self._execute(*cmd, run_as_root=False, root_helper=self._root_helper) analyse_result = self._analyze_output(out) LOG.debug('%(method)s volume returns %(analyse_result)s.' % {'method': method, 'analyse_result': analyse_result}) if err: LOG.error(_LE(""SDS CLI failed, error message is: %s."") % err) return analyse_result def _analyze_output(self, out): LOG.debug(""Enter into _analyze_output."") if out: analyse_result = {} out_temp = out.split('\n') for line in out_temp: LOG.debug(""Line is %s."" % line) if line.find('=') != -1: key, val = line.split('=', 1) LOG.debug(key + "" = "" + val) if key in ['ret_code', 'ret_desc', 'dev_addr']: analyse_result[key] = val return analyse_result else: return None",,277,0
openstack%2Ffuel-docs~master~I520fa7cfe553b4c2c2e2de4d90a55def5af93570,openstack/fuel-docs,master,I520fa7cfe553b4c2c2e2de4d90a55def5af93570,Update Major Component Versions,MERGED,2014-12-18 23:27:05.000000000,2014-12-20 01:37:22.000000000,2014-12-20 01:37:22.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-12-18 23:27:05.000000000', 'files': ['pages/release-notes/v6-0/0025-supported-software-list.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/5d5e31a8363ca992804e6a50a4f9bf4f92461961', 'message': 'Update Major Component Versions\n\nThis commit updates the major component versions\nof the release notes, comparing to contents of\npackages at http://mirror.fuel-infra.org\n\nChange-Id: I520fa7cfe553b4c2c2e2de4d90a55def5af93570\n'}]",0,142933,5d5e31a8363ca992804e6a50a4f9bf4f92461961,9,4,1,9788,,,0,"Update Major Component Versions

This commit updates the major component versions
of the release notes, comparing to contents of
packages at http://mirror.fuel-infra.org

Change-Id: I520fa7cfe553b4c2c2e2de4d90a55def5af93570
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/33/142933/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v6-0/0025-supported-software-list.rst'],1,5d5e31a8363ca992804e6a50a4f9bf4f92461961,60-major-versions,"* **Ceph** `0.80.7 <http://ceph.com/docs/master/release-notes/#v0-80-7-firefly>`_ ""Firefly"" `5.5.40 <http://dev.mysql.com/doc/relnotes/mysql/5.5/en/>`_","* **Keepalived** `1.2.4 <http://www.keepalived.org/changelog.html>`_ * **Ceph** `0.80.4 <http://ceph.com/docs/master/release-notes/#v0-80-4-firefly>`_ ""Firefly"" `5.5.37 <http://dev.mysql.com/doc/relnotes/mysql/5.5/en/>`_",2,4
openstack%2Fcinder~master~I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb,openstack/cinder,master,I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb,Added volume type description for volume type API,MERGED,2014-10-29 21:04:18.000000000,2014-12-20 01:29:57.000000000,2014-12-17 07:59:57.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 428}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 5203}, {'_account_id': 5538}, {'_account_id': 5997}, {'_account_id': 6043}, {'_account_id': 6094}, {'_account_id': 6491}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9624}, {'_account_id': 10503}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 11079}, {'_account_id': 11811}, {'_account_id': 11880}, {'_account_id': 11903}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12779}, {'_account_id': 12780}, {'_account_id': 12924}, {'_account_id': 14082}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-10-29 21:04:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e297d89db54f0b969077d24c12b9d7b2b4fdb1eb', 'message': 'added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update descripitoin, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be retured.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Upgraded the database cinder on table  volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 2, 'created': '2014-10-29 23:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dd3582bc2e98d240e83a02a5ecc7916c84900b04', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update descripitoin, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be retured.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Upgraded the database cinder on table  volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 3, 'created': '2014-10-30 01:07:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fc6aba92d18ec84685e2b2e1b258cae8aca44df4', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update descripitoin, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be retured.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should have notification for message bug when update\nsucceeds or fails.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 4, 'created': '2014-10-31 20:53:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/78e6f9827ddbef243450e411c980df81e7679567', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update descripitoin, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be retured.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should have notification for message bug when update\nsucceeds or fails.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 5, 'created': '2014-11-03 19:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e92c3ae36a274c47fc704819f72d08a603feba79', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update descripitoin, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be retured.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 6, 'created': '2014-11-05 22:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bb6485abf870f06d5052bfb19bf8bfa4b543f265', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update descripitoin, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be retured.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 7, 'created': '2014-11-06 00:27:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/df6005216ea78349b73c07b1293900a32e02494d', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update descripitoin, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be retured.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 8, 'created': '2014-11-13 22:34:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0766483a466306ab95587e3070f091222b302b48', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update descripitoin, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be retured.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 9, 'created': '2014-11-14 19:17:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a2bf4c33aa1ab557a26c0e1ee4a9fb3443ac6d9e', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update descripitoin, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be retured.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 10, 'created': '2014-11-17 20:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b58cea0e74160d0d957c4a6b04e062f90a241e50', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update description, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be returned.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 11, 'created': '2014-11-17 22:22:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b02950980606c609cf9827ba25fce1a46a1a4804', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update description, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be returned.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 12, 'created': '2014-11-19 19:39:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/16763fcd2856f2f3372f8f6159e422f98283f47d', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update description, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be returned.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 13, 'created': '2014-11-20 18:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/876e92e17a1983c81c0e11d17ebf0b234983560d', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update description, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be returned.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 14, 'created': '2014-11-21 19:06:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/118d6e81ee9edf3960f98326e81d631462fb9f85', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update description, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be returned.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 15, 'created': '2014-12-02 00:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f81940bf8f0d6dfff0680006d2bca15b7c96d84b', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update description, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be returned.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 16, 'created': '2014-12-02 00:47:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a8082850e57eb642d8c09f8637053fad84db6bdd', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update description, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be returned.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 17, 'created': '2014-12-02 17:54:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4cf3c2840f7c87fa1b5c77e7cff9361df857ac00', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update description, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be returned.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 18, 'created': '2014-12-06 01:32:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cf7c88903426363df442540ccb602ea9bc1d1e4e', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update description, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be returned.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\n- as of 12/5/2014, had to rebase with master which has volume type\naccess change, I also fixed the tests in that area in order to get\nthe unit tests pass.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 19, 'created': '2014-12-08 21:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cb14e21c7787bd855f4401573faf19e73734374c', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update description, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be returned.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\n- as of 12/5/2014, had to rebase with master which has volume type\naccess change, I also fixed the tests in that area in order to get\nthe unit tests pass.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 20, 'created': '2014-12-08 21:51:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1bd6de25fbd67a686dbe369c85ebc5ef8741c1ab', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update description, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be returned.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\n- as of 12/5/2014, had to rebase with master which has volume type\naccess change, I also fixed the tests in that area in order to get\nthe unit tests pass.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 21, 'created': '2014-12-09 17:24:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/87f523256886d051f2a45609be1e0d476f55321e', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""name"": ""test_updated"",\n      ""description"":""updated_desc""\n    }\n}\n** user can update name and/or description.\n** if update name, name can not be empty spaces.\n** if update name, can not change the name to be the same as the one\nin another volume type\n** if update description, descripiton can be empty spaces.\n** name and description can not be both None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be returned.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\n- as of 12/5/2014, had to rebase with master which has volume type\naccess change, I also fixed the tests in that area in order to get\nthe unit tests pass.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 22, 'created': '2014-12-10 21:38:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6eb9484d7f43d7305ee794a0c48bcef8bccb2289', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""description"":""updated_desc""\n    }\n}\n** user can update description.\n** if update description, descripiton can be empty spaces.\n** description can not be None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be returned.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\n- as of 12/5/2014, had to rebase with master which has volume type\naccess change, I also fixed the tests in that area in order to get\nthe unit tests pass.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 23, 'created': '2014-12-10 23:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0e0c9e728858d368224b0e43c3ee711a4f1e1450', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""description"":""updated_desc""\n    }\n}\n** user can update description.\n** if update description, descripiton can be empty spaces.\n** description can not be None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be returned.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\n- as of 12/5/2014, had to rebase with master which has volume type\naccess change, I also fixed the tests in that area in order to get\nthe unit tests pass.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 24, 'created': '2014-12-15 17:57:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cc2c7be1ee2eb065fde4dc25a0a2b24455696e69', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""description"":""updated_desc""\n    }\n}\n** user can update description.\n** if update description, descripiton can be empty spaces.\n** description can not be None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be returned.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\n- as of 12/5/2014, had to rebase with master which has volume type\naccess change, I also fixed the tests in that area in order to get\nthe unit tests pass.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 25, 'created': '2014-12-16 20:47:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bdeba2d062ecd8096091fe9cc7a9b238a17d0049', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""description"":""updated_desc""\n    }\n}\n** user can update description.\n** if update description, descripiton can be empty spaces.\n** description can not be None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be returned.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\n- as of 12/5/2014, had to rebase with master which has volume type\naccess change, I also fixed the tests in that area in order to get\nthe unit tests pass.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}, {'number': 26, 'created': '2014-12-17 02:22:57.000000000', 'files': ['cinder/db/sqlalchemy/migrate_repo/versions/034_sqlite_downgrade.sql', 'cinder/db/api.py', 'cinder/volume/volume_types.py', 'cinder/api/v2/types.py', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/api/contrib/test_volume_type_access.py', 'cinder/tests/test_volume_types.py', 'cinder/api/views/types.py', 'cinder/api/contrib/types_manage.py', 'cinder/db/sqlalchemy/migrate_repo/versions/034_volume_type_add_desc_column.py', 'cinder/tests/api/v2/test_types.py', 'cinder/exception.py', 'cinder/tests/api/contrib/test_types_manage.py', 'cinder/api/contrib/volume_type_access.py', 'cinder/tests/api/v1/test_types.py', 'cinder/api/openstack/wsgi.py', 'cinder/tests/test_migrations.py', 'cinder/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/cf7381598262a70ab679bdb0417a57dfd361fbbb', 'message': 'Added volume type description for volume type API\n\n- Added the following APIs and tests for volume type\n* update volume type\nPUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}\nbody\n{\n    ""volume_type"": {\n      ""description"":""updated_desc""\n    }\n}\n** user can update description.\n** if update description, descripiton can be empty spaces.\n** description can not be None\n** only admin can access this API\n\n*get default volume type\nGET http://<openstackhost>:8776/v2/${tenant_id}/types/default\n** if default_volume_type is specified in cinder.conf and is valid,\nthe default volume type will be returned.\n** if default_volume_type is not specified in cinder.conf or is not\nvalid, it will return 404 with a message saying default volume type\ncan not be found.\n\n- Updated the following APIs and tests for volume type\n* create volume type should take description as an option.\n* list volume types or get one volume type will include description for\nvolume type if the description is not None.\n\n- Upgraded the database cinder on table volume_types to include\nthe description. database upgrade/downgrade scripts and tests\nare added.\n\n- update API should send a notification to the message bus when\nupdating succeeds or fails.\n\n- as of 12/5/2014, had to rebase with master which has volume type\naccess change, I also fixed the tests in that area in order to get\nthe unit tests pass.\n\nImplements: blueprint volume-type-description\nChange-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb\n'}]",60,131871,cf7381598262a70ab679bdb0417a57dfd361fbbb,289,32,26,11880,,,0,"Added volume type description for volume type API

- Added the following APIs and tests for volume type
* update volume type
PUT http://<openstackhost>:8776/v2/${tenant_id}/types/${vol_type_id}
body
{
    ""volume_type"": {
      ""description"":""updated_desc""
    }
}
** user can update description.
** if update description, descripiton can be empty spaces.
** description can not be None
** only admin can access this API

*get default volume type
GET http://<openstackhost>:8776/v2/${tenant_id}/types/default
** if default_volume_type is specified in cinder.conf and is valid,
the default volume type will be returned.
** if default_volume_type is not specified in cinder.conf or is not
valid, it will return 404 with a message saying default volume type
can not be found.

- Updated the following APIs and tests for volume type
* create volume type should take description as an option.
* list volume types or get one volume type will include description for
volume type if the description is not None.

- Upgraded the database cinder on table volume_types to include
the description. database upgrade/downgrade scripts and tests
are added.

- update API should send a notification to the message bus when
updating succeeds or fails.

- as of 12/5/2014, had to rebase with master which has volume type
access change, I also fixed the tests in that area in order to get
the unit tests pass.

Implements: blueprint volume-type-description
Change-Id: I3100a8f74fa1c0cc8d9293bf30e17b6ac4c72edb
",git fetch https://review.opendev.org/openstack/cinder refs/changes/71/131871/24 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/db/api.py', 'cinder/volume/volume_types.py', 'cinder/api/v2/types.py', 'cinder/db/sqlalchemy/api.py', 'cinder/db/sqlalchemy/migrate_repo/versions/032_sqlite_downgrade.sql', 'cinder/db/sqlalchemy/migrate_repo/versions/032_volume_type_add_desc_column.py', 'cinder/tests/test_volume_types.py', 'cinder/api/views/types.py', 'cinder/api/contrib/types_manage.py', 'cinder/tests/api/v2/test_types.py', 'cinder/exception.py', 'cinder/tests/api/contrib/test_types_manage.py', 'cinder/api/openstack/wsgi.py', 'cinder/tests/test_migrations.py', 'cinder/db/sqlalchemy/models.py']",15,e297d89db54f0b969077d24c12b9d7b2b4fdb1eb,bp/volume-type-description, description = Column(String(255)),,462,22
openstack%2Ffuel-docs~master~I358e9ae4c384e13e61c1986d24e44b8c1accd1ac,openstack/fuel-docs,master,I358e9ae4c384e13e61c1986d24e44b8c1accd1ac,Updated docs for Sahara,MERGED,2014-12-10 15:12:14.000000000,2014-12-20 01:26:51.000000000,2014-12-20 01:26:51.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7132}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 13082}, {'_account_id': 14342}]","[{'number': 1, 'created': '2014-12-10 15:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/ee84fe9cc77c326c8a4a9ccbb13acc01ab94c56e', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 2, 'created': '2014-12-10 15:14:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4e1047e437b23728f3a9c2cb86996d0a8f71d60e', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 3, 'created': '2014-12-10 15:19:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4139a2756c36cd503e5a863b5036f32561bdbfd5', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 4, 'created': '2014-12-10 15:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/25e9ad8fb7266089c2dacdc9b7c3fd9d3a8816bb', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 5, 'created': '2014-12-11 11:53:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/c125dab53943cfa2ad81d81a8f24f8d320facf7d', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 6, 'created': '2014-12-12 11:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/ea2812a463627004b3ae77da0e92822d90c45168', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 7, 'created': '2014-12-12 12:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a5af9181699a3319c6ea2a17bb02983aeac342ca', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 8, 'created': '2014-12-15 10:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f6c9621adde87c7da429630584feb56a12473a95', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 9, 'created': '2014-12-16 11:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a220d02f083d80fb6f99b09fbbc5d246bf12f300', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 10, 'created': '2014-12-16 11:06:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/44a8db4c2efc37833fe1d0dd06f486131f3ef540', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 11, 'created': '2014-12-17 09:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f39d0f18f5b1edb287e79643dc9df46c86adf0e2', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 12, 'created': '2014-12-18 12:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/9a1dab595506ac9980f2263e485eb69cfc0ea3bd', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nCloses-Bug: #1403853\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac'}, {'number': 13, 'created': '2014-12-18 13:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a789a8abf4c0bacfaa65f61427e97ae8111c56df', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nCloses-Bug: #1403853\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 14, 'created': '2014-12-18 13:40:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f9512c2c834eb8db337d64dc79d5782d33911802', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nCloses-Bug: #1403853\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 15, 'created': '2014-12-18 13:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/047faf1200277204726bbeff5cbc9f3291ae4f9f', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nCloses-Bug: #1403853\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 16, 'created': '2014-12-18 13:58:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/d53f8325de639b28899799689442786fd47b83a6', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nCloses-Bug: #1403853\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 17, 'created': '2014-12-18 14:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4e81c05aa414d0f5b22f9a405a493e4d762cc5b5', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nCloses-Bug: #1403853\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 18, 'created': '2014-12-18 14:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/1ad2a895c2699d6c3998d0aac30422a2f4b55cfc', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nCloses-Bug: #1403853\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 19, 'created': '2014-12-18 14:22:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/8fa2348522b0df9f988b3f25ce0dcfa70a8fd0dd', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nCloses-Bug: #1403853\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 20, 'created': '2014-12-18 14:31:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a3135522256d7c02fb01b4b7609c9212246a91c2', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nCloses-Bug: #1403853\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 21, 'created': '2014-12-18 20:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/c59822ff31c7c34325fe3f118b983b835b3fcf1e', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nCloses-Bug: #1403853\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 22, 'created': '2014-12-19 03:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/11203d40d1eb67fbb73eec33a18e47d02fad7b94', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nCloses-Bug: #1403853\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}, {'number': 23, 'created': '2014-12-19 22:00:53.000000000', 'files': ['pages/operations/sahara/7700-prepare-to-test.rst', 'pages/operations/sahara/7600-security-groups.rst', 'pages/user-guide/7000-sahara-install.rst', 'pages/terminology/s/sahara.rst', 'pages/operations/7000-sahara.rst', 'pages/terminology/s/security-groups.rst', 'pages/planning-guide/7000-sahara-plan.rst', 'pages/operations/sahara/7750-test-details.rst', 'pages/operations/sahara/7760-sahara-images.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a4e25c7d193bf4a2872b596b4aee471fba1242a9', 'message': 'Updated docs for Sahara\n\nThe update is targeted for MOS 6.0\n\nCloses-Bug: #1403853\nChange-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac\n'}]",27,140731,a4e25c7d193bf4a2872b596b4aee471fba1242a9,113,10,23,7132,,,0,"Updated docs for Sahara

The update is targeted for MOS 6.0

Closes-Bug: #1403853
Change-Id: I358e9ae4c384e13e61c1986d24e44b8c1accd1ac
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/31/140731/14 && git format-patch -1 --stdout FETCH_HEAD,"['pages/operations/sahara/7700-prepare-to-test.rst', 'pages/operations/sahara/7600-security-groups.rst', 'pages/user-guide/7000-sahara-install.rst', 'pages/operations/sahara/7600-ports.rst', 'pages/terminology/s/sahara.rst', 'pages/operations/7000-sahara.rst', 'pages/terminology/s/security-groups.rst', 'pages/planning-guide/7000-sahara-plan.rst', 'pages/operations/sahara/7750-test-details.rst', 'pages/operations/sahara/7760-sahara-images.rst']",10,ee84fe9cc77c326c8a4a9ccbb13acc01ab94c56e,sahara-60, .. _sahara-images: Sahara Images ------------- +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | Plugin Name | Version | Operating System | Username | Link | Size | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | Vanilla | 1.2.1 | Ubuntu 14.04 | ubuntu | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-vanilla-1.2.1-ubuntu-14.04.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | Vanilla | 1.2.1 | Fedora 20 | cloud-user | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-vanilla-1.2.1-fedora-20.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | Vanilla | 1.2.1 | CentOS 6.5 | root | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-vanilla-1.2.1-centos-6.5.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | Vanilla | 2.4.1 | Ubuntu 14.04 | ubuntu | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-vanilla-2.4.1-ubuntu-14.04.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | Vanilla | 2.4.1 | Fedora 20 | cloud-user | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-vanilla-2.4.1-fedora-20.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | Vanilla | 2.4.1 | CentOS 6.5 | root | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-vanilla-2.4.1-centos-6.5.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | HDP | 1.3.2 | CentOS 6.5 | root | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-hdp-1.3.2-centos-6.5.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | HDP | 2.0.6 | CentOS 6.5 | root | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-hdp-2.0.6-centos-6.5.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | CDH | 5 | Ubuntu 14.04 | ubuntu | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-cdh-5-ubuntu-14.04.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | CDH | 5 | CentOS 6.5 | root | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-cdh-5-centos-6.5.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ | Spark | 1.0.0 | Ubuntu 14.04 | ubuntu | `Download <http://sahara-files.mirantis.com/mos60/sahara-mos60-spark-1.0.0-ubuntu-14.04.qcow2>`_ | | +-------------+---------+------------------+------------+----------------------------------------------------------------------------------------------------+------+ .. note:: You can find MD5 checksum of an image by adding .md5 suffix to the image url. For example MD5 for Vanilla 1.2.1 ubuntu image is available at `http://sahara-files.mirantis.com/mos60/sahara-mos60-vanilla-1.2.1-ubuntu-14.04.qcow2.md5`_,,87,159
openstack%2Fcinder~master~I5c4423da4442f2458417dc3492750412a74ebe09,openstack/cinder,master,I5c4423da4442f2458417dc3492750412a74ebe09,Added UUID as primary key for Encryption model,MERGED,2014-09-04 10:26:20.000000000,2014-12-20 01:06:18.000000000,2014-12-17 02:10:55.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 6491}, {'_account_id': 7491}, {'_account_id': 9008}, {'_account_id': 10503}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11047}, {'_account_id': 11751}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12778}, {'_account_id': 12779}, {'_account_id': 12780}, {'_account_id': 13049}, {'_account_id': 13636}]","[{'number': 1, 'created': '2014-09-04 10:26:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9c1e21dff61b63807bc881ff0f0a9fb5ebfac375', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encription\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nClouses: bug #1316540\n'}, {'number': 2, 'created': '2014-09-04 13:14:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/21f44f1fc7eae8ed7c0378331ca142dd5dbaeca2', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encription\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nClouses-bug #1316540\n'}, {'number': 3, 'created': '2014-09-04 17:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5ad6dbd407e5534a21d849dcb1ad126ed28f7b2b', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encription\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nClouses-bug #1316540\n'}, {'number': 4, 'created': '2014-09-04 18:33:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6716a52e4845c06224366f3021b9d0b77dad8c42', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encription\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nClouses-bug #1316540\n'}, {'number': 5, 'created': '2014-09-04 19:12:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6d30112d978d26b3f53c2e6d3c2325a32923704b', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encription\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nClouses-bug #1316540\n'}, {'number': 6, 'created': '2014-09-04 19:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/13072c4fdacdd5010ac17ff860062600e1d51358', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encription\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nClouses-bug #1316540\n'}, {'number': 7, 'created': '2014-09-04 19:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7c9597f0f5c083322e4e9c27dd5e65590d41f6a8', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encription\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nClouses-bug #1316540\n'}, {'number': 8, 'created': '2014-09-08 15:25:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/543bbd2e03dc9cdfe1808088dcc0d46a16b6d2e9', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encription\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-bug #1316540\n'}, {'number': 9, 'created': '2014-09-08 20:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c0f20465674d47a21423fdbe541af32679a655df', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encription\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-bug #1316540\n'}, {'number': 10, 'created': '2014-09-09 10:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/75ea7e9fe87c7eb8a1780ba159de9cba5a13ccd6', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encription\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-bug #1316540\n'}, {'number': 11, 'created': '2014-09-09 12:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/83842a95c0861b6365602070ccde60a3d4363c0e', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encription\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-Bug #1316540\n'}, {'number': 12, 'created': '2014-09-09 12:23:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0b674a897589cd997ccb5a3ac27d147d1b5e3903', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encription\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-Bug #1316540\n'}, {'number': 13, 'created': '2014-09-09 13:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/21a20c96daf6a016ae3b2d501ccd0c87dc0ab42a', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encryption\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-Bug: #1316540\n'}, {'number': 14, 'created': '2014-09-15 09:24:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/544e0f4347f67becfd6707693a4380a4475e5593', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encryption\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-Bug: #1316540\n'}, {'number': 15, 'created': '2014-09-15 15:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/384fadd666a0953bbb37f1e482fd40d0a87eedbf', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encryption\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-Bug: #1316540\n'}, {'number': 16, 'created': '2014-09-22 08:48:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2ec649fdb2cee91732a0dd36fcd3ec7f9c7655c6', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encryption\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-Bug: #1316540\n'}, {'number': 17, 'created': '2014-10-15 15:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/48da97d7b676b8d3c2951d634f05f9f095b46c24', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encryption\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-Bug: #1316540\n'}, {'number': 18, 'created': '2014-10-24 15:07:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cd31cf12885b84f46c9cbd7056b5ae632e43fe44', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encryption\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-Bug: #1316540\n'}, {'number': 19, 'created': '2014-10-25 09:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/550defbdc1feb7591cf4a5e98bc0c48c3a3064fb', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encryption\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-Bug: #1316540\n'}, {'number': 20, 'created': '2014-10-27 09:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7f896cb546832d281a34006033163a9615c73116', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encryption\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-Bug: #1316540\n'}, {'number': 21, 'created': '2014-10-27 09:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/556d37279cd5854f9b3d3c947442883020024352', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encryption\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-Bug: #1316540\n'}, {'number': 22, 'created': '2014-12-03 13:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a406ea6eba3d988b34e5ff73ff6e283e05b10435', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encryption\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-Bug: #1316540\n'}, {'number': 23, 'created': '2014-12-03 13:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b4bc9df802ed4eacaff17f759c705c5b1f6d7537', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encryption\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-Bug: #1316540\n'}, {'number': 24, 'created': '2014-12-03 14:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a7f232811f597958d402fda21c6197ceb124fdc5', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encryption\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-Bug: #1316540\n'}, {'number': 25, 'created': '2014-12-05 17:50:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/78f020e313ef2f5828786a24da90a6e0c70aa987', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encryption\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-Bug: #1316540\n'}, {'number': 26, 'created': '2014-12-15 12:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/80b54cf432e0ed78b5b6431e81aaab5a64d61dc9', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encryption\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-Bug: #1316540\n'}, {'number': 27, 'created': '2014-12-16 21:21:33.000000000', 'files': ['cinder/tests/test_volume_types.py', 'cinder/db/sqlalchemy/migrate_repo/versions/033_add_encryption_unique_key.py', 'cinder/db/sqlalchemy/api.py', 'cinder/db/sqlalchemy/migrate_repo/versions/033_sqlite_downgrade.sql', 'cinder/tests/test_migrations.py', 'cinder/tests/test_db_api.py', 'cinder/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a21979c1230edb80a08b3bdd6083b2b088cc6aa1', 'message': 'Added UUID as primary key for Encryption model\n\nvolume_type_id could not be used as PK because\nsoft deletes are using for Encryption\n\nChange-Id: I5c4423da4442f2458417dc3492750412a74ebe09\nCloses-Bug: #1316540\n'}]",28,119026,a21979c1230edb80a08b3bdd6083b2b088cc6aa1,184,27,27,1736,,,0,"Added UUID as primary key for Encryption model

volume_type_id could not be used as PK because
soft deletes are using for Encryption

Change-Id: I5c4423da4442f2458417dc3492750412a74ebe09
Closes-Bug: #1316540
",git fetch https://review.opendev.org/openstack/cinder refs/changes/26/119026/16 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/db/sqlalchemy/migrate_repo/versions/027_add_encryption_unique_key.py', 'cinder/db/sqlalchemy/api.py', 'cinder/db/sqlalchemy/models.py']",3,9c1e21dff61b63807bc881ff0f0a9fb5ebfac375,bug/1316540," id = Column(String(36), primary_key=True) ForeignKey('volume_types.id'))"," ForeignKey('volume_types.id'), primary_key=True)",70,2
openstack%2Ffuel-docs~master~Ib3721d72f2630d139448405ecd0b2977b371a2ba,openstack/fuel-docs,master,Ib3721d72f2630d139448405ecd0b2977b371a2ba,Move product description to index.rst from Release Notes,MERGED,2014-11-13 10:46:49.000000000,2014-12-20 00:55:45.000000000,2014-12-20 00:55:45.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9147}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 11548}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-11-13 10:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/97c32e1e20764f45042ee246400da0eac30ac47b', 'message': 'Move product description to index.rst from Release Notes\n\nThis moves the ""What is Mirantis OpenStack"" information from\nthe Release Notes to the index.rst file so it plays out in the\nmain panel of the docs landing page.\nThe content is unmodified.\n\nPlease look at the build results and see what you think.\n\nChange-Id: Ib3721d72f2630d139448405ecd0b2977b371a2ba\n'}, {'number': 2, 'created': '2014-11-15 00:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/0c6f308ca2807bba029c1bc07d5a302c742b0b56', 'message': 'Move product description to index.rst from Release Notes\n\nThis moves the ""What is Mirantis OpenStack"" information from\nthe Release Notes to the index.rst file; it plays out as three\nitems in the main panel of the docs landing page,\neach of which is a link to an article in the Terminology Reference.\n\nPlease look at the build results and see what you think.\nThe ""Support"" link/article is weak -- I need to find a section\nof our web page that describes the support offerings.\n\nThe information is similar to what was in the Release Notes\nbut I made a few modifications to merge info with existing\ninfo in the Terminology Guide.\n\nChange-Id: Ib3721d72f2630d139448405ecd0b2977b371a2ba\n'}, {'number': 3, 'created': '2014-11-26 01:12:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/742b189d29aec272eb3aa19426945f8518994d47', 'message': 'Move product description to index.rst from Release Notes\n\nThis moves the ""What is Mirantis OpenStack"" information from\nthe Release Notes to the index.rst file; it plays out as three\nitems in the main panel of the docs landing page,\ntwo of which are links to articles in the Terminology Reference.\nThe third link is a direct link to the Mirantis ""Support Options"" page.\n\nThe information is similar to what was in the Release Notes\nbut I made a few modifications to merge info with existing\ninfo in the Terminology Guide.\n\nChange-Id: Ib3721d72f2630d139448405ecd0b2977b371a2ba\n'}, {'number': 4, 'created': '2014-12-01 20:27:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4b090891376773bf5b4f329b2d732148c774e45a', 'message': 'Move product description to index.rst from Release Notes\n\nThis moves the ""What is Mirantis OpenStack"" information from\nthe Release Notes to the index.rst file; it plays out as three\nitems in the main panel of the docs landing page,\ntwo of which are links to articles in the Terminology Reference.\nThe third link is a direct link to the Mirantis ""Support Options"" page.\n\nThe information is similar to what was in the Release Notes\nbut I made a few modifications to merge info with existing\ninfo in the Terminology Guide.\n\nChange-Id: Ib3721d72f2630d139448405ecd0b2977b371a2ba\n'}, {'number': 5, 'created': '2014-12-16 03:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/61e92148325fa941f122422b65567857f1ffecee', 'message': 'Move product description to index.rst from Release Notes\n\nThis moves the ""What is Mirantis OpenStack"" information from\nthe Release Notes to the index.rst file; it plays out as three\nitems in the main panel of the docs landing page,\ntwo of which are links to articles in the Terminology Reference.\nThe third link is a direct link to the Mirantis ""Support Options"" page.\n\nThe information is similar to what was in the Release Notes\nbut I made a few modifications to merge info with existing\ninfo in the Terminology Guide.\n\nThe terminology/fuel.rst article now has a paragraph about\nplug-ins.  This needs links to the developer and user docs\nafter that is merged.\n\nChange-Id: Ib3721d72f2630d139448405ecd0b2977b371a2ba\n'}, {'number': 6, 'created': '2014-12-18 10:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/90c2c7e717aea6ec7e92c5b341c4d738c14d1d58', 'message': 'Move product description to index.rst from Release Notes\n\nThis moves the ""What is Mirantis OpenStack"" information from\nthe Release Notes to the index.rst file; it plays out as three\nitems in the main panel of the docs landing page,\nall of which are links to articles in the Terminology Reference\nwith a brief bit of supporting text.\n\nThe information is similar to what was in the Release Notes\nbut I made a few modifications to merge info with existing\ninfo in the Terminology Guide.\n\nThe terminology/fuel.rst article now has a paragraph about\nplug-ins.  This needs links to the developer and user docs\nafter that is merged.\n\nChange-Id: Ib3721d72f2630d139448405ecd0b2977b371a2ba\n'}, {'number': 7, 'created': '2014-12-19 22:27:52.000000000', 'files': ['pages/release-notes/v6-0/0010-what-is-mirantis-openstack.rst', 'pages/terminology/allterms.rst', 'index.rst', 'pages/terminology/h/hardened-packages.rst', 'pages/terminology/f/fuel.rst', 'pages/release-notes/v6-0-juno-full.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/8b2a09b9d1125dfe832b5d83e78b834883bb7393', 'message': 'Move product description to index.rst from Release Notes\n\nThis moves the ""What is Mirantis OpenStack"" information from\nthe Release Notes to the index.rst file; it plays out as three\nitems in the main panel of the docs landing page,\nall of which are links to articles in the Terminology Reference\nwith a brief bit of supporting text.\n\nThe information is similar to what was in the Release Notes\nbut I made a few modifications to merge info with existing\ninfo in the Terminology Guide.\n\nThe terminology/fuel.rst article now has a paragraph about\nplug-ins.  This needs links to the developer and user docs\nafter that is merged.\n\nChange-Id: Ib3721d72f2630d139448405ecd0b2977b371a2ba\n'}]",22,134160,8b2a09b9d1125dfe832b5d83e78b834883bb7393,50,8,7,10014,,,0,"Move product description to index.rst from Release Notes

This moves the ""What is Mirantis OpenStack"" information from
the Release Notes to the index.rst file; it plays out as three
items in the main panel of the docs landing page,
all of which are links to articles in the Terminology Reference
with a brief bit of supporting text.

The information is similar to what was in the Release Notes
but I made a few modifications to merge info with existing
info in the Terminology Guide.

The terminology/fuel.rst article now has a paragraph about
plug-ins.  This needs links to the developer and user docs
after that is merged.

Change-Id: Ib3721d72f2630d139448405ecd0b2977b371a2ba
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/60/134160/5 && git format-patch -1 --stdout FETCH_HEAD,"['pages/release-notes/v6-0/0010-what-is-mirantis-openstack.rst', 'index.rst', 'pages/release-notes/v6-0-juno-full.rst']",3,97c32e1e20764f45042ee246400da0eac30ac47b,60-description-move,,.. include:: /pages/release-notes/v6-0/0010-what-is-mirantis-openstack.rst,65,68
openstack%2Fcinder~master~I64adbca724a52771b68e4838749f8896e6e56019,openstack/cinder,master,I64adbca724a52771b68e4838749f8896e6e56019,Add the StorPool block storage driver.,MERGED,2014-12-05 19:05:39.000000000,2014-12-20 00:54:22.000000000,2014-12-16 22:45:40.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 4355}, {'_account_id': 5997}, {'_account_id': 6043}, {'_account_id': 6491}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12369}, {'_account_id': 12780}, {'_account_id': 12988}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-05 19:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2061c6cc4f2b798041e821e3e86698608a172ffb', 'message': 'Add the StorPool block storage driver.\n\nChange-Id: I64adbca724a52771b68e4838749f8896e6e56019\n'}, {'number': 2, 'created': '2014-12-08 16:36:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cf8862860ad4e58a66a09ff7f83b413a74ccb984', 'message': 'Add the StorPool block storage driver.\n\nChange-Id: I64adbca724a52771b68e4838749f8896e6e56019\n'}, {'number': 3, 'created': '2014-12-10 14:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/75cb4dbdf03a8cfbc645f066d58de0ae39ad8b60', 'message': 'Add the StorPool block storage driver.\n\nChange-Id: I64adbca724a52771b68e4838749f8896e6e56019\nImplements: blueprint storpool-block-driver\n'}, {'number': 4, 'created': '2014-12-11 13:46:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/699f3e9a15f3900d215d740f8eb68bb872b0ae71', 'message': 'Add the StorPool block storage driver.\n\nChange-Id: I64adbca724a52771b68e4838749f8896e6e56019\nImplements: blueprint storpool-block-driver\n'}, {'number': 5, 'created': '2014-12-12 15:58:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d07c42c742ee7fc8f6af4f7d458847ff8bd99214', 'message': 'Add the StorPool block storage driver.\n\nChange-Id: I64adbca724a52771b68e4838749f8896e6e56019\nImplements: blueprint storpool-block-driver\n'}, {'number': 6, 'created': '2014-12-16 00:09:08.000000000', 'files': ['cinder/volume/drivers/storpool.py', 'cinder/tests/test_storpool.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/78f89f5f43a1644f36e62fe7af655c45a6a28fd7', 'message': ""Add the StorPool block storage driver.\n\nStorPool is distributed data storage software running on standard x86\nservers.  StorPool aggregates the performance and capacity of all drives\ninto a shared pool of storage distributed among the servers.  Within\nthis storage pool the user creates thin-provisioned volumes that are\nexposed to the clients as block devices.  StorPool consists of two parts\nwrapped in one package - a server and a client.  The StorPool server\nallows a hypervisor to act as a storage node, while the StorPool client\nallows a hypervisor node to access the storage pool and act as a compute\nnode.  In OpenStack terms the StorPool solution allows each hypervisor\nnode to be both a storage and a compute node simultaneously.\n\nTo make full use of StorPool's native network communication protocol,\nthe Nova compute nodes will need to use the StorPool libvirt volume\nattachment driver, nova.virt.libvirt.storpool.LibvirtStorPoolVolumeDriver.\n\nDocImpact\nChange-Id: I64adbca724a52771b68e4838749f8896e6e56019\nImplements: blueprint storpool-block-driver\n""}]",41,139711,78f89f5f43a1644f36e62fe7af655c45a6a28fd7,69,16,6,12988,,,0,"Add the StorPool block storage driver.

StorPool is distributed data storage software running on standard x86
servers.  StorPool aggregates the performance and capacity of all drives
into a shared pool of storage distributed among the servers.  Within
this storage pool the user creates thin-provisioned volumes that are
exposed to the clients as block devices.  StorPool consists of two parts
wrapped in one package - a server and a client.  The StorPool server
allows a hypervisor to act as a storage node, while the StorPool client
allows a hypervisor node to access the storage pool and act as a compute
node.  In OpenStack terms the StorPool solution allows each hypervisor
node to be both a storage and a compute node simultaneously.

To make full use of StorPool's native network communication protocol,
the Nova compute nodes will need to use the StorPool libvirt volume
attachment driver, nova.virt.libvirt.storpool.LibvirtStorPoolVolumeDriver.

DocImpact
Change-Id: I64adbca724a52771b68e4838749f8896e6e56019
Implements: blueprint storpool-block-driver
",git fetch https://review.opendev.org/openstack/cinder refs/changes/11/139711/6 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/sp.py'],1,2061c6cc4f2b798041e821e3e86698608a172ffb,bp/storpool-block-driver,"""""""StorPool block device driver"""""" from oslo.utils import units from cinder import exception from cinder.image import image_utils from cinder.openstack.common import fileutils from cinder.openstack.common import log as logging from cinder.openstack.common import strutils from cinder.volume import driver from cinder.volume import volume_types LOG = logging.getLogger(__name__) from storpool.spapi import ApiError from storpool.spopenstack import AttachDB from storpool.sptypes import VolumeUpdateDesc class StorPoolDriver(driver.VolumeDriver): """"""The StorPool block device driver using the StorPool API"""""" VERSION = '0.1.0' def __init__(self, *args, **kwargs): super(StorPoolDriver, self).__init__(*args, **kwargs) self._sp_config = None self._ourId = None self._ourIdInt = None self._attach = AttachDB(log=LOG) def _template_from_volume_type(self, vtype): specs = volume_types.get_volume_type_extra_specs(vtype['id']) if specs is None: return None return specs.get('storpool_template', None) def create_volume(self, volume): if int(volume['size']) == 0: size = 100 * units.Mi else: size = int(volume['size']) * units.Gi name = self._attach.volumeName(volume['id']) if volume['volume_type'] is not None: template = self._template_from_volume_type(volume['volume_type']) else: template = None try: if template is None: res = self._attach.api().volumeCreate({ 'name': name, 'size': size, 'replication': 3 }) else: res = self._attach.api().volumeCreate({ 'name': name, 'size': size, 'template': template }) except ApiError as e: raise exception.VolumeBackendAPIException(data=str(e)) def validate_connector(self, connector): pass def initialize_connection(self, volume, connector): return { 'driver_volume_type': 'storpool', 'data': {} } def terminate_connection(self, volume, connector, **kwargs): pass def create_snapshot(self, snapshot): volname = self._attach.volumeName(snapshot['volume_id']) name = self._attach.snapshotName('snap', snapshot['id']) try: res = self._attach.api().snapshotCreate(volname, { 'name': name }) except ApiError as e: raise exception.VolumeBackendAPIException(data=str(e)) def create_volume_from_snapshot(self, volume, snapshot): size = int(volume['size']) if size == 0: size = snapshot['size'] else: size = size * units.Gi volname = self._attach.volumeName(volume['id']) name = self._attach.snapshotName('snap', snapshot['id']) try: res = self._attach.api().volumeCreate({ 'name': volname, 'size': size, 'parent': name }) except ApiError as e: raise exception.VolumeBackendAPIException(data=str(e)) def create_cloned_volume(self, volume, src_vref): refname = self._attach.volumeName(src_vref['id']) snapname = self._attach.snapshotName('clone', volume['id']) try: self._attach.api().snapshotCreate(refname, { 'name': snapname }) except ApiError as e: raise exception.VolumeBackendAPIException(data=str(e)) size = int(volume['size']) if size == 0: size = src_vref['size'] else: size = size * units.Gi volname = self._attach.volumeName(volume['id']) try: self._attach.api().volumeCreate({ 'name': volname, 'size': size, 'parent': snapname }) except ApiError as e: raise exception.VolumeBackendAPIException(data=str(e)) finally: try: self._attach.api().snapshotDelete(snapname) except ApiError as e: # ARGH! LOG.error(""StorPool: could not delete the temporary snapshot {n}: {msg}"".format(n=snapname, msg=str(e))) def create_export(self, context, volume): pass def remove_export(self, context, volume): pass def delete_volume(self, volume): name = self._attach.volumeName(volume['id']) try: self._attach.api().volumesReassign(json=[{ ""volume"": name, ""detach"": ""all"" }]) res = self._attach.api().volumeDelete(name) except ApiError as e: if e.name == 'objectDoesNotExist': pass else: raise exception.VolumeBackendAPIException(data=str(e)) def delete_snapshot(self, snapshot): name = self._attach.snapshotName('snap', snapshot['id']) try: self._attach.api().volumesReassign(json=[{ ""snapshot"": name, ""detach"": ""all"" }]) res = self._attach.api().snapshotDelete(name) except ApiError as e: if e.name == 'objectDoesNotExist': pass else: raise exception.VolumeBackendAPIException(data=str(e)) def check_for_setup_error(self): try: self._attach.api() except Exception as e: LOG.error(""StorPoolDriver API initialization failed: {e}"".format(e=e)) return False return True def get_volume_stats(self, refresh=False): if refresh: self._update_volume_stats() return self._stats def _update_volume_stats(self): try: dl = self._attach.api().disksList() templates = self._attach.api().volumeTemplatesList() except ApiError as e: raise exception.VolumeBackendAPIException(data=str(e)) total = 0 used = 0 free = 0 agSize = 512 * units.Mi for (id, desc) in dl.iteritems(): total += desc.agCount * agSize used += desc.agAllocated * agSize free += desc.agFree * agSize * 4096 / (4096 + 128) # Report the free space as if all new volumes will be created # with StorPool replication 3; anything else is rare. free /= 3 space = { 'total_capacity_gb': total / units.Gi, 'free_capacity_gb': free / units.Gi, 'reserved_percentage': 0, 'QoS_support': False, } pools = [ dict(space, pool_name='default') ] pools += [ dict(space, pool_name='template_' + t.name, storpool_template=t.name) for t in templates ] self._stats = { 'volume_backend_name': self.configuration.safe_get('volume_backend_name') or 'storpool', 'vendor_name': 'StorPool', 'driver_version': self.VERSION, 'storage_protocol': 'storpool', #'location_info': location_info, #'iscsi_target_portal_port': self.iscsi_target_portal_port, #'nms_url': self.nms.url 'pools': pools } def _attach_volume(self, context, volume, properties, remote=False): req_id = context.request_id req = self._attach.get()[req_id] name = req['volume'] self._attach.sync(req_id, None) return { 'device': { 'path': '/dev/storpool/{v}'.format(v=name) } } def _detach_volume(self, context, attach_info, volume, properties, remote=False): req_id = context.request_id req = self._attach.get()[req_id] name = req['volume'] return self._attach.sync(req_id, name) def backup_volume(self, context, backup, backup_service): volume = self.db.volume_get(context, backup['volume_id']) req_id = context.request_id volname = self._attach.volumeName(volume['id']) name = self._attach.volsnapName(volume['id'], req_id) try: res = self._attach.api().snapshotCreate(volname, { 'name': name }) except ApiError as e: raise exception.VolumeBackendAPIException(data=str(e)) self._attach.add(req_id, { 'volume': name, 'type': 'backup', 'id': req_id, 'rights': 1, 'volsnap': True }) try: return super(StorPoolDriver, self).backup_volume(context, backup, backup_service) finally: self._attach.remove(req_id) try: self._attach.api().snapshotDelete(name) except ApiError as e: LOG.error('StorPool: Could not remove the temporary snapshot {n} for volume {v}: {e}'.format(n=name, v=volname, e=str(e))) pass def copy_volume_to_image(self, context, volume, image_service, image_meta): req_id = context.request_id volname = self._attach.volumeName(volume['id']) name = self._attach.volsnapName(volume['id'], req_id) try: res = self._attach.api().snapshotCreate(volname, { 'name': name }) except ApiError as e: raise exception.VolumeBackendAPIException(data=str(e)) self._attach.add(req_id, { 'volume': name, 'type': 'copy-from', 'id': req_id, 'rights': 1, 'volsnap': True }) try: return super(StorPoolDriver, self).copy_volume_to_image(context, volume, image_service, image_meta) finally: self._attach.remove(req_id) try: self._attach.api().snapshotDelete(name) except ApiError as e: LOG.error('StorPool: Could not remove the temporary snapshot {n} for volume {v}: {e}'.format(n=name, v=volname, e=str(e))) pass def copy_image_to_volume(self, context, volume, image_service, image_id): req_id = context.request_id name = self._attach.volumeName(volume['id']) self._attach.add(req_id, { 'volume': name, 'type': 'copy-to', 'id': req_id, 'rights': 2 }) try: return super(StorPoolDriver, self).copy_image_to_volume(context, volume, image_service, image_id) finally: self._attach.remove(req_id) def extend_volume(self, volume, new_size): size = int(new_size) * units.Gi name = self._attach.volumeName(volume['id']) try: self._attach.api().volumeUpdate(name, VolumeUpdateDesc(size=size)) except ApiError as e: raise exception.VolumeBackendAPIException(data=str(e)) ",,262,0
openstack%2Fheat~master~I48846926cc5eb2a1f81db6a2becb310bdf61daa7,openstack/heat,master,I48846926cc5eb2a1f81db6a2becb310bdf61daa7,Remove gettextutils import,MERGED,2014-12-19 14:23:10.000000000,2014-12-20 00:52:27.000000000,2014-12-19 18:06:33.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 8246}, {'_account_id': 13009}, {'_account_id': 13323}]","[{'number': 1, 'created': '2014-12-19 14:23:10.000000000', 'files': ['heat/openstack/common/config/generator.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/213ed63a240e04cdbf757a7379a69b47452113b6', 'message': 'Remove gettextutils import\n\nChange-Id: I48846926cc5eb2a1f81db6a2becb310bdf61daa7\nCloses-Bug: #1404206\n'}]",0,143096,213ed63a240e04cdbf757a7379a69b47452113b6,14,6,1,13323,,,0,"Remove gettextutils import

Change-Id: I48846926cc5eb2a1f81db6a2becb310bdf61daa7
Closes-Bug: #1404206
",git fetch https://review.opendev.org/openstack/heat refs/changes/96/143096/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/openstack/common/config/generator.py'],1,213ed63a240e04cdbf757a7379a69b47452113b6,bug/1404206,,from heat.openstack.common import gettextutilsgettextutils.install('heat') ,0,3
openstack%2Fnova~master~I35104852797dcba4594af4361bf9226e16bfb114,openstack/nova,master,I35104852797dcba4594af4361bf9226e16bfb114,Expand valid resource name character set,MERGED,2014-09-08 12:09:07.000000000,2014-12-20 00:46:35.000000000,2014-12-20 00:46:32.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11748}, {'_account_id': 11929}]","[{'number': 1, 'created': '2014-09-08 12:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c01e60ebe527ed36d57f8e7b6ec50a01060c2e49', 'message': 'Expand valid flavor name character set\n\nThis allows all printable unicode characters and horizontal whitespace\ncharacters in flavor names, as opposed to the rather limited set that\nwas previously available.\n\nCloses-Bug: 1366778\nChange-Id: I35104852797dcba4594af4361bf9226e16bfb114\n'}, {'number': 2, 'created': '2014-09-08 14:51:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8cd7f08e595d190f255cafbc43a94abd4269d514', 'message': 'Expand valid flavor name character set\n\nThis allows all printable unicode characters and horizontal whitespace\ncharacters in flavor names, as opposed to the rather limited set that\nwas previously available.\n\nCloses-Bug: 1366778\nChange-Id: I35104852797dcba4594af4361bf9226e16bfb114\n'}, {'number': 3, 'created': '2014-09-10 13:21:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/57db27171e680c1ca94fb348786a07278068392f', 'message': 'Expand valid resource name character set\n\nThis allows all printable unicode characters and horizontal whitespace\ncharacters in resource names (flavors, aggregates, cells, etc.), as\nopposed to the rather limited set that was previously available.\n\nCloses-Bug: 1366778\nChange-Id: I35104852797dcba4594af4361bf9226e16bfb114\n'}, {'number': 4, 'created': '2014-09-16 13:25:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f8a8350dbbdc0adbcceda58e1eff6d190a84d30', 'message': 'Expand valid resource name character set\n\nThis allows all printable unicode characters and horizontal whitespace\ncharacters in resource names (flavors, aggregates, cells, etc.), as\nopposed to the rather limited set that was previously available. This\nfollows the principle of not creating unnecessary restrictions.\n\nCloses-Bug: 1366778\nChange-Id: I35104852797dcba4594af4361bf9226e16bfb114\n'}, {'number': 5, 'created': '2014-09-16 20:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d8f57e6b7a38927a90a39a583b2413e75daa3098', 'message': 'Expand valid resource name character set\n\nThis allows all printable unicode characters and horizontal whitespace\ncharacters in resource names (flavors, aggregates, cells, etc.), as\nopposed to the rather limited set that was previously available. This\nfollows the principle of not creating unnecessary restrictions.\n\nCloses-Bug: 1366778\nChange-Id: I35104852797dcba4594af4361bf9226e16bfb114\n'}, {'number': 6, 'created': '2014-12-15 17:41:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd5b2c7a268dd37c6797793277fdae551455d185', 'message': 'Expand valid resource name character set\n\nThis allows all printable unicode characters and horizontal whitespace\ncharacters in resource names (flavors, aggregates, cells, etc.), as\nopposed to the rather limited set that was previously available. This\nfollows the principle of not creating unnecessary restrictions.\n\nImplements: blueprint relax-resource-name-restrictions\nCloses-Bug: 1366778\nChange-Id: I35104852797dcba4594af4361bf9226e16bfb114\n'}, {'number': 7, 'created': '2014-12-17 14:03:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6fae5d4f53d97ea76a99d7eb577e4ab0039d4e2d', 'message': 'Expand valid resource name character set\n\nThis allows all printable unicode characters and horizontal whitespace\ncharacters in resource names (flavors, aggregates, cells, etc.), as\nopposed to the rather limited set that was previously available. This\nfollows the principle of not creating unnecessary restrictions.\n\nImplements: blueprint relax-resource-name-restrictions\nCloses-Bug: 1366778\nChange-Id: I35104852797dcba4594af4361bf9226e16bfb114\n'}, {'number': 8, 'created': '2014-12-18 12:50:43.000000000', 'files': ['nova/api/openstack/compute/schemas/v3/servers.py', 'nova/tests/unit/api/openstack/compute/contrib/test_cells.py', 'nova/tests/unit/api/openstack/compute/contrib/test_flavor_manage.py', 'nova/compute/flavors.py', 'nova/api/validation/parameter_types.py', 'nova/tests/unit/test_api_validation.py', 'nova/tests/unit/test_flavors.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f40b6a1d5c91628f78fdbc0417a3a394a69ab716', 'message': 'Expand valid resource name character set\n\nThis allows all printable unicode characters and horizontal whitespace\ncharacters in resource names (flavors, aggregates, cells, etc.), as\nopposed to the rather limited set that was previously available. This\nfollows the principle of not creating unnecessary restrictions.\n\nImplements: blueprint relax-resource-name-restrictions\nCloses-Bug: 1366778\nChange-Id: I35104852797dcba4594af4361bf9226e16bfb114\n'}]",14,119741,f40b6a1d5c91628f78fdbc0417a3a394a69ab716,87,16,8,11748,,,0,"Expand valid resource name character set

This allows all printable unicode characters and horizontal whitespace
characters in resource names (flavors, aggregates, cells, etc.), as
opposed to the rather limited set that was previously available. This
follows the principle of not creating unnecessary restrictions.

Implements: blueprint relax-resource-name-restrictions
Closes-Bug: 1366778
Change-Id: I35104852797dcba4594af4361bf9226e16bfb114
",git fetch https://review.opendev.org/openstack/nova refs/changes/41/119741/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/flavors.py'],1,c01e60ebe527ed36d57f8e7b6ec50a01060c2e49,bug/1366778,"import unicodedata def is_printable(char): """"""determine if a unicode code point is printable. This checks if the character is either ""other"" (mostly control codes), or a non-horizontal space. All characters that don't match those criteria are considered printable; that is: letters; combining marks; numbers; punctuation; symbols; (horizontal) space separators. """""" category = unicodedata.category(char) return (not category.startswith(""C"") and (not category.startswith(""Z"") or category == ""Zs"")) # determine if this is a narrow build or wide build (or py3k) try: unichr(0x10000) MAX_CHAR = 0x110000 except ValueError: MAX_CHAR = 0x9999 # build a regex that matches all printable characters all_chars = (unichr(i) for i in xrange(MAX_CHAR)) printable = ''.join(c for c in all_chars if is_printable(c)) VALID_NAME_REGEX = re.compile('^[%s]*$' % printable, re.UNICODE) msg = _(""Flavor names can only contain printable characters "" ""and horizontal spaces."")","VALID_NAME_REGEX = re.compile(""^[\w\.\- ]*$"", re.UNICODE) msg = _(""Flavor names can only contain alphanumeric characters, "" ""periods, dashes, underscores and spaces."")",31,3
openstack%2Fheat~master~I7c12c055924e7a16a5b9cc573d91c12089a2395d,openstack/heat,master,I7c12c055924e7a16a5b9cc573d91c12089a2395d,Fix doc generation for Rackspace::Cloud::Network,MERGED,2014-12-18 14:14:02.000000000,2014-12-20 00:46:21.000000000,2014-12-20 00:46:21.000000000,"[{'_account_id': 3}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 9189}]","[{'number': 1, 'created': '2014-12-18 14:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2e657f01c31029e0500f6a1e26ad2d60ab6a0570', 'message': 'Fix doc generation for Rackspace::Cloud::Network\n\nSince contrib plugins may not be installed at the time the docs are\ngenerated, the resource_mapping function needs to return all resource\ntypes defined by the resource module.  To selectively load such resource\ntypes - based on requirements being met, for instance, the\navailable_resource_mapping function should be used instead.\n\nThis makes the necessary changes to Rackspace::Cloud::Network so that\nits docs are generated correctly.\n\nRelated-Bug: 1403897\nChange-Id: I7c12c055924e7a16a5b9cc573d91c12089a2395d\n'}, {'number': 2, 'created': '2014-12-19 15:08:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/74b79778ec67217f04430b2c4e9dcd0d52cfacd2', 'message': 'Fix doc generation for Rackspace::Cloud::Network\n\nSince contrib plugins may not be installed at the time the docs are\ngenerated, the resource_mapping function needs to return all resource\ntypes defined by the resource module.  To selectively load such resource\ntypes - based on requirements being met, for instance, the\navailable_resource_mapping function should be used instead.\n\nThis makes the necessary changes to Rackspace::Cloud::Network so that\nits docs are generated correctly.\n\nRelated-Bug: 1403897\nChange-Id: I7c12c055924e7a16a5b9cc573d91c12089a2395d\n'}, {'number': 3, 'created': '2014-12-19 16:31:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/af9f0bcf905aa1f81166f5b1ed7210cd867c8c0f', 'message': 'Fix doc generation for Rackspace::Cloud::Network\n\nSince contrib plugins may not be installed at the time the docs are\ngenerated, the resource_mapping function needs to return all resource\ntypes defined by the resource module.  To selectively load such resource\ntypes - based on requirements being met, for instance, the\navailable_resource_mapping function should be used instead.\n\nThis makes the necessary changes to Rackspace::Cloud::Network so that\nits docs are generated correctly.\n\nRelated-Bug: 1403897\nChange-Id: I7c12c055924e7a16a5b9cc573d91c12089a2395d\n'}, {'number': 4, 'created': '2014-12-19 19:18:50.000000000', 'files': ['contrib/rackspace/rackspace/resources/cloudnetworks.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/973b7ea6b747c5a8b7e5b5511ea350448625a7f6', 'message': 'Fix doc generation for Rackspace::Cloud::Network\n\nSince contrib plugins may not be installed at the time the docs are\ngenerated, the resource_mapping function needs to return all resource\ntypes defined by the resource module.  To selectively load such resource\ntypes - based on requirements being met, for instance, the\navailable_resource_mapping function should be used instead.\n\nThis makes the necessary changes to Rackspace::Cloud::Network so that\nits docs are generated correctly.\n\nRelated-Bug: 1403897\nChange-Id: I7c12c055924e7a16a5b9cc573d91c12089a2395d\n'}]",0,142795,973b7ea6b747c5a8b7e5b5511ea350448625a7f6,24,4,4,9189,,,0,"Fix doc generation for Rackspace::Cloud::Network

Since contrib plugins may not be installed at the time the docs are
generated, the resource_mapping function needs to return all resource
types defined by the resource module.  To selectively load such resource
types - based on requirements being met, for instance, the
available_resource_mapping function should be used instead.

This makes the necessary changes to Rackspace::Cloud::Network so that
its docs are generated correctly.

Related-Bug: 1403897
Change-Id: I7c12c055924e7a16a5b9cc573d91c12089a2395d
",git fetch https://review.opendev.org/openstack/heat refs/changes/95/142795/4 && git format-patch -1 --stdout FETCH_HEAD,['contrib/rackspace/rackspace/resources/cloudnetworks.py'],1,2e657f01c31029e0500f6a1e26ad2d60ab6a0570,bug/1403897, PYRAX_INSTALLED = True except ImportError: PYRAX_INSTALLED = False def resource_mapping(): return {'Rackspace::Cloud::Network': CloudNetwork} def available_resource_mapping(): if PYRAX_INSTALLED: return resource_mapping() return {},except ImportError: def resource_mapping(): return {} else: def resource_mapping(): return {'Rackspace::Cloud::Network': CloudNetwork},12,6
openstack%2Fheat~master~I0163bc7f83e00f9077fc78e638173df2124580dd,openstack/heat,master,I0163bc7f83e00f9077fc78e638173df2124580dd,Remove warnings when generating docs,MERGED,2014-12-18 14:14:02.000000000,2014-12-20 00:46:13.000000000,2014-12-20 00:46:12.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 9189}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-18 14:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5d8d114e5ec8d7a797a8fda5cf69f64030b79dd4', 'message': 'Remove warnings when generating docs\n\nImprove docstrings so that syntax warnings are no longer displayed when\ngenerating docs.\n\nRelated-Bug: 1403897\nChange-Id: I0163bc7f83e00f9077fc78e638173df2124580dd\n'}, {'number': 2, 'created': '2014-12-19 15:08:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/772ea609865af30cdf1b6c420553d16cec1c9a01', 'message': 'Remove warnings when generating docs\n\nImprove docstrings so that syntax warnings are no longer displayed when\ngenerating docs.\n\nRelated-Bug: 1403897\nChange-Id: I0163bc7f83e00f9077fc78e638173df2124580dd\n'}, {'number': 3, 'created': '2014-12-19 16:31:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5271334b6591fb93419e2a7e5c54b5b8479e9dce', 'message': 'Remove warnings when generating docs\n\nImprove docstrings so that syntax warnings are no longer displayed when\ngenerating docs.\n\nRelated-Bug: 1403897\nChange-Id: I0163bc7f83e00f9077fc78e638173df2124580dd\n'}, {'number': 4, 'created': '2014-12-19 19:16:54.000000000', 'files': ['doc/source/template_guide/hot_spec.rst', 'heat/engine/stack_resource.py', 'heat/engine/properties.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/c7627822847f9c5a45ea0d0a30e91347df6a9a5e', 'message': 'Remove warnings when generating docs\n\nImprove docstrings so that syntax warnings are no longer displayed when\ngenerating docs.\n\nRelated-Bug: 1403897\nChange-Id: I0163bc7f83e00f9077fc78e638173df2124580dd\n'}]",2,142794,c7627822847f9c5a45ea0d0a30e91347df6a9a5e,27,6,4,9189,,,0,"Remove warnings when generating docs

Improve docstrings so that syntax warnings are no longer displayed when
generating docs.

Related-Bug: 1403897
Change-Id: I0163bc7f83e00f9077fc78e638173df2124580dd
",git fetch https://review.opendev.org/openstack/heat refs/changes/94/142794/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/template_guide/hot_spec.rst', 'heat/engine/stack_resource.py', 'heat/engine/properties.py']",3,5d8d114e5ec8d7a797a8fda5cf69f64030b79dd4,bug/1403897," ex: input: {'foo': {'Type': 'List'}} output: {'foo': {'Type': 'CommaDelimitedList'}}, {'foo': {'Fn::Split': {'Ref': 'foo'}}} ex: input: {'foo': {'Type': 'String'}, 'bar': {'Type': 'Map'}} output: {'foo': {'Type': 'String'} 'bar': {'Type': 'Json'}}, {'foo': {'Ref': 'foo'}, 'bar': {'Ref': 'bar'}}"," ex: input: {'foo': {'Type': 'String'}} output: {'foo': {'Type': 'String'}}, {'foo': {'Ref': 'foo'}} ex: input: {'foo': {'Type': 'List'}, 'bar': {'Type': 'Map'}} output: {'foo': {'Type': 'CommaDelimitedList'} 'bar': {'Type': 'Json'}}, {'foo': {'Fn::Split': {'Ref': 'foo'}}, 'bar': {'Ref': 'bar'}} ",9,12
openstack%2Fkeystone~master~I8330f0dca0d6c1db601ddecd71c6c92cef260c99,openstack/keystone,master,I8330f0dca0d6c1db601ddecd71c6c92cef260c99,Be more precise with flake8 filename matches,MERGED,2014-12-19 18:01:33.000000000,2014-12-20 00:46:04.000000000,2014-12-20 00:46:03.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6482}]","[{'number': 1, 'created': '2014-12-19 18:01:33.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/c7451d7b554ffd152996d4ad972b0183578ef1c4', 'message': 'Be more precise with flake8 filename matches\n\nIn upcoming patchsets I\'ll be introducing filenames that include\n""keystone-"" as part of the name. These filenames should not be checked\nwith flake8 because they do not contain Python code.\n\nbp functional-testing\n\nChange-Id: I8330f0dca0d6c1db601ddecd71c6c92cef260c99\n'}]",0,143149,c7451d7b554ffd152996d4ad972b0183578ef1c4,8,3,1,7725,,,0,"Be more precise with flake8 filename matches

In upcoming patchsets I'll be introducing filenames that include
""keystone-"" as part of the name. These filenames should not be checked
with flake8 because they do not contain Python code.

bp functional-testing

Change-Id: I8330f0dca0d6c1db601ddecd71c6c92cef260c99
",git fetch https://review.opendev.org/openstack/keystone refs/changes/49/143149/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,c7451d7b554ffd152996d4ad972b0183578ef1c4,functonal-testing,"filename= *.py,keystone-all,keystone-manage","filename= *.py,keystone-*",1,1
openstack%2Fcinder~master~Ic162a1a469e85fa36501d4de245fe16738d3aefa,openstack/cinder,master,Ic162a1a469e85fa36501d4de245fe16738d3aefa,Fix 3PAR driver hang on SSH calls,MERGED,2014-12-15 23:31:07.000000000,2014-12-20 00:30:40.000000000,2014-12-17 07:02:11.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 6043}, {'_account_id': 7198}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 11903}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12370}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-15 23:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/091397f67fde6cfa8176a4e55ac779399c847ffe', 'message': 'Fix 3PAR driver hang on SSH calls\n\nIn removing the 3PAR driver local file locks, part of the fix included\nmaking a new SSH connection for each call in the hp3parclient as\noppose to leaving a connection open. Older hp3parclients(3.1.1 and\nlater) will result in the SSH calls hanging at driver initilization time.\n\nThis patch will now check against the correct minimum hp3parclient version\nand remove the need for checking of the SSH args version since the minimum\nhp3parclient is now greater than 3.1.1\nCloses-Bug: #1402115\n\nChange-Id: Ic162a1a469e85fa36501d4de245fe16738d3aefa\n'}, {'number': 2, 'created': '2014-12-16 18:13:09.000000000', 'files': ['cinder/tests/fake_hp_3par_client.py', 'cinder/tests/test_hp3par.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3f9770d2c0fd76070214ca85e0dd81b9f1924011', 'message': 'Fix 3PAR driver hang on SSH calls\n\nIn removing the 3PAR driver local file locks, part of the fix included\nmaking a new SSH connection for each call in the hp3parclient as\noppose to leaving a connection open. Older hp3parclients(3.1.1 and\nlater) will result in the SSH calls hanging at driver initilization time.\n\nThis patch will now check against the correct minimum hp3parclient version\nand remove the need for checking of the SSH args version since the minimum\nhp3parclient is now greater than 3.1.1\nCloses-Bug: #1402115\n\nChange-Id: Ic162a1a469e85fa36501d4de245fe16738d3aefa\n'}]",0,141937,3f9770d2c0fd76070214ca85e0dd81b9f1924011,21,12,2,6043,,,0,"Fix 3PAR driver hang on SSH calls

In removing the 3PAR driver local file locks, part of the fix included
making a new SSH connection for each call in the hp3parclient as
oppose to leaving a connection open. Older hp3parclients(3.1.1 and
later) will result in the SSH calls hanging at driver initilization time.

This patch will now check against the correct minimum hp3parclient version
and remove the need for checking of the SSH args version since the minimum
hp3parclient is now greater than 3.1.1
Closes-Bug: #1402115

Change-Id: Ic162a1a469e85fa36501d4de245fe16738d3aefa
",git fetch https://review.opendev.org/openstack/cinder refs/changes/37/141937/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/fake_hp_3par_client.py', 'cinder/tests/test_hp3par.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py']",3,091397f67fde6cfa8176a4e55ac779399c847ffe,bug/1402115,"MIN_CLIENT_VERSION = '3.1.2' 2.0.30 - Update the minimum hp3parclient version bug #1402115 VERSION = ""2.0.30"" known_hosts_file = CONF.ssh_hosts_key_file policy = ""AutoAddPolicy"" if CONF.strict_ssh_host_key_policy: policy = ""RejectPolicy"" self.client.setSSHOptions( self.config.san_ip, self.config.san_login, self.config.san_password, port=self.config.san_ssh_port, conn_timeout=self.config.ssh_conn_timeout, privatekey=self.config.san_private_key, missing_key_policy=policy, known_hosts_file=known_hosts_file)","MIN_CLIENT_VERSION = '3.1.0' MIN_CLIENT_SSH_ARGS_VERSION = '3.1.1' VERSION = ""2.0.29"" client_version = hp3parclient.version if client_version < MIN_CLIENT_SSH_ARGS_VERSION: self.client.setSSHOptions( self.config.san_ip, self.config.san_login, self.config.san_password, port=self.config.san_ssh_port, conn_timeout=self.config.ssh_conn_timeout, privatekey=self.config.san_private_key) else: known_hosts_file = CONF.ssh_hosts_key_file policy = ""AutoAddPolicy"" if CONF.strict_ssh_host_key_policy: policy = ""RejectPolicy"" self.client.setSSHOptions( self.config.san_ip, self.config.san_login, self.config.san_password, port=self.config.san_ssh_port, conn_timeout=self.config.ssh_conn_timeout, privatekey=self.config.san_private_key, missing_key_policy=policy, known_hosts_file=known_hosts_file)",22,43
openstack%2Ftaskflow~master~I701a8acdb21de29a9c2d193d906e9f0e4ada3328,openstack/taskflow,master,I701a8acdb21de29a9c2d193d906e9f0e4ada3328,Standardize bases in the pluggable modules,ABANDONED,2014-12-05 22:40:02.000000000,2014-12-20 00:22:34.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-05 22:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/244d85c89c6175404973f9b2e398e191088a7dec', 'message': 'Standardize bases in the [engine, persistence] modules\n\nJust like the other pluggables [jobs, conductors] we should\ntry to have the base class for the [persistence, engine]\npluggables to follow the pattern the other pluggable entities\nfollow (for uniformity and ease of understanding).\n\nThis renames the persistence.backends.base for to\npersistence.backend and in the engines.base to engines.engine to\nprovide a more meaningful and descriptive name of what the module\nis used for.\n\nChange-Id: I701a8acdb21de29a9c2d193d906e9f0e4ada3328\n'}, {'number': 2, 'created': '2014-12-06 04:07:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6feaaf209a6bdafb3b35cc3e8f266c2a9d0a90f7', 'message': 'Standardize bases in the pluggable modules\n\nJust like the other pluggables [jobs, conductors, ...] we should\ntry to have the base class for the [persistence, engine] pluggables\nto follow the pattern the other pluggable entities follow (for\nuniformity and ease of understanding).\n\nBreaking change: This renames the persistence.backends.base to\npersistence.base so the persistence backends follow the same\npattern as in other pluggables.\n\nBreaking change: This renames the jobs.jobboard to jobs.base so\nthat the jobs backends follow the same pattern as in other\npluggables.\n\nChange-Id: I701a8acdb21de29a9c2d193d906e9f0e4ada3328\n'}, {'number': 3, 'created': '2014-12-06 04:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3edfd23b0fdc35079f0ea1464d31736fa3dec94a', 'message': 'Standardize bases in the pluggable modules\n\nJust like the other pluggables [jobs, conductors, ...] we should\ntry to have the base class for the [persistence, engine] pluggables\nto follow the pattern the other pluggable entities follow (for\nuniformity and ease of understanding).\n\nBreaking change: This renames the persistence.backends.base to\npersistence.base so the persistence backends follow the same\npattern as in other pluggables.\n\nBreaking change: This renames the jobs.jobboard to jobs.base so\nthat the jobs backends follow the same pattern as in other\npluggables.\n\nChange-Id: I701a8acdb21de29a9c2d193d906e9f0e4ada3328\n'}, {'number': 4, 'created': '2014-12-08 18:53:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a78d3fb434554e098f96c7bd189ad1593c8deda3', 'message': 'Standardize bases in the pluggable modules\n\nJust like the other pluggables [jobs, conductors, ...] we should\ntry to have the base class for the [persistence, engine] pluggables\nto follow the pattern the other pluggable entities follow (for\nuniformity and ease of understanding).\n\nBreaking change: This renames the persistence.backends.base to\npersistence.base so the persistence backends follow the same\npattern as in other pluggables.\n\nBreaking change: This renames the jobs.jobboard to jobs.base so\nthat the jobs backends follow the same pattern as in other\npluggables.\n\nChange-Id: I701a8acdb21de29a9c2d193d906e9f0e4ada3328\n'}, {'number': 5, 'created': '2014-12-08 19:55:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/98e3697f5ad2fee135f6b1d3f516316fa9f36039', 'message': 'Standardize bases in the pluggable modules\n\nJust like the other pluggables [jobs, conductors, ...] we should\ntry to have the base class for the [persistence, engine] pluggables\nto follow the pattern the other pluggable entities follow (for\nuniformity and ease of understanding).\n\nBreaking change: This renames the persistence.backends.base to\npersistence.base so the persistence backends follow the same\npattern as in other pluggables.\n\nBreaking change: This renames the jobs.jobboard to jobs.base so\nthat the jobs backends follow the same pattern as in other\npluggables.\n\nChange-Id: I701a8acdb21de29a9c2d193d906e9f0e4ada3328\n'}, {'number': 6, 'created': '2014-12-08 23:01:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/17db17548fd61333db19b0ac6c22ed0223bc2f60', 'message': 'Standardize bases in the pluggable modules\n\nJust like the other pluggables [jobs, conductors, ...] we should\ntry to have the base class for the [persistence, engine] pluggables\nto follow the pattern the other pluggable entities follow (for\nuniformity and ease of understanding).\n\nBreaking change: This renames the persistence.backends.base to\npersistence.base so the persistence backends follow the same\npattern as in other pluggables.\n\nBreaking change: This renames the jobs.jobboard to jobs.base so\nthat the jobs backends follow the same pattern as in other\npluggables.\n\nChange-Id: I701a8acdb21de29a9c2d193d906e9f0e4ada3328\n'}, {'number': 7, 'created': '2014-12-11 04:09:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9d359620bc3155eef3cfff5269c6ac434b58cac8', 'message': 'Standardize bases in the pluggable modules\n\nJust like the other pluggables [jobs, conductors, ...] we should\ntry to have the base class for the [persistence, engine] pluggables\nto follow the pattern the other pluggable entities follow (for\nuniformity and ease of understanding).\n\nBreaking change: This renames the persistence.backends.base to\npersistence.base so the persistence backends follow the same\npattern as in other pluggables.\n\nBreaking change: This renames the jobs.jobboard to jobs.base so\nthat the jobs backends follow the same pattern as in other\npluggables.\n\nChange-Id: I701a8acdb21de29a9c2d193d906e9f0e4ada3328\n'}, {'number': 8, 'created': '2014-12-11 21:02:23.000000000', 'files': ['taskflow/engines/base.py', 'taskflow/persistence/base.py', 'taskflow/listeners/timing.py', 'taskflow/jobs/backends/impl_zookeeper.py', 'doc/source/jobs.rst', 'taskflow/persistence/backends/impl_sqlalchemy.py', 'taskflow/listeners/base.py', 'doc/source/persistence.rst', 'taskflow/persistence/backends/impl_zookeeper.py', 'taskflow/persistence/backends/impl_memory.py', 'taskflow/jobs/base.py', 'doc/source/conductors.rst', 'taskflow/persistence/backends/impl_dir.py', 'taskflow/listeners/claims.py', 'taskflow/tests/unit/conductor/test_blocking.py', 'taskflow/listeners/logging.py', 'taskflow/listeners/printing.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/33f99d8e0f56c2da828e53beb14d35793197dcee', 'message': 'Standardize bases in the pluggable modules\n\nJust like the other pluggables [jobs, conductors, ...] we should\ntry to have the base class for the [persistence, engine] pluggables\nto follow the pattern the other pluggable entities follow (for\nuniformity and ease of understanding).\n\nBreaking change: This renames the persistence.backends.base to\npersistence.base so the persistence backends follow the same\npattern as in other pluggables.\n\nBreaking change: This renames the jobs.jobboard to jobs.base so\nthat the jobs backends follow the same pattern as in other\npluggables.\n\nChange-Id: I701a8acdb21de29a9c2d193d906e9f0e4ada3328\n'}]",0,139741,33f99d8e0f56c2da828e53beb14d35793197dcee,24,2,8,1297,,,0,"Standardize bases in the pluggable modules

Just like the other pluggables [jobs, conductors, ...] we should
try to have the base class for the [persistence, engine] pluggables
to follow the pattern the other pluggable entities follow (for
uniformity and ease of understanding).

Breaking change: This renames the persistence.backends.base to
persistence.base so the persistence backends follow the same
pattern as in other pluggables.

Breaking change: This renames the jobs.jobboard to jobs.base so
that the jobs backends follow the same pattern as in other
pluggables.

Change-Id: I701a8acdb21de29a9c2d193d906e9f0e4ada3328
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/41/139741/8 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/persistence/backends/impl_zookeeper.py', 'taskflow/engines/action_engine/engine.py', 'taskflow/persistence/backends/impl_memory.py', 'taskflow/persistence/backend.py', 'taskflow/persistence/backends/impl_dir.py', 'taskflow/persistence/backends/impl_sqlalchemy.py', 'taskflow/engines/engine.py']",7,244d85c89c6175404973f9b2e398e191088a7dec,uniformity,class Engine(object):,class EngineBase(object):,7,7
openstack%2Fcinder~master~I8a78e051e946f4cad7ec4b26d1a590a7e97cb613,openstack/cinder,master,I8a78e051e946f4cad7ec4b26d1a590a7e97cb613,Remove commented out code from cinder/test.py,MERGED,2014-12-15 21:12:29.000000000,2014-12-19 23:55:06.000000000,2014-12-16 22:11:50.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 7198}, {'_account_id': 10621}, {'_account_id': 11079}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-15 21:12:29.000000000', 'files': ['cinder/test.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d794477ccd4c50d1a91da50d8941b515905f6030', 'message': 'Remove commented out code from cinder/test.py\n\nThere was a line of code left from previous development that\nwas left commented out.  This change removes the unnecessary\nline of code.\n\nChange-Id: I8a78e051e946f4cad7ec4b26d1a590a7e97cb613\n'}]",0,141904,d794477ccd4c50d1a91da50d8941b515905f6030,15,8,1,7198,,,0,"Remove commented out code from cinder/test.py

There was a line of code left from previous development that
was left commented out.  This change removes the unnecessary
line of code.

Change-Id: I8a78e051e946f4cad7ec4b26d1a590a7e97cb613
",git fetch https://review.opendev.org/openstack/cinder refs/changes/04/141904/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/test.py'],1,d794477ccd4c50d1a91da50d8941b515905f6030,remove_commented_code_test,,# self.post_migrations(),0,1
openstack%2Fneutron-lbaas~master~I07d9023ef08b03ed7e34ab5f1f5704b17d2eda16,openstack/neutron-lbaas,master,I07d9023ef08b03ed7e34ab5f1f5704b17d2eda16,Bump global requirements,ABANDONED,2014-12-15 23:14:33.000000000,2014-12-19 23:54:32.000000000,,"[{'_account_id': 3}, {'_account_id': 6951}, {'_account_id': 10980}, {'_account_id': 13438}]","[{'number': 1, 'created': '2014-12-15 23:14:33.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/b357008581d0ffe466aae135a9543b420d153fec', 'message': 'Bump global requirements\n\nChange-Id: I07d9023ef08b03ed7e34ab5f1f5704b17d2eda16\n'}]",0,141934,b357008581d0ffe466aae135a9543b420d153fec,13,4,1,10980,,,0,"Bump global requirements

Change-Id: I07d9023ef08b03ed7e34ab5f1f5704b17d2eda16
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/34/141934/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,b357008581d0ffe466aae135a9543b420d153fec,req,"SQLAlchemy>=0.9.7,<=0.9.99oslo.utils>=1.1.0 # Apache-2.0","SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99oslo.utils>=1.0.0 # Apache-2.0",2,2
openstack%2Fkeystone~master~I542cae190845cbb98c030423aa6e2a747dc07263,openstack/keystone,master,I542cae190845cbb98c030423aa6e2a747dc07263,Use bashate to run_tests.sh,MERGED,2014-12-19 18:01:33.000000000,2014-12-19 23:45:44.000000000,2014-12-19 23:45:43.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6482}]","[{'number': 1, 'created': '2014-12-19 18:01:33.000000000', 'files': ['run_tests.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/e00db6a064cae6a7bedc05fd9b447dea3904c33b', 'message': 'Use bashate to run_tests.sh\n\nChange-Id: I542cae190845cbb98c030423aa6e2a747dc07263\n'}]",0,143148,e00db6a064cae6a7bedc05fd9b447dea3904c33b,8,3,1,7725,,,0,"Use bashate to run_tests.sh

Change-Id: I542cae190845cbb98c030423aa6e2a747dc07263
",git fetch https://review.opendev.org/openstack/keystone refs/changes/48/143148/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'tox.ini']",2,e00db6a064cae6a7bedc05fd9b447dea3904c33b,functonal-testing, bashate run_tests.sh examples/pki/gen_pki.sh, bashate examples/pki/gen_pki.sh,81,83
openstack%2Fcinder~master~I75e7c8829153e10b81d2ce5dbfca84fdde14a3ff,openstack/cinder,master,I75e7c8829153e10b81d2ce5dbfca84fdde14a3ff,Update global requirements,MERGED,2014-12-15 21:42:04.000000000,2014-12-19 23:43:05.000000000,2014-12-18 04:22:26.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 6491}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-15 21:42:04.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/10c63e4c9296e28a3da863e04deca8442418bf81', 'message': 'Update global requirements\n\nManual push to sync global req.  Just need the setuptools\npin, further detail here: http://goo.gl/c9RmSE\n\nChange-Id: I75e7c8829153e10b81d2ce5dbfca84fdde14a3ff\n'}]",0,141909,10c63e4c9296e28a3da863e04deca8442418bf81,17,8,1,2243,,,0,"Update global requirements

Manual push to sync global req.  Just need the setuptools
pin, further detail here: http://goo.gl/c9RmSE

Change-Id: I75e7c8829153e10b81d2ce5dbfca84fdde14a3ff
",git fetch https://review.opendev.org/openstack/cinder refs/changes/09/141909/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,10c63e4c9296e28a3da863e04deca8442418bf81,update_global_reqs,oslo.utils>=1.1.0 # Apache-2.0python-glanceclient>=0.15.0,oslo.utils>=1.0.0 # Apache-2.0python-glanceclient>=0.14.0,2,2
openstack%2Fopenstack-ansible~stable%2Ficehouse~I5f75c609b1f02be5a1428d98c8af5551c4d3fc9f,openstack/openstack-ansible,stable/icehouse,I5f75c609b1f02be5a1428d98c8af5551c4d3fc9f,Updates for release tag 9.0.5,MERGED,2014-12-19 22:10:28.000000000,2014-12-19 23:01:15.000000000,2014-12-19 22:11:40.000000000,"[{'_account_id': 3}, {'_account_id': 7414}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-19 22:10:28.000000000', 'files': ['etc/rpc_deploy/user_variables.yml', 'rpc_deployment/inventory/group_vars/all.yml', 'rpc_deployment/vars/repo_packages/raxmon.yml', 'scripts/cloudserver-aio.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/097fa9002a3abbc6ba5dd763ef91d7a133269db2', 'message': 'Updates for release tag 9.0.5\n\nChange-Id: I5f75c609b1f02be5a1428d98c8af5551c4d3fc9f\n'}]",0,143204,097fa9002a3abbc6ba5dd763ef91d7a133269db2,8,3,1,7353,,,0,"Updates for release tag 9.0.5

Change-Id: I5f75c609b1f02be5a1428d98c8af5551c4d3fc9f
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/04/143204/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/rpc_deploy/user_variables.yml', 'rpc_deployment/inventory/group_vars/all.yml', 'rpc_deployment/vars/repo_packages/raxmon.yml', 'scripts/cloudserver-aio.sh']",4,097fa9002a3abbc6ba5dd763ef91d7a133269db2,,"REPO_BRANCH=${REPO_BRANCH:-""9.0.5""}maas_repo_version: 9.0.5","REPO_BRANCH=${REPO_BRANCH:-""9.0.3""}maas_repo_version: 9.0.3",5,5
openstack%2Foslo-specs~master~Ib0fca5dc41c20627658d3103c53b78929f9371cb,openstack/oslo-specs,master,Ib0fca5dc41c20627658d3103c53b78929f9371cb,Graduating Policy,MERGED,2014-12-08 22:05:22.000000000,2014-12-19 23:00:54.000000000,2014-12-19 23:00:53.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 2218}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 2903}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 6928}, {'_account_id': 8866}, {'_account_id': 9107}, {'_account_id': 9142}, {'_account_id': 9656}, {'_account_id': 11022}]","[{'number': 1, 'created': '2014-12-08 22:05:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/ffd0213bd8245e1854c3549723d913f205d83f2c', 'message': 'Graduate Policy\n\nBlueprint graduate-policy\n\nChange-Id: Ib0fca5dc41c20627658d3103c53b78929f9371cb\n'}, {'number': 2, 'created': '2014-12-09 17:34:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/e96df7fcfe987b34e2e2583f2ed86bb694d0c8ff', 'message': 'Graduate Policy\n\nBlueprint graduate-policy\n\nChange-Id: Ib0fca5dc41c20627658d3103c53b78929f9371cb\n'}, {'number': 3, 'created': '2014-12-10 20:36:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/8efecacd8247bcad930ca631b1b779c05d8aeb46', 'message': 'Graduate Policy\n\nGraduation spec for oslo.policy.\n\nCo-Authored-By: Rodrigo Duarte Sousa <rodrigods@lsd.ufcg.edu.br>\n\nImplements: blueprint graduate-policy\nChange-Id: Ib0fca5dc41c20627658d3103c53b78929f9371cb\n'}, {'number': 4, 'created': '2014-12-10 21:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/6a4c4b00e77596c71f2ebe4d72a5bb47ef47b59a', 'message': 'Graduate Policy\n\nGraduation spec for oslo.policy.\n\nCo-Authored-By: Rodrigo Duarte Sousa <rodrigods@lsd.ufcg.edu.br>\n\nImplements: blueprint graduate-policy\nChange-Id: Ib0fca5dc41c20627658d3103c53b78929f9371cb\n'}, {'number': 5, 'created': '2014-12-11 18:38:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/abb704513bf499c012cc72dea8bb392f234f0d77', 'message': 'Graduating Policy\n\nGraduation spec for oslo.policy.\n\nCo-Authored-By: Rodrigo Duarte Sousa <rodrigods@lsd.ufcg.edu.br>\n\nImplements: blueprint graduate-policy\nChange-Id: Ib0fca5dc41c20627658d3103c53b78929f9371cb\n'}, {'number': 6, 'created': '2014-12-11 19:33:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/cde2223fe3c72e811fc8cbbbe99a0353f5da4fea', 'message': 'Graduating Policy\n\nGraduation spec for oslo.policy.\n\nCo-Authored-By: Rodrigo Duarte Sousa <rodrigods@lsd.ufcg.edu.br>\n\nImplements: blueprint graduate-policy\nChange-Id: Ib0fca5dc41c20627658d3103c53b78929f9371cb\n'}, {'number': 7, 'created': '2014-12-13 14:28:30.000000000', 'files': ['specs/kilo/graduate-policy.rst'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/95c56cfed38166bfd056f6b0569a74d965a25a45', 'message': 'Graduating Policy\n\nGraduation spec for oslo.policy.\n\nCo-Authored-By: Rodrigo Duarte Sousa <rodrigods@lsd.ufcg.edu.br>\n\nImplements: blueprint graduate-policy\nChange-Id: Ib0fca5dc41c20627658d3103c53b78929f9371cb\n'}]",13,140161,95c56cfed38166bfd056f6b0569a74d965a25a45,27,16,7,2218,,,0,"Graduating Policy

Graduation spec for oslo.policy.

Co-Authored-By: Rodrigo Duarte Sousa <rodrigods@lsd.ufcg.edu.br>

Implements: blueprint graduate-policy
Change-Id: Ib0fca5dc41c20627658d3103c53b78929f9371cb
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/61/140161/6 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/graduate-policy.rst'],1,ffd0213bd8245e1854c3549723d913f205d83f2c,bp/graduate-policy,".. =============== Graduate Policy =============== https://blueprints.launchpad.net/oslo?searchtext=graduate-policy Graduate the policy API to a standalone library. Problem description =================== The Policy code is security sensitive and needs to be managed as a library. If there is a CVE level defect, deploying a fix should require deploying a new version of the library, not syncing each individual project. Since the policy code is tightly tied to the authorization process managed by Keystone, the AAA program (formerly Identity) has been designated as the owner of the new library. Proposed change =============== Creae a new library named `osaaa-policy`, populated with the contents of `openstack/common/policy.py` and remove the policy.py file from the oslo incubartro repository. Impact on Existing APIs ----------------------- All calls to <prjectname>/openstack/common/policy will be able to refer to osaaa-policy directly. Security impact --------------- Describe any potential security impact on the system. Some of the items to consider include: * Does this change touch sensitive data such as tokens, keys, or user data? * Yes, policy. * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? * No * Does this change involve cryptography or hashing? * No * Does this change require the use of sudo or any elevated privileges? * No * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. * No * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. * No Performance Impact ------------------ No impact Configuration Impact -------------------- Applications will need to update the python imports for code that calls the policy.py file now, update the requirements, and remove the policy code from the list of files synchronized with oslo. Developer Impact ---------------- No changes beyond those posted above. Testing Impact -------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Adam Young ayoung ayoung@redhat.com Other contributors: rodrigods Milestones ---------- Kilo 2 Work Items ---------- * Create new repo. * remove from Oslo Documentation Impact ==================== Library will require its own documentation, but that will be done post graduation. Dependencies ============ None References ========== * https://etherpad.openstack.org/p/kilo-oslo-library-proposals .. note:: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ",,142,0
openstack%2Fswift~master~If50bab9da038ef28aaeb68058bd348f9fe7fd043,openstack/swift,master,If50bab9da038ef28aaeb68058bd348f9fe7fd043,Tiny speedup to ring builder,ABANDONED,2014-12-19 00:32:34.000000000,2014-12-19 22:53:50.000000000,,"[{'_account_id': 3}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-12-19 00:32:34.000000000', 'files': ['swift/common/ring/builder.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/79a05f9ea859fa71e9ed73aa1e0daa32b39a8d04', 'message': ""Tiny speedup to ring builder\n\nA computation was inside a loop, but it didn't depend on the loop\nvariable, so this commit hoists it out of the loop. It's not\nnoticeably faster, but it is a little cleaner.\n\nChange-Id: If50bab9da038ef28aaeb68058bd348f9fe7fd043\n""}]",0,142945,79a05f9ea859fa71e9ed73aa1e0daa32b39a8d04,4,2,1,2622,,,0,"Tiny speedup to ring builder

A computation was inside a loop, but it didn't depend on the loop
variable, so this commit hoists it out of the loop. It's not
noticeably faster, but it is a little cleaner.

Change-Id: If50bab9da038ef28aaeb68058bd348f9fe7fd043
",git fetch https://review.opendev.org/openstack/swift refs/changes/45/142945/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/ring/builder.py'],1,79a05f9ea859fa71e9ed73aa1e0daa32b39a8d04,hershey-constant," # Note: this represents how many partitions may be assigned to a # given tier (region/zone/server/disk). It does not take into # account how many partitions a given tier wants to shed. # # If we did not do this, we could have a zone where, at some # point during assignment, number-of-parts-to-gain equals # number-of-parts-to-shed. At that point, no further placement # into that zone would occur since its parts_available_in_tier # would be 0. This would happen any time a zone had any device # with partitions to shed, which is any time a device is being # removed, which is a pretty frequent operation. wanted = max(dev['parts_wanted'], 0) for tier in tiers: parts_available_in_tier[tier] += wanted"," for tier in tiers: # Note: this represents how many partitions may be assigned to # a given tier (region/zone/server/disk). It does not take # into account how many partitions a given tier wants to shed. # # If we did not do this, we could have a zone where, at some # point during assignment, number-of-parts-to-gain equals # number-of-parts-to-shed. At that point, no further placement # into that zone would occur since its parts_available_in_tier # would be 0. This would happen any time a zone had any device # with partitions to shed, which is any time a device is being # removed, which is a pretty frequent operation. parts_available_in_tier[tier] += max(dev['parts_wanted'], 0)",13,12
openstack%2Fneutron-specs~master~I79f47dc5f4f530419b936c1b65fab6e0c6e8be06,openstack/neutron-specs,master,I79f47dc5f4f530419b936c1b65fab6e0c6e8be06,Dynamic templates for flavors,MERGED,2014-12-04 19:00:41.000000000,2014-12-19 22:47:04.000000000,2014-12-19 22:47:03.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 748}, {'_account_id': 2592}, {'_account_id': 6951}, {'_account_id': 7278}, {'_account_id': 9375}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11685}]","[{'number': 1, 'created': '2014-12-04 19:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/82e2a484399d744a4fe42a8aeda7aee3415af1f3', 'message': 'Dynamic templates for flavors\n\nAPIImpact\nDocImpact\n\nChange-Id: I79f47dc5f4f530419b936c1b65fab6e0c6e8be06\n'}, {'number': 2, 'created': '2014-12-05 00:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0cf0b17d9cd57acae24e9e0a7da1c518ee7f8abc', 'message': 'Dynamic templates for flavors\n\nAPIImpact\nDocImpact\n\nChange-Id: I79f47dc5f4f530419b936c1b65fab6e0c6e8be06\n'}, {'number': 3, 'created': '2014-12-05 00:57:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/83bd5a42080436d62be88f685703bef3b56753fa', 'message': 'Dynamic templates for flavors\n\nAPIImpact\nDocImpact\n\nChange-Id: I79f47dc5f4f530419b936c1b65fab6e0c6e8be06\n'}, {'number': 4, 'created': '2014-12-05 02:30:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/07ebe55ace77d79353083b4185fa0706747fd7d0', 'message': 'Dynamic templates for flavors\n\nAPIImpact\nDocImpact\n\nChange-Id: I79f47dc5f4f530419b936c1b65fab6e0c6e8be06\n'}, {'number': 5, 'created': '2014-12-06 00:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/f15e3e6a4b4e5074a7a4434b94a8fc1b5d8ebb55', 'message': 'Dynamic templates for flavors\n\nAPIImpact\nDocImpact\n\nChange-Id: I79f47dc5f4f530419b936c1b65fab6e0c6e8be06\n'}, {'number': 6, 'created': '2014-12-17 20:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8eaaf604b608a5c56808987d7391394a6d854d0b', 'message': 'Dynamic templates for flavors\n\nAPIImpact\nDocImpact\n\nChange-Id: I79f47dc5f4f530419b936c1b65fab6e0c6e8be06\n'}, {'number': 7, 'created': '2014-12-18 06:33:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/4dc3adcbaea0f7b61a2c90355853476b024e8ca4', 'message': 'Dynamic templates for flavors\n\nAPIImpact\nDocImpact\n\nChange-Id: I79f47dc5f4f530419b936c1b65fab6e0c6e8be06\n'}, {'number': 8, 'created': '2014-12-18 06:34:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5f960d15e092d462a866008de9268899aa3a6b71', 'message': 'Dynamic templates for flavors\n\nAPIImpact\nDocImpact\n\nChange-Id: I79f47dc5f4f530419b936c1b65fab6e0c6e8be06\n'}, {'number': 9, 'created': '2014-12-19 21:13:21.000000000', 'files': ['specs/kilo/neutron-flavor-framework-templates.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/1be57ce19ebcbd82440230ce6fbc6497ab98e258', 'message': 'Dynamic templates for flavors\n\nAPIImpact\nDocImpact\n\nChange-Id: I79f47dc5f4f530419b936c1b65fab6e0c6e8be06\n'}]",43,139155,1be57ce19ebcbd82440230ce6fbc6497ab98e258,48,11,9,10980,,,0,"Dynamic templates for flavors

APIImpact
DocImpact

Change-Id: I79f47dc5f4f530419b936c1b65fab6e0c6e8be06
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/55/139155/6 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/neutron-flavor-framework-templates.rst'],1,82e2a484399d744a4fe42a8aeda7aee3415af1f3,dynamic-flavors,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Flavor framework - Templates and meta-data ========================================== https://blueprints.launchpad.net/neutron/+spec/neutron-flavor-framework-templates The Flavor Framework spec introduces a static framework for creating different feature levels for a service. This proposal adds the ability to have the objects being created for the service, influence the flavor's behavior. Problem Description =================== The original flavor framework allows operators to create custom feature levels for a given service. But, some features require per-instance data to be effectively deployed. An example would be a load balancer that offers page caching. With flavors, you can specify one flavor for no page caching, and another for page caching everything. But, full page caching often breaks legacy applications, and certain URLs often need to be exempted, on a per load-balancer basis, such as ""do page caching, but not for /legacy/bank/thingie"". Another example would be an operator choosing to enable DoS protection for a certain level of load balancer, but security features like those often need to have a per-instance whitelist for the end-admin to be able to quickly deal with false positives. Proposed Change =============== This proposal suggests two changes to the existing flavor framework: * Add a model/table for ""flavor object meta-data"", which is meta-data that is stored for any given flavor-enabled neutron object, back-referenced with that objects' UUID, and a mixin (/me hides) that adds a ""flavor_meta"" attribute to said object. * In the ""metadata"" field passed to drivers, support jinja templating syntax, with macro substitution available for the neutron model attributes or the above per-instance meta data. Macro substitution will happen before the resulting ""metadata"" is passed to the backend plugin/driver, so drivers do not need to be aware of this templating. Examples: With the static flavor framework, you might have a flavor named ""AwesomeSauce"", which includes load balancing and DDoS protection, and the driver metadata might look like this: :: { vendor_z23_ddos_protection = true } and that is exactly what would be passed to the z23 lbaas driver. With the templating syntax, that example becomes: :: { vendor_z23_ddos_protection = true z23_funky_whitelist = {{ meta.whitelist }} } With a corresponsing flavor_meta field on the LoadBalancer object being: :: { whitelist = [ '1.2.3.4', '8.8.8.8' ] } and the resulting metadata passed to the driver would be: :: { vendor_z23_ddos_protection = true z23_funky_whitelist = [ '1.2.3.4', '8.8.8.8' ] } Data Model Impact ----------------- One new logical models will be added to the database. :: FlavorMeta id: uuid object_id: uuid meta: string The following existing models will be modified with a flavor_meta attribute pointing into the above table: LoadBalancer As more features are made flavor aware, their root models should add a flavor_meta reference. REST API Impact --------------- Supporting flavor-enabled models will add an attribute for flavor_meta. +------------+-------+---------+---------+------------+--------------+ |Attribute |Type |Access |Default |Validation/ |Description | |Name | | |Value |Conversion | | +============+=======+=========+=========+============+==============+ |flavor_meta |string |RW, all |'' |json string |per-object | | | | | | |meta data | +------------+-------+---------+---------+------------+--------------+ Security Impact --------------- None Notifications Impact -------------------- None Other End User Impact --------------------- This is an additional hook for operators, and will be invisible to end users. Performance Impact ------------------ None IPv6 Impact ----------- None Other Deployer Impact --------------------- None Developer Impact ---------------- Services/models that want to support flavors and this templating mechanism will need to add the appropriate model entry and db migration. Community Impact ---------------- This change allows operators greater flexibility in enabling advanced services within the Neutron framework, without adding to community developer load for each feature. Alternatives ------------ * The first alternative is to do nothing. This results in what many vendors are doing today, which is to brew up proprietary neutron solutions in order to expose more advanced features. This results in inconsistent solutions for operators, more difficulty tracking trunk, and vendor lock-in. * Another alternative is the same as this proposal minus the templating on the flavor metadata. Since the flavor metadata is tied to a particular driver, and thus vendor specific, removing the templating would force vendors to expose vendor specific goo to their end users. In addition, since multiple service profiles (drivers/vendors) can be used to implement a single flavor, not having templating would mean that that multiple backend support would break unless those backends supported the exact same back-end metadata, which is unlikely and impractical. * Finally, the most straightforward alternative is to implement each feature natively into the services API. In the aforementioned page caching example, add page caching as a feature in the API, with a URL exception list, and wait for all drivers to implement to that backend. This adds maintenance and development load to the entire community, and means that Neutron will have a built-in lag for adding new features that appear in the marketplace. Implementation ============== Assignee(s) ----------- https://launchpad.net/~dougwig Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ * Main flavors framework * LBaaS v2 Testing ======= Please discuss how the change will be tested. We especially want to know what tempest tests will be added. It is assumed that unit test coverage will be added so that doesn't need to be mentioned explicitly, but discussion of why you think unit tests are sufficient and we don't need to add more tempest tests would need to be included. Is this untestable in gate given current limitations (specific hardware / software configurations available)? If so, are there mitigation plans (3rd party testing, gate enhancements, etc). Tempest Tests ------------- Flavor tests need to be enhanced to include per-object meta-data and some basic templated flavor metadata, and verify that substituted data is passed to the backend. Functional Tests ---------------- Tests to verify the flavor_meta field in models, and that the jinja substitution is happening properly in the flavors code before being passed to backends. API Tests --------- Modify flavor API tests to include flavor_meta field for objects. Documentation Impact ==================== User Documentation ------------------ This change is invisible to end users. Developer Documentation ----------------------- Deployers will need documentation for the new API fields and the templating syntax. References ========== * Flavors framework - https://review.openstack.org/#/c/102723 ",,263,0
openstack%2Fopenstacksdk~master~I9d801337c3775e8dc802eecf5d6bca07df55ac1f,openstack/openstacksdk,master,I9d801337c3775e8dc802eecf5d6bca07df55ac1f,Add image v2 tags,MERGED,2014-12-17 21:32:42.000000000,2014-12-19 22:22:01.000000000,2014-12-19 22:22:00.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-12-17 21:32:42.000000000', 'files': ['openstack/image/v2/tag.py', 'openstack/tests/image/v2/test_tag.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/4da9eb7a86646313e6e21338b9703c3b3b60aa69', 'message': 'Add image v2 tags\n\nTags created and deleted through this endpoint only, browse available through\nimage retrieve.\n\nChange-Id: I9d801337c3775e8dc802eecf5d6bca07df55ac1f\n'}]",0,142583,4da9eb7a86646313e6e21338b9703c3b3b60aa69,9,3,1,12807,,,0,"Add image v2 tags

Tags created and deleted through this endpoint only, browse available through
image retrieve.

Change-Id: I9d801337c3775e8dc802eecf5d6bca07df55ac1f
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/83/142583/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/image/v2/tag.py', 'openstack/tests/image/v2/test_tag.py']",2,4da9eb7a86646313e6e21338b9703c3b3b60aa69,add-image-v2-tags,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock import testtools from openstack.image.v2 import tag IDENTIFIER = 'IDENTIFIER' EXAMPLE = { 'image_id': 'IMAGE_ID', 'tag': IDENTIFIER, } class TestTag(testtools.TestCase): def test_basic(self): sot = tag.Tag() self.assertIsNone(sot.resource_key) self.assertEqual('tags', sot.resources_key) self.assertEqual('/images/%(image_id)s/tags', sot.base_path) self.assertEqual('image', sot.service.service_type) self.assertEqual('tag', sot.id_attribute) self.assertTrue(sot.allow_create) self.assertFalse(sot.allow_retrieve) self.assertFalse(sot.allow_update) self.assertTrue(sot.allow_delete) self.assertFalse(sot.allow_list) def test_make_it(self): sot = tag.Tag(EXAMPLE) self.assertEqual(IDENTIFIER, sot.id) self.assertEqual(EXAMPLE['image_id'], sot.image_id) def test_create(self): sess = mock.Mock() resp = mock.Mock() sess.put = mock.Mock(return_value=resp) url = 'images/{image_id}/tags/{tag}'.format(**EXAMPLE) tag.Tag(EXAMPLE).create(sess) sess.put.assert_called_with(url, service=tag.Tag.service, json=None) ",,85,0
openstack%2Fmonasca-agent~master~I0649ae4341fe325007e2a8d37161d330e4c95d72,openstack/monasca-agent,master,I0649ae4341fe325007e2a8d37161d330e4c95d72,Renaming agent packages to reflect monasca,MERGED,2014-12-19 03:27:13.000000000,2014-12-19 22:21:54.000000000,2014-12-19 22:21:54.000000000,"[{'_account_id': 3}, {'_account_id': 11094}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-12-19 03:27:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/a326193f459b1b55e425413afe60a59d0a063a1a', 'message': 'Renaming agent packages to reflect monasca\n\nRenamed monagent package to monasca_agent and monsetup package to monasca_setup.\nAlso, renamed the monstatsd agent package to statsd to more closely match the internal\ncollector and forwarder packages.\n\nChange-Id: I0649ae4341fe325007e2a8d37161d330e4c95d72\n'}, {'number': 2, 'created': '2014-12-19 16:23:38.000000000', 'files': ['monasca_agent/collector/dogstream/supervisord_log.py', 'monasca_setup/detection/plugins/nova.py', 'monasca_setup/detection/plugins/postfix.py', 'tests/test_common.py', 'monasca_setup/service/__init__.py', 'monasca_agent/collector/checks_d/gunicorn.py', 'monasca_agent/collector/checks/collector.py', 'monasca_agent/common/check_status.py', 'monasca_setup/main.py', 'packaging/Makefile', 'monasca_agent/forwarder/api/mon.py', 'tests/test_solr.py', 'monasca_agent/collector/checks_d/jenkins.py', 'monasca_agent/collector/checks/services_checks.py', 'monasca_agent/collector/checks_d/win32_event_log.py', 'monasca_agent/collector/checks/__init__.py', 'monasca_agent/statsd/udp.py', 'monasca_setup/detection/service_plugin.py', 'monasca_agent/collector/checks_d/lighttpd.py', 'agent.conf.template', 'tests/test_monstatsd.py', 'monasca_agent/collector/checks_d/haproxy.py', 'monasca_setup/detection/plugins/neutron.py', 'monasca_agent/collector/checks_d/kyototycoon.py', 'monasca_agent/collector/virt/hyperv/utilsv2.py', 'monasca_agent/collector/virt/xenapi/__init__.py', 'monasca_agent/forwarder/daemon.py', 'monasca_setup/detection/plugins/rabbitmq.py', 'tests/__init__.py', 'tests/test_win32.py', 'monasca_agent/collector/checks_d/http_check.py', 'monasca_agent/common/emitter.py', 'monasca_agent/collector/virt/hyperv/inspector.py', 'monasca_agent/collector/virt/__init__.py', 'monasca_setup/detection/plugins/mysql.py', 'monasca_agent/collector/checks_d/wmi_check.py', 'monasca_agent/collector/checks_d/nginx.py', 'monasca_agent/win32/gui.py', 'monasca_agent/common/__init__.py', 'tests/test_watchdog.py', 'monasca_agent/collector/dogstream/__init__.py', 'monasca_agent/win32/agent.py', 'tests/test_check_status.py', 'monasca_agent/collector/checks_d/sqlserver.py', 'monasca_agent/common/exceptions.py', 'tests/test_system.py', 'monasca_agent/collector/checks_d/nagios_wrapper.py', 'monasca_agent/collector/dogstream/common.py', 'monasca_agent/collector/virt/libvirt/inspector.py', 'monasca_setup/agent_config.py', 'tests/performance/benchmark_aggregator.py', 'monasca_agent/collector/checks/system/__init__.py', 'monasca_agent/collector/checks_d/directory.py', 'monasca_agent/collector/checks_d/hdfs.py', 'monasca_setup/detection/plugins/__init__.py', 'monasca_agent/collector/checks_d/couchbase.py', 'monasca_setup/__init__.py', 'monasca_agent/collector/checks_d/kafka_consumer.py', 'monasca_agent/collector/checks_d/tcp_check.py', 'monasca_setup/detection/plugins/glance.py', 'monasca_setup/detection/plugins/keystone.py', 'monasca_agent/common/config.py', 'monasca_agent/forwarder/__init__.py', 'monasca_agent/collector/checks/check.py', 'monasca_agent/collector/virt/inspector.py', 'monasca_agent/statsd/reporter.py', 'monasca_setup/detection/__init__.py', 'monasca_agent/collector/checks/libs/thread_pool.py', 'monasca_agent/collector/checks_d/rabbitmq.py', 'monasca_setup/detection/plugins/network.py', 'monasca_agent/collector/checks_d/docker.py', 'monasca_agent/common/daemon.py', 'monasca_setup/detection/utils.py', 'tests/common.py', 'monasca_agent/collector/modules.py', 'monasca_agent/collector/checks/utils.py', 'monasca_setup/README.md', 'monasca_setup/detection/plugin.py', 'monasca_setup/detection/plugins/cinder.py', 'monasca_agent/collector/checks_d/postgres.py', 'monasca_agent/collector/checks_d/zk.py', 'monasca_agent/common/util.py', 'monasca_agent/collector/checks_d/redisdb.py', 'monasca_setup/detection/plugins/mon.py', 'monasca_agent/collector/checks_d/process.py', 'monasca_agent/collector/daemon.py', 'monasca_agent/forwarder/transaction.py', 'monasca_setup/detection/plugins/zookeeper.py', 'monasca_setup/service/sysv.py', 'monasca_agent/collector/checks_d/__init__.py', 'monasca_agent/common/keystone.py', 'monasca_agent/win32/common.py', 'monasca_agent/collector/jmxfetch.py', 'monasca_agent/win32/shell.py', 'monasca_agent/collector/checks_d/varnish.py', 'monasca_agent/__init__.py', 'monasca_agent/collector/__init__.py', 'monasca_agent/statsd/daemon.py', 'packaging/monasca-agent.init', 'README.md', 'monasca_agent/collector/checks_d/mcache.py', 'monasca_agent/collector/checks_d/postfix.py', 'monasca_agent/collector/virt/libvirt/__init__.py', 'monasca_agent/collector/checks/libs/__init__.py', 'packaging/supervisor.conf', 'setup.cfg', 'tests/test_config.py', 'monasca_agent/collector/checks/system/win32.py', 'tests/functional/monascastatsd_functional.py', 'monasca_agent/collector/checks/libs/jmxfetch-0.3.0-jar-with-dependencies.jar', 'monasca_agent/common/aggregator.py', 'monasca_agent/collector/checks_d/host_alive.py', 'monasca_agent/collector/checks_d/iis.py', 'monasca_agent/collector/checks_d/mysql.py', 'monasca_agent/collector/checks/datadog.py', 'monasca_agent/collector/checks_d/apache.py', 'monasca_agent/collector/virt/vmware/inspector.py', 'monasca_agent/collector/checks_d/mongo.py', 'monasca_agent/collector/dogstream/cassandra.py', 'monasca_setup/service/service.py', 'monasca_agent/forwarder/api/__init__.py', 'tests/test_tomcat.py', 'tests/test_java_jmx.py', 'tests/test_cassandra_jmx.py', 'monasca_agent/collector/checks_d/gearmand.py', 'monasca_setup/detection/plugins/ceilometer.py', 'packaging/monasca-agent-deb/monasca-agent.init', 'monasca_agent/collector/virt/vmware/vsphere_operations.py', 'monasca_agent/common/metrics.py', 'monasca_agent/win32/__init__.py', 'monasca_agent/collector/checks_d/couch.py', 'tests/test_transaction.py', 'monasca_agent/collector/virt/vmware/__init__.py', 'monasca_agent/collector/virt/xenapi/inspector.py', 'monasca_agent/collector/checks_d/riak.py', 'monasca_setup/detection/plugins/libvirt.py', 'monasca_setup/detection/plugins/swift.py', 'monasca_agent/collector/checks_d/cacti.py', 'monasca_agent/collector/checks/libs/jmxterm-1.0-DATADOG-uber.jar', 'packaging/monasca-agent-deb/supervisor.conf', 'monasca_agent/collector/virt/hyperv/__init__.py', 'monasca_agent/collector/checks_d/network.py', 'monasca_agent/collector/checks/system/unix.py', 'monasca_agent/collector/checks_d/libvirt.py', 'monasca_setup/detection/plugins/kafka_consumer.py', 'monasca_agent/statsd/__init__.py', 'monasca_agent/collector/checks_d/elastic.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/34d82d455e9447323aade4d6ab654d696fd8c411', 'message': 'Renaming agent packages to reflect monasca\n\nRenamed monagent package to monasca_agent and monsetup package to monasca_setup.\nAlso, renamed the monstatsd agent package to statsd to more closely match the internal\ncollector and forwarder packages.\n\nChange-Id: I0649ae4341fe325007e2a8d37161d330e4c95d72\n'}]",0,142968,34d82d455e9447323aade4d6ab654d696fd8c411,10,3,2,12108,,,0,"Renaming agent packages to reflect monasca

Renamed monagent package to monasca_agent and monsetup package to monasca_setup.
Also, renamed the monstatsd agent package to statsd to more closely match the internal
collector and forwarder packages.

Change-Id: I0649ae4341fe325007e2a8d37161d330e4c95d72
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/68/142968/1 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_agent/collector/dogstream/supervisord_log.py', 'monasca_setup/detection/plugins/nova.py', 'monasca_setup/detection/plugins/postfix.py', 'tests/test_common.py', 'monasca_setup/service/__init__.py', 'monasca_agent/collector/checks_d/gunicorn.py', 'monasca_agent/collector/checks/collector.py', 'monasca_agent/common/check_status.py', 'monasca_setup/main.py', 'packaging/Makefile', 'monasca_agent/forwarder/api/mon.py', 'tests/test_solr.py', 'monasca_agent/collector/checks_d/jenkins.py', 'monasca_agent/collector/checks/services_checks.py', 'monasca_agent/collector/checks_d/win32_event_log.py', 'monasca_agent/collector/checks/__init__.py', 'monasca_agent/statsd/udp.py', 'monasca_setup/detection/service_plugin.py', 'monasca_agent/collector/checks_d/lighttpd.py', 'agent.conf.template', 'tests/test_monstatsd.py', 'monasca_agent/collector/checks_d/haproxy.py', 'monasca_setup/detection/plugins/neutron.py', 'monasca_agent/collector/checks_d/kyototycoon.py', 'monasca_agent/collector/virt/hyperv/utilsv2.py', 'monasca_agent/collector/virt/xenapi/__init__.py', 'monasca_agent/forwarder/daemon.py', 'monasca_setup/detection/plugins/rabbitmq.py', 'tests/__init__.py', 'tests/test_win32.py', 'monasca_agent/collector/checks_d/http_check.py', 'monasca_agent/common/emitter.py', 'monasca_agent/collector/virt/hyperv/inspector.py', 'monasca_agent/collector/virt/__init__.py', 'monasca_setup/detection/plugins/mysql.py', 'monasca_agent/collector/checks_d/wmi_check.py', 'monasca_agent/collector/checks_d/nginx.py', 'monasca_agent/win32/gui.py', 'monasca_agent/common/__init__.py', 'tests/test_watchdog.py', 'monasca_agent/collector/dogstream/__init__.py', 'monasca_agent/win32/agent.py', 'tests/test_check_status.py', 'monasca_agent/collector/checks_d/sqlserver.py', 'monasca_agent/common/exceptions.py', 'tests/test_system.py', 'monasca_agent/collector/checks_d/nagios_wrapper.py', 'monasca_agent/collector/dogstream/common.py', 'monasca_agent/collector/virt/libvirt/inspector.py', 'monasca_setup/agent_config.py', 'tests/performance/benchmark_aggregator.py', 'monasca_agent/collector/checks/system/__init__.py', 'monasca_agent/collector/checks_d/directory.py', 'monasca_agent/collector/checks_d/hdfs.py', 'monasca_setup/detection/plugins/__init__.py', 'monasca_agent/collector/checks_d/couchbase.py', 'monasca_setup/__init__.py', 'monasca_agent/collector/checks_d/kafka_consumer.py', 'monasca_agent/collector/checks_d/tcp_check.py', 'monasca_setup/detection/plugins/glance.py', 'monasca_setup/detection/plugins/keystone.py', 'monasca_agent/common/config.py', 'monasca_agent/forwarder/__init__.py', 'monasca_agent/collector/checks/check.py', 'monasca_agent/collector/virt/inspector.py', 'monasca_agent/statsd/reporter.py', 'monasca_setup/detection/__init__.py', 'monasca_agent/collector/checks/libs/thread_pool.py', 'monasca_agent/collector/checks_d/rabbitmq.py', 'monasca_setup/detection/plugins/network.py', 'monasca_agent/collector/checks_d/docker.py', 'monasca_agent/common/daemon.py', 'monasca_setup/detection/utils.py', 'tests/common.py', 'monasca_agent/collector/modules.py', 'monasca_agent/collector/checks/utils.py', 'monasca_setup/README.md', 'monasca_setup/detection/plugin.py', 'monasca_setup/detection/plugins/cinder.py', 'monasca_agent/collector/checks_d/postgres.py', 'monasca_agent/collector/checks_d/zk.py', 'monasca_agent/common/util.py', 'monasca_agent/collector/checks_d/redisdb.py', 'monasca_setup/detection/plugins/mon.py', 'monasca_agent/collector/checks_d/process.py', 'monasca_agent/collector/daemon.py', 'monasca_agent/forwarder/transaction.py', 'monasca_setup/detection/plugins/zookeeper.py', 'monasca_setup/service/sysv.py', 'monasca_agent/collector/checks_d/__init__.py', 'monasca_agent/common/keystone.py', 'monasca_agent/win32/common.py', 'monasca_agent/collector/jmxfetch.py', 'monasca_agent/win32/shell.py', 'monasca_agent/collector/checks_d/varnish.py', 'monasca_agent/__init__.py', 'monasca_agent/collector/__init__.py', 'monasca_agent/statsd/daemon.py', 'packaging/monasca-agent.init', 'README.md', 'monasca_agent/collector/checks_d/mcache.py', 'monasca_agent/collector/checks_d/postfix.py', 'monasca_agent/collector/virt/libvirt/__init__.py', 'monasca_agent/collector/checks/libs/__init__.py', 'packaging/supervisor.conf', 'setup.cfg', 'tests/test_config.py', 'monasca_agent/collector/checks/system/win32.py', 'tests/functional/monascastatsd_functional.py', 'monasca_agent/collector/checks/libs/jmxfetch-0.3.0-jar-with-dependencies.jar', 'monasca_agent/common/aggregator.py', 'monasca_agent/collector/checks_d/host_alive.py', 'monasca_agent/collector/checks_d/iis.py', 'monasca_agent/collector/checks_d/mysql.py', 'monasca_agent/collector/checks/datadog.py', 'monasca_agent/collector/checks_d/apache.py', 'monasca_agent/collector/virt/vmware/inspector.py', 'monasca_agent/collector/checks_d/mongo.py', 'monasca_agent/collector/dogstream/cassandra.py', 'monasca_setup/service/service.py', 'monasca_agent/forwarder/api/__init__.py', 'tests/test_tomcat.py', 'tests/test_java_jmx.py', 'tests/test_cassandra_jmx.py', 'monasca_agent/collector/checks_d/gearmand.py', 'monasca_setup/detection/plugins/ceilometer.py', 'packaging/monasca-agent-deb/monasca-agent.init', 'monasca_agent/collector/virt/vmware/vsphere_operations.py', 'monasca_agent/common/metrics.py', 'monasca_agent/win32/__init__.py', 'monasca_agent/collector/checks_d/couch.py', 'tests/test_transaction.py', 'monasca_agent/collector/virt/vmware/__init__.py', 'monasca_agent/collector/virt/xenapi/inspector.py', 'monasca_agent/collector/checks_d/riak.py', 'monasca_setup/detection/plugins/libvirt.py', 'monasca_setup/detection/plugins/swift.py', 'monasca_agent/collector/checks_d/cacti.py', 'monasca_agent/collector/checks/libs/jmxterm-1.0-DATADOG-uber.jar', 'packaging/monasca-agent-deb/supervisor.conf', 'monasca_agent/collector/virt/hyperv/__init__.py', 'monasca_agent/collector/checks_d/network.py', 'monasca_agent/collector/checks/system/unix.py', 'monasca_agent/collector/checks_d/libvirt.py', 'monasca_setup/detection/plugins/kafka_consumer.py', 'monasca_agent/statsd/__init__.py', 'monasca_agent/collector/checks_d/elastic.py']",147,a326193f459b1b55e425413afe60a59d0a063a1a,monasca/rename-packages,from monasca_agent.collector.checks import AgentCheck from monasca_agent.collector.checks.utils import add_basic_auth from monasca_agent.common.util import headers,from monagent.collector.checks import AgentCheck from monagent.collector.checks.utils import add_basic_auth from monagent.common.util import headers,462,478
openstack%2Fnova~master~Ie150906b85f9059d4828e1b597890b6c234867a9,openstack/nova,master,Ie150906b85f9059d4828e1b597890b6c234867a9,Make resize server schema 'additionalProperties' False,MERGED,2014-12-15 04:05:53.000000000,2014-12-19 22:06:49.000000000,2014-12-19 22:06:46.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-15 04:05:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/320c355c9f305e52a65ab5bab74618628b35ac52', 'message': ""Make resize server schema 'additionalProperties' False\n\nNova V2.1 API has strong input validation by making validation\nthrough JSON schema.\n\nThis patch makes resize server schema 'additionalProperties' to False\nas all resize server extensions are implemented in V2.1.\nAfter this, V2.1 will not allow extra arg for resize server.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ie150906b85f9059d4828e1b597890b6c234867a9\n""}, {'number': 2, 'created': '2014-12-18 01:45:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/524e50cea9af16b498a319e1c1e76a319836ab96', 'message': ""Make resize server schema 'additionalProperties' False\n\nNova V2.1 API has strong input validation by making validation\nthrough JSON schema.\n\nThis patch makes resize server schema 'additionalProperties' to False\nas all resize server extensions are implemented in V2.1.\nAfter this, V2.1 will not allow extra arg for resize server.\n\nThis patch also adds some unit tests for those cases.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ie150906b85f9059d4828e1b597890b6c234867a9\n""}, {'number': 3, 'created': '2014-12-18 05:35:11.000000000', 'files': ['nova/api/openstack/compute/schemas/v3/servers.py', 'nova/tests/unit/api/openstack/compute/plugins/v3/test_server_actions.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7ddd575e43c8be86132d912c9700c87773ab292e', 'message': ""Make resize server schema 'additionalProperties' False\n\nNova V2.1 API has strong input validation by making validation\nthrough JSON schema.\n\nThis patch makes resize server schema 'additionalProperties' to False\nas all resize server extensions are implemented in V2.1.\nAfter this, V2.1 will not allow extra arg for resize server.\n\nThis patch also adds some unit tests for those cases.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ie150906b85f9059d4828e1b597890b6c234867a9\n""}]",2,141701,7ddd575e43c8be86132d912c9700c87773ab292e,37,10,3,8556,,,0,"Make resize server schema 'additionalProperties' False

Nova V2.1 API has strong input validation by making validation
through JSON schema.

This patch makes resize server schema 'additionalProperties' to False
as all resize server extensions are implemented in V2.1.
After this, V2.1 will not allow extra arg for resize server.

This patch also adds some unit tests for those cases.

Partially implements blueprint v2-on-v3-api

Change-Id: Ie150906b85f9059d4828e1b597890b6c234867a9
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/141701/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/schemas/v3/servers.py'],1,320c355c9f305e52a65ab5bab74618628b35ac52,bp/v2-on-v3-api," 'additionalProperties': False,"," # TODO(gmann): enable here after all extension schema # patches are merged. # 'additionalProperties': False,",1,3
openstack%2Fmanila~master~Id686260c9e5889d7b1ed2fe6236af0d7926310ac,openstack/manila,master,Id686260c9e5889d7b1ed2fe6236af0d7926310ac,Updated from global requirements,MERGED,2014-12-18 01:22:31.000000000,2014-12-19 22:01:37.000000000,2014-12-19 22:01:36.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-12-18 01:22:31.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/manila/commit/50cc64a099997ecbfc52aff53b55d682f4f445b7', 'message': 'Updated from global requirements\n\nChange-Id: Id686260c9e5889d7b1ed2fe6236af0d7926310ac\n'}]",0,142636,50cc64a099997ecbfc52aff53b55d682f4f445b7,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: Id686260c9e5889d7b1ed2fe6236af0d7926310ac
",git fetch https://review.opendev.org/openstack/manila refs/changes/36/142636/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,50cc64a099997ecbfc52aff53b55d682f4f445b7,openstack/requirements,alembic>=0.7.1,alembic>=0.6.4,1,1
openstack%2Fcongress~master~I22ee95ff1032129f14981b75ee674cf2d9d2bbaf,openstack/congress,master,I22ee95ff1032129f14981b75ee674cf2d9d2bbaf,Remove last of unneeded setUp methods,MERGED,2014-12-16 22:32:35.000000000,2014-12-19 21:59:18.000000000,2014-12-19 21:59:17.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 9253}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-16 22:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/5bd7acc14b84e406c1a289d8cac3d9d74028787a', 'message': 'Remove last of unneeded setUp methods\n\nChange-Id: I22ee95ff1032129f14981b75ee674cf2d9d2bbaf\n'}, {'number': 2, 'created': '2014-12-18 22:37:35.000000000', 'files': ['congress/tests/test_utils.py', 'congress/tests/test_server.py', 'congress/tests/test_config.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/9d779de79f4a901cc055c3b683de6c9451627a90', 'message': 'Remove last of unneeded setUp methods\n\nChange-Id: I22ee95ff1032129f14981b75ee674cf2d9d2bbaf\n'}]",0,142242,9d779de79f4a901cc055c3b683de6c9451627a90,16,5,2,4395,,,0,"Remove last of unneeded setUp methods

Change-Id: I22ee95ff1032129f14981b75ee674cf2d9d2bbaf
",git fetch https://review.opendev.org/openstack/congress refs/changes/42/142242/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/test_utils.py', 'congress/tests/test_server.py', 'congress/tests/test_config.py']",3,5bd7acc14b84e406c1a289d8cac3d9d74028787a,,,"from congress.common import config def setUp(self): super(ConfigurationTest, self).setUp() config.setup_logging() ",12,23
openstack%2Fcongress~master~Idd05bba57cdf3b384ed2e11817e97d21518ec980,openstack/congress,master,Idd05bba57cdf3b384ed2e11817e97d21518ec980,Python 3: Remove long value check,MERGED,2014-12-16 22:19:47.000000000,2014-12-19 21:59:12.000000000,2014-12-19 21:59:10.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 9253}, {'_account_id': 13050}, {'_account_id': 13593}]","[{'number': 1, 'created': '2014-12-16 22:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/2bcf1c82e4a22e7539209dfebf2c34af4d55a8d7', 'message': 'Python 3: Remove long value\n\nIn python 3 the two types int and long have been unified into one. This\npatch fixes a syntax error that would occur in python3.\n\ncloses-bug: 1403226\nPartially implements blueprint: support-python3\n\nChange-Id: Idd05bba57cdf3b384ed2e11817e97d21518ec980\n'}, {'number': 2, 'created': '2014-12-16 22:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/eb9fbfd5e5bea9928df6adba768357023714fce0', 'message': 'Python 3: Remove long value check\n\nIn python 3 the two types int and long have been unified into one. This\npatch fixes a syntax error that would occur in python3 and ensures that\nwe test it when using python 2.\n\ncloses-bug: 1403226\nPartially implements blueprint: support-python3\n\nChange-Id: Idd05bba57cdf3b384ed2e11817e97d21518ec980\n'}, {'number': 3, 'created': '2014-12-18 22:37:32.000000000', 'files': ['congress/tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/9a1e3126268f182c70745e927e418e1a1e78ba55', 'message': 'Python 3: Remove long value check\n\nIn python 3 the two types int and long have been unified into one. This\npatch fixes a syntax error that would occur in python3 and ensures that\nwe test it when using python 2.\n\ncloses-bug: 1403226\nPartially implements blueprint: support-python3\n\nChange-Id: Idd05bba57cdf3b384ed2e11817e97d21518ec980\n'}]",0,142237,9a1e3126268f182c70745e927e418e1a1e78ba55,19,6,3,4395,,,0,"Python 3: Remove long value check

In python 3 the two types int and long have been unified into one. This
patch fixes a syntax error that would occur in python3 and ensures that
we test it when using python 2.

closes-bug: 1403226
Partially implements blueprint: support-python3

Change-Id: Idd05bba57cdf3b384ed2e11817e97d21518ec980
",git fetch https://review.opendev.org/openstack/congress refs/changes/37/142237/1 && git format-patch -1 --stdout FETCH_HEAD,['congress/tests/test_utils.py'],1,2bcf1c82e4a22e7539209dfebf2c34af4d55a8d7,bug/1403226," self.assertEqual(456, utils.value_to_congress(456))"," self.assertEqual(456L, utils.value_to_congress(456L))",1,1
openstack%2Fcongress~master~I0d721446401225523b7acbab0a3514b53056f815,openstack/congress,master,I0d721446401225523b7acbab0a3514b53056f815,Python 3: Fix import path for d6message in deepsix,MERGED,2014-12-16 21:30:53.000000000,2014-12-19 21:58:16.000000000,2014-12-19 21:58:16.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 9253}, {'_account_id': 13050}, {'_account_id': 13593}]","[{'number': 1, 'created': '2014-12-16 21:30:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/5a6e331241904d7bc14ae8d3a2581630d4d507b8', 'message': 'Python 3: Fix import path for d6message in deepsix\n\nThis patch fixes the import path to be the full path for d6message.\nThis was causing an Import Error for python3. In addition, we should\nhave been using the full path anyways.\n\nCloses-bug: 1403209\nPartially implements: support-python3\n\nChange-Id: I0d721446401225523b7acbab0a3514b53056f815\n'}, {'number': 2, 'created': '2014-12-16 21:52:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/81a56594df1ab318a92384e92ddc4de5e23a971c', 'message': 'Python 3: Fix import path for d6message in deepsix\n\nThis patch fixes the import path to be the full path for d6message.\nThis was causing an Import Error for python3. In addition, we should\nhave been using the full path anyways.\n\nCloses-bug: 1403209\nPartially implements: support-python3\n\nChange-Id: I0d721446401225523b7acbab0a3514b53056f815\n'}, {'number': 3, 'created': '2014-12-16 22:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/953ffe71520f88693f466f9e8074cfce311e1087', 'message': 'Python 3: Fix import path for d6message in deepsix\n\nThis patch fixes the import path to be the full path for d6message.\nThis was causing an ImportError for python3. In addition, we should\nhave been using the full path anyways. Lastly, this import should not\nbe grouped with the stdlibs.\n\nCloses-bug: 1403209\nPartially implements: support-python3\n\nChange-Id: I0d721446401225523b7acbab0a3514b53056f815\n'}, {'number': 4, 'created': '2014-12-16 22:09:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/0da5097e3413aa804d39d19d3aee2fa7c5cf4b14', 'message': 'Python 3: Fix import path for d6message in deepsix\n\nThis patch fixes the import path to be the full path for d6message.\nThis was causing an ImportError for python3. In addition, we should\nhave been using the full path anyways. Lastly, this import should not\nbe grouped with the stdlibs.\n\nCloses-bug: 1403209\nPartially implements blueprint: support-python3\n\nChange-Id: I0d721446401225523b7acbab0a3514b53056f815\n'}, {'number': 5, 'created': '2014-12-18 22:37:29.000000000', 'files': ['congress/dse/deepsix.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/2e693cc897f91dd2c919cf76fbd0c4321790d1f2', 'message': 'Python 3: Fix import path for d6message in deepsix\n\nThis patch fixes the import path to be the full path for d6message.\nThis was causing an ImportError for python3. In addition, we should\nhave been using the full path anyways. Lastly, this import should not\nbe grouped with the stdlibs.\n\nCloses-bug: 1403209\nPartially implements blueprint: support-python3\n\nChange-Id: I0d721446401225523b7acbab0a3514b53056f815\n'}]",0,142228,2e693cc897f91dd2c919cf76fbd0c4321790d1f2,19,6,5,4395,,,0,"Python 3: Fix import path for d6message in deepsix

This patch fixes the import path to be the full path for d6message.
This was causing an ImportError for python3. In addition, we should
have been using the full path anyways. Lastly, this import should not
be grouped with the stdlibs.

Closes-bug: 1403209
Partially implements blueprint: support-python3

Change-Id: I0d721446401225523b7acbab0a3514b53056f815
",git fetch https://review.opendev.org/openstack/congress refs/changes/28/142228/5 && git format-patch -1 --stdout FETCH_HEAD,['congress/dse/deepsix.py'],1,5a6e331241904d7bc14ae8d3a2581630d4d507b8,bug/1403209,from congress.dse.d6message import d6msg,from d6message import d6msg,1,1
openstack%2Fcongress~master~Ifb16082bc96c5672f688a014bee3838c63c1de55,openstack/congress,master,Ifb16082bc96c5672f688a014bee3838c63c1de55,Python 3: Fix httplib,MERGED,2014-12-16 21:22:16.000000000,2014-12-19 21:57:52.000000000,2014-12-19 21:57:51.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 9253}, {'_account_id': 13050}, {'_account_id': 13593}]","[{'number': 1, 'created': '2014-12-16 21:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/63eb6f8ce47fb78f02a589c0c110c932d53efc9b', 'message': 'Python 3: Fix httplib\n\nIn python3 httplib has been renamed to http.client. This patch fixes\nthe httplib imports so that we can support python2 and python3.\n\nPartially implements: support-python3\n\nChange-Id: Ifb16082bc96c5672f688a014bee3838c63c1de55\n'}, {'number': 2, 'created': '2014-12-16 21:52:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/2f8032478ff6395de8df0a36b80b98eed298f570', 'message': 'Python 3: Fix httplib\n\nIn python3 httplib has been renamed to http.client. This patch fixes\nthe httplib imports so that we can support python2 and python3.\n\nPartially implements: support-python3\n\nChange-Id: Ifb16082bc96c5672f688a014bee3838c63c1de55\n'}, {'number': 3, 'created': '2014-12-16 22:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/4f81baf94c2c61942a81dc98c3ff2b7d2fbcd07b', 'message': 'Python 3: Fix httplib\n\nIn python3 httplib has been renamed to http.client. This patch fixes\nthe httplib imports so that we can support python2 and python3.\n\nPartially implements: support-python3\n\nChange-Id: Ifb16082bc96c5672f688a014bee3838c63c1de55\n'}, {'number': 4, 'created': '2014-12-16 22:09:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/b92b5746bfe5613818837e07c98a56941147ef79', 'message': 'Python 3: Fix httplib\n\nIn python3 httplib has been renamed to http.client. This patch fixes\nthe httplib imports so that we can support python2 and python3.\n\nPartially implements blueprint: support-python3\n\nChange-Id: Ifb16082bc96c5672f688a014bee3838c63c1de55\n'}, {'number': 5, 'created': '2014-12-18 22:37:25.000000000', 'files': ['congress/tests/api/test_webservice.py', 'congress/api/webservice.py', 'congress/api/rule_model.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/c9c849aa03a3241eb7d39c8cd9a73d564439d62b', 'message': 'Python 3: Fix httplib\n\nIn python3 httplib has been renamed to http.client. This patch fixes\nthe httplib imports so that we can support python2 and python3.\n\nPartially implements blueprint: support-python3\n\nChange-Id: Ifb16082bc96c5672f688a014bee3838c63c1de55\n'}]",0,142226,c9c849aa03a3241eb7d39c8cd9a73d564439d62b,28,6,5,4395,,,0,"Python 3: Fix httplib

In python3 httplib has been renamed to http.client. This patch fixes
the httplib imports so that we can support python2 and python3.

Partially implements blueprint: support-python3

Change-Id: Ifb16082bc96c5672f688a014bee3838c63c1de55
",git fetch https://review.opendev.org/openstack/congress refs/changes/26/142226/5 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/api/test_webservice.py', 'congress/api/rule_model.py']",2,63eb6f8ce47fb78f02a589c0c110c932d53efc9b,bug/1403209,try: # For Python 3 import http.client as httplib except ImportError: import httplib,import httplib,11,2
openstack%2Fbarbican~master~I7c6a9b738b86c44031318e74048a1055da822230,openstack/barbican,master,I7c6a9b738b86c44031318e74048a1055da822230,Add I18n-related unit tests (Part 2),MERGED,2014-12-10 19:15:05.000000000,2014-12-19 21:57:32.000000000,2014-12-19 21:57:30.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 8004}, {'_account_id': 10273}]","[{'number': 1, 'created': '2014-12-10 19:15:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/237df20035934554806dfe49553f7a6dbc4b932e', 'message': ""Add I18n-related unit tests (Part 2)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR moves the test_repositories.py module to a new 'repository'\npackage, in anticipation of more repository-related unit tests modules\nin future CRs. This CR also refactors the model/repositories.py module\nto make it a bit more testable.\n\nChange-Id: I7c6a9b738b86c44031318e74048a1055da822230\n""}, {'number': 2, 'created': '2014-12-10 23:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/7fb12afd9e6f695902a7f378c07d5f68727ea7f5', 'message': ""Add I18n-related unit tests (Part 2)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR moves the test_repositories.py module to a new 'repository'\npackage, in anticipation of more repository-related unit tests modules\nin future CRs. This CR also refactors the model/repositories.py module\nto make it a bit more testable.\n\nChange-Id: I7c6a9b738b86c44031318e74048a1055da822230\n""}, {'number': 3, 'created': '2014-12-11 00:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/666c92283e36d94965ad6cfde4206f4b362cdfdc', 'message': ""Add I18n-related unit tests (Part 2)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR moves the test_repositories.py module to a new 'repository'\npackage, in anticipation of more repository-related unit tests modules\nin future CRs. This CR also refactors the model/repositories.py module\nto make it a bit more testable.\n\nChange-Id: I7c6a9b738b86c44031318e74048a1055da822230\n""}, {'number': 4, 'created': '2014-12-11 01:06:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/587899ad2d229dbfad9e110e319276cdb92d54ea', 'message': ""Add I18n-related unit tests (Part 2)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR moves the test_repositories.py module to a new 'repository'\npackage, in anticipation of more repository-related unit tests modules\nin future CRs. This CR also refactors the model/repositories.py module\nto make it a bit more testable.\n\nChange-Id: I7c6a9b738b86c44031318e74048a1055da822230\n""}, {'number': 5, 'created': '2014-12-12 04:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/36a8960659424ab1394b7222f40e5c75916703ac', 'message': ""Add I18n-related unit tests (Part 2)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR moves the test_repositories.py module to a new 'repository'\npackage, in anticipation of more repository-related unit tests modules\nin future CRs. This CR also refactors the model/repositories.py module\nto make it a bit more testable.\n\nChange-Id: I7c6a9b738b86c44031318e74048a1055da822230\n""}, {'number': 6, 'created': '2014-12-13 04:57:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/fa049ca9579593f7aa37ee5d49d5abda69a46ced', 'message': ""Add I18n-related unit tests (Part 2)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR moves the test_repositories.py module to a new 'repository'\npackage, in anticipation of more repository-related unit tests modules\nin future CRs. This CR also refactors the model/repositories.py module\nto make it a bit more testable.\n\nChange-Id: I7c6a9b738b86c44031318e74048a1055da822230\n""}, {'number': 7, 'created': '2014-12-17 19:10:03.000000000', 'files': ['barbican/tests/model/repositories/test_repositories.py', 'barbican/common/exception.py', 'barbican/model/repositories.py', 'barbican/tests/model/repositories/__init__.py', 'bin/demo_requests.py', 'barbican/api/controllers/consumers.py', 'barbican/api/controllers/containers.py', 'barbican/tests/tasks/test_keystone_consumer.py', 'barbican/tests/model/test_repositories.py', 'barbican/tests/api/test_resources.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/e73c83a210e6a4e9aa1d72956e8a23923242c366', 'message': ""Add I18n-related unit tests (Part 2)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR moves the test_repositories.py module to a new 'repository'\npackage, in anticipation of more repository-related unit tests modules\nin future CRs. This CR also refactors the model/repositories.py module\nto make it a bit more testable.\n\nChange-Id: I7c6a9b738b86c44031318e74048a1055da822230\n""}]",12,140811,e73c83a210e6a4e9aa1d72956e8a23923242c366,34,6,7,7789,,,0,"Add I18n-related unit tests (Part 2)

This CR is the first of several dependent CRs that break up the overall
tests added via this abandoned CR:
https://review.openstack.org/#/c/139894
This CR moves the test_repositories.py module to a new 'repository'
package, in anticipation of more repository-related unit tests modules
in future CRs. This CR also refactors the model/repositories.py module
to make it a bit more testable.

Change-Id: I7c6a9b738b86c44031318e74048a1055da822230
",git fetch https://review.opendev.org/openstack/barbican refs/changes/11/140811/2 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/tests/model/repositories/test_repositories.py', 'barbican/common/exception.py', 'barbican/model/repositories.py', 'barbican/tests/model/repositories/__init__.py', 'barbican/tests/model/test_repositories.py']",5,237df20035934554806dfe49553f7a6dbc4b932e,add-i18n-related-unit-tests-make-repos-package,,"# Copyright 2013-2014 Rackspace, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import fixtures import mock from oslo.config import cfg import sqlalchemy.orm as sa_orm from barbican.common import exception from barbican.model import models from barbican.model import repositories from barbican.tests import utils class Database(fixtures.Fixture): def __init__(self): super(Database, self).__init__() repositories.CONF.set_override(""sql_connection"", ""sqlite:///:memory:"") def setUp(self): super(Database, self).setUp() repositories.configure_db() engine = repositories.get_engine() models.register_models(engine) self.addCleanup(lambda: models.unregister_models(engine)) class RepositoryTestCase(utils.BaseTestCase): def setUp(self): super(RepositoryTestCase, self).setUp() self.useFixture(Database()) class TestSecretRepository(RepositoryTestCase): def setUp(self): super(TestSecretRepository, self).setUp() self.repo = repositories.SecretRepo() def test_get_by_create_date(self): session = self.repo.get_session() secret = self.repo.create_from(models.Secret(), session=session) project = models.Tenant(keystone_id=""my keystone id"") project.save(session=session) project_secret = models.TenantSecret( secret_id=secret.id, tenant_id=project.id, ) project_secret.save(session=session) secrets, offset, limit, total = self.repo.get_by_create_date( ""my keystone id"", session=session, ) self.assertEqual([s.id for s in secrets], [secret.id]) self.assertEqual(offset, 0) self.assertEqual(limit, 10) self.assertEqual(total, 1) def test_get_by_create_date_with_name(self): session = self.repo.get_session() secret1 = self.repo.create_from( models.Secret(dict(name=""name1"")), session=session, ) secret2 = self.repo.create_from( models.Secret(dict(name=""name2"")), session=session, ) project = models.Tenant(keystone_id=""my keystone id"") project.save(session=session) project_secret1 = models.TenantSecret( secret_id=secret1.id, tenant_id=project.id, ) project_secret1.save(session=session) project_secret2 = models.TenantSecret( secret_id=secret2.id, tenant_id=project.id, ) project_secret2.save(session=session) secrets, offset, limit, total = self.repo.get_by_create_date( ""my keystone id"", name=""name1"", session=session, ) self.assertEqual([s.id for s in secrets], [secret1.id]) self.assertEqual(offset, 0) self.assertEqual(limit, 10) self.assertEqual(total, 1) def test_get_by_create_date_with_alg(self): session = self.repo.get_session() secret1 = self.repo.create_from( models.Secret(dict(algorithm=""algorithm1"")), session=session, ) secret2 = self.repo.create_from( models.Secret(dict(algorithm=""algorithm2"")), session=session, ) project = models.Tenant(keystone_id=""my keystone id"") project.save(session=session) project_secret1 = models.TenantSecret( secret_id=secret1.id, tenant_id=project.id, ) project_secret1.save(session=session) project_secret2 = models.TenantSecret( secret_id=secret2.id, tenant_id=project.id, ) project_secret2.save(session=session) secrets, offset, limit, total = self.repo.get_by_create_date( ""my keystone id"", alg=""algorithm1"", session=session, ) self.assertEqual([s.id for s in secrets], [secret1.id]) self.assertEqual(offset, 0) self.assertEqual(limit, 10) self.assertEqual(total, 1) def test_get_by_create_date_with_mode(self): session = self.repo.get_session() secret1 = self.repo.create_from( models.Secret(dict(mode=""mode1"")), session=session, ) secret2 = self.repo.create_from( models.Secret(dict(mode=""mode2"")), session=session, ) project = models.Tenant(keystone_id=""my keystone id"") project.save(session=session) project_secret1 = models.TenantSecret( secret_id=secret1.id, tenant_id=project.id, ) project_secret1.save(session=session) project_secret2 = models.TenantSecret( secret_id=secret2.id, tenant_id=project.id, ) project_secret2.save(session=session) secrets, offset, limit, total = self.repo.get_by_create_date( ""my keystone id"", mode=""mode1"", session=session, ) self.assertEqual([s.id for s in secrets], [secret1.id]) self.assertEqual(offset, 0) self.assertEqual(limit, 10) self.assertEqual(total, 1) def test_get_by_create_date_with_bits(self): session = self.repo.get_session() secret1 = self.repo.create_from( models.Secret(dict(bit_length=1024)), session=session, ) secret2 = self.repo.create_from( models.Secret(dict(bit_length=2048)), session=session, ) project = models.Tenant(keystone_id=""my keystone id"") project.save(session=session) project_secret1 = models.TenantSecret( secret_id=secret1.id, tenant_id=project.id, ) project_secret1.save(session=session) project_secret2 = models.TenantSecret( secret_id=secret2.id, tenant_id=project.id, ) project_secret2.save(session=session) secrets, offset, limit, total = self.repo.get_by_create_date( ""my keystone id"", bits=1024, session=session, ) self.assertEqual([s.id for s in secrets], [secret1.id]) self.assertEqual(offset, 0) self.assertEqual(limit, 10) self.assertEqual(total, 1) def test_get_by_create_date_nothing(self): session = self.repo.get_session() secrets, offset, limit, total = self.repo.get_by_create_date( ""my keystone id"", bits=1024, session=session, ) self.assertEqual(secrets, []) self.assertEqual(offset, 0) self.assertEqual(limit, 10) self.assertEqual(total, 0) def test_do_entity_name(self): self.assertEqual(self.repo._do_entity_name(), ""Secret"") def test_do_create_instance(self): self.assertIsInstance(self.repo._do_create_instance(), models.Secret) class WhenCleaningRepositoryPagingParameters(utils.BaseTestCase): def setUp(self): super(WhenCleaningRepositoryPagingParameters, self).setUp() self.CONF = cfg.CONF def test_parameters_not_assigned(self): """"""The cleaner should use defaults when params are not specified."""""" clean_offset, clean_limit = repositories.clean_paging_values() self.assertEqual(clean_offset, 0) self.assertEqual(clean_limit, self.CONF.default_limit_paging) def test_limit_as_none(self): """"""When Limit is set to None it should use the default limit."""""" offset = 0 clean_offset, clean_limit = repositories.clean_paging_values( offset_arg=offset, limit_arg=None) self.assertEqual(clean_offset, offset) self.assertIsNotNone(clean_limit) def test_offset_as_none(self): """"""When Offset is set to None it should use an offset of 0."""""" limit = self.CONF.default_limit_paging clean_offset, clean_limit = repositories.clean_paging_values( offset_arg=None, limit_arg=limit) self.assertIsNotNone(clean_offset) self.assertEqual(clean_limit, limit) def test_limit_as_uncastable_str(self): """"""When Limit cannot be cast to an int, expect the default."""""" clean_offset, clean_limit = repositories.clean_paging_values( offset_arg=0, limit_arg='boom') self.assertEqual(clean_offset, 0) self.assertEqual(clean_limit, self.CONF.default_limit_paging) def test_offset_as_uncastable_str(self): """"""When Offset cannot be cast to an int, it should be zero."""""" limit = self.CONF.default_limit_paging clean_offset, clean_limit = repositories.clean_paging_values( offset_arg='boom', limit_arg=limit) self.assertEqual(clean_offset, 0) self.assertEqual(clean_limit, limit) def test_limit_is_less_than_one(self): """"""Offset should default to 1."""""" limit = -1 clean_offset, clean_limit = repositories.clean_paging_values( offset_arg=1, limit_arg=limit) self.assertEqual(clean_offset, 1) self.assertEqual(clean_limit, 1) def test_limit_ist_too_big(self): """"""Limit should max out at configured value."""""" limit = self.CONF.max_limit_paging + 10 clean_offset, clean_limit = repositories.clean_paging_values( offset_arg=1, limit_arg=limit) self.assertEqual(clean_limit, self.CONF.max_limit_paging) def test_should_raise_exception_create_kek_datum_with_null_name(self): repositories._ENGINE = mock.MagicMock() project = mock.MagicMock(id=""1"") plugin_name = None suppress_exception = False session = mock.MagicMock() session.query.side_effect = sa_orm.exc.NoResultFound() kek_repo = repositories.KEKDatumRepo() self.assertRaises(exception.BarbicanException, kek_repo.find_or_create_kek_datum, project, plugin_name, suppress_exception, session) def test_should_raise_exception_create_kek_datum_with_empty_name(self): repositories._ENGINE = mock.MagicMock() project = mock.MagicMock(id=""1"") plugin_name = """" suppress_exception = False session = mock.MagicMock() session.query.side_effect = sa_orm.exc.NoResultFound() kek_repo = repositories.KEKDatumRepo() self.assertRaises(exception.BarbicanException, kek_repo.find_or_create_kek_datum, project, plugin_name, suppress_exception, session) ",489,628
openstack%2Fswift~master~I95ee52dc00dda85a08b7744cb515e9fb1707307b,openstack/swift,master,I95ee52dc00dda85a08b7744cb515e9fb1707307b,"Merge ""fix dlo manifest file getting versioned""",ABANDONED,2014-12-19 10:41:51.000000000,2014-12-19 21:20:27.000000000,,"[{'_account_id': 3}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-12-19 10:41:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/21f9b063f0ca1d953ce0116327ec144d88a23447', 'message': 'Merge ""fix dlo manifest file getting versioned""\n\nChange-Id: I95ee52dc00dda85a08b7744cb515e9fb1707307b\n'}]",0,143033,21f9b063f0ca1d953ce0116327ec144d88a23447,4,2,1,11131,,,0,"Merge ""fix dlo manifest file getting versioned""

Change-Id: I95ee52dc00dda85a08b7744cb515e9fb1707307b
",git fetch https://review.opendev.org/openstack/swift refs/changes/33/143033/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,21f9b063f0ca1d953ce0116327ec144d88a23447,merge/release-tag,,,0,0
openstack%2Fnova~master~Ib67880d0380b539c3a5b12a14ea9ed71b7b588a3,openstack/nova,master,Ib67880d0380b539c3a5b12a14ea9ed71b7b588a3,Make update server schema 'additionalProperties' False,MERGED,2014-12-15 01:54:42.000000000,2014-12-19 21:10:51.000000000,2014-12-19 21:10:47.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-15 01:54:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b5ce1e6740914a1ec62802924a368b3a998697f8', 'message': ""Fix update server test for strong input validation\n\nNova V2.1 API has strong input validation by making validation\nthrough JSON schema.\n\nThis patch fix below update server tests for extra input passed\nin request body-\n    test_update_server_admin_password_ignored\n\nThis is needed to make 'additionalProperties' False in update_server\nschema.\n\nNOTE- Currently 'additionalProperties' is not False in update_server\nschema thats why this tests does not fail.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ib67880d0380b539c3a5b12a14ea9ed71b7b588a3\n""}, {'number': 2, 'created': '2014-12-15 02:25:23.000000000', 'files': ['nova/api/openstack/compute/schemas/v3/servers.py', 'nova/tests/unit/api/openstack/compute/plugins/v3/test_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f9a9865ae811aff89a2bf9b5d3a7c68710d098ae', 'message': ""Make update server schema 'additionalProperties' False\n\nNova V2.1 API has strong input validation by making validation\nthrough JSON schema.\n\nThis patch makes update server schema 'additionalProperties' to False\nas all update server extensions are implemented in V2.1.\n\nAfter this, V2.1 will not allow extra arg for update server.\n\nThis patch also modify the corresponding update server tests\nfor extra input passed in request body-\n    test_update_server_admin_password_ignored\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Ib67880d0380b539c3a5b12a14ea9ed71b7b588a3\n""}]",0,141691,f9a9865ae811aff89a2bf9b5d3a7c68710d098ae,33,12,2,8556,,,0,"Make update server schema 'additionalProperties' False

Nova V2.1 API has strong input validation by making validation
through JSON schema.

This patch makes update server schema 'additionalProperties' to False
as all update server extensions are implemented in V2.1.

After this, V2.1 will not allow extra arg for update server.

This patch also modify the corresponding update server tests
for extra input passed in request body-
    test_update_server_admin_password_ignored

Partially implements blueprint v2-on-v3-api

Change-Id: Ib67880d0380b539c3a5b12a14ea9ed71b7b588a3
",git fetch https://review.opendev.org/openstack/nova refs/changes/91/141691/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/api/openstack/compute/plugins/v3/test_servers.py'],1,b5ce1e6740914a1ec62802924a368b3a998697f8,bp/v2-on-v3-api," def test_update_server_admin_password_extra_arg(self): self.assertRaises(exception.ValidationError, self.controller.update, req, FAKE_UUID, body=body)"," def test_update_server_admin_password_ignored(self): def server_update(context, id, params): filtered_dict = { 'display_name': 'server_test', } self.assertEqual(params, filtered_dict) filtered_dict['uuid'] = id return filtered_dict self.stubs.Set(db, 'instance_update', server_update) # FIXME (comstud) # self.stubs.Set(db, 'instance_get', # return_server_with_attributes(name='server_test')) res_dict = self.controller.update(req, FAKE_UUID, body=body) self.assertEqual(res_dict['server']['id'], FAKE_UUID) self.assertEqual(res_dict['server']['name'], 'server_test')",3,19
openstack%2Fhorizon~master~Ide9109ca22a04b9121bc78eeea26be9ef2adbf97,openstack/horizon,master,Ide9109ca22a04b9121bc78eeea26be9ef2adbf97,Add volume type encryption delete,MERGED,2014-12-08 16:19:09.000000000,2014-12-19 21:10:38.000000000,2014-12-19 21:10:37.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 7012}, {'_account_id': 9622}, {'_account_id': 9981}]","[{'number': 1, 'created': '2014-12-08 16:19:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c9e17abffdeceb8a779fd66235e25074bae42359', 'message': 'Add volume type encryption delete\n\nThis patch adds support to horizon for volume type encryption\ndelete.  The contents of this patch were originally a part of\na combined volume type encryption update and delete patch,\n(https://review.openstack.org/#/c/72024/) but the delete\nportion has been moved to this patch since the pieces do not\ndepend on each other.\n\nThe modifications are made to the Admin Volume Type table, and\nadd the Delete Encryption action to the action column. Unit\ntests are also included.\n\nChange-Id: Ide9109ca22a04b9121bc78eeea26be9ef2adbf97\nImplements: blueprint integration-with-cinder-volume-encryption\n'}, {'number': 2, 'created': '2014-12-09 15:53:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e2cf040f89bf230e1f513bcf431ab56d250a58eb', 'message': 'Add volume type encryption delete\n\nThis patch adds support to horizon for volume type encryption\ndelete.  The contents of this patch were originally a part of\na combined volume type encryption update and delete patch,\n(https://review.openstack.org/#/c/72024/) but the delete\nportion has been moved to this patch since the pieces do not\ndepend on each other.\n\nThe modifications are made to the Admin Volume Type table, and\nadd the Delete Encryption action to the action column. Unit\ntests are also included.\n\nChange-Id: Ide9109ca22a04b9121bc78eeea26be9ef2adbf97\nImplements: blueprint integration-with-cinder-volume-encryption\n'}, {'number': 3, 'created': '2014-12-15 14:38:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b01202d0bc0219bb1c1436e6462c8c4f174daffc', 'message': 'Add volume type encryption delete\n\nThis patch adds support to horizon for volume type encryption\ndelete.  The contents of this patch were originally a part of\na combined volume type encryption update and delete patch,\n(https://review.openstack.org/#/c/72024/) but the delete\nportion has been moved to this patch since the pieces do not\ndepend on each other.\n\nThe modifications are made to the Admin Volume Type table, and\nadd the Delete Encryption action to the action column. Unit\ntests are also included.\n\nChange-Id: Ide9109ca22a04b9121bc78eeea26be9ef2adbf97\nImplements: blueprint integration-with-cinder-volume-encryption\n'}, {'number': 4, 'created': '2014-12-16 16:04:02.000000000', 'files': ['openstack_dashboard/dashboards/admin/volumes/tests.py', 'openstack_dashboard/dashboards/admin/volumes/volume_types/tables.py', 'openstack_dashboard/api/cinder.py', 'openstack_dashboard/dashboards/admin/volumes/volume_types/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/9f73f80e21a3509c6560502ebbd5e806b2edbca9', 'message': 'Add volume type encryption delete\n\nThis patch adds support to horizon for volume type encryption\ndelete.  The contents of this patch were originally a part of\na combined volume type encryption update and delete patch,\n(https://review.openstack.org/#/c/72024/) but the delete\nportion has been moved to this patch since the pieces do not\ndepend on each other.\n\nThe modifications are made to the Admin Volume Type table, and\nadd the Delete Encryption action to the action column. Unit\ntests are also included.\n\nChange-Id: Ide9109ca22a04b9121bc78eeea26be9ef2adbf97\nImplements: blueprint integration-with-cinder-volume-encryption\n'}]",10,140055,9f73f80e21a3509c6560502ebbd5e806b2edbca9,23,6,4,7012,,,0,"Add volume type encryption delete

This patch adds support to horizon for volume type encryption
delete.  The contents of this patch were originally a part of
a combined volume type encryption update and delete patch,
(https://review.openstack.org/#/c/72024/) but the delete
portion has been moved to this patch since the pieces do not
depend on each other.

The modifications are made to the Admin Volume Type table, and
add the Delete Encryption action to the action column. Unit
tests are also included.

Change-Id: Ide9109ca22a04b9121bc78eeea26be9ef2adbf97
Implements: blueprint integration-with-cinder-volume-encryption
",git fetch https://review.opendev.org/openstack/horizon refs/changes/55/140055/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/volumes/tests.py', 'openstack_dashboard/dashboards/admin/volumes/volume_types/tables.py', 'openstack_dashboard/api/cinder.py', 'openstack_dashboard/dashboards/admin/volumes/volume_types/tests.py']",4,c9e17abffdeceb8a779fd66235e25074bae42359,bp/integration-with-cinder-volume-encryption," @test.create_stubs({cinder: ('extension_supported', 'volume_type_list_with_qos_associations', 'qos_spec_list', 'volume_encryption_type_list', 'volume_encryption_type_delete',)}) def test_delete_volume_type_encryption(self): volume_type = self.volume_types.first() volume_type.id = u'1' formData = {'action': 'volume_types__delete_encryption__%s' % volume_type.id} encryption_list = (self.cinder_volume_encryption_types.list()[0], self.cinder_volume_encryption_types.list()[1]) cinder.extension_supported(IsA(http.HttpRequest), 'VolumeTypeEncryption')\ .AndReturn(True) cinder.volume_type_list_with_qos_associations( IsA(http.HttpRequest))\ .AndReturn(self.volume_types.list()) cinder.qos_spec_list(IsA(http.HttpRequest))\ .AndReturn(self.cinder_qos_specs.list()) cinder.volume_encryption_type_list(IsA(http.HttpRequest))\ .AndReturn(encryption_list) cinder.volume_encryption_type_delete(IsA(http.HttpRequest), volume_type.id) self.mox.ReplayAll() res = self.client.post( reverse('horizon:admin:volumes:volume_types_tab'), formData) redirect = reverse('horizon:admin:volumes:volume_types_tab') self.assertNoFormErrors(res) self.assertRedirectsNoFollow(res, redirect)",,62,4
openstack%2Fnova~master~I26003dc27a2bc3f30f1b09000533b571096c8b21,openstack/nova,master,I26003dc27a2bc3f30f1b09000533b571096c8b21,Remove instance_uuids from request_spec,MERGED,2014-12-15 16:07:47.000000000,2014-12-19 21:09:36.000000000,2014-12-19 21:09:32.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5754}, {'_account_id': 7166}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-15 16:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a12f1261526d92e1fe3c22d594c0dc4fb0519829', 'message': 'Remove instance_uuids from request_spec\n\ninstance_uuids was previously deprecated in Scheduler RPC API 3.0, so now we\nbumped the version to 4.0, there is no longer methods which need this.\n\nSo, we can just remove it from FilterScheduler._schedule() method and also\nleave sched_utils.the set_vm_state_and_notify() method use the uuid from\ninstance_properties\n\nChange-Id: I26003dc27a2bc3f30f1b09000533b571096c8b21\nPartially-Implements: blueprint request-spec-object\n'}, {'number': 2, 'created': '2014-12-16 17:17:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1e90ef0058d6e3f09441942d4afcd094ba4c63e3', 'message': 'Remove instance_uuids from request_spec\n\ninstance_uuids was previously deprecated in Scheduler RPC API 3.0, so now we\nbumped the version to 4.0, there is no longer methods which need this.\n\nSo, we can just remove it from FilterScheduler._schedule() method and also\nleave sched_utils.set_vm_state_and_notify() method use the uuid from\ninstance_properties\n\nChange-Id: I26003dc27a2bc3f30f1b09000533b571096c8b21\nPartially-Implements: blueprint request-spec-object\n'}, {'number': 3, 'created': '2014-12-16 20:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/609b3903d676900de27fa8d93ea7945199bddf0c', 'message': 'Remove instance_uuids from request_spec\n\ninstance_uuids was previously deprecated in Scheduler RPC API 3.0, so now we\nbumped the version to 4.0, there is no longer methods which need this.\n\nSo, we can just remove it from FilterScheduler._schedule() method and also\nleave sched_utils.set_vm_state_and_notify() method use the uuid from\ninstance_properties\n\nChange-Id: I26003dc27a2bc3f30f1b09000533b571096c8b21\nPartially-Implements: blueprint request-spec-object\n'}, {'number': 4, 'created': '2014-12-16 22:43:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/67a456bdde5522ea33fcfce61fdbb1fce583f813', 'message': 'Remove instance_uuids from request_spec\n\ninstance_uuids was previously deprecated in Scheduler RPC API 3.0, so now we\nbumped the version to 4.0, there is no longer methods which need this.\n\nSo, we can just remove it from FilterScheduler._schedule() method and also\nleave sched_utils.set_vm_state_and_notify() method use the uuid from\ninstance_properties\n\nChange-Id: I26003dc27a2bc3f30f1b09000533b571096c8b21\nPartially-Implements: blueprint request-spec-object\n'}, {'number': 5, 'created': '2014-12-17 11:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b5eb276d989aabfc085ccc63e43c86305e0c5b01', 'message': 'Remove instance_uuids from request_spec\n\ninstance_uuids was previously deprecated in Scheduler RPC API 3.0, so now we\nbumped the version to 4.0, there is no longer methods which need this.\n\nSo, we can just remove it from FilterScheduler._schedule() method and also\nleave sched_utils.set_vm_state_and_notify() method use the uuid from\ninstance_properties.\nscheduler_utils.setup_instance_group() is also modified to get the uuid\nfrom instance_properties.\n\nChange-Id: I26003dc27a2bc3f30f1b09000533b571096c8b21\nPartially-Implements: blueprint request-spec-object\n'}, {'number': 6, 'created': '2014-12-17 11:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c1a268c188b75715b0b9bd9e984aa7595876afdd', 'message': 'Remove instance_uuids from request_spec\n\ninstance_uuids was previously deprecated in Scheduler RPC API 3.0, so now we\nbumped the version to 4.0, there is no longer methods which need this.\n\nSo, we can just remove it from FilterScheduler._schedule() method and also\nleave sched_utils.set_vm_state_and_notify() method use the uuid from\ninstance_properties.\nscheduler_utils.setup_instance_group() is also modified to get the uuid\nfrom instance_properties.\n\nChange-Id: I26003dc27a2bc3f30f1b09000533b571096c8b21\nPartially-Implements: blueprint request-spec-object\n'}, {'number': 7, 'created': '2014-12-18 11:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cbe7a281550cf26efcd745bce9975de37850744d', 'message': 'Remove instance_uuids from request_spec\n\ninstance_uuids was previously deprecated in Scheduler RPC API 3.0, so now we\nbumped the version to 4.0, there is no longer methods which need this.\n\nSo, we can just remove it from FilterScheduler._schedule() method and also\nleave sched_utils.set_vm_state_and_notify() method use the uuid from\ninstance_properties.\nscheduler_utils.setup_instance_group() is also modified to get the uuid\nfrom instance_properties.\n\nChange-Id: I26003dc27a2bc3f30f1b09000533b571096c8b21\nPartially-Implements: blueprint request-spec-object\n'}, {'number': 8, 'created': '2014-12-18 13:40:16.000000000', 'files': ['nova/scheduler/utils.py', 'nova/tests/unit/conductor/test_conductor.py', 'nova/scheduler/filter_scheduler.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/cells/test_cells_scheduler.py', 'nova/conductor/manager.py', 'nova/compute/manager.py', 'nova/tests/unit/scheduler/test_scheduler_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/15e6a5d0e4f0ad2ce9d2f71f783de9396df1d59b', 'message': 'Remove instance_uuids from request_spec\n\ninstance_uuids was previously deprecated in Scheduler RPC API 3.0, so now we\nbumped the version to 4.0, there is no longer methods which need this.\n\nSo, we can just remove it from FilterScheduler._schedule() method and also\nleave sched_utils.set_vm_state_and_notify() method use the uuid from\ninstance_properties.\nscheduler_utils.setup_instance_group() is also modified to get the uuid\nfrom instance_properties.\n\nChange-Id: I26003dc27a2bc3f30f1b09000533b571096c8b21\nPartially-Implements: blueprint request-spec-object\n'}]",15,141833,15e6a5d0e4f0ad2ce9d2f71f783de9396df1d59b,54,9,8,7166,,,0,"Remove instance_uuids from request_spec

instance_uuids was previously deprecated in Scheduler RPC API 3.0, so now we
bumped the version to 4.0, there is no longer methods which need this.

So, we can just remove it from FilterScheduler._schedule() method and also
leave sched_utils.set_vm_state_and_notify() method use the uuid from
instance_properties.
scheduler_utils.setup_instance_group() is also modified to get the uuid
from instance_properties.

Change-Id: I26003dc27a2bc3f30f1b09000533b571096c8b21
Partially-Implements: blueprint request-spec-object
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/141833/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/utils.py', 'nova/scheduler/filter_scheduler.py', 'nova/tests/unit/scheduler/test_scheduler_utils.py']",3,a12f1261526d92e1fe3c22d594c0dc4fb0519829,bp/request-spec-object," expected_uuid): db.instance_update_and_get_original( self.context, expected_uuid, updates).AndReturn((old_ref, new_ref)) notifications.send_update(self.context, old_ref, new_ref, service=service) compute_utils.add_instance_fault_from_exc( self.context, new_ref, exc_info, mox.IsA(tuple)) payload = dict(request_spec=request_spec, instance_properties=request_spec.get( 'instance_properties', {}), instance_id=expected_uuid, state='fake-vm-state', method=method, reason=exc_info) event_type = '%s.%s' % (service, method) notifier.error(self.context, event_type, payload) def test_set_vm_state_and_notify_uuid_from_instance_props(self): expected_uuid = 'fake-uuid' self._test_set_vm_state_and_notify(request_spec, expected_uuid)"," expected_uuids): for _uuid in expected_uuids: db.instance_update_and_get_original( self.context, _uuid, updates).AndReturn((old_ref, new_ref)) notifications.send_update(self.context, old_ref, new_ref, service=service) compute_utils.add_instance_fault_from_exc( self.context, new_ref, exc_info, mox.IsA(tuple)) payload = dict(request_spec=request_spec, instance_properties=request_spec.get( 'instance_properties', {}), instance_id=_uuid, state='fake-vm-state', method=method, reason=exc_info) event_type = '%s.%s' % (service, method) notifier.error(self.context, event_type, payload) def test_set_vm_state_and_notify_rs_uuids(self): expected_uuids = ['1', '2', '3'] request_spec = dict(instance_uuids=expected_uuids) self._test_set_vm_state_and_notify(request_spec, expected_uuids) def test_set_vm_state_and_notify_uuid_from_instance_props(self): expected_uuids = ['fake-uuid'] self._test_set_vm_state_and_notify(request_spec, expected_uuids)",42,60
openstack%2Fmonasca-api~master~Ib82a064fd00f25a96c9b5b5294ada301270ab93c,openstack/monasca-api,master,Ib82a064fd00f25a96c9b5b5294ada301270ab93c,Don't treat the Agent role as a restriction,MERGED,2014-12-19 21:04:09.000000000,2014-12-19 21:08:45.000000000,2014-12-19 21:08:43.000000000,"[{'_account_id': 3}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-12-19 21:04:09.000000000', 'files': ['src/main/java/monasca/api/infrastructure/servlet/PostAuthenticationFilter.java', 'src/main/java/monasca/api/infrastructure/servlet/RoleAuthorizationFilter.java', 'README.md'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/6783ad6430942fbd7079dc4fb5902ee437838c1b', 'message': ""Don't treat the Agent role as a restriction\n\nPreviously, the Agent role forced the user to only be able to post\nmetrics. Now, it checks the defaultAuthorizedRoles first and only\nif the user has none of those roles does it check for\nagentAuthorizedRoles. A user with roles in both will still have\nfull access\n\nAdded explanation of the Keystone Authentication/Authorization\nto the README\n\nChange-Id: Ib82a064fd00f25a96c9b5b5294ada301270ab93c\n""}]",0,143190,6783ad6430942fbd7079dc4fb5902ee437838c1b,6,2,1,11809,,,0,"Don't treat the Agent role as a restriction

Previously, the Agent role forced the user to only be able to post
metrics. Now, it checks the defaultAuthorizedRoles first and only
if the user has none of those roles does it check for
agentAuthorizedRoles. A user with roles in both will still have
full access

Added explanation of the Keystone Authentication/Authorization
to the README

Change-Id: Ib82a064fd00f25a96c9b5b5294ada301270ab93c
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/90/143190/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/main/java/monasca/api/infrastructure/servlet/PostAuthenticationFilter.java', 'src/main/java/monasca/api/infrastructure/servlet/RoleAuthorizationFilter.java', 'README.md']",3,6783ad6430942fbd7079dc4fb5902ee437838c1b,,"## Keystone Configuration For secure operation of the Monasca API, the API must be configured to use Keystone in the configuration file under the middleware section. Monasca only works with a Keystone v3 server. The important parts of the configuration are explained below: * serverVIP - This is the hostname or IP Address of the Keystone server * serverPort - The port for the Keystone server * useHttps - Whether to use https when making requests of the Keystone API * truststore - If useHttps is true and the Keystone server is not using a certificate signed by a public CA recognized by Java, the CA certificate can be placed in a truststore so the Monasca API will trust it, otherwise it will reject the https connection. This must be a JKS truststore * truststorePassword - The password for the above truststore * connSSLClientAuth - If the Keystone server requires the SSL client used by the Monasca server to have a specific client certificate, this should be true, false otherwise * keystore - The keystore holding the SSL Client certificate if connSSLClientAuth is true * keystorePassword - The password for the keystore * defaultAuthorizedRoles - An array of roles that authorize a user to access the complete Monasca API. User must have at least one of these roles. See below * agentAuthorizedRoles - An array of roles that authorize only the posting of metrics. See Keystone Roles below * adminAuthMethod - ""password"" if the Monasca API should adminUser and adminPassword to login to the Keystone server to check the user's token, ""token"" if the Monasca API should use adminToken * adminUser - Admin user name * adminPassword - Admin user password * adminToken - A valid admin user token if adminAuthMethod is token * timeToCacheToken - How long the Monasca API should cache the user's token before checking it again ### Keystone Roles The Monasca API has two levels of access: # Full access - user can read/write metrics and Alarm Definitions and Alarms # Agent access - user can only write metrics The reason for the ""Agent access"" level is because the Monasca Agent must be configured to use a Keystone user. Since the user and password are configured onto the all of the systems running the Monasca Agent, this user is most in danger of being compromised. If this user is limited to only writing metrics, then the damage can be limited. To configure the user to have full access, the user must have a role that is listed in defaultAuthorizedRoles. To configure a user to have only ""Agent access"", the user must have a role in agentAuthorizedRoles and none of the roles in defaultAuthorizedRoles. ",,58,14
openstack%2Fcongress~master~Ie786451c98fbbb97064bc53551be20b67bd32030,openstack/congress,master,Ie786451c98fbbb97064bc53551be20b67bd32030,Remove E113 comment,MERGED,2014-12-18 07:30:31.000000000,2014-12-19 21:07:12.000000000,2014-12-19 21:07:10.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-18 07:30:31.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/congress/commit/459f716bba0b1c11c1b1914ccd8a5ded50ff0390', 'message': 'Remove E113 comment\n\nE113 was already implement but the comment was never removed. This commit\nremoves it.\n\nChange-Id: Ie786451c98fbbb97064bc53551be20b67bd32030\n'}]",0,142696,459f716bba0b1c11c1b1914ccd8a5ded50ff0390,10,4,1,4395,,,0,"Remove E113 comment

E113 was already implement but the comment was never removed. This commit
removes it.

Change-Id: Ie786451c98fbbb97064bc53551be20b67bd32030
",git fetch https://review.opendev.org/openstack/congress refs/changes/96/142696/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,459f716bba0b1c11c1b1914ccd8a5ded50ff0390,,,# E113 unexpected indentation,0,1
openstack%2Fcongress~master~Idb8ba1075e295e61b13fb8e844421edfda97d810,openstack/congress,master,Idb8ba1075e295e61b13fb8e844421edfda97d810,Circular import of compile/runtime/unify,MERGED,2014-12-19 10:45:52.000000000,2014-12-19 20:57:39.000000000,2014-12-19 20:57:38.000000000,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-19 10:45:52.000000000', 'files': ['congress/policy/unify.py', 'congress/policy/runtime.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/5e6188217508585d489ef5069d4714981b5becb6', 'message': 'Circular import of compile/runtime/unify\n\nThe circular import has already been resolved but the comment still remains in\nthe code with FIXME tag. The comment has been removed to avoid confusion.\n\nChange-Id: Idb8ba1075e295e61b13fb8e844421edfda97d810\nCloses-Bug: #1339814\n'}]",0,143034,5e6188217508585d489ef5069d4714981b5becb6,7,3,1,12293,,,0,"Circular import of compile/runtime/unify

The circular import has already been resolved but the comment still remains in
the code with FIXME tag. The comment has been removed to avoid confusion.

Change-Id: Idb8ba1075e295e61b13fb8e844421edfda97d810
Closes-Bug: #1339814
",git fetch https://review.opendev.org/openstack/congress refs/changes/34/143034/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/policy/unify.py', 'congress/policy/runtime.py']",2,5e6188217508585d489ef5069d4714981b5becb6,bugfix/1339814,,# FIXME there is a circular import here because compile.py imports runtime.py,0,2
openstack%2Fproject-config~master~I358fb649bfee472d47641e2780208bac7521e0d3,openstack/project-config,master,I358fb649bfee472d47641e2780208bac7521e0d3,"Revert ""Push dg-tempest-dsvm-full logs to swift""",MERGED,2014-12-19 20:40:44.000000000,2014-12-19 20:57:21.000000000,2014-12-19 20:57:20.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 5638}, {'_account_id': 7069}]","[{'number': 1, 'created': '2014-12-19 20:40:44.000000000', 'files': ['jenkins/jobs/macros.yaml', 'jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9fe1a61101890af1b405c87ba244fb3cc044e4d9', 'message': 'Revert ""Push dg-tempest-dsvm-full logs to swift""\n\nThis reverts commit 4bde0571f968909bd6c85bccdea95a1de6c8c7f0.\n\nThe upload script lacks the necessary requirements (the ""magic""\nlibrary at least) in the system context on devstack-.* workers.\n\nChange-Id: I358fb649bfee472d47641e2780208bac7521e0d3\n'}]",0,143185,9fe1a61101890af1b405c87ba244fb3cc044e4d9,8,5,1,5263,,,0,"Revert ""Push dg-tempest-dsvm-full logs to swift""

This reverts commit 4bde0571f968909bd6c85bccdea95a1de6c8c7f0.

The upload script lacks the necessary requirements (the ""magic""
library at least) in the system context on devstack-.* workers.

Change-Id: I358fb649bfee472d47641e2780208bac7521e0d3
",git fetch https://review.opendev.org/openstack/project-config refs/changes/85/143185/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/macros.yaml', 'jenkins/jobs/devstack-gate.yaml']",2,9fe1a61101890af1b405c87ba244fb3cc044e4d9,swift-logs,, - zuul-swift-devstack-logs - zuul-swift-upload-console-log - zuul-swift-devstack-logs - zuul-swift-upload-console-log,0,10
openstack%2Fcongress~master~I3705a2d6c386aafd26d9c1f95e3e448ac10f0a3d,openstack/congress,master,I3705a2d6c386aafd26d9c1f95e3e448ac10f0a3d,Include congress in ENABLED_SERVICES,MERGED,2014-12-12 00:08:38.000000000,2014-12-19 20:57:14.000000000,2014-12-19 20:57:13.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-12 00:08:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/499ff3326384fdcd0fdc244a372cf1fe88c06124', 'message': 'Include congress in ENABLED_SERVICES\n\nChange-Id: I3705a2d6c386aafd26d9c1f95e3e448ac10f0a3d\n'}, {'number': 2, 'created': '2014-12-12 23:00:15.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/congress/commit/3e80c177d693fae667020524fddaf4b408022562', 'message': 'Include congress in ENABLED_SERVICES\n\nChange-Id: I3705a2d6c386aafd26d9c1f95e3e448ac10f0a3d\n'}]",0,141225,3e80c177d693fae667020524fddaf4b408022562,13,4,2,4395,,,0,"Include congress in ENABLED_SERVICES

Change-Id: I3705a2d6c386aafd26d9c1f95e3e448ac10f0a3d
",git fetch https://review.opendev.org/openstack/congress refs/changes/25/141225/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,499ff3326384fdcd0fdc244a372cf1fe88c06124,,"Configure ENABLED_SERVICES in the devstack/localrc file (make sure to include congress):: ENABLED_SERVICES=congress,g-api,g-reg,key,n-api,n-crt,n-obj,n-cpu,n-sch,n-cauth,horizon,mysql,rabbit,sysstat,cinder,c-api,c-vol,c-sch,n-cond,quantum,q-svc,q-agt,q-dhcp,q-l3,q-meta,n-novnc,n-xvnc,q-lbaas,ceilometer-acompute,ceilometer-acentral,ceilometer-anotification,ceilometer-collector,ceilometer-alarm-evaluator,ceilometer-alarm-notifier,ceilometer-api,s-proxy,s-object,s-container,s-account","Configure ENABLED_SERVICES in the devstack/localrc file:: ENABLED_SERVICES=g-api,g-reg,key,n-api,n-crt,n-obj,n-cpu,n-sch,n-cauth,horizon,mysql,rabbit,sysstat,cinder,c-api,c-vol,c-sch,n-cond,quantum,q-svc,q-agt,q-dhcp,q-l3,q-meta,n-novnc,n-xvnc,q-lbaas,ceilometer-acompute,ceilometer-acentral,ceilometer-anotification,ceilometer-collector,ceilometer-alarm-evaluator,ceilometer-alarm-notifier,ceilometer-api,s-proxy,s-object,s-container,s-account",2,2
openstack%2Fopenstack-ansible~stable%2Fjuno~I8d100be2461cb25a3f17b81d5e452e4b0cfd3a64,openstack/openstack-ansible,stable/juno,I8d100be2461cb25a3f17b81d5e452e4b0cfd3a64,tag for release 10.1.1,MERGED,2014-12-19 20:01:18.000000000,2014-12-19 20:51:13.000000000,2014-12-19 20:04:14.000000000,"[{'_account_id': 3}, {'_account_id': 7414}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-19 20:01:18.000000000', 'files': ['rpc_deployment/vars/repo_packages/raxmon_agent.yml', 'rpc_deployment/vars/repo_packages/os-ansible-deployment.yml', 'scripts/rpc-aio-rax-heat-template.yml', 'rpc_deployment/inventory/group_vars/all.yml', 'scripts/cloudserver-aio.sh', 'scripts/rpc-aio-heat-template.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ac5a9815eadbb42eda959f0872542ee3a1dfad6d', 'message': 'tag for release 10.1.1\n\nChange-Id: I8d100be2461cb25a3f17b81d5e452e4b0cfd3a64\n'}]",0,143173,ac5a9815eadbb42eda959f0872542ee3a1dfad6d,7,3,1,7353,,,0,"tag for release 10.1.1

Change-Id: I8d100be2461cb25a3f17b81d5e452e4b0cfd3a64
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/73/143173/1 && git format-patch -1 --stdout FETCH_HEAD,"['rpc_deployment/vars/repo_packages/raxmon_agent.yml', 'rpc_deployment/vars/repo_packages/os-ansible-deployment.yml', 'scripts/rpc-aio-rax-heat-template.yml', 'rpc_deployment/inventory/group_vars/all.yml', 'scripts/cloudserver-aio.sh', 'scripts/rpc-aio-heat-template.yml']",6,ac5a9815eadbb42eda959f0872542ee3a1dfad6d,, default: https://raw.githubusercontent.com/stackforge/os-ansible-deployment/10.1.1/scripts/cloudserver-aio.sh default: 10.1.1, default: https://raw.githubusercontent.com/stackforge/os-ansible-deployment/10.1.0rc2/scripts/cloudserver-aio.sh default: 10.1.0rc2,8,8
openstack%2Fdevstack-gate~master~Ic7afaf1f2fbd76396ea5f66d59a4e08371fe8864,openstack/devstack-gate,master,Ic7afaf1f2fbd76396ea5f66d59a4e08371fe8864,WIP: Just checking if any jobs fail with ImportError in zuul_swift_upload.py,ABANDONED,2014-12-19 19:29:08.000000000,2014-12-19 20:44:37.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-19 19:29:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/8302f82057c4f93cbaead6962eab048d7683a1d4', 'message': 'WIP: Just checking if any jobs fail with ImportError in zuul_swift_upload.py\n\nChange-Id: Ic7afaf1f2fbd76396ea5f66d59a4e08371fe8864\n'}, {'number': 2, 'created': '2014-12-19 19:30:10.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/8efe67178d556ca2719465c82fa26f5a95d4c9cf', 'message': 'WIP: Just checking if any jobs fail with ImportError in zuul_swift_upload.py\n\nChange-Id: Ic7afaf1f2fbd76396ea5f66d59a4e08371fe8864\n'}]",0,143161,8efe67178d556ca2719465c82fa26f5a95d4c9cf,4,1,2,5638,,,0,"WIP: Just checking if any jobs fail with ImportError in zuul_swift_upload.py

Change-Id: Ic7afaf1f2fbd76396ea5f66d59a4e08371fe8864
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/61/143161/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,8302f82057c4f93cbaead6962eab048d7683a1d4,,and troubleshoot failures or tease out non-deterministic bugs.,and troubleshoot failures or tease out nondeterministic bugs.,1,1
openstack%2Fcongress~master~I85d2f32d6c770901902e3838371f40343fb22edf,openstack/congress,master,I85d2f32d6c770901902e3838371f40343fb22edf,Add create/delete policy to API,MERGED,2014-11-11 00:08:45.000000000,2014-12-19 20:44:33.000000000,2014-12-19 20:10:04.000000000,"[{'_account_id': 3}, {'_account_id': 1923}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 9253}, {'_account_id': 12875}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-11-11 00:08:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/d02856fa28710767bc5b0389ffab3f1de973f05d', 'message': 'Add create/delete policy to API\n\nChange-Id: I85d2f32d6c770901902e3838371f40343fb22edf\n'}, {'number': 2, 'created': '2014-11-12 21:13:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/d6bec8993d0732a529583751c770007ed37ae93c', 'message': 'Add create/delete policy to API\n\nImplements-blueprint: multiple-policies\nChange-Id: I85d2f32d6c770901902e3838371f40343fb22edf\n'}, {'number': 3, 'created': '2014-11-20 17:48:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/43d1dc84732e67d31ff998419f224747b1e91a3d', 'message': 'Add create/delete policy to API\n\nImplements-blueprint: multiple-policies\nChange-Id: I85d2f32d6c770901902e3838371f40343fb22edf\n'}, {'number': 4, 'created': '2014-11-21 00:06:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/1f3fb88ab01d19f7a1503b24b2ab34da8838da30', 'message': 'Add create/delete policy to API\n\nImplements-blueprint: multiple-policies\nChange-Id: I85d2f32d6c770901902e3838371f40343fb22edf\n'}, {'number': 5, 'created': '2014-12-08 23:28:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/acc8fc89109e50547708794763dbe7ccb2d3811b', 'message': 'Add create/delete policy to API\n\nImplements-blueprint: multiple-policies\nChange-Id: I85d2f32d6c770901902e3838371f40343fb22edf\n'}, {'number': 6, 'created': '2014-12-10 19:45:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/66d00930f1d2b3168e81a5701b23c14778807fc9', 'message': 'Add create/delete policy to API\n\nImplements-blueprint: multiple-policies\nChange-Id: I85d2f32d6c770901902e3838371f40343fb22edf\n'}, {'number': 7, 'created': '2014-12-12 00:35:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/3f7649ab37815a422990775c18afb0400351ec88', 'message': 'Add create/delete policy to API\n\nImplements-blueprint: multiple-policies\nChange-Id: I85d2f32d6c770901902e3838371f40343fb22edf\n'}, {'number': 8, 'created': '2014-12-12 19:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/6303f9cdf5f6082f6dfc1f0fea5bb4ba8e574e66', 'message': 'Add create/delete policy to API\n\nImplements-blueprint: multiple-policies\nChange-Id: I85d2f32d6c770901902e3838371f40343fb22edf\n'}, {'number': 9, 'created': '2014-12-12 19:33:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/a183d51d0597e44dd043c27b98794fd892790e78', 'message': 'Add create/delete policy to API\n\nImplements-blueprint: multiple-policies\nChange-Id: I85d2f32d6c770901902e3838371f40343fb22edf\n'}, {'number': 10, 'created': '2014-12-17 16:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/aa384b87016c615723b5f91a9b54f4ef91bc9087', 'message': 'Add create/delete policy to API\n\nImplements-blueprint: multiple-policies\nChange-Id: I85d2f32d6c770901902e3838371f40343fb22edf\n'}, {'number': 11, 'created': '2014-12-17 18:04:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/69a960876f0b308384b816fd2f14b17cf3e820c8', 'message': 'Add create/delete policy to API\n\nImplements-blueprint: multiple-policies\nChange-Id: I85d2f32d6c770901902e3838371f40343fb22edf\n'}, {'number': 12, 'created': '2014-12-17 19:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/a53c5df82c33a8217037cffaf5b842b9db2baa2c', 'message': 'Add create/delete policy to API\n\nImplements-blueprint: multiple-policies\nChange-Id: I85d2f32d6c770901902e3838371f40343fb22edf\n'}, {'number': 13, 'created': '2014-12-18 22:38:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/219e326fd2395cc128013cc16e52669c1a62c24d', 'message': 'Add create/delete policy to API\n\nImplements-blueprint: multiple-policies\nChange-Id: I85d2f32d6c770901902e3838371f40343fb22edf\n'}, {'number': 14, 'created': '2014-12-18 22:40:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/b49f75146f77f0441fd93ca19601ee27b139f4fd', 'message': 'Add create/delete policy to API\n\nImplements-blueprint: multiple-policies\nChange-Id: I85d2f32d6c770901902e3838371f40343fb22edf\n'}, {'number': 15, 'created': '2014-12-18 23:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/3a453032c6bad3d3bad76d9f1af09554f3d55030', 'message': 'Add create/delete policy to API\n\nImplements-blueprint: multiple-policies\nChange-Id: I85d2f32d6c770901902e3838371f40343fb22edf\n'}, {'number': 16, 'created': '2014-12-19 17:18:52.000000000', 'files': ['congress/api/webservice.py', 'congress/db/migration/alembic_migrations/versions/532e9e1f0f3a_add_policy.py', 'congress/tests/policy/test_nonrecur.py', 'congress/tests/policy/test_runtime.py', 'congress/api/error_codes.py', 'congress/db/migration/alembic_migrations/versions/HEAD', 'congress/policy/runtime.py', 'congress/tests/test_congress.py', 'congress/harness.py', 'congress/server/congress_server.py', 'congress/api/policy_model.py', 'congress/db/db_policy_rules.py', 'congress/tests/policy/test_materialized.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/3aca6e7db4fbb66df8fe1eafcb5f32f40ae56eae', 'message': 'Add create/delete policy to API\n\nImplements-blueprint: multiple-policies\nChange-Id: I85d2f32d6c770901902e3838371f40343fb22edf\n'}]",56,133579,3aca6e7db4fbb66df8fe1eafcb5f32f40ae56eae,86,7,16,8215,,,0,"Add create/delete policy to API

Implements-blueprint: multiple-policies
Change-Id: I85d2f32d6c770901902e3838371f40343fb22edf
",git fetch https://review.opendev.org/openstack/congress refs/changes/79/133579/16 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/test_congress.py', 'congress/api/policy_model.py', 'congress/api/error_codes.py', 'congress/policy/runtime.py']",4,d02856fa28710767bc5b0389ffab3f1de973f05d,multipolicy," def get_policy_type(self, name): """"""Return type of policy NAME. Throws KeyError if does not exist."""""" policy = self.get_policy(name) if isinstance(policy, NonrecursiveRuleTheory): return self.NONRECURSIVE_POLICY_TYPE if isinstance(policy, MaterializedViewTheory): return self.MATERIALIZED_POLICY_TYPE if isinstance(policy, ActionTheory): return self.ACTION_POLICY_TYPE if isinstance(policy, Database): return self.DATABASE_POLICY_TYPE raise compile.CongressException(""Policy %s has unknown type"" % name) ",,163,65
openstack%2Fcinder~master~I620ae8fff4634c60a02329f22d1a0343b27aa955,openstack/cinder,master,I620ae8fff4634c60a02329f22d1a0343b27aa955,Delete default volume size 100M in drivers,MERGED,2014-12-15 10:38:17.000000000,2014-12-19 20:42:07.000000000,2014-12-17 02:13:23.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 13636}]","[{'number': 1, 'created': '2014-12-15 10:38:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d36843c3189fb4c7f4db84bfa936d32476e8d530', 'message': 'Fix default volume size\n\nChange Ceph default volume size from 100 Mb to 1Gb.\n\nChange-Id: I620ae8fff4634c60a02329f22d1a0343b27aa955\n'}, {'number': 2, 'created': '2014-12-15 12:19:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/527242185ce5ea2b9e222d8ffb11eaf41b91015e', 'message': 'Fix default volume size in RBD driver\n\nChange Ceph default volume size from 100 Mb to 1Gb.\n\nChange-Id: I620ae8fff4634c60a02329f22d1a0343b27aa955\n'}, {'number': 3, 'created': '2014-12-16 11:15:06.000000000', 'files': ['cinder/volume/drivers/rbd.py', 'cinder/volume/drivers/ibm/gpfs.py', 'cinder/volume/drivers/san/hp/hp_lefthand_cliq_proxy.py', 'cinder/tests/test_scality.py', 'cinder/tests/test_gpfs.py', 'cinder/volume/drivers/san/solaris.py', 'cinder/volume/drivers/scality.py', 'cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/632f939b9884cc917650f83e50930fd702a05119', 'message': ""Delete default volume size 100M in drivers\n\nThere is check: if volume size == 0 we set default value to 100M,\nit uses only in tests and it's little bit confusing.Use code only\nfor tests in drivers is bad practice.\n\nAlso the create volume flow already won't let user to create\na volume  with size 0. So it was decided to remove this check.\n\nChange-Id: I620ae8fff4634c60a02329f22d1a0343b27aa955\n""}]",1,141765,632f939b9884cc917650f83e50930fd702a05119,42,14,3,13636,,,0,"Delete default volume size 100M in drivers

There is check: if volume size == 0 we set default value to 100M,
it uses only in tests and it's little bit confusing.Use code only
for tests in drivers is bad practice.

Also the create volume flow already won't let user to create
a volume  with size 0. So it was decided to remove this check.

Change-Id: I620ae8fff4634c60a02329f22d1a0343b27aa955
",git fetch https://review.opendev.org/openstack/cinder refs/changes/65/141765/3 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/rbd.py'],1,d36843c3189fb4c7f4db84bfa936d32476e8d530,rbd-volume-size, size = 1 * units.Gi, size = 100 * units.Mi,1,1
openstack%2Fopenstack-ansible~master~Ie5955eaedef14f5916ec19203f8724e107a409da,openstack/openstack-ansible,master,Ie5955eaedef14f5916ec19203f8724e107a409da,Set external_lb_address to eth0's address in all-in-one build,MERGED,2014-12-19 16:32:03.000000000,2014-12-19 20:32:27.000000000,2014-12-19 18:17:35.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-19 16:32:03.000000000', 'files': ['scripts/os-ansible-aio-check.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5606e00e35b9bb46115d35d9b585ff5172cf464c', 'message': ""Set external_lb_address to eth0's address in all-in-one build\n\nThis patch sets the external_lb_address to the instance's eth0 address\nto ensure that any services that rely on accessing that address are able\nto do so.\n\nChange-Id: Ie5955eaedef14f5916ec19203f8724e107a409da\nCloses-Bug: #1404305\n""}]",0,143130,5606e00e35b9bb46115d35d9b585ff5172cf464c,10,4,1,6816,,,0,"Set external_lb_address to eth0's address in all-in-one build

This patch sets the external_lb_address to the instance's eth0 address
to ensure that any services that rely on accessing that address are able
to do so.

Change-Id: Ie5955eaedef14f5916ec19203f8724e107a409da
Closes-Bug: #1404305
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/30/143130/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/os-ansible-aio-check.sh'],1,5606e00e35b9bb46115d35d9b585ff5172cf464c,bug/1404305, external_lb_vip_address: $(ip -o -4 addr show dev eth0 | awk -F '[ /]+' '/global/ {print $4}'), external_lb_vip_address: 192.168.10.10,1,1
openstack%2Fpython-congressclient~master~I073d22da834199cb73aebad7bb80595662c97897,openstack/python-congressclient,master,I073d22da834199cb73aebad7bb80595662c97897,Add policy create/delete endpoints,MERGED,2014-12-10 22:38:51.000000000,2014-12-19 20:31:25.000000000,2014-12-19 20:31:23.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}]","[{'number': 1, 'created': '2014-12-10 22:38:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-congressclient/commit/b0a3f78cf1f15b18de17a0626bf2d9082b70be4c', 'message': 'Add policy create/delete endpoints\n\nAdd the ability to create and delete policies at runtime.\n\nChange-Id: I073d22da834199cb73aebad7bb80595662c97897\n'}, {'number': 2, 'created': '2014-12-12 00:35:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-congressclient/commit/e95eb595b1f85b3f2ce7f1ef0ed6462c75644df7', 'message': 'Add policy create/delete endpoints\n\nAdd the ability to create and delete policies at runtime.\n\nChange-Id: I073d22da834199cb73aebad7bb80595662c97897\n'}, {'number': 3, 'created': '2014-12-15 21:42:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-congressclient/commit/39008839e97354842883da1340bf64236d8dde80', 'message': 'Add policy create/delete endpoints\n\nAdd the ability to create and delete policies at runtime.\n\nChange-Id: I073d22da834199cb73aebad7bb80595662c97897\n'}, {'number': 4, 'created': '2014-12-15 21:43:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-congressclient/commit/f05fb9f4c1de81c2d8a60a7a357a1f1b2e618ac0', 'message': 'Add policy create/delete endpoints\n\nAdd the ability to create and delete policies at runtime.\n\nChange-Id: I073d22da834199cb73aebad7bb80595662c97897\n'}, {'number': 5, 'created': '2014-12-17 16:59:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-congressclient/commit/80de7218476b1592710fe91d20b919774f9c1058', 'message': 'Add policy create/delete endpoints\n\nAdd the ability to create and delete policies at runtime.\n\nChange-Id: I073d22da834199cb73aebad7bb80595662c97897\n'}, {'number': 6, 'created': '2014-12-17 17:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-congressclient/commit/47b5bcfb881686d3afbd06a4d0d3cbf92882e1c8', 'message': 'Add policy create/delete endpoints\n\nAdd the ability to create and delete policies at runtime.\n\nChange-Id: I073d22da834199cb73aebad7bb80595662c97897\n'}, {'number': 7, 'created': '2014-12-17 18:05:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-congressclient/commit/5b852f35fdf9c9c25e0967ad1c49408e4c9e6ef1', 'message': 'Add policy create/delete endpoints\n\nAdd the ability to create and delete policies at runtime.\n\nChange-Id: I073d22da834199cb73aebad7bb80595662c97897\n'}, {'number': 8, 'created': '2014-12-19 20:12:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-congressclient/commit/27cb71df34ce572b0a64c773dbcdc58f4fbdc754', 'message': 'Add policy create/delete endpoints\n\nAdd the ability to create and delete policies at runtime.\n\nChange-Id: I073d22da834199cb73aebad7bb80595662c97897\n'}, {'number': 9, 'created': '2014-12-19 20:13:55.000000000', 'files': ['NEWS', 'congressclient/tests/v1/test_policy.py', 'congressclient/osc/v1/policy.py', 'setup.cfg', 'congressclient/v1/client.py'], 'web_link': 'https://opendev.org/openstack/python-congressclient/commit/17aa3eb477c94f5031cd818d2277be39ef442f3f', 'message': 'Add policy create/delete endpoints\n\nAdd the ability to create and delete policies at runtime.\n\nChange-Id: I073d22da834199cb73aebad7bb80595662c97897\n'}]",3,140850,17aa3eb477c94f5031cd818d2277be39ef442f3f,25,3,9,8215,,,0,"Add policy create/delete endpoints

Add the ability to create and delete policies at runtime.

Change-Id: I073d22da834199cb73aebad7bb80595662c97897
",git fetch https://review.opendev.org/openstack/python-congressclient refs/changes/50/140850/1 && git format-patch -1 --stdout FETCH_HEAD,"['congressclient/osc/v1/policy.py', 'congressclient/tests/v1/test_policy.py', 'setup.cfg', 'congressclient/v1/client.py']",4,b0a3f78cf1f15b18de17a0626bf2d9082b70be4c,," policy = '/v1/policies' policy_path = '/v1/policies/%s' def create_policy(self, body=None): resp, body = self.httpclient.post( self.policy, body=body) return body def delete_policy(self, policy_id): resp, body = self.httpclient.delete( self.policy_path % policy_id) return body def update_policy(self, policy_id, body=None): resp, body = self.httpclient.patch( self.policy_path % policy_id, body=body) return body ",,124,0
openstack%2Fkeystone~master~Ie756fcc0b6a86637142f47291a9bfd4d6f0bb518,openstack/keystone,master,Ie756fcc0b6a86637142f47291a9bfd4d6f0bb518,split auth from other services in paste,ABANDONED,2014-12-02 17:30:05.000000000,2014-12-19 20:31:25.000000000,,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 6482}, {'_account_id': 8978}]","[{'number': 1, 'created': '2014-12-02 17:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4c92ebcc21085852d8781d6d0fa5399bf63e7b79', 'message': 'split auth from other services in paste\n\nChange-Id: Ie756fcc0b6a86637142f47291a9bfd4d6f0bb518\n'}, {'number': 2, 'created': '2014-12-05 16:54:04.000000000', 'files': ['etc/keystone-paste.ini', 'keystone/auth/routers.py', 'keystone/service.py', 'keystone/tests/test_versions.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/234ff2d445dad5d27556bdff41c6071fce707824', 'message': 'split auth from other services in paste\n\nChange-Id: Ie756fcc0b6a86637142f47291a9bfd4d6f0bb518\n'}]",0,138452,234ff2d445dad5d27556bdff41c6071fce707824,7,4,2,2218,,,0,"split auth from other services in paste

Change-Id: Ie756fcc0b6a86637142f47291a9bfd4d6f0bb518
",git fetch https://review.opendev.org/openstack/keystone refs/changes/52/138452/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/keystone-paste.ini', 'keystone/auth/routers.py', 'keystone/service.py', 'keystone/tests/test_versions.py']",4,4c92ebcc21085852d8781d6d0fa5399bf63e7b79,split-pipeline, def xxtest_json_home_v3(self): def xxtest_json_home_root(self): def cxtest_json_home_v3(self): import pdb; pdb.set_trace(), def test_json_home_v3(self): def test_json_home_root(self): def test_json_home_v3(self):,31,10
openstack%2Fcinder~master~I9835073a39aa8b2ffbec12d84147cce027ff731b,openstack/cinder,master,I9835073a39aa8b2ffbec12d84147cce027ff731b,Send the notifications to the Ceilometer for backup service,MERGED,2014-07-03 07:02:58.000000000,2014-12-19 20:29:57.000000000,2014-12-16 21:03:12.000000000,"[{'_account_id': 3}, {'_account_id': 25}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 1773}, {'_account_id': 2759}, {'_account_id': 2861}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 8874}, {'_account_id': 8909}, {'_account_id': 9008}, {'_account_id': 9171}, {'_account_id': 9533}, {'_account_id': 9751}, {'_account_id': 10503}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12778}, {'_account_id': 12779}, {'_account_id': 12780}, {'_account_id': 13049}, {'_account_id': 14084}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-07-03 07:02:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4e5bf7159c8014731a9625c7b11c3303834f36a9', 'message': 'Send the stas to the ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add a flag backup_object_number_per_notification to the swift backup\n  service. It specifies the number of chunks, after which a notification\n  is going to send to the ceilometer.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\ncloses-bug: #1326431\n'}, {'number': 2, 'created': '2014-07-03 07:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/27f0f069488f7211d9cbb9c6527b7e80d1a2a95a', 'message': 'Send the stas to the ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add a flag backup_object_number_per_notification to the swift backup\n  service. It specifies the number of swift objects, for which a notification\n  is going to send to the ceilometer.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\ncloses-bug: #1326431\n'}, {'number': 3, 'created': '2014-07-04 03:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b40a3bb174e680da90bc936f0bc652a87208f235', 'message': 'Send the stats to the ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add a flag backup_object_number_per_notification to the swift backup\n  service. It specifies the number of swift objects, for which a notification\n  is going to send to the ceilometer.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 4, 'created': '2014-07-04 03:40:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f5d12282d89778bc46f0c649648690f09b194086', 'message': 'Send the stats to the ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add a flag backup_object_number_per_notification to the swift backup\n  service. It specifies the number of swift objects, for which a notification\n  is going to send to the ceilometer.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 5, 'created': '2014-07-04 06:00:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0d775504f01079818d2fa56b573238fbb516f03e', 'message': 'Send the notifications to the ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add a flag backup_object_number_per_notification to the swift backup\n  service. It specifies the number of swift objects, for which a notification\n  is going to send to the ceilometer.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 6, 'created': '2014-07-04 06:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9df65915f0f342a5491a7ada8cbf7017b7e11192', 'message': 'Send the notifications to the ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add a flag backup_object_number_per_notification to the swift backup\n  service. It specifies the number of swift objects, for which a notification\n  is going to send to the ceilometer.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 7, 'created': '2014-07-04 08:04:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2a825c6103b6bfc707259ccefb6f9eeef8c6f0c2', 'message': 'Send the notifications to the ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add a config option backup_object_number_per_notification to the swift\n  backup service. It specifies the number of swift objects, for which a\n  notification is going to send to the ceilometer.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 8, 'created': '2014-07-04 08:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/67bff85538866f2390d99b287fdbfded4252b665', 'message': 'Send the notifications to the ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add a config option backup_object_number_per_notification to the swift\n  backup service. It specifies the number of swift objects, for which a\n  notification is going to send to the ceilometer.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 9, 'created': '2014-07-04 08:10:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/48060432adaae25835b9a0f4876f92f6fa8b2e18', 'message': 'Send the notifications to the ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add a config option backup_object_number_per_notification to the swift\n  backup service. It specifies the number of swift objects, for which a\n  notification is going to send to the ceilometer.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 10, 'created': '2014-07-08 06:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/faaf99f4d0cfb79d86922af0cdf9b448b68723cb', 'message': 'Send the notifications to the ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add a config option backup_object_number_per_notification to the swift\n  backup service. It specifies the number of swift objects, for which a\n  notification is going to send to the ceilometer.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 11, 'created': '2014-07-08 07:41:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/aab4269e0ed4371885f85f62b34ab90cd91f358d', 'message': 'Send the notifications to the ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add a config option backup_object_number_per_notification to the swift\n  backup service. It specifies the number of swift objects, for which a\n  notification is going to send to the ceilometer.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 12, 'created': '2014-07-10 02:10:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2a15052be77974f1c838ee13050f50c60c731632', 'message': 'Send the notifications to the ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 13, 'created': '2014-07-10 02:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3b4f44cedc03b9f0f7fd994e0d546340b59d7b26', 'message': 'Send the notifications to the ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 14, 'created': '2014-07-14 03:20:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/67ddf2b0de18b4c9f845ffccbf886ff549799d02', 'message': 'Send the notifications to the ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 15, 'created': '2014-07-14 04:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/de17d8040f203635168f3696613cc8e65bcdb008', 'message': 'Send the notifications to the ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 16, 'created': '2014-07-14 04:06:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a522172c5811af9fdd83435784a8aa30053fb887', 'message': 'Send the notifications to the ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 17, 'created': '2014-07-18 03:14:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cc4bde57ad0b19aae28e56c6f98701b09603ecd4', 'message': 'Send the notifications to the ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 18, 'created': '2014-07-18 05:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/56301bbe77a5b5569924cc407f6d891320ef16b4', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 19, 'created': '2014-08-04 02:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/856a5d28a011605ec1fe2fa218971b6c16a80b02', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 20, 'created': '2014-08-13 09:07:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f24c39c4595fab8b7de8ab5d1d4015d02bd66346', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 21, 'created': '2014-08-27 03:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0661f1e654a2ce846e8523b90ebe741e9e8ab567', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 22, 'created': '2014-08-29 03:25:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0f03599ca7f38072d0075f611da520f9eee1b0f1', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 23, 'created': '2014-08-31 11:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/37c2e66fad352acec8ad3cc9f6fc287d1c065114', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 24, 'created': '2014-09-11 10:09:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/079fcfb5c0e5307ed8d0e346bf360c97151c13bd', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 25, 'created': '2014-09-12 07:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/eb7fbd9b4d628fd1f259e50c5afaf1bc11d596f4', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 26, 'created': '2014-09-12 07:30:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c8fa2abc9b7dbc2db52678a523486290eea26ae3', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 27, 'created': '2014-09-16 03:41:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a372c68102bc120f0a4e0bd09281190a1febad8d', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 28, 'created': '2014-09-17 03:24:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0b08631dbaeea74fca09bb85365b023f7a04aab7', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 29, 'created': '2014-09-18 07:57:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8f83f45b9838b789a185aefc6a4f9257bb728194', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 30, 'created': '2014-09-19 03:30:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/93f362f27b90bdec94fa8765e354b409dbdebac4', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 31, 'created': '2014-09-22 09:21:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ba67baf73a2c16c8fc22353e83fe4049088a2a75', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 32, 'created': '2014-09-23 05:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a241fcf936f7b88d0f8781f503910c74a7312466', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 33, 'created': '2014-09-23 05:29:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/523bfeae3a4e1b3db9da59ef4f76835e0d253158', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 34, 'created': '2014-09-24 03:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/43a0fb3e183f2acf9cad612b3c0e15b59ebc0064', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 35, 'created': '2014-09-24 09:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/17928f91359315d9c2d0ad05fba09624c0006907', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 36, 'created': '2014-09-26 09:55:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/763c98ec8f46026068a2dfbc34c7fb03d0658d09', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 37, 'created': '2014-09-29 14:07:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9f8e15b6f8a8d8f8ff574a3e01ba36ad939813e0', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 38, 'created': '2014-09-29 14:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d574187a3a874b718ab73787ee6ab655a1c66fbf', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n* Remove some used configuration options in cinder.conf.sample.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 39, 'created': '2014-09-29 14:18:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fad3053c03ffb7246c359502d83379c374c4d904', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n* Remove some used configuration options in cinder.conf.sample.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 40, 'created': '2014-09-30 02:40:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bbc4eb76d1bb0711c1e7e0fb16721f3508a25443', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n* Remove some used configuration options in cinder.conf.sample.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 41, 'created': '2014-09-30 02:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/914086e9af733fff53c3cf1d374aab1ff6807023', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 42, 'created': '2014-10-10 03:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cdb88aa01b4f027dbc5ee6b4a3fe07bf8aa56b45', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 43, 'created': '2014-11-24 08:47:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/90db0a9a361d2ac15b49d1f111f68c034f0b4cd3', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 44, 'created': '2014-11-24 08:53:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c18d1d86954471f080dc231de7f0e80affe9cb43', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 45, 'created': '2014-11-24 08:57:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8ba3cad4134eb7b0d5a4c459a0ebeb8bdc2b45a3', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 46, 'created': '2014-12-01 07:00:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f542d12239070a825f437533b94a174c3cb12922', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 47, 'created': '2014-12-01 07:05:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/32221b8633b6b134a431cb08a78b47a18ad03854', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 48, 'created': '2014-12-01 08:03:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7d7ec08fa6107828c2dc60fa2919b28e0d610477', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 49, 'created': '2014-12-01 08:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a6e694454c6d1560ddafa2f221984bf6f86b5d5d', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 50, 'created': '2014-12-02 02:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ecc8429b7b18e9b5113a8d0f6b8b185f4491afbc', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 51, 'created': '2014-12-02 02:34:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3f9727775a60e7c911fd68c3874eb3dc8792ee98', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 52, 'created': '2014-12-03 06:21:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/22a3b1e117970bad25f6e13575733450b6b7526a', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 53, 'created': '2014-12-04 02:20:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1ca916e472290a3e9370fc8e9c3881e088629b52', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 54, 'created': '2014-12-05 01:37:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2f343e580a3fc96c1c9e5c320ff567fbd687348c', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 55, 'created': '2014-12-08 05:18:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/05006da35f085d0f20c57c71ef885d16f1a06fbb', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 56, 'created': '2014-12-09 01:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4fa869e1c5a586c795a97e6aad608e7b87c24a81', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 57, 'created': '2014-12-09 13:06:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bc26cd4f2ed2b94cacf6a39aa7bd1e766dd25bfc', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 58, 'created': '2014-12-11 02:03:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/adf0b61f1f71302aa3675cac99891e7b474ba9e9', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 59, 'created': '2014-12-15 01:48:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/03cb29bb383acd02ff6b59d53a8b71ebaa286c9e', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}, {'number': 60, 'created': '2014-12-16 06:11:43.000000000', 'files': ['cinder/volume/utils.py', 'cinder/backup/manager.py', 'cinder/backup/drivers/swift.py', 'cinder/backup/driver.py', 'cinder/tests/test_backup_swift.py', 'cinder/tests/test_backup.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/77452d8c05d7a6b62e84dd39930fdca40257ce09', 'message': 'Send the notifications to the Ceilometer for backup service\n\n* Add the notification send-out for create_backup, delete_backup\n  and restore_backup.\n* Add the progress notification to Swift backup service.\n\nDocImpact\n\nChange-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b\nimplements-bp: backup-notification\n'}]",32,104463,77452d8c05d7a6b62e84dd39930fdca40257ce09,349,35,60,2861,,,0,"Send the notifications to the Ceilometer for backup service

* Add the notification send-out for create_backup, delete_backup
  and restore_backup.
* Add the progress notification to Swift backup service.

DocImpact

Change-Id: I9835073a39aa8b2ffbec12d84147cce027ff731b
implements-bp: backup-notification
",git fetch https://review.opendev.org/openstack/cinder refs/changes/63/104463/18 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/utils.py', 'cinder/backup/manager.py', 'etc/cinder/cinder.conf.sample', 'cinder/backup/drivers/swift.py']",4,4e5bf7159c8014731a9625c7b11c3303834f36a9,bp/backup-notification,":backup_object_number_per_notification: The number of swift objects, for which ' 'one ceilometer notification will ' 'be sent.' (default: 10).from cinder.volume import utils as volume_utils cfg.IntOpt('backup_object_number_per_notification', default=10, help='The number of swift objects, for which one ' 'ceilometer notification will be sent'), DRIVER_VERSION_MAPPING = {'1.0.0': '_refstore_v1'} self.data_block_num = CONF.backup_object_number_per_notification counter = 0 counter += 1 if counter == self.data_block_num: # send the notification to ceilometer when the chunk # number reaches the data_block_num volume_utils.notify_about_backup_usage(self.context, backup, ""create.start"", extra_usage_info= object_meta, host=self.host) # reset the counter counter = 0", DRIVER_VERSION_MAPPING = {'1.0.0': '_restore_v1'},88,9
openstack%2Fhorizon~master~Ib11a8c67b59df57bdf6fa4263d89987e46343e50,openstack/horizon,master,Ib11a8c67b59df57bdf6fa4263d89987e46343e50,Adds the security group id besides the name in Manage Rules,MERGED,2014-10-25 18:50:29.000000000,2014-12-19 20:25:09.000000000,2014-12-19 20:25:08.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 9317}, {'_account_id': 11599}, {'_account_id': 11997}, {'_account_id': 12355}, {'_account_id': 13785}]","[{'number': 1, 'created': '2014-10-25 18:50:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/64cc0781243d866667a2225032dc938cf0a0a81c', 'message': 'Adds the security group id besides the name in Manage Rules\n\nThis patch adds the security group id between parenthesis after\nthe group name, on the ""Manage rules"" group details page.\n\nChange-Id: Ib11a8c67b59df57bdf6fa4263d89987e46343e50\nCloses-bug: #1370854\n'}, {'number': 2, 'created': '2014-10-26 17:13:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7761746574d4bc3664372a132023677850c51721', 'message': 'Adds the security group id besides the name in Manage Rules\n\nThis patch adds the security group id between parenthesis after\nthe group name, on the ""Manage rules"" group details page.\n\nChange-Id: Ib11a8c67b59df57bdf6fa4263d89987e46343e50\nCloses-bug: #1370854\n'}, {'number': 3, 'created': '2014-12-08 07:14:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f8483ecdafaa53aa4bd99bacd29f597564abb1ac', 'message': 'Adds the security group id besides the name in Manage Rules\n\nThis patch adds the security group id between parenthesis after\nthe group name, on the ""Manage rules"" group details page.\n\nChange-Id: Ib11a8c67b59df57bdf6fa4263d89987e46343e50\nCloses-bug: #1370854\n'}, {'number': 4, 'created': '2014-12-18 05:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/34b27937c44817cf30cc660d9da8c62a3ef633c8', 'message': 'Adds the security group id besides the name in Manage Rules\n\nThis patch adds the security group id between parenthesis after\nthe group name, on the ""Manage rules"" group details page.\n\nChange-Id: Ib11a8c67b59df57bdf6fa4263d89987e46343e50\nCloses-bug: #1370854\n'}, {'number': 5, 'created': '2014-12-19 06:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e9fd90d8720f4eb21e2f3f69d77fd18a54fb732a', 'message': 'Adds the security group id besides the name in Manage Rules\n\nThis patch adds the security group id between parenthesis after\nthe group name, on the ""Manage rules"" group details page.\n\nChange-Id: Ib11a8c67b59df57bdf6fa4263d89987e46343e50\nCloses-bug: #1370854\n'}, {'number': 6, 'created': '2014-12-19 06:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a1e9ae509a801a2eaa89a58a3d143e09941b8ca6', 'message': 'Adds the security group id besides the name in Manage Rules\n\nThis patch adds the security group id between parenthesis after\nthe group name, on the ""Manage rules"" group details page.\n\nChange-Id: Ib11a8c67b59df57bdf6fa4263d89987e46343e50\nCloses-bug: #1370854\n'}, {'number': 7, 'created': '2014-12-19 08:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f1c2e7e942137234a73b5481d7d32a6096dd9147', 'message': 'Adds the security group id besides the name in Manage Rules\n\nThis patch adds the security group id between parenthesis after\nthe group name, on the ""Manage rules"" group details page.\n\nChange-Id: Ib11a8c67b59df57bdf6fa4263d89987e46343e50\nCloses-bug: #1370854\n'}, {'number': 8, 'created': '2014-12-19 08:42:19.000000000', 'files': ['openstack_dashboard/dashboards/project/access_and_security/security_groups/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/c8f9bcd1688a2cf610ce021418a9c4ce27cf716e', 'message': 'Adds the security group id besides the name in Manage Rules\n\nThis patch adds the security group id between parenthesis after\nthe group name, on the ""Manage rules"" group details page.\n\nChange-Id: Ib11a8c67b59df57bdf6fa4263d89987e46343e50\nCloses-bug: #1370854\n'}]",4,130956,c8f9bcd1688a2cf610ce021418a9c4ce27cf716e,32,8,8,11599,,,0,"Adds the security group id besides the name in Manage Rules

This patch adds the security group id between parenthesis after
the group name, on the ""Manage rules"" group details page.

Change-Id: Ib11a8c67b59df57bdf6fa4263d89987e46343e50
Closes-bug: #1370854
",git fetch https://review.opendev.org/openstack/horizon refs/changes/56/130956/8 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/access_and_security/templates/access_and_security/security_groups/detail.html'],1,64cc0781243d866667a2225032dc938cf0a0a81c,bug/1370854," {% include ""horizon/common/_page_header.html"" with title=_(""Manage Security Group Rules: "")|add:security_group.name|add:""(""|add:security_group.id|add:"")"" %}"," {% include ""horizon/common/_page_header.html"" with title=_(""Manage Security Group Rules: "")|add:security_group.name %}",1,1
openstack%2Fglance~master~Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6,openstack/glance,master,Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6,Allow None values to be returned from the API,MERGED,2014-12-01 21:18:25.000000000,2014-12-19 20:22:49.000000000,2014-12-04 05:21:42.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 8759}, {'_account_id': 8871}, {'_account_id': 11356}, {'_account_id': 11391}, {'_account_id': 12000}, {'_account_id': 12196}]","[{'number': 1, 'created': '2014-12-01 21:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/bed960cbc49b5a521723cb1768c3eee59d0f2f33', 'message': ""Allow None values to be returned from the API\n\nCurrently, Glance's API v2 doesn't return fields whose value is None.\nThis, unfortunately, is wrong for a client perspective since it would\ncreate inconsistencies between calls and images due to the lack of\nfields in the response.\n\nThe API should guarantee consistency in its replies and ensure all\nfields have a value, even if it's None.\n\nNOTE: This work is part of the migration to v2. It fixes inconsistencies\nin the API and improves the interaction between the client library and\nGlance.\n\nChange-Id: Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6\n""}, {'number': 2, 'created': '2014-12-02 08:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2f0d5b2bc3c07c00163379788488334dd3279090', 'message': ""Allow None values to be returned from the API\n\nCurrently, Glance's API v2 doesn't return fields whose value is None.\nThis, unfortunately, is wrong for a client perspective since it would\ncreate inconsistencies between calls and images due to the lack of\nfields in the response.\n\nThe API should guarantee consistency in its replies and ensure all\nfields have a value, even if it's None.\n\nNOTE: This work is part of the migration to v2. It fixes inconsistencies\nin the API and improves the interaction between the client library and\nGlance.\n\nCloses-bug: #1398314\n\nChange-Id: Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6\n""}, {'number': 3, 'created': '2014-12-02 10:33:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0b3e402d8c27a0eac416585a74685edb66dbbfc5', 'message': ""Allow None values to be returned from the API\n\nCurrently, Glance's API v2 doesn't return fields whose value is None.\nThis, unfortunately, is wrong for a client perspective since it would\ncreate inconsistencies between calls and images due to the lack of\nfields in the response.\n\nThe API should guarantee consistency in its replies and ensure all\nfields have a value, even if it's None.\n\nNOTE: This work is part of the migration to v2. It fixes inconsistencies\nin the API and improves the interaction between the client library and\nGlance.\n\nCloses-bug: #1398314\n\nChange-Id: Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6\n""}, {'number': 4, 'created': '2014-12-02 10:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e9a52228b4f5bfe55df89777fbcb14b732e6a7b8', 'message': ""Allow None values to be returned from the API\n\nCurrently, Glance's API v2 doesn't return fields whose value is None.\nThis, unfortunately, is wrong for a client perspective since it would\ncreate inconsistencies between calls and images due to the lack of\nfields in the response.\n\nThe API should guarantee consistency in its replies and ensure all\nfields have a value, even if it's None.\n\nNOTE: This work is part of the migration to v2. It fixes inconsistencies\nin the API and improves the interaction between the client library and\nGlance.\n\nCloses-bug: #1398314\n\nChange-Id: Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6\n""}, {'number': 5, 'created': '2014-12-02 12:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/26eaffd4b6726903085385482a0ee5e1682bab6d', 'message': ""Allow None values to be returned from the API\n\nCurrently, Glance's API v2 doesn't return fields whose value is None.\nThis, unfortunately, is wrong for a client perspective since it would\ncreate inconsistencies between calls and images due to the lack of\nfields in the response.\n\nThe API should guarantee consistency in its replies and ensure all\nfields have a value, even if it's None.\n\nNOTE: This work is part of the migration to v2. It fixes inconsistencies\nin the API and improves the interaction between the client library and\nGlance.\n\nCloses-bug: #1398314\n\nChange-Id: Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6\n""}, {'number': 6, 'created': '2014-12-02 13:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/44ebc2ba8b4707c2ab1abcdc4c21b5c8068030a8', 'message': ""Allow None values to be returned from the API\n\nCurrently, Glance's API v2 doesn't return fields whose value is None.\nThis, unfortunately, is wrong for a client perspective since it would\ncreate inconsistencies between calls and images due to the lack of\nfields in the response.\n\nThe API should guarantee consistency in its replies and ensure all\nfields have a value, even if it's None.\n\nNOTE: This work is part of the migration to v2. It fixes inconsistencies\nin the API and improves the interaction between the client library and\nGlance.\n\nCloses-bug: #1398314\n\nChange-Id: Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6\n""}, {'number': 7, 'created': '2014-12-02 14:50:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fee49bf6460d2e6e21e79555a914a2dd7a108c43', 'message': ""Allow None values to be returned from the API\n\nCurrently, Glance's API v2 doesn't return fields whose value is None.\nThis, unfortunately, is wrong for a client perspective since it would\ncreate inconsistencies between calls and images due to the lack of\nfields in the response.\n\nThe API should guarantee consistency in its replies and ensure all\nfields have a value, even if it's None.\n\nNOTE: This work is part of the migration to v2. It fixes inconsistencies\nin the API and improves the interaction between the client library and\nGlance.\n\nApiImpact\nCloses-bug: #1398314\n\nChange-Id: Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6""}, {'number': 8, 'created': '2014-12-02 17:26:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/55e4ce208fd68367a61a4cc428a5a62d3b873904', 'message': ""Allow None values to be returned from the API\n\nCurrently, Glance's API v2 doesn't return fields whose value is None.\nThis, unfortunately, is wrong for a client perspective since it would\ncreate inconsistencies between calls and images due to the lack of\nfields in the response.\n\nThe API should guarantee consistency in its replies and ensure all\nfields have a value, even if it's None.\n\nNOTE: This work is part of the migration to v2. It fixes inconsistencies\nin the API and improves the interaction between the client library and\nGlance.\n\nCloses-bug: #1398314\n\nChange-Id: Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6\n""}, {'number': 9, 'created': '2014-12-03 16:22:39.000000000', 'files': ['glance/tests/functional/v2/test_images.py', 'glance/tests/functional/v2/test_tasks.py', 'glance/tests/unit/v2/test_images_resource.py', 'glance/schema.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/d17a1ed78a259789ec7d52658057ca92a6935ead', 'message': ""Allow None values to be returned from the API\n\nCurrently, Glance's API v2 doesn't return fields whose value is None.\nThis, unfortunately, is wrong for a client perspective since it would\ncreate inconsistencies between calls and images due to the lack of\nfields in the response.\n\nThe API should guarantee consistency in its replies and ensure all\nfields have a value, even if it's None.\n\nNOTE: This work is part of the migration to v2. It fixes inconsistencies\nin the API and improves the interaction between the client library and\nGlance.\n\nNOTE2: A follow-up patch will bump the minor API version, wait for it.\n\nApiImpact\nDocImpact\nCloses-bug: #1398314\n\nChange-Id: Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6\n""}]",5,138184,d17a1ed78a259789ec7d52658057ca92a6935ead,48,11,9,6159,,,0,"Allow None values to be returned from the API

Currently, Glance's API v2 doesn't return fields whose value is None.
This, unfortunately, is wrong for a client perspective since it would
create inconsistencies between calls and images due to the lack of
fields in the response.

The API should guarantee consistency in its replies and ensure all
fields have a value, even if it's None.

NOTE: This work is part of the migration to v2. It fixes inconsistencies
in the API and improves the interaction between the client library and
Glance.

NOTE2: A follow-up patch will bump the minor API version, wait for it.

ApiImpact
DocImpact
Closes-bug: #1398314

Change-Id: Ieaddd8a686cf7361f18cb1ee83b7887cdca22bd6
",git fetch https://review.opendev.org/openstack/glance refs/changes/84/138184/6 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/functional/v2/test_images.py', 'glance/tests/unit/v2/test_images_resource.py', 'glance/schema.py']",3,bed960cbc49b5a521723cb1768c3eee59d0f2f33,bug/1398314," if self._filter_func(self.properties, key):"," if self._filter_func(self.properties, key) and value is not None:",53,8
openstack%2Fpython-openstackclient~master~I3b1cd7aac5c9603dfaccbd4ae30d07cbf7c96da2,openstack/python-openstackclient,master,I3b1cd7aac5c9603dfaccbd4ae30d07cbf7c96da2,Updated from global requirements,MERGED,2014-12-11 07:20:14.000000000,2014-12-19 20:20:18.000000000,2014-12-19 20:20:18.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-12-11 07:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6c90273e6a41bd9adfe321caef7921bebf0fdef9', 'message': 'Updated from global requirements\n\nChange-Id: I3b1cd7aac5c9603dfaccbd4ae30d07cbf7c96da2\n'}, {'number': 2, 'created': '2014-12-12 22:21:33.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a4208a7201bac0d6f361864e6f37bfd6b3626978', 'message': 'Updated from global requirements\n\nChange-Id: I3b1cd7aac5c9603dfaccbd4ae30d07cbf7c96da2\n'}]",0,140958,a4208a7201bac0d6f361864e6f37bfd6b3626978,11,3,2,11131,,,0,"Updated from global requirements

Change-Id: I3b1cd7aac5c9603dfaccbd4ae30d07cbf7c96da2
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/58/140958/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,6c90273e6a41bd9adfe321caef7921bebf0fdef9,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Fcinder~master~I8768d07f19147dc2544bebc0dbf3392313838e8f,openstack/cinder,master,I8768d07f19147dc2544bebc0dbf3392313838e8f,ZFSSA iSCSI driver should support extra specs,MERGED,2014-11-13 15:55:16.000000000,2014-12-19 20:18:21.000000000,2014-12-17 04:43:33.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2861}, {'_account_id': 5997}, {'_account_id': 9008}, {'_account_id': 9067}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11509}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 12779}, {'_account_id': 12780}]","[{'number': 1, 'created': '2014-11-13 15:55:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/743da26ccbbb9d51774b9adbe3568875eb0e00ea', 'message': 'ZFSSA iSCSI driver should support extra specs\n\nSupport for extra specs at volume creation time,\nwould allow more flexibility to create custom volumes.\nThe following scoped keys are supported:\n-zfssa_lun:volblocksize\n-zfssa_lun:sparse\n-zfssa_lun:compression\n-zfssa_lun:logbias\n\nCloses-Bug: #1379403\nDocImpact\n\nChange-Id: I8768d07f19147dc2544bebc0dbf3392313838e8f\n'}, {'number': 2, 'created': '2014-11-25 04:22:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/39c87812649c4ab3986bcb03772b50212bbdc316', 'message': 'ZFSSA iSCSI driver should support extra specs\n\nSupport for extra specs at volume creation time,\nwould allow more flexibility to create custom volumes.\nThe following scoped keys are supported:\n-zfssa:volblocksize\n-zfssa:sparse\n-zfssa:compression\n-zfssa:logbias\n\nCloses-Bug: #1379403\nDocImpact\n\nChange-Id: I8768d07f19147dc2544bebc0dbf3392313838e8f\n'}, {'number': 3, 'created': '2014-12-03 14:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/87f20e01fa7ec343f3a9b4604695c39c380f16c4', 'message': 'ZFSSA iSCSI driver should support extra specs\n\nSupport for extra specs at volume creation time,\nwould allow more flexibility to create custom volumes.\nThe following scoped keys are supported:\n-zfssa:volblocksize\n-zfssa:sparse\n-zfssa:compression\n-zfssa:logbias\n\nCloses-Bug: #1379403\nDocImpact\n\nChange-Id: I8768d07f19147dc2544bebc0dbf3392313838e8f\n'}, {'number': 4, 'created': '2014-12-07 01:02:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4d0d4b8b908f667ef88069ca27170a41b5f62664', 'message': 'ZFSSA iSCSI driver should support extra specs\n\nSupport for extra specs at volume creation time,\nwould allow more flexibility to create custom volumes.\nThe following scoped keys are supported:\n-zfssa:volblocksize\n-zfssa:sparse\n-zfssa:compression\n-zfssa:logbias\n\nCloses-Bug: #1379403\nDocImpact\n\nChange-Id: I8768d07f19147dc2544bebc0dbf3392313838e8f\n'}, {'number': 5, 'created': '2014-12-08 02:16:29.000000000', 'files': ['cinder/volume/drivers/zfssa/zfssarest.py', 'cinder/tests/test_zfssa.py', 'cinder/volume/drivers/zfssa/zfssaiscsi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d86779a09881bb0548534120ff0f84b7ffa22050', 'message': 'ZFSSA iSCSI driver should support extra specs\n\nSupport for extra specs at volume creation time,\nwould allow more flexibility to create custom volumes.\nThe following scoped keys are supported:\n-zfssa:volblocksize\n-zfssa:sparse\n-zfssa:compression\n-zfssa:logbias\n\nCloses-Bug: #1379403\nDocImpact\n\nChange-Id: I8768d07f19147dc2544bebc0dbf3392313838e8f\n'}]",7,134258,d86779a09881bb0548534120ff0f84b7ffa22050,71,16,5,11509,,,0,"ZFSSA iSCSI driver should support extra specs

Support for extra specs at volume creation time,
would allow more flexibility to create custom volumes.
The following scoped keys are supported:
-zfssa:volblocksize
-zfssa:sparse
-zfssa:compression
-zfssa:logbias

Closes-Bug: #1379403
DocImpact

Change-Id: I8768d07f19147dc2544bebc0dbf3392313838e8f
",git fetch https://review.opendev.org/openstack/cinder refs/changes/58/134258/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/zfssa/zfssaiscsi.py'],1,743da26ccbbb9d51774b9adbe3568875eb0e00ea,bug/1379403,"from cinder.volume import volume_types vblocksz, vsparse, vcompression, vlogbias = self._get_xspecs(volume) volblocksize=vblocksz, sparse=vsparse, compression=vcompression, logbias=vlogbias) def _get_xspecs(self, volume): """"""Get extra specs that can be used for volume creation."""""" lcfg = self.configuration vtype = volume.get('volume_type_id') if vtype: xspecs = volume_types.get_volume_type_extra_specs(vtype) if xspecs: vblocksz = xspecs.pop('zfssa_lun:volblocksize', lcfg.zfssa_lun_volblocksize) vsparse = xspecs.pop('zfssa_lun:sparse', lcfg.zfssa_lun_sparse) vcompression = xspecs.pop('zfssa_lun:compression', lcfg.zfssa_lun_compression) vlogbias = xspecs.pop('zfssa_lun:logbias', lcfg.zfssa_lun_logbias) return vblocksz, vsparse, vcompression, vlogbias return lcfg.zfssa_lun_volblocksize, lcfg.zfssa_lun_sparse,\ lcfg.zfssa_lun_compression, lcfg.zfssa_lun_logbias"," volblocksize=lcfg.zfssa_lun_volblocksize, sparse=lcfg.zfssa_lun_sparse, compression=lcfg.zfssa_lun_compression, logbias=lcfg.zfssa_lun_logbias)",27,4
openstack%2Fcongress~master~Ia15d0943a4386d36018d3beee7651ec74cdcd520,openstack/congress,master,Ia15d0943a4386d36018d3beee7651ec74cdcd520,Added subscribers/subscriptions to datasource status,MERGED,2014-11-26 22:44:52.000000000,2014-12-19 20:12:55.000000000,2014-12-19 20:12:53.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-11-26 22:44:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/95e43ad36ffc6d2607cd075f175e34fb2c0c1bf0', 'message': 'Added subscribers/subscriptions to datasource status\n\nChange-Id: Ia15d0943a4386d36018d3beee7651ec74cdcd520\n'}, {'number': 2, 'created': '2014-11-27 05:10:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/eb9c85620fbd9426774202a151ada845a92ed724', 'message': 'Added subscribers/subscriptions to datasource status\n\nChange-Id: Ia15d0943a4386d36018d3beee7651ec74cdcd520\n'}, {'number': 3, 'created': '2014-11-27 06:30:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/51c037776617f594f92600b16d4ba55a86ff9a69', 'message': 'Added subscribers/subscriptions to datasource status\n\nChange-Id: Ia15d0943a4386d36018d3beee7651ec74cdcd520\n'}, {'number': 4, 'created': '2014-11-27 06:42:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/70fe95a598e9bc853b445f5e2e54f8bd5e24f8db', 'message': 'Added subscribers/subscriptions to datasource status\n\nChange-Id: Ia15d0943a4386d36018d3beee7651ec74cdcd520\n'}, {'number': 5, 'created': '2014-11-27 17:04:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/d48bf6f3a73f545ae4cb857bb332bd05ea83221e', 'message': 'Added subscribers/subscriptions to datasource status\n\nChange-Id: Ia15d0943a4386d36018d3beee7651ec74cdcd520\n'}, {'number': 6, 'created': '2014-11-27 17:29:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/af60ab31f9f756462bb7306de041598a4014a227', 'message': 'Added subscribers/subscriptions to datasource status\n\nChange-Id: Ia15d0943a4386d36018d3beee7651ec74cdcd520\n'}, {'number': 7, 'created': '2014-11-27 18:04:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/6b74cd5dde4bfa6466c88e5a0945467302ac6b85', 'message': 'Added subscribers/subscriptions to datasource status\n\nChange-Id: Ia15d0943a4386d36018d3beee7651ec74cdcd520\n'}, {'number': 8, 'created': '2014-12-03 21:52:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/eb9a9317d24bf6d021abcf547c1557a400a43fd4', 'message': 'Added subscribers/subscriptions to datasource status\n\nChange-Id: Ia15d0943a4386d36018d3beee7651ec74cdcd520\n'}, {'number': 9, 'created': '2014-12-10 20:51:55.000000000', 'files': ['congress/tests/test_congress.py', 'congress/datasources/datasource_driver.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/41dbe85c7ab42bb59ee92fe4b5679d4ac7ffb39f', 'message': 'Added subscribers/subscriptions to datasource status\n\nChange-Id: Ia15d0943a4386d36018d3beee7651ec74cdcd520\n'}]",1,137483,41dbe85c7ab42bb59ee92fe4b5679d4ac7ffb39f,36,4,9,8215,,,0,"Added subscribers/subscriptions to datasource status

Change-Id: Ia15d0943a4386d36018d3beee7651ec74cdcd520
",git fetch https://review.opendev.org/openstack/congress refs/changes/83/137483/7 && git format-patch -1 --stdout FETCH_HEAD,['congress/datasources/datasource_driver.py'],1,95e43ad36ffc6d2607cd075f175e34fb2c0c1bf0,debugging," d['subscriptions'] = [(value.key, value.dataindex) for value in self.subdata.values()] d['subscribers'] = [(name, pubdata.dataindex) for pubdata in self.pubdata.values() for name in pubdata.subscribers] ",,6,0
openstack%2Fdevstack~master~I9fc247ab343c2cea0a8a5b7a3823b5525d6c311f,openstack/devstack,master,I9fc247ab343c2cea0a8a5b7a3823b5525d6c311f,Comment option to enable Setuptools warnings,MERGED,2014-12-18 17:42:09.000000000,2014-12-19 20:10:49.000000000,2014-12-19 20:10:47.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5263}, {'_account_id': 7687}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-18 17:42:09.000000000', 'files': ['tools/install_pip.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/35b5283a8f365f12996af1209448ccd816276e1f', 'message': 'Comment option to enable Setuptools warnings\n\nChange-Id: I9fc247ab343c2cea0a8a5b7a3823b5525d6c311f\n'}]",0,142855,35b5283a8f365f12996af1209448ccd816276e1f,11,6,1,5263,,,0,"Comment option to enable Setuptools warnings

Change-Id: I9fc247ab343c2cea0a8a5b7a3823b5525d6c311f
",git fetch https://review.opendev.org/openstack/devstack refs/changes/55/142855/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/install_pip.sh'],1,35b5283a8f365f12996af1209448ccd816276e1f,setuptools-8,"# Setuptools 8 implements PEP 440, and 8.0.4 adds a warning triggered any time # pkg_resources inspects the list of installed Python packages if there are # non-compliant version numbers in the egg-info (for example, from distro # system packaged Python libraries). This is off by default after 8.2 but can # be enabled by uncommenting the lines below. #PYTHONWARNINGS=$PYTHONWARNINGS,always::RuntimeWarning:pkg_resources #export PYTHONWARNINGS",,7,0
openstack%2Fcongress~master~I32535579818b3fce9e44115e5a9cbc46d15dcfc6,openstack/congress,master,I32535579818b3fce9e44115e5a9cbc46d15dcfc6,Reject rules that reference policies in head,MERGED,2014-11-12 22:21:11.000000000,2014-12-19 20:10:38.000000000,2014-12-19 20:10:38.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-11-12 22:21:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/cbe4375484c1507a555f96c06766ef091367efba', 'message': ""Reject rules that reference policies in head\n\nCongress now assumes that the table reference\n'classify:servers' refers to the 'servers' table from the 'classify'\npolicy.  Previously people could write rules\nwith 'alice:servers' in the head and place that rule inside\nof say the 'bob' policy.  For such rules, there were 2 options for\nresolving the reference: (i) leave it as 'alice:servers' or\n(ii) prefix the table with the policy in which the table is defined:\n'bob:alice:servers'.  Option (i) breaks the invariant that 'alice:servers'\nrefers to the 'servers' table within the 'alice' policy.  Option (ii)\nis confusing.\n\nThis change eliminates the problem by prohibiting rules from including\npolicies in the head.\n\nChange-Id: I32535579818b3fce9e44115e5a9cbc46d15dcfc6\n""}, {'number': 2, 'created': '2014-11-12 22:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/a60ab85041230df3104a33517161a54345711aba', 'message': ""Reject rules that reference policies in head\n\nCongress now assumes that the table reference 'classify:servers'\nrefers to the 'servers' table from the 'classify' policy.\nPreviously people could write rules with 'alice:servers' in the\nhead and place that rule inside of say the 'bob' policy.  For\nsuch rules, there were 2 options for resolving the reference:\n(i) leave it as 'alice:servers' or (ii) prefix the table with\nthe policy in which the table is defined: 'bob:alice:servers'.\nOption (i) breaks the invariant that 'alice:servers' refers to\nthe 'servers' table within the 'alice' policy.  Option (ii)\nis confusing.\n\nThis change eliminates the problem by prohibiting rules from including\npolicies in the head.  It also makes schemas explicitly declare\nwhether they have information about all of the tables permitted\ninside the policy or whether they have incomplete information.\n\nChange-Id: I32535579818b3fce9e44115e5a9cbc46d15dcfc6\n""}, {'number': 3, 'created': '2014-11-20 17:48:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/3bd0deeabc10f0df239089bb025b2a4b20386d9a', 'message': ""Reject rules that reference policies in head\n\nCongress now assumes that the table reference 'classify:servers'\nrefers to the 'servers' table from the 'classify' policy.\nPreviously people could write rules with 'alice:servers' in the\nhead and place that rule inside of say the 'bob' policy.  For\nsuch rules, there were 2 options for resolving the reference:\n(i) leave it as 'alice:servers' or (ii) prefix the table with\nthe policy in which the table is defined: 'bob:alice:servers'.\nOption (i) breaks the invariant that 'alice:servers' refers to\nthe 'servers' table within the 'alice' policy.  Option (ii)\nis confusing.\n\nThis change eliminates the problem by prohibiting rules from including\npolicies in the head.  It also makes schemas explicitly declare\nwhether they have information about all of the tables permitted\ninside the policy or whether they have incomplete information.\n\nChange-Id: I32535579818b3fce9e44115e5a9cbc46d15dcfc6\n""}, {'number': 4, 'created': '2014-11-21 00:06:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/60e310f49d6fe98ce95fbe812a9a54deb7a6daf1', 'message': ""Reject rules that reference policies in head\n\nCongress now assumes that the table reference 'classify:servers'\nrefers to the 'servers' table from the 'classify' policy.\nPreviously people could write rules with 'alice:servers' in the\nhead and place that rule inside of say the 'bob' policy.  For\nsuch rules, there were 2 options for resolving the reference:\n(i) leave it as 'alice:servers' or (ii) prefix the table with\nthe policy in which the table is defined: 'bob:alice:servers'.\nOption (i) breaks the invariant that 'alice:servers' refers to\nthe 'servers' table within the 'alice' policy.  Option (ii)\nis confusing.\n\nThis change eliminates the problem by prohibiting rules from including\npolicies in the head.  It also makes schemas explicitly declare\nwhether they have information about all of the tables permitted\ninside the policy or whether they have incomplete information.\n\nChange-Id: I32535579818b3fce9e44115e5a9cbc46d15dcfc6\n""}, {'number': 5, 'created': '2014-12-08 23:28:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/d4b9394b6ffa17a5a65b1e460b64b47487ffe96b', 'message': ""Reject rules that reference policies in head\n\nCongress now assumes that the table reference 'classify:servers'\nrefers to the 'servers' table from the 'classify' policy.\nPreviously people could write rules with 'alice:servers' in the\nhead and place that rule inside of say the 'bob' policy.  For\nsuch rules, there were 2 options for resolving the reference:\n(i) leave it as 'alice:servers' or (ii) prefix the table with\nthe policy in which the table is defined: 'bob:alice:servers'.\nOption (i) breaks the invariant that 'alice:servers' refers to\nthe 'servers' table within the 'alice' policy.  Option (ii)\nis confusing.\n\nThis change eliminates the problem by prohibiting rules from including\npolicies in the head.  It also makes schemas explicitly declare\nwhether they have information about all of the tables permitted\ninside the policy or whether they have incomplete information.\n\nChange-Id: I32535579818b3fce9e44115e5a9cbc46d15dcfc6\n""}, {'number': 6, 'created': '2014-12-10 19:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/10ff0b6fbabb43f859f22bb30548201665f03465', 'message': ""Reject rules that reference policies in head\n\nCongress now assumes that the table reference 'classify:servers'\nrefers to the 'servers' table from the 'classify' policy.\nPreviously people could write rules with 'alice:servers' in the\nhead and place that rule inside of say the 'bob' policy.  For\nsuch rules, there were 2 options for resolving the reference:\n(i) leave it as 'alice:servers' or (ii) prefix the table with\nthe policy in which the table is defined: 'bob:alice:servers'.\nOption (i) breaks the invariant that 'alice:servers' refers to\nthe 'servers' table within the 'alice' policy.  Option (ii)\nis confusing.\n\nThis change eliminates the problem by prohibiting rules from including\npolicies in the head.  It also makes schemas explicitly declare\nwhether they have information about all of the tables permitted\ninside the policy or whether they have incomplete information.\n\nChange-Id: I32535579818b3fce9e44115e5a9cbc46d15dcfc6\n""}, {'number': 7, 'created': '2014-12-12 00:35:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/837f44b1786a058c9691dd5fe179b6b315891863', 'message': ""Reject rules that reference policies in head\n\nCongress now assumes that the table reference 'classify:servers'\nrefers to the 'servers' table from the 'classify' policy.\nPreviously people could write rules with 'alice:servers' in the\nhead and place that rule inside of say the 'bob' policy.  For\nsuch rules, there were 2 options for resolving the reference:\n(i) leave it as 'alice:servers' or (ii) prefix the table with\nthe policy in which the table is defined: 'bob:alice:servers'.\nOption (i) breaks the invariant that 'alice:servers' refers to\nthe 'servers' table within the 'alice' policy.  Option (ii)\nis confusing.\n\nThis change eliminates the problem by prohibiting rules from including\npolicies in the head.  It also makes schemas explicitly declare\nwhether they have information about all of the tables permitted\ninside the policy or whether they have incomplete information.\n\nChange-Id: I32535579818b3fce9e44115e5a9cbc46d15dcfc6\n""}, {'number': 8, 'created': '2014-12-12 19:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/6f8174336d9f9b3e8c5900400a7672b3a4d0be72', 'message': ""Reject rules that reference policies in head\n\nCongress now assumes that the table reference 'classify:servers'\nrefers to the 'servers' table from the 'classify' policy.\nPreviously people could write rules with 'alice:servers' in the\nhead and place that rule inside of say the 'bob' policy.  For\nsuch rules, there were 2 options for resolving the reference:\n(i) leave it as 'alice:servers' or (ii) prefix the table with\nthe policy in which the table is defined: 'bob:alice:servers'.\nOption (i) breaks the invariant that 'alice:servers' refers to\nthe 'servers' table within the 'alice' policy.  Option (ii)\nis confusing.\n\nThis change eliminates the problem by prohibiting rules from including\npolicies in the head.  It also makes schemas explicitly declare\nwhether they have information about all of the tables permitted\ninside the policy or whether they have incomplete information.\n\nChange-Id: I32535579818b3fce9e44115e5a9cbc46d15dcfc6\n""}, {'number': 9, 'created': '2014-12-12 19:33:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/4b3db6484e4ae6dfe3ea2c55caa05715277ad17b', 'message': ""Reject rules that reference policies in head\n\nCongress now assumes that the table reference 'classify:servers'\nrefers to the 'servers' table from the 'classify' policy.\nPreviously people could write rules with 'alice:servers' in the\nhead and place that rule inside of say the 'bob' policy.  For\nsuch rules, there were 2 options for resolving the reference:\n(i) leave it as 'alice:servers' or (ii) prefix the table with\nthe policy in which the table is defined: 'bob:alice:servers'.\nOption (i) breaks the invariant that 'alice:servers' refers to\nthe 'servers' table within the 'alice' policy.  Option (ii)\nis confusing.\n\nThis change eliminates the problem by prohibiting rules from including\npolicies in the head.  It also makes schemas explicitly declare\nwhether they have information about all of the tables permitted\ninside the policy or whether they have incomplete information.\n\nChange-Id: I32535579818b3fce9e44115e5a9cbc46d15dcfc6\n""}, {'number': 10, 'created': '2014-12-17 16:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/77ff083bc863ac73b7ce204a45af61da3fc0c2f6', 'message': ""Reject rules that reference policies in head\n\nCongress now assumes that the table reference 'classify:servers'\nrefers to the 'servers' table from the 'classify' policy.\nPreviously people could write rules with 'alice:servers' in the\nhead and place that rule inside of say the 'bob' policy.  For\nsuch rules, there were 2 options for resolving the reference:\n(i) leave it as 'alice:servers' or (ii) prefix the table with\nthe policy in which the table is defined: 'bob:alice:servers'.\nOption (i) breaks the invariant that 'alice:servers' refers to\nthe 'servers' table within the 'alice' policy.  Option (ii)\nis confusing.\n\nThis change eliminates the problem by prohibiting rules from including\npolicies in the head.  It also makes schemas explicitly declare\nwhether they have information about all of the tables permitted\ninside the policy or whether they have incomplete information.\n\nChange-Id: I32535579818b3fce9e44115e5a9cbc46d15dcfc6\n""}, {'number': 11, 'created': '2014-12-17 18:04:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/a084588d17e774e430ddf486c33d868ceeaacf52', 'message': ""Reject rules that reference policies in head\n\nCongress now assumes that the table reference 'classify:servers'\nrefers to the 'servers' table from the 'classify' policy.\nPreviously people could write rules with 'alice:servers' in the\nhead and place that rule inside of say the 'bob' policy.  For\nsuch rules, there were 2 options for resolving the reference:\n(i) leave it as 'alice:servers' or (ii) prefix the table with\nthe policy in which the table is defined: 'bob:alice:servers'.\nOption (i) breaks the invariant that 'alice:servers' refers to\nthe 'servers' table within the 'alice' policy.  Option (ii)\nis confusing.\n\nThis change eliminates the problem by prohibiting rules from including\npolicies in the head.  It also makes schemas explicitly declare\nwhether they have information about all of the tables permitted\ninside the policy or whether they have incomplete information.\n\nChange-Id: I32535579818b3fce9e44115e5a9cbc46d15dcfc6\n""}, {'number': 12, 'created': '2014-12-17 19:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/23f1b171b29d428fdb7af7430684794eab7116f8', 'message': ""Reject rules that reference policies in head\n\nCongress now assumes that the table reference 'classify:servers'\nrefers to the 'servers' table from the 'classify' policy.\nPreviously people could write rules with 'alice:servers' in the\nhead and place that rule inside of say the 'bob' policy.  For\nsuch rules, there were 2 options for resolving the reference:\n(i) leave it as 'alice:servers' or (ii) prefix the table with\nthe policy in which the table is defined: 'bob:alice:servers'.\nOption (i) breaks the invariant that 'alice:servers' refers to\nthe 'servers' table within the 'alice' policy.  Option (ii)\nis confusing.\n\nThis change eliminates the problem by prohibiting rules from including\npolicies in the head.  It also makes schemas explicitly declare\nwhether they have information about all of the tables permitted\ninside the policy or whether they have incomplete information.\n\nChange-Id: I32535579818b3fce9e44115e5a9cbc46d15dcfc6\n""}, {'number': 13, 'created': '2014-12-18 22:38:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/63c5028c904f53e15fd6ba81f9c3b5a4666aed32', 'message': ""Reject rules that reference policies in head\n\nCongress now assumes that the table reference 'classify:servers'\nrefers to the 'servers' table from the 'classify' policy.\nPreviously people could write rules with 'alice:servers' in the\nhead and place that rule inside of say the 'bob' policy.  For\nsuch rules, there were 2 options for resolving the reference:\n(i) leave it as 'alice:servers' or (ii) prefix the table with\nthe policy in which the table is defined: 'bob:alice:servers'.\nOption (i) breaks the invariant that 'alice:servers' refers to\nthe 'servers' table within the 'alice' policy.  Option (ii)\nis confusing.\n\nThis change eliminates the problem by prohibiting rules from including\npolicies in the head.  It also makes schemas explicitly declare\nwhether they have information about all of the tables permitted\ninside the policy or whether they have incomplete information.\n\nChange-Id: I32535579818b3fce9e44115e5a9cbc46d15dcfc6\n""}, {'number': 14, 'created': '2014-12-18 22:40:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/519d1ba0dbe84ba64a112160c0fc72b8ac2c07d4', 'message': ""Reject rules that reference policies in head\n\nCongress now assumes that the table reference 'classify:servers'\nrefers to the 'servers' table from the 'classify' policy.\nPreviously people could write rules with 'alice:servers' in the\nhead and place that rule inside of say the 'bob' policy.  For\nsuch rules, there were 2 options for resolving the reference:\n(i) leave it as 'alice:servers' or (ii) prefix the table with\nthe policy in which the table is defined: 'bob:alice:servers'.\nOption (i) breaks the invariant that 'alice:servers' refers to\nthe 'servers' table within the 'alice' policy.  Option (ii)\nis confusing.\n\nThis change eliminates the problem by prohibiting rules from including\npolicies in the head.  It also makes schemas explicitly declare\nwhether they have information about all of the tables permitted\ninside the policy or whether they have incomplete information.\n\nChange-Id: I32535579818b3fce9e44115e5a9cbc46d15dcfc6\n""}, {'number': 15, 'created': '2014-12-18 23:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/568c08e8502b91cab0f8ccf55e033167f875a74f', 'message': ""Reject rules that reference policies in head\n\nCongress now assumes that the table reference 'classify:servers'\nrefers to the 'servers' table from the 'classify' policy.\nPreviously people could write rules with 'alice:servers' in the\nhead and place that rule inside of say the 'bob' policy.  For\nsuch rules, there were 2 options for resolving the reference:\n(i) leave it as 'alice:servers' or (ii) prefix the table with\nthe policy in which the table is defined: 'bob:alice:servers'.\nOption (i) breaks the invariant that 'alice:servers' refers to\nthe 'servers' table within the 'alice' policy.  Option (ii)\nis confusing.\n\nThis change eliminates the problem by prohibiting rules from including\npolicies in the head.  It also makes schemas explicitly declare\nwhether they have information about all of the tables permitted\ninside the policy or whether they have incomplete information.\n\nChange-Id: I32535579818b3fce9e44115e5a9cbc46d15dcfc6\n""}, {'number': 16, 'created': '2014-12-19 17:18:52.000000000', 'files': ['congress/policy/compile.py', 'congress/tests/policy/test_runtime.py', 'congress/tests/policy/test_compiler.py', 'congress/policy/runtime.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/c70a2e731caf199f087065b0e6b56bcabe21cf01', 'message': ""Reject rules that reference policies in head\n\nCongress now assumes that the table reference 'classify:servers'\nrefers to the 'servers' table from the 'classify' policy.\nPreviously people could write rules with 'alice:servers' in the\nhead and place that rule inside of say the 'bob' policy.  For\nsuch rules, there were 2 options for resolving the reference:\n(i) leave it as 'alice:servers' or (ii) prefix the table with\nthe policy in which the table is defined: 'bob:alice:servers'.\nOption (i) breaks the invariant that 'alice:servers' refers to\nthe 'servers' table within the 'alice' policy.  Option (ii)\nis confusing.\n\nThis change eliminates the problem by prohibiting rules from including\npolicies in the head.  It also makes schemas explicitly declare\nwhether they have information about all of the tables permitted\ninside the policy or whether they have incomplete information.\n\nChange-Id: I32535579818b3fce9e44115e5a9cbc46d15dcfc6\n""}]",0,134064,c70a2e731caf199f087065b0e6b56bcabe21cf01,70,4,16,8215,,,0,"Reject rules that reference policies in head

Congress now assumes that the table reference 'classify:servers'
refers to the 'servers' table from the 'classify' policy.
Previously people could write rules with 'alice:servers' in the
head and place that rule inside of say the 'bob' policy.  For
such rules, there were 2 options for resolving the reference:
(i) leave it as 'alice:servers' or (ii) prefix the table with
the policy in which the table is defined: 'bob:alice:servers'.
Option (i) breaks the invariant that 'alice:servers' refers to
the 'servers' table within the 'alice' policy.  Option (ii)
is confusing.

This change eliminates the problem by prohibiting rules from including
policies in the head.  It also makes schemas explicitly declare
whether they have information about all of the tables permitted
inside the policy or whether they have incomplete information.

Change-Id: I32535579818b3fce9e44115e5a9cbc46d15dcfc6
",git fetch https://review.opendev.org/openstack/congress refs/changes/64/134064/12 && git format-patch -1 --stdout FETCH_HEAD,"['congress/policy/compile.py', 'congress/policy/tests/test_runtime.py', 'congress/policy/tests/test_compiler.py', 'congress/policy/runtime.py']",4,cbe4375484c1507a555f96c06766ef091367efba,multipolicy," event.formula, self.theories, self.name)) event.formula, self.theories, self.name)) event.formula, self.theories, self.name)) event.formula, self.theories, self.name)) event.formula, self.theories, self.name)) event.formula, self.theories, self.name)) def set_schema(self, name, schema, complete=False): self.theory[name].schema = compile.Schema(schema, complete=complete)"," event.formula, self.theories)) event.formula, self.theories)) event.formula, self.theories)) event.formula, self.theories)) event.formula, self.theories)) event.formula, self.theories)) def set_schema(self, name, schema): self.theory[name].schema = compile.Schema(schema)",90,37
openstack%2Fcinder~master~Ic483e54b40349ede20e078c6406f5bab8d7d7cc2,openstack/cinder,master,Ic483e54b40349ede20e078c6406f5bab8d7d7cc2,Add Support for Dell Storage Center,MERGED,2014-12-04 18:54:02.000000000,2014-12-19 20:06:21.000000000,2014-12-16 22:06:21.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 7160}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10068}, {'_account_id': 10379}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12112}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12779}, {'_account_id': 12780}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-04 18:54:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f7d513c4a34b980c54380ef03d26837eecb88c25', 'message': 'Add Support for Dell Storage Center.\n\nThis driver implements cinder FC and iSCSI volume drivers.\nThe file dell_storagecenter_api.py is called to interface with the\nDell Storage Center backend via a REST interface.\nDell_storagecenter_common.py is the base class implementation with\ndell_storagecenter_fc.py and dell_storagecenter_iscsi.py being providing\nfc and iscsi specific support respectivly.\n\nImplements: blueprint dell-storage-center-block-storage-driver\nChange-Id: Ic483e54b40349ede20e078c6406f5bab8d7d7cc2\n'}, {'number': 2, 'created': '2014-12-04 20:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/92e574259865f94d5c7f0ab4afd383f0438f1097', 'message': 'Add Support for Dell Storage Center.\n\nThis driver implements cinder FC and iSCSI volume drivers.\nThe file dell_storagecenter_api.py is called to interface with the\nDell Storage Center backend via a REST interface.\nDell_storagecenter_common.py is the base class implementation with\ndell_storagecenter_fc.py and dell_storagecenter_iscsi.py being providing\nfc and iscsi specific support respectivly.\n\nImplements: blueprint dell-storage-center-block-storage-driver\nChange-Id: Ic483e54b40349ede20e078c6406f5bab8d7d7cc2\n'}, {'number': 3, 'created': '2014-12-04 21:12:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4d99322eda172a5f23bab799c40ecbd8c9589e51', 'message': 'Add Support for Dell Storage Center.\n\nThis driver implements cinder FC and iSCSI volume drivers.\nThe file dell_storagecenter_api.py is called to interface with the\nDell Storage Center backend via a REST interface.\nDell_storagecenter_common.py is the base class implementation with\ndell_storagecenter_fc.py and dell_storagecenter_iscsi.py being providing\nfc and iscsi specific support respectivly.\n\nImplements: blueprint dell-storage-center-block-storage-driver\nChange-Id: Ic483e54b40349ede20e078c6406f5bab8d7d7cc2\n'}, {'number': 4, 'created': '2014-12-05 21:17:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9fbf7596a003fc512ec0e478eefb2b7c2a1f2044', 'message': 'Add Support for Dell Storage Center.\n\nThis driver implements cinder FC and iSCSI volume drivers.\nThe file dell_storagecenter_api.py is called to interface with the\nDell Storage Center backend via a REST interface.\nDell_storagecenter_common.py is the base class implementation with\ndell_storagecenter_fc.py and dell_storagecenter_iscsi.py being providing\nfc and iscsi specific support respectivly.\n\nImplements: blueprint dell-storage-center-block-storage-driver\nChange-Id: Ic483e54b40349ede20e078c6406f5bab8d7d7cc2\n'}, {'number': 5, 'created': '2014-12-05 21:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/54689ee401301ebe084d5575975638ed25dac144', 'message': 'Add Support for Dell Storage Center.\n\nThis driver implements cinder FC and iSCSI volume drivers.\nThe file dell_storagecenter_api.py is called to interface with the\nDell Storage Center backend via a REST interface.\nDell_storagecenter_common.py is the base class implementation with\ndell_storagecenter_fc.py and dell_storagecenter_iscsi.py being providing\nfc and iscsi specific support respectivly.\n\nImplements: blueprint dell-storage-center-block-storage-driver\nChange-Id: Ic483e54b40349ede20e078c6406f5bab8d7d7cc2\n'}, {'number': 6, 'created': '2014-12-08 22:01:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4337399a5dda7c806004e6737fb79a522a3f0535', 'message': 'Add Support for Dell Storage Center.\n\nThis driver implements cinder FC and iSCSI volume drivers.\nThe file dell_storagecenter_api.py is called to interface with the\nDell Storage Center backend via a REST interface.\nDell_storagecenter_common.py is the base class implementation with\ndell_storagecenter_fc.py and dell_storagecenter_iscsi.py being providing\nfc and iscsi specific support respectivly.\n\nImplements: blueprint dell-storage-center-block-storage-driver\nChange-Id: Ic483e54b40349ede20e078c6406f5bab8d7d7cc2\n'}, {'number': 7, 'created': '2014-12-08 22:34:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cde9e158cee0a39e9b4e8ba135a8aca959290fbd', 'message': 'Add Support for Dell Storage Center.\n\nThis driver implements cinder FC and iSCSI volume drivers.\nThe file dell_storagecenter_api.py is called to interface with the\nDell Storage Center backend via a REST interface.\nDell_storagecenter_common.py is the base class implementation with\ndell_storagecenter_fc.py and dell_storagecenter_iscsi.py being providing\nfc and iscsi specific support respectivly.\n\nImplements: blueprint dell-storage-center-block-storage-driver\nChange-Id: Ic483e54b40349ede20e078c6406f5bab8d7d7cc2\n'}, {'number': 8, 'created': '2014-12-10 20:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e539be2f00250bf70f8d0bd67e62135b92dd958e', 'message': 'Add Support for Dell Storage Center\n\nThis driver implements cinder FC and iSCSI volume drivers.\nThe file dell_storagecenter_api.py is called to interface with the\nDell Storage Center backend via a REST interface.\nDell_storagecenter_common.py is the base class implementation with\ndell_storagecenter_fc.py and dell_storagecenter_iscsi.py being providing\nfc and iscsi specific support respectivly.\n\nhttps://bugs.launchpad.net/cinder/+bug/1398951\n\nImplements: blueprint dell-storage-center-block-storage-driver\nChange-Id: Ic483e54b40349ede20e078c6406f5bab8d7d7cc2\n'}, {'number': 9, 'created': '2014-12-12 16:23:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/926d1816b250607014ee0a9cae0f8f9df3ebc4b9', 'message': 'Add Support for Dell Storage Center\n\nThis driver implements cinder FC and iSCSI volume drivers.\nThe file dell_storagecenter_api.py is called to interface with the\nDell Storage Center backend via a REST interface.\nDell_storagecenter_common.py is the base class implementation with\ndell_storagecenter_fc.py and dell_storagecenter_iscsi.py being providing\nfc and iscsi specific support respectivly.\n\nhttps://bugs.launchpad.net/cinder/+bug/1398951\n\nImplements: blueprint dell-storage-center-block-storage-driver\nChange-Id: Ic483e54b40349ede20e078c6406f5bab8d7d7cc2\n'}, {'number': 10, 'created': '2014-12-12 23:23:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e1f4388f6fff08bcf75fe5c6eb4ef619662a5d77', 'message': 'Add Support for Dell Storage Center\n\nThis driver implements cinder FC and iSCSI volume drivers.\nThe file dell_storagecenter_api.py is called to interface with the\nDell Storage Center backend via a REST interface.\nDell_storagecenter_common.py is the base class implementation with\ndell_storagecenter_fc.py and dell_storagecenter_iscsi.py being providing\nfc and iscsi specific support respectivly.\n\nhttps://bugs.launchpad.net/cinder/+bug/1398951\n\nImplements: blueprint dell-storage-center-block-storage-driver\nChange-Id: Ic483e54b40349ede20e078c6406f5bab8d7d7cc2\n'}, {'number': 11, 'created': '2014-12-15 16:41:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/96f741c172ff66b5b19746fd259157dccfdcb600', 'message': 'Add Support for Dell Storage Center\n\nThis driver implements cinder FC and iSCSI volume drivers.\nThe file dell_storagecenter_api.py is called to interface with the\nDell Storage Center backend via a REST interface.\nDell_storagecenter_common.py is the base class implementation with\ndell_storagecenter_fc.py and dell_storagecenter_iscsi.py being providing\nfc and iscsi specific support respectivly.\n\nhttps://bugs.launchpad.net/cinder/+bug/1398951\n\nImplements: blueprint dell-storage-center-block-storage-driver\nChange-Id: Ic483e54b40349ede20e078c6406f5bab8d7d7cc2\n'}, {'number': 12, 'created': '2014-12-15 18:02:09.000000000', 'files': ['cinder/tests/test_dellsc.py', 'cinder/volume/drivers/dell/dell_storagecenter_common.py', 'cinder/tests/test_dellfc.py', 'cinder/volume/drivers/dell/dell_storagecenter_api.py', 'cinder/volume/drivers/dell/dell_storagecenter_fc.py', 'cinder/volume/drivers/dell/dell_storagecenter_iscsi.py', 'cinder/volume/drivers/dell/__init__.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a114dd3c83df72afcf64aa89fb2f10361102bdb7', 'message': 'Add Support for Dell Storage Center\n\nThis driver implements cinder FC and iSCSI volume drivers.\nThe file dell_storagecenter_api.py is called to interface with the\nDell Storage Center backend via a REST interface.\nDell_storagecenter_common.py is the base class implementation with\ndell_storagecenter_fc.py and dell_storagecenter_iscsi.py being providing\nfc and iscsi specific support respectivly.\n\nhttps://bugs.launchpad.net/cinder/+bug/1398951\n\nImplements: blueprint dell-storage-center-block-storage-driver\nChange-Id: Ic483e54b40349ede20e078c6406f5bab8d7d7cc2\n'}]",112,139153,a114dd3c83df72afcf64aa89fb2f10361102bdb7,115,23,12,12112,,,0,"Add Support for Dell Storage Center

This driver implements cinder FC and iSCSI volume drivers.
The file dell_storagecenter_api.py is called to interface with the
Dell Storage Center backend via a REST interface.
Dell_storagecenter_common.py is the base class implementation with
dell_storagecenter_fc.py and dell_storagecenter_iscsi.py being providing
fc and iscsi specific support respectivly.

https://bugs.launchpad.net/cinder/+bug/1398951

Implements: blueprint dell-storage-center-block-storage-driver
Change-Id: Ic483e54b40349ede20e078c6406f5bab8d7d7cc2
",git fetch https://review.opendev.org/openstack/cinder refs/changes/53/139153/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/dell/dell_storagecenter_common.py', 'cinder/volume/drivers/dell/dell_storagecenter_api.py', 'cinder/volume/drivers/dell/dell_storagecenter_fc.py', 'cinder/volume/drivers/dell/dell_storagecenter_iscsi.py', 'cinder/volume/drivers/dell/__init__.py']",5,f7d513c4a34b980c54380ef03d26837eecb88c25,bp/dell-storage-center-block-storage-driver,,,1696,0
openstack%2Fproject-config~master~I957d4fc263673584901b2c813d813102751ad75b,openstack/project-config,master,I957d4fc263673584901b2c813d813102751ad75b,Update ironic ACLs for ironic-stable-maint,ABANDONED,2014-12-17 17:00:29.000000000,2014-12-19 19:52:43.000000000,,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1106}, {'_account_id': 5263}, {'_account_id': 6316}]","[{'number': 1, 'created': '2014-12-17 17:00:29.000000000', 'files': ['gerrit/acls/openstack/ironic.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a23eb5915047e69a3d6dd7bd3e6565d3e7292279', 'message': 'Update ironic ACLs for ironic-stable-maint\n\nThis updates the openstack/ironic ACLs and allows members of the\nironic-stable-maint -2/+2 on the ironic stable branches.\n\nChange-Id: I957d4fc263673584901b2c813d813102751ad75b\n'}]",0,142504,a23eb5915047e69a3d6dd7bd3e6565d3e7292279,9,5,1,1420,,,0,"Update ironic ACLs for ironic-stable-maint

This updates the openstack/ironic ACLs and allows members of the
ironic-stable-maint -2/+2 on the ironic stable branches.

Change-Id: I957d4fc263673584901b2c813d813102751ad75b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/04/142504/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/openstack/ironic.config'],1,a23eb5915047e69a3d6dd7bd3e6565d3e7292279,,"[access ""refs/heads/stable/*""] abandon = group ironic-stable-maint exclusiveGroupPermissions = abandon label-Code-Review label-Workflow label-Code-Review = -2..+2 group ironic-stable-maint label-Code-Review = -1..+1 group Registered Users label-Workflow = -1..+1 group ironic-stable-maint ",,7,0
openstack%2Fproject-config~master~I232eb538c766d6cc7be7dccd4fd1a698af643d78,openstack/project-config,master,I232eb538c766d6cc7be7dccd4fd1a698af643d78,Update stable branch ACLs for zaqar and ironic,MERGED,2014-12-19 15:20:27.000000000,2014-12-19 19:48:55.000000000,2014-12-19 19:48:55.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6159}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-19 15:20:27.000000000', 'files': ['gerrit/acls/openstack/ironic.config', 'gerrit/acls/openstack/zaqar.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f32e433529d8625a03ef09e0f7adef9bc926392f', 'message': ""Update stable branch ACLs for zaqar and ironic\n\nZaqar and Ironic did not have a stable-branch-team-supported release\nyet, so they aren't directly handled by stable-maint-core yet.\nHowever, their ACL did not explicitly specify a fallback team other\nthan openstack-stable-maint (which used to be inherited from\nAll-projects). Since that group was discontinued, that left their\nstable branches in limbo. After discussion with their PTLs, we\ndecided to fallback on zaqar-core and ironic-milestone groups for\nstable reviews.\n\nChange-Id: I232eb538c766d6cc7be7dccd4fd1a698af643d78\n""}]",0,143112,f32e433529d8625a03ef09e0f7adef9bc926392f,10,5,1,308,,,0,"Update stable branch ACLs for zaqar and ironic

Zaqar and Ironic did not have a stable-branch-team-supported release
yet, so they aren't directly handled by stable-maint-core yet.
However, their ACL did not explicitly specify a fallback team other
than openstack-stable-maint (which used to be inherited from
All-projects). Since that group was discontinued, that left their
stable branches in limbo. After discussion with their PTLs, we
decided to fallback on zaqar-core and ironic-milestone groups for
stable reviews.

Change-Id: I232eb538c766d6cc7be7dccd4fd1a698af643d78
",git fetch https://review.opendev.org/openstack/project-config refs/changes/12/143112/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/ironic.config', 'gerrit/acls/openstack/zaqar.config']",2,f32e433529d8625a03ef09e0f7adef9bc926392f,stable-incubated-acls,"[access ""refs/heads/stable/*""] abandon = group zaqar-core exclusiveGroupPermissions = abandon label-Code-Review label-Workflow label-Code-Review = -2..+2 group zaqar-core label-Code-Review = -1..+1 group Registered Users label-Workflow = -1..+1 group zaqar-core ",,14,0
openstack%2Fsahara~master~I8d0713ae0c9de4384ee3f0615a04b46d728bb890,openstack/sahara,master,I8d0713ae0c9de4384ee3f0615a04b46d728bb890,Refactor ip assign in service/engine,ABANDONED,2014-12-19 12:41:55.000000000,2014-12-19 19:46:06.000000000,,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-12-19 12:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/8fa9d21c6c40a1b4e6f1461bb4ddd4cc06b43d32', 'message': 'Refactor ip assign in service/engine\n\nWe add this refactor to make process with assigning events to\nprovisioning steps more clear. Now we can use wrapper to assign\nevent to instance in that case.\n\nChange-Id: I8d0713ae0c9de4384ee3f0615a04b46d728bb890\n'}, {'number': 2, 'created': '2014-12-19 12:56:54.000000000', 'files': ['sahara/service/engine.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/74474feed79c1142edfb6fe02819718b0d4234cc', 'message': 'Refactor ip assign in service/engine\n\nWe add this refactor to make process with assigning events to\nprovisioning steps more clear. Now we can use wrapper to assign\nevent to instance in that case.\n\nChange-Id: I8d0713ae0c9de4384ee3f0615a04b46d728bb890\n'}]",2,143071,74474feed79c1142edfb6fe02819718b0d4234cc,8,4,2,12038,,,0,"Refactor ip assign in service/engine

We add this refactor to make process with assigning events to
provisioning steps more clear. Now we can use wrapper to assign
event to instance in that case.

Change-Id: I8d0713ae0c9de4384ee3f0615a04b46d728bb890
",git fetch https://review.opendev.org/openstack/sahara refs/changes/71/143071/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/service/engine.py'],1,8fa9d21c6c40a1b4e6f1461bb4ddd4cc06b43d32,ref1," def _assign_ip_to_instance(self, instance): while True: if not g.check_cluster_exists(instance.node_group.cluster): return if networks.init_instances_ips(instance): return context.sleep(2) with context.ThreadGroup as tg: for instance in instances: tg.spawn('assign-ip-%', instance.instance_name, self._assign_ip_to_instance, instance)"," ips_assigned = set() while len(ips_assigned) != len(instances): if not g.check_cluster_exists(cluster): return for instance in instances: if instance.id not in ips_assigned: if networks.init_instances_ips(instance): ips_assigned.add(instance.id) context.sleep(1) instances = g.get_instances(cluster, ips_assigned)",13,10
openstack%2Fsahara~master~Ic692882714da0f8f420347f25c8bb92c166ac2c9,openstack/sahara,master,Ic692882714da0f8f420347f25c8bb92c166ac2c9,Add refactor to service/direct_engine,ABANDONED,2014-12-19 12:55:02.000000000,2014-12-19 19:45:21.000000000,,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-12-19 12:55:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/5d905722d35c1928358310e4b4434b2922060dcb', 'message': 'Add refactor to service/direct_engine\n\nWe add this refactor to make process with assigning events to\nprovisioning steps more clear. Now we can use wrapper to assign\nevent to instance in that case.\n\nChange-Id: Ic692882714da0f8f420347f25c8bb92c166ac2c9\n'}, {'number': 2, 'created': '2014-12-19 12:57:56.000000000', 'files': ['sahara/service/direct_engine.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/42ab1854d49e4ed1a6b488f84ede218fb071ce6b', 'message': 'Add refactor to service/direct_engine\n\nWe add this refactor to make process with assigning events to\nprovisioning steps more clear. Now we can use wrapper to assign\nevent to instance in that case.\n\nChange-Id: Ic692882714da0f8f420347f25c8bb92c166ac2c9\n'}]",0,143073,42ab1854d49e4ed1a6b488f84ede218fb071ce6b,8,4,2,12038,,,0,"Add refactor to service/direct_engine

We add this refactor to make process with assigning events to
provisioning steps more clear. Now we can use wrapper to assign
event to instance in that case.

Change-Id: Ic692882714da0f8f420347f25c8bb92c166ac2c9
",git fetch https://review.opendev.org/openstack/sahara refs/changes/73/143073/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/service/direct_engine.py'],1,5d905722d35c1928358310e4b4434b2922060dcb,ref2," def _await_instance_active(self, instance): while True: if not g.check_cluster_exists(instance.node_group.cluster): return if self._check_if_active(instance): return context.sleep(1) def _await_instance_deleted(self, instance): while True: if not g.check_cluster_exists(instance.node_group.cluster): return if self._check_if_deleted(instance): LOG.debug(""Instance '%s' is deleted"" % instance.instance_name) return context.sleep(1) with context.ThreadGroup as tg: for instance in instances: tg.spawn('await-active-%s' % instance.instance_name, self._await_instance_active, instance) with context.ThreadGroup as tg: for instance in instances: tg.spawn('await-deleted-%s' % instance.instance_name, self._await_instance_deleted, instance)"," active_ids = set() while len(active_ids) != len(instances): if not g.check_cluster_exists(cluster): return for instance in instances: if instance.id not in active_ids: if self._check_if_active(instance): active_ids.add(instance.id) context.sleep(1) deleted_ids = set() while len(deleted_ids) != len(instances): if not g.check_cluster_exists(cluster): return for instance in instances: if instance.id not in deleted_ids: if self._check_if_deleted(instance): LOG.debug(""Instance '%s' is deleted"" % instance.instance_name) deleted_ids.add(instance.id) context.sleep(1)",28,20
openstack%2Fopenstack-manuals~master~If9b7431fb29ea52552147c92847da465801bb0f1,openstack/openstack-manuals,master,If9b7431fb29ea52552147c92847da465801bb0f1,Clarify that namespaces are not deleted by default for DHCP and L3 agents,MERGED,2014-12-15 16:46:06.000000000,2014-12-19 19:42:20.000000000,2014-12-19 19:42:19.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 704}, {'_account_id': 964}, {'_account_id': 3114}, {'_account_id': 6547}, {'_account_id': 10705}, {'_account_id': 12402}]","[{'number': 1, 'created': '2014-12-15 16:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/726bbfa0a5d1a7f828192ae0f419f1549f2f16b3', 'message': 'Clarify that namespaces are not deleted by default for DHCP and L3 agents\n\nAll namespaces for DHCP and L3 agent in Neutron are not deleted\nby default, this note indicates that and also clarifies that this\nbehaviour can be changed for both agents via configuration files\n\nChange-Id: If9b7431fb29ea52552147c92847da465801bb0f1\nCloses-bug: #1402739\nRelated-bug: #1052535\n'}, {'number': 2, 'created': '2014-12-15 16:59:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/273e1b31c0d3a24bc6b879fceacce38d38b190ab', 'message': 'Clarify that namespaces are not deleted by default for DHCP and L3 agents\n\nAll namespaces for DHCP and L3 agent in Neutron are not deleted\nby default, this note indicates that and also clarifies that this\nbehaviour can be changed for both agents via configuration files\n\nChange-Id: If9b7431fb29ea52552147c92847da465801bb0f1\nCloses-bug: #1402739\nRelated-bug: #1052535\n'}, {'number': 3, 'created': '2014-12-15 22:36:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ef124343c235f9c638896a553a625f612206b150', 'message': 'Clarify that namespaces are not deleted by default for DHCP and L3 agents\n\nAll namespaces for DHCP and L3 agent in Neutron are not deleted\nby default, this note indicates that and also clarifies that this\nbehaviour can be changed for both agents via configuration files\n\nChange-Id: If9b7431fb29ea52552147c92847da465801bb0f1\nCloses-bug: #1402739\nRelated-bug: #1052535\n'}, {'number': 4, 'created': '2014-12-16 03:54:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ab2d0c665393e02963c7b511c29ae77771ff2b4e', 'message': 'Clarify that namespaces are not deleted by default for DHCP and L3 agents\n\nAll namespaces for DHCP and L3 agent in Neutron are not deleted\nby default, this note indicates that and also clarifies that this\nbehaviour can be changed for both agents via configuration files\n\nChange-Id: If9b7431fb29ea52552147c92847da465801bb0f1\nCloses-bug: #1402739\nRelated-bug: #1052535\n'}, {'number': 5, 'created': '2014-12-18 17:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e5bdd6fdccaf6d939b79134d26abe1a7b626daac', 'message': 'Clarify that namespaces are not deleted by default for DHCP and L3 agents\n\nAll namespaces for DHCP and L3 agent in Neutron are not deleted\nby default, this note indicates that and also clarifies that this\nbehaviour can be changed for both agents via configuration files\n\nChange-Id: If9b7431fb29ea52552147c92847da465801bb0f1\nCloses-bug: #1402739\nRelated-bug: #1052535\n'}, {'number': 6, 'created': '2014-12-18 22:13:20.000000000', 'files': ['doc/admin-guide-cloud/networking/section_networking_config-agents.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/66db5fcba7f6ba71651f160247fa515973c5357e', 'message': 'Clarify that namespaces are not deleted by default for DHCP and L3 agents\n\nAll namespaces for DHCP and L3 agent in Neutron are not deleted\nby default, this note indicates that and also clarifies that this\nbehaviour can be changed for both agents via configuration files\n\nChange-Id: If9b7431fb29ea52552147c92847da465801bb0f1\nCloses-bug: #1402739\nRelated-bug: #1052535\n'}]",16,141837,66db5fcba7f6ba71651f160247fa515973c5357e,30,8,6,704,,,0,"Clarify that namespaces are not deleted by default for DHCP and L3 agents

All namespaces for DHCP and L3 agent in Neutron are not deleted
by default, this note indicates that and also clarifies that this
behaviour can be changed for both agents via configuration files

Change-Id: If9b7431fb29ea52552147c92847da465801bb0f1
Closes-bug: #1402739
Related-bug: #1052535
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/37/141837/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/networking/section_networking_config-agents.xml'],1,726bbfa0a5d1a7f828192ae0f419f1549f2f16b3,bug/1402739, <note> <para>Networking namespaces are configured to not be deleted by default. This behavior can be change for both DHCP and L3 agents. The configuration files are <filename>dhcp_agent.ini</filename> and <filename>l3_agent.ini</filename> respectively.</para> </note>,,7,0
openstack%2Fheat-translator~master~Iffbe5f00e1ecb7a95a2dc22c3655526087c86021,openstack/heat-translator,master,Iffbe5f00e1ecb7a95a2dc22c3655526087c86021,Create relationship between TOSCA nodes per updated specs,MERGED,2014-12-10 01:44:02.000000000,2014-12-19 19:39:10.000000000,2014-12-19 19:39:10.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 6460}, {'_account_id': 7193}, {'_account_id': 11355}]","[{'number': 1, 'created': '2014-12-10 01:44:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/971ae06203a95781af69c1e6a8fb117b0a32450a', 'message': 'Create relationship between TOSCA nodes per updated specs\n\nPer latest TOSCA specs, TOSCA requirements can now be specified with\nspecific keywords and relationship templates to define relationship\nbetween TOSCA nodes.\n\nChange-Id: Iffbe5f00e1ecb7a95a2dc22c3655526087c86021\n'}, {'number': 2, 'created': '2014-12-10 01:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/9e91fe853ab2fe2f18a803725e5b8369c889a591', 'message': 'Create relationship between TOSCA nodes per updated specs\n\nPer latest TOSCA specs, TOSCA requirements can now be specified with\nspecific keywords and relationship templates to define relationship\nbetween TOSCA nodes.\n\nChange-Id: Iffbe5f00e1ecb7a95a2dc22c3655526087c86021\n'}, {'number': 3, 'created': '2014-12-10 03:30:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/7c042931e753ab51f75f03ec4a727e9c29939862', 'message': 'Create relationship between TOSCA nodes per updated specs\n\nPer latest TOSCA specs, TOSCA requirements can now be specified with\nspecific keywords and relationship templates to define relationship\nbetween TOSCA nodes.\n\nimplements blueprint tosca-requirement-update\n\nChange-Id: Iffbe5f00e1ecb7a95a2dc22c3655526087c86021\n'}, {'number': 4, 'created': '2014-12-10 03:43:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/df5434ce4fb57a8ccdc430c5b1ebf70097066ad8', 'message': 'Create relationship between TOSCA nodes per updated specs\n\nPer latest TOSCA specs, TOSCA requirements can now be specified with\nspecific keywords and relationship templates to define relationship\nbetween TOSCA nodes.\n\nimplements blueprint tosca-requirement-update\n\nChange-Id: Iffbe5f00e1ecb7a95a2dc22c3655526087c86021\n'}, {'number': 5, 'created': '2014-12-16 14:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/aaed23b16394296ec29aaaa3512292111510ee33', 'message': 'Create relationship between TOSCA nodes per updated specs\n\nPer latest TOSCA specs, TOSCA requirements can now be specified with\nspecific keywords and relationship templates to define relationship\nbetween TOSCA nodes.\n\nimplements blueprint tosca-requirement-update\n\nChange-Id: Iffbe5f00e1ecb7a95a2dc22c3655526087c86021\n'}, {'number': 6, 'created': '2014-12-19 03:54:18.000000000', 'files': ['translator/toscalib/elements/relationshiptype.py', 'translator/toscalib/nodetemplate.py', 'translator/toscalib/tests/data/test_requirements.yaml', 'translator/toscalib/tests/test_toscatpl.py', 'translator/toscalib/tosca_template.py'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/1f6a6f57aebcc5f25d02a3814179f9dd13f3f182', 'message': 'Create relationship between TOSCA nodes per updated specs\n\nPer latest TOSCA specs, TOSCA requirements can now be specified with\nspecific keywords and relationship templates to define relationship\nbetween TOSCA nodes.\n\nimplements blueprint tosca-requirement-update\n\nChange-Id: Iffbe5f00e1ecb7a95a2dc22c3655526087c86021\n'}]",17,140551,1f6a6f57aebcc5f25d02a3814179f9dd13f3f182,23,5,6,6456,,,0,"Create relationship between TOSCA nodes per updated specs

Per latest TOSCA specs, TOSCA requirements can now be specified with
specific keywords and relationship templates to define relationship
between TOSCA nodes.

implements blueprint tosca-requirement-update

Change-Id: Iffbe5f00e1ecb7a95a2dc22c3655526087c86021
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/51/140551/1 && git format-patch -1 --stdout FETCH_HEAD,"['translator/toscalib/elements/relationshiptype.py', 'translator/toscalib/nodetemplate.py', 'translator/toscalib/tests/test_toscatpl.py', 'translator/toscalib/tosca_template.py']",4,971ae06203a95781af69c1e6a8fb117b0a32450a,bp/tosca-requirement-update,"from translator.toscalib.relationship_template import RelationshipTemplate self.relationship_templates = self._relationship_templates() tpl = NodeTemplate(name, tpls, custom_types, self.relationship_templates) def _relationship_templates(self): custom_types = {} imports = self._tpl_imports() if imports: for definition in imports: if os.path.isabs(definition): def_file = definition else: tpl_dir = os.path.dirname(os.path.abspath(self.path)) def_file = os.path.join(tpl_dir, definition) custom_type = YAML_LOADER(def_file) rel_types = custom_type.get('relationship_types') or {} for name in rel_types: defintion = rel_types[name] custom_types[name] = defintion rel_templates = [] tpls = self._tpl_relationship_templates() for name in tpls: tpl = RelationshipTemplate(tpls[name], name, custom_types) rel_templates.append(tpl) return rel_templates def _tpl_relationship_templates(self): return self.tpl.get(RELATIONSHIP_TEMPLATES) or {} "," tpl = NodeTemplate(name, tpls, custom_types)",200,12
openstack%2Frally~master~I7c5e312801db886483b0ff5c45a80cba6848c95e,openstack/rally,master,I7c5e312801db886483b0ff5c45a80cba6848c95e,Adding iteritems validation,MERGED,2014-12-17 13:30:48.000000000,2014-12-19 19:36:02.000000000,2014-12-19 19:36:01.000000000,"[{'_account_id': 3}, {'_account_id': 7369}, {'_account_id': 8367}, {'_account_id': 8507}, {'_account_id': 9545}, {'_account_id': 10475}, {'_account_id': 12395}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-17 13:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d3c8bf1c538a4e37270390109636871889e4cca5', 'message': ""Adding iteritems vallidation\n\nSince in Python 3 there's no longer dict.iteritems()\nand to keep the compatibility with Python 2, instead of call\ndict.iteritems(), we must call six.iteritems(dict).\nThis patch is to avoid broken this compatibility in the future\nadding a validation for iteritems.\n\nChange-Id: I7c5e312801db886483b0ff5c45a80cba6848c95e\n""}, {'number': 2, 'created': '2014-12-17 14:23:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a8b921f04cbda5d549e32fbc1f1b1d2b85c4326b', 'message': ""Adding iteritems vallidation\n\nSince in Python 3 there's no longer dict.iteritems()\nand to keep the compatibility with Python 2, instead of call\ndict.iteritems(), we must call six.iteritems(dict).\nThis patch is to avoid broken this compatibility in the future\nadding a validation for iteritems.\n\nChange-Id: I7c5e312801db886483b0ff5c45a80cba6848c95e\n""}, {'number': 3, 'created': '2014-12-17 14:24:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3c256f5eed7a96ca12f291062af17739d7daf5ce', 'message': ""Adding iteritems vallidation\n\nSince in Python 3 there's no longer dict.iteritems()\nand to keep the compatibility with Python 2, instead of call\ndict.iteritems(), we must call six.iteritems(dict).\nThis patch is to avoid broken this compatibility in the future\nadding a validation for iteritems.\n\nChange-Id: I7c5e312801db886483b0ff5c45a80cba6848c95e\n""}, {'number': 4, 'created': '2014-12-17 14:37:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/15bf87dab1c78c310b91a7a9e2f3ce233c600fa4', 'message': ""Adding iteritems vallidation\n\nSince in Python 3 there's no longer dict.iteritems()\nand to keep the compatibility with Python 2, instead of call\ndict.iteritems(), we must call six.iteritems(dict).\nThis patch is to avoid broken this compatibility in the future\nadding a validation for iteritems.\n\nChange-Id: I7c5e312801db886483b0ff5c45a80cba6848c95e\n""}, {'number': 5, 'created': '2014-12-17 14:39:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b820f8351c0fb572a8ba2da6eaf6fe776c8bcdee', 'message': ""Adding iteritems vallidation\n\nSince in Python 3 there's no longer dict.iteritems()\nand to keep the compatibility with Python 2, instead of call\ndict.iteritems(), we must call six.iteritems(dict).\nThis patch is to avoid broken this compatibility in the future\nadding a validation for iteritems.\n\nChange-Id: I7c5e312801db886483b0ff5c45a80cba6848c95e\n""}, {'number': 6, 'created': '2014-12-17 14:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6cf3a8efab2d6a9ada5fc91e774cdf5b9c7599a5', 'message': ""Adding iteritems vallidation\n\nSince in Python 3 there's no longer dict.iteritems()\nand to keep the compatibility with Python 2, instead of call\ndict.iteritems(), we must call six.iteritems(dict).\nThis patch is to avoid broken this compatibility in the future\nadding a validation for iteritems.\n\nChange-Id: I7c5e312801db886483b0ff5c45a80cba6848c95e\n""}, {'number': 7, 'created': '2014-12-17 15:50:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3f4ac9cc362b3558555226e2e02c489296558d27', 'message': ""Adding iteritems vallidation\n\nSince in Python 3 there's no longer dict.iteritems()\nand to keep the compatibility with Python 2, instead of call\ndict.iteritems(), we must call six.iteritems(dict).\nThis patch is to avoid broken this compatibility in the future\nadding a validation for iteritems.\n\nChange-Id: I7c5e312801db886483b0ff5c45a80cba6848c95e\n""}, {'number': 8, 'created': '2014-12-19 15:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4d86dcff6d7b32e3e85bb85d527e336aa3e96bc5', 'message': ""Adding iteritems vallidation\n\nSince in Python 3 there's no longer dict.iteritems()\nand to keep the compatibility with Python 2, instead of call\ndict.iteritems(), we must call six.iteritems(dict).\nThis patch is to avoid broken this compatibility in the future\nadding a validation for iteritems.\n\nChange-Id: I7c5e312801db886483b0ff5c45a80cba6848c95e\n""}, {'number': 9, 'created': '2014-12-19 15:47:10.000000000', 'files': ['tests/hacking/checks.py', 'rally/benchmark/context/network.py', 'tests/unit/test_hacking.py', 'tests/hacking/README.rst'], 'web_link': 'https://opendev.org/openstack/rally/commit/f5d43e6eea0bcd377b6dba2b402db036903dff54', 'message': ""Adding iteritems validation\n\nSince in Python 3 there's no longer dict.iteritems()\nand to keep the compatibility with Python 2, instead of call\ndict.iteritems(), we must call six.iteritems(dict).\nThis patch is to avoid broken this compatibility in the future\nadding a validation for iteritems.\n\nChange-Id: I7c5e312801db886483b0ff5c45a80cba6848c95e\n""}]",8,142441,f5d43e6eea0bcd377b6dba2b402db036903dff54,39,8,9,8367,,,0,"Adding iteritems validation

Since in Python 3 there's no longer dict.iteritems()
and to keep the compatibility with Python 2, instead of call
dict.iteritems(), we must call six.iteritems(dict).
This patch is to avoid broken this compatibility in the future
adding a validation for iteritems.

Change-Id: I7c5e312801db886483b0ff5c45a80cba6848c95e
",git fetch https://review.opendev.org/openstack/rally refs/changes/41/142441/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/hacking/checks.py'],1,d3c8bf1c538a4e37270390109636871889e4cca5,iteritems,"re_iteritems_method = re.compile(r""\.iteritems\(\)"")def check_iteritems_method(logical_line): """"""Check if iteritems is properly called for compatibility with Python 3 The correct form is six.iteritems(dict) instead of dict.iteritems() N325 """""" res = re_iteritems_method.search(logical_line) if res: yield (0, ""N325: Use six.iteritems(dict) rather than "" ""dict.iteritems() to iterate a collection."") register(check_iteritems_method)",,15,0
openstack%2Fneutron-specs~master~Ic59c0cac849d0676797bd581b859bfef06a7b792,openstack/neutron-specs,master,Ic59c0cac849d0676797bd581b859bfef06a7b792,Specification for reference IPAM driver,MERGED,2014-12-03 17:53:56.000000000,2014-12-19 19:35:54.000000000,2014-12-19 19:35:54.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 6524}, {'_account_id': 7448}, {'_account_id': 8976}]","[{'number': 1, 'created': '2014-12-03 17:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3849849e1eb9a5c84e96ad821478833fff0b3566', 'message': ""Specification for reference IPAM driver\n\nThis specification proposes an IPAM driver which will\nimplement the same functionality as the logic currently\ncontained in the neutron's base DB class.\n\nPlease note that this document is not yet complete.\n\nChange-Id: Ic59c0cac849d0676797bd581b859bfef06a7b792\n""}, {'number': 2, 'created': '2014-12-11 00:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/7c29f48f429137801ca7b11730e66adf9338d75f', 'message': ""Specification for reference IPAM driver\n\nThis specification proposes an IPAM driver which will\nimplement the same functionality as the logic currently\ncontained in the neutron's base DB class.\n\nPlease note that this document is not yet complete.\n\nChange-Id: Ic59c0cac849d0676797bd581b859bfef06a7b792\n""}, {'number': 3, 'created': '2014-12-19 00:50:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/037d99c63ac62fe476d83b20e2d079bd2af2d82b', 'message': ""Specification for reference IPAM driver\n\nThis specification proposes an IPAM driver which will\nimplement the same functionality as the logic currently\ncontained in the neutron's base DB class.\n\nPlease note that this document is not yet complete.\n\nChange-Id: Ic59c0cac849d0676797bd581b859bfef06a7b792\n""}, {'number': 4, 'created': '2014-12-19 06:11:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3c420d9681ae49e1504f7d5a4d84f55d5ff480b0', 'message': ""Specification for reference IPAM driver\n\nThis specification proposes an IPAM driver which will\nimplement the same functionality as the logic currently\ncontained in the neutron's base DB class.\n\nPlease note that this document is not yet complete.\n\nChange-Id: Ic59c0cac849d0676797bd581b859bfef06a7b792\n""}, {'number': 5, 'created': '2014-12-19 07:42:00.000000000', 'files': ['specs/kilo/reference-ipam-driver.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/f777a46f1831afb77ce250221ee7486783495892', 'message': ""Specification for reference IPAM driver\n\nThis specification proposes an IPAM driver which will\nimplement the same functionality as the logic currently\ncontained in the neutron's base DB class.\n\nPlease note that this document is not yet complete.\n\nChange-Id: Ic59c0cac849d0676797bd581b859bfef06a7b792\n""}]",32,138803,f777a46f1831afb77ce250221ee7486783495892,21,9,5,261,,,0,"Specification for reference IPAM driver

This specification proposes an IPAM driver which will
implement the same functionality as the logic currently
contained in the neutron's base DB class.

Please note that this document is not yet complete.

Change-Id: Ic59c0cac849d0676797bd581b859bfef06a7b792
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/03/138803/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/reference-ipam-driver.rst'],1,3849849e1eb9a5c84e96ad821478833fff0b3566,reference-ipam-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Reference IPAM driver ========================================== https://blueprints.launchpad.net/neutron/+spec/reference-ipam-driver This specification proposes moving Neutron's IPAM code, currently baked in the database logic, into an appropriate driver which will be called by Neutron through the interface being defined in [1]_. Decoupling IPAM logic from the Neutron management layer has been on the list of ""debt repayment"" tasks for a long time. It is also a necessary step towards the implementation of a pluggable IPAM framework, which has been sanctioned as one of the priorities for the Kilo release cycle [2]_ The following specification provides both a long-term picture for the evolution of the proposed reference IPAM driver and a short-term detailed description of the changes proposed as part of this blueprint. The discussion on the long-term evolution is in the section titled ""The Big Picture""; readers concerned exclusively with changes that will be performed as a part of this specification can safely skip this section. Problem Description =================== Neutron's IPAM logic is baked into the ""base"" DB class [3]_. This has serious manageability shortcomings, and is also incompatible with the activity promoted by [1]_. The latter point makes it pretty much compulsory to transform this IPAM logic into a driver which gets called through the IPAM interface. Also, this IPAM logic is currently the first source of ""lock wait timeout"" issues in neutron DB because of deeply nested (and long) transactions. Proposed Change =============== This specification is complementary to other specifications proposed for the Kilo release cycle [1]_, [4]_. Putting all together the result would be the ability of making IPAM ""pluggable"", meaning that deployers will be able to pick the solution that best suits them to perform IP address management. On the other hand, the current logic, used in many production deployments, will become an IPAM driver as well. More precisely this would be IPAM driver that would be used in upstream gate tests. For this reason we will refer to this IPAM driver, which is the subject of this document, as the ""reference"" driver, without hopefully abusing this term. At the end of the Kilo release cycle Neutron will have a driver which does IP address management exactly in the same way as Neutron does today. As a part of this blueprint we will also try and fix some of its well known shortcomings, leveraging community contributions already available for review where possible. TODO: provide extensive details about how the routines in the db plugin class will be split and moved into the driver Providing the appropriate level of detail is going to be impossible if we do not know the exact shape of the interface... if that's a requirement this specification should just be postponed The Big Picture --------------- This specification so far discussed how the driver will look in Kilo. From an architectural perspective it will simply be a class which is loaded at starup, and where IPAM calls are dispatched. This still does not address two important aspectcs of IPAM in Neutron: * independence from the core plugin * coordination among multiple servers (or even workers) In Kilo indeed the calls to the IPAM interface will still be in the base DB class, which is also the base class for the great majority of Neutron plugins. This means that the reference IPAM driver will actually be called by the plugin, and not by the neutron management layer. This applies to any other IPAM driver as well. This is an architectural flow, even if not a major one, as it means that: * The ability of running a specific IPAM driver depends on the core_plugin currently configured. * IPAM interface hooks might need to be explicitly added to plugin modules. Indeed with the current codebase, we'll need to insert calls to the IPAM interface at least in the base DB class and in the ML2 plugin class [5]_. * As a plugin will still be free to choose how to use the IPAM interface, the interactions defined in [1]_ are therefore plugin-specific. This could lead to unexpected behaviours when running specific combinations of plugins and IPAM driver. Therefore IPAM driver calls should be performed by the management layer, and the result of IPAM operation should then be sent to the plugin layer. This however will require extensive changes in the plugin interface, and is out of scope for this release cycle. Ideally this would fit very well in a world where a ""v3"" plugin interface is defined which allows to have distinct, namespaced interfaces for operating on different resource. When multiple servers or workers (or both) are deployed there will also be several instances of the reference IPAM driver. With the current implementation this leads to well known race conditions such as [7]_. The first iteration of the IPAM reference driver will likely suffer of the same issues. In subsequent iteration the community might evaluate scalable and reliable solution which might include either distributed coordination among driver instances or a ""conductor-style"" implementatin where drivers forward operations to a centeralized IPAM service. Data Model Impact ----------------- TODO: This is going to be a long one.... Bear with me. REST API Impact --------------- The proposed change won't alter a bit the syntax and semantics of the Neutron API. Any API change behaviour resulting from this implementation will be an unintentional side effect and should therefore be treated as a high priority bug. Security Impact --------------- We do not expect the reference IPAM driver to be less secure than the current logic, since most of code will remain unchanged in the driver. Notifications Impact -------------------- None. Other End User Impact --------------------- None. Performance Impact ------------------ The reference driver will contain logic for preventing lock timeout and reducing the scope of locking queries. This might result in a performance improvement under heavy load, but we expect this improvement to not be relevant. The changes in logic from the 'baked IPAM' are aimed mostly towards reliability. IPv6 Impact ----------- No change expected in IPv6-related IPAM features such as SLAAC. Any change deriving from the implementation of this spec is an unintentional side effect and should be treated as a high priority bug. Other Deployer Impact --------------------- The reference driver will be the default value for the IPAM driver. In order to avoid potential mayhem is a deployer is running multiple servers, the same IPAM driver should be used on every server. Developer Impact ---------------- None Community Impact ---------------- This will be good for the community as it will provide a single place in the neutron code tree where IPAM SMEs can contribute. Note: so far this work is targeting the neutron code tree, but in the future the IPAM reference driver might be moved outside in line with what's being prpoposed for the plugin/driver split blueprint [6]_ Alternatives ------------ Under the hypothesis that there will be a pluggable IPAM interface there is really no alternative. Unless wrapping every IPAM interface call with a logic like the following might be considered an alternative: :: if cfg.CONF.use_pluggable_ipam: self.ipam_driver.do_this(subnet_id, ...) else: <previous logic in db base class> The author of this documentation has high hopes that nobody will consider the snippet above a viable alternative. Even if it can be a short-time measure to allow for independently develop the pluggable interface, it's something that should be avoided if possible. Implementation ============== The minimum goal for Kilo is to have a driver which manages IPs in the same way as the ""baked"" logic does today. Assignee(s) ----------- Primary assignee: salv-orlando Work Items ---------- * Implement the driver * Write unit tests and functional tests for it * Combine with pluggable interface, face the gate * According to the strategy chosen in syncing up with effort [1]_, theree might be vestigial code to remove Dependencies ============ * Pluggable IPAM interface [1]_ * Introduction of Subnet Pool concept. This is part of [4]_ Testing ======= Testing is going to be tricky because the driver can't be fully tested until the pluggable interface is in place. On the other hand for introducing the pluggable interface one needs a driver in place. In order to break this deadlock one possibility is to introduce the driver, but limit only to unit and functional testing until the IPAM interface is in place. The following sections will define strategies for both the cases in which the driver is merged with the pluggable IPAM interface in place and the case in which the driver is merged withoutit. Tempest Tests ------------- Currently defined scenario tests provide enough coverage for the reference driver, since it's going to be functionally equivalent to what the current ""baked in"" code does today. Obviously coverage by tempest scenario tests will be possible only when the pluggable IPAM interface will be in place and dispatching calls to the reference IPAM driver. Functional Tests ---------------- Functional testing in the classical neutron sense won't be possible until the pluggable IPAM interface merges. However, functional tests intended as exercising the driver trough its interface should always be possible. On the other hand, if the IPAM pluggable interface is already in place, this will allow us to perform functional testing by exercising the neutron API thus leveraging the current framework. API Tests --------- As there will be no API change, no changes to API tests will be needed. Documentation Impact ==================== User Documentation ------------------ No change. Developer Documentation ----------------------- The reference IPAM driver should come with appropriate developer documentation References ========== .. [1] meh .. [2] meh meh .. [3] meh meh meh .. [4] meh meh meh meh .. [5] meh meh meh meh meh .. [6] meh meh meh meh meh meh .. [7] meh meh meh meh meh meh meh ",,296,0
openstack%2Fproject-config~master~I0ac6ee99391f218fa467b58bf39934c6c68d1808,openstack/project-config,master,I0ac6ee99391f218fa467b58bf39934c6c68d1808,Extend ACL checks to OpenStack namespace.,MERGED,2014-12-16 21:43:52.000000000,2014-12-19 19:29:40.000000000,2014-12-19 19:29:39.000000000,"[{'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-12-16 21:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a36a7fb641c195598bd09e255ac64441ec2ee198', 'message': 'Extend ACL checks to OpenStack namespace.\n\nChange-Id: I0ac6ee99391f218fa467b58bf39934c6c68d1808\n'}, {'number': 2, 'created': '2014-12-16 23:22:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/cda4507a35904c9bc55a732407716f7c75617dfa', 'message': 'Extend ACL checks to OpenStack namespace.\n\nChange-Id: I0ac6ee99391f218fa467b58bf39934c6c68d1808\n'}, {'number': 3, 'created': '2014-12-17 22:04:22.000000000', 'files': ['tools/check_valid_gerrit_config.sh', 'tools/normalize_acl.py'], 'web_link': 'https://opendev.org/openstack/project-config/commit/af09d7ca4be1e2dda65fb8aea7ee2ea19135214b', 'message': 'Extend ACL checks to OpenStack namespace.\n\nChange-Id: I0ac6ee99391f218fa467b58bf39934c6c68d1808\n'}]",0,142230,af09d7ca4be1e2dda65fb8aea7ee2ea19135214b,16,5,3,748,,,0,"Extend ACL checks to OpenStack namespace.

Change-Id: I0ac6ee99391f218fa467b58bf39934c6c68d1808
",git fetch https://review.opendev.org/openstack/project-config refs/changes/30/142230/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/check_valid_gerrit_config.sh', 'tools/normalize_acl.py']",2,a36a7fb641c195598bd09e255ac64441ec2ee198,extend-acl-check," special_teams = ( ""admins"", ""committee"", ""core"", ""maint"", ""Managers"", ""milestone"", ""Users"", )"," special_teams = (""core"", ""milestone"", ""Users"", ""admins"")",10,2
openstack%2Fneutron~master~I74c4c6aadb5b663892fda3740babaf5490d6ea19,openstack/neutron,master,I74c4c6aadb5b663892fda3740babaf5490d6ea19,Fix VPN Service for Distributed Routers,ABANDONED,2014-10-09 04:55:51.000000000,2014-12-19 19:27:22.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 7016}, {'_account_id': 7448}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10354}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 13051}]","[{'number': 1, 'created': '2014-10-09 04:55:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6c4d448ed86d1769408a7daea7990454c2b4a426', 'message': 'Fix VPN Service for Distributed Routers\n\nWith the new distributed routers in\nneutron the reference implementation for\nVPN Service was not fully functional\nbecause of the way namespaces were\nhandled in DVR Service Node.\n\nThis patch fixes the issue and installs\nthe IPsec VPN Service on the SNAT namespace\nin the service node as compared to the\nRouter namespace in legacy network nodes.\n\nChange-Id: I74c4c6aadb5b663892fda3740babaf5490d6ea19\nCloses-Bug: #1356467\n'}, {'number': 2, 'created': '2014-11-26 20:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4f507b8812b6f515d7464186e326a5ac20f35fc0', 'message': 'Fix VPN Service for Distributed Routers\n\nWith the new distributed routers in\nneutron the reference implementation for\nVPN Service was not fully functional\nbecause of the way namespaces were\nhandled in DVR Service Node.\n\nThis patch fixes the issue and installs\nthe IPsec VPN Service on the SNAT namespace\nin the service node as compared to the\nRouter namespace in legacy network nodes.\n\nChange-Id: I74c4c6aadb5b663892fda3740babaf5490d6ea19\nCloses-Bug: #1356467\n'}, {'number': 3, 'created': '2014-12-02 01:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f94e0ab0bf8e9792f78c5d630f1df592f37f6ae2', 'message': 'Fix VPN Service for Distributed Routers\n\nWith the new distributed routers in\nneutron the reference implementation for\nVPN Service was not fully functional\nbecause of the way namespaces were\nhandled in DVR Service Node.\n\nThis patch fixes the issue and installs\nthe IPsec VPN Service on the SNAT namespace\nin the service node as compared to the\nRouter namespace in legacy network nodes.\n\nChange-Id: I74c4c6aadb5b663892fda3740babaf5490d6ea19\nCloses-Bug: #1356467\n'}, {'number': 4, 'created': '2014-12-02 20:22:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/32d27c5de46b0fe1649af0de2bd4a07e6f0ac24a', 'message': 'Fix VPN Service for Distributed Routers\n\nWith the new distributed routers in\nneutron the reference implementation for\nVPN Service was not fully functional\nbecause of the way namespaces were\nhandled in DVR Service Node.\n\nThis patch fixes the issue and installs\nthe IPsec VPN Service on the SNAT namespace\nin the service node as compared to the\nRouter namespace in legacy network nodes.\n\nChange-Id: I74c4c6aadb5b663892fda3740babaf5490d6ea19\nCloses-Bug: #1356467\n'}, {'number': 5, 'created': '2014-12-02 21:59:22.000000000', 'files': ['neutron/db/vpn/vpn_db.py', 'neutron/services/vpn/agent.py', 'neutron/tests/unit/services/vpn/test_vpn_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/467c49f739051731432c7f8d23df092d1441f778', 'message': 'Fix VPN Service for Distributed Routers\n\nWith the new distributed routers in\nneutron the reference implementation for\nVPN Service was not fully functional\nbecause of the way namespaces were\nhandled in DVR Service Node.\n\nThis patch fixes the issue and installs\nthe IPsec VPN Service on the SNAT namespace\nin the service node as compared to the\nRouter namespace in legacy network nodes.\n\nChange-Id: I74c4c6aadb5b663892fda3740babaf5490d6ea19\nCloses-Bug: #1356467\n'}]",18,127133,467c49f739051731432c7f8d23df092d1441f778,123,28,5,7016,,,0,"Fix VPN Service for Distributed Routers

With the new distributed routers in
neutron the reference implementation for
VPN Service was not fully functional
because of the way namespaces were
handled in DVR Service Node.

This patch fixes the issue and installs
the IPsec VPN Service on the SNAT namespace
in the service node as compared to the
Router namespace in legacy network nodes.

Change-Id: I74c4c6aadb5b663892fda3740babaf5490d6ea19
Closes-Bug: #1356467
",git fetch https://review.opendev.org/openstack/neutron refs/changes/33/127133/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/vpn/device_drivers/ipsec.py', 'neutron/db/vpn/vpn_db.py', 'neutron/services/vpn/agent.py']",3,6c4d448ed86d1769408a7daea7990454c2b4a426,bug/1356467,"from neutron.openstack.common import log as logging LOG = logging.getLogger(__name__) # Added for handling the distributed Routers within SNAT namespace if router_info.router['distributed']: return self.get_snat_ns_name(router_id) else: return router_info.ns_name # Added for handling the distributed Routers within SNAT namespace if router_info.router['distributed']: router_info.snat_iptables_manager.ipv4['nat'].add_rule( chain, rule, top=top) else: router_info.iptables_manager.ipv4['nat'].add_rule( chain, rule, top=top) # Added for handling the distributed Routers within SNAT namespace if router_info.router['distributed']: router_info.snat_iptables_manager.ipv4['nat'].remove_rule( chain, rule, top=top) else: router_info.iptables_manager.ipv4['nat'].remove_rule( chain, rule, top=top) # Added for handling the distributed Routers within SNAT namespace if router_info.router['distributed']: router_info.snat_iptables_manager.apply() else: router_info.iptables_manager.apply()"," return router_info.ns_name router_info.iptables_manager.ipv4['nat'].add_rule( chain, rule, top=top) router_info.iptables_manager.ipv4['nat'].remove_rule( chain, rule, top=top) router_info.iptables_manager.apply()",38,8
openstack%2Fdevstack-vagrant~master~Id499ee890c43aa2a1682e447227e50d9bd12872c,openstack/devstack-vagrant,master,Id499ee890c43aa2a1682e447227e50d9bd12872c,Add support for swift,ABANDONED,2014-09-20 11:14:38.000000000,2014-12-19 19:24:25.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-09-20 11:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-vagrant/commit/428352de6f7c05a7b16c3dbb93a8e04232ca4859', 'message': 'Add support for swift\n\nChange-Id: Id499ee890c43aa2a1682e447227e50d9bd12872c\n'}, {'number': 2, 'created': '2014-09-29 21:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-vagrant/commit/a14770f1a62c0b2cd4e81cc8e9f97d7e67da825b', 'message': 'Add support for swift\n\nChange-Id: Id499ee890c43aa2a1682e447227e50d9bd12872c\n'}, {'number': 3, 'created': '2014-09-29 21:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-vagrant/commit/e7c565f81e5a7547af7c98ddd1975f38cca0bcca', 'message': 'Add support for swift\n\nChange-Id: Id499ee890c43aa2a1682e447227e50d9bd12872c\n'}, {'number': 4, 'created': '2014-09-29 21:16:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-vagrant/commit/e9624104192fc387d8e83723c79fc6503908c6a0', 'message': 'Add support for swift\n\nChange-Id: Id499ee890c43aa2a1682e447227e50d9bd12872c\n'}, {'number': 5, 'created': '2014-11-04 08:02:57.000000000', 'files': ['Vagrantfile', 'puppet/modules/devstack/templates/local.erb', 'config.yaml.sample'], 'web_link': 'https://opendev.org/openstack/devstack-vagrant/commit/8956019e5a1800e98baefa19f946d48be56f0e0c', 'message': 'Add support for swift\n\nChange-Id: Id499ee890c43aa2a1682e447227e50d9bd12872c\n'}]",0,122940,8956019e5a1800e98baefa19f946d48be56f0e0c,15,2,5,167,,,0,"Add support for swift

Change-Id: Id499ee890c43aa2a1682e447227e50d9bd12872c
",git fetch https://review.opendev.org/openstack/devstack-vagrant refs/changes/40/122940/5 && git format-patch -1 --stdout FETCH_HEAD,"['Vagrantfile', 'puppet/modules/devstack/templates/local.erb', 'config.yaml.sample']",3,428352de6f7c05a7b16c3dbb93a8e04232ca4859,use_swift,# Uncomment below to setup swift on the management node. This will # also enable the backup service of cinder. #use_swift: true ,,15,0
openstack%2Fdevstack-vagrant~master~Ie478454e1f05693c24a6078f9ec490189c8ae0c6,openstack/devstack-vagrant,master,Ie478454e1f05693c24a6078f9ec490189c8ae0c6,"Make machine resources (CPUs, memory) configurable",ABANDONED,2014-08-07 11:09:25.000000000,2014-12-19 19:24:18.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-08-07 11:09:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-vagrant/commit/db48bf0e711dd81a5def5dcaa173cc07afd9bc78', 'message': 'Make machine resources (CPUs, memory) configurable\n\nChange-Id: Ie478454e1f05693c24a6078f9ec490189c8ae0c6\n'}, {'number': 2, 'created': '2014-09-19 19:51:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-vagrant/commit/6203aa9d9422c7309f76f0fb55e2e94bf7a46711', 'message': 'Make machine resources (CPUs, memory) configurable\n\nChange-Id: Ie478454e1f05693c24a6078f9ec490189c8ae0c6\n'}, {'number': 3, 'created': '2014-09-29 21:13:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-vagrant/commit/6b9185337ba2d88ad4a2f851d61d81544685fa62', 'message': 'Make machine resources (CPUs, memory) configurable\n\nChange-Id: Ie478454e1f05693c24a6078f9ec490189c8ae0c6\n'}, {'number': 4, 'created': '2014-09-30 14:20:10.000000000', 'files': ['Vagrantfile', 'config.yaml.sample'], 'web_link': 'https://opendev.org/openstack/devstack-vagrant/commit/ab04c76350a8823b6f7de870a098f722ab108a4d', 'message': 'Make machine resources (CPUs, memory) configurable\n\nChange-Id: Ie478454e1f05693c24a6078f9ec490189c8ae0c6\n'}]",0,112555,ab04c76350a8823b6f7de870a098f722ab108a4d,17,3,4,167,,,0,"Make machine resources (CPUs, memory) configurable

Change-Id: Ie478454e1f05693c24a6078f9ec490189c8ae0c6
",git fetch https://review.opendev.org/openstack/devstack-vagrant refs/changes/55/112555/3 && git format-patch -1 --stdout FETCH_HEAD,"['Vagrantfile', 'config.yaml.sample']",2,db48bf0e711dd81a5def5dcaa173cc07afd9bc78,conf_machine_details,# Set resources used by the manager and compute machine. # The default resources are 8192 MByte memory and 4 CPUs. # memory_manager: 8192 # cpus_manager: 4 # memory_compute: 8192 # cpus_compute: 4 ,,9,0
openstack%2Fmonasca-api~master~I7585f60393d3d2733bfcacc4b36fd4bb481ca096,openstack/monasca-api,master,I7585f60393d3d2733bfcacc4b36fd4bb481ca096,Removed HealthCheck from MonascaAPI,MERGED,2014-12-17 20:24:22.000000000,2014-12-19 19:20:49.000000000,2014-12-19 19:20:48.000000000,"[{'_account_id': 3}, {'_account_id': 10046}, {'_account_id': 10068}, {'_account_id': 11809}, {'_account_id': 14375}]","[{'number': 1, 'created': '2014-12-17 20:24:22.000000000', 'files': ['src/main/java/monasca/api/MonApiApplication.java'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/df7cb6e9ca9484ca2665b058b4887bebc5ddf88c', 'message': 'Removed HealthCheck from MonascaAPI\n\nChange-Id: I7585f60393d3d2733bfcacc4b36fd4bb481ca096\n'}]",2,142570,df7cb6e9ca9484ca2665b058b4887bebc5ddf88c,9,5,1,14375,,,0,"Removed HealthCheck from MonascaAPI

Change-Id: I7585f60393d3d2733bfcacc4b36fd4bb481ca096
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/70/142570/1 && git format-patch -1 --stdout FETCH_HEAD,['src/main/java/monasca/api/MonApiApplication.java'],1,df7cb6e9ca9484ca2665b058b4887bebc5ddf88c,, ,"import monasca.common.messaging.kafka.KafkaHealthCheck; /** Configure health checks */ environment.healthChecks().register(""kafka"", new KafkaHealthCheck(config.kafka)); ",1,4
openstack%2Fdevstack~master~I3c97a4d7810870c9ac058350b362930ce2af713b,openstack/devstack,master,I3c97a4d7810870c9ac058350b362930ce2af713b,"Revert ""Revert ""Revert ""Pin version of setuptools""""""",MERGED,2014-12-18 23:15:40.000000000,2014-12-19 19:04:16.000000000,2014-12-19 19:04:15.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 5196}, {'_account_id': 5263}, {'_account_id': 6816}, {'_account_id': 7687}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-18 23:15:40.000000000', 'files': ['tools/install_pip.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/9d0d3fb46824d3f9056acf18ad218b22b31b64af', 'message': 'Revert ""Revert ""Revert ""Pin version of setuptools""""""\n\nThis reverts commit 2191f838a718049b3ba3be42f3aef8a970ff4278.\n\nApprove once Setuptools 8 is silencing runtime warnings by default,\ne.g. via https://github.com/jaraco/setuptools/pull/23 or a similar\npatch.\n\nChange-Id: I3c97a4d7810870c9ac058350b362930ce2af713b\n'}]",0,142928,9d0d3fb46824d3f9056acf18ad218b22b31b64af,18,7,1,5263,,,0,"Revert ""Revert ""Revert ""Pin version of setuptools""""""

This reverts commit 2191f838a718049b3ba3be42f3aef8a970ff4278.

Approve once Setuptools 8 is silencing runtime warnings by default,
e.g. via https://github.com/jaraco/setuptools/pull/23 or a similar
patch.

Change-Id: I3c97a4d7810870c9ac058350b362930ce2af713b
",git fetch https://review.opendev.org/openstack/devstack refs/changes/28/142928/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/install_pip.sh'],1,9d0d3fb46824d3f9056acf18ad218b22b31b64af,setuptools-8,pip_install -U setuptools,"pip_install -U ""setuptools<8.0""",1,1
openstack%2Fsolum~master~If2873baacbfa55a79c7d647af0326e762231ef13,openstack/solum,master,If2873baacbfa55a79c7d647af0326e762231ef13,Report unittest status from worker shell handler,MERGED,2014-12-17 23:26:05.000000000,2014-12-19 18:33:36.000000000,2014-12-19 18:33:35.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 6662}, {'_account_id': 7784}, {'_account_id': 9095}]","[{'number': 1, 'created': '2014-12-17 23:26:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/364d72164b7ab32dc06052e71e2a5e0e4a946ec7', 'message': ""Report repo status from shell worker handler\n\n1. Added calls to send repo status from shell worker handler;\n2. Send out 'pending' repo status from API, rather than worker;\n3. Change assembly status to 'QUEUED' right after it gets created.\n\nChange-Id: If2873baacbfa55a79c7d647af0326e762231ef13\nCloses-bug: #1401689\n""}, {'number': 2, 'created': '2014-12-18 17:33:13.000000000', 'files': ['functionaltests/api/v1/test_assembly.py', 'solum/worker/handlers/shell.py', 'solum/tests/worker/handlers/test_shell_nobuild.py', 'solum/worker/handlers/shell_nobuild.py', 'solum/objects/assembly.py', 'solum/api/handlers/assembly_handler.py', 'solum/tests/api/handlers/test_assembly.py', 'solum/common/repo_utils.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/bd563bcdd64a070eb65f6fb2ea9e71ca35fc35b2', 'message': ""Report unittest status from worker shell handler\n\n1. Send unittest status from worker shell handler;\n2. Send unittest 'pending' status from API, rather than worker;\n3. Change assembly status to 'QUEUED' right after it gets created.\n\nChange-Id: If2873baacbfa55a79c7d647af0326e762231ef13\nCloses-bug: #1401689\n""}]",2,142612,bd563bcdd64a070eb65f6fb2ea9e71ca35fc35b2,12,5,2,6662,,,0,"Report unittest status from worker shell handler

1. Send unittest status from worker shell handler;
2. Send unittest 'pending' status from API, rather than worker;
3. Change assembly status to 'QUEUED' right after it gets created.

Change-Id: If2873baacbfa55a79c7d647af0326e762231ef13
Closes-bug: #1401689
",git fetch https://review.opendev.org/openstack/solum refs/changes/12/142612/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/worker/handlers/shell.py', 'solum/tests/worker/handlers/test_shell_nobuild.py', 'solum/worker/handlers/shell_nobuild.py', 'solum/objects/assembly.py', 'solum/api/handlers/assembly_handler.py', 'solum/tests/api/handlers/test_assembly.py', 'solum/common/repo_utils.py']",7,364d72164b7ab32dc06052e71e2a5e0e4a946ec7,bug/1401689,"# Copyright 2014 - Rackspace Hosting # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import json import httplib2 from oslo.config import cfg from solum.common import exception from solum.openstack.common import log as logging LOG = logging.getLogger(__name__) cfg.CONF.import_opt('log_url_prefix', 'solum.worker.config', group='worker') def send_status(test_result, status_url, repo_token, pending=False): if status_url and repo_token: commit_id = status_url.rstrip('/').split('/')[-1] log_url = cfg.CONF.worker.log_url_prefix + commit_id headers = {'Authorization': 'token ' + repo_token, 'Content-Type': 'application/json'} if pending: data = {'state': 'pending', 'description': 'Solum says: Testing in progress', 'target_url': log_url} elif test_result == 0: data = {'state': 'success', 'description': 'Solum says: Tests passed', 'target_url': log_url} else: data = {'state': 'failure', 'description': 'Solum says: Tests failed', 'target_url': log_url} try: http = httplib2.Http() resp, _ = http.request(status_url, 'POST', headers=headers, body=json.dumps(data)) if resp['status'] != '201': LOG.debug(""Failed to send back status. Error code %s,"" ""status_url %s, repo_token %s"" % (resp['status'], status_url, repo_token)) except httplib2.HttpLib2Error as ex: LOG.debug(""Error in sending status %s"" % ex) else: LOG.debug(""No url or token available to send back status"") def verify_artifact(artifact, collab_url): # TODO(james_li): verify if the artifact is the one that gets triggered if collab_url is None: return True repo_token = artifact.get('repo_token') if repo_token is None: return False headers = {'Authorization': 'token ' + repo_token} try: resp, _ = httplib2.Http().request(collab_url, headers=headers) if resp['status'] == '204': return True elif resp['status'] == '404': raise exception.RequestForbidden( reason=""User %s not allowed to do rebuild"" % collab_url.split('/')[-1]) except httplib2.HttpLib2Error as ex: LOG.info(""Error in verifying collaborator %s"" % ex) return False ",,97,77
openstack%2Fopenstack-ansible~master~Idd88575c1cffb07e31807b1123e888725f47a72c,openstack/openstack-ansible,master,Idd88575c1cffb07e31807b1123e888725f47a72c,Set the admin_token in keystone.conf to the correct value,MERGED,2014-12-19 13:24:12.000000000,2014-12-19 18:16:43.000000000,2014-12-19 18:16:43.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-19 13:24:12.000000000', 'files': ['rpc_deployment/inventory/group_vars/all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bed6bd74218b5c99fa28cd23f21319516730eeaa', 'message': 'Set the admin_token in keystone.conf to the correct value\n\nThis patch ensures that admin_token in keystone.conf is correctly set to\nthe user variable keystone_auth_admin_token.\n\nChange-Id: Idd88575c1cffb07e31807b1123e888725f47a72c\nCloses-Bug: #1404235\n'}]",0,143081,bed6bd74218b5c99fa28cd23f21319516730eeaa,11,5,1,6816,,,0,"Set the admin_token in keystone.conf to the correct value

This patch ensures that admin_token in keystone.conf is correctly set to
the user variable keystone_auth_admin_token.

Change-Id: Idd88575c1cffb07e31807b1123e888725f47a72c
Closes-Bug: #1404235
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/81/143081/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/inventory/group_vars/all.yml'],1,bed6bd74218b5c99fa28cd23f21319516730eeaa,bug/1404235,"auth_admin_token: ""{{ keystone_auth_admin_token }}""","auth_admin_token: ""{{ keystone_auth_admin_password }}""",1,1
openstack%2Fironic~master~I2d9e4f20419ca2789c2f60034c403d28a5e2b9e8,openstack/ironic,master,I2d9e4f20419ca2789c2f60034c403d28a5e2b9e8,Extend API multivalue fields,MERGED,2014-11-28 11:09:42.000000000,2014-12-19 18:06:54.000000000,2014-12-19 18:06:53.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 3099}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 7882}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 12081}, {'_account_id': 13362}]","[{'number': 1, 'created': '2014-11-28 11:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/39bd33c7bcb0d0c860ab41816474a06cfc74533b', 'message': 'Extend API multivalue fields\n\nExtend API multivalue fields to accept the default json decoding types.\n\nThis patch is creating a new ApiMultiType type that accepts: bytes,\nunicode, float, long, int, dict, list and bool primitive types.\n\nChange-Id: I2d9e4f20419ca2789c2f60034c403d28a5e2b9e8\n'}, {'number': 2, 'created': '2014-11-28 11:15:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e99770bb8af2a3e5f84f7616546216e4a5b46dd0', 'message': 'Extend API multivalue fields\n\nExtend API multivalue fields to accept the default json decoding types.\n\nThis patch is creating a new ApiMultiType type that accepts: bytes,\nunicode, float, long, int, dict, list and bool primitive types.\n\nChange-Id: I2d9e4f20419ca2789c2f60034c403d28a5e2b9e8\n'}, {'number': 3, 'created': '2014-11-28 14:16:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/099effcc98054734570a21b183f5e4dbc99a7698', 'message': 'Extend API multivalue fields\n\nExtend API multivalue fields to accept the default json decoding types.\n\nThis patch is creating a new ApiMultiType type that accepts: bytes,\nunicode, float, long, int, dict, list and bool primitive types.\n\nChange-Id: I2d9e4f20419ca2789c2f60034c403d28a5e2b9e8\n'}, {'number': 4, 'created': '2014-12-02 11:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3ad974983344c2bcfa529258e8cbd7d6a2b3f670', 'message': 'Extend API multivalue fields\n\nExtend API multivalue fields to accept the default json decoding types.\n\nThis patch is creating a new ApiMultiType type that accepts: bytes,\nunicode, float, long, int, dict, list and bool primitive types.\n\nChange-Id: I2d9e4f20419ca2789c2f60034c403d28a5e2b9e8\n'}, {'number': 5, 'created': '2014-12-02 11:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9c36d6f7d8fd6bf829a736e2224785e0fb0424db', 'message': 'Extend API multivalue fields\n\nExtend API multivalue fields to accept the default json decoding types.\n\nThis patch is creating a new ApiMultiType type that accepts: bytes,\nunicode, float, long, int, dict, list and bool primitive types.\n\nCloses-Bug: #1398350\nChange-Id: I2d9e4f20419ca2789c2f60034c403d28a5e2b9e8\n'}, {'number': 6, 'created': '2014-12-16 13:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3e022eb9cc523be0d9576c1b226c4651609ae288', 'message': 'Extend API multivalue fields\n\nExtend API multivalue fields to accept the default json decoding types.\n\nThis patch is creating a new ApiMultiType type that accepts: bytes,\nunicode, float, long, int, dict, list and bool primitive types.\n\nChange-Id: I2d9e4f20419ca2789c2f60034c403d28a5e2b9e8\n'}, {'number': 7, 'created': '2014-12-17 17:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b7e5475beba28cacf54d952ca76201a9244499ea', 'message': 'Extend API multivalue fields\n\nExtend API multivalue fields to accept the default json decoding types.\n\nThis patch is creating a new ApiMultiType type that accepts: bytes,\nunicode, float, long, int, dict, list and bool primitive types.\n\nChange-Id: I2d9e4f20419ca2789c2f60034c403d28a5e2b9e8\n'}, {'number': 8, 'created': '2014-12-17 17:06:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0d8e82bf2fd3b0c6ac95cf1e922ad9490b0ba309', 'message': 'Extend API multivalue fields\n\nExtend API multivalue fields to accept the default json decoding types.\n\nThis patch is creating a new ApiMultiType type that accepts: bytes,\nunicode, float, long, int, dict, list and bool primitive types.\n\nChange-Id: I2d9e4f20419ca2789c2f60034c403d28a5e2b9e8\n'}, {'number': 9, 'created': '2014-12-18 17:44:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/059fa0f0eb0cdc78679ecf7dfd43cf36cc16d6de', 'message': ""Extend API multivalue fields\n\nThis patch is creating a new JsonType type that accepts all the json\nprimitive types: bytes, unicode, float, long, int, dict, list and bool.\n\nSince the MultiType type is no longer used anywhere in the code it's\nbeen deleted.\n\nCloses-Bug: #1398350\nChange-Id: I2d9e4f20419ca2789c2f60034c403d28a5e2b9e8\n""}, {'number': 10, 'created': '2014-12-18 17:46:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/27540a501d0f034faf3be575e1346c9bf360d83b', 'message': ""Extend API multivalue fields\n\nThis patch is creating a new JsonType type that accepts all the json\nprimitive types: bytes, unicode, float, long, int, dict, list and bool.\n\nSince the MultiType type is no longer used anywhere in the code it's\nbeen deleted.\n\nCloses-Bug: #1398350\nChange-Id: I2d9e4f20419ca2789c2f60034c403d28a5e2b9e8\n""}, {'number': 11, 'created': '2014-12-19 14:20:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4774af61b6e7062cd1a059b5983493e9c42dcbf8', 'message': ""Extend API multivalue fields\n\nThis patch is creating a new JsonType type that accepts all the json\nprimitive types: bytes, unicode, float, long, int, dict, list, None\nand bool.\n\nSince the MultiType type is no longer used anywhere in the code it's\nbeen deleted.\n\nCloses-Bug: #1398350\nChange-Id: I2d9e4f20419ca2789c2f60034c403d28a5e2b9e8\n""}, {'number': 12, 'created': '2014-12-19 14:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/76d83bb6b9541f4ef28792922207bedc94c33c70', 'message': ""Extend API multivalue fields\n\nThis patch is creating a new JsonType type that accepts all the json\nprimitive types: bytes, unicode, float, long, int, dict, list, None\nand bool.\n\nSince the MultiType type is no longer used anywhere in the code it's\nbeen deleted.\n\nCloses-Bug: #1398350\nChange-Id: I2d9e4f20419ca2789c2f60034c403d28a5e2b9e8\n""}, {'number': 13, 'created': '2014-12-19 15:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c65b9cd805efa138b8a099467595b355e9c24bc6', 'message': ""Extend API multivalue fields\n\nThis patch is creating a new JsonType type that accepts all the json\nprimitive types: bytes, unicode, float, long, int, dict, list, None\nand bool.\n\nSince the MultiType type is no longer used anywhere in the code it's\nbeen deleted.\n\nCloses-Bug: #1398350\nChange-Id: I2d9e4f20419ca2789c2f60034c403d28a5e2b9e8\n""}, {'number': 14, 'created': '2014-12-19 16:20:51.000000000', 'files': ['ironic/api/controllers/v1/types.py', 'ironic/api/controllers/v1/port.py', 'ironic/api/controllers/v1/chassis.py', 'ironic/tests/api/v1/test_ports.py', 'ironic/tests/api/v1/test_types.py', 'ironic/tests/api/v1/test_chassis.py', 'ironic/tests/api/v1/test_nodes.py', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/98d4bfd3ec214f941d2f99bc8b5279bd0a9545ee', 'message': ""Extend API multivalue fields\n\nThis patch is creating a new JsonType type that accepts all the json\nprimitive types: bytes, unicode, float, long, int, dict, list, None\nand bool.\n\nSince the MultiType type is no longer used anywhere in the code it's\nbeen deleted.\n\nCloses-Bug: #1398350\nChange-Id: I2d9e4f20419ca2789c2f60034c403d28a5e2b9e8\n""}]",23,137762,98d4bfd3ec214f941d2f99bc8b5279bd0a9545ee,90,10,14,6773,,,0,"Extend API multivalue fields

This patch is creating a new JsonType type that accepts all the json
primitive types: bytes, unicode, float, long, int, dict, list, None
and bool.

Since the MultiType type is no longer used anywhere in the code it's
been deleted.

Closes-Bug: #1398350
Change-Id: I2d9e4f20419ca2789c2f60034c403d28a5e2b9e8
",git fetch https://review.opendev.org/openstack/ironic refs/changes/62/137762/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/api/controllers/v1/types.py', 'ironic/api/controllers/v1/port.py', 'ironic/api/controllers/v1/chassis.py', 'ironic/tests/api/v1/test_ports.py', 'ironic/tests/api/v1/test_types.py', 'ironic/tests/api/v1/test_chassis.py', 'ironic/tests/api/v1/test_nodes.py', 'ironic/api/controllers/v1/node.py']",8,39bd33c7bcb0d0c860ab41816474a06cfc74533b,extend-json-fields, console_info = {wtypes.text: types.ApiMultiType} instance_info = {wtypes.text: types.ApiMultiType} driver_info = {wtypes.text: types.ApiMultiType} extra = {wtypes.text: types.ApiMultiType} properties = {wtypes.text: types.ApiMultiType}," console_info = {wtypes.text: types.MultiType(wtypes.text, six.integer_types)} instance_info = {wtypes.text: types.MultiType(wtypes.text, six.integer_types)} driver_info = {wtypes.text: types.MultiType(wtypes.text, six.integer_types)} extra = {wtypes.text: types.MultiType(wtypes.text, six.integer_types)} properties = {wtypes.text: types.MultiType(wtypes.text, six.integer_types)}",46,32
openstack%2Fnova~master~Ia6fa2602dd7a9e7623abcfd46c8b57d3631372ef,openstack/nova,master,Ia6fa2602dd7a9e7623abcfd46c8b57d3631372ef,libvirt: change representation of guest features,MERGED,2014-12-08 17:21:39.000000000,2014-12-19 18:06:48.000000000,2014-12-19 13:25:38.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12898}]","[{'number': 1, 'created': '2014-12-08 17:21:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d23aca14cf3abab0c9551d48fae74c97e84c889', 'message': 'libvirt: change representation of guest features\n\nWhile the current acpi, apic & pae features are mere single elements,\nfurther feature will require complex data structures. The libvirt\nconfig class must thus change from using a simple string to represent\na feature, to a full class\n\nRelated-bug: #1400315\nChange-Id: Ia6fa2602dd7a9e7623abcfd46c8b57d3631372ef\n'}, {'number': 2, 'created': '2014-12-11 16:18:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/417aef124cb388f87fb63866762329a69d02c1c4', 'message': 'libvirt: change representation of guest features\n\nWhile the current acpi, apic & pae features are mere single elements,\nfurther feature will require complex data structures. The libvirt\nconfig class must thus change from using a simple string to represent\na feature, to a full class\n\nRelated-bug: #1400315\nChange-Id: Ia6fa2602dd7a9e7623abcfd46c8b57d3631372ef\n'}, {'number': 3, 'created': '2014-12-16 11:44:51.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/config.py', 'nova/tests/unit/virt/libvirt/test_config.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3afdc2a2b0ba7c558d51a53096a97bf2ba3640ce', 'message': 'libvirt: change representation of guest features\n\nWhile the current acpi, apic & pae features are mere single elements,\nfurther feature will require complex data structures. The libvirt\nconfig class must thus change from using a simple string to represent\na feature, to a full class\n\nRelated-bug: #1400315\nChange-Id: Ia6fa2602dd7a9e7623abcfd46c8b57d3631372ef\n'}]",0,140086,3afdc2a2b0ba7c558d51a53096a97bf2ba3640ce,36,12,3,1779,,,0,"libvirt: change representation of guest features

While the current acpi, apic & pae features are mere single elements,
further feature will require complex data structures. The libvirt
config class must thus change from using a simple string to represent
a feature, to a full class

Related-bug: #1400315
Change-Id: Ia6fa2602dd7a9e7623abcfd46c8b57d3631372ef
",git fetch https://review.opendev.org/openstack/nova refs/changes/86/140086/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/config.py', 'nova/tests/unit/virt/libvirt/test_config.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",4,3d23aca14cf3abab0c9551d48fae74c97e84c889,libvirt-win-timers," self.assertEqual(2, len(cfg.features)) self.assertIsInstance(cfg.features[0], vconfig.LibvirtConfigGuestFeatureACPI) self.assertIsInstance(cfg.features[1], vconfig.LibvirtConfigGuestFeatureAPIC) self.assertEqual(2, len(cfg.features)) self.assertIsInstance(cfg.features[0], vconfig.LibvirtConfigGuestFeatureACPI) self.assertIsInstance(cfg.features[1], vconfig.LibvirtConfigGuestFeatureAPIC) self.assertEqual(0, len(cfg.features)) self.assertEqual(3, len(cfg.features)) self.assertIsInstance(cfg.features[0], vconfig.LibvirtConfigGuestFeaturePAE) self.assertIsInstance(cfg.features[1], vconfig.LibvirtConfigGuestFeatureACPI) self.assertIsInstance(cfg.features[2], vconfig.LibvirtConfigGuestFeatureAPIC) self.assertEqual(3, len(cfg.features)) self.assertIsInstance(cfg.features[0], vconfig.LibvirtConfigGuestFeaturePAE) self.assertIsInstance(cfg.features[1], vconfig.LibvirtConfigGuestFeatureACPI) self.assertIsInstance(cfg.features[2], vconfig.LibvirtConfigGuestFeatureAPIC)"," self.assertEqual(cfg.pae, False) self.assertEqual(cfg.acpi, True) self.assertEqual(cfg.apic, True) self.assertEqual(cfg.acpi, True) self.assertEqual(cfg.acpi, False) self.assertEqual(cfg.pae, True) self.assertEqual(cfg.pae, True)",70,25
openstack%2Fheat~master~Ia51cb7c8b0c375d2a430d45b9ece50eb67271788,openstack/heat,master,Ia51cb7c8b0c375d2a430d45b9ece50eb67271788,Re-enable doc generation for contrib plugins,MERGED,2014-12-18 14:14:02.000000000,2014-12-19 18:06:44.000000000,2014-12-19 18:06:43.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 9189}]","[{'number': 1, 'created': '2014-12-18 14:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/45fcdc8eec47ed930429a4f620e6b96342c8a817', 'message': 'Re-enable doc generation for contrib plugins\n\nThis re-enables doc generation for contrib plugins and removes legacy\ncode no longer needed because of stevedore.\n\nRelated-Bug: 1403897\nChange-Id: Ia51cb7c8b0c375d2a430d45b9ece50eb67271788\n'}, {'number': 2, 'created': '2014-12-19 15:08:17.000000000', 'files': ['doc/source/conf.py', 'doc/source/ext/resources.py', 'doc/source/template_guide/contrib.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/c9082144bc9fbc7ef793d8a2ea84abbe7086dd41', 'message': 'Re-enable doc generation for contrib plugins\n\nThis re-enables doc generation for contrib plugins and removes legacy\ncode no longer needed because of stevedore.\n\nRelated-Bug: 1403897\nChange-Id: Ia51cb7c8b0c375d2a430d45b9ece50eb67271788\n'}]",2,142793,c9082144bc9fbc7ef793d8a2ea84abbe7086dd41,13,5,2,9189,,,0,"Re-enable doc generation for contrib plugins

This re-enables doc generation for contrib plugins and removes legacy
code no longer needed because of stevedore.

Related-Bug: 1403897
Change-Id: Ia51cb7c8b0c375d2a430d45b9ece50eb67271788
",git fetch https://review.opendev.org/openstack/heat refs/changes/93/142793/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'doc/source/ext/resources.py', 'doc/source/template_guide/contrib.rst']",3,45fcdc8eec47ed930429a4f620e6b96342c8a817,bug/1403897,.. resourcepages:: OS::Nova::Flavor,.. resourcepages:: NovaFlavor::,5,19
openstack%2Ftempest~master~I8e75d29edc62d30c2ba51f01a3bec490c88adde4,openstack/tempest,master,I8e75d29edc62d30c2ba51f01a3bec490c88adde4,Reorder setup and cleanup functions for readability,MERGED,2014-12-17 21:41:03.000000000,2014-12-19 18:04:33.000000000,2014-12-19 18:04:31.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 8556}, {'_account_id': 9194}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 21:41:03.000000000', 'files': ['tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5bd4cbf5b55aee678d0531a16f1ca6cfcee0dc46', 'message': 'Reorder setup and cleanup functions for readability\n\nAs suggested on another patch, reordering these to have the setup\nfunctions together for readability.\n\nPartially-implements bp:resource-cleanup\n\nChange-Id: I8e75d29edc62d30c2ba51f01a3bec490c88adde4\n'}]",0,142584,5bd4cbf5b55aee678d0531a16f1ca6cfcee0dc46,16,5,1,9194,,,0,"Reorder setup and cleanup functions for readability

As suggested on another patch, reordering these to have the setup
functions together for readability.

Partially-implements bp:resource-cleanup

Change-Id: I8e75d29edc62d30c2ba51f01a3bec490c88adde4
",git fetch https://review.opendev.org/openstack/tempest refs/changes/84/142584/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/test.py'],1,5bd4cbf5b55aee678d0531a16f1ca6cfcee0dc46,bp/resource-cleanup," @classmethod def resource_setup(cls): """"""Class level resource setup for test cases. """""" pass @classmethod def resource_cleanup(cls): """"""Class level resource cleanup for test cases. Resource cleanup must be able to handle the case of partially setup resources, in case a failure during `resource_setup` should happen. """""" pass "," def resource_setup(cls): """"""Class level resource setup for test cases. """""" pass @classmethod def resource_cleanup(cls): """"""Class level resource cleanup for test cases. Resource cleanup must be able to handle the case of partially setup resources, in case a failure during `resource_setup` should happen. """""" pass @classmethod",14,14
openstack%2Fheat~master~Id6ece4379599925dd17d22cef401c8d667a0ac51,openstack/heat,master,Id6ece4379599925dd17d22cef401c8d667a0ac51,Fix doc generation for contrib resources,MERGED,2014-12-18 14:14:02.000000000,2014-12-19 18:02:10.000000000,2014-12-19 18:02:09.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4257}, {'_account_id': 7253}, {'_account_id': 7256}]","[{'number': 1, 'created': '2014-12-18 14:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/05dcc454db79168ca441f0aaf1a143efcf20ce8f', 'message': ""Fix doc generation for contrib resources\n\nSince we shouldn't require contrib resources to be installed in order to\ngenerate documentation, this adds an exception to the plugin loader so\nthat it doesn't try to load the setup.py files that can be found inside\neach plugin directory inside contrib/\n\nCloses-Bug: 1403897\nChange-Id: Id6ece4379599925dd17d22cef401c8d667a0ac51\n""}, {'number': 2, 'created': '2014-12-19 15:08:17.000000000', 'files': ['heat/common/plugin_loader.py', 'heat/tests/test_plugin_loader.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/4d522fa55132807a7edaa5c090c1e8c7f4019ec8', 'message': ""Fix doc generation for contrib resources\n\nSince we shouldn't require contrib resources to be installed in order to\ngenerate documentation, this adds an exception to the plugin loader so\nthat it doesn't try to load the setup.py files that can be found inside\neach plugin directory inside contrib/\n\nCloses-Bug: 1403897\nChange-Id: Id6ece4379599925dd17d22cef401c8d667a0ac51\n""}]",1,142792,4d522fa55132807a7edaa5c090c1e8c7f4019ec8,13,5,2,9189,,,0,"Fix doc generation for contrib resources

Since we shouldn't require contrib resources to be installed in order to
generate documentation, this adds an exception to the plugin loader so
that it doesn't try to load the setup.py files that can be found inside
each plugin directory inside contrib/

Closes-Bug: 1403897
Change-Id: Id6ece4379599925dd17d22cef401c8d667a0ac51
",git fetch https://review.opendev.org/openstack/heat refs/changes/92/142792/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/common/plugin_loader.py', 'heat/tests/test_plugin_loader.py']",2,05dcc454db79168ca441f0aaf1a143efcf20ce8f,bug/1403897," @mock.patch.object(plugin_loader, ""_import_module"", mock.MagicMock()) @mock.patch('pkgutil.walk_packages') def test_load_modules_skip_setup(self, mp): importer = pkgutil.ImpImporter(heat.engine.__path__[0]) mp.return_value = ((importer, ""hola.foo"", None), (importer, ""hola.setup"", None)) loaded = plugin_loader.load_modules( heat.engine, ignore_error=True) self.assertEqual(1, len(list(loaded)))",,14,3
openstack%2Foctavia~master~I82aa573c7db13c7a491b18540379b234c1023eb9,openstack/octavia,master,I82aa573c7db13c7a491b18540379b234c1023eb9,Add Cert+PK generation to Certificate Interface,MERGED,2014-12-18 01:12:24.000000000,2014-12-19 18:01:12.000000000,2014-12-19 18:01:12.000000000,"[{'_account_id': 3}, {'_account_id': 7398}, {'_account_id': 10273}, {'_account_id': 10980}, {'_account_id': 11685}]","[{'number': 1, 'created': '2014-12-18 01:12:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/0dc73a8b43c8e8cc36d233f4592e1a7fb992bed1', 'message': 'Add PK and CSR generation to Certificate Interface\n\nChange-Id: I82aa573c7db13c7a491b18540379b234c1023eb9\n'}, {'number': 2, 'created': '2014-12-18 17:41:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/8ae07a77b114bf3da5add472e6a79b020b7d07a6', 'message': 'Add Cert+PK generation to Certificate Interface\n\nChange-Id: I82aa573c7db13c7a491b18540379b234c1023eb9\n'}, {'number': 3, 'created': '2014-12-18 19:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/398ffcd0c9b0f2bee86d1b22017f0e92fbd1e0f4', 'message': 'Add Cert+PK generation to Certificate Interface\n\nChange-Id: I82aa573c7db13c7a491b18540379b234c1023eb9\n'}, {'number': 4, 'created': '2014-12-18 20:21:15.000000000', 'files': ['octavia/certificates/generator/cert_gen.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/293f44e211e4f26a0b7eca842dd2af515957a4bd', 'message': 'Add Cert+PK generation to Certificate Interface\n\nChange-Id: I82aa573c7db13c7a491b18540379b234c1023eb9\n'}]",1,142628,293f44e211e4f26a0b7eca842dd2af515957a4bd,16,5,4,10273,,,0,"Add Cert+PK generation to Certificate Interface

Change-Id: I82aa573c7db13c7a491b18540379b234c1023eb9
",git fetch https://review.opendev.org/openstack/octavia refs/changes/28/142628/4 && git format-patch -1 --stdout FETCH_HEAD,['octavia/certificates/generator/cert_gen.py'],1,0dc73a8b43c8e8cc36d233f4592e1a7fb992bed1,(detached," A Certificate Generator is responsible for generating private keys, generating CSRs, and signing TLS certificates. @abc.abstractmethod def generate_private_key(self, bit_length, passphrase): """"""Generates a private key :param bit_length: Private key bit length :param passphrase: Passphrase to use for encrypting the private key :return: PEM encoded private key :raises Exception: If private key generation fails """""" pass @abc.abstractmethod def generate_csr(self, private_key, passphrase): """"""Generates a CSR :param private_key: The private key to use for the CSR :param passphrase: The passphrase to decrypt the private key :return: PKCS #10 CSR :raises Exception: If CSR generation fails """""" pass", A Certificate Generator is responsible for signing TLS certificates.,26,1
openstack%2Fheat~master~I411ff41a9e0730e9864f5ed4ac54f1d5d0ec02d7,openstack/heat,master,I411ff41a9e0730e9864f5ed4ac54f1d5d0ec02d7,Disable nested validation for ResourceGroup with zero count,MERGED,2014-12-12 17:52:29.000000000,2014-12-19 18:00:51.000000000,2014-12-19 18:00:49.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4330}, {'_account_id': 7256}]","[{'number': 1, 'created': '2014-12-12 17:52:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a035a4f8a28ae795185f0653d8027ff54711259f', 'message': ""Disable nested validation for ResourceGroup with zero count\n\nSome users (TripleO specifically) want to disable features via a\ncount of zero, which is a problem as we always recurse and validate\nthe nested stack since c31c34f8dfd0919bf46a975701c139073115debc\n\nInstead, we only do validation when the count is non-zero, to\nenable, e.g default image names, to be ignored at validation\ntime (as we'll never use them) instead of rejected by the nested\nschema (e.g the server.py properties schema which contains a\ncustom contraint to always validate the image).\n\nThis should still allow us to fail fast (at validation time before\ncreating anything) when we're actually about to create something,\ne.g when the count is non-zero.\n\nChange-Id: I411ff41a9e0730e9864f5ed4ac54f1d5d0ec02d7\nCloses-Bug: #1401929\n""}, {'number': 2, 'created': '2014-12-19 11:18:28.000000000', 'files': ['heat/engine/resources/resource_group.py', 'heat_integrationtests/functional/test_resource_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/907c0aac79a367d84bdbc26acbf5c4475f9abab7', 'message': ""Disable nested validation for ResourceGroup with zero count\n\nSome users (TripleO specifically) want to disable features via a\ncount of zero, which is a problem as we always recurse and validate\nthe nested stack since c31c34f8dfd0919bf46a975701c139073115debc\n\nInstead, we only do validation when the count is non-zero, to\nenable, e.g default image names, to be ignored at validation\ntime (as we'll never use them) instead of rejected by the nested\nschema (e.g the server.py properties schema which contains a\ncustom contraint to always validate the image).\n\nThis should still allow us to fail fast (at validation time before\ncreating anything) when we're actually about to create something,\ne.g when the count is non-zero.\n\nChange-Id: I411ff41a9e0730e9864f5ed4ac54f1d5d0ec02d7\nCloses-Bug: #1401929\n""}]",0,141444,907c0aac79a367d84bdbc26acbf5c4475f9abab7,20,7,2,4328,,,0,"Disable nested validation for ResourceGroup with zero count

Some users (TripleO specifically) want to disable features via a
count of zero, which is a problem as we always recurse and validate
the nested stack since c31c34f8dfd0919bf46a975701c139073115debc

Instead, we only do validation when the count is non-zero, to
enable, e.g default image names, to be ignored at validation
time (as we'll never use them) instead of rejected by the nested
schema (e.g the server.py properties schema which contains a
custom contraint to always validate the image).

This should still allow us to fail fast (at validation time before
creating anything) when we're actually about to create something,
e.g when the count is non-zero.

Change-Id: I411ff41a9e0730e9864f5ed4ac54f1d5d0ec02d7
Closes-Bug: #1401929
",git fetch https://review.opendev.org/openstack/heat refs/changes/44/141444/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/resource_group.py'],1,a035a4f8a28ae795185f0653d8027ff54711259f,bug/1401929," # Only validate the resource definition (which may be a # nested template) if count is non-zero, to enable folks # to disable features via a zero count if they wish if self.properties[self.COUNT]: res_inst.validate()", res_inst.validate(),5,1
openstack%2Fcinder~stable%2Ficehouse~I2f81fed18342fe384e3c61184948f1e4052765d5,openstack/cinder,stable/icehouse,I2f81fed18342fe384e3c61184948f1e4052765d5,Fix NetApp AutoSupport Shortcomings.,MERGED,2014-12-08 16:35:51.000000000,2014-12-19 17:56:17.000000000,2014-12-19 17:56:15.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 7198}, {'_account_id': 9003}, {'_account_id': 9186}, {'_account_id': 10621}]","[{'number': 1, 'created': '2014-12-08 16:35:51.000000000', 'files': ['cinder/volume/drivers/netapp/utils.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/volume/drivers/netapp/common.py', 'cinder/tests/test_netapp_utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/114283035508354c3b54bc469ce85105f73c2a11', 'message': 'Fix NetApp AutoSupport Shortcomings.\n\nThis patch addresses several problems with the current implementation.\n\n1. Appending a record to EMS should not in itself trigger ASUP\ndelivery. These should be separately scheduled and Openstack cinder\nshould have no role in ASUP scheduling or delivery, only a role in\nlogging via EMS.\n\n2. Log frequency should be adjusted from weekly to hourly.\n\n3. The log message should be useful for support. It should include\nrelease (Havana, Icehouse, Juno, etc.) version (2014.1.1), and\ndistribution information (RHEL-OSP, etc.) rather than simply noting that\nthe message came from ""Openstack.""\n\nCloses-Bug: 1367676\nChange-Id: I2f81fed18342fe384e3c61184948f1e4052765d5\n(cherry picked from commit b3be30b14ce3f31af8a5f23542246ca8d0c4da8c)\n'}]",0,140071,114283035508354c3b54bc469ce85105f73c2a11,11,7,1,9003,,,0,"Fix NetApp AutoSupport Shortcomings.

This patch addresses several problems with the current implementation.

1. Appending a record to EMS should not in itself trigger ASUP
delivery. These should be separately scheduled and Openstack cinder
should have no role in ASUP scheduling or delivery, only a role in
logging via EMS.

2. Log frequency should be adjusted from weekly to hourly.

3. The log message should be useful for support. It should include
release (Havana, Icehouse, Juno, etc.) version (2014.1.1), and
distribution information (RHEL-OSP, etc.) rather than simply noting that
the message came from ""Openstack.""

Closes-Bug: 1367676
Change-Id: I2f81fed18342fe384e3c61184948f1e4052765d5
(cherry picked from commit b3be30b14ce3f31af8a5f23542246ca8d0c4da8c)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/71/140071/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/netapp/utils.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/volume/drivers/netapp/common.py', 'cinder/tests/test_netapp_utils.py']",5,114283035508354c3b54bc469ce85105f73c2a11,bug/1367676,"# Copyright 2014 Tom Barron. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import platform import mock from cinder.openstack.common import processutils as putils from cinder import test from cinder import version from cinder.volume.drivers.netapp import utils as na_utils class OpenstackInfoTestCase(test.TestCase): UNKNOWN_VERSION = 'unknown version' UNKNOWN_RELEASE = 'unknown release' UNKNOWN_VENDOR = 'unknown vendor' UNKNOWN_PLATFORM = 'unknown platform' VERSION_STRING_RET_VAL = 'fake_version_1' RELEASE_STRING_RET_VAL = 'fake_release_1' PLATFORM_RET_VAL = 'fake_platform_1' VERSION_INFO_VERSION = 'fake_version_2' VERSION_INFO_RELEASE = 'fake_release_2' RPM_INFO_VERSION = 'fake_version_3' RPM_INFO_RELEASE = 'fake_release_3' RPM_INFO_VENDOR = 'fake vendor 3' PUTILS_RPM_RET_VAL = ('fake_version_3 fake_release_3 fake vendor 3', '') NO_PKG_FOUND = ('', 'whatever') PUTILS_DPKG_RET_VAL = ('epoch:upstream_version-debian_revision', '') DEB_RLS = 'upstream_version-debian_revision' DEB_VENDOR = 'debian_revision' def setUp(self): super(OpenstackInfoTestCase, self).setUp() def test_openstack_info_init(self): info = na_utils.OpenStackInfo() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(version.version_info, 'version_string', mock.Mock(return_value=VERSION_STRING_RET_VAL)) def test_update_version_from_version_string(self): info = na_utils.OpenStackInfo() info._update_version_from_version_string() self.assertEqual(self.VERSION_STRING_RET_VAL, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(version.version_info, 'version_string', mock.Mock(side_effect=Exception)) def test_xcption_in_update_version_from_version_string(self): info = na_utils.OpenStackInfo() info._update_version_from_version_string() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(version.version_info, 'release_string', mock.Mock(return_value=RELEASE_STRING_RET_VAL)) def test_update_release_from_release_string(self): info = na_utils.OpenStackInfo() info._update_release_from_release_string() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.RELEASE_STRING_RET_VAL, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(version.version_info, 'release_string', mock.Mock(side_effect=Exception)) def test_xcption_in_update_release_from_release_string(self): info = na_utils.OpenStackInfo() info._update_release_from_release_string() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(platform, 'platform', mock.Mock(return_value=PLATFORM_RET_VAL)) def test_update_platform(self): info = na_utils.OpenStackInfo() info._update_platform() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.PLATFORM_RET_VAL, info._platform) @mock.patch.object(platform, 'platform', mock.Mock(side_effect=Exception)) def test_xcption_in_update_platform(self): info = na_utils.OpenStackInfo() info._update_platform() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(na_utils.OpenStackInfo, '_get_version_info_version', mock.Mock(return_value=VERSION_INFO_VERSION)) @mock.patch.object(na_utils.OpenStackInfo, '_get_version_info_release', mock.Mock(return_value=VERSION_INFO_RELEASE)) def test_update_info_from_version_info(self): info = na_utils.OpenStackInfo() info._update_info_from_version_info() self.assertEqual(self.VERSION_INFO_VERSION, info._version) self.assertEqual(self.VERSION_INFO_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(na_utils.OpenStackInfo, '_get_version_info_version', mock.Mock(return_value='')) @mock.patch.object(na_utils.OpenStackInfo, '_get_version_info_release', mock.Mock(return_value=None)) def test_no_info_from_version_info(self): info = na_utils.OpenStackInfo() info._update_info_from_version_info() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(na_utils.OpenStackInfo, '_get_version_info_version', mock.Mock(return_value=VERSION_INFO_VERSION)) @mock.patch.object(na_utils.OpenStackInfo, '_get_version_info_release', mock.Mock(side_effect=Exception)) def test_xcption_in_info_from_version_info(self): info = na_utils.OpenStackInfo() info._update_info_from_version_info() self.assertEqual(self.VERSION_INFO_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) @mock.patch.object(putils, 'execute', mock.Mock(return_value=PUTILS_RPM_RET_VAL)) def test_update_info_from_rpm(self): info = na_utils.OpenStackInfo() found_package = info._update_info_from_rpm() self.assertEqual(self.RPM_INFO_VERSION, info._version) self.assertEqual(self.RPM_INFO_RELEASE, info._release) self.assertEqual(self.RPM_INFO_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) self.assertTrue(found_package) @mock.patch.object(putils, 'execute', mock.Mock(return_value=NO_PKG_FOUND)) def test_update_info_from_rpm_no_pkg_found(self): info = na_utils.OpenStackInfo() found_package = info._update_info_from_rpm() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) self.assertFalse(found_package) @mock.patch.object(putils, 'execute', mock.Mock(side_effect=Exception)) def test_xcption_in_update_info_from_rpm(self): info = na_utils.OpenStackInfo() found_package = info._update_info_from_rpm() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) self.assertFalse(found_package) @mock.patch.object(putils, 'execute', mock.Mock(return_value=PUTILS_DPKG_RET_VAL)) def test_update_info_from_dpkg(self): info = na_utils.OpenStackInfo() found_package = info._update_info_from_dpkg() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.DEB_RLS, info._release) self.assertEqual(self.DEB_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) self.assertTrue(found_package) @mock.patch.object(putils, 'execute', mock.Mock(return_value=NO_PKG_FOUND)) def test_update_info_from_dpkg_no_pkg_found(self): info = na_utils.OpenStackInfo() found_package = info._update_info_from_dpkg() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) self.assertFalse(found_package) @mock.patch.object(putils, 'execute', mock.Mock(side_effect=Exception)) def test_xcption_in_update_info_from_dpkg(self): info = na_utils.OpenStackInfo() found_package = info._update_info_from_dpkg() self.assertEqual(self.UNKNOWN_VERSION, info._version) self.assertEqual(self.UNKNOWN_RELEASE, info._release) self.assertEqual(self.UNKNOWN_VENDOR, info._vendor) self.assertEqual(self.UNKNOWN_PLATFORM, info._platform) self.assertFalse(found_package) @mock.patch.object(na_utils.OpenStackInfo, '_update_version_from_version_string', mock.Mock()) @mock.patch.object(na_utils.OpenStackInfo, '_update_release_from_release_string', mock.Mock()) @mock.patch.object(na_utils.OpenStackInfo, '_update_platform', mock.Mock()) @mock.patch.object(na_utils.OpenStackInfo, '_update_info_from_version_info', mock.Mock()) @mock.patch.object(na_utils.OpenStackInfo, '_update_info_from_rpm', mock.Mock(return_value=True)) @mock.patch.object(na_utils.OpenStackInfo, '_update_info_from_dpkg') def test_update_openstack_info_rpm_pkg_found(self, mock_updt_from_dpkg): info = na_utils.OpenStackInfo() info._update_openstack_info() self.assertFalse(mock_updt_from_dpkg.called) @mock.patch.object(na_utils.OpenStackInfo, '_update_version_from_version_string', mock.Mock()) @mock.patch.object(na_utils.OpenStackInfo, '_update_release_from_release_string', mock.Mock()) @mock.patch.object(na_utils.OpenStackInfo, '_update_platform', mock.Mock()) @mock.patch.object(na_utils.OpenStackInfo, '_update_info_from_version_info', mock.Mock()) @mock.patch.object(na_utils.OpenStackInfo, '_update_info_from_rpm', mock.Mock(return_value=False)) @mock.patch.object(na_utils.OpenStackInfo, '_update_info_from_dpkg') def test_update_openstack_info_rpm_pkg_not_found(self, mock_updt_from_dpkg): info = na_utils.OpenStackInfo() info._update_openstack_info() self.assertTrue(mock_updt_from_dpkg.called) ",,422,18
openstack%2Fkolla~master~I91098ff987b18646d901ac63a3a644fbb68fc857,openstack/kolla,master,I91098ff987b18646d901ac63a3a644fbb68fc857,Enable usage of containers outside of Kubernetes,MERGED,2014-12-17 04:50:22.000000000,2014-12-19 17:29:54.000000000,2014-12-19 17:29:54.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 10419}]","[{'number': 1, 'created': '2014-12-17 04:50:22.000000000', 'files': ['docker/fedora-rdo-base/service_hosts.sh', 'docker/keystone/start.sh', 'docker/fedora-rdo-base/Dockerfile', 'docker/fedora-rdo-base/kolla-common.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/816612192c179a6b73c3f3b5f105d481ab1a438c', 'message': ""Enable usage of containers outside of Kubernetes\n\nKubernetes currently creates FOO_SERVICE_HOST and FOO_SERVICE_PORT env\nvars as part of starting the containers. However this is not done when\nstarting them with plain docker.\n\nDefaulting variables to their common version if they're not already set\nallows the usage of --link in plain 'docker run' to wire together\ncontainers.\n\nCo-Authored-By: Charles Crouch <ccrouch@redhat.com>\nChange-Id: I91098ff987b18646d901ac63a3a644fbb68fc857\n""}]",0,142343,816612192c179a6b73c3f3b5f105d481ab1a438c,7,3,1,13039,,,0,"Enable usage of containers outside of Kubernetes

Kubernetes currently creates FOO_SERVICE_HOST and FOO_SERVICE_PORT env
vars as part of starting the containers. However this is not done when
starting them with plain docker.

Defaulting variables to their common version if they're not already set
allows the usage of --link in plain 'docker run' to wire together
containers.

Co-Authored-By: Charles Crouch <ccrouch@redhat.com>
Change-Id: I91098ff987b18646d901ac63a3a644fbb68fc857
",git fetch https://review.opendev.org/openstack/kolla refs/changes/43/142343/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/fedora-rdo-base/service_hosts.sh', 'docker/keystone/start.sh', 'docker/fedora-rdo-base/Dockerfile', 'docker/fedora-rdo-base/kolla-common.sh']",4,816612192c179a6b73c3f3b5f105d481ab1a438c,docker_link,. /opt/kolla/service_hosts.sh ,,48,2
openstack%2Fnova~master~I6af05b4e8e0b2145733c0f301c04555da23b7da8,openstack/nova,master,I6af05b4e8e0b2145733c0f301c04555da23b7da8,libvirt: add support for hyperv timer source with windows guests,MERGED,2014-12-08 17:21:39.000000000,2014-12-19 17:25:02.000000000,2014-12-19 13:22:15.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 3185}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6062}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12898}]","[{'number': 1, 'created': '2014-12-08 17:21:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/75d72190f47d0fcb13943dac2457542ec48d467d', 'message': ""libvirt: add support for hyperv timer source with windows guests\n\nThe hyperv timer source enables Windows guests to keep accurate\ntime, much like kvmclock does for Linux guests. It should be\nenabled for all windows guests, as it doesn't harm older windows\nversions which don't know about it.\n\nRelated-bug: #1400315\nChange-Id: I6af05b4e8e0b2145733c0f301c04555da23b7da8\n""}, {'number': 2, 'created': '2014-12-11 16:18:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/009f6506ef15488068b227a7aba7a5a1a9cd6079', 'message': ""libvirt: add support for hyperv timer source with windows guests\n\nThe hyperv timer source enables Windows guests to keep accurate\ntime, much like kvmclock does for Linux guests. It should be\nenabled for all windows guests, as it doesn't harm older windows\nversions which don't know about it.\n\nRelated-bug: #1400315\nChange-Id: I6af05b4e8e0b2145733c0f301c04555da23b7da8\n""}, {'number': 3, 'created': '2014-12-16 11:44:51.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/989eac8b748fd6a545198541afa672039e339f90', 'message': ""libvirt: add support for hyperv timer source with windows guests\n\nThe hyperv timer source enables Windows guests to keep accurate\ntime, much like kvmclock does for Linux guests. It should be\nenabled for all windows guests, as it doesn't harm older windows\nversions which don't know about it.\n\nRelated-bug: #1400315\nChange-Id: I6af05b4e8e0b2145733c0f301c04555da23b7da8\n""}]",3,140085,989eac8b748fd6a545198541afa672039e339f90,38,14,3,1779,,,0,"libvirt: add support for hyperv timer source with windows guests

The hyperv timer source enables Windows guests to keep accurate
time, much like kvmclock does for Linux guests. It should be
enabled for all windows guests, as it doesn't harm older windows
versions which don't know about it.

Related-bug: #1400315
Change-Id: I6af05b4e8e0b2145733c0f301c04555da23b7da8
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/140085/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,75d72190f47d0fcb13943dac2457542ec48d467d,libvirt-win-timers," @mock.patch.object(host.Host, 'has_min_version') def test_get_guest_config_windows(self, mock_flavor, mock_version): mock_version.return_value = False self.assertEqual(3, len(cfg.clock.timers)) self.assertEqual(cfg.clock.timers[0].name, ""pit"") self.assertEqual(cfg.clock.timers[1].name, ""rtc"") self.assertEqual(cfg.clock.timers[2].name, ""hpet"") self.assertFalse(cfg.clock.timers[2].present) @mock.patch.object(host.Host, 'has_min_version') @mock.patch.object(objects.Flavor, 'get_by_id') def test_get_guest_config_windows_timer(self, mock_flavor, mock_version): mock_version.return_value = True conn = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) instance_ref = objects.Instance(**self.test_instance) instance_ref['os_type'] = 'windows' flavor = instance_ref.get_flavor() flavor.extra_specs = {} mock_flavor.return_value = flavor disk_info = blockinfo.get_disk_info(CONF.libvirt.virt_type, instance_ref) cfg = conn._get_guest_config(instance_ref, _fake_network_info(self.stubs, 1), {}, disk_info) self.assertIsInstance(cfg.clock, vconfig.LibvirtConfigGuestClock) self.assertEqual(cfg.clock.offset, ""localtime"") self.assertEqual(4, len(cfg.clock.timers)) self.assertEqual(cfg.clock.timers[0].name, ""pit"") self.assertEqual(cfg.clock.timers[1].name, ""rtc"") self.assertEqual(cfg.clock.timers[2].name, ""hpet"") self.assertFalse(cfg.clock.timers[2].present) self.assertEqual(cfg.clock.timers[3].name, ""hypervclock"") self.assertTrue(cfg.clock.timers[3].present) "," def test_get_guest_config_windows(self, mock_flavor):",56,3
openstack%2Fneutron-fwaas~master~I54fd528b04ae34bc42a691045abd19a2a99e18f9,openstack/neutron-fwaas,master,I54fd528b04ae34bc42a691045abd19a2a99e18f9,FWaaS: Get unit tests working,ABANDONED,2014-12-19 16:46:00.000000000,2014-12-19 17:20:01.000000000,,[{'_account_id': 6659}],"[{'number': 1, 'created': '2014-12-19 16:46:00.000000000', 'files': ['neutron_fwaas/tests/unit/services/firewall/agents/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/l3reference/__init__.py', 'neutron_fwaas/tests.skip/unit/__init__.py', 'neutron_fwaas/tests/unit/db/firewall/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/varmour/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/test_fwaas_plugin.py', 'neutron_fwaas/tests/unit/services/firewall/agents/l3reference/test_firewall_l3_agent.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/linux/test_iptables_fwaas.py', 'neutron_fwaas/tests/unit/__init__.py', 'neutron_fwaas/tests/unit/services/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/test_firewall_agent_api.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/varmour/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/__init__.py', 'neutron_fwaas/tests.skip/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/linux/__init__.py', 'neutron_fwaas/tests/unit/test_true.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/varmour/test_varmour_fwaas.py', 'neutron_fwaas/tests/unit/db/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/varmour/test_varmour_router.py', 'neutron_fwaas/tests/unit/db/firewall/test_db_firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/8a8ef6285191ece9120f921528fa5d0b965dcb11', 'message': 'FWaaS: Get unit tests working\n\nMoved unit tests from tests.skip to tests area and modified\ntests to run.\n\nNOTE: This will probably need another pass, to address any\nissues with policy.json.\n\nChange-Id: I54fd528b04ae34bc42a691045abd19a2a99e18f9\nPartially-Implements: blueprint service-split\n'}]",0,143136,8a8ef6285191ece9120f921528fa5d0b965dcb11,3,1,1,6659,,,0,"FWaaS: Get unit tests working

Moved unit tests from tests.skip to tests area and modified
tests to run.

NOTE: This will probably need another pass, to address any
issues with policy.json.

Change-Id: I54fd528b04ae34bc42a691045abd19a2a99e18f9
Partially-Implements: blueprint service-split
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/36/143136/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas/tests/unit/services/firewall/agents/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/l3reference/__init__.py', 'neutron_fwaas/tests.skip/unit/__init__.py', 'neutron_fwaas/tests/unit/db/firewall/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/varmour/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/test_fwaas_plugin.py', 'neutron_fwaas/tests/unit/services/firewall/agents/l3reference/test_firewall_l3_agent.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/linux/test_iptables_fwaas.py', 'neutron_fwaas/tests/unit/__init__.py', 'neutron_fwaas/tests/unit/services/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/test_firewall_agent_api.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/varmour/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/__init__.py', 'neutron_fwaas/tests.skip/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/linux/__init__.py', 'neutron_fwaas/tests/unit/test_true.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/varmour/test_varmour_fwaas.py', 'neutron_fwaas/tests/unit/db/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/varmour/test_varmour_router.py', 'neutron_fwaas/tests/unit/db/firewall/test_db_firewall.py']",21,8a8ef6285191ece9120f921528fa5d0b965dcb11,bp/service-split," ""neutron_fwaas.db.firewall.firewall_db.Firewall_db_mixin""FWAAS_PLUGIN = 'neutron_fwaas.services.firewall.fwaas_plugin'"," ""neutron.db.firewall.firewall_db.Firewall_db_mixin""FWAAS_PLUGIN = 'neutron.services.firewall.fwaas_plugin'",28,47
openstack%2Fironic~master~Ide755f6e27b6fc3b667995ecd0bdbe597abf4852,openstack/ironic,master,Ide755f6e27b6fc3b667995ecd0bdbe597abf4852,clean up manager logging,ABANDONED,2014-12-16 00:15:05.000000000,2014-12-19 17:09:48.000000000,,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-12-16 00:15:05.000000000', 'files': ['ironic/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e5924e9e2c8171f9ec9ce58f9e07da9b710a4bc8', 'message': 'clean up manager logging\n\nRemove a unneeded log line from manager.py\n\nChange-Id: Ide755f6e27b6fc3b667995ecd0bdbe597abf4852\n'}]",0,141949,e5924e9e2c8171f9ec9ce58f9e07da9b710a4bc8,11,5,1,5805,,,0,"clean up manager logging

Remove a unneeded log line from manager.py

Change-Id: Ide755f6e27b6fc3b667995ecd0bdbe597abf4852
",git fetch https://review.opendev.org/openstack/ironic refs/changes/49/141949/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/conductor/manager.py'],1,e5924e9e2c8171f9ec9ce58f9e07da9b710a4bc8,fsm_log_fixup," LOG.warning(_LW(""Attempt to change power state of node %(node)s "" ""to '%(state)s' failed. Will retry.""), {'node': node.uuid, 'state': node.power_state})"," LOG.error(_LE(""Failed to change power state of node %(node)s "" ""to '%(state)s'.""), {'node': node.uuid, 'state': node.power_state}) attempts_left = CONF.conductor.power_state_sync_max_retries - count LOG.warning(_LW(""%(left)s attempts remaining to "" ""sync_power_state for node %(node)s""), {'left': attempts_left, 'node': node.uuid})",3,8
openstack%2Fmanila~master~Iff9073866239d7ee3bcbd2b71c1e930bc91d58e9,openstack/manila,master,Iff9073866239d7ee3bcbd2b71c1e930bc91d58e9,Fix tempest compatibility for network client,MERGED,2014-12-19 09:46:17.000000000,2014-12-19 17:03:12.000000000,2014-12-19 17:03:10.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7102}]","[{'number': 1, 'created': '2014-12-19 09:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b00c0e64a114049e09a95e753bcf659f3c6a99ae', 'message': 'Fix tempest compatibility for network client\n\nCommit in tempest\nhttps://github.com/openstack/tempest/commit/34e88120\n\nchanged response, make our plugin compatible with it.\n\nChange-Id: Iff9073866239d7ee3bcbd2b71c1e930bc91d58e9\n'}, {'number': 2, 'created': '2014-12-19 09:47:09.000000000', 'files': ['contrib/tempest/tempest/api/share/base.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/ecf0b90b73cfa1a17af6b2f1cd2ed2895947ecf1', 'message': 'Fix tempest compatibility for network client\n\nCommit in tempest\nhttps://github.com/openstack/tempest/commit/34e88120\n\nchanged response type from network client, make our plugin compatible with it.\n\nChange-Id: Iff9073866239d7ee3bcbd2b71c1e930bc91d58e9\n'}]",0,143023,ecf0b90b73cfa1a17af6b2f1cd2ed2895947ecf1,9,4,2,8851,,,0,"Fix tempest compatibility for network client

Commit in tempest
https://github.com/openstack/tempest/commit/34e88120

changed response type from network client, make our plugin compatible with it.

Change-Id: Iff9073866239d7ee3bcbd2b71c1e930bc91d58e9
",git fetch https://review.opendev.org/openstack/manila refs/changes/23/143023/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/tempest/tempest/api/share/base.py'],1,b00c0e64a114049e09a95e753bcf659f3c6a99ae,tempest, networks = network_client.list_networks()," __, networks = network_client.list_networks()",1,1
openstack%2Ffuel-web~master~I5ccfce89ad35018b4f561c03621d7eefb9042f29,openstack/fuel-web,master,I5ccfce89ad35018b4f561c03621d7eefb9042f29,Fix vlan disappear on ip range add,MERGED,2014-12-19 10:29:17.000000000,2014-12-19 17:02:30.000000000,2014-12-19 17:02:30.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-12-19 10:29:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8e0d011c95022d474ab2b55d09eaf8e41aff5d81', 'message': 'Fix vlan disappear on ip range add\n\nCloses-bug: #1398391\n\nChange-Id: I5ccfce89ad35018b4f561c03621d7eefb9042f29\n'}, {'number': 2, 'created': '2014-12-19 10:30:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a865ade1ddee5b1cf0c0a35a8a67c0e2bae7260d', 'message': 'Fix vlan disappear on ip range add\n\nCloses-bug: #1398391\n\nChange-Id: I5ccfce89ad35018b4f561c03621d7eefb9042f29\n'}, {'number': 3, 'created': '2014-12-19 14:38:51.000000000', 'files': ['nailgun/static/js/views/cluster_page_tabs/network_tab.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/27406ed5a6b50a971aa751db6db56e15d39541e0', 'message': 'Fix vlan disappear on ip range add\n\nCloses-bug: #1398391\n\nChange-Id: I5ccfce89ad35018b4f561c03621d7eefb9042f29\n'}]",2,143030,27406ed5a6b50a971aa751db6db56e15d39541e0,23,6,3,9091,,,0,"Fix vlan disappear on ip range add

Closes-bug: #1398391

Change-Id: I5ccfce89ad35018b4f561c03621d7eefb9042f29
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/30/143030/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/js/views/cluster_page_tabs/network_tab.js'],1,8e0d011c95022d474ab2b55d09eaf8e41aff5d81,network_bugs, var bindingSelector = (this.network ? ('.' + this.network.get('name')) : '') + ' .vlan-tagging input[type=checkbox]'; bindings[bindingSelector] = {, bindings['.vlan-tagging input[type=checkbox]'] = {,2,1
openstack%2Ffuel-web~master~I85b57bab488072b3e1d1f3990fcb231e77cf4645,openstack/fuel-web,master,I85b57bab488072b3e1d1f3990fcb231e77cf4645,Fix for thisArg in Backbone lodash monkeypatch,MERGED,2014-12-19 14:53:26.000000000,2014-12-19 17:00:47.000000000,2014-12-19 17:00:46.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}]","[{'number': 1, 'created': '2014-12-19 14:53:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/799209389dd93952f31d21173aae73e7c8d90ae9', 'message': ""Fix for thisArg in Backbone lodash monkeypatch\n\nIt turns out that thisArg was not taken into account when applying the\nlodash functions which resulted in wrong 'this' argument in the inner function\nof such calls:\n\nnodes.filter(function(node) { ... }, this);\n\nChange-Id: I85b57bab488072b3e1d1f3990fcb231e77cf4645\n""}, {'number': 2, 'created': '2014-12-19 14:54:33.000000000', 'files': ['nailgun/static/js/libs/custom/backbone-lodash-monkeypatch.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/39b77db74230c821bcfe10e299d0e98a990c92e8', 'message': ""Fix for thisArg in Backbone lodash monkeypatch\n\nIt turns out that thisArg was not taken into account when applying the\nlodash functions which resulted in wrong 'this' argument in the inner function\nof such calls:\n\nnodes.filter(function(node) { ... }, this);\n\nRelated-Bug: #1281076\nChange-Id: I85b57bab488072b3e1d1f3990fcb231e77cf4645\n""}]",0,143102,39b77db74230c821bcfe10e299d0e98a990c92e8,13,5,2,13445,,,0,"Fix for thisArg in Backbone lodash monkeypatch

It turns out that thisArg was not taken into account when applying the
lodash functions which resulted in wrong 'this' argument in the inner function
of such calls:

nodes.filter(function(node) { ... }, this);

Related-Bug: #1281076
Change-Id: I85b57bab488072b3e1d1f3990fcb231e77cf4645
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/02/143102/2 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/js/libs/custom/backbone-lodash-monkeypatch.js'],1,799209389dd93952f31d21173aae73e7c8d90ae9,bug/1281076," Backbone.Collection.prototype[method] = function() { var args = [].slice.call(arguments), predicate = args[0]; args[0] = function(model) { args.unshift(this.models); return _[method].apply(_, args);"," Backbone.Collection.prototype[method] = function(predicate) { var pred = predicate; pred = function(model) { return _[method].apply(_, [this.models, pred]);",7,4
openstack%2Fneutron-specs~master~Iff70cbfddbe1b73b905c6c4c948757ea9551a0ca,openstack/neutron-specs,master,Iff70cbfddbe1b73b905c6c4c948757ea9551a0ca,Add LP link,MERGED,2014-12-19 14:38:25.000000000,2014-12-19 16:57:33.000000000,2014-12-19 16:57:32.000000000,"[{'_account_id': 3}, {'_account_id': 261}]","[{'number': 1, 'created': '2014-12-19 14:38:25.000000000', 'files': ['specs/kilo/pydev-debugger-support.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/97f59966575544ca2536d73e4dc6a293b0075576', 'message': 'Add LP link\n\nChange-Id: Iff70cbfddbe1b73b905c6c4c948757ea9551a0ca\n'}]",0,143101,97f59966575544ca2536d73e4dc6a293b0075576,6,2,1,105,,,0,"Add LP link

Change-Id: Iff70cbfddbe1b73b905c6c4c948757ea9551a0ca
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/01/143101/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/pydev-debugger-support.rst'],1,97f59966575544ca2536d73e4dc6a293b0075576,fix-pydev,https://blueprints.launchpad.net/neutron/+spec/pydev-debugger-support ,,2,0
openstack%2Fneutron-specs~master~Icae1f646d1de87837b4e4d5720a8b3b4e9c2784c,openstack/neutron-specs,master,Icae1f646d1de87837b4e4d5720a8b3b4e9c2784c,Fix the LP link for the pecan spec,MERGED,2014-12-19 14:35:46.000000000,2014-12-19 16:56:13.000000000,2014-12-19 16:56:12.000000000,"[{'_account_id': 3}, {'_account_id': 261}]","[{'number': 1, 'created': '2014-12-19 14:35:46.000000000', 'files': ['specs/kilo/pecan-switch.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/187539bba939848947ea8e76d03eb07b445dc1e7', 'message': 'Fix the LP link for the pecan spec\n\nChange-Id: Icae1f646d1de87837b4e4d5720a8b3b4e9c2784c\n'}]",0,143099,187539bba939848947ea8e76d03eb07b445dc1e7,6,2,1,105,,,0,"Fix the LP link for the pecan spec

Change-Id: Icae1f646d1de87837b4e4d5720a8b3b4e9c2784c
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/99/143099/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/pecan-switch.rst'],1,187539bba939848947ea8e76d03eb07b445dc1e7,fix-wsgi,https://blueprints.launchpad.net/neutron/+spec/wsgi-pecan-switch,https://blueprints.launchpad.net/neutron/+spec/pecan-switch,1,1
openstack%2Fkeystonemiddleware~master~I9ec6b1e5d242a336774ed1a7154f5b19148954e3,openstack/keystonemiddleware,master,I9ec6b1e5d242a336774ed1a7154f5b19148954e3,Add a test to ensure no HTTP call for no token,ABANDONED,2014-12-19 16:39:09.000000000,2014-12-19 16:54:44.000000000,,[],"[{'number': 1, 'created': '2014-12-19 16:39:09.000000000', 'files': ['keystonemiddleware/tests/test_auth_token_middleware.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/6359ff8e205ac42e69a87302194928dca336f699', 'message': ""Add a test to ensure no HTTP call for no token\n\nThere was no test to ensure that when a request is made and there's\nno token in the request that the auth_token middleware doesn't make\nan HTTP request.\n\nSome other OpenStack projects' unit tests rely on this behavior.\n\nPartial-Bug: #1404294\nChange-Id: I9ec6b1e5d242a336774ed1a7154f5b19148954e3\n""}]",0,143134,6359ff8e205ac42e69a87302194928dca336f699,3,0,1,6486,,,0,"Add a test to ensure no HTTP call for no token

There was no test to ensure that when a request is made and there's
no token in the request that the auth_token middleware doesn't make
an HTTP request.

Some other OpenStack projects' unit tests rely on this behavior.

Partial-Bug: #1404294
Change-Id: I9ec6b1e5d242a336774ed1a7154f5b19148954e3
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/34/143134/1 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/tests/test_auth_token_middleware.py'],1,6359ff8e205ac42e69a87302194928dca336f699,bug/1404294," def test_auth_with_no_token_does_not_call_http(self): self.set_middleware() req = webob.Request.blank('/') self.middleware(req.environ, self.start_fake_response) self.assertLastPath(None) self.assertEqual(401, self.response_status) ",,7,0
openstack%2Fmagnum~master~I9bdeabf5efcead9a5b51779b89cc6dd9552defad,openstack/magnum,master,I9bdeabf5efcead9a5b51779b89cc6dd9552defad,Fix external_network_id,MERGED,2014-12-18 10:13:51.000000000,2014-12-19 16:53:42.000000000,2014-12-19 16:53:42.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-18 10:13:51.000000000', 'files': ['magnum/api/controllers/v1/baymodel.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/0dc370a4624219f6585e61c0249025a2b84468d1', 'message': 'Fix external_network_id\n\nMake external_network be external_network_id to match the rest of the system.\n\nChange-Id: I9bdeabf5efcead9a5b51779b89cc6dd9552defad\n'}]",0,142712,0dc370a4624219f6585e61c0249025a2b84468d1,7,2,1,2834,,,0,"Fix external_network_id

Make external_network be external_network_id to match the rest of the system.

Change-Id: I9bdeabf5efcead9a5b51779b89cc6dd9552defad
",git fetch https://review.opendev.org/openstack/magnum refs/changes/12/142712/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/api/controllers/v1/baymodel.py'],1,0dc370a4624219f6585e61c0249025a2b84468d1,, external_network_id = wtypes.text, external_network = wtypes.text,1,1
openstack%2Fgnocchi~master~Ic09cd51dbc03c8acec76878b66758ed3363d0019,openstack/gnocchi,master,Ic09cd51dbc03c8acec76878b66758ed3363d0019,_carbonara: fix futures import,MERGED,2014-12-19 15:46:57.000000000,2014-12-19 16:49:20.000000000,2014-12-19 16:49:19.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2014-12-19 15:46:57.000000000', 'files': ['gnocchi/storage/_carbonara.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/a03badaf4fa908bff1b687c7ed1a116756828c6d', 'message': '_carbonara: fix futures import\n\nThis method is deprecated.\n\nChange-Id: Ic09cd51dbc03c8acec76878b66758ed3363d0019\n'}]",0,143121,a03badaf4fa908bff1b687c7ed1a116756828c6d,6,2,1,1669,,,0,"_carbonara: fix futures import

This method is deprecated.

Change-Id: Ic09cd51dbc03c8acec76878b66758ed3363d0019
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/21/143121/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/storage/_carbonara.py'],1,a03badaf4fa908bff1b687c7ed1a116756828c6d,jd/fix-futures,from concurrent import futures,import futures,1,1
openstack%2Fironic-inspector~master~Ibcfe90875805ac31d5c36a7e9f8a7fb6b4bd6397,openstack/ironic-inspector,master,Ibcfe90875805ac31d5c36a7e9f8a7fb6b4bd6397,Add option to overwrite existing properties,MERGED,2014-12-19 16:00:33.000000000,2014-12-19 16:34:45.000000000,2014-12-19 16:34:45.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-12-19 16:00:33.000000000', 'files': ['ironic_discoverd/plugins/standard.py', 'ironic_discoverd/conf.py', 'example.conf', 'ironic_discoverd/test/test_process.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/4a7c33f1d4502abf958921b8a82fcc7feffc8639', 'message': 'Add option to overwrite existing properties\n\nRequested by Ironic upstream, disabled by default.\n\nChange-Id: Ibcfe90875805ac31d5c36a7e9f8a7fb6b4bd6397\nCloses-Bug: #1396604\n'}]",0,143124,4a7c33f1d4502abf958921b8a82fcc7feffc8639,7,3,1,10239,,,0,"Add option to overwrite existing properties

Requested by Ironic upstream, disabled by default.

Change-Id: Ibcfe90875805ac31d5c36a7e9f8a7fb6b4bd6397
Closes-Bug: #1396604
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/24/143124/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_discoverd/plugins/standard.py', 'ironic_discoverd/conf.py', 'example.conf', 'ironic_discoverd/test/test_process.py']",4,4a7c33f1d4502abf958921b8a82fcc7feffc8639,bug/1396604," def test_overwrite(self, filters_mock, post_hook_mock): conf.CONF.set('discoverd', 'overwrite_existing', 'true') patch = [ {'path': '/properties/cpus', 'value': '2', 'op': 'add'}, {'path': '/properties/cpu_arch', 'value': 'x86_64', 'op': 'add'}, {'path': '/properties/memory_mb', 'value': '1024', 'op': 'add'}, {'path': '/properties/local_gb', 'value': '20', 'op': 'add'}] self.call() self.cli.node.update.assert_any_call(self.uuid, patch) self.cli.node.update.assert_any_call(self.uuid, self.patch_after) ",,20,1
openstack%2Fmonasca-agent~master~I7ceab560fae2e37de7453b3896f8d7aadddd55cb,openstack/monasca-agent,master,I7ceab560fae2e37de7453b3896f8d7aadddd55cb,Fixed perc calculations to be 0->100 rather than < 1,MERGED,2014-12-19 16:09:28.000000000,2014-12-19 16:20:18.000000000,2014-12-19 16:20:17.000000000,"[{'_account_id': 3}, {'_account_id': 12108}]","[{'number': 1, 'created': '2014-12-19 16:09:28.000000000', 'files': ['monagent/collector/checks/system/unix.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/110781ca0c5b30ebc9b5ee91e0c2d876fe45f42c', 'message': 'Fixed perc calculations to be 0->100 rather than < 1\n\nChange-Id: I7ceab560fae2e37de7453b3896f8d7aadddd55cb\n'}]",0,143125,110781ca0c5b30ebc9b5ee91e0c2d876fe45f42c,6,2,1,11094,,,0,"Fixed perc calculations to be 0->100 rather than < 1

Change-Id: I7ceab560fae2e37de7453b3896f8d7aadddd55cb
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/25/143125/1 && git format-patch -1 --stdout FETCH_HEAD,['monagent/collector/checks/system/unix.py'],1,110781ca0c5b30ebc9b5ee91e0c2d876fe45f42c,, (memData['mem.usable_mb']) / float(memData['mem.total_mb']) * 100) (memData['mem.swap_free_mb']) / float(memData['mem.swap_total_mb']) * 100), memData['mem.usable_perc'] = memData['mem.total_mb'] - memData['mem.free_mb'] memData['mem.usable_mb']) / float(memData['mem.total_mb']) memData['mem.swap_free_mb']) / float(memData['mem.swap_total_mb']),2,3
openstack%2Fglance~master~I19f65a1b2a556f5c5a873c68e6fe34c76e5ddf7c,openstack/glance,master,I19f65a1b2a556f5c5a873c68e6fe34c76e5ddf7c,Prevent image creation without container format,ABANDONED,2014-01-13 18:15:37.000000000,2014-12-19 16:02:49.000000000,,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 8158}, {'_account_id': 8871}, {'_account_id': 9236}, {'_account_id': 9410}, {'_account_id': 9751}, {'_account_id': 10725}, {'_account_id': 11258}]","[{'number': 1, 'created': '2014-01-13 18:15:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9535171a6972c26dc1e0b76ba3b6a9bc1090e98b', 'message': 'Prevent image creation without container format\n\nChange-Id: I19f65a1b2a556f5c5a873c68e6fe34c76e5ddf7c\nCloses-Bug: #1268680\n'}, {'number': 2, 'created': '2014-01-13 18:39:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1d8d3d4fbc399114a67ba800f7516df747d1f1f4', 'message': 'Prevent image creation without container format\n\nChange-Id: I19f65a1b2a556f5c5a873c68e6fe34c76e5ddf7c\nCloses-Bug: #1268680\n'}, {'number': 3, 'created': '2014-02-11 22:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7a2c811498d0ec896dcc8b6e392256b9d7caf8cf', 'message': 'Prevent image creation without container format\n\nChange-Id: I19f65a1b2a556f5c5a873c68e6fe34c76e5ddf7c\nCloses-Bug: #1268680\n'}, {'number': 4, 'created': '2014-02-11 23:30:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7e44ad1518ed6314519d32ef12ae4fee451faba6', 'message': 'Prevent image creation without container format\n\nChange-Id: I19f65a1b2a556f5c5a873c68e6fe34c76e5ddf7c\nCloses-Bug: #1268680\n'}, {'number': 5, 'created': '2014-04-16 17:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e83c0611f45c953b00f53a449079e9b2b646ecb0', 'message': 'Prevent image creation without container format\n\nChange-Id: I19f65a1b2a556f5c5a873c68e6fe34c76e5ddf7c\nCloses-Bug: #1268680\n'}, {'number': 6, 'created': '2014-05-22 17:00:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2f8868ec103105efee63e7b6e2532a88f939e69b', 'message': 'Prevent image creation without container format\n\nChange-Id: I19f65a1b2a556f5c5a873c68e6fe34c76e5ddf7c\nCloses-Bug: #1268680\n'}, {'number': 7, 'created': '2014-05-29 21:33:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/efcf725ee8f941362eac4ae0c7bb47e4755f0bb6', 'message': 'Prevent image creation without container format\n\nThis patch requires the user to provide a container format for all image\ncreate and update operations.  The disk format logic remains unchanged,\nalthough it could easily be updated to follow the same behaviour.\n\nThere is one exception when a container format can be missing, when\na disk format matches one of the amazon formats.  In this case, the\ncontainer format is assumed to be the same as disk format.\n\nChange-Id: I19f65a1b2a556f5c5a873c68e6fe34c76e5ddf7c\nCloses-Bug: #1268680\n'}, {'number': 8, 'created': '2014-06-04 18:30:37.000000000', 'files': ['glance/tests/unit/v1/test_api.py', 'glance/api/v1/images.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/ee4f52e4413faf9b1545660e467d933d39a66643', 'message': 'Prevent image creation without container format\n\nThis patch requires the user to provide a container format for all image\ncreate and update operations.  The disk format logic remains unchanged,\nalthough it could easily be updated to follow the same behaviour.\n\nThere is one exception when a container format can be missing, when\na disk format matches one of the amazon formats.  In this case, the\ncontainer format is assumed to be the same as disk format.\n\nChange-Id: I19f65a1b2a556f5c5a873c68e6fe34c76e5ddf7c\nCloses-Bug: #1268680\n'}]",21,66386,ee4f52e4413faf9b1545660e467d933d39a66643,71,12,8,9236,,,0,"Prevent image creation without container format

This patch requires the user to provide a container format for all image
create and update operations.  The disk format logic remains unchanged,
although it could easily be updated to follow the same behaviour.

There is one exception when a container format can be missing, when
a disk format matches one of the amazon formats.  In this case, the
container format is assumed to be the same as disk format.

Change-Id: I19f65a1b2a556f5c5a873c68e6fe34c76e5ddf7c
Closes-Bug: #1268680
",git fetch https://review.opendev.org/openstack/glance refs/changes/86/66386/8 && git format-patch -1 --stdout FETCH_HEAD,['glance/api/v1/images.py'],1,9535171a6972c26dc1e0b76ba3b6a9bc1090e98b,lp/1268680," LOG.warning(""raising exception"") raise HTTPBadRequest(explanation=msg, request=req) else: msg = ""Missing container format for image."" LOG.warning(""raising exception"")",,5,0
openstack%2Fneutron~master~Ie63e6e04bbb4e9799685770d53c3c2a799447f4f,openstack/neutron,master,Ie63e6e04bbb4e9799685770d53c3c2a799447f4f,Block subnet gateway IP to be used as LB VIP,ABANDONED,2014-11-10 07:12:26.000000000,2014-12-19 15:57:42.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 7921}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9828}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10068}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 12215}, {'_account_id': 12621}, {'_account_id': 13051}]","[{'number': 1, 'created': '2014-11-10 07:12:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/488906fff8c5421c46beaf95d56a50b3ed01385f', 'message': 'Block subnet gateway IP to be used as LB VIP\n\nThis fix raises an IpAddressInUse exception when subnet gateway IP is assigned\nto a loadbalancer VIP.\n\nFor a neutron network that is connected to a hardware router, its subnet\ngateway IP address is not associated with a neutron port. But neutron allows\nuser to set this gateway IP as a loadbalancer VIP.  When both the router and LB\nVIP uses the same IP address, traffic to and from the subnet may not reach its\nintended destination.\n\nChange-Id: Ie63e6e04bbb4e9799685770d53c3c2a799447f4f\nCloses-Bug: 1391059\n'}, {'number': 2, 'created': '2014-11-13 06:29:36.000000000', 'files': ['neutron/db/loadbalancer/loadbalancer_db.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0415d7352ee6419d2bdbb6260f977178d2b82532', 'message': 'Block subnet gateway IP to be used as LB VIP\n\nThis fix raises an IpAddressInUse exception when subnet gateway IP is assigned\nto a loadbalancer VIP.\n\nFor a neutron network that is connected to a hardware router, its subnet\ngateway IP address is not associated with a neutron port. But neutron allows\nuser to set this gateway IP as a loadbalancer VIP.  When both the router and LB\nVIP uses the same IP address, traffic to and from the subnet may not reach its\nintended destination.\n\nChange-Id: Ie63e6e04bbb4e9799685770d53c3c2a799447f4f\nCloses-Bug: 1391059\n'}]",4,133399,0415d7352ee6419d2bdbb6260f977178d2b82532,57,30,2,12621,,,0,"Block subnet gateway IP to be used as LB VIP

This fix raises an IpAddressInUse exception when subnet gateway IP is assigned
to a loadbalancer VIP.

For a neutron network that is connected to a hardware router, its subnet
gateway IP address is not associated with a neutron port. But neutron allows
user to set this gateway IP as a loadbalancer VIP.  When both the router and LB
VIP uses the same IP address, traffic to and from the subnet may not reach its
intended destination.

Change-Id: Ie63e6e04bbb4e9799685770d53c3c2a799447f4f
Closes-Bug: 1391059
",git fetch https://review.opendev.org/openstack/neutron refs/changes/99/133399/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/loadbalancer/loadbalancer_db.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py']",2,488906fff8c5421c46beaf95d56a50b3ed01385f,bug/1391059, def test_create_vip_with_gateway_ip(self): with testtools.ExpectedException(webob.exc.HTTPClientError): self.test_create_vip(address='10.0.0.1') ,,8,0
openstack%2Fnova~master~Id6b3ecde499e9b54804175d635b89e62c1fed804,openstack/nova,master,Id6b3ecde499e9b54804175d635b89e62c1fed804,Cleanup in ResourceExtension ALIAS(v2.1api),MERGED,2014-12-17 02:54:38.000000000,2014-12-19 15:57:03.000000000,2014-12-19 15:56:59.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 9578}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11189}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-12-17 02:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/27c108016acfc3bab8fb840223954ed344b449c0', 'message': 'Cleanup in ResourceExtension ALIAS(v2.1api)\n\nUse global variables ALIAS in ResourceExtension if the the alias of the\nextension happen to be the same as ALIAS.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Id6b3ecde499e9b54804175d635b89e62c1fed804\n'}, {'number': 2, 'created': '2014-12-17 06:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6765fd6734a3d3a72390bdb64ab2cab1702c8daf', 'message': 'Cleanup in ResourceExtension ALIAS(v2.1api)\n\nUse global variables ALIAS in ResourceExtension if the the alias of the\nextension happen to be the same as ALIAS.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Id6b3ecde499e9b54804175d635b89e62c1fed804\n'}, {'number': 3, 'created': '2014-12-17 07:55:13.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/certificates.py', 'nova/api/openstack/compute/plugins/v3/migrations.py', 'nova/api/openstack/compute/plugins/v3/console_auth_tokens.py', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/api/openstack/compute/plugins/v3/aggregates.py', 'nova/api/openstack/compute/plugins/v3/networks.py', 'nova/api/openstack/compute/plugins/v3/security_groups.py', 'nova/api/openstack/compute/plugins/v3/hosts.py', 'nova/api/openstack/compute/plugins/v3/extension_info.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8aa259ae9dbefbea871610cd7df19d924b1d6e8e', 'message': ""Cleanup in ResourceExtension ALIAS(v2.1api)\n\nAdd global variables ALIAS if it's not existing and use it in\nResourceExtension if the the alias of the extension happen to be\nthe same as ALIAS.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: Id6b3ecde499e9b54804175d635b89e62c1fed804\n""}]",3,142312,8aa259ae9dbefbea871610cd7df19d924b1d6e8e,29,12,3,11189,,,0,"Cleanup in ResourceExtension ALIAS(v2.1api)

Add global variables ALIAS if it's not existing and use it in
ResourceExtension if the the alias of the extension happen to be
the same as ALIAS.

Partially implements blueprint v2-on-v3-api

Change-Id: Id6b3ecde499e9b54804175d635b89e62c1fed804
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/142312/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/certificates.py', 'nova/api/openstack/compute/plugins/v3/instance_usage_audit_log.py', 'nova/api/openstack/compute/plugins/v3/console_auth_tokens.py', 'nova/api/openstack/compute/plugins/v3/migrations.py', 'nova/api/openstack/compute/plugins/v3/networks.py', 'nova/api/openstack/compute/plugins/v3/security_groups.py', 'nova/api/openstack/compute/plugins/v3/hosts.py']",7,27c108016acfc3bab8fb840223954ed344b449c0,bp/v2-on-v3-api," resources = [extensions.ResourceExtension(ALIAS,"," resources = [extensions.ResourceExtension('os-hosts',",8,8
openstack%2Fheat~master~Ic52fa855ccafff506585d8a7ef973142dc862ac2,openstack/heat,master,Ic52fa855ccafff506585d8a7ef973142dc862ac2,"Add a ""show_hidden"" parameter to stack-list",ABANDONED,2014-11-19 22:13:42.000000000,2014-12-19 15:49:50.000000000,,"[{'_account_id': 3}, {'_account_id': 7253}]","[{'number': 1, 'created': '2014-11-19 22:13:42.000000000', 'files': ['heat/rpc/client.py', 'heat/db/api.py', 'heat/rpc/api.py', 'heat/db/sqlalchemy/api.py', 'heat/engine/stack.py', 'heat/api/openstack/v1/stacks.py', 'heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/060f34dea904a56af74e843f66f3a3aa74182d45', 'message': 'Add a ""show_hidden"" parameter to stack-list\n\nblueprint hidden-stacks\n\nChange-Id: Ic52fa855ccafff506585d8a7ef973142dc862ac2\n'}]",0,135743,060f34dea904a56af74e843f66f3a3aa74182d45,5,2,1,7253,,,0,"Add a ""show_hidden"" parameter to stack-list

blueprint hidden-stacks

Change-Id: Ic52fa855ccafff506585d8a7ef973142dc862ac2
",git fetch https://review.opendev.org/openstack/heat refs/changes/43/135743/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/rpc/client.py', 'heat/db/api.py', 'heat/rpc/api.py', 'heat/db/sqlalchemy/api.py', 'heat/engine/stack.py', 'heat/api/openstack/v1/stacks.py', 'heat/engine/service.py']",7,060f34dea904a56af74e843f66f3a3aa74182d45,bp/hidden-stacks," show_deleted=False, show_hidden=False, show_nested=False): show_hidden=show_hidden, show_deleted=False, show_hidden=False, show_nested=False): show_hidden=show_hidden,"," show_deleted=False, show_nested=False): show_deleted=False, show_nested=False):",42,18
openstack%2Fheat~master~Iab0d025ccefbc5822adee0d6e2795a69304d86bb,openstack/heat,master,Iab0d025ccefbc5822adee0d6e2795a69304d86bb,"Add a ""hidden"" parameter to stack-create",ABANDONED,2014-11-19 22:13:42.000000000,2014-12-19 15:49:46.000000000,,"[{'_account_id': 3}, {'_account_id': 7253}]","[{'number': 1, 'created': '2014-11-19 22:13:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4f90ae428bc9077ed765d2bc26029209fb2e683c', 'message': 'Add a ""hidden"" parameter to stack-create\n\nblueprint hidden-stacks\n\nChange-Id: Iab0d025ccefbc5822adee0d6e2795a69304d86bb\n'}, {'number': 2, 'created': '2014-11-21 22:07:11.000000000', 'files': ['heat/engine/api.py', 'heat/rpc/api.py', 'heat/tests/test_parser.py', 'heat/engine/stack.py', 'heat/tests/test_engine_api_utils.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/3949169f385a4837ff5603fb3b01659624ad9007', 'message': 'Add a ""hidden"" parameter to stack-create\n\nblueprint hidden-stacks\n\nChange-Id: Iab0d025ccefbc5822adee0d6e2795a69304d86bb\n'}]",0,135742,3949169f385a4837ff5603fb3b01659624ad9007,9,2,2,7253,,,0,"Add a ""hidden"" parameter to stack-create

blueprint hidden-stacks

Change-Id: Iab0d025ccefbc5822adee0d6e2795a69304d86bb
",git fetch https://review.opendev.org/openstack/heat refs/changes/42/135742/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/api.py', 'heat/rpc/api.py', 'heat/engine/stack.py']",3,4f90ae428bc9077ed765d2bc26029209fb2e683c,bp/hidden-stacks," use_stored_context=False, username=None, hidden=False, self.hidden = hidden 'nested_depth': self.nested_depth, 'hidden': self.hidden"," use_stored_context=False, username=None, 'nested_depth': self.nested_depth",10,4
openstack%2Fheat~master~I2899e0e1caeb183bf9f79901117718f1fdd0aca2,openstack/heat,master,I2899e0e1caeb183bf9f79901117718f1fdd0aca2,"Add ""hidden"" column to stack table",ABANDONED,2014-11-19 22:13:42.000000000,2014-12-19 15:49:42.000000000,,"[{'_account_id': 3}, {'_account_id': 7253}, {'_account_id': 7256}]","[{'number': 1, 'created': '2014-11-19 22:13:42.000000000', 'files': ['heat/db/sqlalchemy/migrate_repo/versions/049_stack_hidden.py', 'heat/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/e70feeb3e94703511e814acc480cb304f4820572', 'message': 'Add ""hidden"" column to stack table\n\nblueprint hidden-stacks\n\nChange-Id: I2899e0e1caeb183bf9f79901117718f1fdd0aca2\n'}]",0,135741,e70feeb3e94703511e814acc480cb304f4820572,6,3,1,7253,,,0,"Add ""hidden"" column to stack table

blueprint hidden-stacks

Change-Id: I2899e0e1caeb183bf9f79901117718f1fdd0aca2
",git fetch https://review.opendev.org/openstack/heat refs/changes/41/135741/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/db/sqlalchemy/migrate_repo/versions/049_stack_hidden.py', 'heat/db/sqlalchemy/models.py']",2,e70feeb3e94703511e814acc480cb304f4820572,bp/hidden-stacks," hidden = sqlalchemy.Column('hidden', sqlalchemy.Boolean)",,30,0
openstack%2Fsahara~master~I967aa43f7e1c27b14439db1ab2b7f3cd0f1f9e1b,openstack/sahara,master,I967aa43f7e1c27b14439db1ab2b7f3cd0f1f9e1b,Fix oslo.db import due to move out of the namespace package,MERGED,2014-12-18 10:25:07.000000000,2014-12-19 15:34:42.000000000,2014-12-19 14:01:46.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 6849}, {'_account_id': 7213}, {'_account_id': 7491}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-12-18 10:25:07.000000000', 'files': ['sahara/tests/unit/db/migration/test_migrations_base.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/8ad3a06eba8a739da30e5622633d5f0cd506e434', 'message': 'Fix oslo.db import due to move out of the namespace package\n\noslo.db going to move out of the namespace package soon - see change\nIe96b482b9fbcb1d85203ad35bb65c1f43e912a44 - so we should fix related\nimport in Sahara to avoid of issues after the new release.\n\nChange-Id: I967aa43f7e1c27b14439db1ab2b7f3cd0f1f9e1b\n'}]",3,142718,8ad3a06eba8a739da30e5622633d5f0cd506e434,14,8,1,7491,,,0,"Fix oslo.db import due to move out of the namespace package

oslo.db going to move out of the namespace package soon - see change
Ie96b482b9fbcb1d85203ad35bb65c1f43e912a44 - so we should fix related
import in Sahara to avoid of issues after the new release.

Change-Id: I967aa43f7e1c27b14439db1ab2b7f3cd0f1f9e1b
",git fetch https://review.opendev.org/openstack/sahara refs/changes/18/142718/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/tests/unit/db/migration/test_migrations_base.py'],1,8ad3a06eba8a739da30e5622633d5f0cd506e434,,from oslo.db.sqlalchemy import test_migrations as t_m,import oslo.db.sqlalchemy.test_migrations as t_m,1,1
