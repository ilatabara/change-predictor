id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fheat-templates~master~I062eec8963645f19de42f7348524758f382cffa1,openstack/heat-templates,master,I062eec8963645f19de42f7348524758f382cffa1,Fix Typo in Heat template,MERGED,2014-08-07 09:51:48.000000000,2014-08-11 12:52:29.000000000,2014-08-11 12:52:28.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 7193}, {'_account_id': 8157}, {'_account_id': 8435}, {'_account_id': 8537}, {'_account_id': 10348}]","[{'number': 1, 'created': '2014-08-07 09:51:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/7a1dbbecaf9477a7f9d2107bb3ac36a6bca3cfa5', 'message': 'Fix Typo in Heat template\n\nThis change fixes a typo in the swift.yaml template\nan extra ""s"" was removed in the word resources\n\nChange-Id: I062eec8963645f19de42f7348524758f382cffa1\n'}, {'number': 2, 'created': '2014-08-07 10:33:56.000000000', 'files': ['hot/swift.yaml'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/d917f5150b629a61ffcfe6ac12edff01b486724b', 'message': 'Fix Typo in Heat template\n\nThis change fixes a typo in the swift.yaml template\nan extra ""s"" was removed in the word resources\n\nCloses-Bug: #1353941\nChange-Id: I062eec8963645f19de42f7348524758f382cffa1\n'}]",0,112539,d917f5150b629a61ffcfe6ac12edff01b486724b,19,7,2,10348,,,0,"Fix Typo in Heat template

This change fixes a typo in the swift.yaml template
an extra ""s"" was removed in the word resources

Closes-Bug: #1353941
Change-Id: I062eec8963645f19de42f7348524758f382cffa1
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/39/112539/2 && git format-patch -1 --stdout FETCH_HEAD,['hot/swift.yaml'],1,7a1dbbecaf9477a7f9d2107bb3ac36a6bca3cfa5,bug/1353941,description: Template which creates a Swift container resource,description: Template which creates a Swift container ressource,1,1
openstack%2Ffuel-library~master~I5e1be91199108bd5feec7ef1264e78222e171280,openstack/fuel-library,master,I5e1be91199108bd5feec7ef1264e78222e171280,Remove useless 120 seconds sleep for rabbitmq service,MERGED,2014-08-05 11:28:54.000000000,2014-08-11 12:39:13.000000000,2014-08-11 12:39:12.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}]","[{'number': 1, 'created': '2014-08-05 11:28:54.000000000', 'files': ['deployment/puppet/nova/manifests/rabbitmq.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a6e80f3b4802c19704b549f4b057a1dbbf6e2519', 'message': 'Remove useless 120 seconds sleep for rabbitmq service\n\nChange-Id: I5e1be91199108bd5feec7ef1264e78222e171280\nCloses-bug: #1350031\n'}]",0,111983,a6e80f3b4802c19704b549f4b057a1dbbf6e2519,15,5,1,8786,,,0,"Remove useless 120 seconds sleep for rabbitmq service

Change-Id: I5e1be91199108bd5feec7ef1264e78222e171280
Closes-bug: #1350031
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/83/111983/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nova/manifests/rabbitmq.pp'],1,a6e80f3b4802c19704b549f4b057a1dbbf6e2519,master,, exec { 'waiting for start rabbitmq-master': command => '/bin/sleep 120' } Exec['waiting for start rabbitmq-master'] ->,0,5
openstack%2Ftripleo-image-elements~master~I2f970399109b1396c25cb6e2ef2906310d04c5f8,openstack/tripleo-image-elements,master,I2f970399109b1396c25cb6e2ef2906310d04c5f8,Add new multipath element,MERGED,2014-07-29 16:31:29.000000000,2014-08-11 12:23:22.000000000,2014-08-11 12:23:22.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 1605}, {'_account_id': 1726}, {'_account_id': 6153}, {'_account_id': 6449}, {'_account_id': 6969}, {'_account_id': 8688}, {'_account_id': 10373}, {'_account_id': 10375}]","[{'number': 1, 'created': '2014-07-29 16:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/049811d5b58d9d4f1304405060d89c7c9c72545e', 'message': 'Add new multipath element\n\nProvide an element that provides multipath support allowing a user to\nconfigure multiple I/O paths to storage devices. Typically used with\nSAN storage arrays.\n\nChange-Id: I2f970399109b1396c25cb6e2ef2906310d04c5f8\n'}, {'number': 2, 'created': '2014-07-29 16:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/cdb24f3d280576d0b1ca9bcd73457a87d9cd0312', 'message': 'Add new multipath element\n\nProvide an element that provides multipath support allowing a user to\nconfigure multiple I/O paths to storage devices. Typically used with\nSAN storage arrays.\n\nChange-Id: I2f970399109b1396c25cb6e2ef2906310d04c5f8\n'}, {'number': 3, 'created': '2014-07-29 17:08:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/d00fe8673d5c1f627bb1315a5bc2f1c3eff5b651', 'message': 'Add new multipath element\n\nProvide an element that provides multipath support allowing a user to\nconfigure multiple I/O paths to storage devices. Typically used with\nSAN storage arrays.\n\nChange-Id: I2f970399109b1396c25cb6e2ef2906310d04c5f8\n'}, {'number': 4, 'created': '2014-07-30 07:45:29.000000000', 'files': ['elements/multipath/README.md', 'elements/multipath/files/multipath.conf', 'elements/multipath/pkg-map', 'elements/multipath/install.d/90-multipath'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/2739f348f326e7240192b9e07fa231bd358b62aa', 'message': 'Add new multipath element\n\nProvide an element that provides multipath support allowing a user to\nconfigure multiple I/O paths to storage devices. Typically used with\nSAN storage arrays.\n\nChange-Id: I2f970399109b1396c25cb6e2ef2906310d04c5f8\n'}]",2,110363,2739f348f326e7240192b9e07fa231bd358b62aa,40,10,4,6153,,,0,"Add new multipath element

Provide an element that provides multipath support allowing a user to
configure multiple I/O paths to storage devices. Typically used with
SAN storage arrays.

Change-Id: I2f970399109b1396c25cb6e2ef2906310d04c5f8
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/63/110363/3 && git format-patch -1 --stdout FETCH_HEAD,"['elements/multipath/README.md', 'elements/multipath/files/multipath.conf', 'elements/multipath/pkg-map', 'elements/multipath/install.d/90-multipath']",4,049811d5b58d9d4f1304405060d89c7c9c72545e,multipath,"#!/bin/bash # Copyright 2014 Hewlett-Packard Development Company, L.P. # # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. set -eux install-packages -m multipath multipath_tools_package # default to blacklisting all devices to avoid the installation of multipath # changing the default behaviour of the system. install -m 0440 -o root -g root $(dirname $0)/../files/multipath.conf /etc/multipath.conf ",,49,0
openstack%2Ffuel-web~master~I7d5ea8c14540c4ae9b82e67759ef66ad1c39bfb3,openstack/fuel-web,master,I7d5ea8c14540c4ae9b82e67759ef66ad1c39bfb3,"Added new command to fuel-cli, for deleting node from fuel",MERGED,2014-08-01 13:29:19.000000000,2014-08-11 12:14:30.000000000,2014-08-11 12:14:30.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8797}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 11082}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-08-01 13:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ffe87ed33b1794a249184b5941d23d0b6d6d26e3', 'message': 'Added new command to fuel-cli, for deleting node from fuel\n* added destroy method to Node action\n* added test\n\nChange-Id: I7d5ea8c14540c4ae9b82e67759ef66ad1c39bfb3\nCloses-Bug: #1326116\n'}, {'number': 2, 'created': '2014-08-04 08:30:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/89f93686dab7611f9f7034442e6d8e62ebed1476', 'message': 'Added new command to fuel-cli, for deleting node from fuel\n\n* added destroy method to Node action\n* added test\n\nChange-Id: I7d5ea8c14540c4ae9b82e67759ef66ad1c39bfb3\nCloses-Bug: #1326116\n'}, {'number': 3, 'created': '2014-08-04 09:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d25b8992d43f797051e9508814feed3795777a74', 'message': 'Added new command to fuel-cli, for deleting node from fuel\n\n* added destroy method to Node action\n* added test\n\nChange-Id: I7d5ea8c14540c4ae9b82e67759ef66ad1c39bfb3\nCloses-Bug: #1326116\n'}, {'number': 4, 'created': '2014-08-04 09:49:57.000000000', 'files': ['fuelclient/fuelclient/cli/arguments.py', 'fuelclient/fuelclient/objects/node.py', 'fuelclient/fuelclient/cli/actions/node.py', 'fuelclient/tests/test_client.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3053ea80f9ff3328bbcdf5c5b5b6be4d6b4e2ed7', 'message': 'Added new command to fuel-cli, for deleting node from fuel\n\n* added destroy method to Node action\n* added test\n\nChange-Id: I7d5ea8c14540c4ae9b82e67759ef66ad1c39bfb3\nCloses-Bug: #1326116\n'}]",12,111277,3053ea80f9ff3328bbcdf5c5b5b6be4d6b4e2ed7,39,10,4,11082,,,0,"Added new command to fuel-cli, for deleting node from fuel

* added destroy method to Node action
* added test

Change-Id: I7d5ea8c14540c4ae9b82e67759ef66ad1c39bfb3
Closes-Bug: #1326116
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/77/111277/2 && git format-patch -1 --stdout FETCH_HEAD,"['fuelclient/fuelclient/cli/arguments.py', 'fuelclient/fuelclient/objects/node.py', 'fuelclient/fuelclient/cli/actions/node.py', 'fuelclient/tests/test_client.py']",4,ffe87ed33b1794a249184b5941d23d0b6d6d26e3,bug/1326116," "" --deploy | --destroy | --provision]"", ""-h"", ""--help"", "" -s"", ""--default"", "" -d"", ""--download"", "" -u"", ""--upload"", ""--dir"", ""--node"", ""--node-id"", "" -r"", ""--role"", ""--net""] def test_destroy_node(self): self.load_data_to_nailgun_server() self.run_cli_commands(( ""env create --name=NewEnv --release=1"", ""--env-id=1 node set --node 1 --role=controller"" )) msg = ""Node with id [1] has been deleted from fuel.\n"" self.check_for_stdout( ""node --node 1 --destroy"", msg ) "," "" --deploy | --provision]"", ""-h"", ""--help"", "" -s"", ""--default"", "" -d"", ""--download"", "" -u"", ""--upload"", ""--dir"", ""--node"", ""--node-id"", "" -r"", ""--role"", ""--net""]",37,3
openstack%2Ffuel-web~master~I782045a559a72c74655dc492aa961c2d723fefc6,openstack/fuel-web,master,I782045a559a72c74655dc492aa961c2d723fefc6,Modified the password and user arguments in fuel-cli to work correctly,MERGED,2014-08-06 07:45:42.000000000,2014-08-11 12:14:05.000000000,2014-08-11 12:14:04.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-08-06 07:45:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/757480d2e53cb673c28c23e553f1888eb6df01e0', 'message': 'Modified the credential arguments in fuel-cli to work correctly\n\nChange-Id: I782045a559a72c74655dc492aa961c2d723fefc6\nCloses-Bug: #1348395\n'}, {'number': 2, 'created': '2014-08-06 07:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c220fc241c6245923077342ed3c6f0afdccd7125', 'message': 'Modified the credential arguments in fuel-cli to work correctly\n\nChange-Id: I782045a559a72c74655dc492aa961c2d723fefc6\nCloses-Bug: #1352420\n'}, {'number': 3, 'created': '2014-08-06 08:44:03.000000000', 'files': ['fuelclient/fuelclient/cli/parser.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3899a49a2105c0278a372418f96d81ee7c8eb09b', 'message': 'Modified the password and user arguments in fuel-cli to work correctly\n\nChange-Id: I782045a559a72c74655dc492aa961c2d723fefc6\nCloses-Bug: #1352420\n'}]",0,112231,3899a49a2105c0278a372418f96d81ee7c8eb09b,29,8,3,11082,,,0,"Modified the password and user arguments in fuel-cli to work correctly

Change-Id: I782045a559a72c74655dc492aa961c2d723fefc6
Closes-Bug: #1352420
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/31/112231/3 && git format-patch -1 --stdout FETCH_HEAD,['fuelclient/fuelclient/cli/parser.py'],1,757480d2e53cb673c28c23e553f1888eb6df01e0,bug/1352420,," self.universal_flags.append(""--os-username"") action=""store"", self.universal_flags.append(""--os-password"") action=""store"",",0,4
openstack%2Ftempest~master~I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab,openstack/tempest,master,I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab,Add scenario test for load balancer's health monitor,ABANDONED,2014-04-28 20:01:23.000000000,2014-08-11 12:08:34.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4694}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6447}, {'_account_id': 7293}, {'_account_id': 7317}, {'_account_id': 7428}, {'_account_id': 8556}, {'_account_id': 8576}, {'_account_id': 8625}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9461}, {'_account_id': 10385}]","[{'number': 17, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/804d5f74b5c217fd5fbfad5af48dba2da3cdcc1e', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Suspend one instance and make sure it's marked as INACTIVE\n    7. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nAdd _create_health_monitor and _associate_health_monitor_with_pool\nmethods to tempest/scenario/manager.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 16, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a602728dca54aa253b584c22bf56d38cc2013687', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Suspend one instance and make sure it's marked as INACTIVE\n    7. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nAdd _create_health_monitor and _associate_health_monitor_with_pool\nmethods to tempest/scenario/manager.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 19, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6c73fdf684d066ef08701b906ae6b9ebe7e61701', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Suspend one instance and make sure it's marked as INACTIVE\n    7. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 18, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3fe2695424751f8e64669d47e7ac5f5fd8c6f667', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Suspend one instance and make sure it's marked as INACTIVE\n    7. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 21, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5f2c0f0f7473302339d0b13413f142c5533814d7', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Suspend one instance and make sure it's marked as INACTIVE\n    7. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 20, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c24c536d8071dc9bea8891139619a213f920e63b', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Suspend one instance and make sure it's marked as INACTIVE\n    7. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 23, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4790019027a79b02249a00ddb24356c5c5175365', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Suspend one instance and make sure it's marked as INACTIVE\n    7. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 22, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/be5df2f07e9c3b281a0c28d60cf992b282b4c813', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Suspend one instance and make sure it's marked as INACTIVE\n    7. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 25, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5d698a11751d0d1be925c2c4c24005081c33084e', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Suspend one instance and make sure it's marked as INACTIVE\n    7. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 24, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5ffd49015692e9868d3ede2bc2dc4049bcc018ac', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Suspend one instance and make sure it's marked as INACTIVE\n    7. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 27, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/42dafb29161f3846a14d000ac7ac0a16a3cbac42', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Check that both members answer requests\n    7. Suspend one instance and make sure it's marked as INACTIVE\n    8. Check that only the ACTIVE member answers requests\n    9. Resume the suspended instance and check it's ACTIVE again\n    10. Check that both members answer requests again.\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\nAdd get_pids method to tempest/common/utils/linux/remote_client.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 26, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/421326df3c75b7b9f84578f6236c27599ce36f0e', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Check that both members answer requests\n    7. Suspend one instance and make sure it's marked as INACTIVE\n    8. Check that only the ACTIVE member answers requests\n    9. Resume the suspended instance and check it's ACTIVE again\n    10. Check that both members answer requests again.\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\nAdd get_pids method to tempest/common/utils/linux/remote_client.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 29, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4562d5d39f367adaf4200c01fede2cdc4b0badc3', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Check that both members answer requests\n    7. Suspend one instance and make sure it's marked as INACTIVE\n    8. Check that only the ACTIVE member answers requests\n    9. Resume the suspended instance and check it's ACTIVE again\n    10. Check that both members answer requests again.\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\nAdd get_pids method to tempest/common/utils/linux/remote_client.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 28, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8d9ede8d49e4868dd9ec859ae6e401c75164d2e7', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Check that both members answer requests\n    7. Suspend one instance and make sure it's marked as INACTIVE\n    8. Check that only the ACTIVE member answers requests\n    9. Resume the suspended instance and check it's ACTIVE again\n    10. Check that both members answer requests again.\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\nAdd get_pids method to tempest/common/utils/linux/remote_client.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 31, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ac3e8b5f8cd5ebac88837bb662d00e6a403e89bc', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Check that both members answer requests\n    7. Suspend one instance and make sure it's marked as INACTIVE\n    8. Check that only the ACTIVE member answers requests\n    9. Resume the suspended instance and check it's ACTIVE again\n    10. Check that both members answer requests again.\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 30, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a2510d8097f0fa62ef8f06d27726a890bf2f4124', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Check that both members answer requests\n    7. Suspend one instance and make sure it's marked as INACTIVE\n    8. Check that only the ACTIVE member answers requests\n    9. Resume the suspended instance and check it's ACTIVE again\n    10. Check that both members answer requests again.\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/39133b2070bb2342a36c02e6a6397b612a230a24', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n  1. Create two instances\n  2. Create a load balancer with two members and with ROUND_ROBIN algorithm\n  3. SSH to the instances and start two servers\n  4. Check that the health monitor marked the members as ACTIVE\n  5. Suspend one instance and make sure it's marked as INACTIVE\n  6. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nAdd _create_health_monitor and _associate_health_monitor_with_pool\nmethods to tempest/scenario/manager.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 3, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e63f08136fc9ae2321a9b585b891ada4d89d1abe', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n  1. Create two instances\n  2. Create a load balancer with two members and with ROUND_ROBIN algorithm\n  3. SSH to the instances and start two servers\n  4. Check that the health monitor marked the members as ACTIVE\n  5. Suspend one instance and make sure it's marked as INACTIVE\n  6. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nAdd _create_health_monitor and _associate_health_monitor_with_pool\nmethods to tempest/scenario/manager.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 2, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0522f90fd43e7c7facabbde5d2a93f784284f4a7', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n  1. Create two instances\n  2. Create a load balancer with two members and with ROUND_ROBIN algorithm\n  3. SSH to the instances and start two servers\n  4. Check that the health monitor marked the members as ACTIVE\n  5. Suspend one instance and make sure it's marked as INACTIVE\n  6. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nAdd _create_health_monitor and _associate_health_monitor_with_pool\nmethods to tempest/scenario/manager.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 5, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/354ceae0c9c1ae8af63ca977e105001d817c4fb3', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n  1. Create two instances\n  2. Create a load balancer with two members and with ROUND_ROBIN algorithm\n  3. SSH to the instances and start two servers\n  4. Check that the health monitor marked the members as ACTIVE\n  5. Suspend one instance and make sure it's marked as INACTIVE\n  6. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nAdd _create_health_monitor and _associate_health_monitor_with_pool\nmethods to tempest/scenario/manager.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 4, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/634e2171fcc74c4758019b218943b80937ce81b6', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n  1. Create two instances\n  2. Create a load balancer with two members and with ROUND_ROBIN algorithm\n  3. SSH to the instances and start two servers\n  4. Check that the health monitor marked the members as ACTIVE\n  5. Suspend one instance and make sure it's marked as INACTIVE\n  6. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nAdd _create_health_monitor and _associate_health_monitor_with_pool\nmethods to tempest/scenario/manager.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 7, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6c0caf205d87cc8c17225ccf40792a519cd6c86b', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n  1. Create two instances\n  2. Create a load balancer with two members and with ROUND_ROBIN algorithm\n  3. SSH to the instances and start two servers\n  4. Check that the health monitor marked the members as ACTIVE\n  5. Suspend one instance and make sure it's marked as INACTIVE\n  6. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nAdd _create_health_monitor and _associate_health_monitor_with_pool\nmethods to tempest/scenario/manager.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 6, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b4dd0f0a179fab02fb052377d56a987ed06a6927', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n  1. Create two instances\n  2. Create a load balancer with two members and with ROUND_ROBIN algorithm\n  3. SSH to the instances and start two servers\n  4. Check that the health monitor marked the members as ACTIVE\n  5. Suspend one instance and make sure it's marked as INACTIVE\n  6. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nAdd _create_health_monitor and _associate_health_monitor_with_pool\nmethods to tempest/scenario/manager.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 9, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bdb17a84554576f1ead62d7431b2d0d46d2d9d38', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n  1. Create two instances\n  2. Create a load balancer with two members and with ROUND_ROBIN algorithm\n  3. SSH to the instances and start two servers\n  4. Check that the health monitor marked the members as ACTIVE\n  5. Suspend one instance and make sure it's marked as INACTIVE\n  6. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nAdd _create_health_monitor and _associate_health_monitor_with_pool\nmethods to tempest/scenario/manager.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 8, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5c5b7892e43cdef50fa7b5286f326b6962657c40', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n  1. Create two instances\n  2. Create a load balancer with two members and with ROUND_ROBIN algorithm\n  3. SSH to the instances and start two servers\n  4. Check that the health monitor marked the members as ACTIVE\n  5. Suspend one instance and make sure it's marked as INACTIVE\n  6. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nAdd _create_health_monitor and _associate_health_monitor_with_pool\nmethods to tempest/scenario/manager.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 11, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e638eb550a8f35df863ca8c0f65b8c2a412c5e4c', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Suspend one instance and make sure it's marked as INACTIVE\n    7. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nAdd _create_health_monitor and _associate_health_monitor_with_pool\nmethods to tempest/scenario/manager.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 10, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d4c318c28ac012c585d0cb31495e2ffc6981ba10', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n  1. Create two instances\n  2. SSH to the instances and start two servers\n  3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n  4. Check that the health monitor marked the members as ACTIVE\n  5. Suspend one instance and make sure it's marked as INACTIVE\n  6. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nAdd _create_health_monitor and _associate_health_monitor_with_pool\nmethods to tempest/scenario/manager.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 13, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e8fe47a9116f8e1e95499c94fc23c14476f52ea9', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Suspend one instance and make sure it's marked as INACTIVE\n    7. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nAdd _create_health_monitor and _associate_health_monitor_with_pool\nmethods to tempest/scenario/manager.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 12, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a9f8c8c45c4b91ab9ef31119f012d39c0f7ce2bd', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Suspend one instance and make sure it's marked as INACTIVE\n    7. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nAdd _create_health_monitor and _associate_health_monitor_with_pool\nmethods to tempest/scenario/manager.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 15, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7bf31116e9311b9cc3b60d7ce7c35514a8d44019', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Suspend one instance and make sure it's marked as INACTIVE\n    7. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nAdd _create_health_monitor and _associate_health_monitor_with_pool\nmethods to tempest/scenario/manager.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 14, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3ee6c3745732966a8ca148b775be6e0914748ebc', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Suspend one instance and make sure it's marked as INACTIVE\n    7. Resume the suspended instance and check it's ACTIVE again\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nAdd _create_health_monitor and _associate_health_monitor_with_pool\nmethods to tempest/scenario/manager.py\n\nbp lbaas-scenario-tests\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 32, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/40daeaed3f9fdac34822069317b750caf6dc05a1', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Check that both members answer requests\n    7. Suspend one instance and make sure it's marked as INACTIVE\n    8. Check that only the ACTIVE member answers requests\n    9. Resume the suspended instance and check it's ACTIVE again\n    10. Check that both members answer requests again.\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 33, 'created': '2014-05-06 15:14:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/22ce672e287a125a05b66d91c83e571d0094714b', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Check that both members answer requests\n    7. Suspend one instance and make sure it's marked as INACTIVE\n    8. Check that only the ACTIVE member answers requests\n    9. Resume the suspended instance and check it's ACTIVE again\n    10. Check that both members answer requests again.\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 34, 'created': '2014-05-14 15:42:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/45d06e8fcba8b0d0fdb0ae5137273cd216864a56', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Check that both members answer requests\n    7. Suspend one instance and make sure it's marked as INACTIVE\n    8. Check that only the ACTIVE member answers requests\n    9. Resume the suspended instance and check it's ACTIVE again\n    10. Check that both members answer requests again.\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}, {'number': 35, 'created': '2014-05-20 10:25:28.000000000', 'files': ['tempest/scenario/manager.py', 'tempest/scenario/test_load_balancer_basic.py', 'tempest/api/network/common.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/14da6ceff1a16d04db107d382bb737150f299ca9', 'message': ""Add scenario test for load balancer's health monitor\n\nThis test checks load balancing with a health monitor.\n\nThe following is the scenario outline:\n    1. Create two instances\n    2. SSH to the instances and start two servers\n    3. Create a load balancer with two members and with ROUND_ROBIN algorithm\n    4. Create a health monitor and associate it with the created pool\n    5. Check that the health monitor marked the members as ACTIVE\n    6. Check that both members answer requests\n    7. Suspend one instance and make sure it's marked as INACTIVE\n    8. Check that only the ACTIVE member answers requests\n    9. Resume the suspended instance and check it's ACTIVE again\n    10. Check that both members answer requests again.\n\nAdd DeletableHealthMonitor class to tempest/api/network/common.py\n\nChange-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab\n""}]",63,59729,14da6ceff1a16d04db107d382bb737150f299ca9,295,18,35,7293,,,0,"Add scenario test for load balancer's health monitor

This test checks load balancing with a health monitor.

The following is the scenario outline:
    1. Create two instances
    2. SSH to the instances and start two servers
    3. Create a load balancer with two members and with ROUND_ROBIN algorithm
    4. Create a health monitor and associate it with the created pool
    5. Check that the health monitor marked the members as ACTIVE
    6. Check that both members answer requests
    7. Suspend one instance and make sure it's marked as INACTIVE
    8. Check that only the ACTIVE member answers requests
    9. Resume the suspended instance and check it's ACTIVE again
    10. Check that both members answer requests again.

Add DeletableHealthMonitor class to tempest/api/network/common.py

Change-Id: I5f4df4ce20b7635fb020cd4fc81b0f96cfc383ab
",git fetch https://review.opendev.org/openstack/tempest refs/changes/29/59729/17 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/manager.py', 'tempest/scenario/test_load_balancer_basic.py', 'tempest/api/network/common.py']",3,804d5f74b5c217fd5fbfad5af48dba2da3cdcc1e,test_hm, class DeletableHealthMonitor(DeletableResource): def delete(self): self.client.delete_health_monitor(self.id),,207,58
openstack%2Ftempest~master~I3bd6b42d9e07db797222aa654ac423b1a5aa49e1,openstack/tempest,master,I3bd6b42d9e07db797222aa654ac423b1a5aa49e1,Add scenario test for load balancer's session persistence,ABANDONED,2013-12-17 14:30:18.000000000,2014-08-11 12:08:17.000000000,,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 2750}, {'_account_id': 4694}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 7293}, {'_account_id': 7428}, {'_account_id': 8556}, {'_account_id': 8576}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10385}]","[{'number': 1, 'created': '2013-12-17 14:30:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8927c0b8d09d164fe118d2df81a40f6cacce0fb7', 'message': 'Test load balancer session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot two instances\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool\n\nbp lbaas-scenario-tests\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n'}, {'number': 2, 'created': '2013-12-19 15:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8469a090cf92ac85fa603d560a0b5dae05443527', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot two instances\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n\nbp lbaas-scenario-tests\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 3, 'created': '2013-12-24 10:56:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bc49209fb9b885a186361f2abec062c9efcfb84f', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot two instances\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n\nbp lbaas-scenario-tests\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 4, 'created': '2013-12-26 10:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9ded22c18c24e458e9e9fc407b53a2dfe65d1294', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot an instance\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n\nbp lbaas-scenario-tests\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 5, 'created': '2014-01-17 08:05:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7c226fb0f0ba736e64da8254825eae2ee73f64bb', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot an instance\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n\nbp lbaas-scenario-tests\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 6, 'created': '2014-02-18 15:00:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b0180b55ad84b2b564824eb19f9d53158a43c7fd', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot an instance\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n\nbp lbaas-scenario-tests\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 7, 'created': '2014-02-24 11:28:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0439b68912daf7bf8d5db35aaef07aaf05d0065f', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot an instance\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n\nbp lbaas-scenario-tests\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 8, 'created': '2014-03-04 12:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/803679ed026fab273911d8365218d647b4bf5257', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot an instance\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n\nbp lbaas-scenario-tests\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 9, 'created': '2014-03-17 16:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1d6e06e392466e9af94dbbf8c855e4fc902b2313', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot an instance\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n\nbp lbaas-scenario-tests\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 11, 'created': '2014-03-24 14:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d8d6de172fa4e36d0d026161bb2d094a799f49d3', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot an instance\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n\nbp lbaas-scenario-tests\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 10, 'created': '2014-03-24 14:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/00cc0549170f88cd164b25da0639d60b004fd6ba', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot an instance\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n\nbp lbaas-scenario-tests\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 12, 'created': '2014-04-07 12:18:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d2e20020d826ef1d7a3257636ea93cdfb372d5d7', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot an instance\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n\nbp lbaas-scenario-tests\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 13, 'created': '2014-04-07 12:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5864007961769956d8d14a1299e997c5724c553d', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot an instance\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n    8. Turn session persistence off and check that the requests\n       are again distributed according to the ROUND_ROBIN algorithm\n\nbp lbaas-scenario-tests\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 14, 'created': '2014-04-08 12:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2541ba0025a3ee416420a8f8483477e1f503b767', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot an instance\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n    8. Turn session persistence off and check that the requests\n       are again distributed according to the ROUND_ROBIN algorithm\n\nbp lbaas-scenario-tests\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 15, 'created': '2014-04-09 12:29:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d49e6e7a212b90c41c03f8d4070c7633cde819f2', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot an instance\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n    8. Turn session persistence off and check that the requests\n       are again distributed according to the ROUND_ROBIN algorithm\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 17, 'created': '2014-04-09 13:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8556b0b7c54174c1559f3da74916f229ebd556d4', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot an instance\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n    8. Turn session persistence off and check that the requests\n       are again distributed according to the ROUND_ROBIN algorithm\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 16, 'created': '2014-04-09 13:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/da60dfc24ffc3f970e7accbd75a836945f9d347f', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot an instance\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n    8. Turn session persistence off and check that the requests\n       are again distributed according to the ROUND_ROBIN algorithm\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 18, 'created': '2014-05-06 15:29:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1f3fa942df0d7fc433b34a2420b3da0f277b35c1', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot an instance\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n    8. Turn session persistence off and check that the requests\n       are again distributed according to the ROUND_ROBIN algorithm\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 19, 'created': '2014-05-14 15:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c045148ee6872da3c7194b41d0789dd9201c5c1d', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot an instance\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n    8. Turn session persistence off and check that the requests\n       are again distributed according to the ROUND_ROBIN algorithm\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}, {'number': 20, 'created': '2014-05-20 10:30:13.000000000', 'files': ['tempest/scenario/manager.py', 'tempest/scenario/test_load_balancer_basic.py', 'tempest/api/network/common.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/6ee5b29c6f4ffdf658e1be77a79ab9716f2c12cb', 'message': ""Add scenario test for load balancer's session persistence\n\nTest session persistence feature of load balancer.\n\nThe following is the scenario outline:\n    1. Boot an instance\n    2. Create a load balancer with two members, with ROUND_ROBIN\n       algorithm and SOURCE_IP session persistence type.\n    3. Send 10 requests to the floating ip, associated with the VIP,\n       and make sure all the requests from the same ip\n       are proceesed by the same member of the pool.\n    4. Change session persistence type of the VIP to HTTP_COOKIE.\n    5. Check that this session persistence type also forces all\n       the requests containing the same cookie to hit the same\n       member of the pool.\n    6. Change session persistence type of the VIP to APP_COOKIE.\n    7. Perform the same check.\n    8. Turn session persistence off and check that the requests\n       are again distributed according to the ROUND_ROBIN algorithm\n\nChange-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1\n""}]",15,62662,6ee5b29c6f4ffdf658e1be77a79ab9716f2c12cb,178,15,20,7293,,,0,"Add scenario test for load balancer's session persistence

Test session persistence feature of load balancer.

The following is the scenario outline:
    1. Boot an instance
    2. Create a load balancer with two members, with ROUND_ROBIN
       algorithm and SOURCE_IP session persistence type.
    3. Send 10 requests to the floating ip, associated with the VIP,
       and make sure all the requests from the same ip
       are proceesed by the same member of the pool.
    4. Change session persistence type of the VIP to HTTP_COOKIE.
    5. Check that this session persistence type also forces all
       the requests containing the same cookie to hit the same
       member of the pool.
    6. Change session persistence type of the VIP to APP_COOKIE.
    7. Perform the same check.
    8. Turn session persistence off and check that the requests
       are again distributed according to the ROUND_ROBIN algorithm

Change-Id: I3bd6b42d9e07db797222aa654ac423b1a5aa49e1
",git fetch https://review.opendev.org/openstack/tempest refs/changes/62/62662/7 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/manager.py', 'tempest/scenario/neutron_lbaas/test_lb_session_persistence.py', 'tempest/scenario/neutron_lbaas/lbaas_manager.py']",3,8927c0b8d09d164fe118d2df81a40f6cacce0fb7,test_sesion_persistence," def _create_vip(self, persistence_type): subnet_id, pool_id, persistence_type= persistence_type) assign_floating_ip=True, persistence_type=None): self._create_vip(persistence_type)"," def _create_vip(self): subnet_id, pool_id) assign_floating_ip=True): self._create_vip()",135,5
openstack%2Fsahara-specs~master~I7b44ed96f78811ee93ef2ee83bc8d7ae0ce6bb41,openstack/sahara-specs,master,I7b44ed96f78811ee93ef2ee83bc8d7ae0ce6bb41,Added spec for provisioning error handling,MERGED,2014-07-03 21:53:34.000000000,2014-08-11 12:03:26.000000000,2014-08-11 12:03:26.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7109}, {'_account_id': 7555}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-07-03 21:53:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/87b9b156a5774c5888e79b511132661374365975', 'message': 'Added spec for provisioning error handling\n\nblueprint error-handling-in-provisioning\n\nChange-Id: I7b44ed96f78811ee93ef2ee83bc8d7ae0ce6bb41\n'}, {'number': 2, 'created': '2014-08-04 19:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/bcd7d34a04a7b4ca72f9ad03b3930c88fc2fda05', 'message': 'Added spec for provisioning error handling\n\nblueprint error-handling-in-provisioning\n\nChange-Id: I7b44ed96f78811ee93ef2ee83bc8d7ae0ce6bb41\n'}, {'number': 3, 'created': '2014-08-04 19:30:45.000000000', 'files': ['specs/juno/error-handling-in-provisioning.rst'], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/b20de7fddabdd1300925cc117e0c8f713eb0540c', 'message': 'Added spec for provisioning error handling\n\nblueprint error-handling-in-provisioning\n\nChange-Id: I7b44ed96f78811ee93ef2ee83bc8d7ae0ce6bb41\n'}]",4,104700,b20de7fddabdd1300925cc117e0c8f713eb0540c,33,7,3,8411,,,0,"Added spec for provisioning error handling

blueprint error-handling-in-provisioning

Change-Id: I7b44ed96f78811ee93ef2ee83bc8d7ae0ce6bb41
",git fetch https://review.opendev.org/openstack/sahara-specs refs/changes/00/104700/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/error-handling-in-provisioning.rst'],1,87b9b156a5774c5888e79b511132661374365975,bp/error-handling-in-provisioning,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Example Spec - The title of your blueprint ========================================== https://blueprints.launchpad.net/sahara/+spec/error-handling-in-provisioning Currently provisioning error handling is sprayed across the whole provisioning code. This spec is to unify error handling and localize it in one place. Problem description =================== Currently we have two problems connected with error handling in provisioning part: 1) The code incorrectly handles situations when cluster was deleted by user during provisioning. In that case an arbitrary error might be raised in many places. 2) The code performs rollback only in certain places, while it could be done for any provisioning/scaling phase. The following CR: https://review.openstack.org/#/c/98556 mostly fixes issue #1, but it is full of duplicate code. Proposed change =============== The following solution is proposed instead which requires architectural changes, but rather reliably fixes both problems: 1) For both cluster creation and scaling move error handling logic to the very top functions inside ops.py file. Once exception is caught properly process it: a) if cluster object does not exists in DB, that means that user deleted the cluster during provisioning; handle it and return b) if cluster object exists, log it and perform rollback 2) Do not do any checks if cluster exists outside of ops.py, except places where processing might hang indefinitely without the check. We can employ the following rollback strategy: For cluster creation: if anything went wrong, kill all VMs and move cluster to the Error state. For cluster scaling: that will be long. Cluster scaling has the following stages: 1) decommission unneeded nodes (by plugin) 2) terminate unneeded nodes and create a new ones if needed (by engine). Note that both scaling up and down could be run simultaneously but in different node groups. 3) Configure and start nodes (by plugin) My suggestion what to do if an exception occurred in the respective stage: 1) move cluster to Error state 2) kill unneeded nodes (finish scale down). Also kill new nodes, if they were created for scale up. 3) move cluster to Error state In cases #1 and #3 it is dangerous to delete not decommissioned or not configured nodes as this can lead to data loss. Alternatives ------------ Keep supporting current code. It is not elegant but works good enough. Data model impact ----------------- None REST API impact --------------- None Other end user impact --------------------- Data provisioning logic will be changed a lot. This could lead to behavior change in case of errors on different stages. Deployer impact --------------- None Developer impact ---------------- Provisioning engine API will be extended with ""rollback_cluster"" method. Sahara-image-elements impact ---------------------------- None Sahara-dashboard / Horizon impact --------------------------------- None Implementation ============== Assignee(s) ----------- Primary assignee: alazarev Other contributors: dmitrymex Work Items ---------- 1) Implement chnage 2) Test that cluster provisioning and rollback works on all feature matrix we have. Dependencies ============ None Testing ======= Provisioning could be tested manually and by CI. It is much harder to test rollback. Even current code is not tested well (e.g. https://bugs.launchpad.net/sahara/+bug/1337006). Documentation Impact ==================== None References ========== None",,154,0
openstack%2Ffuel-library~master~I68d08660120ad373b52a42e8bad650f805c6372b,openstack/fuel-library,master,I68d08660120ad373b52a42e8bad650f805c6372b,add an ability to pass optional neutron parameters from CLI,MERGED,2014-07-24 12:40:24.000000000,2014-08-11 11:55:44.000000000,2014-08-11 11:55:44.000000000,"[{'_account_id': 3}, {'_account_id': 6072}, {'_account_id': 7125}, {'_account_id': 7604}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}]","[{'number': 1, 'created': '2014-07-24 12:40:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c482ce16cb38104c9192f64c5eb782b76c2749bb', 'message': 'add an ability to pass important neutron parameters from astute.yaml\n\nby CLI\n\nChange-Id: I68d08660120ad373b52a42e8bad650f805c6372b\nCloses-bug: #1348149\n'}, {'number': 2, 'created': '2014-07-29 15:02:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d4e830c5a66363106aa9b83013c7c4bb0a91d294', 'message': 'add an ability to pass important neutron parameters from astute.yaml\n\nby CLI\n\nChange-Id: I68d08660120ad373b52a42e8bad650f805c6372b\nCloses-bug: #1348149\n'}, {'number': 3, 'created': '2014-07-30 10:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/887fce62742b79a6e3a708d394e67ed590f6faff', 'message': 'add an ability to pass important neutron parameters from astute.yaml\n\nby CLI\n\nChange-Id: I68d08660120ad373b52a42e8bad650f805c6372b\nCloses-bug: #1348149\n'}, {'number': 4, 'created': '2014-07-30 15:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/046dfbf908cf74c024d673f3e88a658c753da663', 'message': 'add an ability to pass optional neutron parameters from CLI\n\n- added parameters are required for production environments because they affects Neutron performance.\nThey allows to increase the number of api, rpc and metadata workers.\n\nChange-Id: I68d08660120ad373b52a42e8bad650f805c6372b\nCloses-bug: #1348149\n'}, {'number': 5, 'created': '2014-07-31 08:06:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ece81f42ac19d05d8b4fe73cbf215ff9263e50a9', 'message': 'add an ability to pass optional neutron parameters from CLI\n\n- added parameters are required for production environments because they affect Neutron performance.\nThey allows to increase the number of api, rpc and metadata workers.\n\nChange-Id: I68d08660120ad373b52a42e8bad650f805c6372b\nCloses-bug: #1348149\n'}, {'number': 6, 'created': '2014-08-11 09:32:27.000000000', 'files': ['deployment/puppet/neutron/manifests/server.pp', 'deployment/puppet/neutron/lib/puppet/parser/functions/sanitize_neutron_config.rb', 'deployment/puppet/neutron/manifests/agents/metadata.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d162226de292f5f296bf28865f905ddf1a3ddc51', 'message': 'add an ability to pass optional neutron parameters from CLI\n\n- added parameters are required for production environments because they affect Neutron performance.\nThey allows to increase the number of api, rpc and metadata workers.\n\nChange-Id: I68d08660120ad373b52a42e8bad650f805c6372b\nCloses-bug: #1348149\n'}]",0,109274,d162226de292f5f296bf28865f905ddf1a3ddc51,52,7,6,7468,,,0,"add an ability to pass optional neutron parameters from CLI

- added parameters are required for production environments because they affect Neutron performance.
They allows to increase the number of api, rpc and metadata workers.

Change-Id: I68d08660120ad373b52a42e8bad650f805c6372b
Closes-bug: #1348149
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/74/109274/6 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/neutron/manifests/server.pp', 'deployment/puppet/neutron/lib/puppet/parser/functions/sanitize_neutron_config.rb', 'deployment/puppet/neutron/manifests/agents/metadata.pp']",3,c482ce16cb38104c9192f64c5eb782b76c2749bb,master," 'DEFAULT/metadata_workers': value => $neutron_config['metadata']['workers'] ? { default => $neutron_config['metadata']['workers'], undef => min($::processorcount + 0, 50 + 0) }; 'DEFAULT/metadata_backlog': value => $neutron_config['metadata']['backlog'];"," 'DEFAULT/metadata_workers': value => min($::processorcount + 0, 50 + 0); 'DEFAULT/metadata_backlog': value => 2048;",17,4
openstack%2Fnova~master~Ic240b877d8e7afeb32adf3dc3899a55396cf7210,openstack/nova,master,Ic240b877d8e7afeb32adf3dc3899a55396cf7210,Add API schema for v2.1/v3 security_groups extension,MERGED,2014-01-27 10:31:06.000000000,2014-08-11 11:54:09.000000000,2014-08-11 09:50:51.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 9533}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-01-27 10:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9923e87e9c54a96bcdf3e57bdf4182925e0b797c', 'message': 'Add API schema for v3 security_groups extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: Ic240b877d8e7afeb32adf3dc3899a55396cf7210\n'}, {'number': 2, 'created': '2014-02-05 08:15:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/86b08dd6005c7b13fc3ef7ed3131e192f2d76386', 'message': 'Add API schema for v3 security_groups extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: Ic240b877d8e7afeb32adf3dc3899a55396cf7210\n'}, {'number': 3, 'created': '2014-02-05 10:13:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8c841acf633d7b6ec7e514ff79ae4f3ca0a2a9ca', 'message': 'Add API schema for v3 security_groups extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: Ic240b877d8e7afeb32adf3dc3899a55396cf7210\n'}, {'number': 4, 'created': '2014-02-06 10:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f6e95ab5be633d183e3991a63e869d315a1b82ac', 'message': 'Add API schema for v3 security_groups extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: Ic240b877d8e7afeb32adf3dc3899a55396cf7210\n'}, {'number': 5, 'created': '2014-02-06 12:21:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aa3b104416fab404b1b607fb7418bcf0aabf50e2', 'message': 'Add API schema for v3 security_groups extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: Ic240b877d8e7afeb32adf3dc3899a55396cf7210\n'}, {'number': 6, 'created': '2014-02-07 04:47:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cefcf185712c61e9b3c1297ad0a8639e4534888b', 'message': 'Add API schema for v3 security_groups extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: Ic240b877d8e7afeb32adf3dc3899a55396cf7210\n'}, {'number': 7, 'created': '2014-02-17 02:51:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5a9ae81d6a2531ceea19a058753a76b27e4221f4', 'message': 'Add API schema for v3 security_groups extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint nova-api-validation-fw\n\nChange-Id: Ic240b877d8e7afeb32adf3dc3899a55396cf7210\n'}, {'number': 8, 'created': '2014-06-18 06:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/16d3caa6722f501d6e436c0e0fe0cd2e185bfeb2', 'message': 'Add API schema for v2.1/v3 security_groups extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v3-api-schema\n\nChange-Id: Ic240b877d8e7afeb32adf3dc3899a55396cf7210\n'}, {'number': 9, 'created': '2014-08-07 01:10:16.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_security_groups.py', 'nova/api/openstack/compute/plugins/v3/security_groups.py', 'nova/api/openstack/compute/schemas/v3/security_groups.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b26cbdd4874c672c07092a5e72833b119aebca3b', 'message': 'Add API schema for v2.1/v3 security_groups extension\n\nBy defining the API schema, it is possible to separate the validation\ncode from the API method. The API method can be more simple.\nIn addition, a response of API validation error can be consistent for\nthe whole Nova API.\n\nPartially implements blueprint v3-api-schema\n\nChange-Id: Ic240b877d8e7afeb32adf3dc3899a55396cf7210\n'}]",9,69316,b26cbdd4874c672c07092a5e72833b119aebca3b,107,9,9,9533,,,0,"Add API schema for v2.1/v3 security_groups extension

By defining the API schema, it is possible to separate the validation
code from the API method. The API method can be more simple.
In addition, a response of API validation error can be consistent for
the whole Nova API.

Partially implements blueprint v3-api-schema

Change-Id: Ic240b877d8e7afeb32adf3dc3899a55396cf7210
",git fetch https://review.opendev.org/openstack/nova refs/changes/16/69316/9 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/plugins/v3/test_security_groups.py', 'nova/api/openstack/compute/plugins/v3/security_groups.py', 'nova/api/openstack/compute/schemas/v3/security_groups.py']",3,9923e87e9c54a96bcdf3e57bdf4182925e0b797c,bp/v3-api-schema,"# Copyright 2014 NEC Corporation. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. server_create = { 'os-security-groups:security_groups': { 'type': 'array', 'items': { 'type': 'object', 'properties': { 'name': {'type': 'string', 'maxLength': 255}, }, 'additionalProperties': False, } }, } ",,61,0
openstack%2Fsahara~master~I6a82a9dfdf704da16ed709c650fa68f9527fd668,openstack/sahara,master,I6a82a9dfdf704da16ed709c650fa68f9527fd668,Migration to oslo.utils,MERGED,2014-07-31 14:20:23.000000000,2014-08-11 11:50:50.000000000,2014-08-11 11:44:31.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 12038}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-07-31 14:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ce6dd5bdc104c4c63980f5903f8539ebd83239d3', 'message': 'Migrate to oslo.utils instead of copy-pasted utils\n\nThe oslo.utils 0.1.1 is now released and added to global requirements,\nso, we could migrate to it.\n\nChange-Id: I6a82a9dfdf704da16ed709c650fa68f9527fd668\n'}, {'number': 2, 'created': '2014-07-31 15:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/4c597cd177883adac38a63fb6d561eef78a19ac4', 'message': 'Migrate to oslo.utils instead of copy-pasted utils\n\nThe oslo.utils 0.1.1 is now released and added to global requirements,\nso, we could migrate to it.\n\nChange-Id: I6a82a9dfdf704da16ed709c650fa68f9527fd668\n'}, {'number': 3, 'created': '2014-08-07 13:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/fd6be984a66908df66c3fe9c01a6de1df996945d', 'message': 'Migration to oslo.utils\n\nCommon code from sahara.openstack.common.db was replaced\nby usage of oslo.utils library.\nsahara/openstack/common/network_utils.py module was removed.\nexcutils.py, importutils.py, timeutils.py and importutils.py\nmodules are waiting for migration to oslo.utils in other\noslo-incubator modules and still exist.\n\nChange-Id: I6a82a9dfdf704da16ed709c650fa68f9527fd668\n'}, {'number': 4, 'created': '2014-08-07 13:33:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/bd19277dcc11ee0a3514f67184830d65b2277add', 'message': 'Migration to oslo.utils\n\nCommon code from sahara.openstack.common.db was replaced\nby usage of oslo.utils library.\nsahara/openstack/common/network_utils.py module was removed.\nexcutils.py, importutils.py, timeutils.py and importutils.py\nmodules are waiting for migration to oslo.utils in other\noslo-incubator modules and still exist.\n\nChange-Id: I6a82a9dfdf704da16ed709c650fa68f9527fd668\n'}, {'number': 5, 'created': '2014-08-08 08:01:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/540aec889b39d7dc872621f129e9a9269fe1924a', 'message': 'Migration to oslo.utils\n\nCommon code from sahara.openstack.common.db was replaced\nby usage of oslo.utils library.\nsahara/openstack/common/network_utils.py module was removed.\nexcutils.py, importutils.py, timeutils.py and importutils.py\nmodules are waiting for migration to oslo.utils in other\noslo-incubator modules and still exist.\n\nChange-Id: I6a82a9dfdf704da16ed709c650fa68f9527fd668\n'}, {'number': 6, 'created': '2014-08-08 09:56:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/cb3ccb2a261bc01d0ccd1f6b4c70ddca07d7fe7a', 'message': 'Migration to oslo.utils\n\nCommon code from sahara.openstack.common.db was replaced\nby usage of oslo.utils library.\nsahara/openstack/common/network_utils.py module was removed.\nexcutils.py, importutils.py, timeutils.py and importutils.py\nmodules are waiting for migration to oslo.utils in other\noslo-incubator modules and still exist.\n\nChange-Id: I6a82a9dfdf704da16ed709c650fa68f9527fd668\n'}, {'number': 7, 'created': '2014-08-08 10:30:55.000000000', 'files': ['sahara/plugins/vanilla/hadoop2/scaling.py', 'sahara/tests/integration/tests/edp.py', 'sahara/tests/integration/tests/swift.py', 'sahara/service/heat_engine.py', 'sahara/plugins/spark/scaling.py', 'sahara/tests/integration/tests/cluster_configs.py', 'sahara/tests/integration/tests/scaling.py', 'requirements.txt', 'sahara/service/api.py', 'sahara/tests/unit/service/test_periodic.py', 'openstack-common.conf', 'sahara/plugins/general/utils.py', 'sahara/plugins/vanilla/v1_2_1/scaling.py', 'sahara/service/periodic.py', 'sahara/service/volumes.py', 'sahara/tests/integration/tests/gating/test_hdp_gating.py', 'sahara/tests/integration/tests/gating/test_vanilla_gating.py', 'sahara/db/base.py', 'sahara/openstack/common/network_utils.py', 'sahara/tests/integration/tests/map_reduce.py', 'sahara/tests/integration/tests/vanilla_transient_cluster.py', 'sahara/service/direct_engine.py', 'sahara/utils/ssh_remote.py', 'sahara/tests/integration/tests/base.py', 'sahara/db/migration/alembic_migrations/env.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/9885a98d06a35d67fc31d4badaa723f11c7e1a14', 'message': 'Migration to oslo.utils\n\nCommon code from sahara.openstack.common.db was replaced\nby usage of oslo.utils library.\nsahara/openstack/common/network_utils.py module was removed.\nexcutils.py, importutils.py, timeutils.py and importutils.py\nmodules are waiting for migration to oslo.utils in other\noslo-incubator modules and still exist.\n\nChange-Id: I6a82a9dfdf704da16ed709c650fa68f9527fd668\n'}]",0,110977,9885a98d06a35d67fc31d4badaa723f11c7e1a14,53,8,7,6786,,,0,"Migration to oslo.utils

Common code from sahara.openstack.common.db was replaced
by usage of oslo.utils library.
sahara/openstack/common/network_utils.py module was removed.
excutils.py, importutils.py, timeutils.py and importutils.py
modules are waiting for migration to oslo.utils in other
oslo-incubator modules and still exist.

Change-Id: I6a82a9dfdf704da16ed709c650fa68f9527fd668
",git fetch https://review.opendev.org/openstack/sahara refs/changes/77/110977/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/vanilla/hadoop2/scaling.py', 'sahara/tests/integration/tests/edp.py', 'sahara/tests/integration/tests/swift.py', 'sahara/service/heat_engine.py', 'sahara/plugins/spark/scaling.py', 'sahara/tests/integration/tests/cluster_configs.py', 'sahara/tests/integration/tests/scaling.py', 'requirements.txt', 'sahara/service/api.py', 'sahara/tests/unit/service/test_periodic.py', 'openstack-common.conf', 'sahara/plugins/general/utils.py', 'sahara/plugins/vanilla/v1_2_1/scaling.py', 'sahara/service/periodic.py', 'sahara/service/volumes.py', 'sahara/tests/integration/tests/gating/test_hdp_gating.py', 'sahara/tests/integration/tests/gating/test_vanilla_gating.py', 'sahara/db/base.py', 'sahara/openstack/common/network_utils.py', 'sahara/tests/integration/tests/map_reduce.py', 'sahara/tests/integration/tests/vanilla_transient_cluster.py', 'sahara/service/direct_engine.py', 'sahara/utils/ssh_remote.py', 'sahara/tests/integration/tests/base.py', 'sahara/db/migration/alembic_migrations/env.py']",25,ce6dd5bdc104c4c63980f5903f8539ebd83239d3,oslo.utils,from oslo.utils import importutils,from sahara.openstack.common import importutils,39,189
openstack%2Fsahara~master~I80b79ce78296d26d50737952cafcf2d9fe288938,openstack/sahara,master,I80b79ce78296d26d50737952cafcf2d9fe288938,Updated from global requirements,ABANDONED,2014-08-05 16:55:00.000000000,2014-08-11 11:46:07.000000000,,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-08-05 16:55:00.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/sahara/commit/268b4fecff6231c55802c55f1f266ca728effb66', 'message': 'Updated from global requirements\n\nChange-Id: I80b79ce78296d26d50737952cafcf2d9fe288938\n'}]",0,112078,268b4fecff6231c55802c55f1f266ca728effb66,8,3,1,11131,,,0,"Updated from global requirements

Change-Id: I80b79ce78296d26d50737952cafcf2d9fe288938
",git fetch https://review.opendev.org/openstack/sahara refs/changes/78/112078/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,268b4fecff6231c55802c55f1f266ca728effb66,openstack/requirements,"oslo.config>=1.4.0.0a3oslo.messaging>=1.4.0.0a3python-keystoneclient>=0.10.0python-swiftclient>=2.2.0 python-neutronclient>=2.3.6,<3SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99","oslo.config>=1.2.1oslo.messaging>=1.3.0python-keystoneclient>=0.9.0python-swiftclient>=2.0.2 python-neutronclient>=2.3.5,<3SQLAlchemy>=0.8.4,!=0.9.5,<=0.9.99",6,6
openstack%2Fsahara~master~Icd2e2b7b0b75e88926cb6d355ccf5e03cf5dc423,openstack/sahara,master,Icd2e2b7b0b75e88926cb6d355ccf5e03cf5dc423,Fixed bug with NotFoundException,MERGED,2014-08-08 12:46:07.000000000,2014-08-11 11:42:07.000000000,2014-08-11 11:42:06.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8411}, {'_account_id': 12015}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-08-08 12:46:07.000000000', 'files': ['sahara/exceptions.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/d9fd11658bb0c3415223e9633a1761889cf6b0d4', 'message': 'Fixed bug with NotFoundException\n\nFixed bug with NotFoundException when unsubstituted\nvariable appears instead of given value.\n\nChange-Id: Icd2e2b7b0b75e88926cb6d355ccf5e03cf5dc423\nCloses-bug: #1354421\n'}]",0,112850,d9fd11658bb0c3415223e9633a1761889cf6b0d4,29,7,1,12039,,,0,"Fixed bug with NotFoundException

Fixed bug with NotFoundException when unsubstituted
variable appears instead of given value.

Change-Id: Icd2e2b7b0b75e88926cb6d355ccf5e03cf5dc423
Closes-bug: #1354421
",git fetch https://review.opendev.org/openstack/sahara refs/changes/50/112850/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/exceptions.py'],1,d9fd11658bb0c3415223e9633a1761889cf6b0d4,bug/1354421, else: self.message = self.message % value,,2,0
openstack%2Fmurano-dashboard~master~Ic71e66b4f75b45a707b462c72ec985c981c570d7,openstack/murano-dashboard,master,Ic71e66b4f75b45a707b462c72ec985c981c570d7,Bootstrap 3 upgrade fixes for catalog index,MERGED,2014-08-01 20:15:41.000000000,2014-08-11 11:04:54.000000000,2014-08-11 11:04:54.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7227}, {'_account_id': 7549}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 8040}]","[{'number': 1, 'created': '2014-08-01 20:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/e053e130d52e9f3d079024b0949aac1ff3fc3d96', 'message': 'Bootstrap 3 upgrade fixes for catalog index\n\nMarkup and CSS tweaks to resolve layout and button issues related to\nBootstrap 3 upgrade in Horizon master\n\nChange-Id: Ic71e66b4f75b45a707b462c72ec985c981c570d7\nCloses-Bug: 1350900\n'}, {'number': 2, 'created': '2014-08-04 15:32:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/9836daa94a022f3f2b40d1fabc807936fc382267', 'message': 'Bootstrap 3 upgrade fixes for catalog index\n\nMarkup and CSS tweaks to resolve layout and button issues related to\nBootstrap 3 upgrade in Horizon master\n\nChange-Id: Ic71e66b4f75b45a707b462c72ec985c981c570d7\nCloses-Bug: 1350900\n'}, {'number': 3, 'created': '2014-08-04 22:02:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/dbdcdd6333fceed4feb3c1db4bdafd7622e96b99', 'message': 'Bootstrap 3 upgrade fixes for catalog index\n\nMarkup and CSS tweaks to resolve layout and button issues related to\nBootstrap 3 upgrade in Horizon master and make it more responsive\n\nChange-Id: Ic71e66b4f75b45a707b462c72ec985c981c570d7\nCloses-Bug: 1350900\n'}, {'number': 4, 'created': '2014-08-05 16:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/5593748cecf43625de263ffaf27b26056567fcf5', 'message': 'Bootstrap 3 upgrade fixes for catalog index\n\nMarkup and CSS tweaks to resolve layout and button issues related to\nBootstrap 3 upgrade in Horizon master and make it more responsive\n\nChange-Id: Ic71e66b4f75b45a707b462c72ec985c981c570d7\nCloses-Bug: 1350900\n'}, {'number': 5, 'created': '2014-08-05 16:22:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/22110ec9083cf02d3e257f813a6b97f06ecc04f3', 'message': 'Bootstrap 3 upgrade fixes for catalog index\n\nMarkup and CSS tweaks to resolve layout and button issues related to\nBootstrap 3 upgrade in Horizon master and make it more responsive\n\nChange-Id: Ic71e66b4f75b45a707b462c72ec985c981c570d7\nCloses-Bug: 1350900\n'}, {'number': 6, 'created': '2014-08-05 16:41:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/e60848ef6525515dd2e3f98a6a7331a9b1723560', 'message': 'Bootstrap 3 upgrade fixes for catalog index\n\nMarkup and CSS tweaks to resolve layout and button issues related to\nBootstrap 3 upgrade in Horizon master and make it more responsive\n\nChange-Id: Ic71e66b4f75b45a707b462c72ec985c981c570d7\nCloses-Bug: 1350900\n'}, {'number': 7, 'created': '2014-08-07 16:48:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/4b46019e321809bf8c2de23616f2132bc28dac8d', 'message': 'Bootstrap 3 upgrade fixes for catalog index\n\nMarkup and CSS tweaks to resolve layout and button issues related to\nBootstrap 3 upgrade in Horizon master and make it more responsive\n\nChange-Id: Ic71e66b4f75b45a707b462c72ec985c981c570d7\nCloses-Bug: 1350900\n'}, {'number': 8, 'created': '2014-08-08 17:08:48.000000000', 'files': ['muranodashboard/templates/catalog/index.html', 'muranodashboard/static/muranodashboard/css/catalog.css', 'muranodashboard/templates/catalog/app_tile.html'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/cb965e646859153e715763cd9eb216de2792b028', 'message': 'Bootstrap 3 upgrade fixes for catalog index\n\nMarkup and CSS tweaks to resolve layout and button issues related to\nBootstrap 3 upgrade in Horizon master and make it more responsive\n\nChange-Id: Ic71e66b4f75b45a707b462c72ec985c981c570d7\nCloses-Bug: 1350900\n'}]",4,111380,cb965e646859153e715763cd9eb216de2792b028,57,8,8,11098,,,0,"Bootstrap 3 upgrade fixes for catalog index

Markup and CSS tweaks to resolve layout and button issues related to
Bootstrap 3 upgrade in Horizon master and make it more responsive

Change-Id: Ic71e66b4f75b45a707b462c72ec985c981c570d7
Closes-Bug: 1350900
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/80/111380/5 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/templates/catalog/index.html', 'muranodashboard/static/muranodashboard/css/catalog.css', 'muranodashboard/templates/catalog/app_tile.html', 'muranodashboard/templates/catalog/env_switcher.html']",4,e053e130d52e9f3d079024b0949aac1ff3fc3d96,bug/1350900," <a href=""#environment_switcher"" class=""btn btn-default btn-sm dropdown-toggle"" data-toggle=""dropdown"">{{ environment.name }} {% if num_of_envs > 1 %} <b class=""caret""></b>{% endif %}</a> <a href=""{% url 'horizon:murano:environments:create_environment' %}?next={% url 'horizon:murano:catalog:index' %}"" title=""{% trans 'Click to create an environment' %}"" class=""btn btn-default ajax-modal"">{% trans ""Create Environment"" %}</a> <li class=""divider""></li>"," <a href=""#environment_switcher"" class=""btn btn-small dropdown-toggle"" data-toggle=""dropdown"">{{ environment.name }} {% if num_of_envs > 1 %} <b class=""caret""></b>{% endif %}</a> <a href=""{% url 'horizon:murano:environments:create_environment' %}?next={% url 'horizon:murano:catalog:index' %}"" title=""{% trans 'Click to create an environment' %}"" class=""btn btn-small btn-create ajax-modal"">{% trans ""Create Environment"" %}</a>",79,69
openstack%2Ftripleo-image-elements~master~I2a8a74ef486bb8cebf36a4080069b4414172a653,openstack/tripleo-image-elements,master,I2a8a74ef486bb8cebf36a4080069b4414172a653,Remove a few more `lsb_release -is` calls,ABANDONED,2014-06-30 20:31:33.000000000,2014-08-11 10:44:50.000000000,,"[{'_account_id': 3}, {'_account_id': 741}]","[{'number': 1, 'created': '2014-06-30 20:31:33.000000000', 'files': ['elements/haproxy/os-refresh-config/pre-configure.d/98-haproxy-iptables', 'elements/mysql-migration/os-refresh-config/migration.d/10-bootstrap-mysql', 'elements/nova-baremetal/os-refresh-config/post-configure.d/70-enable-iscsid', 'elements/mysql/os-refresh-config/pre-configure.d/40-mysql', 'elements/iptables/bin/add-rule', 'elements/geard/os-refresh-config/pre-configure.d/97-gearman-iptables', 'elements/heat-cfntools/install.d/10-ec2-user'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9300f29b21bb0a26b813b723e2326b62bc2d5edf', 'message': 'Remove a few more `lsb_release -is` calls\n\nWe update `lsb_release -is` calls to use the DTSTRO_NAME environment\nvariables provided by the operating-system elements.\n\nChange-Id: I2a8a74ef486bb8cebf36a4080069b4414172a653\n'}]",0,103652,9300f29b21bb0a26b813b723e2326b62bc2d5edf,6,2,1,741,,,0,"Remove a few more `lsb_release -is` calls

We update `lsb_release -is` calls to use the DTSTRO_NAME environment
variables provided by the operating-system elements.

Change-Id: I2a8a74ef486bb8cebf36a4080069b4414172a653
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/52/103652/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/haproxy/os-refresh-config/pre-configure.d/98-haproxy-iptables', 'elements/mysql-migration/os-refresh-config/migration.d/10-bootstrap-mysql', 'elements/nova-baremetal/os-refresh-config/post-configure.d/70-enable-iscsid', 'elements/mysql/os-refresh-config/pre-configure.d/40-mysql', 'elements/geard/os-refresh-config/pre-configure.d/97-gearman-iptables', 'elements/iptables/bin/add-rule', 'elements/heat-cfntools/install.d/10-ec2-user']",7,9300f29b21bb0a26b813b723e2326b62bc2d5edf,rmq-ha_mode,"if [ ""$DISTRO_NAME"" != ""ubuntu"" ] ; then","distro=$(lsb_release -is || :) if [ ""$distro"" != ""Ubuntu"" ] ; then",7,19
openstack%2Fdiskimage-builder~master~Ic9770370f5cde1d458f877c142f67a3a9a9ee097,openstack/diskimage-builder,master,Ic9770370f5cde1d458f877c142f67a3a9a9ee097,Remove a few more `lsb_release -is` calls,ABANDONED,2014-06-30 20:25:29.000000000,2014-08-11 10:44:49.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4190}, {'_account_id': 6769}, {'_account_id': 7579}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-06-30 20:25:29.000000000', 'files': ['elements/vm/finalise.d/50-remove-bogus-udev-links', 'elements/vm/finalise.d/51-bootloader'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/408febfebcbb96c78abd11119bc3296d9a55f91c', 'message': 'Remove a few more `lsb_release -is` calls\n\nWe update `lsb_release -is` calls to use the DTSTRO_NAME environment\nvariables provided by the operating-system elements.\n\nChange-Id: Ic9770370f5cde1d458f877c142f67a3a9a9ee097\n'}]",1,103651,408febfebcbb96c78abd11119bc3296d9a55f91c,13,6,1,741,,,0,"Remove a few more `lsb_release -is` calls

We update `lsb_release -is` calls to use the DTSTRO_NAME environment
variables provided by the operating-system elements.

Change-Id: Ic9770370f5cde1d458f877c142f67a3a9a9ee097
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/51/103651/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/vm/finalise.d/50-remove-bogus-udev-links', 'elements/vm/finalise.d/51-bootloader']",2,408febfebcbb96c78abd11119bc3296d9a55f91c,," case $DISTRO_NAME in 'ubuntu'|'debian') 'fedora') 'opensuse') if [ ""$DISTRO_NAME"" = 'fedora' ] ; then"," DIST=`lsb_release -is` [ -n ""$DIST"" ] case $DIST in 'Ubuntu'|'Debian') 'Fedora') 'openSUSE project') if [ ""$DIST"" = 'Fedora' ] ; then",6,8
openstack%2Fmurano-dashboard~master~I50236f5cccd82c420d1c534a4276b776660d54e6,openstack/murano-dashboard,master,I50236f5cccd82c420d1c534a4276b776660d54e6,Fixed issue with incorrect tearDown method,ABANDONED,2014-07-24 08:17:00.000000000,2014-08-11 10:19:45.000000000,,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7227}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 8824}]","[{'number': 1, 'created': '2014-07-24 08:17:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/34eb9a32da3ab8aeb518247944fbe00002d4424f', 'message': ""Fixed issue with incorrect tearDown method\n\ntearDown method will be called only if setUp method\nwas successfully executed before the test.\nNeed to perform some actions even setUp method doesn't\nexecuted successfully.\n\nChange-Id: I50236f5cccd82c420d1c534a4276b776660d54e6\nCloses-Bug: #1348071\n""}, {'number': 2, 'created': '2014-07-24 08:23:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/ecd676ac49d7c26b5723d5ace781c2fca50a1dcf', 'message': ""Fixed issue with incorrect tearDown method\n\ntearDown method will be called only if setUp method\nwas successfully executed before the test.\nNeed to perform some actions even setUp method doesn't\nexecuted successfully and we need use addCleanup method:\n https://docs.python.org/2/library/unittest.html#unittest.TestCase.addCleanup\n\nChange-Id: I50236f5cccd82c420d1c534a4276b776660d54e6\nCloses-Bug: #1348071\n""}, {'number': 3, 'created': '2014-07-24 08:27:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/f5fcaa93c72b3de9b44b18a71ed18fd76db72f32', 'message': ""Fixed issue with incorrect tearDown method\n\ntearDown method will be called only if setUp method\nwas successfully executed before the test.\nNeed to perform some actions even setUp method doesn't\nexecuted successfully and we need use addCleanup method:\n https://docs.python.org/2/library/unittest.html#unittest.TestCase.addCleanup\n\nChange-Id: I50236f5cccd82c420d1c534a4276b776660d54e6\nCloses-Bug: #1348071\n""}, {'number': 4, 'created': '2014-07-24 08:29:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/70ab43e0b56b496eac59d7b8557b92ca8a622d5a', 'message': ""Fixed issue with incorrect tearDown method\n\ntearDown method will be called only if setUp method\nwas successfully executed before the test.\nNeed to perform some actions even setUp method doesn't\nexecuted successfully and we need use addCleanup method:\n https://docs.python.org/2/library/unittest.html#unittest.TestCase.addCleanup\n\nChange-Id: I50236f5cccd82c420d1c534a4276b776660d54e6\nCloses-Bug: #1348071\n""}, {'number': 5, 'created': '2014-07-24 11:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/8a25bb8b6891acbdefe956a272e4d1efbff1031b', 'message': ""Fixed issue with incorrect tearDown method\n\ntearDown method will be called only if setUp method\nwas successfully executed before the test.\nNeed to perform some actions even setUp method doesn't\nexecuted successfully and we need use addCleanup method:\n https://docs.python.org/2/library/unittest.html#unittest.TestCase.addCleanup\n\nChange-Id: I50236f5cccd82c420d1c534a4276b776660d54e6\nCloses-Bug: #1348071\n""}, {'number': 6, 'created': '2014-07-24 12:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/ce10ed17a22722ef0d937a12587a1e13d21cc621', 'message': ""Fixed issue with incorrect tearDown method\n\ntearDown method will be called only if setUp method\nwas successfully executed before the test.\nNeed to perform some actions even setUp method doesn't\nexecuted successfully and we need use addCleanup method:\n https://docs.python.org/2/library/unittest.html#unittest.TestCase.addCleanup\n\nChange-Id: I50236f5cccd82c420d1c534a4276b776660d54e6\nCloses-Bug: #1348071\n""}, {'number': 7, 'created': '2014-07-28 09:33:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/696ce17882ddd88d078f5e093cce3d593af16048', 'message': ""Fixed issue with incorrect tearDown method\n\ntearDown method will be called only if setUp method\nwas successfully executed before the test.\nNeed to perform some actions even setUp method doesn't\nexecuted successfully and we need use addCleanup method:\n https://docs.python.org/2/library/unittest.html#unittest.TestCase.addCleanup\n\nChange-Id: I50236f5cccd82c420d1c534a4276b776660d54e6\nCloses-Bug: #1348071\n""}, {'number': 8, 'created': '2014-07-28 13:25:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/d71d81db262e3e6c8fb254e725e36353c30ce443', 'message': ""Fixed issue with incorrect tearDown method\n\ntearDown method will be called only if setUp method\nwas successfully executed before the test.\nNeed to perform some actions even setUp method doesn't\nexecuted successfully and we need use addCleanup method:\n https://docs.python.org/2/library/unittest.html#unittest.TestCase.addCleanup\n\nChange-Id: I50236f5cccd82c420d1c534a4276b776660d54e6\nCloses-Bug: #1348071\n""}, {'number': 9, 'created': '2014-07-28 13:52:11.000000000', 'files': ['functionaltests/base.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/2f29cfde3c0c52f3f605c7d77fe96f0045293fe7', 'message': ""Fixed issue with incorrect tearDown method\n\ntearDown method will be called only if setUp method\nwas successfully executed before the test.\nNeed to perform some actions even setUp method doesn't\nexecuted successfully and we need use addCleanup method:\n https://docs.python.org/2/library/unittest.html#unittest.TestCase.addCleanup\n\nChange-Id: I50236f5cccd82c420d1c534a4276b776660d54e6\nCloses-Bug: #1348071\n""}]",4,109206,2f29cfde3c0c52f3f605c7d77fe96f0045293fe7,45,9,9,7227,,,0,"Fixed issue with incorrect tearDown method

tearDown method will be called only if setUp method
was successfully executed before the test.
Need to perform some actions even setUp method doesn't
executed successfully and we need use addCleanup method:
 https://docs.python.org/2/library/unittest.html#unittest.TestCase.addCleanup

Change-Id: I50236f5cccd82c420d1c534a4276b776660d54e6
Closes-Bug: #1348071
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/06/109206/6 && git format-patch -1 --stdout FETCH_HEAD,['functionaltests/base.py'],1,34eb9a32da3ab8aeb518247944fbe00002d4424f,(detached, cls.addCleanup(remove_environments) self.driver = webdriver.Firefox() self.addOnException(self.take_screenshot(self._testMethodName)) self.addCleanup(self.driver.quit()) def remove_environments(self):," self.driver = webdriver.Firefox() def tearDown(self): super(UITestCase, self).tearDown() self.addOnException(self.take_screenshot(self._testMethodName)) self.driver.quit() ",7,6
openstack%2Fsahara~master~I199e650968850b00d7e08c0ae3e68dda824450e4,openstack/sahara,master,I199e650968850b00d7e08c0ae3e68dda824450e4,Imported Translations from Transifex,MERGED,2014-08-09 06:10:21.000000000,2014-08-11 10:19:12.000000000,2014-08-11 10:19:12.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-08-09 06:10:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/20419c19a2b2d0fa627f6fe783915b4eabbf11dc', 'message': 'Imported Translations from Transifex\n\nChange-Id: I199e650968850b00d7e08c0ae3e68dda824450e4\n'}, {'number': 2, 'created': '2014-08-10 06:10:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/29f2fc4ddabd9e36a7bea82d9e7cfc512a53cff2', 'message': 'Imported Translations from Transifex\n\nChange-Id: I199e650968850b00d7e08c0ae3e68dda824450e4\n'}, {'number': 3, 'created': '2014-08-11 06:10:00.000000000', 'files': ['sahara/locale/de/LC_MESSAGES/sahara.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara.po', 'sahara/locale/en_US/LC_MESSAGES/sahara.po', 'sahara/locale/fr/LC_MESSAGES/sahara.po', 'sahara/locale/es/LC_MESSAGES/sahara.po', 'sahara/locale/sahara.pot', 'sahara/locale/zh_CN/LC_MESSAGES/sahara.po'], 'web_link': 'https://opendev.org/openstack/sahara/commit/088529fd2f1a6c115e38fe0e5ee55a6df75b2ff4', 'message': 'Imported Translations from Transifex\n\nChange-Id: I199e650968850b00d7e08c0ae3e68dda824450e4\n'}]",0,113073,088529fd2f1a6c115e38fe0e5ee55a6df75b2ff4,21,4,3,11131,,,0,"Imported Translations from Transifex

Change-Id: I199e650968850b00d7e08c0ae3e68dda824450e4
",git fetch https://review.opendev.org/openstack/sahara refs/changes/73/113073/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/locale/de/LC_MESSAGES/sahara.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara.po', 'sahara/locale/en_US/LC_MESSAGES/sahara.po', 'sahara/locale/fr/LC_MESSAGES/sahara.po', 'sahara/locale/es/LC_MESSAGES/sahara.po', 'sahara/locale/sahara.pot', 'sahara/locale/zh_CN/LC_MESSAGES/sahara.po']",7,20419c19a2b2d0fa627f6fe783915b4eabbf11dc,transifex/translations,"""POT-Creation-Date: 2014-08-09 06:10+0000\n""#: sahara/api/middleware/auth_valid.py:55 msgid ""Incorrect path"" msgstr """" #: sahara/api/middleware/auth_valid.py:61 msgid ""Token tenant != requested tenant"" msgstr """" ","""POT-Creation-Date: 2014-08-08 06:10+0000\n""#: sahara/middleware/auth_valid.py:55 msgid ""Incorrect path"" msgstr """" #: sahara/middleware/auth_valid.py:61 msgid ""Token tenant != requested tenant"" msgstr """" ",64,64
openstack%2Fheat~master~Id3dafef3c2c04cd43c3094283dceece26834a5e1,openstack/heat,master,Id3dafef3c2c04cd43c3094283dceece26834a5e1,Add RPC method to snapshot stacks,MERGED,2014-04-14 14:30:36.000000000,2014-08-11 10:13:49.000000000,2014-08-11 10:13:49.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4328}, {'_account_id': 6488}, {'_account_id': 6498}, {'_account_id': 7193}, {'_account_id': 7233}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 8537}]","[{'number': 1, 'created': '2014-04-14 14:30:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/250c20dd98fff7a6efeac5987f269badad4371c1', 'message': 'Add RPC method to snapshot stacks\n\nThis adds new methods to snapshot a stack and manipulates snapshots.\n\nblueprint stack-snapshot\nCo-Authored-By: ala.rezmerita@cloudwatt.com\n\nChange-Id: Id3dafef3c2c04cd43c3094283dceece26834a5e1\n'}, {'number': 2, 'created': '2014-04-17 15:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2412b1bf86e932d18fd287bce6ab165db8c52cc9', 'message': 'Add RPC method to snapshot stacks\n\nThis adds new methods to snapshot a stack and manipulates snapshots.\n\nblueprint stack-snapshot\nCo-Authored-By: ala.rezmerita@cloudwatt.com\n\nChange-Id: Id3dafef3c2c04cd43c3094283dceece26834a5e1\n'}, {'number': 3, 'created': '2014-04-26 16:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1b89686e001b55dc45b9f79e046128dc225bb222', 'message': 'Add RPC method to snapshot stacks\n\nThis adds new methods to snapshot a stack and manipulates snapshots.\n\nblueprint stack-snapshot\nCo-Authored-By: ala.rezmerita@cloudwatt.com\n\nChange-Id: Id3dafef3c2c04cd43c3094283dceece26834a5e1\n'}, {'number': 4, 'created': '2014-04-29 12:41:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/89f09789f797895e83126b5aa709d67f20cb9ec8', 'message': 'Add RPC method to snapshot stacks\n\nThis adds new methods to snapshot a stack and manipulates snapshots.\n\nblueprint stack-snapshot\nCo-Authored-By: ala.rezmerita@cloudwatt.com\n\nChange-Id: Id3dafef3c2c04cd43c3094283dceece26834a5e1\n'}, {'number': 5, 'created': '2014-05-05 14:38:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/786aa1a39fe4ad4ebdda23d8f7c5d2a3df8f5e74', 'message': 'Add RPC method to snapshot stacks\n\nThis adds new methods to snapshot a stack and manipulates snapshots.\n\nblueprint stack-snapshot\nCo-Authored-By: ala.rezmerita@cloudwatt.com\n\nChange-Id: Id3dafef3c2c04cd43c3094283dceece26834a5e1\n'}, {'number': 6, 'created': '2014-05-06 13:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/27ef8a6c9db7086ad83caed70d40aa1b20728679', 'message': 'Add RPC method to snapshot stacks\n\nThis adds new methods to snapshot a stack and manipulates snapshots.\n\nblueprint stack-snapshot\nCo-Authored-By: ala.rezmerita@cloudwatt.com\n\nChange-Id: Id3dafef3c2c04cd43c3094283dceece26834a5e1\n'}, {'number': 7, 'created': '2014-05-09 08:15:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3b275b6a2bed48d9c64d270abfdb645a789738e8', 'message': 'Add RPC method to snapshot stacks\n\nThis adds new methods to snapshot a stack and manipulates snapshots.\n\nblueprint stack-snapshot\nCo-Authored-By: ala.rezmerita@cloudwatt.com\n\nChange-Id: Id3dafef3c2c04cd43c3094283dceece26834a5e1\n'}, {'number': 8, 'created': '2014-05-22 17:14:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a606c52cc97a86aa12eebcfbbfc257fd398564cf', 'message': 'Add RPC method to snapshot stacks\n\nThis adds new methods to snapshot a stack and manipulates snapshots.\n\nblueprint stack-snapshot\nCo-Authored-By: ala.rezmerita@cloudwatt.com\n\nChange-Id: Id3dafef3c2c04cd43c3094283dceece26834a5e1\n'}, {'number': 9, 'created': '2014-06-25 15:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/20036521c64504a4791d06feaf538800ff5d8130', 'message': 'Add RPC method to snapshot stacks\n\nThis adds new methods to snapshot a stack and manipulates snapshots.\n\nblueprint stack-snapshot\nCo-Authored-By: ala.rezmerita@cloudwatt.com\n\nChange-Id: Id3dafef3c2c04cd43c3094283dceece26834a5e1\n'}, {'number': 10, 'created': '2014-06-30 09:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/30fdebd547067ee188cd80da7d4b15afc6354a9d', 'message': 'Add RPC method to snapshot stacks\n\nThis adds new methods to snapshot a stack and manipulates snapshots.\n\nblueprint stack-snapshot\nCo-Authored-By: ala.rezmerita@cloudwatt.com\n\nChange-Id: Id3dafef3c2c04cd43c3094283dceece26834a5e1\n'}, {'number': 11, 'created': '2014-07-15 12:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b928b510d36ccbf2bb980a2f58d7173db5bc57a1', 'message': 'Add RPC method to snapshot stacks\n\nThis adds new methods to snapshot a stack and manipulates snapshots.\n\nblueprint stack-snapshot\nCo-Authored-By: ala.rezmerita@cloudwatt.com\n\nChange-Id: Id3dafef3c2c04cd43c3094283dceece26834a5e1\n'}, {'number': 12, 'created': '2014-07-31 10:40:39.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/db/api.py', 'heat/engine/api.py', 'heat/rpc/api.py', 'heat/tests/test_parser.py', 'heat/db/sqlalchemy/api.py', 'heat/engine/stack.py', 'heat/engine/service.py', 'heat/engine/resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/413fc0b3a6a0d94742d422f3b03937b17736bcc7', 'message': 'Add RPC method to snapshot stacks\n\nThis adds new methods to snapshot a stack and manipulates snapshots.\n\nblueprint stack-snapshot\nCo-Authored-By: ala.rezmerita@cloudwatt.com\n\nChange-Id: Id3dafef3c2c04cd43c3094283dceece26834a5e1\n'}]",22,87278,413fc0b3a6a0d94742d422f3b03937b17736bcc7,78,11,12,7385,,,0,"Add RPC method to snapshot stacks

This adds new methods to snapshot a stack and manipulates snapshots.

blueprint stack-snapshot
Co-Authored-By: ala.rezmerita@cloudwatt.com

Change-Id: Id3dafef3c2c04cd43c3094283dceece26834a5e1
",git fetch https://review.opendev.org/openstack/heat refs/changes/78/87278/10 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/engine/parser.py', 'heat/engine/api.py', 'heat/rpc/api.py', 'heat/engine/resource.py', 'heat/engine/service.py']",6,250c20dd98fff7a6efeac5987f269badad4371c1,bp/stack-snapshot," def stack_snapshot(self, cnxt, stack_identity): def _stack_snapshot(stack, snapshot): logger.debug(_(""snapshotting stack %s"") % stack.name) stack.snapshot() data = stack.get_abandon_data() db_api.snapshot_update( cnxt, snapshot.id, {'data': data, 'status': stack.status, 'status_reason': stack.status_reason}) s = self._get_stack(cnxt, stack_identity) stack = parser.Stack.load(cnxt, stack=s) snapshot = db_api.snapshot_create(cnxt, { 'tenant': cnxt.tenant_id, 'status': 'IN_PROGRESS'}) self.thread_group_mgr.start_with_lock(cnxt, stack, self.engine_id, _stack_snapshot, stack, snapshot) return api.format_snapshot(snapshot) @request_context def show_snapshot(self, cnxt, snapshot_id): snapshot = db_api.snapshot_get(cnxt, snapshot_id) return api.format_snapshot(snapshot) @request_context def delete_snapshot(self, cnxt, snapshot_id): db_api.snapshot_delete(cnxt, snapshot_id) @request_context",,140,4
openstack%2Ftraining-guides~master~Ifff79e7d84b2f02c2bdded854721a6a73fa82465,openstack/training-guides,master,Ifff79e7d84b2f02c2bdded854721a6a73fa82465,labs: install RabbitMQ message broker service,MERGED,2014-08-11 09:46:20.000000000,2014-08-11 10:06:00.000000000,2014-08-11 10:06:00.000000000,"[{'_account_id': 3}, {'_account_id': 7007}]","[{'number': 1, 'created': '2014-08-11 09:46:20.000000000', 'files': ['labs/scripts/install_rabbitmq.sh', 'labs/config/scripts.controller', 'labs/config/credentials'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/8d08b00899bc9e405026a9b22991263408254b94', 'message': 'labs: install RabbitMQ message broker service\n\nThis changeset installs RabbitMQ on the controller node.\n\nThe password needed by OpenStack services to use rabbitmq can be sourced\nfrom config/credentials.\n\nImplements: blueprint openstack-training-labs\nChange-Id: Ifff79e7d84b2f02c2bdded854721a6a73fa82465\n'}]",0,113201,8d08b00899bc9e405026a9b22991263408254b94,7,2,1,11109,,,0,"labs: install RabbitMQ message broker service

This changeset installs RabbitMQ on the controller node.

The password needed by OpenStack services to use rabbitmq can be sourced
from config/credentials.

Implements: blueprint openstack-training-labs
Change-Id: Ifff79e7d84b2f02c2bdded854721a6a73fa82465
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/01/113201/1 && git format-patch -1 --stdout FETCH_HEAD,"['labs/scripts/install_rabbitmq.sh', 'labs/config/scripts.controller', 'labs/config/credentials']",3,8d08b00899bc9e405026a9b22991263408254b94,bp/openstack-training-labs,# Used for MySQL or whatever other DBMS is configured : ${RABBIT_PASSWORD:=rabbitPass} ,,22,0
openstack%2Ftripleo-image-elements~master~Ia6f26305f8e744e4ff938dff85de1193183ecd8f,openstack/tripleo-image-elements,master,Ia6f26305f8e744e4ff938dff85de1193183ecd8f,Network init order fixes for VIP,MERGED,2014-07-09 20:04:35.000000000,2014-08-11 09:40:15.000000000,2014-08-11 09:40:15.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 4190}, {'_account_id': 6796}, {'_account_id': 6969}, {'_account_id': 8399}, {'_account_id': 9369}, {'_account_id': 9453}, {'_account_id': 10035}, {'_account_id': 11655}]","[{'number': 1, 'created': '2014-07-09 20:04:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e93c82d39ed9188434077f3f45672599882cebec', 'message': 'Network init order and keepalived fixes\n\nThese changes revise the boot order for network intialization such\nthat the configuration, VIP, HAProxy, and MySQL are available\nand running prior to openstack-init starting.\n\nThese changes are necessary in order to prevent services in the boot\nsequence from failing once the MySQL database URLs and bind-address\nare changed.\n\nWith regards to keepalived, this commit includes a new script called\nkeepalived-status which determines the state of keepalived, and\nreturns 0 if keepalived appears to be in a healthy state.\n\nChange-Id: Ia6f26305f8e744e4ff938dff85de1193183ecd8f\n'}, {'number': 2, 'created': '2014-07-09 23:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/db1d550347c531a5fa5b7b8e19ab838c5e1dc32b', 'message': 'Network init order and keepalived fixes\n\nThese changes revise the boot order for network intialization such\nthat the configuration, VIP, HAProxy, and MySQL are available\nand running prior to openstack-init starting.\n\nThese changes are necessary in order to prevent services in the boot\nsequence from failing once the MySQL database URLs and bind-address\nare changed.\n\nWith regards to keepalived, this commit includes a new script called\nkeepalived-status which determines the state of keepalived, and\nreturns 0 if keepalived appears to be in a healthy state.\n\nChange-Id: Ia6f26305f8e744e4ff938dff85de1193183ecd8f\n'}, {'number': 3, 'created': '2014-07-11 21:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/51de19f72b21e6d90e8c635bb2160753048ed5db', 'message': 'Network init order and keepalived fixes\n\nThese changes revise the boot order for network intialization such\nthat the configuration, VIP, HAProxy, and MySQL are available\nand running prior to openstack-init starting.\n\nThese changes are necessary in order to prevent services in the boot\nsequence from failing once the MySQL database URLs and bind-address\nare changed.\n\nWith regards to keepalived, this commit includes a new script called\nkeepalived-status which determines the state of keepalived, and\nreturns 0 if keepalived appears to be in a healthy state via status\nfiles that keepalived has been configured to write out, and via\npinging any configured virtual_ips.\n\nService startup changes:\n\nhaproxy-nonlocal-bind in configure.d was moved from step 75 to step\n21 to execute before haproxy was started so it could could perform\nthe non-local bind.\n\nhaproxy was moved from post-configure.d/ to configure.d/21-haproxy\nto allow for HAProxy to bind to the VIP address that keepalived will\nneed to initalize and support passing connections to MySQL.\n\nneutron-openvswitch-agent in configure.d was moved from starting at\nstep 80 to starting at step 21 as it creates the bridge interface\nthat keepalived utilizes, and thus is required for the vip to come\nonline.\n\nkeepalived was moved from from post-configure.d step 15 to\nconfigure.d step 22 to allow the VIP to initailize to occur prior\nto configure.d/53-init-openstack which is required for applications\nto be configured to utilize the VIP address and HAProxy for MySQL\nconnectivity.  Additionally this script recieved a check to only\nrestart keepalived if it does not appear to be working, which may\nbe due to the state of the metadata being available to the instance\nor just timing.\n\nService start-up addition:\n\nconfigure.d/52-check-keepalived was added to abort the intialization\nprocess instead of allowing 53-openstack-init to fail attempting to\naccess the database should keepalived or the vip not yet be ready.\n\nChange-Id: Ia6f26305f8e744e4ff938dff85de1193183ecd8f\n'}, {'number': 4, 'created': '2014-07-15 18:42:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/1aadb6ce161b44eee5a63b21101427223af28d51', 'message': 'Network init order fixes for VIP\n\nThese changes revise the boot order for network intialization such\nthat the configuration, VIP, HAProxy, and MySQL are available\nand running prior to openstack-init starting.\n\nThese changes are necessary in order to prevent services in the boot\nsequence from failing once the MySQL database URLs and bind-address\nare changed to utilize the VIP address.\n\nService startup changes:\n\nhaproxy-nonlocal-bind in configure.d was moved from step 75 to step\n21 to execute before haproxy was started so it could could perform\nthe non-local bind.\n\nhaproxy was moved from post-configure.d/ to configure.d/21-haproxy\nto allow for HAProxy to bind to the VIP address that keepalived will\nneed to initalize and support passing connections to MySQL.\n\nneutron-openvswitch-agent in configure.d was moved from starting at\nstep 80 to starting at step 21 as it creates the bridge interface\nthat keepalived utilizes, and thus is required for the vip to come\nonline.\n\nos-apply-config in configure.d was moved from 50 to 20 as the\nconfiguration files must be written out for haproxy and keepalived\nto function properly.\n\nThis change is depends on I29613bf314fd054d0c82492692d95de2303c64ae\n\nChange-Id: Ia6f26305f8e744e4ff938dff85de1193183ecd8f\n'}, {'number': 5, 'created': '2014-07-17 19:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/badf3a2e248b2eb55f843b424feb7eddea972198', 'message': 'Network init order fixes for VIP\n\nThese changes revise the boot order for network intialization such\nthat the configuration, VIP, HAProxy, and MySQL are available\nand running prior to openstack-init starting.\n\nThese changes are necessary in order to prevent services in the boot\nsequence from failing once the MySQL database URLs and bind-address\nare changed to utilize the VIP address.\n\nService startup changes:\n\nhaproxy-nonlocal-bind in configure.d was moved from step 75 to step\n21 to execute before haproxy was started so it could could perform\nthe non-local bind.\n\nhaproxy was moved from post-configure.d/ to configure.d/21-haproxy\nto allow for HAProxy to bind to the VIP address that keepalived will\nneed to initalize and support passing connections to MySQL.\n\nneutron-openvswitch-agent in configure.d was moved from starting at\nstep 80 to starting at step 21 as it creates the bridge interface\nthat keepalived utilizes, and thus is required for the vip to come\nonline.\n\nos-apply-config in configure.d was moved from 50 to 20 as the\nconfiguration files must be written out for haproxy and keepalived\nto function properly.\n\nThis change is depends on I29613bf314fd054d0c82492692d95de2303c64ae\n\nChange-Id: Ia6f26305f8e744e4ff938dff85de1193183ecd8f\n'}, {'number': 6, 'created': '2014-07-21 19:10:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/8671ac49f7f2db515eebb01bc61a935cd485d127', 'message': 'Network init order fixes for VIP\n\nThese changes revise the boot order for network intialization such\nthat the configuration, VIP, HAProxy, and MySQL are available\nand running prior to openstack-init starting.\n\nThese changes are necessary in order to prevent services in the boot\nsequence from failing once the MySQL database URLs and bind-address\nare changed to utilize the VIP address.\n\nService startup changes:\n\nhaproxy-nonlocal-bind in configure.d was moved from step 75 to step\n20 to execute before haproxy was started so it could could perform\nthe non-local bind.\n\nhaproxy was moved from post-configure.d/ to configure.d/21-haproxy\nto allow for HAProxy to bind to the VIP address that keepalived will\nneed to initalize and support passing connections to MySQL.\n\nneutron-openvswitch-agent in configure.d was moved from starting at\nstep 80 to starting at step 21 as it creates the bridge interface\nthat keepalived utilizes, and thus is required for the vip to come\nonline.\n\nos-apply-config in configure.d was moved from 50 to 20 as the\nconfiguration files must be written out for haproxy and keepalived\nto function properly.\n\nThis change is depends on I29613bf314fd054d0c82492692d95de2303c64ae\n\nChange-Id: Ia6f26305f8e744e4ff938dff85de1193183ecd8f\n'}, {'number': 7, 'created': '2014-07-22 18:47:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/0465fec45edd3223bdfaa48c72bbece247ac50d7', 'message': 'Network init order fixes for VIP\n\nThese changes revise the boot order for network intialization such\nthat the configuration, VIP, HAProxy, and MySQL are available\nand running prior to openstack-init starting.\n\nThese changes are necessary in order to prevent services in the boot\nsequence from failing once the MySQL database URLs and bind-address\nare changed to utilize the VIP address.\n\nService startup changes:\n\nhaproxy-nonlocal-bind in configure.d was moved from step 75 to step\n20 to execute before haproxy was started so it could could perform\nthe non-local bind.\n\nhaproxy was moved from post-configure.d/ to configure.d/21-haproxy\nto allow for HAProxy to bind to the VIP address that keepalived will\nneed to initalize and support passing connections to MySQL.\n\nneutron-openvswitch-agent in configure.d was moved from starting at\nstep 80 to starting at step 21 as it creates the bridge interface\nthat keepalived utilizes, and thus is required for the vip to come\nonline.\n\nos-apply-config in configure.d was moved from 50 to 20 as the\nconfiguration files must be written out for haproxy and keepalived\nto function properly.\n\nThis change is depends on I29613bf314fd054d0c82492692d95de2303c64ae\n\nChange-Id: Ia6f26305f8e744e4ff938dff85de1193183ecd8f\n'}, {'number': 8, 'created': '2014-07-24 12:51:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/bbac5cb6a36d52663e71589b87a413f668cdce30', 'message': 'Network init order fixes for VIP\n\nThese changes revise the boot order for network intialization such\nthat the configuration, VIP, HAProxy, and MySQL are available\nand running prior to openstack-init starting.\n\nThese changes are necessary in order to prevent services in the boot\nsequence from failing once the MySQL database URLs and bind-address\nare changed to utilize the VIP address.\n\nService startup changes:\n\nhaproxy-nonlocal-bind in configure.d was moved from step 75 to step\n20 to execute before haproxy was started so it could could perform\nthe non-local bind.\n\nhaproxy was moved from post-configure.d/ to configure.d/21-haproxy\nto allow for HAProxy to bind to the VIP address that keepalived will\nneed to initalize and support passing connections to MySQL.\n\nneutron-openvswitch-agent in configure.d was moved from starting at\nstep 80 to starting at step 21 as it creates the bridge interface\nthat keepalived utilizes, and thus is required for the vip to come\nonline.\n\nos-apply-config in configure.d was moved from 50 to 20 as the\nconfiguration files must be written out for haproxy and keepalived\nto function properly.\n\nThis change is depends on I29613bf314fd054d0c82492692d95de2303c64ae\n\nChange-Id: Ia6f26305f8e744e4ff938dff85de1193183ecd8f\n'}, {'number': 9, 'created': '2014-08-11 01:40:22.000000000', 'files': ['elements/haproxy/os-refresh-config/configure.d/20-haproxy-nonlocal-bind', 'elements/neutron-openvswitch-agent/os-refresh-config/configure.d/21-neutron-openvswitch-agent', 'elements/os-apply-config/os-refresh-config/configure.d/20-os-apply-config', 'elements/haproxy/os-refresh-config/configure.d/21-haproxy', 'elements/keepalived/os-refresh-config/configure.d/22-keepalived'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/3625ab254cc49e6e8574976dfdf1690bf65d1401', 'message': 'Network init order fixes for VIP\n\nThese changes revise the boot order for network intialization such\nthat the configuration, VIP, HAProxy, and MySQL are available\nand running prior to openstack-init starting.\n\nThese changes are necessary in order to prevent services in the boot\nsequence from failing once the MySQL database URLs and bind-address\nare changed to utilize the VIP address.\n\nService startup changes:\n\nhaproxy-nonlocal-bind in configure.d was moved from step 75 to step\n20 to execute before haproxy was started so it could could perform\nthe non-local bind.\n\nhaproxy was moved from post-configure.d/ to configure.d/21-haproxy\nto allow for HAProxy to bind to the VIP address that keepalived will\nneed to initalize and support passing connections to MySQL.\n\nneutron-openvswitch-agent in configure.d was moved from starting at\nstep 80 to starting at step 21 as it creates the bridge interface\nthat keepalived utilizes, and thus is required for the vip to come\nonline.\n\nos-apply-config in configure.d was moved from 50 to 20 as the\nconfiguration files must be written out for haproxy and keepalived\nto function properly.\n\nThis change is depends on I29613bf314fd054d0c82492692d95de2303c64ae\n\nChange-Id: Ia6f26305f8e744e4ff938dff85de1193183ecd8f\n'}]",40,105862,3625ab254cc49e6e8574976dfdf1690bf65d1401,73,10,9,11655,,,0,"Network init order fixes for VIP

These changes revise the boot order for network intialization such
that the configuration, VIP, HAProxy, and MySQL are available
and running prior to openstack-init starting.

These changes are necessary in order to prevent services in the boot
sequence from failing once the MySQL database URLs and bind-address
are changed to utilize the VIP address.

Service startup changes:

haproxy-nonlocal-bind in configure.d was moved from step 75 to step
20 to execute before haproxy was started so it could could perform
the non-local bind.

haproxy was moved from post-configure.d/ to configure.d/21-haproxy
to allow for HAProxy to bind to the VIP address that keepalived will
need to initalize and support passing connections to MySQL.

neutron-openvswitch-agent in configure.d was moved from starting at
step 80 to starting at step 21 as it creates the bridge interface
that keepalived utilizes, and thus is required for the vip to come
online.

os-apply-config in configure.d was moved from 50 to 20 as the
configuration files must be written out for haproxy and keepalived
to function properly.

This change is depends on I29613bf314fd054d0c82492692d95de2303c64ae

Change-Id: Ia6f26305f8e744e4ff938dff85de1193183ecd8f
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/62/105862/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/haproxy/os-refresh-config/configure.d/20-haproxy-nonlocal-bind', 'elements/neutron-openvswitch-agent/os-refresh-config/configure.d/21-neutron-openvswitch-agent', 'elements/haproxy/os-refresh-config/configure.d/21-haproxy', 'elements/keepalived/bin/keepalived-status', 'elements/keepalived/os-refresh-config/configure.d/52-check-keepalived', 'elements/keepalived/os-refresh-config/configure.d/22-keepalived', 'elements/keepalived/os-refresh-config/post-configure.d/15-keepalived', 'elements/os-apply-config/os-refresh-config/configure.d/20-os-config-applier']",8,e93c82d39ed9188434077f3f45672599882cebec,bp/tripleo-icehouse-ha-production-configuration,,,80,4
openstack%2Ffuel-library~master~Id170eb1f6061f08154db110ef15d55bfbbfdf67c,openstack/fuel-library,master,Id170eb1f6061f08154db110ef15d55bfbbfdf67c,osnailyfacter changes for heat,MERGED,2014-08-01 18:06:06.000000000,2014-08-11 09:39:41.000000000,2014-08-11 09:39:41.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-08-01 18:06:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/637a996ed087ef7decbdd41c80bb9ba7712c42f9', 'message': 'osnailyfacter changes for heat\n\n* Add keystone_ec2_uri parameter to the openstack:heat section.\nThis changeset rewrites default values for heat::keystone_ec2_uri,\nwhich points to localhost instead of controller_node_address.\n* Remove RedHat OS check for openstack:heat.\n\nChange-Id: Id170eb1f6061f08154db110ef15d55bfbbfdf67c\n'}, {'number': 2, 'created': '2014-08-04 16:34:02.000000000', 'files': ['deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cf3a4233e170a86baf49389121de6e303ae302e1', 'message': 'osnailyfacter changes for heat\n\n* Add keystone_ec2_uri parameter to the openstack:heat section.\nThis changeset rewrites default values for heat::keystone_ec2_uri,\nwhich points to localhost instead of controller_node_address.\n* Remove RedHat OS check for openstack:heat.\nCloses-Bug: 1352444\n\nChange-Id: Id170eb1f6061f08154db110ef15d55bfbbfdf67c\n'}]",0,111354,cf3a4233e170a86baf49389121de6e303ae302e1,25,5,2,7613,,,0,"osnailyfacter changes for heat

* Add keystone_ec2_uri parameter to the openstack:heat section.
This changeset rewrites default values for heat::keystone_ec2_uri,
which points to localhost instead of controller_node_address.
* Remove RedHat OS check for openstack:heat.
Closes-Bug: 1352444

Change-Id: Id170eb1f6061f08154db110ef15d55bfbbfdf67c
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/54/111354/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp']",2,637a996ed087ef7decbdd41c80bb9ba7712c42f9,bug/1352444," class { 'openstack::heat' : pacemaker => false, external_ip => $controller_node_public, keystone_host => $controller_node_address, keystone_user => 'heat', keystone_password => $heat_hash['user_password'], keystone_tenant => 'services', keystone_ec2_uri => ""http://${controller_node_address}:5000/v2.0"", rpc_backend => 'heat.openstack.common.rpc.impl_kombu', amqp_hosts => [$amqp_hosts], amqp_user => $rabbit_hash['user'], amqp_password => $rabbit_hash['password'], sql_connection => ""mysql://heat:${heat_hash['db_password']}@${$controller_node_address}/heat?read_timeout=60"", db_host => $controller_node_address, db_password => $heat_hash['db_password'], max_retries => $max_retries, max_pool_size => $max_pool_size, max_overflow => $max_overflow, idle_timeout => $idle_timeout, debug => $::debug, verbose => $::verbose, use_syslog => $::use_syslog, syslog_log_facility => $::syslog_log_facility_heat, } "," if ($::operatingsystem != 'RedHat') { class { 'openstack::heat' : pacemaker => false, external_ip => $controller_node_public, keystone_host => $controller_node_address, keystone_user => 'heat', keystone_password => $heat_hash['user_password'], keystone_tenant => 'services', rpc_backend => 'heat.openstack.common.rpc.impl_kombu', amqp_hosts => [$amqp_hosts], amqp_user => $rabbit_hash['user'], amqp_password => $rabbit_hash['password'], sql_connection => ""mysql://heat:${heat_hash['db_password']}@${$controller_node_address}/heat?read_timeout=60"", db_host => $controller_node_address, db_password => $heat_hash['db_password'], max_retries => $max_retries, max_pool_size => $max_pool_size, max_overflow => $max_overflow, idle_timeout => $idle_timeout, debug => $::debug, verbose => $::verbose, use_syslog => $::use_syslog, syslog_log_facility => $::syslog_log_facility_heat, } } ",55,53
openstack%2Ffuel-library~master~Ib654853a5dae5344deabf9404f8972041c8bd157,openstack/fuel-library,master,Ib654853a5dae5344deabf9404f8972041c8bd157,Fix sending parameter 'ceilometer' to openstack::cinder class,MERGED,2014-08-05 13:04:04.000000000,2014-08-11 09:39:23.000000000,2014-08-11 09:39:23.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 7126}, {'_account_id': 7604}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-08-05 13:04:04.000000000', 'files': ['deployment/puppet/openstack/manifests/controller.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e313d375479b26c2f3e142ed71209db81a2b74e4', 'message': ""Fix sending parameter 'ceilometer' to openstack::cinder class\n\nIf role 'cinder' isn't exist in cluster, parameter 'ceilometer'\nisn't sent in openstack:cinder class, and then cinder:ceilometer\nmanifest doesn't execute\n\nChange-Id: Ib654853a5dae5344deabf9404f8972041c8bd157\nCloses-bug: #1312631\n""}]",0,112007,e313d375479b26c2f3e142ed71209db81a2b74e4,17,7,1,7732,,,0,"Fix sending parameter 'ceilometer' to openstack::cinder class

If role 'cinder' isn't exist in cluster, parameter 'ceilometer'
isn't sent in openstack:cinder class, and then cinder:ceilometer
manifest doesn't execute

Change-Id: Ib654853a5dae5344deabf9404f8972041c8bd157
Closes-bug: #1312631
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/07/112007/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack/manifests/controller.pp'],1,e313d375479b26c2f3e142ed71209db81a2b74e4,master," ceilometer => $ceilometer,",,1,0
openstack%2Ftripleo-image-elements~master~I29613bf314fd054d0c82492692d95de2303c64ae,openstack/tripleo-image-elements,master,I29613bf314fd054d0c82492692d95de2303c64ae,Keepalived reload check addition,MERGED,2014-07-15 18:42:50.000000000,2014-08-11 09:39:10.000000000,2014-08-11 09:39:10.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 4190}, {'_account_id': 6796}, {'_account_id': 6969}, {'_account_id': 7471}, {'_account_id': 9369}, {'_account_id': 9453}, {'_account_id': 10035}, {'_account_id': 11655}]","[{'number': 1, 'created': '2014-07-15 18:42:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/4715a155744ea2d0d1b244922eb1b61832ea5186', 'message': 'Adding keepalived restart check\n\nThis commit changes the keepalive script such that the presence of\naddress configuration is checked prior to taking any action as\nkeepalived is capable of running without address configuration in\naddition to assuming a MASTER state.\n\nThe configuration has been also modified such that\n/var/run/keepalived.operational is touched when keepalived is in\nMASTER or BACKUP state.  The presence of that file will block the\npost-configuration script from restarting keepalived as it can take\nseveral seconds to initialize and if restarted every run can easily\nresult in undesirable looping during if CONTROLSCALE=1 and services\nrequire the VIP address to be accessible to initalize.\n\nThese changes are in anticipation of changing the intialization\norder to ensure that VIP initialization takes place before services\nattempt to initialize.\n\nChange-Id: I29613bf314fd054d0c82492692d95de2303c64ae\n'}, {'number': 2, 'created': '2014-07-15 18:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/06c2297b9bcc66ba72429ac23343c8ed1d6233f1', 'message': 'Adding keepalived restart check\n\nThis commit changes the keepalive script such that the presence of\naddress configuration is checked prior to taking any action as\nkeepalived is capable of running without address configuration in\naddition to assuming a MASTER state.\n\nThe configuration has been also modified such that\n/var/run/keepalived.operational is touched when keepalived is in\nMASTER or BACKUP state.  The presence of that file will block the\npost-configuration script from restarting keepalived as it can take\nseveral seconds to initialize and if restarted every run can easily\nresult in undesirable looping if CONTROLSCALE=1 and services \nrequire the VIP address to be accessible to initalize.\n\nThese changes are in anticipation of changing the intialization\norder to ensure that VIP initialization takes place before services\nattempt to initialize.\n\nChange-Id: I29613bf314fd054d0c82492692d95de2303c64ae\n'}, {'number': 3, 'created': '2014-07-16 13:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/0f04f879847143039d944ab166ccecc16b78d42b', 'message': 'Adding keepalived restart check\n\nThis commit changes the keepalive script such that the presence of\naddress configuration is checked prior to taking any action as\nkeepalived is capable of running without address configuration in\naddition to assuming a MASTER state.\n\nThe configuration has been also modified such that\n/var/run/keepalived.operational is touched when keepalived is in\nMASTER or BACKUP state.  The presence of that file will block the\npost-configuration script from restarting keepalived as it can take\nseveral seconds to initialize and if restarted every run can easily\nresult in undesirable looping if CONTROLSCALE=1 and services\nrequire the VIP address to be accessible to initialize.\n\nThese changes are in anticipation of changing the intialization\norder to ensure that VIP initialization takes place before services\nattempt to initialize.\n\nChange-Id: I29613bf314fd054d0c82492692d95de2303c64ae\n'}, {'number': 4, 'created': '2014-07-21 19:10:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/6f2a8b6b156210e6dc569d9073849d9330c234bc', 'message': 'Adding keepalived restart check\n\nThis commit changes the keepalived script such that if keepalived is\nalready running, then it is sent a reload command instead of a\nrestart command.\n\nChange-Id: I29613bf314fd054d0c82492692d95de2303c64ae\n'}, {'number': 5, 'created': '2014-07-22 17:40:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/528cdf5828a57052c1416acbe6c998ffc3a28ce6', 'message': 'Adding keepalived restart check\n\nThis commit changes the keepalived script such that if keepalived is\nalready running, then it is sent a reload command instead of a\nrestart command.\n\nChange-Id: I29613bf314fd054d0c82492692d95de2303c64ae\n'}, {'number': 6, 'created': '2014-07-22 17:50:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/41c405a750df163d4be2d2732b89dd667a217819', 'message': 'Adding keepalived restart check\n\nThis commit changes the keepalived script such that if keepalived is\nalready running, then it is sent a reload command instead of a\nrestart command.\n\nChange-Id: I29613bf314fd054d0c82492692d95de2303c64ae\n'}, {'number': 7, 'created': '2014-07-24 12:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/56b3bd510f58ddd66bdacd09b64dfb8eb22168ca', 'message': 'Keepalived reload check addition\n\nThis commit changes the keepalived script such that if keepalived is\nalready running, then it is sent a reload command instead of a\nrestart command.\n\nChange-Id: I29613bf314fd054d0c82492692d95de2303c64ae\n'}, {'number': 8, 'created': '2014-08-11 01:40:22.000000000', 'files': ['elements/keepalived/os-refresh-config/post-configure.d/15-keepalived'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/73e1ae1fbb2ffb447d5546b39b398a281fc88bc5', 'message': 'Keepalived reload check addition\n\nThis commit changes the keepalived script such that if keepalived is\nalready running, then it is sent a reload command instead of a\nrestart command.\n\nChange-Id: I29613bf314fd054d0c82492692d95de2303c64ae\n'}]",4,107147,73e1ae1fbb2ffb447d5546b39b398a281fc88bc5,76,10,8,11655,,,0,"Keepalived reload check addition

This commit changes the keepalived script such that if keepalived is
already running, then it is sent a reload command instead of a
restart command.

Change-Id: I29613bf314fd054d0c82492692d95de2303c64ae
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/47/107147/8 && git format-patch -1 --stdout FETCH_HEAD,"['elements/keepalived/os-refresh-config/post-configure.d/15-keepalived', 'elements/keepalived/os-apply-config/etc/keepalived/keepalived.conf']",2,4715a155744ea2d0d1b244922eb1b61832ea5186,bp/tripleo-icehouse-ha-production-configuration," notify_backup ""/bin/touch /var/run/keepalived.operational"" notify_master ""/bin/touch /var/run/keepalived.operational"" notify_fault ""/bin/rm /var/run/keepalived.operational""",,21,1
openstack%2Ffuel-library~master~I33823a3abfd42b75fa6bc73d6f3cd038a2163fd6,openstack/fuel-library,master,I33823a3abfd42b75fa6bc73d6f3cd038a2163fd6,Make rabbitmq autoheal partitions,MERGED,2014-08-08 08:30:25.000000000,2014-08-11 09:35:50.000000000,2014-08-11 09:35:50.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8971}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-08-08 08:30:25.000000000', 'files': ['deployment/puppet/rabbitmq/templates/rabbitmq.config'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6051006e213225d7ebf8254f8385aa3dd9909eed', 'message': ""Make rabbitmq autoheal partitions\n\nDefault policy is 'ignore' and it does nothing in order\nto recover from partitioning allowing many partitioned\nrabbit clusters to operate as is.\nAuto-heal policy will merge all partitions into the winner\none once exited from partitioned state\n(e.g. connectivity restored).\n\nCloses-bug: #1354319\n\nChange-Id: I33823a3abfd42b75fa6bc73d6f3cd038a2163fd6\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n""}]",0,112791,6051006e213225d7ebf8254f8385aa3dd9909eed,15,7,1,6926,,,0,"Make rabbitmq autoheal partitions

Default policy is 'ignore' and it does nothing in order
to recover from partitioning allowing many partitioned
rabbit clusters to operate as is.
Auto-heal policy will merge all partitions into the winner
one once exited from partitioned state
(e.g. connectivity restored).

Closes-bug: #1354319

Change-Id: I33823a3abfd42b75fa6bc73d6f3cd038a2163fd6
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/91/112791/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/rabbitmq/templates/rabbitmq.config'],1,6051006e213225d7ebf8254f8385aa3dd9909eed,fix1354319," {cluster_partition_handling, autoheal},",,1,0
openstack%2Ffuel-library~master~Ic82dede59bbc84b9493234defd81e23345222b2e,openstack/fuel-library,master,Ic82dede59bbc84b9493234defd81e23345222b2e,Suppress errors from socat,ABANDONED,2014-08-04 12:37:06.000000000,2014-08-11 09:32:48.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-08-04 12:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1034f35e355ee8582363e2331743df5a87b54f7d', 'message': 'Suppress errors from socat\n\nIn haproxy backends status detection commands, socat might\nproduce an error output when being issued with ""| grep -q""\npipeline. That could be safely suppressed without affecting\nthe query result as well.\n\nCloses-bug: #1352295\n\nChange-Id: Ic82dede59bbc84b9493234defd81e23345222b2e\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 2, 'created': '2014-08-05 07:44:46.000000000', 'files': ['deployment/puppet/openstack/manifests/ha/mysqld.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6f85614997bee328212cfa69f98ecf560ae01f18', 'message': 'Suppress errors from socat\n\nIn haproxy backends status detection commands, socat might\nproduce an error output when being issued with ""| grep -q""\npipeline. That could be safely suppressed without affecting\nthe query result as well\n\nCloses-bug: #1352295\n\nChange-Id: Ic82dede59bbc84b9493234defd81e23345222b2e\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,111704,6f85614997bee328212cfa69f98ecf560ae01f18,19,7,2,6926,,,0,"Suppress errors from socat

In haproxy backends status detection commands, socat might
produce an error output when being issued with ""| grep -q""
pipeline. That could be safely suppressed without affecting
the query result as well

Closes-bug: #1352295

Change-Id: Ic82dede59bbc84b9493234defd81e23345222b2e
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/04/111704/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/manifests/ha/mysqld.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp']",2,1034f35e355ee8582363e2331743df5a87b54f7d,fix1352295," command => ""echo show stat | socat unix-connect:///var/lib/haproxy/stats\ stdio 2>/dev/null | grep -q '^nova-api-2,BACKEND,.*,UP,'"", command => ""echo show stat | socat unix-connect:///var/lib/haproxy/stats\ stdio 2>/dev/null | grep -q '^keystone-1,BACKEND,.*,UP,'"","," command => ""echo show stat | socat unix-connect:///var/lib/haproxy/stats stdio | grep -q '^nova-api-2,BACKEND,.*,UP,'"", command => ""echo show stat | socat unix-connect:///var/lib/haproxy/stats stdio | grep -q '^keystone-1,BACKEND,.*,UP,'"",",6,3
openstack%2Fceilometer~master~I6ed46c00ee32cf4fb9ecf71a0a38ed85fc6d113b,openstack/ceilometer,master,I6ed46c00ee32cf4fb9ecf71a0a38ed85fc6d113b,SOME TEST COMMIT - DO NOT MERGE,ABANDONED,2014-08-04 11:06:02.000000000,2014-08-11 09:32:08.000000000,,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 3012}]","[{'number': 1, 'created': '2014-08-04 11:06:02.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/65b56627083a6e1a2d794138dccbc05b1a1a35ae', 'message': 'SOME TEST COMMIT - DO NOT MERGE\n\nChange-Id: I6ed46c00ee32cf4fb9ecf71a0a38ed85fc6d113b\n'}]",0,111691,65b56627083a6e1a2d794138dccbc05b1a1a35ae,17,3,1,3012,,,0,"SOME TEST COMMIT - DO NOT MERGE

Change-Id: I6ed46c00ee32cf4fb9ecf71a0a38ed85fc6d113b
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/91/111691/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,65b56627083a6e1a2d794138dccbc05b1a1a35ae,do-not-merge-test-commit, # this change does nothing and will be used only for the testing ,,4,0
openstack%2Ffuel-library~master~Ib022b051d56235f1743d3cb34500d828666511cc,openstack/fuel-library,master,Ib022b051d56235f1743d3cb34500d828666511cc,Configure syslog rfc format for compute as well,MERGED,2014-08-08 13:54:44.000000000,2014-08-11 09:28:40.000000000,2014-08-11 09:28:38.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-08-08 13:54:44.000000000', 'files': ['deployment/puppet/openstack/manifests/compute.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5f5304d073eb7f25875726e6cd393e47bac77ef3', 'message': 'Configure syslog rfc format for compute as well\n\nCloses-bug: #1354449\n\nChange-Id: Ib022b051d56235f1743d3cb34500d828666511cc\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,112872,5f5304d073eb7f25875726e6cd393e47bac77ef3,18,5,1,6926,,,0,"Configure syslog rfc format for compute as well

Closes-bug: #1354449

Change-Id: Ib022b051d56235f1743d3cb34500d828666511cc
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/72/112872/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack/manifests/compute.pp'],1,5f5304d073eb7f25875726e6cd393e47bac77ef3,fix1354449, if $use_syslog { nova_config { 'DEFAULT/use_syslog_rfc_format': value => true; } } ,,6,0
openstack%2Ffuel-library~master~I514af033bf5fff380e252aaef8e020ca2edaf993,openstack/fuel-library,master,I514af033bf5fff380e252aaef8e020ca2edaf993,Reconfigure Neutron to use only one network type,MERGED,2014-08-07 18:16:10.000000000,2014-08-11 09:24:12.000000000,2014-08-11 09:24:12.000000000,"[{'_account_id': 3}, {'_account_id': 5950}, {'_account_id': 6072}, {'_account_id': 6926}, {'_account_id': 7125}, {'_account_id': 7227}, {'_account_id': 8598}, {'_account_id': 8781}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8824}, {'_account_id': 8971}, {'_account_id': 9705}]","[{'number': 1, 'created': '2014-08-07 18:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e7f613b868b60c7cb7924aeaf7ff7a53e696ab53', 'message': ""Reconfigure Neutron to use only one network type\n\nWhen network type isn't selected during network creation (for example, using\nHorizon), the first network type from the Neutron plugin config file seems to\nbe selected. Currently it's 'local' and it leads to wrong network type creation\n\nChange-Id: I514af033bf5fff380e252aaef8e020ca2edaf993\nCloses-bug: #1352203\n""}, {'number': 2, 'created': '2014-08-08 13:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c51bf3a3b5e2f91ae60eb7d3482c00ff10090470', 'message': ""Reconfigure Neutron to use only one network type\n\nWhen network type isn't selected during network creation (for example, using\nHorizon), the first network type from the Neutron plugin config file seems to\nbe selected. Currently it's 'local' and it leads to wrong network type creation\n\nChange-Id: I514af033bf5fff380e252aaef8e020ca2edaf993\nCloses-bug: #1352203\n""}, {'number': 3, 'created': '2014-08-08 13:48:39.000000000', 'files': ['deployment/puppet/neutron/lib/puppet/parser/functions/sanitize_neutron_config.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/80d7fb3d0c91425270ef44f2fb9ba0e6aace9d49', 'message': ""Reconfigure Neutron to use only one network type\n\nWhen network type isn't selected during network creation (for example, using\nHorizon), the first network type from the Neutron plugin config file seems to\nbe selected. Currently it's 'local' and it leads to wrong network type creation\n\nChange-Id: I514af033bf5fff380e252aaef8e020ca2edaf993\nCloses-bug: #1352203\n""}]",1,112646,80d7fb3d0c91425270ef44f2fb9ba0e6aace9d49,39,13,3,7604,,,0,"Reconfigure Neutron to use only one network type

When network type isn't selected during network creation (for example, using
Horizon), the first network type from the Neutron plugin config file seems to
be selected. Currently it's 'local' and it leads to wrong network type creation

Change-Id: I514af033bf5fff380e252aaef8e020ca2edaf993
Closes-bug: #1352203
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/46/112646/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/neutron/lib/puppet/parser/functions/sanitize_neutron_config.rb'],1,e7f613b868b60c7cb7924aeaf7ff7a53e696ab53,(detached," rv[:type_drivers] ||= ""#{l2[:segmentation_type]}"" rv[:tenant_network_types] ||= ""#{l2[:segmentation_type]}"""," rv[:type_drivers] ||= ""local,flat,#{l2[:segmentation_type]}"" rv[:tenant_network_types] ||= ""local,flat,#{l2[:segmentation_type]}""",2,2
openstack%2Ftripleo-ci~master~I86c7b6c774c1a3ca578f8d33b2cf22c412cf80e3,openstack/tripleo-ci,master,I86c7b6c774c1a3ca578f8d33b2cf22c412cf80e3,temprevert : Configuration agent for Cisco devices,ABANDONED,2014-08-01 20:39:20.000000000,2014-08-11 08:52:51.000000000,,"[{'_account_id': 3}, {'_account_id': 360}]","[{'number': 1, 'created': '2014-08-01 20:39:20.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2f892205a7cbe16f75d6bedc1159b99a2a7a0e89', 'message': 'temprevert : Configuration agent for Cisco devices\n\nTemp revert of Ic887a93480eca0b56049c67e32c98658e3a4427f\n\nChange-Id: I86c7b6c774c1a3ca578f8d33b2cf22c412cf80e3\n'}]",0,111388,2f892205a7cbe16f75d6bedc1159b99a2a7a0e89,6,2,1,1926,,,0,"temprevert : Configuration agent for Cisco devices

Temp revert of Ic887a93480eca0b56049c67e32c98658e3a4427f

Change-Id: I86c7b6c774c1a3ca578f8d33b2cf22c412cf80e3
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/88/111388/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,2f892205a7cbe16f75d6bedc1159b99a2a7a0e89,revert,# https://review.openstack.org/#/c/103593/ (revert Configuration agent for Cisco devices) temprevert neutron 334aeccd3f0fe34cbd980df7b1bc490616eb1eb1 1351466,,2,0
openstack%2Ftripleo-ci~master~I7e9b905f353011323c7cacc43a3f1a7c27205cb0,openstack/tripleo-ci,master,I7e9b905f353011323c7cacc43a3f1a7c27205cb0,Specify the control plane network for testenvs.,MERGED,2014-07-23 01:47:57.000000000,2014-08-11 08:51:59.000000000,2014-08-11 08:51:58.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 7144}, {'_account_id': 8449}, {'_account_id': 9369}]","[{'number': 1, 'created': '2014-07-23 01:47:57.000000000', 'files': ['heat-templates/testenv-workers.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e3eba95cdbf01315362e6b87cdf6008424a8ca88', 'message': 'Specify the control plane network for testenvs.\n\nWe now have two networks (public and ctlplane) on the undercloud so\nwe need to choose.\n\nChange-Id: I7e9b905f353011323c7cacc43a3f1a7c27205cb0\n'}]",0,108876,e3eba95cdbf01315362e6b87cdf6008424a8ca88,17,5,1,4190,,,0,"Specify the control plane network for testenvs.

We now have two networks (public and ctlplane) on the undercloud so
we need to choose.

Change-Id: I7e9b905f353011323c7cacc43a3f1a7c27205cb0
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/76/108876/1 && git format-patch -1 --stdout FETCH_HEAD,['heat-templates/testenv-workers.yaml'],1,e3eba95cdbf01315362e6b87cdf6008424a8ca88,, networks: - network: ctlplane,,2,0
openstack%2Ffuel-library~master~I67d471a120506f8a182a7b5d2f7110f2c7ce27ce,openstack/fuel-library,master,I67d471a120506f8a182a7b5d2f7110f2c7ce27ce,Use modulepath as base for package versions yaml path,MERGED,2014-08-04 12:52:26.000000000,2014-08-11 08:43:42.000000000,2014-08-11 08:43:42.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8749}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 10391}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-08-04 12:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/31d0f981f02a8d3cb6fda0309a60a97f660a3f03', 'message': ""Use modulepath as base for package versions yaml path\n\nUses Puppet's modulepath variable to find path\nto manifests/(centos|ubuntu)-versions.yaml in a\nreliable method that works with custom modulepath\nspecified during puppet invocation.\n\nChange-Id: I67d471a120506f8a182a7b5d2f7110f2c7ce27ce\nCloses-Bug: #1346247\n""}, {'number': 2, 'created': '2014-08-05 17:20:26.000000000', 'files': ['deployment/puppet/package/lib/puppet/type/package.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6a1de5c9acad5331b0ac5748682df3b7eb11c147', 'message': ""Use modulepath as base for package versions yaml path\n\nUses Puppet's modulepath variable to find path\nto manifests/(centos|ubuntu)-versions.yaml in a\nreliable method that works with custom modulepath\nspecified during puppet invocation.\n\nChange-Id: I67d471a120506f8a182a7b5d2f7110f2c7ce27ce\nCloses-Bug: #1346247\n""}]",5,111710,6a1de5c9acad5331b0ac5748682df3b7eb11c147,28,8,2,7195,,,0,"Use modulepath as base for package versions yaml path

Uses Puppet's modulepath variable to find path
to manifests/(centos|ubuntu)-versions.yaml in a
reliable method that works with custom modulepath
specified during puppet invocation.

Change-Id: I67d471a120506f8a182a7b5d2f7110f2c7ce27ce
Closes-Bug: #1346247
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/10/111710/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/package/lib/puppet/type/package.rb'],1,31d0f981f02a8d3cb6fda0309a60a97f660a3f03,bug/1346247," module_path = Puppet.settings[:modulepath] manifests_dir = File.join(File.dirname(module_path), 'manifests') when :apt then manifests_dir + 'ubuntu-versions.yaml' when :yum then manifests_dir + 'centos-versions.yaml'", when :apt then '/etc/puppet/manifests/ubuntu-versions.yaml' when :yum then '/etc/puppet/manifests/centos-versions.yaml',4,3
openstack%2Fneutron~master~I01996859e9e3e44611a000ea97b3801407a5f8aa,openstack/neutron,master,I01996859e9e3e44611a000ea97b3801407a5f8aa,Ensure db.clear_db is called after test success/fail,ABANDONED,2014-08-06 12:56:07.000000000,2014-08-11 08:38:18.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10068}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10370}, {'_account_id': 10386}]","[{'number': 1, 'created': '2014-08-06 12:56:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7b3ebd8e87c2cd498f06abe23efdea4b04465bd6', 'message': 'Ensure db.clear_db is called after test success/fail\n\nReplace db.clear_db call in tearDown by an addCleanup in setUp\n\nChange-Id: I01996859e9e3e44611a000ea97b3801407a5f8aa\n'}, {'number': 2, 'created': '2014-08-06 14:00:22.000000000', 'files': ['neutron/tests/unit/cisco/n1kv/test_n1kv_db.py', 'neutron/tests/unit/cisco/n1kv/test_n1kv_plugin.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/tests/unit/embrane/test_embrane_neutron_plugin.py', 'neutron/tests/unit/ml2/drivers/test_l2population.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc571a386a5b5f41f52e1b2f854a871f0db9fe1b', 'message': 'Ensure db.clear_db is called after test success/fail\n\nReplace db.clear_db call in tearDown by an addCleanup in setUp\n\nChange-Id: I01996859e9e3e44611a000ea97b3801407a5f8aa\n'}]",0,112291,bc571a386a5b5f41f52e1b2f854a871f0db9fe1b,39,19,2,12036,,,0,"Ensure db.clear_db is called after test success/fail

Replace db.clear_db call in tearDown by an addCleanup in setUp

Change-Id: I01996859e9e3e44611a000ea97b3801407a5f8aa
",git fetch https://review.opendev.org/openstack/neutron refs/changes/91/112291/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/cisco/n1kv/test_n1kv_db.py', 'neutron/tests/unit/cisco/n1kv/test_n1kv_plugin.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/tests/unit/embrane/test_embrane_neutron_plugin.py', 'neutron/tests/unit/ml2/drivers/test_l2population.py']",5,7b3ebd8e87c2cd498f06abe23efdea4b04465bd6,,, self.addCleanup(db_api.clear_db) ,1,6
openstack%2Fheat~master~Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29,openstack/heat,master,Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29,Add native WaitConditionHandle resource,MERGED,2014-06-26 16:56:10.000000000,2014-08-11 08:21:01.000000000,2014-08-04 01:22:27.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7404}, {'_account_id': 7761}, {'_account_id': 8246}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-06-26 16:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a02e6b396563593f35aa844fc5a225ada9a5e654', 'message': 'Add native WaitConditionHandle resource\n\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 2, 'created': '2014-07-02 16:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/eacf0bd24f096e5ae613dc1e6115e87f7155760a', 'message': 'Add native WaitConditionHandle resource\n\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 3, 'created': '2014-07-03 13:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/88cbd86d89e6b40c09ed8c1b2c47f6e3eb4ca6d1', 'message': 'Add native WaitConditionHandle resource\n\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 4, 'created': '2014-07-03 15:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a8e1ba6ac1ad88f45cf7e535af149e674356b9bf', 'message': 'Add native WaitConditionHandle resource\n\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 5, 'created': '2014-07-08 09:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cf9249a08f84d48bffd4e5c6b6b6bc0c87b0f735', 'message': 'Add native WaitConditionHandle resource\n\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 6, 'created': '2014-07-08 14:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d1400228e9664d2c9d232599633fa348c5628661', 'message': 'Add native WaitConditionHandle resource\n\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 7, 'created': '2014-07-08 15:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f9d805bf920a9de0d6afbb1db3cb7a645e7854c8', 'message': 'Add native WaitConditionHandle resource\n\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 8, 'created': '2014-07-08 18:29:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/768019d2111af2039ee774390dfaabed1906361a', 'message': 'Add native WaitConditionHandle resource\n\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 9, 'created': '2014-07-10 16:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bc1dd1b242afb0a07c81a818b6f1e1872539c470', 'message': 'Add native WaitConditionHandle resource\n\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 10, 'created': '2014-07-11 16:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/50452c0f0afd7e64d8957cbfaf37729f41f14ed6', 'message': 'Add native WaitConditionHandle resource\n\nAdds a native OS::HeatWaitConditionHandle resource, which works\nin a similar way to the CFN compatible one, but with a few changes\nto make it simpler to use:\n- The data passed is validated less strictly, so we tolerate missing keys\n  for any of the data (we just fill in default values)\n- A signal passed with no data is assumed to mean success\n- There are two convenience attributes which provide a string representing\n  the necessary curl call to send the signal (to the native ReST API)\n\nThis allows a similarly simple signalling mechanism to the CFN compatible\nHandle resource, but with no dependency on the ec2tokens keystone extension\nor heat-api-cfn service.\n\nSome usage examples here:\n  - https://review.openstack.org/106424\n\nblueprint: native-waitcondition\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 11, 'created': '2014-07-14 17:28:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/762905457c03824f7cc41fdd078696eb7f93f1b4', 'message': 'Add native WaitConditionHandle resource\n\nAdds a native OS::HeatWaitConditionHandle resource, which works\nin a similar way to the CFN compatible one, but with a few changes\nto make it simpler to use:\n- The data passed is validated less strictly, so we tolerate missing keys\n  for any of the data (we just fill in default values)\n- A signal passed with no data is assumed to mean success\n- There are two convenience attributes which provide a string representing\n  the necessary curl call to send the signal (to the native ReST API)\n\nThis allows a similarly simple signalling mechanism to the CFN compatible\nHandle resource, but with no dependency on the ec2tokens keystone extension\nor heat-api-cfn service.\n\nSome usage examples here:\n  - https://review.openstack.org/106424\n\nblueprint: native-waitcondition\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 12, 'created': '2014-07-15 13:01:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/67e532c8e82e17fa284c222cca9df530f53d687d', 'message': 'Add native WaitConditionHandle resource\n\nAdds a native OS::HeatWaitConditionHandle resource, which works\nin a similar way to the CFN compatible one, but with a few changes\nto make it simpler to use:\n- The data passed is validated less strictly, so we tolerate missing keys\n  for any of the data (we just fill in default values)\n- A signal passed with no data is assumed to mean success\n- There are two convenience attributes which provide a string representing\n  the necessary curl call to send the signal (to the native ReST API)\n\nThis allows a similarly simple signalling mechanism to the CFN compatible\nHandle resource, but with no dependency on the ec2tokens keystone extension\nor heat-api-cfn service.\n\nSome usage examples here:\n  - https://review.openstack.org/106424\n\nblueprint: native-waitcondition\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 13, 'created': '2014-07-15 13:14:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ba1599bba9da71cd7f1bac26e82e279f225600dc', 'message': 'Add native WaitConditionHandle resource\n\nAdds a native OS::HeatWaitConditionHandle resource, which works\nin a similar way to the CFN compatible one, but with a few changes\nto make it simpler to use:\n- The data passed is validated less strictly, so we tolerate missing keys\n  for any of the data (we just fill in default values)\n- A signal passed with no data is assumed to mean success\n- There are two convenience attributes which provide a string representing\n  the necessary curl call to send the signal (to the native ReST API)\n\nThis allows a similarly simple signalling mechanism to the CFN compatible\nHandle resource, but with no dependency on the ec2tokens keystone extension\nor heat-api-cfn service.\n\nSome usage examples here:\n  - https://review.openstack.org/106424\n\nblueprint: native-waitcondition\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 14, 'created': '2014-07-16 12:16:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ee0341628ba6427e988ab512ffa0dfbfc4a526d0', 'message': 'Add native WaitConditionHandle resource\n\nAdds a native OS::HeatWaitConditionHandle resource, which works\nin a similar way to the CFN compatible one, but with a few changes\nto make it simpler to use:\n- The data passed is validated less strictly, so we tolerate missing keys\n  for any of the data (we just fill in default values)\n- A signal passed with no data is assumed to mean success\n- There are two convenience attributes which provide a string representing\n  the necessary curl call to send the signal (to the native ReST API)\n\nThis allows a similarly simple signalling mechanism to the CFN compatible\nHandle resource, but with no dependency on the ec2tokens keystone extension\nor heat-api-cfn service.\n\nSome usage examples here:\n  - https://review.openstack.org/106424\n\nblueprint: native-waitcondition\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 15, 'created': '2014-07-16 18:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c332b4f41a255333ab2ee84ee31aed3df027adce', 'message': 'Add native WaitConditionHandle resource\n\nAdds a native OS::HeatWaitConditionHandle resource, which works\nin a similar way to the CFN compatible one, but with a few changes\nto make it simpler to use:\n- The data passed is validated less strictly, so we tolerate missing keys\n  for any of the data (we just fill in default values)\n- A signal passed with no data is assumed to mean success\n- There are two convenience attributes which provide a string representing\n  the necessary curl call to send the signal (to the native ReST API)\n\nThis allows a similarly simple signalling mechanism to the CFN compatible\nHandle resource, but with no dependency on the ec2tokens keystone extension\nor heat-api-cfn service.\n\nSome usage examples here:\n  - https://review.openstack.org/106424\n\nblueprint: native-waitcondition\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 16, 'created': '2014-07-21 14:29:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f4093dd64893e96c7c0fddf5c425739bedbe5b6a', 'message': 'Add native WaitConditionHandle resource\n\nAdds a native OS::HeatWaitConditionHandle resource, which works\nin a similar way to the CFN compatible one, but with a few changes\nto make it simpler to use:\n- The data passed is validated less strictly, so we tolerate missing keys\n  for any of the data (we just fill in default values)\n- A signal passed with no data is assumed to mean success\n- There are two convenience attributes which provide a string representing\n  the necessary curl call to send the signal (to the native ReST API)\n\nThis allows a similarly simple signalling mechanism to the CFN compatible\nHandle resource, but with no dependency on the ec2tokens keystone extension\nor heat-api-cfn service.\n\nSome usage examples here:\n  - https://review.openstack.org/106424\n\nblueprint: native-waitcondition\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 17, 'created': '2014-07-23 19:53:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/63f7038758e6e3cd8fcb0fd86a96d40c069d9ed1', 'message': 'Add native WaitConditionHandle resource\n\nAdds a native OS::HeatWaitConditionHandle resource, which works\nin a similar way to the CFN compatible one, but with a few changes\nto make it simpler to use:\n- The data passed is validated less strictly, so we tolerate missing keys\n  for any of the data (we just fill in default values)\n- A signal passed with no data is assumed to mean success\n- There are two convenience attributes which provide a string representing\n  the necessary curl call to send the signal (to the native ReST API)\n\nThis allows a similarly simple signalling mechanism to the CFN compatible\nHandle resource, but with no dependency on the ec2tokens keystone extension\nor heat-api-cfn service.\n\nSome usage examples here:\n  - https://review.openstack.org/106424\n\nblueprint: native-waitcondition\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 18, 'created': '2014-07-24 19:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d7ab9459beeffab59b2e7676c8605dea8571eb27', 'message': 'Add native WaitConditionHandle resource\n\nAdds a native OS::HeatWaitConditionHandle resource, which works\nin a similar way to the CFN compatible one, but with a few changes\nto make it simpler to use:\n- The data passed is validated less strictly, so we tolerate missing keys\n  for any of the data (we just fill in default values)\n- A signal passed with no data is assumed to mean success\n- There are two convenience attributes which provide a string representing\n  the necessary curl call to send the signal (to the native ReST API)\n\nThis allows a similarly simple signalling mechanism to the CFN compatible\nHandle resource, but with no dependency on the ec2tokens keystone extension\nor heat-api-cfn service.\n\nSome usage examples here:\n  - https://review.openstack.org/106424\n\nblueprint: native-waitcondition\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}, {'number': 19, 'created': '2014-07-25 13:14:03.000000000', 'files': ['heat/tests/fakes.py', 'heat/tests/test_waitcondition.py', 'heat/engine/resources/wait_condition.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/adf02483dcc386b9ed1dd81c4f48d10c42490ef5', 'message': 'Add native WaitConditionHandle resource\n\nAdds a native OS::HeatWaitConditionHandle resource, which works\nin a similar way to the CFN compatible one, but with a few changes\nto make it simpler to use:\n- The data passed is validated less strictly, so we tolerate missing keys\n  for any of the data (we just fill in default values)\n- A signal passed with no data is assumed to mean success\n- There are two convenience attributes which provide a string representing\n  the necessary curl call to send the signal (to the native ReST API)\n\nThis allows a similarly simple signalling mechanism to the CFN compatible\nHandle resource, but with no dependency on the ec2tokens keystone extension\nor heat-api-cfn service.\n\nSome usage examples here:\n  - https://review.openstack.org/106424\n\nblueprint: native-waitcondition\nChange-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29\n'}]",26,102888,adf02483dcc386b9ed1dd81c4f48d10c42490ef5,91,9,19,4328,,,0,"Add native WaitConditionHandle resource

Adds a native OS::HeatWaitConditionHandle resource, which works
in a similar way to the CFN compatible one, but with a few changes
to make it simpler to use:
- The data passed is validated less strictly, so we tolerate missing keys
  for any of the data (we just fill in default values)
- A signal passed with no data is assumed to mean success
- There are two convenience attributes which provide a string representing
  the necessary curl call to send the signal (to the native ReST API)

This allows a similarly simple signalling mechanism to the CFN compatible
Handle resource, but with no dependency on the ec2tokens keystone extension
or heat-api-cfn service.

Some usage examples here:
  - https://review.openstack.org/106424

blueprint: native-waitcondition
Change-Id: Ie9b5aeb13bfab5fba55c1a49d1572e0777864b29
",git fetch https://review.opendev.org/openstack/heat refs/changes/88/102888/6 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_waitcondition.py', 'heat/engine/resources/wait_condition.py']",2,a02e6b396563593f35aa844fc5a225ada9a5e654,bp/native-waitcondition8,"import uuidclass BaseWaitConditionHandle(signal_responder.SignalResponder): ''' Base WaitConditionHandle resource. The main point of this class is to : - have no dependencies (so the instance can reference it) - create credentials to allow for signalling from the instance. - handle signals from the instance, validate and store result ''' properties_schema = {} def handle_create(self): super(BaseWaitConditionHandle, self).handle_create() self.resource_id_set(self._get_user_id()) def _status_ok(self, status): return status in self.WAIT_STATUSES def _metadata_format_ok(self, metadata): if sorted(tuple(metadata.keys())) == sorted(self.METADATA_KEYS): return self._status_ok(metadata[self.STATUS]) def handle_signal(self, metadata=None): if self._metadata_format_ok(metadata): rsrc_metadata = self.metadata_get(refresh=True) if metadata[self.UNIQUE_ID] in rsrc_metadata: LOG.warning(_(""Overwriting Metadata item for id %s!"") % metadata[self.UNIQUE_ID]) safe_metadata = {} for k in self.METADATA_KEYS: if k == self.UNIQUE_ID: continue safe_metadata[k] = metadata[k] rsrc_metadata.update({metadata[self.UNIQUE_ID]: safe_metadata}) self.metadata_set(rsrc_metadata) else: LOG.error(_(""Metadata failed validation for %s"") % self.name) raise ValueError(_(""Metadata format invalid"")) def get_status(self): ''' Return a list of the Status values for the handle signals ''' return [v[self.STATUS] for v in self.metadata_get(refresh=True).values()] def get_status_reason(self, status): ''' Return a list of reasons associated with a particular status ''' return [v[self.REASON] for v in self.metadata_get(refresh=True).values() if v[self.STATUS] == status] class HeatWaitConditionHandle(BaseWaitConditionHandle): WAIT_STATUSES = ( STATUS_FAILURE, STATUS_SUCCESS, ) = ( 'FAILED', 'COMPLETE', ) METADATA_KEYS = ( DATA, REASON, STATUS, UNIQUE_ID ) = ( 'data', 'reason', 'status', 'id' ) ATTRIBUTES = ( TOKEN, ENDPOINT, CURL_CLI, ) = ( 'token', 'endpoint', 'curl_cli', ) attributes_schema = { TOKEN: attributes.Schema( _('Token for stack-user which can be used for signalling handle'), cache_mode=attributes.Schema.CACHE_NONE ), ENDPOINT: attributes.Schema( _('Endpoint/url which can be used for signalling handle'), cache_mode=attributes.Schema.CACHE_NONE ), CURL_CLI: attributes.Schema( _('Convenience attribute, provides curl CLI command ' 'which can be used for signalling handle'), cache_mode=attributes.Schema.CACHE_NONE ), } def handle_create(self): password = uuid.uuid4().hex self.data_set('password', password, True) self._create_user() self.resource_id_set(self._get_user_id()) # FIXME(shardy): The assumption here is that token expiry > timeout # but we probably need a check here to fail fast if that's not true # Also need to implement an update property, such that the handle # can be replaced on update which will replace the token token = self._user_token() self.data_set('token', token, True) self.data_set('endpoint', self._get_resource_endpoint(), True) def _get_resource_endpoint(self): # Get the endpoint from stack.clients then replace the context # project_id in the path to the resource (which includes the # context project_id), then replace the context project with # the one needed for signalling from the stack_user_project endpoint = self.stack.clients.get_heat_url() rsrc_ep = endpoint.replace(self.context.tenant_id, self.identifier().url_path()) return rsrc_ep.replace(self.context.tenant_id, self.stack.stack_user_project_id) def handle_delete(self): self._delete_user() @property def password(self): return self.data().get('password') def _resolve_attribute(self, key): if self.resource_id: if key == self.TOKEN: return self.data().get('token') elif key == self.ENDPOINT: return self.data().get('endpoint') elif key == self.CURL_CLI: # Construct curl command for template-author convenience return ('curl -i -X POST ' '-H \'X-Auth-Token: %(token)s\' ' '-H \'Content-Type: application/json\' ' '-H \'Accept: application/json\' ' '%(endpoint)s/signal' % dict(token=self.data().get('token'), endpoint=self.data().get('endpoint'))) def handle_signal(self, new_metadata=None): ''' Validate and update the resource metadata. metadata is not mandatory, but if passed it must use the following format: { ""status"" : ""Status (must be SUCCESS or FAILURE)"" ""data"" : ""Arbitrary data"", ""reason"" : ""Reason string"" } Optionally ""id"" may also be specified, but if missing the index of the signal recieved will be used. ''' rsrc_metadata = self.metadata_get(refresh=True) signal_num = len(rsrc_metadata) + 1 if new_metadata is None: metadata = { self.STATUS: self.STATUS_SUCCESS, self.REASON: 'Signal %s recieved' % signal_num, self.DATA: None, self.UNIQUE_ID: signal_num} else: metadata = new_metadata if self.UNIQUE_ID not in metadata: metadata[self.UNIQUE_ID] = signal_num super(HeatWaitConditionHandle, self).handle_signal(metadata) class WaitConditionHandle(BaseWaitConditionHandle): metadata must use the following format: { ""Status"" : ""Status (must be SUCCESS or FAILURE)"" ""UniqueId"" : ""Some ID, should be unique for Count>1"", ""Data"" : ""Arbitrary Data"", ""Reason"" : ""Reason String"" } super(WaitConditionHandle, self).handle_signal(new_metadata) 'OS::Heat::WaitConditionHandle': HeatWaitConditionHandle,","class WaitConditionHandle(signal_responder.SignalResponder): properties_schema = {} def _metadata_format_ok(self, metadata): """""" Check the format of the provided metadata is as expected. metadata must use the following format: { ""Status"" : ""Status (must be SUCCESS or FAILURE)"" ""UniqueId"" : ""Some ID, should be unique for Count>1"", ""Data"" : ""Arbitrary Data"", ""Reason"" : ""Reason String"" } """""" if tuple(sorted(metadata.keys())) == self.METADATA_KEYS: return metadata[self.STATUS] in self.WAIT_STATUSES if self._metadata_format_ok(new_metadata): rsrc_metadata = self.metadata_get(refresh=True) if new_metadata[self.UNIQUE_ID] in rsrc_metadata: LOG.warning(_(""Overwriting Metadata item for UniqueId %s!"") % new_metadata[self.UNIQUE_ID]) safe_metadata = {} for k in self.METADATA_KEYS: if k == self.UNIQUE_ID: continue safe_metadata[k] = new_metadata[k] rsrc_metadata.update({new_metadata[self.UNIQUE_ID]: safe_metadata}) self.metadata_set(rsrc_metadata) else: LOG.error(_(""Metadata failed validation for %s"") % self.name) raise ValueError(_(""Metadata format invalid"")) def get_status(self): ''' Return a list of the Status values for the handle signals ''' return [v[self.STATUS] for v in self.metadata_get(refresh=True).values()] def get_status_reason(self, status): ''' Return a list of reasons associated with a particular status ''' return [v[self.REASON] for v in self.metadata_get(refresh=True).values() if v[self.STATUS] == status]",409,52
openstack%2Ffuel-library~stable%2F5.0~I1d9e79a9ef28076f83dd9426d17de7d8d4b97d30,openstack/fuel-library,stable/5.0,I1d9e79a9ef28076f83dd9426d17de7d8d4b97d30,cron job to clean up rabbitmq connections,MERGED,2014-08-07 20:25:13.000000000,2014-08-11 08:18:14.000000000,2014-08-11 08:18:14.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-08-07 20:25:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/82c0400a3f4c5565e4504f5673138f95de768f8e', 'message': ""cron job to clean up rabbitmq connections\n\nInstall a cleanup script to terminate RabbitMQ connections that don't\nhave any channels, set up a cron job to run the script every minute.\n\nChange-Id: I1d9e79a9ef28076f83dd9426d17de7d8d4b97d30\nRelated-Bug: #856764\n""}, {'number': 2, 'created': '2014-08-07 22:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b352a3c4ae1f1f12950c1b48e3845d9af3d7564a', 'message': ""cron job to clean up rabbitmq connections\n\nInstall a cleanup script to terminate RabbitMQ connections that don't\nhave any channels, set up a cron job to run the script every minute.\n\nChange-Id: I1d9e79a9ef28076f83dd9426d17de7d8d4b97d30\nRelated-Bug: #856764\n""}, {'number': 3, 'created': '2014-08-07 23:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e4adb485aa6051f7cee685b4e1e362d87e3b3d83', 'message': ""cron job to clean up rabbitmq connections\n\nInstall a cleanup script to terminate RabbitMQ connections that don't\nhave any channels, set up a cron job to run the script every minute.\n\nChange-Id: I1d9e79a9ef28076f83dd9426d17de7d8d4b97d30\nRelated-Bug: #856764\n""}, {'number': 4, 'created': '2014-08-08 02:18:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e89ee42db8c813eae3582e2249776eed508a979a', 'message': ""cron job to clean up rabbitmq connections\n\nInstall a cleanup script to terminate RabbitMQ connections that don't\nhave any channels, set up a cron job to run the script every minute.\n\nChange-Id: I1d9e79a9ef28076f83dd9426d17de7d8d4b97d30\nRelated-Bug: #856764\n""}, {'number': 5, 'created': '2014-08-08 10:57:11.000000000', 'files': ['deployment/puppet/openstack/templates/rabbitmq-connections-cleanup.conf.erb', 'deployment/puppet/openstack/manifests/ha/rabbitmq_connections_cleanup.pp', 'deployment/puppet/openstack/manifests/controller_ha.pp', 'deployment/puppet/openstack/templates/rabbitmq-connections-cleanup'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/27838e431636853daa748a35d1789148aad94ab2', 'message': ""cron job to clean up rabbitmq connections\n\nInstall a cleanup script to terminate RabbitMQ connections that don't\nhave any channels, set up a cron job to run the script every minute.\n\nChange-Id: I1d9e79a9ef28076f83dd9426d17de7d8d4b97d30\nRelated-Bug: #856764\n""}]",0,112681,27838e431636853daa748a35d1789148aad94ab2,44,6,5,8787,,,0,"cron job to clean up rabbitmq connections

Install a cleanup script to terminate RabbitMQ connections that don't
have any channels, set up a cron job to run the script every minute.

Change-Id: I1d9e79a9ef28076f83dd9426d17de7d8d4b97d30
Related-Bug: #856764
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/81/112681/5 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/templates/rabbitmq-connections-cleanup.conf.erb', 'deployment/puppet/openstack/templates/rabbitmq-connections-cleanup.py', 'deployment/puppet/openstack/manifests/ha/rabbitmq_connections_cleanup.pp', 'deployment/puppet/openstack/manifests/controller_ha.pp']",4,82c0400a3f4c5565e4504f5673138f95de768f8e,bug/856764, class {'openstack::ha::rabbitmq_connections_cleanup': } ,,149,0
openstack%2Foctavia~master~I1b73b3839b86198f3d56587ca3fb2644dc231f00,openstack/octavia,master,I1b73b3839b86198f3d56587ca3fb2644dc231f00,Documenting project direction and design,MERGED,2014-07-30 08:01:35.000000000,2014-08-11 08:15:02.000000000,2014-08-08 19:46:29.000000000,"[{'_account_id': 3}, {'_account_id': 6437}, {'_account_id': 10750}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11628}, {'_account_id': 11685}]","[{'number': 1, 'created': '2014-07-30 08:01:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/bf728e3fd2713be6a11c19abc815daed9e0fb047', 'message': ""Documenting project direction and design\n\nThis commit isn't yet complete as I've not yet imported the\ndesigns already discussed via the mailing list. However I wanted\nto get the constitution and draft roadmap into people's hands so\nwe can start getting feedback on where we're going with this, eh.\n\nChange-Id: I1b73b3839b86198f3d56587ca3fb2644dc231f00\n""}, {'number': 2, 'created': '2014-08-01 21:53:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/a56902e4e58d89e692353f43e540d78529baf1ce', 'message': ""Documenting project direction and design\n\nThis commit adds documentation around project direction and conventions.\nAdditionally, I've added doc8 checks to make sure or .rst and .txt files\nin this repository follow good conventions, and fixed a check related to\ngraphviz external .dot files.\n\nChange-Id: I1b73b3839b86198f3d56587ca3fb2644dc231f00\n""}, {'number': 3, 'created': '2014-08-01 22:39:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d16b5d868d6b00a5ad35f91e0470d546005e1f0e', 'message': ""Documenting project direction and design\n\nThis commit adds documentation around project direction and conventions.\nAdditionally, I've added doc8 checks to make sure or .rst and .txt files\nin this repository follow good conventions, and fixed a check related to\ngraphviz external .dot files.\n\nChange-Id: I1b73b3839b86198f3d56587ca3fb2644dc231f00\n""}, {'number': 4, 'created': '2014-08-01 22:41:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/83b689986ef16487ea45099a99640f6129625dbd', 'message': ""Documenting project direction and design\n\nThis commit adds documentation around project direction and conventions.\nAdditionally, I've added doc8 checks to make sure or .rst and .txt files\nin this repository follow good conventions, and fixed a check related to\ngraphviz external .dot files.\n\nChange-Id: I1b73b3839b86198f3d56587ca3fb2644dc231f00\n""}, {'number': 5, 'created': '2014-08-02 03:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/42fc930049a62093d8ee86506a7c91ebf26f124c', 'message': ""Documenting project direction and design\n\nThis commit adds documentation around project direction and conventions.\nAdditionally, I've added doc8 checks to make sure or .rst and .txt files\nin this repository follow good conventions, and fixed a check related to\ngraphviz external .dot files.\n\nChange-Id: I1b73b3839b86198f3d56587ca3fb2644dc231f00\n""}, {'number': 6, 'created': '2014-08-02 03:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d729cf189a4667b5027f1fa3e9307c6c285b0319', 'message': ""Documenting project direction and design\n\nThis commit adds documentation around project direction and conventions.\nAdditionally, I've added doc8 checks to make sure or .rst and .txt files\nin this repository follow good conventions, and fixed a check related to\ngraphviz external .dot files.\n\nChange-Id: I1b73b3839b86198f3d56587ca3fb2644dc231f00\n""}, {'number': 7, 'created': '2014-08-02 04:47:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d01e3ad0271ad41d61c2fb961130f1edf63ad966', 'message': ""Documenting project direction and design\n\nThis commit adds documentation around project direction and conventions.\nAdditionally, I've added doc8 checks to make sure or .rst and .txt files\nin this repository follow good conventions, and fixed a check related to\ngraphviz external .dot files.\n\nChange-Id: I1b73b3839b86198f3d56587ca3fb2644dc231f00\n""}, {'number': 8, 'created': '2014-08-02 17:08:10.000000000', 'files': ['specs/example.dot', 'specs/template.rst', 'test-requirements.txt', 'ROADMAP.rst', 'README.rst', 'specs-tests/tests/test_titles.py', 'tox.ini', 'CONSTITUTION.rst', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/octavia/commit/3324e1219ac542d657d7b91bdd8d79bbc69d6115', 'message': ""Documenting project direction and design\n\nThis commit adds documentation around project direction and conventions.\nAdditionally, I've added doc8 checks to make sure or .rst and .txt files\nin this repository follow good conventions, and fixed a check related to\ngraphviz external .dot files.\n\nChange-Id: I1b73b3839b86198f3d56587ca3fb2644dc231f00\n""}]",16,110563,3324e1219ac542d657d7b91bdd8d79bbc69d6115,48,7,8,11685,,,0,"Documenting project direction and design

This commit adds documentation around project direction and conventions.
Additionally, I've added doc8 checks to make sure or .rst and .txt files
in this repository follow good conventions, and fixed a check related to
graphviz external .dot files.

Change-Id: I1b73b3839b86198f3d56587ca3fb2644dc231f00
",git fetch https://review.opendev.org/openstack/octavia refs/changes/63/110563/8 && git format-patch -1 --stdout FETCH_HEAD,"['ROADMAP.rst', 'README.rst', 'CONSTITUTION.rst']",3,bf728e3fd2713be6a11c19abc815daed9e0fb047,initial-design-and-direction,"==================== Octavia Constitution ==================== This document defines the guiding principles that project leadership will be following in creating, improving and maintaining the Octavia project. ===================== Governance philosophy ===================== Octavia is an OpenStack project ------------------------------- This means we try to run things the same way other ""canonized"" OpenStack projects operate from a procedural perspective. This is because we hope that Octavia will eventually become a standard part of any OpenStack deployment. Octavia is as open as OpenStack ------------------------------- Octavia tries to follow the same standards for openness that the OpenStack project also strives to follow: https://wiki.openstack.org/wiki/Open We are committed to open design, development, and community. Octavia is ""free"" ----------------- We mean that both in the ""beer"" and in the ""speech"" sense. That is to say, the reference implementation for Octavia should be made up only of open source components that share the same kind of unencumbered licensing that OpenStack uses. Note that this does not mean we are against having vendors develop products which can replace some of the components within Octavia. (For example, the Octavia VM images might be replaced by a vendor's proprietary VM image.) Rather, it means that: * The reference implementation should always be open source and unencumbered. * We are typically not interested in making design compromises in order to work with a vendor's proprietary product. If a vendor wants to develop a component for Octavia, then the vendor should bend to Octavia's needs, not the other way around. Octavia is a load balancer for large operators ---------------------------------------------- That's not to say that small operators can't use it. (In fact, we expect it to work well for small deployements, too.) But what we mean here is that if in creating, improving or maintaining Octavia we somehow make it unable to meet the needs of a typical large operator (or that operator's users), then we have failed. =============== Code guidelines =============== For the most part, Octavia tries to follow the coding standards set forth for the OpenStack project in general: http://docs.openstack.org/developer/hacking/ More specific additional standards can be found in the HACKING.rst file in the same directory as this constitution. Any exceptions should be well justified and documented. (Comments in or near the breach in coding standards are usually sufficient documentation.) As far as coding philosophy is concerned, please consider the following guidelines: Everything is python -------------------- Although OpenStack apparently allows either python or C++ code, at this time we don't envision needing anything other than python (and standard, supported open source modules) for anything we intend to do in Octavia. Idempotency ----------- With as much as is going on inside Octavia, its likely that certain messages and commands will be repeatedly processed. It's important that this doesn't break the functionality of the load balancing service. Therefore, as much as possible, algorithms and interfaces should be made as idempotent as possible. Centralize intelligence, de-centralize workload ----------------------------------------------- This means that tasks which need to be done relatively infrequently but require either additional knowledge about the state of other components in the Octavia system, advanced logic behind decisions, or otherwise a high degree of intelligence should be done by centralized components (ex. controllers) within the Octavia system. Examples of this might include: * Generating haproxy configuration files * Managing the lifecycle of Octavia VMs * Moving a loadbalancer instance from one Octavia VM to another. On the other hand, tasks done extremely often, or which entail a significant load on the system should be pushed as far out to the most horizontally scalable components as possible. Examples of this might include: * Serving actual client requests to end-users (ie. running haproxy) * Monitoring pool members for failure and sending notifications about this * Processing log files There will often be a balance that needs to be struck between these two design considerations for any given task for which an algorithm needs to be designed. In considering how to strike this balance, always consider the conditions that will be present in a large operator environment. Also, as a secondary benefit of the above, minor feature additions and bugfixes can often be accomplished in a large operator environment without having to touch every Octavia VM running in said environment. All APIs are versioned ------------------------------ This includes ""internal"" APIs between Octavia components. Experience coding in the Neutron LBaaS project has taught us that in a large project with many heterogenous parts, throughout the lifecycle of this project, different parts will evolve at different rates. It is important that these components are allowed to do so without hindering or being hindered by parallel development in other components. It is also likely that in very large deployments, there might be tens- or hundreds-of-thousands of individual instances of a given component deployed (most likely, the Octavia VMs). It is unreasonable to expect a large operator to update all of these components at once. Therefore it is likely that for a significant amount of time during a roll-out of a new version, both the old and new versions of a given component must be able to be controlled or otherwise interfaced with by the new components. Both of the above considerations can be allowed for if we use versioning of APIs where components interact with each other. Scalability and resilience are as important as functionality ------------------------------------------------------------ Octavia is meant to be an *operator scale* load balancer. As such, it's usually not enough just to get something working: It also needs to be scalable. For most components, ""scalable"" implies horizontally scalable. In any large operational environment, resilience to failures is a necessity. Practically speaking, this means that all components of the system that make up Octavia should be monitored in one way or another, and that where possible automatic recovery from the most common kinds of failures should become a standard feature. Where automatic recovery is not an option, then some form of notification about the failure should be implemented. Avoid premature optimization ---------------------------- Understand that being ""high performance"" is often not the same thing as being ""scalable."" First get the thing to work in an intelligent way. Only worry about making it fast if speed becomes an issue. Security is not an afterthought ------------------------------- The load balancer is often both the most visible public interface to a given user application, but load balancers themselves often have direct access to sensitive components and data within the application environment. Security bugs will happen, but in general we should not approve designs which have known significant security problems, or which could be made more secure by better design. Octavia should follow industry standards ---------------------------------------- By ""industry standards"" we either mean RFCs or well-established best practices. We are generally not interested in defining new standards if a prior open standard already exists. We should also avoid doing things which directly or indirectly contradict established standards. ",,307,3
openstack%2Ffuel-web~master~Ie48a6a95301eeb070905946100e5282ea9f954fb,openstack/fuel-web,master,Ie48a6a95301eeb070905946100e5282ea9f954fb,Enable Ceph role for vCenter environment,ABANDONED,2014-08-01 12:40:12.000000000,2014-08-11 07:52:02.000000000,,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}]","[{'number': 1, 'created': '2014-08-01 12:40:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/495f63a4a7576f6e414c90ed7177969b6a8d53ac', 'message': 'Enable Ceph role for vCenter environment\n\nCloses-Bug:#1351288\n\nChange-Id: Ie48a6a95301eeb070905946100e5282ea9f954fb\n'}, {'number': 2, 'created': '2014-08-08 09:07:26.000000000', 'files': ['nailgun/nailgun/fixtures/openstack.yaml', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/node_list_screen.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/dd9239c0472dec301ecc67a52f81741c9d5096f0', 'message': 'Enable Ceph role for vCenter environment\n\nCloses-Bug:#1351288\n\nChange-Id: Ie48a6a95301eeb070905946100e5282ea9f954fb\n'}]",0,111262,dd9239c0472dec301ecc67a52f81741c9d5096f0,23,5,2,8766,,,0,"Enable Ceph role for vCenter environment

Closes-Bug:#1351288

Change-Id: Ie48a6a95301eeb070905946100e5282ea9f954fb
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/62/111262/2 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/fixtures/openstack.yaml', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/node_list_screen.js']",2,495f63a4a7576f6e414c90ed7177969b6a8d53ac,bug/1351288," if (unavailable) { role.set({unavailable: true, unavailabityReason: _.compact(unavailabityReasons).join(' ')});"," // FIXME(vk): hack for vCenter, do not allow ceph and controllers // has to be removed when we describe it in role metadata if (this.settings.get('common.libvirt_type.value') == 'vcenter') { if (role.get('name') == 'compute') { unavailable = true; unavailabityReasons.push('Computes cannot be used with vCenter'); } else if (role.get('name') == 'ceph-osd') { unavailable = true; unavailabityReasons.push('Ceph cannot be used with vCenter'); } } if (unavailable) { role.set({unavailable: true, unavailabityReason: unavailabityReasons.join(' ')});",4,13
openstack%2Fhorizon~master~I08fe4aa1d1ab1d131153c1a02e37b27dabc8de0b,openstack/horizon,master,I08fe4aa1d1ab1d131153c1a02e37b27dabc8de0b,Fix for Sahara Cluster Templates,ABANDONED,2014-08-01 12:14:10.000000000,2014-08-11 07:49:45.000000000,,"[{'_account_id': 3}, {'_account_id': 8090}]","[{'number': 1, 'created': '2014-08-01 12:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/424fe9a1e6c7d52e837ce37c425ad0384d5cd325', 'message': 'Fix for Sahara Cluster Templates\n\nThe form field class changed from ""control-group"" to ""form-group"".\n\nThe js updated to work with new class.\n\nChange-Id: I08fe4aa1d1ab1d131153c1a02e37b27dabc8de0b\n'}, {'number': 2, 'created': '2014-08-01 12:21:49.000000000', 'files': ['openstack_dashboard/dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/cluster_node_groups_template.html', 'openstack_dashboard/dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/cluster_templates.html', 'openstack_dashboard/dashboards/project/data_processing/jobs/templates/data_processing.jobs/library_template.html', 'openstack_dashboard/dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_fields_help.html', 'openstack_dashboard/dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/job_binaries_form_script.html', 'openstack_dashboard/dashboards/project/data_processing/clusters/templates/data_processing.clusters/clusters.html', 'openstack_dashboard/dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/job_executions.html', 'openstack_dashboard/dashboards/project/data_processing/jobs/templates/data_processing.jobs/jobs.html', 'openstack_dashboard/dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html', 'openstack_dashboard/dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/data_sources_form_script.html', 'openstack_dashboard/dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/nodegroup_templates.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/3ccc955b5a99bcb81763e3e2e6b43986ca4a861f', 'message': 'Fix for Sahara Cluster Templates\n\nThe form field class changed from ""control-group"" to ""form-group"".\n\nThe js updated to work with new class.\n\nCloses-bug: bug #1351292\nChange-Id: I08fe4aa1d1ab1d131153c1a02e37b27dabc8de0b\n'}]",0,111253,3ccc955b5a99bcb81763e3e2e6b43986ca4a861f,7,2,2,7132,,,0,"Fix for Sahara Cluster Templates

The form field class changed from ""control-group"" to ""form-group"".

The js updated to work with new class.

Closes-bug: bug #1351292
Change-Id: I08fe4aa1d1ab1d131153c1a02e37b27dabc8de0b
",git fetch https://review.opendev.org/openstack/horizon refs/changes/53/111253/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/cluster_node_groups_template.html', 'openstack_dashboard/dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/cluster_templates.html', 'openstack_dashboard/dashboards/project/data_processing/jobs/templates/data_processing.jobs/library_template.html', 'openstack_dashboard/dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_fields_help.html', 'openstack_dashboard/dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/job_binaries_form_script.html', 'openstack_dashboard/dashboards/project/data_processing/clusters/templates/data_processing.clusters/clusters.html', 'openstack_dashboard/dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/job_executions.html', 'openstack_dashboard/dashboards/project/data_processing/jobs/templates/data_processing.jobs/jobs.html', 'openstack_dashboard/dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html', 'openstack_dashboard/dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/data_sources_form_script.html', 'openstack_dashboard/dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/nodegroup_templates.html']",11,424fe9a1e6c7d52e837ce37c425ad0384d5cd325,bug/1351292," $("".plugin_version_choice"").closest("".form-group"").hide(); $("".plugin_version_choice"").closest("".form-group"").hide(); $(""."" + plugin.val() + ""_version_choice"").closest("".form-group"").show(); $("".volume_per_node_field"").closest("".form-group"").show(); $("".volume_size_field"").closest("".form-group"").show(); } else { $("".volume_per_node_field"").closest("".form-group"").hide(); $("".volume_size_field"").closest("".form-group"").hide();"," $("".plugin_version_choice"").closest("".control-group"").hide(); $("".plugin_version_choice"").closest("".control-group"").hide(); $(""."" + plugin.val() + ""_version_choice"").closest("".control-group"").show(); $("".volume_per_node_field"").closest("".control-group"").show(); $("".volume_size_field"").closest("".control-group"").show(); } else { $("".volume_per_node_field"").closest("".control-group"").hide(); $("".volume_size_field"").closest("".control-group"").hide();",66,66
openstack%2Fopenstack-doc-tools~master~Ic8e27f213215d075f0d3248ea87b18294f0bbe83,openstack/openstack-doc-tools,master,Ic8e27f213215d075f0d3248ea87b18294f0bbe83,jsoncheck: indent strings only when printing them,MERGED,2014-08-11 07:39:24.000000000,2014-08-11 07:47:47.000000000,2014-08-11 07:47:47.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-11 07:39:24.000000000', 'files': ['os_doc_tools/jsoncheck.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/483122f1fd46de3c6d3d16f888386c2e005d9193', 'message': 'jsoncheck: indent strings only when printing them\n\nIn preparation for passing strings to external callers that do no expect\nindented strings, call _indent_note only when strings are printed.\n\nblueprint modularize-doctest\nChange-Id: Ic8e27f213215d075f0d3248ea87b18294f0bbe83\n'}]",0,113187,483122f1fd46de3c6d3d16f888386c2e005d9193,7,2,1,11109,,,0,"jsoncheck: indent strings only when printing them

In preparation for passing strings to external callers that do no expect
indented strings, call _indent_note only when strings are printed.

blueprint modularize-doctest
Change-Id: Ic8e27f213215d075f0d3248ea87b18294f0bbe83
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/87/113187/1 && git format-patch -1 --stdout FETCH_HEAD,['os_doc_tools/jsoncheck.py'],1,483122f1fd46de3c6d3d16f888386c2e005d9193,bp/modularize-doctest," note = str(err) note += ""\n"" + demerr print(""%s\n%s"" % (path, _indent_note(str(err)))) errstr = ""Reformatted"" else: errstr = ""Reformatting needed"" print(""%s\n%s"" % (path, _indent_note(errstr)))"," note = _indent_note(str(err)) note += ""\n"" + _indent_note(demerr) print(""%s\n%s"" % (path, err)) errstr = _indent_note(""Reformatted"") else: errstr = _indent_note(""Reformatting needed"") print(""%s\n%s"" % (path, errstr))",6,6
openstack%2Fheat-specs~master~Ie84ff23e2ab3546ba5725a732ded7e29204459d5,openstack/heat-specs,master,Ie84ff23e2ab3546ba5725a732ded7e29204459d5,Add specification to implement eip/eipassociation updatable,ABANDONED,2014-07-15 03:18:36.000000000,2014-08-11 07:38:47.000000000,,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 8289}]","[{'number': 1, 'created': '2014-07-15 03:18:36.000000000', 'files': ['specs/implement-ec2eip-updatable.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/dc5ea592947509f45ad59cf10625839c0350dfda', 'message': 'Add specification to implement eip/eipassociation updatable\n\nAdd specification to implement the AWS::EC2::EIP and\nAWS::EC2::EIPAssociation resources updatable to be\ncompatible with AWSCloudFormation.\n\nSpecification blueprint implement-ec2eip-updatable\n\nChange-Id: Ie84ff23e2ab3546ba5725a732ded7e29204459d5\n'}]",0,106925,dc5ea592947509f45ad59cf10625839c0350dfda,8,3,1,8289,,,0,"Add specification to implement eip/eipassociation updatable

Add specification to implement the AWS::EC2::EIP and
AWS::EC2::EIPAssociation resources updatable to be
compatible with AWSCloudFormation.

Specification blueprint implement-ec2eip-updatable

Change-Id: Ie84ff23e2ab3546ba5725a732ded7e29204459d5
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/25/106925/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/implement-ec2eip-updatable.rst'],1,dc5ea592947509f45ad59cf10625839c0350dfda,bp/implement-ec2eip-updatable,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/heat/+spec/awesome-thing should be named awesome-thing.rst . Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ========================================================================= Implement AWS::EC2::EIP and AWS::EC2::EIPAssociation updatable ========================================================================= Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/heat/+spec/implement-ec2eip-updatable We should support the AWS::EC2::EIP and AWS::EC2::EIPAssociation resources updatable to be compatible with AWSCloudFormation. Problem description =================== Now in Heat, the AWS::EC2::EIP and AWS::EC2::EIPAssociation resources do not support the properties updatable, we should support the AWS::EC2::EIP and AWS::EC2::EIPAssociation resources updatable to be compatible with AWSCloudFormation. See AWSCloudFormation doc: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-eip.html http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-eip-association.html Proposed change =============== 1. Support 'InstanceId' property updatable for AWS::EC2::EIP resource 2. Support 'InstanceId', 'EIP', 'AllocationId', 'NetworkInterfaceId' properties updatable for AWS::EC2::EIPAssociation resource 3. Add validate function to check whether provide one of 'EIP' and 'AllocationId' for AWS::EC2::EIPAssociation resource 4. Modify the way to get 'network_id' of the port for AWS::EC2::EIPAssociation resource 5. Modify if the association is not created successful, don't try to delete it. Alternatives ------------ None Implementation ============== Assignee(s) ----------- Primary assignee: <huangtianhua> Milestones ---------- Target Milestone for completion: Juno-2 Work Items ---------- 1. Support 'InstanceId' property updatable for AWS::EC2::EIP resource 2. Support 'InstanceId', 'EIP', 'AllocationId', 'NetworkInterfaceId' properties updatable for AWS::EC2::EIPAssociation resource 3. Add UT/Tempest for the change Dependencies ============ None ",,81,0
openstack%2Ffuel-astute~master~I50a43c1b81d150ced64435f04173d22365d61192,openstack/fuel-astute,master,I50a43c1b81d150ced64435f04173d22365d61192,Prevent fall with exception if remote node close connection,MERGED,2014-05-30 11:55:40.000000000,2014-08-11 07:26:08.000000000,2014-06-02 09:06:03.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8782}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-05-30 11:55:40.000000000', 'files': ['lib/astute/ssh.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/1fc4cf583700244adf3604bfb84decf7cbc5f487', 'message': 'Prevent fall with exception if remote node close connection\n\nChange-Id: I50a43c1b81d150ced64435f04173d22365d61192\nCloses-Bug: #1319883\n'}]",0,96736,1fc4cf583700244adf3604bfb84decf7cbc5f487,13,4,1,8776,,,0,"Prevent fall with exception if remote node close connection

Change-Id: I50a43c1b81d150ced64435f04173d22365d61192
Closes-Bug: #1319883
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/36/96736/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/astute/ssh.rb'],1,1fc4cf583700244adf3604bfb84decf7cbc5f487,bug/1319883," exception_process(servers) rescue Net::SSH::Disconnect Astute.logger.debug ""SSH connection closed by remote host"" exception_process(servers) end def self.exception_process(servers) if s.busy? # Pending connection could not be shutdown, but always return busy as true s.session.shutdown! if s.session.channels.present? s.fail! end", s.session.shutdown! && s.fail! if s.busy?,11,1
openstack%2Fnova~master~I718fc0ee67dbd625af00c20fa4e34b8a35015437,openstack/nova,master,I718fc0ee67dbd625af00c20fa4e34b8a35015437,Remove ESXDriver from Juno.,MERGED,2014-07-22 22:02:59.000000000,2014-08-11 07:16:49.000000000,2014-08-07 06:53:19.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12134}]","[{'number': 1, 'created': '2014-07-22 22:02:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f4ef71e0e1840c6870e489b725f0dfb0f8b0f10', 'message': 'Remove ESXDriver from Juno.\n\nFirst in a series of patches to remove the\nVMwareESXDriver code for the Juno release,\nthis patch focusses on removing the VMwareESXDriver\nclass by either removing the code or moving it to\nVMwareVCDriver. This patch would be dependent on\ncoming series of patches which would:\na. Remove tests related to VMwareESXDriver.\nb. Fix broken functionality in VmwareVCDriver as a\n result of this refactoring process.\n\nDocImpact\nCloses-Bug: #134637\n\nChange-Id: I718fc0ee67dbd625af00c20fa4e34b8a35015437\n'}, {'number': 2, 'created': '2014-07-22 22:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/543ce3af0782be72953939778d9e9a286a1ffd7a', 'message': 'Remove ESXDriver from Juno.\n\nFirst in a series of patches to remove the VMwareESXDriver\ncode for the Juno release. This patch focusses on removing\nthe VMwareESXDriver class by either removing the code or\nmoving it to VMwareVCDriver. This patch would be dependent\non coming series of patches which would:\n\na. Remove tests related to VMwareESXDriver.\nb. Fix broken functionality in VmwareVCDriver as a\n result of this refactoring process.\n\nDocImpact\nCloses-Bug: #1346637\n\nChange-Id: I718fc0ee67dbd625af00c20fa4e34b8a35015437\n'}, {'number': 3, 'created': '2014-07-22 23:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d21189652a15e68f6d665918fcc4ebf709b1dbc1', 'message': 'Remove ESXDriver from Juno.\n\nFirst in a series of patches to remove the VMwareESXDriver\ncode for the Juno release. This patch focusses on removing\nthe VMwareESXDriver class by either removing the code or\nmoving it to VMwareVCDriver. This patch would be dependent\non coming series of patches which would:\n\na. Remove tests related to VMwareESXDriver.\nb. Fix broken functionality in VmwareVCDriver as a\n result of this refactoring process.\n\nDocImpact\nCloses-Bug: #1346637\n\nChange-Id: I718fc0ee67dbd625af00c20fa4e34b8a35015437\n'}, {'number': 4, 'created': '2014-07-23 06:59:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/637b42f2e7529d4c20180935b8d778b719daf053', 'message': 'Remove ESXDriver from Juno.\n\nFirst of the two patches to remove the VMwareESXDriver code\nfor the Juno release. This patch focusses on removing the\nVMwareESXDriver class by either removing the code or moving\nit to VMwareVCDriver. This patch would be dependent on a\nsubsequent patch  which would fix broken functionality in\nVmwareVCDriver as a result of this refactoring process.\n\nDocImpact\nCloses-Bug: #1346637\n\nChange-Id: I718fc0ee67dbd625af00c20fa4e34b8a35015437\n'}, {'number': 5, 'created': '2014-07-24 03:56:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2256f0001c95ca04062761d8bfeb994442cb1de9', 'message': 'Remove ESXDriver from Juno.\n\nPatch removes the VMwareESXDriver code by either deleting\nthe redundant methods or moving them to VMwareVCDriver.\n\nDocImpact\nCloses-Bug: #1346637\nChange-Id: I718fc0ee67dbd625af00c20fa4e34b8a35015437\n'}, {'number': 6, 'created': '2014-07-26 01:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db9acd27d8fa2190802572c811e94d5caba39890', 'message': 'Remove ESXDriver from Juno.\n\n1. Removes the VMwareESXDriver code in nova/virt/vmwareapi/driver.py\nby either deleting the redundant methods or moving them to VMwareVCDriver.\n2. Changes the test cases to use VMwareVCDriver and also removes duplicate\ntest cases which were previously being testing both VMwareESXDriver\nand VMwareVCDriver to just the latter.\n\nDocImpact\nCloses-Bug: #1346637\nChange-Id: I718fc0ee67dbd625af00c20fa4e34b8a35015437\n'}, {'number': 7, 'created': '2014-07-26 03:41:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db63eb1341063e1a2691e60192f4bfa835457911', 'message': 'Remove ESXDriver from Juno.\n\n1. Removes the VMwareESXDriver code in nova/virt/vmwareapi/driver.py\nby either deleting the redundant methods or moving them to VMwareVCDriver.\n2. Changes the test cases to use VMwareVCDriver and also removes duplicate\ntest cases which were previously being testing both VMwareESXDriver\nand VMwareVCDriver to just the latter.\n\nDocImpact\nCloses-Bug: #1346637\nChange-Id: I718fc0ee67dbd625af00c20fa4e34b8a35015437\n'}, {'number': 8, 'created': '2014-07-26 04:17:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/68c80715c44d178c0a67370951e1f5b153182e24', 'message': 'Remove ESXDriver from Juno.\n\n1. Removes the VMwareESXDriver code in nova/virt/vmwareapi/driver.py\nby either deleting the redundant methods or moving them to VMwareVCDriver.\n2. Changes the test cases to use VMwareVCDriver and also removes duplicate\ntest cases which were previously being testing both VMwareESXDriver\nand VMwareVCDriver to just the latter.\n\nDocImpact\nCloses-Bug: #1346637\nChange-Id: I718fc0ee67dbd625af00c20fa4e34b8a35015437\n'}, {'number': 9, 'created': '2014-07-29 17:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8dd788fee6d78007a7b74f9b950d9e63a3419a08', 'message': 'Remove ESXDriver from Juno.\n\n1. Removes the VMwareESXDriver code in nova/virt/vmwareapi/driver.py\nby either deleting the redundant methods or moving them to\nVMwareVCDriver.\n2. Changes the test cases to use VMwareVCDriver and also removes\nduplicate test cases which were previously being testing both\nVMwareESXDriver and VMwareVCDriver to just the latter.\n\nDocImpact\nCloses-Bug: #1346637\nChange-Id: I718fc0ee67dbd625af00c20fa4e34b8a35015437\n'}, {'number': 10, 'created': '2014-07-29 17:53:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e90f5ff2e72d82243ecc0558a943439d0e56e8cf', 'message': 'Remove ESXDriver from Juno.\n\n1. Removes the VMwareESXDriver code in nova/virt/vmwareapi/driver.py\nby either deleting the redundant methods or moving them to VMwareVCDriver.\n2. Changes the test cases to use VMwareVCDriver and also removes\nduplicate test cases which were previously being testing both\nVMwareESXDriver and VMwareVCDriver to just the latter.\n\nDocImpact\nCloses-Bug: #1346637\nChange-Id: I718fc0ee67dbd625af00c20fa4e34b8a35015437\n'}, {'number': 11, 'created': '2014-07-29 22:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e726fdd321e9b314317ecc9873e14021164d027c', 'message': 'Remove ESXDriver from Juno.\n\n1. Removes the VMwareESXDriver code in nova/virt/vmwareapi/driver.py\nby either deleting the redundant methods or moving them to VMwareVCDriver.\n2. Changes the test cases to use VMwareVCDriver and also removes\nduplicate test cases which were previously being testing both\nVMwareESXDriver and VMwareVCDriver to just the latter.\n\nDocImpact\nCloses-Bug: #1346637\nChange-Id: I718fc0ee67dbd625af00c20fa4e34b8a35015437\n'}, {'number': 12, 'created': '2014-08-06 06:02:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f750ed3b405a756af2849835949f446acb31508c', 'message': 'Remove ESXDriver from Juno.\n\n1. Removes the VMwareESXDriver code in nova/virt/vmwareapi/driver.py\nby either deleting the redundant methods or moving them to\nVMwareVCDriver.\n2. Changes the test cases to use VMwareVCDriver and also removes\nduplicate test cases which were previously being testing both\nVMwareESXDriver and VMwareVCDriver to just the latter.\n\nDocImpact\nCloses-Bug: #1346637\nChange-Id: I718fc0ee67dbd625af00c20fa4e34b8a35015437\n'}, {'number': 13, 'created': '2014-08-06 20:37:07.000000000', 'files': ['nova/virt/vmwareapi/__init__.py', 'nova/tests/virt/vmwareapi/test_vim_util.py', 'nova/tests/virt/vmwareapi/test_configdrive.py', 'nova/virt/vmwareapi/driver.py', 'nova/tests/virt/vmwareapi/fake.py', 'nova/tests/virt/vmwareapi/test_driver_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1deb31f85a8f5d1e261b2cf1eddc537a5da7f60b', 'message': 'Remove ESXDriver from Juno.\n\n1. Removes the VMwareESXDriver code in nova/virt/vmwareapi/driver.py\nby either deleting the redundant methods or moving them to\nVMwareVCDriver.\n2. Changes the test cases to use VMwareVCDriver and also removes\nduplicate test cases which were previously being testing both\nVMwareESXDriver and VMwareVCDriver to just the latter.\n\nDocImpact\nCloses-Bug: #1346637\nChange-Id: I718fc0ee67dbd625af00c20fa4e34b8a35015437\n'}]",26,108854,1deb31f85a8f5d1e261b2cf1eddc537a5da7f60b,95,14,13,12134,,,0,"Remove ESXDriver from Juno.

1. Removes the VMwareESXDriver code in nova/virt/vmwareapi/driver.py
by either deleting the redundant methods or moving them to
VMwareVCDriver.
2. Changes the test cases to use VMwareVCDriver and also removes
duplicate test cases which were previously being testing both
VMwareESXDriver and VMwareVCDriver to just the latter.

DocImpact
Closes-Bug: #1346637
Change-Id: I718fc0ee67dbd625af00c20fa4e34b8a35015437
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/108854/11 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/__init__.py', 'nova/locale/nova.pot', 'nova/virt/vmwareapi/driver.py', 'nova/locale/en_US/LC_MESSAGES/nova.po', 'nova/locale/es/LC_MESSAGES/nova.po']",5,4f4ef71e0e1840c6870e489b725f0dfb0f8b0f10,bug/1346637,"""compute_driver=vmwareapi.VMwareVCDriver""""compute_driver=vmwareapi.VMwareVCDriver""","""compute_driver=vmwareapi.VMwareESXDriver or vmwareapi.VMwareVCDriver""""compute_driver=vmwareapi.VMwareESXDriver o vmwareapi.VMwareVCDriver""",77,254
openstack%2Fneutron~master~I4db6b9ad7a2c6584c6bc561a07009760ecaf17af,openstack/neutron,master,I4db6b9ad7a2c6584c6bc561a07009760ecaf17af,Set mysql_engine only if parameter is provided,ABANDONED,2014-08-08 15:22:23.000000000,2014-08-11 07:12:25.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7962}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-08-08 15:22:23.000000000', 'files': ['neutron/db/migration/alembic_migrations/env.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e18305b30c71711a4882a87ebe513fbb89a190fa', 'message': 'Set mysql_engine only if parameter is provided\n\n--mysql-engine parameter for neutron-db-manage can be provided only for\nupgrades and downgrades but run_migration_online/offline is called\nwhenever env module is imported. This patch sets global MYSQL_ENGINE\nonly if --mysql-engine parameter was passed.\n\nChange-Id: I4db6b9ad7a2c6584c6bc561a07009760ecaf17af\nCloses-Bug: #1354495\n'}]",0,112927,e18305b30c71711a4882a87ebe513fbb89a190fa,21,17,1,8655,,,0,"Set mysql_engine only if parameter is provided

--mysql-engine parameter for neutron-db-manage can be provided only for
upgrades and downgrades but run_migration_online/offline is called
whenever env module is imported. This patch sets global MYSQL_ENGINE
only if --mysql-engine parameter was passed.

Change-Id: I4db6b9ad7a2c6584c6bc561a07009760ecaf17af
Closes-Bug: #1354495
",git fetch https://review.opendev.org/openstack/neutron refs/changes/27/112927/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/migration/alembic_migrations/env.py'],1,e18305b30c71711a4882a87ebe513fbb89a190fa,bug/1346658," if hasattr(neutron_config.command, 'mysql_engine'): set_mysql_engine(neutron_config.command.mysql_engine) if hasattr(neutron_config.command, 'mysql_engine'): set_mysql_engine(neutron_config.command.mysql_engine)", set_mysql_engine(neutron_config.command.mysql_engine) set_mysql_engine(neutron_config.command.mysql_engine),4,2
openstack%2Fnova~master~I5a0f6673405cb6c4fb4ce1a518dfa5dc09ae5bbe,openstack/nova,master,I5a0f6673405cb6c4fb4ce1a518dfa5dc09ae5bbe,Fix scheduling failure for disk_filter,ABANDONED,2014-06-28 03:56:52.000000000,2014-08-11 04:03:27.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 7148}, {'_account_id': 7166}, {'_account_id': 8276}, {'_account_id': 8290}, {'_account_id': 8922}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10618}, {'_account_id': 11531}]","[{'number': 1, 'created': '2014-06-28 03:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/59f7c845a43e5ce387c839117d644573b19eeb15', 'message': ""Fix scheduling failure for disk_filter\n\nCreate Vm by volume,the disk_filter should not be check the root_gb size\nand compute node report the resource(local_gb_used) should not be add the\nVm's root_db which created by volume\n\nChange-Id: I5a0f6673405cb6c4fb4ce1a518dfa5dc09ae5bbe\nCloses-Bug: #1334974\n""}, {'number': 2, 'created': '2014-06-30 03:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6898fd2df6ab6fff0e1973ebed1a4e339bed9943', 'message': ""Fix scheduling failure for disk_filter\n\nCreate Vm by volume,the disk_filter should not be check the root_gb size\nand compute node report the resource(local_gb_used) should not be add the\nVm's root_db which created by volume\n\nChange-Id: I5a0f6673405cb6c4fb4ce1a518dfa5dc09ae5bbe\nCloses-Bug: #1334974\n""}, {'number': 3, 'created': '2014-06-30 08:08:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0773dc87e4e6bc1527fef80ecce7e22639c38998', 'message': ""Fix scheduling failure for disk_filter\n\nCreate Vm by volume,the disk_filter should not be check the root_gb size\nand compute node report the resource(local_gb_used) should not be add the\nVm's root_db which created by volume\n\nChange-Id: I5a0f6673405cb6c4fb4ce1a518dfa5dc09ae5bbe\nCloses-Bug: #1334974\n""}, {'number': 4, 'created': '2014-06-30 09:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b5e06a1a79d9bd77e6a12a24f6ecb36aabf0ace8', 'message': ""Fix scheduling failure for disk_filter\n\nCreate Vm by volume,the disk_filter should not be check the root_gb size\nand compute node report the resource(local_gb_used) should not be add the\nVm's root_db which created by volume\n\nChange-Id: I5a0f6673405cb6c4fb4ce1a518dfa5dc09ae5bbe\nCloses-Bug: #1334974\n""}, {'number': 5, 'created': '2014-06-30 12:55:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11ec5d68bbb8a620771ece926c09929e9eb9844e', 'message': ""Fix scheduling failure for disk_filter\n\nCreate Vm by volume,the disk_filter should not be check the root_gb size\nand compute node report the resource(local_gb_used) should not be add the\nVm's root_db which created by volume\n\nChange-Id: I5a0f6673405cb6c4fb4ce1a518dfa5dc09ae5bbe\nCloses-Bug: #1334974\n""}, {'number': 6, 'created': '2014-07-25 08:55:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/734957c48fc9bddfdd6cabc0169007bbe9add820', 'message': ""Fix scheduling failure for disk_filter\n\nCreate Vm by volume,the disk_filter should not be check the root_gb size\nand compute node report the resource(local_gb_used) should not be add the\nVm's root_db which created by volume\n\nChange-Id: I5a0f6673405cb6c4fb4ce1a518dfa5dc09ae5bbe\nCloses-Bug: #1334974\n""}, {'number': 7, 'created': '2014-07-25 09:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d6c22700e45bcb9485ce0dbce67757b0c2ace505', 'message': ""Fix scheduling failure for disk_filter\n\nCreate Vm by volume,the disk_filter should not be check the root_gb size\nand compute node report the resource(local_gb_used) should not be add the\nVm's root_db which created by volume\n\nChange-Id: I5a0f6673405cb6c4fb4ce1a518dfa5dc09ae5bbe\nCloses-Bug: #1334974\n""}, {'number': 8, 'created': '2014-07-25 09:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/10cddae8b60afc79650e0d31988d6af7269f8046', 'message': ""Fix scheduling failure for disk_filter\n\nCreate Vm by volume,the disk_filter should not be check the root_gb size\nand compute node report the resource(local_gb_used) should not be add the\nVm's root_db which created by volume\n\nChange-Id: I5a0f6673405cb6c4fb4ce1a518dfa5dc09ae5bbe\nCloses-Bug: #1334974\n""}, {'number': 9, 'created': '2014-07-29 05:11:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6614ff0ff021605f42ce47ed67cef4de5b47f2bf', 'message': ""Fix scheduling failure for disk_filter\n\nCreate Vm by volume,the disk_filter should not be check the root_gb size\nand compute node report the resource(local_gb_used) should not be add the\nVm's root_db which created by volume\n\nChange-Id: I5a0f6673405cb6c4fb4ce1a518dfa5dc09ae5bbe\nCloses-Bug: #1334974\n""}, {'number': 10, 'created': '2014-07-30 04:50:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/59eb6505fff51471cd94b27ba22987214f1fdd6a', 'message': ""Fix scheduling failure for disk_filter\n\nCreate Vm by volume,the disk_filter should not be check the root_gb size\nand compute node report the resource(local_gb_used) should not be add the\nVm's root_db which created by volume\n\nChange-Id: I5a0f6673405cb6c4fb4ce1a518dfa5dc09ae5bbe\nCloses-Bug: #1334974\n""}, {'number': 11, 'created': '2014-08-06 00:39:21.000000000', 'files': ['nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/disk_filter.py', 'nova/tests/compute/test_resource_tracker.py', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6890936cb9b1ab7788ab83ecd4d475234732fb99', 'message': ""Fix scheduling failure for disk_filter\n\nCreate Vm by volume,the disk_filter should not be check the root_gb size\nand compute node report the resource(local_gb_used) should not be add the\nVm's root_db which created by volume\n\nChange-Id: I5a0f6673405cb6c4fb4ce1a518dfa5dc09ae5bbe\nCloses-Bug: #1334974\n""}]",73,103288,6890936cb9b1ab7788ab83ecd4d475234732fb99,96,17,11,11531,,,0,"Fix scheduling failure for disk_filter

Create Vm by volume,the disk_filter should not be check the root_gb size
and compute node report the resource(local_gb_used) should not be add the
Vm's root_db which created by volume

Change-Id: I5a0f6673405cb6c4fb4ce1a518dfa5dc09ae5bbe
Closes-Bug: #1334974
",git fetch https://review.opendev.org/openstack/nova refs/changes/88/103288/10 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/disk_filter.py', 'nova/tests/compute/test_resource_tracker.py', 'nova/compute/resource_tracker.py']",4,59f7c845a43e5ce387c839117d644573b19eeb15,bug/1334974," # the instance may be use volume, depending on the way of create vm if usage.get('image_ref',None): resources['local_gb_used'] += sign * usage.get('root_gb', 0)"," resources['local_gb_used'] += sign * usage.get('root_gb', 0)",54,15
openstack%2Fnova~master~I9d8101916bcb449345d3123617c2ac75776d053e,openstack/nova,master,I9d8101916bcb449345d3123617c2ac75776d053e,Add hacking check for explicit import of _(),MERGED,2014-07-29 20:11:23.000000000,2014-08-11 03:16:07.000000000,2014-08-09 19:29:56.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 679}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 7198}, {'_account_id': 7641}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-29 20:11:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d77a35b2a107d28f5987f0a5d9152506e5adc509', 'message': ""Add hacking check for explicit import of _()\n\nTo ensure the right message catalog is used when translating\nmessages we need to make sure to explicitly import '_' in\nany files that use that function.  We cannot count on\nunit test to catch cases where the user has forgotten to\nimport the _() function.\n\nThis hacking check ensures that the function has been imported\nanywhere that it is used.  Unit tests for the hacking check are\nincluded.\n\nChange-Id: I9d8101916bcb449345d3123617c2ac75776d053e\n""}, {'number': 2, 'created': '2014-08-02 22:15:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/88c6b4f2dad807b992443a656ed5e26acdd2cc5f', 'message': ""Add hacking check for explicit import of _()\n\nTo ensure the right message catalog is used when translating\nmessages we need to make sure to explicitly import '_' in\nany files that use that function.  We cannot count on\nunit test to catch cases where the user has forgotten to\nimport the _() function.\n\nThis hacking check ensures that the function has been imported\nanywhere that it is used.  Unit tests for the hacking check are\nincluded.\n\nChange-Id: I9d8101916bcb449345d3123617c2ac75776d053e\n""}, {'number': 3, 'created': '2014-08-03 13:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/609ff792e67a0fcef72a607f83151e27fada9bbb', 'message': ""Add hacking check for explicit import of _()\n\nTo ensure the right message catalog is used when translating\nmessages we need to make sure to explicitly import '_' in\nany files that use that function.  We cannot count on\nunit test to catch cases where the user has forgotten to\nimport the _() function.\n\nThis hacking check ensures that the function has been imported\nanywhere that it is used.  Unit tests for the hacking check are\nincluded.\n\nChange-Id: I9d8101916bcb449345d3123617c2ac75776d053e\n""}, {'number': 4, 'created': '2014-08-03 16:57:25.000000000', 'files': ['nova/hacking/checks.py', 'nova/tests/api/openstack/test_faults.py', 'nova/tests/test_hacking.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/416283bd35bb5f8c6b71c493244b00cdfcf7aefc', 'message': ""Add hacking check for explicit import of _()\n\nTo ensure the right message catalog is used when translating\nmessages we need to make sure to explicitly import '_' in\nany files that use that function.  We cannot count on\nunit test to catch cases where the user has forgotten to\nimport the _() function.\n\nThis hacking check ensures that the function has been imported\nanywhere that it is used.  Unit tests for the hacking check are\nincluded.\n\nChange-Id: I9d8101916bcb449345d3123617c2ac75776d053e\n""}]",1,110444,416283bd35bb5f8c6b71c493244b00cdfcf7aefc,46,11,4,7198,,,0,"Add hacking check for explicit import of _()

To ensure the right message catalog is used when translating
messages we need to make sure to explicitly import '_' in
any files that use that function.  We cannot count on
unit test to catch cases where the user has forgotten to
import the _() function.

This hacking check ensures that the function has been imported
anywhere that it is used.  Unit tests for the hacking check are
included.

Change-Id: I9d8101916bcb449345d3123617c2ac75776d053e
",git fetch https://review.opendev.org/openstack/nova refs/changes/44/110444/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/hacking/checks.py', 'nova/tests/test_hacking.py']",2,d77a35b2a107d28f5987f0a5d9152506e5adc509,," def test_check_explicit_underscore_import(self): self.assertEqual(len(list(checks.check_explicit_underscore_import( ""LOG.info(_('My info message'))"", ""cinder/tests/other_files.py""))), 1) self.assertEqual(len(list(checks.check_explicit_underscore_import( ""msg = _('My message')"", ""cinder/tests/other_files.py""))), 1) self.assertEqual(len(list(checks.check_explicit_underscore_import( ""from cinder.i18n import _"", ""cinder/tests/other_files.py""))), 0) self.assertEqual(len(list(checks.check_explicit_underscore_import( ""LOG.info(_('My info message'))"", ""cinder/tests/other_files.py""))), 0) self.assertEqual(len(list(checks.check_explicit_underscore_import( ""msg = _('My message')"", ""cinder/tests/other_files.py""))), 0)",,40,0
openstack%2Ftempest~master~I0dfb6340ca1bdda44e0dd81059cd171807deffb6,openstack/tempest,master,I0dfb6340ca1bdda44e0dd81059cd171807deffb6,Unskip test_stack_update_metadata,ABANDONED,2014-07-18 06:05:53.000000000,2014-08-11 03:04:09.000000000,,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-18 06:05:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0d460f6563dd10aa9528c4aecb61d06fe30b8b9f', 'message': 'Unskip test_stack_update_metadata\n\nTo demonstrate this test failing for bug #1287953\n\nChange-Id: I0dfb6340ca1bdda44e0dd81059cd171807deffb6\n'}, {'number': 2, 'created': '2014-08-05 01:36:45.000000000', 'files': ['tempest/api/orchestration/stacks/test_update.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/98f499db02123165c2e6dfc325726309cbabe179', 'message': 'Unskip test_stack_update_metadata\n\nTo demonstrate this test failing for bug #1287953\n\nChange-Id: I0dfb6340ca1bdda44e0dd81059cd171807deffb6\n'}]",0,107902,98f499db02123165c2e6dfc325726309cbabe179,13,5,2,4571,,,0,"Unskip test_stack_update_metadata

To demonstrate this test failing for bug #1287953

Change-Id: I0dfb6340ca1bdda44e0dd81059cd171807deffb6
",git fetch https://review.opendev.org/openstack/tempest refs/changes/02/107902/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/orchestration/stacks/test_update.py'],1,0d460f6563dd10aa9528c4aecb61d06fe30b8b9f,bug/1287953,, @test.skip_because(bug='1287953'),0,1
openstack%2Fnova~master~I82c6064159d7bfa7f4dc7fca5a7c9bc52b0f07fb,openstack/nova,master,I82c6064159d7bfa7f4dc7fca5a7c9bc52b0f07fb,"Add index for reservations on (deleted, expire)",MERGED,2014-07-25 17:05:05.000000000,2014-08-11 02:31:29.000000000,2014-07-30 00:49:57.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 100}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2243}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-25 17:05:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2cbae5c60ca42d35def5efaf9537eb98bbb6d920', 'message': 'Add index for reservations on (deleted, expire)\n\nthe query for expire_reservations currently does a full table scan.\nThis adds an index so frequent invocations of expire does not bog\ndown the database.\n\nChange-Id: I82c6064159d7bfa7f4dc7fca5a7c9bc52b0f07fb\nResolves-bug: 1348720\n'}, {'number': 2, 'created': '2014-07-25 20:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8bc1a4b068178025166174e0f9b3890c9dcae8a2', 'message': 'Add index for reservations on (deleted, expire)\n\nthe query for expire_reservations currently does a full table scan.\nThis adds an index so frequent invocations of expire does not bog\ndown the database.\n\nChange-Id: I82c6064159d7bfa7f4dc7fca5a7c9bc52b0f07fb\nResolves-bug: 1348720\n'}, {'number': 3, 'created': '2014-07-25 20:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b215c1e2f5097d31824a41569567827ae8b693f6', 'message': 'Add index for reservations on (deleted, expire)\n\nthe query for expire_reservations currently does a full table scan.\nThis adds an index so frequent invocations of expire does not bog\ndown the database.\n\nChange-Id: I82c6064159d7bfa7f4dc7fca5a7c9bc52b0f07fb\nResolves-bug: 1348720\n'}, {'number': 4, 'created': '2014-07-25 22:14:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d7a1648bc2413ec4ea8fc17a6c35b56583fe477', 'message': 'Add index for reservations on (deleted, expire)\n\nthe query for expire_reservations currently does a full table scan.\nThis adds an index so frequent invocations of expire does not bog\ndown the database.\n\nChange-Id: I82c6064159d7bfa7f4dc7fca5a7c9bc52b0f07fb\nResolves-bug: 1348720\n'}, {'number': 5, 'created': '2014-07-25 22:32:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e57e9c86b410d4e24cec6fd041c46fd4d0e251d4', 'message': 'Add index for reservations on (deleted, expire)\n\nthe query for expire_reservations currently does a full table scan.\nThis adds an index so frequent invocations of expire does not bog\ndown the database.\n\nChange-Id: I82c6064159d7bfa7f4dc7fca5a7c9bc52b0f07fb\nResolves-bug: 1348720\n'}, {'number': 6, 'created': '2014-07-28 17:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4802f3cb825b4fe1fe175bceb6af0b5ae77313b5', 'message': 'Add index for reservations on (deleted, expire)\n\nthe query for expire_reservations currently does a full table scan.\nThis adds an index so frequent invocations of expire does not bog\ndown the database.\n\nChange-Id: I82c6064159d7bfa7f4dc7fca5a7c9bc52b0f07fb\nResolves-bug: 1348720\n'}, {'number': 7, 'created': '2014-07-28 17:42:22.000000000', 'files': ['nova/db/sqlalchemy/models.py', 'nova/db/sqlalchemy/migrate_repo/versions/248_add_expire_reservations_index.py', 'nova/tests/db/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b67eedb8e255776e853536f7a86217845dc57ecf', 'message': 'Add index for reservations on (deleted, expire)\n\nthe query for expire_reservations currently does a full table scan.\nThis adds an index so frequent invocations of expire does not bog\ndown the database.\n\nChange-Id: I82c6064159d7bfa7f4dc7fca5a7c9bc52b0f07fb\nResolves-bug: 1348720\n'}]",15,109660,b67eedb8e255776e853536f7a86217845dc57ecf,77,13,7,67,,,0,"Add index for reservations on (deleted, expire)

the query for expire_reservations currently does a full table scan.
This adds an index so frequent invocations of expire does not bog
down the database.

Change-Id: I82c6064159d7bfa7f4dc7fca5a7c9bc52b0f07fb
Resolves-bug: 1348720
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/109660/7 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/sqlalchemy/migrate_repo/versions/247_add_expire_reservations_index.py', 'nova/tests/db/test_migrations.py']",2,2cbae5c60ca42d35def5efaf9537eb98bbb6d920,bug/1348720," def _check_247(self, engine, data): self.assertIndexMembers(engine, 'reservations', 'reservations_deleted_expire_idx', ['deleted', 'expire']) def _post_downgrade_247(self, engine): reservations = oslodbutils.get_table(engine, 'reservations') index_names = [idx.name for idx in reservations.indexes] self.assertNotIn('reservations_deleted_expire_idx', index_names) ",,53,0
openstack%2Fdiskimage-builder~master~Ida652e3ff7cdb882319707287d01308da9b72d91,openstack/diskimage-builder,master,Ida652e3ff7cdb882319707287d01308da9b72d91,Echo that the image is being created,ABANDONED,2014-07-23 18:52:54.000000000,2014-08-11 02:14:35.000000000,,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 1726}, {'_account_id': 4190}, {'_account_id': 9369}, {'_account_id': 10375}, {'_account_id': 12385}]","[{'number': 1, 'created': '2014-07-23 18:52:54.000000000', 'files': ['lib/common-functions'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/dffc541399892b98ce59a944a77fdaca0ec7a5b9', 'message': ""Echo that the image is being created\n\nIt takes roughly one to three minutes to perform the 'mv' in the\nguts of finish_image, which means the user needs to know that dib\nis currently writing the image, which is unobvious. Make it so.\n\nChange-Id: Ida652e3ff7cdb882319707287d01308da9b72d91\n""}]",1,109075,dffc541399892b98ce59a944a77fdaca0ec7a5b9,25,7,1,9369,,,0,"Echo that the image is being created

It takes roughly one to three minutes to perform the 'mv' in the
guts of finish_image, which means the user needs to know that dib
is currently writing the image, which is unobvious. Make it so.

Change-Id: Ida652e3ff7cdb882319707287d01308da9b72d91
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/75/109075/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/common-functions'],1,dffc541399892b98ce59a944a77fdaca0ec7a5b9,image-creating-message," echo ""Creating image file ${1}..."" echo ""Image file $1 created"""," echo ""Image file $1 created...""",2,2
openstack%2Fdevstack~master~I49f7a9d2bfe703e0e09df5ab93220fcf93dea3aa,openstack/devstack,master,I49f7a9d2bfe703e0e09df5ab93220fcf93dea3aa,make vpn plugin configurable,ABANDONED,2014-07-10 03:55:34.000000000,2014-08-11 01:52:42.000000000,,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-10 03:55:34.000000000', 'files': ['lib/neutron', 'lib/neutron_plugins/services/vpn'], 'web_link': 'https://opendev.org/openstack/devstack/commit/b524cbaede84eb2cc65f6c0974727aa7d3fd81a6', 'message': 'make vpn plugin configurable\n\nChange-Id: I49f7a9d2bfe703e0e09df5ab93220fcf93dea3aa\n'}]",0,105960,b524cbaede84eb2cc65f6c0974727aa7d3fd81a6,7,4,1,2874,,,0,"make vpn plugin configurable

Change-Id: I49f7a9d2bfe703e0e09df5ab93220fcf93dea3aa
",git fetch https://review.opendev.org/openstack/devstack refs/changes/60/105960/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/neutron', 'lib/neutron_plugins/services/vpn']",2,b524cbaede84eb2cc65f6c0974727aa7d3fd81a6,qvpn,"VPN_PLUGIN=${VPN_PLUGIN:-""neutron.services.vpn.plugin.VPNDriverPlugin""}","VPN_PLUGIN=""neutron.services.vpn.plugin.VPNDriverPlugin""",3,3
openstack%2Fpython-cinderclient~master~I9044256a07bed8f86bc792df313f5026cc968ea4,openstack/python-cinderclient,master,I9044256a07bed8f86bc792df313f5026cc968ea4,Convert auth tests to HTTPretty,ABANDONED,2014-03-10 07:35:01.000000000,2014-08-11 00:34:13.000000000,,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 7191}]","[{'number': 1, 'created': '2014-03-10 07:35:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/96d2325732eee43d5c67c42b0414102759445fbc', 'message': 'Convert auth tests to HTTPretty\n\nChange-Id: I9044256a07bed8f86bc792df313f5026cc968ea4\nblueprint: httpretty-testing\n'}, {'number': 2, 'created': '2014-03-11 02:06:13.000000000', 'files': ['cinderclient/tests/v2/test_auth.py', 'cinderclient/tests/v1/test_auth.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/9496d2022f4d1e84c9875e834bcf1608e625dbc4', 'message': 'Convert auth tests to HTTPretty\n\nChange-Id: I9044256a07bed8f86bc792df313f5026cc968ea4\nblueprint: httpretty-testing\n'}]",0,79265,9496d2022f4d1e84c9875e834bcf1608e625dbc4,10,3,2,7191,,,0,"Convert auth tests to HTTPretty

Change-Id: I9044256a07bed8f86bc792df313f5026cc968ea4
blueprint: httpretty-testing
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/65/79265/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/tests/v2/test_auth.py', 'cinderclient/tests/v1/test_auth.py']",2,96d2325732eee43d5c67c42b0414102759445fbc,bp/httpretty-testing," import httpretty import mock import six @httpretty.activate def test_authenticate_success(self): httpretty.register_uri(httpretty.GET, ""http://localhost:8776/v1"") httpretty.register_uri(httpretty.POST, ""http://localhost:8776/v1/v2.0/tokens"", body=json.dumps(resp)) cs = client.Client(""username"", ""password"", ""project_id"", ""http://localhost:8776/v1"", service_type='volume') cs.client.authenticate() headers = { 'User-Agent': cs.client.USER_AGENT, 'Content-Type': 'application/json', 'Accept': 'application/json', } self.assertEqual(httpretty.last_request().method, httpretty.POST) self.assertEqual(httpretty.last_request().path, '/v1/v2.0/tokens') for k, v in six.iteritems(headers): self.assertEqual(httpretty.last_request().headers[k], v) self.assertEqual(cs.client.management_url, ""http://localhost:8776/v1"") self.assertEqual(cs.client.auth_token, ""FAKE_ID"") @httpretty.activate def test_authenticate_tenant_id(self): httpretty.register_uri(httpretty.GET, 'http://localhost:8776/v1') httpretty.register_uri(httpretty.POST, 'http://localhost:8776/v1/v2.0/tokens', body=json.dumps(resp)) cs = client.Client(""username"", ""password"", auth_url=""http://localhost:8776/v1"", tenant_id='tenant_id', service_type='volume') cs.client.authenticate() headers = { 'User-Agent': cs.client.USER_AGENT, 'Content-Type': 'application/json', 'Accept': 'application/json', } self.assertEqual(httpretty.last_request().method, httpretty.POST) self.assertEqual(httpretty.last_request().path, '/v1/v2.0/tokens') for k, v in six.iteritems(headers): self.assertEqual(httpretty.last_request().headers[k], v) self.assertEqual(cs.client.management_url, 'http://localhost:8776/v1') self.assertEqual(cs.client.auth_token, ""FAKE_ID"") self.assertEqual(cs.client.tenant_id, ""tenant_id"") @httpretty.activate def test_authenticate_failure(self): resp = {""unauthorized"": {""message"": ""Unauthorized"", ""code"": ""401""}} httpretty.register_uri(httpretty.GET, 'http://localhost:8776/v1') httpretty.register_uri(httpretty.POST, 'http://localhost:8776/v1/v2.0/tokens', body=json.dumps(resp), status=401) self.assertRaises(exceptions.Unauthorized, cs.client.authenticate) @httpretty.activate def test_auth_redirect(self): # Configured on admin port, cinder redirects to v2.0 port. # When trying to connect on it, keystone auth succeed by v1.0 # protocol (through headers) but tokens are being returned in # body (looks like keystone bug). Leaved for compatibility. httpretty.register_uri(httpretty.GET, 'http://localhost:8776/', status=305, body='Use proxy', location='http://127.0.0.1:5001') httpretty.register_uri(httpretty.GET, 'http://127.0.0.1:5001/', body=json.dumps(dict_correct_response)) httpretty.register_uri(httpretty.POST, 'http://127.0.0.1:5001/v2.0/tokens', body=json.dumps(dict_correct_response)) ""http://localhost:8776/"", service_type='volume') cs.client.authenticate() self.assertEqual(httpretty.last_request().method, httpretty.POST) self.assertEqual(httpretty.last_request().path, '/v2.0/tokens') headers = { 'User-Agent': cs.client.USER_AGENT, 'Content-Type': 'application/json', 'Accept': 'application/json', } for k, v in six.iteritems(headers): self.assertEqual(httpretty.last_request().headers[k], v) self.assertEqual(cs.client.management_url, ""http://localhost:8776/v1"") self.assertEqual(cs.client.auth_token, ""FAKE_ID"") @httpretty.activate def test_ambiguous_endpoints(self): httpretty.register_uri(httpretty.GET, 'http://localhost:8776/') httpretty.register_uri(httpretty.POST, 'http://localhost:8776/v2.0/tokens', body=json.dumps(resp)) cs = client.Client(""username"", ""password"", ""project_id"", ""http://localhost:8776/"", service_type='volume') self.assertRaises(exceptions.AmbiguousEndpoints, cs.client.authenticate) @httpretty.activate def test_authenticate_success(self): auth_token = '1b751d74-de0c-46ae-84f0-915744b582d1' httpretty.register_uri(httpretty.GET, 'http://auth/', status=204, x_server_management_url=management_url, x_auth_token=auth_token) cs = client.Client(""username"", ""password"", ""project_id"", ""http://auth"") cs.client.authenticate() headers = { 'Accept': 'application/json', 'X-Auth-User': 'username', 'X-Auth-Key': 'password', 'X-Auth-Project-Id': 'project_id', 'User-Agent': cs.client.USER_AGENT } self.assertEqual(httpretty.last_request().method, httpretty.GET) self.assertEqual(httpretty.last_request().path, '/') for k, v in six.iteritems(headers): self.assertEqual(httpretty.last_request().headers[k], v) @httpretty.activate def test_authenticate_failure(self): httpretty.register_uri(httpretty.GET, 'http://auth/', status=401) cs = client.Client(""username"", ""password"", ""project_id"", ""http://auth"") self.assertRaises(exceptions.Unauthorized, cs.client.authenticate)","import mock import requests def test_authenticate_success(self): cs = client.Client(""username"", ""password"", ""project_id"", ""http://localhost:8776/v1"", service_type='volume') auth_response = utils.TestResponse({ ""status_code"": 200, ""text"": json.dumps(resp), }) mock_request = mock.Mock(return_value=(auth_response)) @mock.patch.object(requests, ""request"", mock_request) def test_auth_call(): cs.client.authenticate() headers = { 'User-Agent': cs.client.USER_AGENT, 'Content-Type': 'application/json', 'Accept': 'application/json', } body = { 'auth': { 'passwordCredentials': { 'username': cs.client.user, 'password': cs.client.password, }, 'tenantName': cs.client.projectid, }, } token_url = cs.client.auth_url + ""/tokens"" mock_request.assert_called_with( ""POST"", token_url, headers=headers, data=json.dumps(body), allow_redirects=True, **self.TEST_REQUEST_BASE) endpoints = resp[""access""][""serviceCatalog""][0]['endpoints'] public_url = endpoints[0][""publicURL""].rstrip('/') self.assertEqual(cs.client.management_url, public_url) token_id = resp[""access""][""token""][""id""] self.assertEqual(cs.client.auth_token, token_id) test_auth_call() def test_authenticate_tenant_id(self): cs = client.Client(""username"", ""password"", auth_url=""http://localhost:8776/v1"", tenant_id='tenant_id', service_type='volume') auth_response = utils.TestResponse({ ""status_code"": 200, ""text"": json.dumps(resp), }) mock_request = mock.Mock(return_value=(auth_response)) @mock.patch.object(requests, ""request"", mock_request) def test_auth_call(): cs.client.authenticate() headers = { 'User-Agent': cs.client.USER_AGENT, 'Content-Type': 'application/json', 'Accept': 'application/json', } body = { 'auth': { 'passwordCredentials': { 'username': cs.client.user, 'password': cs.client.password, }, 'tenantId': cs.client.tenant_id, }, } token_url = cs.client.auth_url + ""/tokens"" mock_request.assert_called_with( ""POST"", token_url, headers=headers, data=json.dumps(body), allow_redirects=True, **self.TEST_REQUEST_BASE) endpoints = resp[""access""][""serviceCatalog""][0]['endpoints'] public_url = endpoints[0][""publicURL""].rstrip('/') self.assertEqual(cs.client.management_url, public_url) token_id = resp[""access""][""token""][""id""] self.assertEqual(cs.client.auth_token, token_id) tenant_id = resp[""access""][""token""][""tenant""][""id""] self.assertEqual(cs.client.tenant_id, tenant_id) test_auth_call() def test_authenticate_failure(self): resp = {""unauthorized"": {""message"": ""Unauthorized"", ""code"": ""401""}} auth_response = utils.TestResponse({ ""status_code"": 401, ""text"": json.dumps(resp), }) mock_request = mock.Mock(return_value=(auth_response)) @mock.patch.object(requests, ""request"", mock_request) def test_auth_call(): self.assertRaises(exceptions.Unauthorized, cs.client.authenticate) test_auth_call() def test_auth_redirect(self): cs = client.Client(""username"", ""password"", ""project_id"", ""http://localhost:8776/v1"", service_type='volume') correct_response = json.dumps(dict_correct_response) dict_responses = [ {""headers"": {'location': 'http://127.0.0.1:5001'}, ""status_code"": 305, ""text"": ""Use proxy""}, # Configured on admin port, cinder redirects to v2.0 port. # When trying to connect on it, keystone auth succeed by v1.0 # protocol (through headers) but tokens are being returned in # body (looks like keystone bug). Leaved for compatibility. {""headers"": {}, ""status_code"": 200, ""text"": correct_response}, {""headers"": {}, ""status_code"": 200, ""text"": correct_response} ] responses = [(utils.TestResponse(resp)) for resp in dict_responses] def side_effect(*args, **kwargs): return responses.pop(0) mock_request = mock.Mock(side_effect=side_effect) @mock.patch.object(requests, ""request"", mock_request) def test_auth_call(): cs.client.authenticate() headers = { 'User-Agent': cs.client.USER_AGENT, 'Content-Type': 'application/json', 'Accept': 'application/json', } body = { 'auth': { 'passwordCredentials': { 'username': cs.client.user, 'password': cs.client.password, }, 'tenantName': cs.client.projectid, }, } token_url = cs.client.auth_url + ""/tokens"" mock_request.assert_called_with( ""POST"", token_url, headers=headers, data=json.dumps(body), allow_redirects=True, **self.TEST_REQUEST_BASE) resp = dict_correct_response endpoints = resp[""access""][""serviceCatalog""][0]['endpoints'] public_url = endpoints[0][""publicURL""].rstrip('/') self.assertEqual(cs.client.management_url, public_url) token_id = resp[""access""][""token""][""id""] self.assertEqual(cs.client.auth_token, token_id) test_auth_call() def test_ambiguous_endpoints(self): ""http://localhost:8776/v1"", service_type='volume') auth_response = utils.TestResponse({ ""status_code"": 200, ""text"": json.dumps(resp), }) mock_request = mock.Mock(return_value=(auth_response)) @mock.patch.object(requests, ""request"", mock_request) def test_auth_call(): self.assertRaises(exceptions.AmbiguousEndpoints, cs.client.authenticate) test_auth_call() def test_authenticate_success(self): cs = client.Client(""username"", ""password"", ""project_id"", ""auth_url"") auth_response = utils.TestResponse({ 'status_code': 204, 'headers': { 'x-server-management-url': management_url, 'x-auth-token': '1b751d74-de0c-46ae-84f0-915744b582d1', }, }) mock_request = mock.Mock(return_value=(auth_response)) @mock.patch.object(requests, ""request"", mock_request) def test_auth_call(): cs.client.authenticate() headers = { 'Accept': 'application/json', 'X-Auth-User': 'username', 'X-Auth-Key': 'password', 'X-Auth-Project-Id': 'project_id', 'User-Agent': cs.client.USER_AGENT } mock_request.assert_called_with( ""GET"", cs.client.auth_url, headers=headers, **self.TEST_REQUEST_BASE) self.assertEqual(cs.client.management_url, auth_response.headers['x-server-management-url']) self.assertEqual(cs.client.auth_token, auth_response.headers['x-auth-token']) test_auth_call() def test_authenticate_failure(self): cs = client.Client(""username"", ""password"", ""project_id"", ""auth_url"") auth_response = utils.TestResponse({""status_code"": 401}) mock_request = mock.Mock(return_value=(auth_response)) @mock.patch.object(requests, ""request"", mock_request) def test_auth_call(): self.assertRaises(exceptions.Unauthorized, cs.client.authenticate) test_auth_call()",250,407
openstack%2Ftripleo-specs~master~I782277e256a3f179620ea58dc7da74ae4a62727e,openstack/tripleo-specs,master,I782277e256a3f179620ea58dc7da74ae4a62727e,Update the Tuskar storage spec to reference Heat,MERGED,2014-07-17 13:06:03.000000000,2014-08-10 23:50:01.000000000,2014-08-10 23:50:01.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 4330}, {'_account_id': 7585}, {'_account_id': 8042}, {'_account_id': 8399}]","[{'number': 1, 'created': '2014-07-17 13:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/4ed469cf1c615bc6588a1229e6cad2a9ff1c90e5', 'message': 'Update the Tuskar storage spec to reference Heat\n\nGiven the progress being made in Heat the most favourable option\nnow is to use it for parameter storage rather than Barbican.\nThis update highlights that slight change in direction in the\nspec and moves the requirement of Barbican to be a possible\nalternative.\n\nChange-Id: I782277e256a3f179620ea58dc7da74ae4a62727e\n'}, {'number': 2, 'created': '2014-07-25 12:31:58.000000000', 'files': ['specs/juno/tripleo-juno-tuskar-template-storage.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/1450573734398c71411e656bf9bfc1908ad40729', 'message': 'Update the Tuskar storage spec to reference Heat\n\nGiven the progress being made in Heat the most favourable option\nnow is to use it for parameter storage rather than Barbican.\nThis update highlights that slight change in direction in the\nspec and moves the requirement of Barbican to be a possible\nalternative.\n\nChange-Id: I782277e256a3f179620ea58dc7da74ae4a62727e\n'}]",1,107684,1450573734398c71411e656bf9bfc1908ad40729,25,6,2,9712,,,0,"Update the Tuskar storage spec to reference Heat

Given the progress being made in Heat the most favourable option
now is to use it for parameter storage rather than Barbican.
This update highlights that slight change in direction in the
spec and moves the requirement of Barbican to be a possible
alternative.

Change-Id: I782277e256a3f179620ea58dc7da74ae4a62727e
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/84/107684/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/tripleo-juno-tuskar-template-storage.rst'],1,4ed469cf1c615bc6588a1229e6cad2a9ff1c90e5,,"Storage drivers operate by storing object dictionaries. For storage solutions such as Glance these dictionaries are stored as flat files. For a storage solution such as a database, the dictionary is translated into a table row. It is the responsibility of the driver to understand how it is storing the objectFor Juno, we will aim to use a combination of a relational database and Heat. Heat will be used for the secure storage of sensitive environment parameters. Database tables will be used for everything else. The usage of Heat for secure stores relies on `PATCH support`_ to be added the Heat API. This bug is targeted for completion by Juno-2. .. _PATCH support: https://bugs.launchpad.net/heat/+bug/1224828However, this information would appear to be available as part of a plan'sSwift was considered as an option to replace the relational database but wasBarbican, the OpenStack secure storage service, provides us with an alternative if PATCH support isn't added to Heat in time. Currently the only alternative other than Barbican is to implement our own cryptography with one of the other options listed above. This isn't a favourable choice as it adds a technical complexity and risk that should be beyond the scope of this proposal.For this reason, Heat or Barbican will be used to store all configuration values.TripleO will now require the use of a local database or Glance.- https://bugs.launchpad.net/heat/+bug/1224828","Storage drivers operate by storing object dictionaries. For storage solutions such as Glance or Barbican, these dictionaries are stored as flat files. For a storage solution such as a database, the dictionary is translated into a table row. It is the responsibility of the driver to understand how it is storing the objectFor Juno, we will aim to use a combination of a relational database and Barbican. Barbican will be used for the secure storage of environment files. Database tables will be used for everything else.However, this information wold appear to be available as part of a plan'sSwift was considered as an option that would work with Barbican but wasCurrently the only alternative to Barbican is to implement our own cryptography with one of the other options listed above. This isn't a favourable choice as it adds a technical complexity and risk that should be beyond the scope of this proposal.For this reason, Barbican will be used to store all configuration values.TripleO will now require the use of a Barbican and a local database or Glance.",24,15
openstack%2Ftripleo-specs~master~I38cce8d407eaaf7ff58b3381e5d1cf294ab1515f,openstack/tripleo-specs,master,I38cce8d407eaaf7ff58b3381e5d1cf294ab1515f,Update pbr version,ABANDONED,2014-06-28 16:49:31.000000000,2014-08-10 23:46:43.000000000,,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 10901}]","[{'number': 1, 'created': '2014-06-28 16:49:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/af1286646335bab2146a9ce8da109fb3c6f2415d', 'message': 'Update pbr version\n\nChange-Id: I38cce8d407eaaf7ff58b3381e5d1cf294ab1515f\n'}, {'number': 2, 'created': '2014-06-30 06:28:16.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/723f480cc8823dbf8918ad76f4c73a3602234592', 'message': 'Update pbr version\n\nMatches Global Requirements. In the tripleo-specs project pbr version\ndoes not match the global requirements.\n\nChange-Id: I38cce8d407eaaf7ff58b3381e5d1cf294ab1515f\n'}]",0,103351,723f480cc8823dbf8918ad76f4c73a3602234592,10,3,2,9536,,,0,"Update pbr version

Matches Global Requirements. In the tripleo-specs project pbr version
does not match the global requirements.

Change-Id: I38cce8d407eaaf7ff58b3381e5d1cf294ab1515f
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/51/103351/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,af1286646335bab2146a9ce8da109fb3c6f2415d,pbr_version_update,"pbr>=0.6,!=0.7,<1.0","pbr>=0.6,<1.0",1,1
openstack%2Ftripleo-specs~master~Id9addc65f0d2ed519ce4b3edbd561ed660a2786e,openstack/tripleo-specs,master,Id9addc65f0d2ed519ce4b3edbd561ed660a2786e,Also bind public services to a dedicated VIP,MERGED,2014-06-16 06:16:12.000000000,2014-08-10 23:42:55.000000000,2014-08-10 23:42:55.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1605}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 8449}, {'_account_id': 9093}, {'_account_id': 9453}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-06-16 06:16:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/d8a5228a569383b236ff05837c724a5e4b046824', 'message': 'Also bind public services to a dedicated VIP\n\nThe current public IP feature is intended to specify the endpoint that\na cloud can be reached at. This is typically something where HA is\nhighly desirable.\n\nChange-Id: Id9addc65f0d2ed519ce4b3edbd561ed660a2786e\n'}, {'number': 2, 'created': '2014-06-16 19:30:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/0fa5303c9372299bf90dc94aada762168e53dfa3', 'message': 'Also bind public services to a dedicated VIP\n\nThe current public IP feature is intended to specify the endpoint that\na cloud can be reached at. This is typically something where HA is\nhighly desirable.\n\nChange-Id: Id9addc65f0d2ed519ce4b3edbd561ed660a2786e\n'}, {'number': 3, 'created': '2014-06-30 18:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/9b707e3c75e7fb29ce3ed0edc0754d2bb34e8b8a', 'message': 'Also bind public services to a dedicated VIP\n\nThe current public IP feature is intended to specify the endpoint that\na cloud can be reached at. This is typically something where HA is\nhighly desirable.\n\nChange-Id: Id9addc65f0d2ed519ce4b3edbd561ed660a2786e\n'}, {'number': 4, 'created': '2014-07-25 07:45:09.000000000', 'files': ['specs/juno/virtual-public-ips.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/84edfb9580af1ada9920e9f87cf23fd2fd564b98', 'message': 'Also bind public services to a dedicated VIP\n\nThe current public IP feature is intended to specify the endpoint that\na cloud can be reached at. This is typically something where HA is\nhighly desirable.\n\nChange-Id: Id9addc65f0d2ed519ce4b3edbd561ed660a2786e\n'}]",28,100151,84edfb9580af1ada9920e9f87cf23fd2fd564b98,54,11,4,4190,,,0,"Also bind public services to a dedicated VIP

The current public IP feature is intended to specify the endpoint that
a cloud can be reached at. This is typically something where HA is
highly desirable.

Change-Id: Id9addc65f0d2ed519ce4b3edbd561ed660a2786e
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/51/100151/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/virtual-public-ips.rst'],1,d8a5228a569383b236ff05837c724a5e4b046824,virtual-public-ip,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================ Virtual IPs for public addresses ================================ Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/tripleo/+specs/tripleo-juno-virtual-public-ips The current public IP feature is intended to specify the endpoint that a cloud can be reached at. This is typically something where HA is highly desirable. Making that a virtual IP should increase uptime. Problem Description =================== Today, we run all OpenStack services with listening ports on one virtual IP. This means that we're exposing RabbitMQ, MySQL and possibly other cluster-only services to the world, when really what we want is public services exposed to the world and cluster only servers not exposed to the world. Proposed Change =============== Create a second virtual IP from a user supplied network. Bind additional copies of API endpoints that should be publically accessible to that virtual IP. We need to bind them internally as well so that servers without any public connectivity such as hypervisors can still use the APIs (though they may need to override the IP to use in their hosts files - we have facilities for that already). The second virtual IP could in principle be on a dedicated ethernet card, or on a VLAN on a shared card. For now, lets require the admin to specify the interface on which keepalived should be provisioning the shared IP - be that ``br-ctlplane``, ``vlan25`` or ``eth2``. The user must be able to specify the same undercloud network as they do today so tht small installs are not made impossible. Alternatives ------------ We could not do HA for the public endpoints - not really an option. No other suggestions have been made so far. Security Impact --------------- Our security story improves by making this change, as we can potentially start firewalling the intra-cluster virtual IP to only allow known nodes to connect. Short of that, our security story has improved since we started binding to specific ips only, as that made opening a new IP address not actually expose core services (other than ssh) on it. Other End User Impact --------------------- End users will need to be able to find out about the new virtual IP. That should be straight forward via our existing mechanisms. Performance Impact ------------------ None anticipated. Other Deployer Impact --------------------- Deployers will require an additional IP address either on their undercloud ctlplane network (small installs) or on their public network (larger/production installs). Developer Impact ---------------- None expected. Implementation ============== Assignee(s) ----------- Primary assignee: lifeless (hahahaha) Other contributors: None. Work Items ---------- * Generalise keepalived.conf to support multople VRRP interfaces. * Add support for binding multiple ip's to the haproxy configuration. * Add logic to incubator // heat templates to request a second IP. * Change heat templates to bind public services to the public virtual IP. * Possibly tweak setup-endpoints to cooperate, though the prior support should be sufficient. Dependencies ============ None. Testing ======= This will be on by default, so our default CI path will exercise it. Additionally we'll be using it in the up coming VLAN test job which will give us confidence it works when the networks are partitoned. Documentation Impact ==================== Add to the manual is the main thing. References ========== None ",,132,0
openstack%2Ftaskflow~master~I62296f12eee6fa00559e84068ec5ee2a6d4bc0dc,openstack/taskflow,master,I62296f12eee6fa00559e84068ec5ee2a6d4bc0dc,Improve WBE testing coverage,MERGED,2014-06-21 21:05:18.000000000,2014-08-10 23:41:07.000000000,2014-08-10 23:41:07.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 8871}, {'_account_id': 8895}, {'_account_id': 9608}, {'_account_id': 9648}, {'_account_id': 11024}]","[{'number': 1, 'created': '2014-06-21 21:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5e0e0bbeb0caec21a79a621fb545aef8c2beba76', 'message': 'Add a latch type and use it during WBE tests (WIP)\n\nChange-Id: I62296f12eee6fa00559e84068ec5ee2a6d4bc0dc\n'}, {'number': 2, 'created': '2014-06-22 04:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2c356a3069f68fe251bc00c02160a96d36c6ea75', 'message': 'Add a latch type and use it during WBE tests (WIP)\n\nChange-Id: I62296f12eee6fa00559e84068ec5ee2a6d4bc0dc\n'}, {'number': 3, 'created': '2014-06-23 22:48:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/626454350f0c683cea51c35227e65eecf962f7e1', 'message': 'Improve WBE testing coverage\n\nTest more of the message pump process and verify\nthat messages are received and sent correctly by\nusing a latch type and waiting for the desired\nnumber of messages to be triggered.\n\nTest the full server and executor pipeline by\nsetting up threads and a in-memory queue/exchange\nthat is used by these threads for task execution.\n\nChange-Id: I62296f12eee6fa00559e84068ec5ee2a6d4bc0dc\n'}, {'number': 4, 'created': '2014-06-24 00:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2f417d8df05158969ee332651f7046099ddfa485', 'message': 'Improve WBE testing coverage\n\nTest more of the message pump process and verify\nthat messages are received and sent correctly by\nusing a latch type and waiting for the desired\nnumber of messages to be triggered.\n\nTest the full server and executor pipeline by\nsetting up threads and a in-memory queue/exchange\nthat is used by these threads for task execution.\n\nChange-Id: I62296f12eee6fa00559e84068ec5ee2a6d4bc0dc\n'}, {'number': 5, 'created': '2014-06-30 22:39:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e46cb28373f5537b0da8199b73e3f0afab26b37d', 'message': 'Improve WBE testing coverage\n\nTest more of the message pump process and verify\nthat messages are received and sent correctly by\nusing a latch type and waiting for the desired\nnumber of messages to be triggered.\n\nTest the full server and executor pipeline by\nsetting up threads and a in-memory queue/exchange\nthat is used by these threads for task execution.\n\nChange-Id: I62296f12eee6fa00559e84068ec5ee2a6d4bc0dc\n'}, {'number': 6, 'created': '2014-07-02 00:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3ecf7b34154e451a04dd01bb9bc13639eace4492', 'message': 'Improve WBE testing coverage\n\nTest more of the message pump process and verify\nthat messages are received and sent correctly by\nusing a latch type and waiting for the desired\nnumber of messages to be triggered.\n\nTest the full server and executor pipeline by\nsetting up threads and a in-memory queue/exchange\nthat is used by these threads for task execution.\n\nChange-Id: I62296f12eee6fa00559e84068ec5ee2a6d4bc0dc\n'}, {'number': 7, 'created': '2014-07-03 04:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/50c7e122072ff7e50bf6d1d70ba1273df9d0e45d', 'message': 'Improve WBE testing coverage\n\nTest more of the message pump process and verify\nthat messages are received and sent correctly by\nusing a latch type and waiting for the desired\nnumber of messages to be triggered.\n\nTest the full server and executor pipeline by\nsetting up threads and a in-memory queue/exchange\nthat is used by these threads for task execution.\n\nChange-Id: I62296f12eee6fa00559e84068ec5ee2a6d4bc0dc\n'}, {'number': 8, 'created': '2014-07-25 21:49:57.000000000', 'files': ['taskflow/engines/worker_based/executor.py', 'taskflow/tests/unit/worker_based/test_pipeline.py', 'taskflow/tests/unit/worker_based/test_message_pump.py', 'taskflow/types/latch.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/630364b4c13ae6f1aa6cdf9a2219239593e639dd', 'message': 'Improve WBE testing coverage\n\nTest more of the message pump process and verify\nthat messages are received and sent correctly by\nusing a latch type and waiting for the desired\nnumber of messages to be triggered.\n\nTest the full server and executor pipeline by\nsetting up threads and a in-memory queue/exchange\nthat is used by these threads for task execution.\n\nChange-Id: I62296f12eee6fa00559e84068ec5ee2a6d4bc0dc\n'}]",4,101717,630364b4c13ae6f1aa6cdf9a2219239593e639dd,64,7,8,1297,,,0,"Improve WBE testing coverage

Test more of the message pump process and verify
that messages are received and sent correctly by
using a latch type and waiting for the desired
number of messages to be triggered.

Test the full server and executor pipeline by
setting up threads and a in-memory queue/exchange
that is used by these threads for task execution.

Change-Id: I62296f12eee6fa00559e84068ec5ee2a6d4bc0dc
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/17/101717/8 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/types/latch.py'],1,5e0e0bbeb0caec21a79a621fb545aef8c2beba76,wbe-testing,"# -*- coding: utf-8 -*- # Copyright (C) 2014 Yahoo! Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import threading from taskflow.types import time as tt class Latch(object): """"""A class that ensures N-arrivals occur before unblocking."""""" def __init__(self, count): count = int(count) if count <= 0: raise ValueError(""Count must be greater than zero"") self._count = count self._cond = threading.Condition() @property def needed(self): """"""Returns how many decrements are needed before latch is released."""""" return max(0, self._count) def countdown(self): """"""Decrements the internal counter due to an arrival."""""" self._cond.acquire() try: self._count -= 1 if self._count <= 0: self._cond.notify_all() finally: self._cond.release() def wait(self, timeout=None): """"""Waits until the latch is released. NOTE(harlowja): if a timeout is provided this function will wait until that timeout expires, if the latch has been released before the timeout expires then this will return True, otherwise it will return False. """""" w = None if timeout is not None: w = tt.StopWatch(timeout).start() self._cond.acquire() try: while self._count > 0: if w is not None: if w.expired(): return False else: timeout = w.leftover() self._cond.wait(timeout) return True finally: self._cond.release() ",,69,0
openstack%2Ffuel-main~stable%2F5.0~I106ae30bd06f9499f9f940a78228405424e646b2,openstack/fuel-main,stable/5.0,I106ae30bd06f9499f9f940a78228405424e646b2,Up devops version to 2.4.2,MERGED,2014-08-10 21:48:52.000000000,2014-08-10 23:00:23.000000000,2014-08-10 23:00:23.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 11081}, {'_account_id': 11110}]","[{'number': 1, 'created': '2014-08-10 21:48:52.000000000', 'files': ['fuelweb_test/requirements.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/43374c706b4fdce28aeb4ef11e69a53f41646740', 'message': 'Up devops version to 2.4.2\n\nChange-Id: I106ae30bd06f9499f9f940a78228405424e646b2\n(cherry picked from commit 16c54168143061724e635a20a99545a756725b49)\n'}]",0,113149,43374c706b4fdce28aeb4ef11e69a53f41646740,9,7,1,8965,,,0,"Up devops version to 2.4.2

Change-Id: I106ae30bd06f9499f9f940a78228405424e646b2
(cherry picked from commit 16c54168143061724e635a20a99545a756725b49)
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/49/113149/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/requirements.txt'],1,43374c706b4fdce28aeb4ef11e69a53f41646740,,git+git://github.com/stackforge/fuel-devops.git@2.4.2,git+git://github.com/stackforge/fuel-devops.git@2.4.1,1,1
openstack%2Ffuel-main~master~I106ae30bd06f9499f9f940a78228405424e646b2,openstack/fuel-main,master,I106ae30bd06f9499f9f940a78228405424e646b2,Up devops version to 2.4.2,MERGED,2014-08-07 14:44:49.000000000,2014-08-10 21:48:52.000000000,2014-08-07 14:45:46.000000000,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8965}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-08-07 14:44:49.000000000', 'files': ['fuelweb_test/requirements.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/16c54168143061724e635a20a99545a756725b49', 'message': 'Up devops version to 2.4.2\n\nChange-Id: I106ae30bd06f9499f9f940a78228405424e646b2\n'}]",0,112598,16c54168143061724e635a20a99545a756725b49,11,4,1,8882,,,0,"Up devops version to 2.4.2

Change-Id: I106ae30bd06f9499f9f940a78228405424e646b2
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/98/112598/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/requirements.txt'],1,16c54168143061724e635a20a99545a756725b49,master,git+git://github.com/stackforge/fuel-devops.git@2.4.2,git+git://github.com/stackforge/fuel-devops.git@2.4.1,1,1
openstack%2Ftaskflow~master~I229fa7f4976b4792954a395e1af1b1e50e68cde1,openstack/taskflow,master,I229fa7f4976b4792954a395e1af1b1e50e68cde1,Allow accumulating the machines history,ABANDONED,2014-07-30 01:56:53.000000000,2014-08-10 21:38:34.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-07-30 01:56:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2f6f746d9d98173aeeba4396579ad5dc789c9a30', 'message': 'Allow accumulating the machines history\n\nIt is expected that analyzing the state machines\nruntime history will be a useful activity for others\nto do.\n\nTo enable this allow for a history parameter to be\nprovided that can be used in the following manner.\n\n- True (unlimited history)\n- False (no history) [default]\n- Integer (size limited history)\n\nChange-Id: I229fa7f4976b4792954a395e1af1b1e50e68cde1\n'}, {'number': 2, 'created': '2014-07-30 21:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/fa743ddb8723269b25a3e69846ec9066a61e4779', 'message': 'Allow accumulating the machines history\n\nIt is expected that analyzing the state machines\nruntime history will be a useful activity for others\nto do.\n\nTo enable this allow for a history parameter to be\nprovided that can be used in the following manner.\n\n- True (unlimited history)\n- False (no history) [*default*]\n- Integer (size limited history)\n\nChange-Id: I229fa7f4976b4792954a395e1af1b1e50e68cde1\n'}, {'number': 3, 'created': '2014-07-30 21:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5312d6c559fd46d8d7f53b5d5232729e94f6930b', 'message': 'Allow accumulating the machines history\n\nIt is expected that analyzing the state machines\nruntime history will be a useful activity for others\nto do.\n\nTo enable this allow for a history parameter to be\nprovided that can be used in the following manner.\n\n- True (unlimited history)\n- False (no history) [*default*]\n- Integer (size limited history)\n\nChange-Id: I229fa7f4976b4792954a395e1af1b1e50e68cde1\n'}, {'number': 4, 'created': '2014-07-31 01:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/12f48b25c805deeb0b07863722760c786d9f678c', 'message': 'Allow accumulating the machines history\n\nIt is expected that analyzing the state machines\nruntime history will be a useful activity for others\nto do.\n\nTo enable this allow for a history parameter to be\nprovided that can be used in the following manner.\n\n- True (unlimited history)\n- False (no history) [*default*]\n- Integer (size limited history)\n\nChange-Id: I229fa7f4976b4792954a395e1af1b1e50e68cde1\n'}, {'number': 5, 'created': '2014-08-01 03:39:38.000000000', 'files': ['taskflow/types/fsm.py', 'taskflow/tests/unit/test_types.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8300e6f6af59a8dd4d2a11eed48c956f1e5dd429', 'message': 'Allow accumulating the machines history\n\nIt is expected that analyzing the state machines\nruntime history will be a useful activity for others\nto do.\n\nTo enable this allow for a history parameter to be\nprovided that can be used in the following manner.\n\n- True (unlimited history)\n- False (no history) [*default*]\n- Integer (size limited history)\n\nChange-Id: I229fa7f4976b4792954a395e1af1b1e50e68cde1\n'}]",0,110525,8300e6f6af59a8dd4d2a11eed48c956f1e5dd429,19,2,5,1297,,,0,"Allow accumulating the machines history

It is expected that analyzing the state machines
runtime history will be a useful activity for others
to do.

To enable this allow for a history parameter to be
provided that can be used in the following manner.

- True (unlimited history)
- False (no history) [*default*]
- Integer (size limited history)

Change-Id: I229fa7f4976b4792954a395e1af1b1e50e68cde1
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/25/110525/5 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/types/fsm.py'],1,2f6f746d9d98173aeeba4396579ad5dc789c9a30,fsm,"import collections def __init__(self, start_state, history=False): if isinstance(history, bool): if not history: self._history = None else: self._history = collections.deque() elif isinstance(history, int): self._history = collections.deque(maxlen=history) else: raise ValueError(""history must be either a boolean or an"" "" integer that specifies the histories size"" "" limitation"") def history_iter(self): """"""Returns an iterator over the machines history. This iterator will iterate over (from newest to oldest) tuples of the following format (old_state, new_state, event_triggered). If the history specified was size limited then this will only contain the X amount of previous tuples (and not the full machines history). NOTE(harlowja): it should *not* be used on a machine that is actively running (by another thread for example). """""" if self._history is not None: return iter(self._history) else: return iter([]) if self._history is not None: self._history.appendleft((current.name, replacement.name, event)) if self._history is not None: self._history.clear()"," def __init__(self, start_state):",34,1
openstack%2Ftraining-guides~master~I2880a8b301c6032b1e077bd458b2b25a89552b89,openstack/training-guides,master,I2880a8b301c6032b1e077bd458b2b25a89552b89,labs: fix snapshot taking for ssh installs,MERGED,2014-08-10 16:35:09.000000000,2014-08-10 20:35:37.000000000,2014-08-10 20:35:37.000000000,"[{'_account_id': 3}, {'_account_id': 7007}]","[{'number': 1, 'created': '2014-08-10 16:35:09.000000000', 'files': ['labs/lib/osbash/functions.host'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/77c3156e61ec8573c8f79dafce3683fea116512d', 'message': 'labs: fix snapshot taking for ssh installs\n\nautostart_from_config reads the config/scripts.* files from stdin. That\nworks as long as nothing messes with the standard file descriptors. When\nwe use ssh to execute scripts within the autostart_from_config reading\nloop, stdin is no longer safe.\n\nThe result is that config files are only read until the first boot\ncommand is encountered and executed, which for the current configuration\nfiles means that the final snapshot command is skipped.\n\nTo fix this bug, the patch opens the config file on file descriptor 3\nwhere it is safe from ssh.\n\nChange-Id: I2880a8b301c6032b1e077bd458b2b25a89552b89\n'}]",0,113138,77c3156e61ec8573c8f79dafce3683fea116512d,7,2,1,11109,,,0,"labs: fix snapshot taking for ssh installs

autostart_from_config reads the config/scripts.* files from stdin. That
works as long as nothing messes with the standard file descriptors. When
we use ssh to execute scripts within the autostart_from_config reading
loop, stdin is no longer safe.

The result is that config files are only read until the first boot
command is encountered and executed, which for the current configuration
files means that the final snapshot command is skipped.

To fix this bug, the patch opens the config file on file descriptor 3
where it is safe from ssh.

Change-Id: I2880a8b301c6032b1e077bd458b2b25a89552b89
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/38/113138/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/lib/osbash/functions.host'],1,77c3156e61ec8573c8f79dafce3683fea116512d,fix_snapshot_ssh," # Open file on file descriptor 3 so programs we call in this loop (ssh) # are free to mess with the standard file descriptors. exec 3< ""$config_path"" while read -r field_1 field_2 <&3; do done"," while read -r field_1 field_2; do done < ""$config_path""",6,2
openstack%2Fopenstack-doc-tools~master~If7023f825c76bec16980dc84283da446c18a82b7,openstack/openstack-doc-tools,master,If7023f825c76bec16980dc84283da446c18a82b7,jsoncheck: fix _indent_note for pre-formatted strings,MERGED,2014-08-07 06:40:29.000000000,2014-08-10 20:09:58.000000000,2014-08-10 20:09:57.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-07 06:40:29.000000000', 'files': ['os_doc_tools/jsoncheck.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/b0a2f9818a67671d4dff57f51b9078e27e530f22', 'message': 'jsoncheck: fix _indent_note for pre-formatted strings\n\nCurrent versions of demjson return pre-formatted, pre-indented strings.\nLine wrapping them results in strings that are harder to read.\n\nWith this patch, _indent_note splits strings into lines before indenting\nand (if necessary) line wrapping them.\n\nblueprint modularize-doctest\nChange-Id: If7023f825c76bec16980dc84283da446c18a82b7\n'}]",0,112489,b0a2f9818a67671d4dff57f51b9078e27e530f22,10,3,1,11109,,,0,"jsoncheck: fix _indent_note for pre-formatted strings

Current versions of demjson return pre-formatted, pre-indented strings.
Line wrapping them results in strings that are harder to read.

With this patch, _indent_note splits strings into lines before indenting
and (if necessary) line wrapping them.

blueprint modularize-doctest
Change-Id: If7023f825c76bec16980dc84283da446c18a82b7
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/89/112489/1 && git format-patch -1 --stdout FETCH_HEAD,['os_doc_tools/jsoncheck.py'],1,b0a2f9818a67671d4dff57f51b9078e27e530f22,bp/modularize-doctest,"def _indent_note(note): indented_note = [] # Split into single lines in case the argument is pre-formatted. for line in note.splitlines(): indented_note.append(textwrap.fill(line, initial_indent=8 * ' ', subsequent_indent=12 * ' ', width=80)) return ""\n"".join(indented_note)","def _indent_note(errstr): return textwrap.fill(errstr, initial_indent=8 * ' ', subsequent_indent=12 * ' ', width=80)",8,4
openstack%2Fneutron~master~Ia393f8cbeafe03455b8f75302c71365fcd75a51e,openstack/neutron,master,Ia393f8cbeafe03455b8f75302c71365fcd75a51e,ofagent: Update a comment in port_bound,MERGED,2014-07-29 02:47:57.000000000,2014-08-10 20:02:43.000000000,2014-08-10 20:02:41.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 1653}, {'_account_id': 1935}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-07-29 02:47:57.000000000', 'files': ['neutron/plugins/ofagent/agent/ofa_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6b4da14d76daaaaf99cd6934acecee5f60306868', 'message': 'ofagent: Update a comment in port_bound\n\nChange-Id: Ia393f8cbeafe03455b8f75302c71365fcd75a51e\n'}]",0,110186,6b4da14d76daaaaf99cd6934acecee5f60306868,49,25,1,6854,,,0,"ofagent: Update a comment in port_bound

Change-Id: Ia393f8cbeafe03455b8f75302c71365fcd75a51e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/86/110186/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ofagent/agent/ofa_neutron_agent.py'],1,6b4da14d76daaaaf99cd6934acecee5f60306868,ofagent-misc-fix1, :param port: a ports.Port object., :param port: a ovs_lib.VifPort object.,1,1
openstack%2Fnova~master~I33c86b1500f9a69081b4c6ecbe79151f10f69cea,openstack/nova,master,I33c86b1500f9a69081b4c6ecbe79151f10f69cea,Only use dhcp if enable_dhcp is set on the network,MERGED,2014-05-15 16:15:58.000000000,2014-08-10 19:10:13.000000000,2014-07-29 04:33:46.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 67}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6681}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-15 16:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/427938e03f69b1324f5ea58c582d476173295af9', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nPartially-implements blueprint add-mtu-and-dhcp-server-to-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 2, 'created': '2014-05-15 18:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/68922db4142b9cda05628abdcf5d52103ea41eea', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nPartially-implements blueprint add-mtu-and-dhcp-server-to-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 3, 'created': '2014-05-18 19:55:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e6693be14786e1bbb851362dea0f22ebdbf9bd45', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nAlso removes an unused call to init_host if there is no network\nto setup. The signature of this call was wrong so clearly it was\nnot being used.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 4, 'created': '2014-05-18 23:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1c10d5ed56e876f45d3e79a4e61a2e3428f6cfa3', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nAlso removes an unused call to init_host if there is no network\nto setup. The signature of this call was wrong so clearly it was\nnot being used.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 5, 'created': '2014-05-19 18:37:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca0239333a856d710b2560e52ee67d3f9669ab91', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nAlso removes an unused call to init_host if there is no network\nto setup. The signature of this call was wrong so clearly it was\nnot being used.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 6, 'created': '2014-05-20 20:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f1f0355a6ad091e764f758f7912c06df4d8e713', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nAlso removes an unused call to init_host if there is no network\nto setup. The signature of this call was wrong so clearly it was\nnot being used.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 7, 'created': '2014-05-20 23:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cced9b197bb81967a7a3886c44353a1e5c94ce21', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nAlso removes an unused call to init_host if there is no network\nto setup. The signature of this call was wrong so clearly it was\nnot being used.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 8, 'created': '2014-05-21 04:59:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8e6a44d440f03e91eace8f745185545cccbd03ae', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nAlso removes an unused call to init_host if there is no network\nto setup. The signature of this call was wrong so clearly it was\nnot being used.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 9, 'created': '2014-05-21 06:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f48b28df6ed88ae18ee297659b2f39927206346a', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nAlso removes an unused call to init_host if there is no network\nto setup. The signature of this call was wrong so clearly it was\nnot being used.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 10, 'created': '2014-05-23 21:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7093240d75efb6e69a800a5c8ec03a12018c144f', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nAlso removes an unused call to init_host if there is no network\nto setup. The signature of this call was wrong so clearly it was\nnot being used.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 11, 'created': '2014-05-30 18:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d49732b82163d29d157b3c72b6c7e247f0b7a5c7', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nAlso removes an unused call to init_host if there is no network\nto setup. The signature of this call was wrong so clearly it was\nnot being used.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 12, 'created': '2014-05-30 23:00:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/451e8aa547fc6d5f49068d4752459822d2edd245', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nAlso removes an unused call to init_host if there is no network\nto setup. The signature of this call was wrong so clearly it was\nnot being used.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 13, 'created': '2014-06-16 18:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4367b10959c94fae0aee4731dfb9409d1035bddb', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nAlso removes an unused call to init_host if there is no network\nto setup. The signature of this call was wrong so clearly it was\nnot being used.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 14, 'created': '2014-06-19 16:24:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/83bed828b7ff3c0b2a763a0fdfbbd3868aec402d', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nAlso removes an unused call to init_host if there is no network\nto setup. The signature of this call was wrong so clearly it was\nnot being used.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 15, 'created': '2014-07-02 18:50:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f63810d57387aa1d62421c8126d1e943d77c30c', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nAlso removes an unused call to init_host if there is no network\nto setup. The signature of this call was wrong so clearly it was\nnot being used.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 16, 'created': '2014-07-17 19:22:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4e5914d565226cb273c1d7fef04a1dc4a7326d5b', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nAlso removes an unused call to init_host if there is no network\nto setup. The signature of this call was wrong so clearly it was\nnot being used.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 17, 'created': '2014-07-25 20:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e0eb8333e34c2cb523d9901386c71e9a840384ed', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nAlso removes an unused call to init_host if there is no network\nto setup. The signature of this call was wrong so clearly it was\nnot being used.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 18, 'created': '2014-07-25 20:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/007c93a3c7f949245b6a935d43182179e6373145', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nAlso removes an unused call to init_host if there is no network\nto setup. The signature of this call was wrong so clearly it was\nnot being used.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}, {'number': 19, 'created': '2014-07-25 20:46:14.000000000', 'files': ['nova/network/manager.py', 'nova/network/l3.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6ee9fa429c97aee1507a0a4d21d885845fa0b85e', 'message': 'Only use dhcp if enable_dhcp is set on the network\n\nAlso removes an unused call to init_host if there is no network\nto setup. The signature of this call was wrong so clearly it was\nnot being used.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea\n'}]",1,93758,6ee9fa429c97aee1507a0a4d21d885845fa0b85e,151,14,19,67,,,0,"Only use dhcp if enable_dhcp is set on the network

Also removes an unused call to init_host if there is no network
to setup. The signature of this call was wrong so clearly it was
not being used.

Partially-implements blueprint better-support-for-multiple-networks

Change-Id: I33c86b1500f9a69081b4c6ecbe79151f10f69cea
",git fetch https://review.opendev.org/openstack/nova refs/changes/58/93758/19 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/manager.py'],1,427938e03f69b1324f5ea58c582d476173295af9,bp/better-support-for-multiple-networks," # NOTE(vish): if dhcp server is not set then don't dhcp if not CONF.fake_network and network.enable_dhcp: # NOTE(vish): if dhcp server is not set then don't dhcp if not CONF.fake_network and network.enable_dhcp: if network.enable_dhcp: elevated = context.elevated() self.driver.update_dhcp(elevated, dev, network) if network.enable_dhcp: self.driver.kill_dhcp(dev) # NOTE(vish): if dhcp server is not set then don't dhcp elif network.enable_dhcp: # NOTE(dprince): dhcp DB queries require elevated context elevated = context.elevated()"," if not CONF.fake_network: if not CONF.fake_network: elevated = context.elevated() self.driver.update_dhcp(elevated, dev, network) # NOTE(dprince): dhcp DB queries require elevated context elevated = context.elevated() self.driver.update_dhcp(elevated, dev, network) self.driver.kill_dhcp(dev) else:",13,9
openstack%2Fnova~master~Id040ce1fb0f889418815568ff6c80402b69bf09e,openstack/nova,master,Id040ce1fb0f889418815568ff6c80402b69bf09e,Allow dhcp_server to be set from new field,MERGED,2014-05-15 16:15:58.000000000,2014-08-10 18:24:19.000000000,2014-07-27 22:59:50.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 67}, {'_account_id': 642}, {'_account_id': 1030}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 8430}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-15 16:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c313bc2af01a9cfb34636de9e9c540256aa4deaf', 'message': ""Allow dhcp_server to be set from new field\n\nNow that dhcp_server and gateway can be different, update dnsmasq\nto hand out the gateway if we have a single ip address and they\ndon't match.\n\nPartially-implements blueprint add-mtu-and-dhcp-server-to-networks\n\nChange-Id: Id040ce1fb0f889418815568ff6c80402b69bf09e\n""}, {'number': 2, 'created': '2014-05-15 18:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ac11b8f768934df8dcdde0ebbe3bccad4329562b', 'message': ""Allow dhcp_server to be set from new field\n\nNow that dhcp_server and gateway can be different, update dnsmasq\nto hand out the gateway if we have a single ip address and they\ndon't match.\n\nPartially-implements blueprint add-mtu-and-dhcp-server-to-networks\n\nChange-Id: Id040ce1fb0f889418815568ff6c80402b69bf09e\n""}, {'number': 3, 'created': '2014-05-18 19:55:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f727c40c3cd085b66dbcb6aed7367e542a6283c5', 'message': ""Allow dhcp_server to be set from new field\n\nNow that dhcp_server and gateway can be different, update dnsmasq\nto hand out the gateway if we have a single ip address and they\ndon't match.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id040ce1fb0f889418815568ff6c80402b69bf09e\n""}, {'number': 4, 'created': '2014-05-20 20:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7013f531a5d2a30436615a90a6b4314022ad39f5', 'message': ""Allow dhcp_server to be set from new field\n\nNow that dhcp_server and gateway can be different, update dnsmasq\nto hand out the gateway if we have a single ip address and they\ndon't match.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id040ce1fb0f889418815568ff6c80402b69bf09e\n""}, {'number': 5, 'created': '2014-05-20 23:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d4b45ae85df35f2108e10d26d51bf0a17da01ab2', 'message': ""Allow dhcp_server to be set from new field\n\nNow that dhcp_server and gateway can be different, update dnsmasq\nto hand out the gateway if we have a single ip address and they\ndon't match.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id040ce1fb0f889418815568ff6c80402b69bf09e\n""}, {'number': 6, 'created': '2014-05-21 04:59:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/665cf2da92a3ba29a38e184ef7df6ae9f33cb98b', 'message': ""Allow dhcp_server to be set from new field\n\nNow that dhcp_server and gateway can be different, update dnsmasq\nto hand out the gateway if we have a single ip address and they\ndon't match.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id040ce1fb0f889418815568ff6c80402b69bf09e\n""}, {'number': 7, 'created': '2014-05-21 06:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fb225690332f5fc43520484b064a5f71de005f29', 'message': ""Allow dhcp_server to be set from new field\n\nNow that dhcp_server and gateway can be different, update dnsmasq\nto hand out the gateway if we have a single ip address and they\ndon't match.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id040ce1fb0f889418815568ff6c80402b69bf09e\n""}, {'number': 8, 'created': '2014-05-30 18:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ac725a95f6566a7cae06a7e41822fa1a7500f1ac', 'message': ""Allow dhcp_server to be set from new field\n\nNow that dhcp_server and gateway can be different, update dnsmasq\nto hand out the gateway if we have a single ip address and they\ndon't match.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id040ce1fb0f889418815568ff6c80402b69bf09e\n""}, {'number': 9, 'created': '2014-05-30 23:00:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/77ac9a40ff469bccef5330ea1e20f43ae62ee7d5', 'message': ""Allow dhcp_server to be set from new field\n\nNow that dhcp_server and gateway can be different, update dnsmasq\nto hand out the gateway if we have a single ip address and they\ndon't match.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id040ce1fb0f889418815568ff6c80402b69bf09e\n""}, {'number': 10, 'created': '2014-06-16 18:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8e066e2fe0a8119dea0700211cbbc5ba156aeef7', 'message': ""Allow dhcp_server to be set from new field\n\nNow that dhcp_server and gateway can be different, update dnsmasq\nto hand out the gateway if we have a single ip address and they\ndon't match.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id040ce1fb0f889418815568ff6c80402b69bf09e\n""}, {'number': 11, 'created': '2014-06-19 16:24:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d84164bd080b05dfa48479483a959b0d190a4b81', 'message': ""Allow dhcp_server to be set from new field\n\nNow that dhcp_server and gateway can be different, update dnsmasq\nto hand out the gateway if we have a single ip address and they\ndon't match.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id040ce1fb0f889418815568ff6c80402b69bf09e\n""}, {'number': 12, 'created': '2014-07-02 18:50:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aad8ddd8110d7b49d7a53d66572ad8740a3c79f1', 'message': ""Allow dhcp_server to be set from new field\n\nNow that dhcp_server and gateway can be different, update dnsmasq\nto hand out the gateway if we have a single ip address and they\ndon't match.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id040ce1fb0f889418815568ff6c80402b69bf09e\n""}, {'number': 13, 'created': '2014-07-17 19:22:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3dd5d9593c9cf967b2448a24580852cd774d564a', 'message': ""Allow dhcp_server to be set from new field\n\nNow that dhcp_server and gateway can be different, update dnsmasq\nto hand out the gateway if we have a single ip address and they\ndon't match.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id040ce1fb0f889418815568ff6c80402b69bf09e\n""}, {'number': 14, 'created': '2014-07-25 20:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fea44c1982d5e94f6fad26d26ad93d28365c7775', 'message': ""Allow dhcp_server to be set from new field\n\nNow that dhcp_server and gateway can be different, update dnsmasq\nto hand out the gateway if we have a single ip address and they\ndon't match.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id040ce1fb0f889418815568ff6c80402b69bf09e\n""}, {'number': 15, 'created': '2014-07-25 20:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b502dd31c2caa4caa8e567e59dd3f924601dc3cb', 'message': ""Allow dhcp_server to be set from new field\n\nNow that dhcp_server and gateway can be different, update dnsmasq\nto hand out the gateway if we have a single ip address and they\ndon't match.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id040ce1fb0f889418815568ff6c80402b69bf09e\n""}, {'number': 16, 'created': '2014-07-25 20:46:14.000000000', 'files': ['nova/network/nova_ipam_lib.py', 'nova/network/manager.py', 'nova/network/linux_net.py', 'nova/tests/network/test_linux_net.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c4fc94e66c7b4955de7ee38b8dd68fd55a4890fa', 'message': ""Allow dhcp_server to be set from new field\n\nNow that dhcp_server and gateway can be different, update dnsmasq\nto hand out the gateway if we have a single ip address and they\ndon't match.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id040ce1fb0f889418815568ff6c80402b69bf09e\n""}]",8,93757,c4fc94e66c7b4955de7ee38b8dd68fd55a4890fa,152,15,16,67,,,0,"Allow dhcp_server to be set from new field

Now that dhcp_server and gateway can be different, update dnsmasq
to hand out the gateway if we have a single ip address and they
don't match.

Partially-implements blueprint better-support-for-multiple-networks

Change-Id: Id040ce1fb0f889418815568ff6c80402b69bf09e
",git fetch https://review.opendev.org/openstack/nova refs/changes/57/93757/9 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/nova_ipam_lib.py', 'nova/network/manager.py', 'nova/network/linux_net.py', 'nova/tests/network/test_linux_net.py']",4,c313bc2af01a9cfb34636de9e9c540256aa4deaf,bp/better-support-for-multiple-networks," 'vpn_public_address': '192.168.0.2', 'mtu': None, 'dhcp_server': '192.168.0.1', 'enable_dhcp': True, 'share_address': False}, 'vpn_public_address': '192.168.1.2', 'mtu': None, 'dhcp_server': '192.168.1.1', 'enable_dhcp': True, 'share_address': False}] self.flags(use_single_default_gateway=True) expected_opts = 'NW-0,3,192.168.0.1\nNW-3,3\nNW-4,3' self.flags(use_single_default_gateway=True, host='fake_instance01') expected_opts = ""NW-2,3,192.168.1.1\nNW-5,3"" 'gateway': '10.0.0.1', 'dhcp_server': '10.0.0.1', 'shared_address': False} '--dhcp-optsfile=%s' % linux_net._dhcp_file(dev, 'opts'),"," 'vpn_public_address': '192.168.0.2'}, 'vpn_public_address': '192.168.1.2'}] expected_opts = 'NW-3,3\nNW-4,3' self.flags(host='fake_instance01') expected_opts = ""NW-5,3"" 'dhcp_server': '10.0.0.1'}",72,39
openstack%2Fnova~master~Id5ec66946c3a82841a6dd2d019404e822cdafe64,openstack/nova,master,Id5ec66946c3a82841a6dd2d019404e822cdafe64,Properly handle snatting for external gateways,MERGED,2014-05-18 19:55:07.000000000,2014-08-10 18:08:43.000000000,2014-08-01 22:28:05.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 67}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-18 19:55:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/92853a28bee151c788d3491ae2f1c1b7cb1d0550', 'message': ""Properly handle snatting for external gateways\n\nPreviously, snatting for netowrks with external gateways had to be\nhandled by manually setting:\n * public_interface = ''\n * force_snat_range = snat_range\nWhereas networks with a gateway managed by nova needed:\n * public_interface = eth0\n * force_snat_range = None or ['0.0.0.0/0']\n\nIn order to support both simultaneously, we calcualate whether the\ngateway is external, and use the force_snat_range and skip interface\nif it is an external gateway. Otherwise, we use the setting for public\ninterface and 0.0.0.0/0. This allows external and internal gateways\nto co-exist.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64\n""}, {'number': 2, 'created': '2014-05-18 23:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/338ca86d258c4fc71a4ac4dd8e9661662c2763ed', 'message': ""Properly handle snatting for external gateways\n\nPreviously, snatting for netowrks with external gateways had to be\nhandled by manually setting:\n * public_interface = ''\n * force_snat_range = snat_range\nWhereas networks with a gateway managed by nova needed:\n * public_interface = eth0\n * force_snat_range = None or ['0.0.0.0/0']\n\nIn order to support both simultaneously, we calcualate whether the\ngateway is external, and use the force_snat_range and skip interface\nif it is an external gateway. Otherwise, we use the setting for public\ninterface and 0.0.0.0/0. This allows external and internal gateways\nto co-exist.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64\n""}, {'number': 3, 'created': '2014-05-19 18:37:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/34c6f0ec028e329e725360d1afaba3870034bfb2', 'message': ""Properly handle snatting for external gateways\n\nPreviously, snatting for netowrks with external gateways had to be\nhandled by manually setting:\n * public_interface = ''\n * force_snat_range = snat_range\nWhereas networks with a gateway managed by nova needed:\n * public_interface = eth0\n * force_snat_range = None or ['0.0.0.0/0']\n\nIn order to support both simultaneously, we calcualate whether the\ngateway is external, and use the force_snat_range and skip interface\nif it is an external gateway. Otherwise, we use the setting for public\ninterface and 0.0.0.0/0. This allows external and internal gateways\nto co-exist.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64\n""}, {'number': 4, 'created': '2014-05-20 20:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/40ed29ae30d99c44c7134960f5a411c678c755a2', 'message': ""Properly handle snatting for external gateways\n\nPreviously, snatting for netowrks with external gateways had to be\nhandled by manually setting:\n * public_interface = ''\n * force_snat_range = snat_range\nWhereas networks with a gateway managed by nova needed:\n * public_interface = eth0\n * force_snat_range = None or ['0.0.0.0/0']\n\nIn order to support both simultaneously, we calcualate whether the\ngateway is external, and use the force_snat_range and skip interface\nif it is an external gateway. Otherwise, we use the setting for public\ninterface and 0.0.0.0/0. This allows external and internal gateways\nto co-exist.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64\n""}, {'number': 5, 'created': '2014-05-20 23:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dee7f3c6ae7604e5c4a042f6ab2576890a981307', 'message': ""Properly handle snatting for external gateways\n\nPreviously, snatting for netowrks with external gateways had to be\nhandled by manually setting:\n * public_interface = ''\n * force_snat_range = snat_range\nWhereas networks with a gateway managed by nova needed:\n * public_interface = eth0\n * force_snat_range = None or ['0.0.0.0/0']\n\nIn order to support both simultaneously, we calcualate whether the\ngateway is external, and use the force_snat_range and skip interface\nif it is an external gateway. Otherwise, we use the setting for public\ninterface and 0.0.0.0/0. This allows external and internal gateways\nto co-exist.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64\n""}, {'number': 6, 'created': '2014-05-21 04:59:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ac7edeb207054cbb50261c81ecbb2afbc773083', 'message': ""Properly handle snatting for external gateways\n\nPreviously, snatting for netowrks with external gateways had to be\nhandled by manually setting:\n * public_interface = ''\n * force_snat_range = snat_range\nWhereas networks with a gateway managed by nova needed:\n * public_interface = eth0\n * force_snat_range = None or ['0.0.0.0/0']\n\nIn order to support both simultaneously, we calcualate whether the\ngateway is external, and use the force_snat_range and skip interface\nif it is an external gateway. Otherwise, we use the setting for public\ninterface and 0.0.0.0/0. This allows external and internal gateways\nto co-exist.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64\n""}, {'number': 7, 'created': '2014-05-21 06:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c961795ecef8cdae664550ca0cc6cd3aee814fc', 'message': ""Properly handle snatting for external gateways\n\nPreviously, snatting for netowrks with external gateways had to be\nhandled by manually setting:\n * public_interface = ''\n * force_snat_range = snat_range\nWhereas networks with a gateway managed by nova needed:\n * public_interface = eth0\n * force_snat_range = None or ['0.0.0.0/0']\n\nIn order to support both simultaneously, we calcualate whether the\ngateway is external, and use the force_snat_range and skip interface\nif it is an external gateway. Otherwise, we use the setting for public\ninterface and 0.0.0.0/0. This allows external and internal gateways\nto co-exist.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64\n""}, {'number': 8, 'created': '2014-05-23 21:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/38c067a664ab06f268737cfe5ac1ea4f5ab7fe5f', 'message': ""Properly handle snatting for external gateways\n\nPreviously, snatting for netowrks with external gateways had to be\nhandled by manually setting:\n * public_interface = ''\n * force_snat_range = snat_range\nWhereas networks with a gateway managed by nova needed:\n * public_interface = eth0\n * force_snat_range = None or ['0.0.0.0/0']\n\nIn order to support both simultaneously, we calcualate whether the\ngateway is external, and use the force_snat_range and skip interface\nif it is an external gateway. Otherwise, we use the setting for public\ninterface and 0.0.0.0/0. This allows external and internal gateways\nto co-exist.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64\n""}, {'number': 9, 'created': '2014-05-30 18:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32613722641c5fd3aeb3e022683be8c4390d278e', 'message': ""Properly handle snatting for external gateways\n\nPreviously, snatting for netowrks with external gateways had to be\nhandled by manually setting:\n * public_interface = ''\n * force_snat_range = snat_range\nWhereas networks with a gateway managed by nova needed:\n * public_interface = eth0\n * force_snat_range = None or ['0.0.0.0/0']\n\nIn order to support both simultaneously, we calcualate whether the\ngateway is external, and use the force_snat_range and skip interface\nif it is an external gateway. Otherwise, we use the setting for public\ninterface and 0.0.0.0/0. This allows external and internal gateways\nto co-exist.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64\n""}, {'number': 10, 'created': '2014-05-30 23:00:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1868d22397956d8ade504ec85588e381f32d1954', 'message': ""Properly handle snatting for external gateways\n\nPreviously, snatting for netowrks with external gateways had to be\nhandled by manually setting:\n * public_interface = ''\n * force_snat_range = snat_range\nWhereas networks with a gateway managed by nova needed:\n * public_interface = eth0\n * force_snat_range = None or ['0.0.0.0/0']\n\nIn order to support both simultaneously, we calcualate whether the\ngateway is external, and use the force_snat_range and skip interface\nif it is an external gateway. Otherwise, we use the setting for public\ninterface and 0.0.0.0/0. This allows external and internal gateways\nto co-exist.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64\n""}, {'number': 11, 'created': '2014-06-16 18:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/df25b4711041f2841e0c47d609eab4413a7cb570', 'message': ""Properly handle snatting for external gateways\n\nPreviously, snatting for netowrks with external gateways had to be\nhandled by manually setting:\n * public_interface = ''\n * force_snat_range = snat_range\nWhereas networks with a gateway managed by nova needed:\n * public_interface = eth0\n * force_snat_range = None or ['0.0.0.0/0']\n\nIn order to support both simultaneously, we calcualate whether the\ngateway is external, and use the force_snat_range and skip interface\nif it is an external gateway. Otherwise, we use the setting for public\ninterface and 0.0.0.0/0. This allows external and internal gateways\nto co-exist.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64\n""}, {'number': 12, 'created': '2014-06-19 16:24:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a458ab78cfc5d45c55665c978f1c4ddd3764d24', 'message': ""Properly handle snatting for external gateways\n\nPreviously, snatting for netowrks with external gateways had to be\nhandled by manually setting:\n * public_interface = ''\n * force_snat_range = snat_range\nWhereas networks with a gateway managed by nova needed:\n * public_interface = eth0\n * force_snat_range = None or ['0.0.0.0/0']\n\nIn order to support both simultaneously, we calcualate whether the\ngateway is external, and use the force_snat_range and skip interface\nif it is an external gateway. Otherwise, we use the setting for public\ninterface and 0.0.0.0/0. This allows external and internal gateways\nto co-exist.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64\n""}, {'number': 13, 'created': '2014-07-02 18:50:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f93384d9187663a2094cd9fda0251f1aa52e8cb4', 'message': ""Properly handle snatting for external gateways\n\nPreviously, snatting for netowrks with external gateways had to be\nhandled by manually setting:\n * public_interface = ''\n * force_snat_range = snat_range\nWhereas networks with a gateway managed by nova needed:\n * public_interface = eth0\n * force_snat_range = None or ['0.0.0.0/0']\n\nIn order to support both simultaneously, we calcualate whether the\ngateway is external, and use the force_snat_range and skip interface\nif it is an external gateway. Otherwise, we use the setting for public\ninterface and 0.0.0.0/0. This allows external and internal gateways\nto co-exist.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64\n""}, {'number': 14, 'created': '2014-07-17 19:22:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/635636b66ccca304bf4b35c80f7180a7703b8b4b', 'message': ""Properly handle snatting for external gateways\n\nPreviously, snatting for netowrks with external gateways had to be\nhandled by manually setting:\n * public_interface = ''\n * force_snat_range = snat_range\nWhereas networks with a gateway managed by nova needed:\n * public_interface = eth0\n * force_snat_range = None or ['0.0.0.0/0']\n\nIn order to support both simultaneously, we calcualate whether the\ngateway is external, and use the force_snat_range and skip interface\nif it is an external gateway. Otherwise, we use the setting for public\ninterface and 0.0.0.0/0. This allows external and internal gateways\nto co-exist.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64\n""}, {'number': 15, 'created': '2014-07-25 20:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a190eec518ded9d8b42edd5991b59093d9a96bd2', 'message': ""Properly handle snatting for external gateways\n\nPreviously, snatting for netowrks with external gateways had to be\nhandled by manually setting:\n * public_interface = ''\n * force_snat_range = snat_range\nWhereas networks with a gateway managed by nova needed:\n * public_interface = eth0\n * force_snat_range = None or ['0.0.0.0/0']\n\nIn order to support both simultaneously, we calcualate whether the\ngateway is external, and use the force_snat_range and skip interface\nif it is an external gateway. Otherwise, we use the setting for public\ninterface and 0.0.0.0/0. This allows external and internal gateways\nto co-exist.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64\n""}, {'number': 16, 'created': '2014-07-25 20:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1b0163c1d01bd742c123f4d3e665aac540fad55d', 'message': ""Properly handle snatting for external gateways\n\nPreviously, snatting for netowrks with external gateways had to be\nhandled by manually setting:\n * public_interface = ''\n * force_snat_range = snat_range\nWhereas networks with a gateway managed by nova needed:\n * public_interface = eth0\n * force_snat_range = None or ['0.0.0.0/0']\n\nIn order to support both simultaneously, we calcualate whether the\ngateway is external, and use the force_snat_range and skip interface\nif it is an external gateway. Otherwise, we use the setting for public\ninterface and 0.0.0.0/0. This allows external and internal gateways\nto co-exist.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64\n""}, {'number': 17, 'created': '2014-07-25 20:46:14.000000000', 'files': ['nova/network/manager.py', 'nova/network/linux_net.py', 'nova/network/l3.py', 'nova/tests/network/test_manager.py', 'nova/tests/network/test_linux_net.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/59ac254bf15bb059cca12a82c9d819c371ea5c6f', 'message': ""Properly handle snatting for external gateways\n\nPreviously, snatting for netowrks with external gateways had to be\nhandled by manually setting:\n * public_interface = ''\n * force_snat_range = snat_range\nWhereas networks with a gateway managed by nova needed:\n * public_interface = eth0\n * force_snat_range = None or ['0.0.0.0/0']\n\nIn order to support both simultaneously, we calcualate whether the\ngateway is external, and use the force_snat_range and skip interface\nif it is an external gateway. Otherwise, we use the setting for public\ninterface and 0.0.0.0/0. This allows external and internal gateways\nto co-exist.\n\nPartially-implements blueprint better-support-for-multiple-networks\n\nChange-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64\n""}]",9,94112,59ac254bf15bb059cca12a82c9d819c371ea5c6f,151,12,17,67,,,0,"Properly handle snatting for external gateways

Previously, snatting for netowrks with external gateways had to be
handled by manually setting:
 * public_interface = ''
 * force_snat_range = snat_range
Whereas networks with a gateway managed by nova needed:
 * public_interface = eth0
 * force_snat_range = None or ['0.0.0.0/0']

In order to support both simultaneously, we calcualate whether the
gateway is external, and use the force_snat_range and skip interface
if it is an external gateway. Otherwise, we use the setting for public
interface and 0.0.0.0/0. This allows external and internal gateways
to co-exist.

Partially-implements blueprint better-support-for-multiple-networks

Change-Id: Id5ec66946c3a82841a6dd2d019404e822cdafe64
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/94112/7 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/linux_net.py', 'nova/network/l3.py', 'nova/tests/network/test_linux_net.py']",3,92853a28bee151c788d3491ae2f1c1b7cb1d0550,bp/better-support-for-multiple-networks," def _test_add_snat_rule(self, expected, ext_gateway): self.called = True self.called = False linux_net.add_snat_rule('10.0.0.0/24', ext_gateway) if expected: self.assertTrue(self.called) def test_add_snat_rule_no_ext(self): self._test_add_snat_rule(expected, False) def test_add_snat_rule_ext(self): self.flags(routing_source_ip='10.10.10.1') expected = () self._test_add_snat_rule(expected, True) def test_add_snat_rule_snat_range_no_ext(self): self.flags(routing_source_ip='10.10.10.1', force_snat_range=['10.10.10.0/24']) expected = ('-s 10.0.0.0/24 -d 0.0.0.0/0 ' '-j SNAT --to-source 10.10.10.1 -o eth0') self._test_add_snat_rule(expected, False) def test_add_snat_rule_snat_range_ext(self): '-j SNAT --to-source 10.10.10.1') self._test_add_snat_rule(expected, True)"," def _test_add_snat_rule(self, expected): linux_net.add_snat_rule('10.0.0.0/24') def test_add_snat_rule(self): self._test_add_snat_rule(expected) def test_add_snat_rule_snat_range(self): '-j SNAT --to-source 10.10.10.1 -o eth0') self._test_add_snat_rule(expected)",46,19
openstack%2Fdesignate~master~Ie367b796b1a501d8a78e98d690a4b482dcabe8da,openstack/designate,master,Ie367b796b1a501d8a78e98d690a4b482dcabe8da,Remove the Priority Field in V2,MERGED,2014-07-22 18:34:23.000000000,2014-08-10 16:54:08.000000000,2014-08-10 16:54:08.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8130}]","[{'number': 1, 'created': '2014-07-22 18:34:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/5ed2e0bfbdef45ae1625a7aa8aa0f12ba83bd902', 'message': 'Remove the Priority Field in V2\n\nThe priority field is now the first item in the data field for\nMX and SRV records, instead of beng a separate field.\nV1 has not been changed and remains a separate\nfield.\n\nChange-Id: Ie367b796b1a501d8a78e98d690a4b482dcabe8da\nImplements: blueprint remove-priority-field\n'}, {'number': 2, 'created': '2014-07-23 18:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/f0fc97af1ce62aacce51758f425c9816c72fb2db', 'message': 'Remove the Priority Field in V2\n\nThe priority field is now the first item in the data field for\nMX and SRV records, instead of beng a separate field.\nV1 has not been changed and remains a separate\nfield.\n\nChange-Id: Ie367b796b1a501d8a78e98d690a4b482dcabe8da\nImplements: blueprint remove-priority-field\n'}, {'number': 3, 'created': '2014-07-23 20:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/6a9d474911b3ff3b2b218d0e486228f0f159e5ec', 'message': 'Remove the Priority Field in V2\n\nThe priority field is now the first item in the data field for\nMX and SRV records, instead of beng a separate field.\nV1 has not been changed and remains a separate\nfield.\n\nChange-Id: Ie367b796b1a501d8a78e98d690a4b482dcabe8da\nImplements: blueprint remove-priority-field\n'}, {'number': 4, 'created': '2014-07-24 20:31:08.000000000', 'files': ['designate/resources/schemas/v2/recordset.json', 'designate/api/v2/views/recordsets.py', 'designate/objects/recordset.py', 'designate/central/service.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/65a882cfbb91a3d61be9febd9df7b1fa78647a5c', 'message': 'Remove the Priority Field in V2\n\nThe priority field is now the first item in the data field for\nMX and SRV records, instead of beng a separate field.\nV1 has not been changed and remains a separate\nfield.\n\nChange-Id: Ie367b796b1a501d8a78e98d690a4b482dcabe8da\nImplements: blueprint remove-priority-field\n'}]",4,108797,65a882cfbb91a3d61be9febd9df7b1fa78647a5c,30,5,4,8130,,,0,"Remove the Priority Field in V2

The priority field is now the first item in the data field for
MX and SRV records, instead of beng a separate field.
V1 has not been changed and remains a separate
field.

Change-Id: Ie367b796b1a501d8a78e98d690a4b482dcabe8da
Implements: blueprint remove-priority-field
",git fetch https://review.opendev.org/openstack/designate refs/changes/97/108797/4 && git format-patch -1 --stdout FETCH_HEAD,"['designate/api/v2/views/recordsets.py', 'designate/central/service.py']",2,5ed2e0bfbdef45ae1625a7aa8aa0f12ba83bd902,bp/remove-priority-field," # Methods to handle priority def _get_priority(self, recordset): cnt = 0 for r in recordset.records: recordset.records[cnt].data = str(r.priority) + "" "" + r.data cnt += 1 LOG.debug(""The record is %s"" % r) return recordset def _set_priority(self, recordset): if recordset.records is not None: for r in recordset.records: head, sep, tail = r.data.partition("" "") if sep: r.priority = head r.data = tail return recordset # Extract the priority from the data if recordset.type == ""MX"" or recordset.type == ""SRV"": recordset = self._set_priority(recordset) # Get Recordset to get it in the correct format for priority new_recordset = self.get_recordset(context, created_recordset.domain_id, created_recordset.id) return new_recordset if recordset.type == ""SRV"" or recordset.type == ""MX"": recordset = self._get_priority(recordset) recordsets = self.storage.find_recordsets(context, criterion, marker, cnt = 0 for rs in recordsets: if rs.type == ""SRV"" or rs.type == ""MX"": recordsets[cnt] = self._get_priority(rs) cnt += 1 return recordsets recordset = self.storage.find_recordset(context, criterion) if recordset.type == ""SRV"" or recordset.type == ""MX"": recordset = self._get_priority(recordset) return recordset # Set the priority for MX and SRV records if recordset.type == ""MX"" or recordset.type == ""SRV"": recordset = self._set_priority(recordset) recordset = self.get_recordset(context, recordset.domain_id, recordset.id) "," return created_recordset return self.storage.find_recordsets(context, criterion, marker, return self.storage.find_recordset(context, criterion)",62,12
openstack%2Fopenstack-doc-tools~master~Ibbbb78c3c22eedd3f6e56ee60780c85777b0054d,openstack/openstack-doc-tools,master,Ibbbb78c3c22eedd3f6e56ee60780c85777b0054d,Print run time,MERGED,2014-08-08 07:51:43.000000000,2014-08-10 16:53:56.000000000,2014-08-10 16:53:56.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-08 07:51:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/7224ecb11e4d06d29980c1f1d760b36d6397f093', 'message': 'Print run time\n\nPrint how long the testing took.\n\nChange-Id: Ibbbb78c3c22eedd3f6e56ee60780c85777b0054d\n'}, {'number': 2, 'created': '2014-08-08 08:48:53.000000000', 'files': ['os_doc_tools/doctest.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/a70659f5641b456fb3f9f62d7fbf8702b37fef52', 'message': 'Print run time\n\nPrint how long the testing took.\n\nChange-Id: Ibbbb78c3c22eedd3f6e56ee60780c85777b0054d\n'}]",0,112782,a70659f5641b456fb3f9f62d7fbf8702b37fef52,16,3,2,6547,,,0,"Print run time

Print how long the testing took.

Change-Id: Ibbbb78c3c22eedd3f6e56ee60780c85777b0054d
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/82/112782/2 && git format-patch -1 --stdout FETCH_HEAD,['os_doc_tools/doctest.py'],1,7224ecb11e4d06d29980c1f1d760b36d6397f093,time-run,"import time start_time = time.clock() elapsed_time = (time.clock() - start_time) print (""Run time was: %.2f seconds."" % elapsed_time)",,4,0
openstack%2Fmonasca-api~master~I970888cd277dfc25dc93f04d8f4a6b6da4b639ba,openstack/monasca-api,master,I970888cd277dfc25dc93f04d8f4a6b6da4b639ba,Fix problems with capitalization in file names,MERGED,2014-08-10 16:37:12.000000000,2014-08-10 16:40:12.000000000,2014-08-10 16:40:12.000000000,"[{'_account_id': 3}, {'_account_id': 11809}]","[{'number': 1, 'created': '2014-08-10 16:37:12.000000000', 'files': ['src/test/java/com/hpcloud/mon/infrastructure/persistence/mysql/NotificationMethodMySqlRepositoryImplTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/mysql/AlarmMySQLRepositoryImplTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/mysql/NotificationMethodMySQLRepositoryImplTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/mysql/AlarmMySqlRepositoryImplTest.java'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/fee6cecc7d3c635d9645580f3d9e19a2f27a79f5', 'message': 'Fix problems with capitalization in file names\n\nChange-Id: I970888cd277dfc25dc93f04d8f4a6b6da4b639ba\n'}]",0,113139,fee6cecc7d3c635d9645580f3d9e19a2f27a79f5,7,2,1,11809,,,0,"Fix problems with capitalization in file names

Change-Id: I970888cd277dfc25dc93f04d8f4a6b6da4b639ba
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/39/113139/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/test/java/com/hpcloud/mon/infrastructure/persistence/mysql/NotificationMethodMySqlRepositoryImplTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/mysql/AlarmMySQLRepositoryImplTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/mysql/NotificationMethodMySQLRepositoryImplTest.java', 'src/test/java/com/hpcloud/mon/infrastructure/persistence/mysql/AlarmMySqlRepositoryImplTest.java']",4,fee6cecc7d3c635d9645580f3d9e19a2f27a79f5,fix_files,,"package com.hpcloud.mon.infrastructure.persistence.mysql; import static org.testng.Assert.assertEquals; import static org.testng.Assert.assertFalse; import static org.testng.Assert.assertNull; import static org.testng.Assert.assertTrue; import static org.testng.Assert.fail; import java.nio.charset.Charset; import java.util.ArrayList; import java.util.Arrays; import java.util.Collections; import java.util.List; import java.util.Map; import org.skife.jdbi.v2.DBI; import org.skife.jdbi.v2.Handle; import org.skife.jdbi.v2.util.StringMapper; import org.testng.annotations.AfterClass; import org.testng.annotations.BeforeClass; import org.testng.annotations.BeforeMethod; import org.testng.annotations.Test; import com.google.common.collect.ImmutableMap; import com.google.common.io.Resources; import com.hpcloud.mon.common.model.alarm.AggregateFunction; import com.hpcloud.mon.common.model.alarm.AlarmOperator; import com.hpcloud.mon.common.model.alarm.AlarmState; import com.hpcloud.mon.common.model.alarm.AlarmSubExpression; import com.hpcloud.mon.common.model.metric.MetricDefinition; import com.hpcloud.mon.domain.exception.EntityNotFoundException; import com.hpcloud.mon.domain.model.alarm.Alarm; import com.hpcloud.mon.domain.model.alarm.AlarmRepository; @Test public class AlarmMySqlRepositoryImplTest { private DBI db; private Handle handle; private AlarmRepository repo; private List<String> alarmActions; @BeforeClass protected void setupClass() throws Exception { db = new DBI(""jdbc:h2:mem:test;MODE=MySQL""); handle = db.open(); handle .execute(Resources.toString(getClass().getResource(""alarm.sql""), Charset.defaultCharset())); repo = new AlarmMySqlRepositoryImpl(db); alarmActions = new ArrayList<String>(); alarmActions.add(""29387234""); alarmActions.add(""77778687""); } @AfterClass protected void afterClass() { handle.close(); } @BeforeMethod protected void beforeMethod() { handle.execute(""SET foreign_key_checks = 0;""); handle.execute(""truncate table sub_alarm""); handle.execute(""truncate table alarm_action""); handle.execute(""truncate table sub_alarm_dimension""); handle.execute(""truncate table alarm""); handle .execute(""insert into alarm (id, tenant_id, name, severity, expression, state, actions_enabled, created_at, updated_at, deleted_at) "" + ""values ('123', 'bob', '90% CPU', 'LOW', 'avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=cpu, device=1}) > 10', 'UNDETERMINED', 1, NOW(), NOW(), NULL)""); handle .execute(""insert into sub_alarm (id, alarm_id, function, metric_name, operator, threshold, period, periods, state, created_at, updated_at) "" + ""values ('111', '123', 'avg', 'hpcs.compute', 'GT', 10, 60, 1, 'UNDETERMINED', NOW(), NOW())""); handle.execute(""insert into sub_alarm_dimension values ('111', 'flavor_id', '777')""); handle.execute(""insert into sub_alarm_dimension values ('111', 'image_id', '888')""); handle.execute(""insert into sub_alarm_dimension values ('111', 'metric_name', 'cpu')""); handle.execute(""insert into sub_alarm_dimension values ('111', 'device', '1')""); handle.execute(""insert into alarm_action values ('123', 'ALARM', '29387234')""); handle.execute(""insert into alarm_action values ('123', 'ALARM', '77778687')""); handle .execute(""insert into alarm (id, tenant_id, name, severity, expression, state, actions_enabled, created_at, updated_at, deleted_at) "" + ""values ('234', 'bob', '50% CPU', 'LOW', 'avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=mem}) > 20 and avg(hpcs.compute) < 100', 'UNDETERMINED', 1, NOW(), NOW(), NULL)""); handle .execute(""insert into sub_alarm (id, alarm_id, function, metric_name, operator, threshold, period, periods, state, created_at, updated_at) "" + ""values ('222', '234', 'avg', 'hpcs.compute', 'GT', 20, 60, 1, 'UNDETERMINED', NOW(), NOW())""); handle .execute(""insert into sub_alarm (id, alarm_id, function, metric_name, operator, threshold, period, periods, state, created_at, updated_at) "" + ""values ('223', '234', 'avg', 'hpcs.compute', 'LT', 100, 60, 1, 'UNDETERMINED', NOW(), NOW())""); handle.execute(""insert into sub_alarm_dimension values ('222', 'flavor_id', '777')""); handle.execute(""insert into sub_alarm_dimension values ('222', 'image_id', '888')""); handle.execute(""insert into sub_alarm_dimension values ('222', 'metric_name', 'mem')""); handle.execute(""insert into alarm_action values ('234', 'ALARM', '29387234')""); handle.execute(""insert into alarm_action values ('234', 'ALARM', '77778687')""); } public void shouldCreate() { Map<String, AlarmSubExpression> subExpressions = ImmutableMap .<String, AlarmSubExpression>builder() .put( ""4433"", AlarmSubExpression .of(""avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=cpu}) > 10"")) .build(); Alarm alarmA = repo.create(""555"", ""2345"", ""90% CPU"", null, ""LOW"", ""avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=cpu}) > 10"", subExpressions, alarmActions, null, null); Alarm alarmB = repo.findById(""555"", alarmA.getId()); assertEquals(alarmA, alarmB); // Assert that sub-alarm and sub-alarm-dimensions made it to the db assertEquals( handle.createQuery(""select count(*) from sub_alarm where id = 4433"") .map(StringMapper.FIRST).first(), ""1""); assertEquals( handle.createQuery(""select count(*) from sub_alarm_dimension where sub_alarm_id = 4433"") .map(StringMapper.FIRST).first(), ""3""); } @Test(groups = ""database"") public void shouldUpdate() { db = new DBI(""jdbc:mysql://192.168.10.4/mon"", ""monapi"", ""password""); handle = db.open(); repo = new AlarmMySqlRepositoryImpl(db); beforeMethod(); List<String> oldSubAlarmIds = Arrays.asList(""222""); AlarmSubExpression changedSubExpression = AlarmSubExpression.of(""avg(hpcs.compute) <= 200""); Map<String, AlarmSubExpression> changedSubExpressions = ImmutableMap.<String, AlarmSubExpression>builder().put(""223"", changedSubExpression).build(); AlarmSubExpression newSubExpression = AlarmSubExpression.of(""avg(foo{flavor_id=777}) > 333""); Map<String, AlarmSubExpression> newSubExpressions = ImmutableMap.<String, AlarmSubExpression>builder().put(""555"", newSubExpression).build(); repo.update(""bob"", ""234"", false, ""90% CPU"", null, ""avg(foo{flavor_id=777}) > 333 and avg(hpcs.compute) <= 200"", ""LOW"", AlarmState.ALARM, false, oldSubAlarmIds, changedSubExpressions, newSubExpressions, alarmActions, null, null); Alarm alarm = repo.findById(""bob"", ""234""); Alarm expected = new Alarm(""234"", ""90% CPU"", null, ""LOW"", ""avg(foo{flavor_id=777}) > 333 and avg(hpcs.compute) <= 200"", AlarmState.ALARM, false, alarmActions, Collections.<String>emptyList(), Collections.<String>emptyList()); assertEquals(expected, alarm); Map<String, AlarmSubExpression> subExpressions = repo.findSubExpressions(""234""); assertEquals(subExpressions.get(""223""), changedSubExpression); assertEquals(subExpressions.get(""555""), newSubExpression); } public void shouldFindById() { Alarm alarm = repo.findById(""bob"", ""123""); assertEquals(alarm.getId(), ""123""); assertEquals(alarm.getName(), ""90% CPU""); assertEquals(alarm.getSeverity(), ""LOW""); assertEquals(alarm.getExpression(), ""avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=cpu, device=1}) > 10""); assertEquals(alarm.getState(), AlarmState.UNDETERMINED); assertEquals(alarm.isActionsEnabled(), true); assertEquals(alarm.getAlarmActions(), alarmActions); } @Test(groups = ""database"") public void shouldFindSubAlarmMetricDefinitions() { db = new DBI(""jdbc:mysql://192.168.10.4/mon"", ""monapi"", ""password""); handle = db.open(); repo = new AlarmMySqlRepositoryImpl(db); beforeMethod(); assertEquals( repo.findSubAlarmMetricDefinitions(""123"").get(""111""), new MetricDefinition(""hpcs.compute"", ImmutableMap.<String, String>builder() .put(""flavor_id"", ""777"").put(""image_id"", ""888"").put(""metric_name"", ""cpu"") .put(""device"", ""1"").build())); assertEquals( repo.findSubAlarmMetricDefinitions(""234"").get(""222""), new MetricDefinition(""hpcs.compute"", ImmutableMap.<String, String>builder() .put(""flavor_id"", ""777"").put(""image_id"", ""888"").put(""metric_name"", ""mem"").build())); assertTrue(repo.findSubAlarmMetricDefinitions(""asdfasdf"").isEmpty()); } @Test(groups = ""database"") public void shouldFindSubExpressions() { db = new DBI(""jdbc:mysql://192.168.10.4/mon"", ""monapi"", ""password""); handle = db.open(); repo = new AlarmMySqlRepositoryImpl(db); beforeMethod(); assertEquals( repo.findSubExpressions(""123"").get(""111""), new AlarmSubExpression(AggregateFunction.AVG, new MetricDefinition(""hpcs.compute"", ImmutableMap.<String, String>builder().put(""flavor_id"", ""777"").put(""image_id"", ""888"") .put(""metric_name"", ""cpu"").put(""device"", ""1"").build()), AlarmOperator.GT, 10, 60, 1)); assertEquals(repo.findSubExpressions(""234"").get(""223""), new AlarmSubExpression( AggregateFunction.AVG, new MetricDefinition(""hpcs.compute"", null), AlarmOperator.LT, 100, 60, 1)); assertTrue(repo.findSubAlarmMetricDefinitions(""asdfasdf"").isEmpty()); } public void testExists() { assertTrue(repo.exists(""bob"", ""90% CPU"")); // Negative assertFalse(repo.exists(""bob"", ""999% CPU"")); } public void shouldFind() { List<Alarm> alarms = repo.find(""bob"", null, null, null); assertEquals( alarms, Arrays.asList( new Alarm(""123"", ""90% CPU"", null, ""LOW"", ""avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=cpu, device=1}) > 10"", AlarmState.UNDETERMINED, true, Arrays.asList(""29387234"", ""77778687""), Collections .<String>emptyList(), Collections.<String>emptyList()), new Alarm( ""234"", ""50% CPU"", null, ""LOW"", ""avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=mem}) > 20 and avg(hpcs.compute) < 100"", AlarmState.UNDETERMINED, true, Arrays.asList(""29387234"", ""77778687""), Collections .<String>emptyList(), Collections.<String>emptyList()))); } public void shouldFindByName() { List<Alarm> alarms = repo.find(""bob"", ""90% CPU"", null, null); assertEquals(alarms, Arrays.asList(new Alarm(""123"", ""90% CPU"", null, ""LOW"", ""avg(hpcs.compute{flavor_id=777, image_id=888, metric_name=cpu, device=1}) > 10"", AlarmState.UNDETERMINED, true, Arrays.asList(""29387234"", ""77778687""), Collections .<String>emptyList(), Collections.<String>emptyList()))); } public void shouldDeleteById() { repo.deleteById(""bob"", ""123""); try { assertNull(repo.findById(""bob"", ""123"")); fail(); } catch (EntityNotFoundException expected) { } } } ",28,350
openstack%2Fec2-api~master~Idbd33a99db908a190f3f86994ebea1e329b25f57,openstack/ec2-api,master,Idbd33a99db908a190f3f86994ebea1e329b25f57,Security groups unit tests,MERGED,2014-08-10 14:46:45.000000000,2014-08-10 16:12:40.000000000,2014-08-10 16:12:40.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-08-10 14:46:45.000000000', 'files': ['ec2api/tests/fakes.py', 'ec2api/exception.py', 'ec2api/api/security_group.py', 'ec2api/tests/test_security_group.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/e13ff1fd469facff77d96b64a84d7ba127ac5814', 'message': 'Security groups unit tests\n\nChange-Id: Idbd33a99db908a190f3f86994ebea1e329b25f57\n'}]",0,113135,e13ff1fd469facff77d96b64a84d7ba127ac5814,8,4,1,9312,,,0,"Security groups unit tests

Change-Id: Idbd33a99db908a190f3f86994ebea1e329b25f57
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/35/113135/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/tests/fakes.py', 'ec2api/api/security_group.py', 'ec2api/exception.py', 'ec2api/tests/test_security_group.py']",4,e13ff1fd469facff77d96b64a84d7ba127ac5814,,"# Copyright 2014 Cloudscaling Group, Inc # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import copy import mock from neutronclient.common import exceptions as neutron_exception from ec2api.tests import base from ec2api.tests import fakes from ec2api.tests import matchers from ec2api.tests import tools class SecurityGroupTestCase(base.ApiTestCase): def test_create_security_group(self): self.db_api.get_item_by_id.return_value = fakes.DB_VPC_1 self.db_api.add_item.return_value = fakes.DB_SECURITY_GROUP_1 self.neutron.create_security_group.return_value = { 'security_group': fakes.OS_SECURITY_GROUP_1} def check_response(resp, auto_ips=False): self.assertEqual(200, resp['status']) self.assertEqual(fakes.ID_EC2_SECURITY_GROUP_1, resp['groupId']) self.db_api.add_item.called_once_with( mock.ANY, 'security_group', tools.purge_dict(fakes.DB_SECURITY_GROUP_1, ('id',))) self.neutron.create_security_group.assert_called_once_with( {'security_group': {'name': 'groupname', 'description': 'Group description'}}) self.neutron.reset_mock() self.db_api.reset_mock() resp = self.execute( 'CreateSecurityGroup', {'VpcId': fakes.ID_EC2_VPC_1, 'GroupName': 'groupname', 'GroupDescription': 'Group description'}) check_response(resp) def test_create_security_group_rollback(self): self.db_api.get_item_by_id.return_value = fakes.DB_VPC_1 self.neutron.create_security_group.return_value = { 'security_group': fakes.OS_SECURITY_GROUP_1} self.db_api.add_item.side_effect = Exception() resp = self.execute( 'CreateSecurityGroup', {'VpcId': fakes.ID_EC2_VPC_1, 'GroupName': 'groupname', 'GroupDescription': 'Group description'}) self.neutron.delete_security_group.assert_called_once_with( fakes.ID_OS_SECURITY_GROUP_1) def test_delete_security_group(self): self.db_api.get_item_by_id.return_value = fakes.DB_SECURITY_GROUP_1 self.db_api.get_items.return_value = [] resp = self.execute( 'DeleteSecurityGroup', {'GroupId': fakes.ID_EC2_SECURITY_GROUP_1}) self.assertEqual(200, resp['status']) self.assertEqual(True, resp['return']) self.db_api.get_item_by_id.assert_has_call( mock.ANY, fakes.ID_DB_SECURITY_GROUP_1) self.db_api.delete_item.assert_called_once_with( mock.ANY, fakes.ID_DB_SECURITY_GROUP_1) self.neutron.delete_security_group.assert_called_once_with( fakes.ID_OS_SECURITY_GROUP_1) def test_delete_security_group_no_security_group(self): self.db_api.get_item_by_id.return_value = None resp = self.execute( 'DeleteSecurityGroup', {'GroupId': fakes.ID_EC2_SECURITY_GROUP_1}) self.assertEqual(400, resp['status']) self.assertEqual('InvalidSecurityGroupID.NotFound', resp['Error']['Code']) self.assertEqual(0, self.neutron.delete_port.call_count) def test_delete_security_group_is_in_use(self): self.db_api.get_item_by_id.return_value = fakes.DB_SECURITY_GROUP_1 self.neutron.delete_security_group.side_effect = ( neutron_exception.Conflict()) resp = self.execute( 'DeleteSecurityGroup', {'GroupId': fakes.ID_EC2_SECURITY_GROUP_1}) self.assertEqual(400, resp['status']) self.assertEqual('DependencyViolation', resp['Error']['Code']) self.assertEqual(0, self.db_api.delete_item.call_count) def test_describe_security_groups(self): self.db_api.get_items.return_value = [fakes.DB_SECURITY_GROUP_1, fakes.DB_SECURITY_GROUP_2] self.neutron.list_security_groups.return_value = ( {'security_groups': [fakes.OS_SECURITY_GROUP_1, fakes.OS_SECURITY_GROUP_2]}) resp = self.execute('DescribeSecurityGroups', {}) self.assertEqual(200, resp['status']) self.assertThat(resp['securityGroupInfo'], matchers.DictListMatches( [fakes.EC2_SECURITY_GROUP_1, fakes.EC2_SECURITY_GROUP_2])) def test_authorize_security_group_ingress_ip_ranges(self): self.db_api.get_item_by_id.side_effect = copy.deepcopy( fakes.get_db_api_get_item_by_id({ fakes.ID_DB_SECURITY_GROUP_1: fakes.DB_SECURITY_GROUP_1, fakes.ID_DB_SECURITY_GROUP_2: fakes.DB_SECURITY_GROUP_2})) self.neutron.create_security_group_rule.return_value = ( {'security_group_rule': [fakes.OS_SECURITY_GROUP_RULE_1]}) resp = self.execute( 'AuthorizeSecurityGroupIngress', {'GroupId': fakes.ID_EC2_SECURITY_GROUP_2, 'IpPermissions.1.FromPort': '10', 'IpPermissions.1.ToPort': '10', 'IpPermissions.1.IpProtocol': 'tcp', 'IpPermissions.1.IpRanges.1.CidrIp': '192.168.1.0/24'}) self.assertEqual(200, resp['status']) self.neutron.create_security_group_rule.assert_called_once_with( {'security_group_rule': tools.purge_dict(fakes.OS_SECURITY_GROUP_RULE_1, {'id', 'remote_group_id', 'tenant_id'})}) def test_authorize_security_group_egress_groups(self): self.db_api.get_item_by_id.side_effect = copy.deepcopy( fakes.get_db_api_get_item_by_id({ fakes.ID_DB_SECURITY_GROUP_1: fakes.DB_SECURITY_GROUP_1, fakes.ID_DB_SECURITY_GROUP_2: fakes.DB_SECURITY_GROUP_2})) self.neutron.create_security_group_rule.return_value = ( {'security_group_rule': [fakes.OS_SECURITY_GROUP_RULE_1]}) resp = self.execute( 'AuthorizeSecurityGroupEgress', {'GroupId': fakes.ID_EC2_SECURITY_GROUP_2, 'IpPermissions.1.FromPort': '10', 'IpPermissions.1.IpProtocol': '100', 'IpPermissions.1.Groups.1.GroupId': fakes.ID_EC2_SECURITY_GROUP_1}) self.assertEqual(200, resp['status']) self.neutron.create_security_group_rule.assert_called_once_with( {'security_group_rule': tools.purge_dict(fakes.OS_SECURITY_GROUP_RULE_2, {'id', 'remote_ip_prefix', 'tenant_id', 'port_range_max'})}) def test_revoke_security_group_ingress_ip_ranges(self): self.db_api.get_item_by_id.side_effect = copy.deepcopy( fakes.get_db_api_get_item_by_id({ fakes.ID_DB_SECURITY_GROUP_1: fakes.DB_SECURITY_GROUP_1, fakes.ID_DB_SECURITY_GROUP_2: fakes.DB_SECURITY_GROUP_2})) self.neutron.show_security_group.return_value = { 'security_group': fakes.OS_SECURITY_GROUP_2} self.neutron.delete_security_group_rule.return_value = True resp = self.execute( 'RevokeSecurityGroupIngress', {'GroupId': fakes.ID_EC2_SECURITY_GROUP_2, 'IpPermissions.1.FromPort': '10', 'IpPermissions.1.ToPort': '10', 'IpPermissions.1.IpProtocol': 'tcp', 'IpPermissions.1.IpRanges.1.CidrIp': '192.168.1.0/24'}) self.assertEqual(200, resp['status']) self.neutron.show_security_group.assert_called_once_with( fakes.ID_OS_SECURITY_GROUP_2) self.neutron.delete_security_group_rule.assert_called_once_with( fakes.OS_SECURITY_GROUP_RULE_1['id']) def test_revoke_security_group_egress_groups(self): self.db_api.get_item_by_id.side_effect = copy.deepcopy( fakes.get_db_api_get_item_by_id({ fakes.ID_DB_SECURITY_GROUP_1: fakes.DB_SECURITY_GROUP_1, fakes.ID_DB_SECURITY_GROUP_2: fakes.DB_SECURITY_GROUP_2})) self.neutron.show_security_group.return_value = { 'security_group': fakes.OS_SECURITY_GROUP_2} self.neutron.delete_security_group_rule.return_value = True resp = self.execute( 'RevokeSecurityGroupEgress', {'GroupId': fakes.ID_EC2_SECURITY_GROUP_2, 'IpPermissions.1.FromPort': '10', 'IpPermissions.1.IpProtocol': '100', 'IpPermissions.1.Groups.1.GroupId': fakes.ID_EC2_SECURITY_GROUP_1}) self.assertEqual(200, resp['status']) self.neutron.show_security_group.assert_called_once_with( fakes.ID_OS_SECURITY_GROUP_2) self.neutron.delete_security_group_rule.assert_called_once_with( fakes.OS_SECURITY_GROUP_RULE_2['id']) ",,355,17
openstack%2Ffreezer~master~Ic9fcca4b81b1ec0c78baeeef6be1d5e22355e551,openstack/freezer,master,Ic9fcca4b81b1ec0c78baeeef6be1d5e22355e551,Added --lvm-auto-snap guessing option,MERGED,2014-08-05 13:52:55.000000000,2014-08-10 16:10:39.000000000,2014-08-10 16:10:39.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 1999}, {'_account_id': 6780}, {'_account_id': 11151}, {'_account_id': 12211}, {'_account_id': 12629}]","[{'number': 1, 'created': '2014-08-05 13:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/61af5edb18b7eaffcdfb801992638e2eed32b7fe', 'message': 'Added --lvm-auto-snap guessing option\n\nThe lvm group and volume name now can be\nguessed automatically using the --lvm-auto-snap\noption. The corresponding blueprint is available:\n\n- https://blueprints.launchpad.net/freezer/+spec/lvm-snap-auto\n\nAlso several pep8 style improvements are implemented.\n\nChange-Id: Ic9fcca4b81b1ec0c78baeeef6be1d5e22355e551\n'}, {'number': 2, 'created': '2014-08-05 16:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/7aa772bd886aa017c331a21f4892bea0e771adb5', 'message': 'Added --lvm-auto-snap guessing option\n\nThe lvm group and volume name now can be\nguessed automatically using the --lvm-auto-snap\noption. The corresponding blueprint is available:\n\n- https://blueprints.launchpad.net/freezer/+spec/lvm-snap-auto\n\nAlso several pep8 style improvements are implemented.\n\nChange-Id: Ic9fcca4b81b1ec0c78baeeef6be1d5e22355e551\n'}, {'number': 3, 'created': '2014-08-07 21:27:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/ba77f0efa3fb39e0133226b6c24ff2475682b840', 'message': 'Added --lvm-auto-snap guessing option\n\nThe lvm group and volume name now can be\nguessed automatically using the --lvm-auto-snap\noption. The corresponding blueprint is available:\n\n- https://blueprints.launchpad.net/freezer/+spec/lvm-snap-auto\n\nAlso several pep8 style improvements are implemented.\n\nChange-Id: Ic9fcca4b81b1ec0c78baeeef6be1d5e22355e551\n'}, {'number': 4, 'created': '2014-08-08 19:21:13.000000000', 'files': ['MANIFEST', 'freezer/swift.py', 'freezer/arguments.py', 'freezer/utils.py', 'freezer/backup.py', 'freezer/tar.py', 'freezer/lvm.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/a4dc71013586a6861733c198d758d3da41ad07f7', 'message': 'Added --lvm-auto-snap guessing option\n\nThe lvm group and volume name now can be\nguessed automatically using the --lvm-auto-snap\noption. The corresponding blueprint is available:\n\n- https://blueprints.launchpad.net/freezer/+spec/lvm-snap-auto\n\nAlso several pep8 style improvements are implemented.\n\nChange-Id: Ic9fcca4b81b1ec0c78baeeef6be1d5e22355e551\n'}]",3,112024,a4dc71013586a6861733c198d758d3da41ad07f7,29,7,4,11151,,,0,"Added --lvm-auto-snap guessing option

The lvm group and volume name now can be
guessed automatically using the --lvm-auto-snap
option. The corresponding blueprint is available:

- https://blueprints.launchpad.net/freezer/+spec/lvm-snap-auto

Also several pep8 style improvements are implemented.

Change-Id: Ic9fcca4b81b1ec0c78baeeef6be1d5e22355e551
",git fetch https://review.opendev.org/openstack/freezer refs/changes/24/112024/3 && git format-patch -1 --stdout FETCH_HEAD,"['MANIFEST', 'freezer/swift.py', 'freezer/arguments.py', 'freezer/utils.py', 'freezer/backup.py', 'freezer/tar.py', 'freezer/lvm.py']",7,61af5edb18b7eaffcdfb801992638e2eed32b7fe,bp/is,""""""""""""" create_dir, get_vol_fs_type, validate_all_args, get_mount_from_path) """""" """""" """""" """""" """""" """""" def get_lvm_info(backup_opt_dict): """""" Take a file system path as argument as backup_opt_dict.src_file and return a dictionary containing dictionary['lvm_srcvol'] and dictionary['lvm_volgroup'] where the path is mounted on. :param backup_opt_dict: backup_opt_dict.src_file, the file system path :returns: the dictionary backup_opt_dict containing keys lvm_srcvol and lvm_volgroup with respective values """""" mount_point_path = get_mount_from_path(backup_opt_dict.src_file) with open('/proc/mounts', 'r') as mount_fd: mount_points = mount_fd.readlines() vol_group_name = vol_name = False for mount_line in mount_points: device, mount_path = mount_line.split(' ')[0:2] if mount_point_path.strip() == mount_path.strip(): mount_match = re.search( r'/dev/mapper/(\w.+?\w)-(\w.+?\w)$', device) if mount_match: backup_opt_dict.__dict__['lvm_volgroup'] = \ mount_match.group(1).replace('--', '-') lvm_srcvol = mount_match.group(2).replace('--', '-') backup_opt_dict.__dict__['lvm_srcvol'] = u'/dev/{0}/{1}'.format( backup_opt_dict.lvm_volgroup, lvm_srcvol) break return backup_opt_dict","'''''' create_dir, get_vol_fs_type, validate_all_args) ''' ''' ''' ''' ''' '''",144,92
openstack%2Frally~master~I8f4cf3e2e8a0392612a0d0828a9c3bd6ab3da90f,openstack/rally,master,I8f4cf3e2e8a0392612a0d0828a9c3bd6ab3da90f,Modify config semantic validation of benchmark engine,MERGED,2014-08-08 17:45:33.000000000,2014-08-10 15:43:15.000000000,2014-08-10 15:43:15.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 9545}, {'_account_id': 9556}]","[{'number': 1, 'created': '2014-08-08 17:45:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/01cc5bf044bd69867bb7474c8ad6f45384b4ad33', 'message': 'Modify config semantic validation of benchmark engine\n\nPass to validation the full kwargs instead of extracting specific parts\n(ex. args) of it.\n\nChange-Id: I8f4cf3e2e8a0392612a0d0828a9c3bd6ab3da90f\n'}, {'number': 2, 'created': '2014-08-09 13:34:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bceaafc59ebf42707859d5cb7feb07b65dbcaac8', 'message': 'Modify config semantic validation of benchmark engine\n\nPass to validation the full kwargs instead of extracting specific parts\n(ex. args) of it.\n\nChange-Id: I8f4cf3e2e8a0392612a0d0828a9c3bd6ab3da90f\n'}, {'number': 3, 'created': '2014-08-09 14:12:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d0a6dc6db9dc4e25a4b0c3d2c60a2b4d591cbadc', 'message': 'Modify config semantic validation of benchmark engine\n\nPass to validation the full kwargs instead of extracting specific parts\n(ex. args) of it.\n\nChange-Id: I8f4cf3e2e8a0392612a0d0828a9c3bd6ab3da90f\n'}, {'number': 4, 'created': '2014-08-09 18:46:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/57f72474cbaf88d83da3ccfbca58d75a2a76db2f', 'message': 'Modify config semantic validation of benchmark engine\n\nPass to validation the full benchmark configuration instead of\nextracting parts of it (ex. only args).\n\nChange-Id: I8f4cf3e2e8a0392612a0d0828a9c3bd6ab3da90f\n'}, {'number': 5, 'created': '2014-08-09 19:21:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b7e1b09a05562e2747f726b5d6d57412125b3f6c', 'message': 'Modify config semantic validation of benchmark engine\n\nPass to validation the full benchmark configuration instead of\nextracting parts of it (ex. passing only args).\n\nChange-Id: I8f4cf3e2e8a0392612a0d0828a9c3bd6ab3da90f\n'}, {'number': 6, 'created': '2014-08-09 20:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/efa1077a11d36ef2bfabc845a319394e60297aca', 'message': 'Modify config semantic validation of benchmark engine\n\nPass to validation the full benchmark configuration instead of\nextracting parts of it (ex. passing only args).\n\nChange-Id: I8f4cf3e2e8a0392612a0d0828a9c3bd6ab3da90f\n'}, {'number': 7, 'created': '2014-08-09 22:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/aa7767b2b25aab98bfadea2342d3ec62f8475323', 'message': 'Modify config semantic validation of benchmark engine\n\nPass to validation the full benchmark configuration instead of\nextracting parts of it (ex. passing only args).\n\nChange-Id: I8f4cf3e2e8a0392612a0d0828a9c3bd6ab3da90f\n'}, {'number': 8, 'created': '2014-08-09 23:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1440d785079e33f717f181056587ace9d6a8d0b3', 'message': 'Modify config semantic validation of benchmark engine\n\nPass to validation the full benchmark configuration instead of\nextracting parts of it (ex. passing only args).\n\nChange-Id: I8f4cf3e2e8a0392612a0d0828a9c3bd6ab3da90f\n'}, {'number': 9, 'created': '2014-08-09 23:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/75d14946830f06fc7d30838f06917749858bb5ef', 'message': 'Modify config semantic validation of benchmark engine\n\nPass to validation the full benchmark configuration instead of\nextracting parts of it (ex. passing only args).\n\nChange-Id: I8f4cf3e2e8a0392612a0d0828a9c3bd6ab3da90f\n'}, {'number': 10, 'created': '2014-08-10 00:03:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9f60385d3e7f3cb64cdebcff079b328a37943df5', 'message': 'Modify config semantic validation of benchmark engine\n\nPass to validation the full benchmark configuration instead of\nextracting parts of it (ex. passing only args).\n\nChange-Id: I8f4cf3e2e8a0392612a0d0828a9c3bd6ab3da90f\n'}, {'number': 11, 'created': '2014-08-10 12:49:21.000000000', 'files': ['rally/benchmark/validation.py', 'rally/exceptions.py', 'tests/benchmark/scenarios/test_base.py', 'tests/benchmark/test_engine.py', 'rally/benchmark/scenarios/base.py', 'tests/benchmark/test_validation.py', 'rally/benchmark/engine.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/54dbf08b86730adafb5f3f7c0ce148f5556419d9', 'message': 'Modify config semantic validation of benchmark engine\n\nPass to validation the full benchmark configuration instead of\nextracting parts of it (ex. passing only args).\n\nChange-Id: I8f4cf3e2e8a0392612a0d0828a9c3bd6ab3da90f\n'}]",9,112981,54dbf08b86730adafb5f3f7c0ce148f5556419d9,50,4,11,9556,,,0,"Modify config semantic validation of benchmark engine

Pass to validation the full benchmark configuration instead of
extracting parts of it (ex. passing only args).

Change-Id: I8f4cf3e2e8a0392612a0d0828a9c3bd6ab3da90f
",git fetch https://review.opendev.org/openstack/rally refs/changes/81/112981/9 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/validation.py', 'rally/benchmark/scenarios/base.py', 'rally/benchmark/engine.py']",3,01cc5bf044bd69867bb7474c8ad6f45384b4ad33,modify-benchmark-engine," base_scenario.Scenario.validate(name, kwargs, admin=admin,"," base_scenario.Scenario.validate(name, args, admin=admin,",16,16
openstack%2Freviewstats~master~I10f48237d15e2a31b1546ded0a6bf5d8479c2231,openstack/reviewstats,master,I10f48237d15e2a31b1546ded0a6bf5d8479c2231,Add --server param to reviewers,MERGED,2014-07-30 10:15:43.000000000,2014-08-10 14:52:59.000000000,2014-08-10 14:52:59.000000000,"[{'_account_id': 3}, {'_account_id': 1561}]","[{'number': 1, 'created': '2014-07-30 10:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/59623421b470a615ad9f2e39dd074d187e9df65a', 'message': 'Add --server param to reviewers\n\nAdd --server param to reviewers to make it consistent with the\nopenreviews command.\n\nChange-Id: I10f48237d15e2a31b1546ded0a6bf5d8479c2231\n'}, {'number': 2, 'created': '2014-07-30 10:22:56.000000000', 'files': ['reviewstats/cmd/reviewers.py'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/8f76f6455122b993d791b8e2e6a4b15d962a88af', 'message': 'Add --server param to reviewers\n\nAdd --server param to reviewers to make it consistent with the\nopenreviews command.\n\nChange-Id: I10f48237d15e2a31b1546ded0a6bf5d8479c2231\n'}]",0,110587,8f76f6455122b993d791b8e2e6a4b15d962a88af,17,2,2,1390,,,0,"Add --server param to reviewers

Add --server param to reviewers to make it consistent with the
openreviews command.

Change-Id: I10f48237d15e2a31b1546ded0a6bf5d8479c2231
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/87/110587/1 && git format-patch -1 --stdout FETCH_HEAD,['reviewstats/cmd/reviewers.py'],1,59623421b470a615ad9f2e39dd074d187e9df65a,110587," optparser.add_option( '--server', default='review.openstack.org', help='Gerrit server to connect to') stable=options.stable, server=options.server)", stable=options.stable),4,1
openstack%2Fnova~master~I33c33e3ac1180e8293d950d60fb126e325a2c0cf,openstack/nova,master,I33c33e3ac1180e8293d950d60fb126e325a2c0cf,"Do not fail cell's instance deletion, if it's missing info_cache",MERGED,2014-05-16 05:54:09.000000000,2014-08-10 13:22:32.000000000,2014-08-10 13:22:29.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 67}, {'_account_id': 1011}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 7730}, {'_account_id': 8430}, {'_account_id': 8802}, {'_account_id': 9008}, {'_account_id': 9545}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10663}, {'_account_id': 12287}]","[{'number': 1, 'created': '2014-05-16 05:54:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cb71669913bf66c056e73dfbbcf3bc3ddca032d0', 'message': ""Do not fail cell's instance deletion, if it's missing info_cache\n\nCurrently the methods in cell messaging are trying to refresh the\ninstance. However, in some corner cases info_case is not being\ncreated for instances in ERROR state. This makes the delete\noperation, of such instances, to fail, while it should not.\n\nHandling the InstanceInfoCacheNotFound exception and not\nreraisng it, for delete operations.\n\nCloses-Bug: #1316373\nChange-Id: I33c33e3ac1180e8293d950d60fb126e325a2c0cf\n""}, {'number': 2, 'created': '2014-07-02 01:51:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a1f88678b364cdb7b3fc40629aaa6c279f297d31', 'message': ""Do not fail cell's instance deletion, if it's missing info_cache\n\nCurrently the methods in cell messaging are trying to refresh the\ninstance. However, in some corner cases info_case is not being\ncreated for instances in ERROR state. This makes the delete\noperation, of such instances, to fail, while it should not.\n\nHandling the InstanceInfoCacheNotFound exception and not\nreraisng it, for delete operations.\n\nCloses-Bug: #1316373\nChange-Id: I33c33e3ac1180e8293d950d60fb126e325a2c0cf\n""}, {'number': 3, 'created': '2014-07-08 13:44:28.000000000', 'files': ['nova/tests/cells/test_cells_messaging.py', 'nova/cells/messaging.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/47898ba8f9526c88a03209dbc35a59d90b79e809', 'message': ""Do not fail cell's instance deletion, if it's missing info_cache\n\nCurrently the methods in cell messaging are trying to refresh the\ninstance. However, in some corner cases info_cache is not being\ncreated for instances in ERROR state. This makes the delete\noperation, of such instances, to fail, while it should not.\n\nHandling the InstanceInfoCacheNotFound exception and not\nre-raising it, for delete operations.\n\nCloses-Bug: #1316373\nChange-Id: I33c33e3ac1180e8293d950d60fb126e325a2c0cf\n""}]",10,93860,47898ba8f9526c88a03209dbc35a59d90b79e809,72,20,3,8802,,,0,"Do not fail cell's instance deletion, if it's missing info_cache

Currently the methods in cell messaging are trying to refresh the
instance. However, in some corner cases info_cache is not being
created for instances in ERROR state. This makes the delete
operation, of such instances, to fail, while it should not.

Handling the InstanceInfoCacheNotFound exception and not
re-raising it, for delete operations.

Closes-Bug: #1316373
Change-Id: I33c33e3ac1180e8293d950d60fb126e325a2c0cf
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/93860/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/cells/test_cells_messaging.py', 'nova/cells/messaging.py']",2,cb71669913bf66c056e73dfbbcf3bc3ddca032d0,bug/1316373, except exception.InstanceInfoCacheNotFound: with excutils.save_and_reraise_exception() as error: if method == 'delete': error.reraise = False ,,32,0
openstack%2Ftraining-guides~master~I824c5571410411f2f17671657c90d463c2846ee2,openstack/training-guides,master,I824c5571410411f2f17671657c90d463c2846ee2,Adds horizon scripts for training labs,MERGED,2014-08-10 08:08:51.000000000,2014-08-10 11:50:32.000000000,2014-08-10 11:50:32.000000000,"[{'_account_id': 3}, {'_account_id': 11109}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-08-10 08:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/d3fb710cadf4391dbce7cf6111ada67d118d82e7', 'message': 'Adds horizon scripts for training labs\n\nAdds horizon scripts for training labs which will install openstack\n dashboard service.\n\nChange-Id: I824c5571410411f2f17671657c90d463c2846ee2\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}, {'number': 2, 'created': '2014-08-10 08:11:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/ea0b403ef698b01962b1035db81346bc8f050f23', 'message': 'Adds horizon scripts for training labs\n\nAdds horizon scripts for training labs which will install openstack\ndashboard service.\n\nChange-Id: I824c5571410411f2f17671657c90d463c2846ee2\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}, {'number': 3, 'created': '2014-08-10 11:03:00.000000000', 'files': ['labs/scripts/setup_horizon.sh', 'labs/config/scripts.controller'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/5a32910539a72ed74e21e3b7fbbf4cb60b287d5b', 'message': 'Adds horizon scripts for training labs\n\nAdds horizon scripts for training labs which will install\nOpenStack dashboard.\n\nChange-Id: I824c5571410411f2f17671657c90d463c2846ee2\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}]",0,113121,5a32910539a72ed74e21e3b7fbbf4cb60b287d5b,14,3,3,7007,,,0,"Adds horizon scripts for training labs

Adds horizon scripts for training labs which will install
OpenStack dashboard.

Change-Id: I824c5571410411f2f17671657c90d463c2846ee2
Partial-Bug: 1312764
Implements: blueprint openstack-training-labs
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/21/113121/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/scripts/setup_horizon.sh'],1,d3fb710cadf4391dbce7cf6111ada67d118d82e7,bug/1312764,"#!/usr/bin/env bash TOP_DIR=$(cd $(dirname ""$0"")/.. && pwd) source ""$TOP_DIR/config/paths"" source ""$CONFIG_DIR/credentials"" source ""$LIB_DIR/functions.guest"" source ""$CONFIG_DIR/labs-openstackrc.sh"" exec_logfile indicate_current_auto #------------------------------------------------------------------------------ # Set up OpenStack Dashboard (horizon). #------------------------------------------------------------------------------ echo ""Installing horizon."" sudo apt-get install -y openstack-dashboard memcached echo ""Purge ubuntu theme."" dpkg --purge openstack-dashboard-ubuntu-theme echo ""Reload apache and memcached service"" sudo service apache2 restart; sudo service memcached restart; ",,24,0
openstack%2Fhorizon~master~I3418a217bab540bb6f1e6504167411f60d6c2fab,openstack/horizon,master,I3418a217bab540bb6f1e6504167411f60d6c2fab,Enable images metadata update,ABANDONED,2014-07-30 11:47:14.000000000,2014-08-10 10:53:40.000000000,,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 10247}, {'_account_id': 12231}]","[{'number': 1, 'created': '2014-07-30 11:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f041443c0909a256eb16a0c01875d40b183d76e2', 'message': 'Enable images metadata update\n\nGlance currently expose an api to let the users update\nthe images properties and at the same time they are exposing\na metadata dictionary in Juno, where users can register\nthe key/value pairs that describe their cloud deployment\n\nThis patch uses the glance metadata api to expose the available\nmetadata and the glance api to update the images properties\n\nChange-Id: I3418a217bab540bb6f1e6504167411f60d6c2fab\nImplements: blueprint glance-metadata-images\n'}, {'number': 2, 'created': '2014-08-06 17:52:30.000000000', 'files': ['openstack_dashboard/dashboards/admin/images/templates/images/_edit_capabilities.html', 'openstack_dashboard/dashboards/admin/images/urls.py', 'openstack_dashboard/dashboards/admin/images/tables.py', 'openstack_dashboard/dashboards/admin/images/views.py', 'openstack_dashboard/dashboards/admin/images/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/51687bc0c207f9a057a6d5c17cb3783f28ebddde', 'message': 'Enable images metadata update\n\nGlance currently expose an api to let the users update\nthe images properties and at the same time they are exposing\na metadata dictionary in Juno, where users can register\nthe key/value pairs that describe their cloud deployment\n\nThis patch uses the glance metadata api to expose the available\nmetadata and the glance api to update the images properties\n\nChange-Id: I3418a217bab540bb6f1e6504167411f60d6c2fab\nImplements: blueprint glance-metadata-images\n'}]",0,110619,51687bc0c207f9a057a6d5c17cb3783f28ebddde,10,4,2,10247,,,0,"Enable images metadata update

Glance currently expose an api to let the users update
the images properties and at the same time they are exposing
a metadata dictionary in Juno, where users can register
the key/value pairs that describe their cloud deployment

This patch uses the glance metadata api to expose the available
metadata and the glance api to update the images properties

Change-Id: I3418a217bab540bb6f1e6504167411f60d6c2fab
Implements: blueprint glance-metadata-images
",git fetch https://review.opendev.org/openstack/horizon refs/changes/19/110619/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/images/templates/images/_edit_capabilities.html', 'openstack_dashboard/dashboards/admin/images/urls.py', 'openstack_dashboard/dashboards/admin/images/tables.py', 'openstack_dashboard/dashboards/admin/images/views.py', 'openstack_dashboard/dashboards/admin/images/forms.py']",5,f041443c0909a256eb16a0c01875d40b183d76e2,bp/tagging,"from openstack_dashboard.dashboards.project.images.images import forms as images_forms import json from django.utils.translation import ugettext_lazy as _ from horizon import exceptions from horizon import forms from horizon import messages from openstack_dashboard import api class AdminCreateImageForm(images_forms.CreateImageForm):class AdminUpdateImageForm(images_forms.UpdateImageForm): class EditCapabilitiesForm(forms.SelfHandlingForm): def __init__(self, request, *args, **kwargs): super(EditCapabilitiesForm, self).__init__(request, *args, **kwargs) def handle(self, request, data): id = self.initial['id'] old_metadata = self.initial['metadata'] try: new_metadata = json.loads(self.data['metadata']) metadata = {} for item in new_metadata: metadata[item['key']] = str(item['value']) remove_props = [] for key in old_metadata: if key not in metadata: remove_props.append(key) api.glance.image_update_properties(request, id, remove_props, **metadata) message = _('Metadata successfully updated') messages.success(request, message) except Exception: exceptions.handle(request, _('Unable to update the image metadata.')) return False return True",from openstack_dashboard.dashboards.project.images.images import forms class AdminCreateImageForm(forms.CreateImageForm):class AdminUpdateImageForm(forms.UpdateImageForm):,109,12
openstack%2Ftraining-guides~master~I1f5f6d5aa3842da8fa94bd1a10a753bb80db023b,openstack/training-guides,master,I1f5f6d5aa3842da8fa94bd1a10a753bb80db023b,labs: make use of snapshot functionality,MERGED,2014-08-09 15:58:44.000000000,2014-08-10 09:10:00.000000000,2014-08-10 09:10:00.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2014-08-09 15:58:44.000000000', 'files': ['labs/config/scripts.controller', 'labs/config/scripts.nodeinit_osbash', 'labs/lib/osbash/virtualbox.install_node', 'labs/config/scripts.compute', 'labs/config/scripts.network'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/6372b4e5e03fcd42d4ca8b99cd3d76674b183e6a', 'message': 'labs: make use of snapshot functionality\n\nThis changeset pushes some of the code from virtualbox.install_node\nto the configuration files.\n\nIn doing so, the patch demonstrates how additional snapshots can be\nconfigured just by editing config/scripts.*.\n\nImplements: blueprint openstack-training-labs\nChange-Id: I1f5f6d5aa3842da8fa94bd1a10a753bb80db023b\n'}]",0,113094,6372b4e5e03fcd42d4ca8b99cd3d76674b183e6a,12,3,1,11109,,,0,"labs: make use of snapshot functionality

This changeset pushes some of the code from virtualbox.install_node
to the configuration files.

In doing so, the patch demonstrates how additional snapshots can be
configured just by editing config/scripts.*.

Implements: blueprint openstack-training-labs
Change-Id: I1f5f6d5aa3842da8fa94bd1a10a753bb80db023b
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/94/113094/1 && git format-patch -1 --stdout FETCH_HEAD,"['labs/config/scripts.controller', 'labs/config/scripts.nodeinit_osbash', 'labs/lib/osbash/virtualbox.install_node', 'labs/config/scripts.compute', 'labs/config/scripts.network']",5,6372b4e5e03fcd42d4ca8b99cd3d76674b183e6a,bp/openstack-training-labs,"scripts shutdown.sh boot snapshot ""pre-installed""",,11,5
openstack%2Ftraining-guides~master~I74faae2cb302b0faf5865df2922fb00e8a51936e,openstack/training-guides,master,I74faae2cb302b0faf5865df2922fb00e8a51936e,"labs: remove autostart scripts for ssh execution, too",MERGED,2014-08-09 07:08:47.000000000,2014-08-10 08:54:37.000000000,2014-08-10 08:54:36.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-08-09 07:08:47.000000000', 'files': ['labs/lib/osbash/functions.host'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/356976e6fe54c0ebebb208b29cc9a2fceb0861ba', 'message': 'labs: remove autostart scripts for ssh execution, too\n\nScripts are copied to the autostart directory before they are executed.\nAfter a script has been executed by osbash through an ssh connection, it\nis not removed from that directory, but it should be.\n\nIf a VM has both methods enabled (ssh and osbashauto via shared), this\nmight result in scripts being executed twice.\n\nWith this patch, scripts are removed from the autostart directory after\nexecution, both in the VM and on the host.\n\nImplements: blueprint openstack-training-labs\nChange-Id: I74faae2cb302b0faf5865df2922fb00e8a51936e\n'}]",0,113079,356976e6fe54c0ebebb208b29cc9a2fceb0861ba,13,4,1,11109,,,0,"labs: remove autostart scripts for ssh execution, too

Scripts are copied to the autostart directory before they are executed.
After a script has been executed by osbash through an ssh connection, it
is not removed from that directory, but it should be.

If a VM has both methods enabled (ssh and osbashauto via shared), this
might result in scripts being executed twice.

With this patch, scripts are removed from the autostart directory after
execution, both in the VM and on the host.

Implements: blueprint openstack-training-labs
Change-Id: I74faae2cb302b0faf5865df2922fb00e8a51936e
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/79/113079/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/lib/osbash/functions.host'],1,356976e6fe54c0ebebb208b29cc9a2fceb0861ba,bp/openstack-training-labs," vm_ssh ""$SSH_PORT"" ""bash $REMOTE_PATH && rm -vf $REMOTE_PATH"" > ""$LOG_PATH"" 2>&1 rm -vf ""$SCRIPT_PATH"" >&2"," vm_ssh ""$SSH_PORT"" ""bash $REMOTE_PATH"" > ""$LOG_PATH"" 2>&1",2,1
openstack%2Ftraining-guides~master~I2213125715e4cdf4cd2b4f501f3c216e2474b465,openstack/training-guides,master,I2213125715e4cdf4cd2b4f501f3c216e2474b465,labs: add snapshot/boot commands to config/scripts.* handler,MERGED,2014-08-09 15:49:56.000000000,2014-08-10 08:53:20.000000000,2014-08-10 08:53:20.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2014-08-09 15:49:56.000000000', 'files': ['labs/lib/osbash/virtualbox.functions', 'labs/scripts/vagrant/run_scripts.sh', 'labs/lib/osbash/functions.host', 'labs/lib/functions'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/06fe3a3e84d80be5576329cb5b7905989b4e8781', 'message': 'labs: add snapshot/boot commands to config/scripts.* handler\n\nThis patch adds the ability for osbash to understand boot and\nsnapshot commands in config/scripts.* files.\n\nThe syntax for running scripts within the VM remains:\n\n<dircode> <script_name>\n\nFor the new commands, it is:\nboot\nsnapshot ""Description for snapshot""\n\nThe Vagrant-side of the code will simply ignore these commands.\n\nget_script_paths_from_config has been removed and merged into the\nexecution routine for osbash and Vagrant, respectively.\n\nThis changeset puts only the functionality in place. It is going to be\nused by a subsequent patch.\n\nImplements: blueprint openstack-training-labs\nChange-Id: I2213125715e4cdf4cd2b4f501f3c216e2474b465\n'}]",0,113092,06fe3a3e84d80be5576329cb5b7905989b4e8781,12,3,1,11109,,,0,"labs: add snapshot/boot commands to config/scripts.* handler

This patch adds the ability for osbash to understand boot and
snapshot commands in config/scripts.* files.

The syntax for running scripts within the VM remains:

<dircode> <script_name>

For the new commands, it is:
boot
snapshot ""Description for snapshot""

The Vagrant-side of the code will simply ignore these commands.

get_script_paths_from_config has been removed and merged into the
execution routine for osbash and Vagrant, respectively.

This changeset puts only the functionality in place. It is going to be
used by a subsequent patch.

Implements: blueprint openstack-training-labs
Change-Id: I2213125715e4cdf4cd2b4f501f3c216e2474b465
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/92/113092/1 && git format-patch -1 --stdout FETCH_HEAD,"['labs/lib/osbash/virtualbox.functions', 'labs/scripts/vagrant/run_scripts.sh', 'labs/lib/osbash/functions.host', 'labs/lib/functions']",4,06fe3a3e84d80be5576329cb5b7905989b4e8781,bp/openstack-training-labs,,"# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - # Returns list of enabled scripts (to disable, comment out with #) function get_script_paths_from_config { local CONFIG_FILE=$1 local CONFIG_PATH=$CONFIG_DIR/$CONFIG_FILE if [ ! -f ""$CONFIG_PATH"" ]; then echo >&2 ""Config file not found: $CONFIG_FILE"" return 1 fi local DIR_CODE="""" local NAME="""" while read -r DIR_CODE NAME; do if [[ $DIR_CODE =~ ^# ]]; then # Skip lines that are commented out continue else local DIR=""$(src_dir_code_to_dir ""$DIR_CODE"")"" local SCR_PATH=$DIR/$NAME echo ""$SCR_PATH"" fi done < ""$CONFIG_PATH"" }",58,40
openstack%2Fneutron~master~I01788d376c64f32aaa971fbd17dd9435e29de3ac,openstack/neutron,master,I01788d376c64f32aaa971fbd17dd9435e29de3ac,TLS implementation,ABANDONED,2014-06-26 14:02:12.000000000,2014-08-10 08:49:19.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 7398}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9885}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10980}, {'_account_id': 11685}]","[{'number': 1, 'created': '2014-06-26 14:02:12.000000000', 'files': ['neutron/db/loadbalancer/loadbalancer_db.py', 'neutron/db/migration/alembic_migrations/versions/6815e9450v77_tls_extension.py', 'neutron/plugins/common/constants.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/tests/unit/db/loadbalancer/test_db_lbaas_tls.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/services/loadbalancer/plugin.py', 'neutron/db/loadbalancer/lbaas_tls_db.py', 'neutron/extensions/lbaas_tls.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/38786baca828fb2c8d3fe0453b2623f86fe69309', 'message': 'TLS implementation\n\nThis is WIP\nIncluding extension and db model implementation\nIncluding db model unit testing\n\nChange-Id: I01788d376c64f32aaa971fbd17dd9435e29de3ac\nImplements: blueprint lbaas-ssl-termination\n'}]",3,102837,38786baca828fb2c8d3fe0453b2623f86fe69309,18,16,1,8446,,,0,"TLS implementation

This is WIP
Including extension and db model implementation
Including db model unit testing

Change-Id: I01788d376c64f32aaa971fbd17dd9435e29de3ac
Implements: blueprint lbaas-ssl-termination
",git fetch https://review.opendev.org/openstack/neutron refs/changes/37/102837/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/loadbalancer/loadbalancer_db.py', 'neutron/db/migration/alembic_migrations/versions/6815e9450v77_tls_extension.py', 'neutron/plugins/common/constants.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/tests/unit/db/loadbalancer/test_db_lbaas_tls.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/services/loadbalancer/plugin.py', 'neutron/db/loadbalancer/lbaas_tls_db.py', 'neutron/extensions/lbaas_tls.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py']",10,38786baca828fb2c8d3fe0453b2623f86fe69309,bp/lbaas-ssl-termination," super(LoadBalancerPluginDbTestCase, self).setUp( ext_mgr=ext_mgr, service_plugins=service_plugins ) def _test_create_vip_with_protocol_mismatch(self): def _test_update_vip_with_protocol_mismatch(self):","from neutron.common import config super(LoadBalancerPluginDbTestCase, self).setUp( ext_mgr=ext_mgr, service_plugins=service_plugins ) app = config.load_paste_app('extensions_test_app') self.ext_api = extensions.ExtensionMiddleware(app, ext_mgr=ext_mgr) def test_create_vip_with_protocol_mismatch(self): def test_update_vip_with_protocol_mismatch(self):",584,30
openstack%2Ftraining-guides~master~Ide4180544aded732ca22e971e944dbe2f0717209,openstack/training-guides,master,Ide4180544aded732ca22e971e944dbe2f0717209,Update Vagrantfile from Ubuntu 12.04 to 14.04,MERGED,2014-08-09 15:53:47.000000000,2014-08-10 08:40:44.000000000,2014-08-10 08:40:43.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2014-08-09 15:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/ac11832c4d6d3819a75c950f535bc0bc19dd640a', 'message': ""Update Vagrantfile from Ubuntu 12.04 to 14.04\n\nWe have changed the osbash default from Ubuntu 12.04 LTS to\nUbuntu 14.04 LTS.\n\nIt's time for the Vagrant scripts to do the same.\n\nChange-Id: Ide4180544aded732ca22e971e944dbe2f0717209\n""}, {'number': 2, 'created': '2014-08-10 06:57:19.000000000', 'files': ['labs/Vagrantfile'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/08f2b3a76eb2dbc1031e3abe3af881a61852a14d', 'message': ""Update Vagrantfile from Ubuntu 12.04 to 14.04\n\nWe have changed the osbash default from Ubuntu 12.04 LTS to\nUbuntu 14.04 LTS.\n\nIt's time for the Vagrant scripts to do the same.\n\nChange-Id: Ide4180544aded732ca22e971e944dbe2f0717209\n""}]",0,113093,08f2b3a76eb2dbc1031e3abe3af881a61852a14d,14,3,2,11109,,,0,"Update Vagrantfile from Ubuntu 12.04 to 14.04

We have changed the osbash default from Ubuntu 12.04 LTS to
Ubuntu 14.04 LTS.

It's time for the Vagrant scripts to do the same.

Change-Id: Ide4180544aded732ca22e971e944dbe2f0717209
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/93/113093/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/Vagrantfile'],1,ac11832c4d6d3819a75c950f535bc0bc19dd640a,vagrant_14," # from. The Vagrantfile currently uses Ubuntu 14.04 LTS (aka Trusty # Thar). Modify the line below and the box_url line to use a different config.vm.box = ""ubuntu/trusty64"" config.vm.box_url = ""https://vagrantcloud.com/ubuntu/trusty64"""," # from. The Vagrantfile currently uses Ubuntu 12.04 LTS (aka Precise # Pangolin). Modify the line below and the box_url line to use a different config.vm.box = ""precise64"" config.vm.box_url = ""http://files.vagrantup.com/precise64.box""",4,4
openstack%2Ftraining-guides~master~Ic564ac9e1683ec18eb4eded5aae7b2db640b9dbe,openstack/training-guides,master,Ic564ac9e1683ec18eb4eded5aae7b2db640b9dbe,Changes permission for setup_glance.sh,MERGED,2014-08-10 07:58:29.000000000,2014-08-10 08:14:24.000000000,2014-08-10 08:14:24.000000000,"[{'_account_id': 3}, {'_account_id': 11109}]","[{'number': 1, 'created': '2014-08-10 07:58:29.000000000', 'files': ['labs/scripts/setup_glance.sh'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/a1dbfd86b3dc50d0e3bd93f8b23708e59474cc5c', 'message': 'Changes permission for setup_glance.sh\n\nGives executable permission to setup_glance.sh\n\nChange-Id: Ic564ac9e1683ec18eb4eded5aae7b2db640b9dbe\nImplements: blueprint openstack-training-labs\n'}]",0,113120,a1dbfd86b3dc50d0e3bd93f8b23708e59474cc5c,7,2,1,7007,,,0,"Changes permission for setup_glance.sh

Gives executable permission to setup_glance.sh

Change-Id: Ic564ac9e1683ec18eb4eded5aae7b2db640b9dbe
Implements: blueprint openstack-training-labs
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/20/113120/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/scripts/setup_glance.sh'],1,a1dbfd86b3dc50d0e3bd93f8b23708e59474cc5c,bp/openstack-training-labs,,,0,0
openstack%2Ftraining-guides~master~I6863041e5c4e1a53f68629ca810ad812cf82bf02,openstack/training-guides,master,I6863041e5c4e1a53f68629ca810ad812cf82bf02,Fix links broken by openstack-manuals file move,MERGED,2014-08-10 07:09:44.000000000,2014-08-10 07:47:21.000000000,2014-08-10 07:47:21.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7007}]","[{'number': 1, 'created': '2014-08-10 07:09:44.000000000', 'files': ['doc/training-guides/associate-guide/ch_associate-controller-node.xml', 'doc/training-guides/associate-guide/ch_associate-compute-node.xml'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/388298c0e975ade97d9b706019674e782d196850', 'message': 'Fix links broken by openstack-manuals file move\n\nSeveral files were moved out of openstack-manuals/doc/common\nwith Change-Id Iacd5c68c639e60e8c711cb18351543e477444299, which broke\nbuilding in training-guides.\n\nThis patch fixes the broken links and makes training-guides build again.\n\nChange-Id: I6863041e5c4e1a53f68629ca810ad812cf82bf02\n'}]",0,113116,388298c0e975ade97d9b706019674e782d196850,8,3,1,11109,,,0,"Fix links broken by openstack-manuals file move

Several files were moved out of openstack-manuals/doc/common
with Change-Id Iacd5c68c639e60e8c711cb18351543e477444299, which broke
building in training-guides.

This patch fixes the broken links and makes training-guides build again.

Change-Id: I6863041e5c4e1a53f68629ca810ad812cf82bf02
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/16/113116/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/training-guides/associate-guide/ch_associate-controller-node.xml', 'doc/training-guides/associate-guide/ch_associate-compute-node.xml']",2,388298c0e975ade97d9b706019674e782d196850,fix_build," <xi:include href=""http://git.openstack.org/cgit/openstack/openstack-manuals/plain/doc/user-guide/section_cli_nova_terminate.xml"""," <xi:include href=""http://git.openstack.org/cgit/openstack/openstack-manuals/plain/doc/common/section_cli_nova_terminate.xml""",2,2
openstack%2Fapi-site~master~I8765ff2c7b1e0603308e3233f2cb56eb291ed311,openstack/api-site,master,I8765ff2c7b1e0603308e3233f2cb56eb291ed311,Imported Translations from Transifex,MERGED,2014-08-10 06:06:43.000000000,2014-08-10 06:43:55.000000000,2014-08-10 06:43:55.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-10 06:06:43.000000000', 'files': ['api-ref/locale/fr.po'], 'web_link': 'https://opendev.org/openstack/api-site/commit/8db3dc04076128e32bdfc0b755058667af9406ff', 'message': 'Imported Translations from Transifex\n\nChange-Id: I8765ff2c7b1e0603308e3233f2cb56eb291ed311\n'}]",0,113111,8db3dc04076128e32bdfc0b755058667af9406ff,7,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I8765ff2c7b1e0603308e3233f2cb56eb291ed311
",git fetch https://review.opendev.org/openstack/api-site refs/changes/11/113111/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/locale/fr.po'],1,8db3dc04076128e32bdfc0b755058667af9406ff,transifex/translations,"""POT-Creation-Date: 2014-08-08 07:08+0000\n"" ""PO-Revision-Date: 2014-08-09 19:10+0000\n"" ""Last-Translator: Nicolas HAHN <hahnn@x-itools.com>\n""msgstr ""Liste, cre, affiche les informations, met  jour, et supprime les rseaux.""msgstr ""Liste, cre, affiche les informations, et met  jour les ports.""msgstr ""Liste, cre, affiche les informations, et supprime les groupes de scurit et les les rgles des groupes de scurit.""msgstr ""Etats des load-balancers""msgstr ""Oprationnel""msgstr ""Une entit a t cre mais n'est pas encore lie  un load-balancer.""msgstr ""Non""msgstr ""Une entit est en cours de cration.""msgstr ""PENDING_UPDATE""msgstr ""Une entit a t mise  jour. Elle demeure dans l'tat oprationnel.""msgstr ""Oui""msgstr ""La suppression d'une unit a t initie.""msgstr ""Une entit est dans un tat oprationnel normal.""msgstr ""S'applique aux membres ayant chou aux tests de bon fonctionnement.""msgstr ""Quelque chose ne s'est pas pass correctement.""msgstr ""Cela peut tre soit dans un tat oprationnel, soit dans un tat non oprationnel.""msgstr ""Utilisez cette extension pour crer et grer des load balancers, des listeners, des pools, des membres, et des sondes de monitoring.""msgstr ""Mots de passe""msgstr ""Lorsque vous crez un serveur, vous pouvez indiquer un mot de passe au moyen de l'attribut optionnel <property>adminPass</property>. Le mot de passe indiqu doit correspondre aux rglages de complexit donns par votre fournisseur de Calcul OpenStack. Le serveur pourrait provoquer un tat d'<code>ERREUR</code> si les critres de complexit ne sont pas remplis. Dans ce cas, un client peut ventuellement dclencher une action de changement de mot de passe pour rinitialiser le mot de passe du serveur.""msgstr ""Si vous n'indiquez pas de mot de passe, un mot de passe gnr de faon alatoire est configur et retourn dans l'objet rponse. Ce mot de passe obira aux rgles de complexit rgls par le fournisseur de calcul. Pour des raisons de scurit, le mot de passe n'est pas retourn dans les appels ultrieurs.""msgstr ""Vous pouvez indiquer des mtadonnes de serveur customises au lancement de celui-ci. La taille maximale pour chaque cl-valeur de mtadonne est de 255 octets. Le nombre maximal de paires cl-valeur qui peuvent tre fournies par serveur est dtermin par le fournisseur de calcul. Vous pouvez obtenir cette valeur au moyen de la limite absolue <code>maxServerMeta</code>.""msgstr ""Rseaux du serveur""msgstr ""Vous pouvez spcifier les rseaux auxquels le serveur se connecte lors du lancement. Vous pouvez spcifier un ou plusieurs rseaux. Les utilisateurs peuvent aussi indiquer un port spcifique sur le rseau ou une adresse IP fixe  assigner  l'interface du serveur.""msgstr ""Vous pouvez utiliser  la fois des adresses IPv4 et IPv6 en tant qu'adresses d'accs et vous pouvez configurer ces deux adresses simultanment. Vous pouvez mettre  jour les adresses d'accs aprs avoir cr un serveur.""msgstr ""Personnalit du serveur.""msgstr ""Vous pouvez personnaliser la personnalit d'une instance de serveur en injectant des donnes dans son systme de fichiers. Par exemple, vous pourriez insrer des cls ssh, crire des fichiers de configuration, ou stocker des donnes que vous souhaiteriez retrouver depuis l'intrieur de l'instance. Cette fonctionnalit donne une personnalisation du dmarrage minimale. Si vous avez besoin de plus de personnalisation, crez une image personnalise.""msgstr ""Suivez ces recommandations lorsque vous injectez des fichiers:""msgstr ""La taille maximum des donnes de chemin de fichier est de 255 octets.""msgstr ""Encodez le contenu des fichiers en tant que chaine de caractres en Base64. Les fournisseurs de calcul dterminent la taille maximum du contenu des fichiers. Cette valeur peut varier en fonction de l'image qui est utilise pour crer le serveur.""msgstr ""La limite maximum fait rfrence au nombre d'octets dans les donnes dcodes et pas au nombre de caractres dans les donnes encodes.""msgstr ""Vous pouvez injecter des fichiers texte seulement. Vous ne pouvez pas injecter de fichiers binaires ou au format ZIP dans une nouvelle version.""msgstr ""Le nombre maximum de paires chemin de fichier/contenu que vous pouvez fournir est aussi dtermin par le fournisseur de calcul et est dfini parla limite absolue maxPersonality.""msgstr ""La limite absolue, <code>maxPersonalitySize</code>, est une limite en octets qui est garantie s'appliquer  toutes les images dans le dploiement. Les fournisseurs peuvent configurer des limites de personnalit par image.""msgstr ""L'injection de fichier ne devrait pas pouvoir survenir avant que le serveur n'est t construit et n'ait boot.""msgstr ""Durant l'injection de fichier, tout fichier existant correspondant aux fichiers spcifis est renomm afin d'inclure l'extension BAK avec la date et l'heure. Par exemple, si le fichier <filename>/etc/passwd</filename> existe, il est dupliqu en tant que <filename>/etc/passwd.bak.1246036261.5785</filename>.""msgstr ""Aprs l'injection du fichier, les fichiers de personnalit sont accessibles uniquement par les administrateurs systme. Par exemple, sous Linux, tous les fichiers ont l'utilisateur propritaire root et le groupe root, respectivement, et permettent seulement des accs en lecture seule au propritaire et au groupe ( ).""msgstr ""Adresses d'accs au serveur.""msgstr ""Dans un environnement hybride, l'adresse IP d'un serveur pourrait ne pas tre contrle par l'implmentation infrieure. Au lieu de cela, l'adresse IP d'accs pourrait tre une partie d'un composant matriel ddi; par exemple, un priphrique de routage/NAT. Dans ce cas, les adresses fournies par l'implmentation ne peuvent pas tre utilises pour accder au serveur (depuis l'extrieur du rseau local). Ici, une <firstterm>adresse d'accs</firstterm> spare pourrait tre assigne au moment de la cration pour donner l'accs au serveur. Cette adresse pourrait ne pas tre directement lie  une interface rseau sur le serveur et pourrait ne pas ncessairement apparatre lorsque vous interrogez les adresses du serveur. Voyez <xref linkend=\""compute_server-addresses\""/>. Nanmoins, les clients qui doivent accder au serveur directement sont encourags  le faire au moyen d'une adresse d'accs.""msgstr ""Fournit des donnes sur les migrations.""","""POT-Creation-Date: 2014-08-07 06:40+0000\n"" ""PO-Revision-Date: 2014-08-07 08:50+0000\n"" ""Last-Translator: Franois Bureau <francois.bureau@cloudwatt.com>\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr ""Fournissez des donnes sur les migrations.""",42,42
openstack%2Ftripleo-heat-templates~master~I0cdebf75d4752a35f547d4fbb81545ece3172405,openstack/tripleo-heat-templates,master,I0cdebf75d4752a35f547d4fbb81545ece3172405,Fix overcloud controller scaling,MERGED,2014-08-07 09:47:05.000000000,2014-08-10 05:45:33.000000000,2014-08-10 05:45:33.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 7582}]","[{'number': 1, 'created': '2014-08-07 09:47:05.000000000', 'files': ['undercloud-source.yaml', 'overcloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a5413281e08b7cf9dd4648d4f31b7593d7dd4c0a', 'message': 'Fix overcloud controller scaling\n\nController scaling was broken by the commit\n02772ba2877b9f6d427c6fd760bf19d6334c68a8. Merge.py raises an exception\nwhen it tries to scale the default value ""controller0"" of the\n`BootstrapNodeResource` parameter.\n\nThis reverts back to using Fn::Select for specifying the bootstrap host,\nthe rest of the Fn::Select -> get_attr changes are kept.\n\nChange-Id: I0cdebf75d4752a35f547d4fbb81545ece3172405\n'}]",0,112538,a5413281e08b7cf9dd4648d4f31b7593d7dd4c0a,16,3,1,4330,,,0,"Fix overcloud controller scaling

Controller scaling was broken by the commit
02772ba2877b9f6d427c6fd760bf19d6334c68a8. Merge.py raises an exception
when it tries to scale the default value ""controller0"" of the
`BootstrapNodeResource` parameter.

This reverts back to using Fn::Select for specifying the bootstrap host,
the rest of the Fn::Select -> get_attr changes are kept.

Change-Id: I0cdebf75d4752a35f547d4fbb81545ece3172405
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/38/112538/1 && git format-patch -1 --stdout FETCH_HEAD,"['undercloud-source.yaml', 'overcloud-source.yaml']",2,a5413281e08b7cf9dd4648d4f31b7593d7dd4c0a,fix-controller-scaling, bootstrap_nodeid: Fn::Select: - 0 - Fn::Select: - 0 - Merge::Map: controller0: - Fn::Select: - name - get_attr: - controller0 - show," BootstrapNodeResource: default: controller0 description: Name of the bootstrap controller resource type: string bootstrap_nodeid: {get_attr: [{get_param: BootstrapNodeResource}, show, name]}",24,6
openstack%2Fcinder~master~I95ef533d031d333da5615ead997b54c6506c2c2a,openstack/cinder,master,I95ef533d031d333da5615ead997b54c6506c2c2a,Updated HACKING.rst so that it is accurate,MERGED,2014-08-03 17:49:18.000000000,2014-08-10 05:27:30.000000000,2014-08-10 05:04:42.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}]","[{'number': 1, 'created': '2014-08-03 17:49:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e0ce63994535b64de04e5fc008a7bc0b8a1589db', 'message': ""Updated HACKING.rst so that it is accurate\n\nWe haven't been very good at enforcing putting new hacking checks\ninto HACKING.rst.  This change brings the file up to date.\n\nChange-Id: I95ef533d031d333da5615ead997b54c6506c2c2a\n""}, {'number': 2, 'created': '2014-08-09 18:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bcc76fd6b270ae0f1987a834b9f50958bca41fdc', 'message': ""Updated HACKING.rst so that it is accurate\n\nWe haven't been very good at enforcing putting new hacking checks\ninto HACKING.rst.  This change brings the file up to date.\n\nChange-Id: I95ef533d031d333da5615ead997b54c6506c2c2a\n""}, {'number': 3, 'created': '2014-08-10 03:12:35.000000000', 'files': ['HACKING.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/79b6b98f210b47fb6313132ba8cfbb977bfb072e', 'message': ""Updated HACKING.rst so that it is accurate\n\nWe haven't been very good at enforcing putting new hacking checks\ninto HACKING.rst.  This change brings the file up to date.\n\nChange-Id: I95ef533d031d333da5615ead997b54c6506c2c2a\n""}]",0,111590,79b6b98f210b47fb6313132ba8cfbb977bfb072e,42,11,3,7198,,,0,"Updated HACKING.rst so that it is accurate

We haven't been very good at enforcing putting new hacking checks
into HACKING.rst.  This change brings the file up to date.

Change-Id: I95ef533d031d333da5615ead997b54c6506c2c2a
",git fetch https://review.opendev.org/openstack/cinder refs/changes/90/111590/3 && git format-patch -1 --stdout FETCH_HEAD,['HACKING.rst'],1,e0ce63994535b64de04e5fc008a7bc0b8a1589db,update-hacking-rst,- [N314] Check for vi editor configuration in source files.- [N322] Ensure default arguments are not mutable.,,2,1
openstack%2Fnova~master~I2e0a08438174f0fe0d7ea732670971e65811a700,openstack/nova,master,I2e0a08438174f0fe0d7ea732670971e65811a700,Fix doc build errors in models.py,MERGED,2014-07-25 02:46:29.000000000,2014-08-10 05:10:11.000000000,2014-07-25 21:44:24.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-25 02:46:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c1f80a6cabb6d4072005896c9c8ba68e6b44250', 'message': 'Fix doc build errors in models.py\n\nThe docs build has errors like the following:\nnova/nova/db/sqlalchemy/models.py:docstring of\nnova.db.sqlalchemy.models.relationship:517: ERROR: Unknown interpreted\ntext role ""paramref"".\n\nTo fix this remove the import for relationship and refer to it\ninstead using orm.relationship.\n\nChange-Id: I2e0a08438174f0fe0d7ea732670971e65811a700\n'}, {'number': 2, 'created': '2014-07-25 13:43:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5322821870ea229fd9221504e158336b96c49bda', 'message': 'Fix doc build errors in models.py\n\nThe docs build has errors like the following:\nnova/nova/db/sqlalchemy/models.py:docstring of\nnova.db.sqlalchemy.models.relationship:517: ERROR: Unknown interpreted\ntext role ""paramref"".\n\nTo fix this remove the import for relationship and refer to it\ninstead using orm.relationship.\n\nChange-Id: I2e0a08438174f0fe0d7ea732670971e65811a700\n'}, {'number': 3, 'created': '2014-07-25 18:08:52.000000000', 'files': ['nova/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9f1ba4d75eb1a1866f23a0520b6d219356e574fa', 'message': 'Fix doc build errors in models.py\n\nThe docs build has errors like the following:\nnova/nova/db/sqlalchemy/models.py:docstring of\nnova.db.sqlalchemy.models.relationship:517: ERROR: Unknown interpreted\ntext role ""paramref"".\n\nTo fix this remove the import for relationship and refer to it\ninstead using orm.relationship.\n\nChange-Id: I2e0a08438174f0fe0d7ea732670971e65811a700\n'}]",0,109474,9f1ba4d75eb1a1866f23a0520b6d219356e574fa,30,10,3,5638,,,0,"Fix doc build errors in models.py

The docs build has errors like the following:
nova/nova/db/sqlalchemy/models.py:docstring of
nova.db.sqlalchemy.models.relationship:517: ERROR: Unknown interpreted
text role ""paramref"".

To fix this remove the import for relationship and refer to it
instead using orm.relationship.

Change-Id: I2e0a08438174f0fe0d7ea732670971e65811a700
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/109474/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/models.py'],1,6c1f80a6cabb6d4072005896c9c8ba68e6b44250,fix-tox-docs,"from sqlalchemy import orm service = orm.relationship(Service, backref=orm.backref('compute_node'), for column in iter(orm.object_mapper(self).columns): instance = orm.relationship(Instance, backref=orm.backref('info_cache', uselist=False), usage = orm.relationship( instance = orm.relationship(Instance, backref=orm.backref('block_device_mapping'), volume = orm.relationship(Volume, backref=orm.backref('iscsi_target', uselist=False), instances = orm.relationship(Instance, parent_group = orm.relationship(""SecurityGroup"", backref=""rules"", grantee_group = orm.relationship(""SecurityGroup"", instance = orm.relationship(""Instance"", foreign_keys=instance_uuid, network = orm.relationship(Network, backref=orm.backref('fixed_ips'), instance = orm.relationship(Instance, fixed_ip = orm.relationship(FixedIp, backref=orm.backref('floating_ips'), pool = orm.relationship(ConsolePool, backref=orm.backref('consoles')) instance = orm.relationship(Instance, backref=""metadata"", instance = orm.relationship(Instance, backref=""system_metadata"", instance_type = orm.relationship(InstanceTypes, backref=""projects"", instance_type = orm.relationship(InstanceTypes, backref=""extra_specs"", _hosts = orm.relationship(AggregateHost, _metadata = orm.relationship(AggregateMetadata, _policies = orm.relationship(InstanceGroupPolicy, primaryjoin='and_(' _metadata = orm.relationship(InstanceGroupMetadata, primaryjoin='and_(' _members = orm.relationship(InstanceGroupMember, primaryjoin='and_(' instance = orm.relationship(Instance, backref=""pci_devices"",","from sqlalchemy.orm import relationship, backref, object_mapper service = relationship(Service, backref=backref('compute_node'), for column in iter(object_mapper(self).columns): instance = relationship(Instance, backref=backref('info_cache', uselist=False), usage = relationship( instance = relationship(Instance, backref=backref('block_device_mapping'), volume = relationship(Volume, backref=backref('iscsi_target', uselist=False), instances = relationship(Instance, parent_group = relationship(""SecurityGroup"", backref=""rules"", grantee_group = relationship(""SecurityGroup"", instance = relationship(""Instance"", foreign_keys=instance_uuid, network = relationship(Network, backref=backref('fixed_ips'), instance = relationship(Instance, fixed_ip = relationship(FixedIp, backref=backref('floating_ips'), pool = relationship(ConsolePool, backref=backref('consoles')) instance = relationship(Instance, backref=""metadata"", instance = relationship(Instance, backref=""system_metadata"", instance_type = relationship(InstanceTypes, backref=""projects"", instance_type = relationship(InstanceTypes, backref=""extra_specs"", _hosts = relationship(AggregateHost, _metadata = relationship(AggregateMetadata, _policies = relationship(InstanceGroupPolicy, primaryjoin='and_(' _metadata = relationship(InstanceGroupMetadata, primaryjoin='and_(' _members = relationship(InstanceGroupMember, primaryjoin='and_(' instance = relationship(Instance, backref=""pci_devices"",",31,31
openstack%2Ftempest~master~I39803d89ac507146e1cb3a371b4a66f7244c8990,openstack/tempest,master,I39803d89ac507146e1cb3a371b4a66f7244c8990,Update v3 identity client to skip uri_v3 requirement,ABANDONED,2014-05-13 06:59:34.000000000,2014-08-10 04:54:58.000000000,,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 7139}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-13 06:59:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f0c2140bd7e576bc0868f24982e894088284de18', 'message': 'Update v3 identity client to skip uri_v3 requirement\n\nEven when V3 is disabled the identity client requires\na uri_v3 which is not necessary. Folllowing patch removes\nthe requirement.\n\nChange-Id: I39803d89ac507146e1cb3a371b4a66f7244c8990\nCloses-Bug:#1295132\n'}, {'number': 2, 'created': '2014-05-13 09:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f37ed1ac51bd8ecedd1d8284a7409b034d15dde8', 'message': 'Update v3 identity client to skip uri_v3 requirement\n\nEven when V3 is disabled the identity client requires\na uri_v3 which is not necessary. Folllowing patch removes\nthe requirement.\n\nChange-Id: I39803d89ac507146e1cb3a371b4a66f7244c8990\nCloses-Bug:#1295132\n'}, {'number': 3, 'created': '2014-05-13 13:03:06.000000000', 'files': ['tempest/services/identity/v3/json/identity_client.py', 'tempest/services/identity/v3/xml/identity_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7c868475514f36492880d1e6118347f6df0c917e', 'message': 'Update v3 identity client to skip uri_v3 requirement\n\nEven when V3 is disabled the identity client requires\na uri_v3 which is not necessary. Folllowing patch removes\nthe requirement.\n\nChange-Id: I39803d89ac507146e1cb3a371b4a66f7244c8990\nCloses-Bug:#1295132\n'}]",2,93382,7c868475514f36492880d1e6118347f6df0c917e,17,5,3,11105,,,0,"Update v3 identity client to skip uri_v3 requirement

Even when V3 is disabled the identity client requires
a uri_v3 which is not necessary. Folllowing patch removes
the requirement.

Change-Id: I39803d89ac507146e1cb3a371b4a66f7244c8990
Closes-Bug:#1295132
",git fetch https://review.opendev.org/openstack/tempest refs/changes/82/93382/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/identity/v3/json/identity_client.py', 'tempest/services/identity/v3/xml/identity_client.py']",2,f0c2140bd7e576bc0868f24982e894088284de18,bug/1295132, if CONF.identity.auth_version is 'v3': auth_url = CONF.identity.uri_v3 if not auth_url and CONF.identity_feature_enabled.api_v3: raise exceptions.InvalidConfiguration('you must specify a v3 ' 'uri if using the v3 ' 'identity api') if 'auth/tokens' not in auth_url: auth_url = auth_url.rstrip('/') + '/auth/tokens' self.auth_url = auth_url, auth_url = CONF.identity.uri_v3 if not auth_url and CONF.identity_feature_enabled.api_v3: raise exceptions.InvalidConfiguration('you must specify a v3 uri ' 'if using the v3 identity ' 'api') if 'auth/tokens' not in auth_url: auth_url = auth_url.rstrip('/') + '/auth/tokens' self.auth_url = auth_url,18,16
openstack%2Fcinder~master~Icc416a68f958f60260f1c55af0d8605c95913bf1,openstack/cinder,master,Icc416a68f958f60260f1c55af0d8605c95913bf1,Add hacking check for use of LOG.audit,MERGED,2014-08-01 20:53:29.000000000,2014-08-10 04:13:36.000000000,2014-08-09 18:46:35.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 7860}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}]","[{'number': 1, 'created': '2014-08-01 20:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/71a35742b1ccce02086609a2d09ad7eac38bd1bc', 'message': 'Add hacking check for use of LOG.audit\n\nCommit 4dc37abc removes the few instances of LOG.audit that\nwere in Cinder.  Given that the plan is to remove LOG.audit messages\nfrom OpenStack, I am adding this hacking check to ensure that such\nmessages do not sneak their way back into Cinder.\n\nUnit tests are included with this change.\n\nChange-Id: Icc416a68f958f60260f1c55af0d8605c95913bf1\n'}, {'number': 2, 'created': '2014-08-09 15:22:04.000000000', 'files': ['cinder/tests/test_hacking.py', 'cinder/hacking/checks.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/097d3d791071148b53c076aef66eefa77b2b10db', 'message': 'Add hacking check for use of LOG.audit\n\nCommit 4dc37abc removes the few instances of LOG.audit that\nwere in Cinder.  Given that the plan is to remove LOG.audit messages\nfrom OpenStack, I am adding this hacking check to ensure that such\nmessages do not sneak their way back into Cinder.\n\nUnit tests are included with this change.\n\nChange-Id: Icc416a68f958f60260f1c55af0d8605c95913bf1\n'}]",0,111389,097d3d791071148b53c076aef66eefa77b2b10db,26,12,2,7198,,,0,"Add hacking check for use of LOG.audit

Commit 4dc37abc removes the few instances of LOG.audit that
were in Cinder.  Given that the plan is to remove LOG.audit messages
from OpenStack, I am adding this hacking check to ensure that such
messages do not sneak their way back into Cinder.

Unit tests are included with this change.

Change-Id: Icc416a68f958f60260f1c55af0d8605c95913bf1
",git fetch https://review.opendev.org/openstack/cinder refs/changes/89/111389/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_hacking.py', 'cinder/hacking/checks.py', 'HACKING.rst']",3,71a35742b1ccce02086609a2d09ad7eac38bd1bc,add_audit_hacking_check,- [N324] Enforce no use of LOG.audit messages. LOG.info should be used instead.,,22,0
openstack%2Frally~master~I0a7fb9fbf0c415aa357a2d24d1d674e3208b4a75,openstack/rally,master,I0a7fb9fbf0c415aa357a2d24d1d674e3208b4a75,Removed concurency from Quotas.nova_update_and_delete,MERGED,2014-08-10 02:23:24.000000000,2014-08-10 03:35:59.000000000,2014-08-10 03:35:59.000000000,"[{'_account_id': 3}, {'_account_id': 6172}]","[{'number': 1, 'created': '2014-08-10 02:23:24.000000000', 'files': ['rally-scenarios/rally.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/64f4295be2d4240487a94f857af5743c6e6364cc', 'message': ""Removed concurency from Quotas.nova_update_and_delete\n\nFor some bug or design issue nova doesn't allow do update quotas\nsimultaneously for one user\n\nTo avoid fails in Rally gates remove concurency\n\nChange-Id: I0a7fb9fbf0c415aa357a2d24d1d674e3208b4a75\nCloses-Bug: #1354761\n""}]",0,113103,64f4295be2d4240487a94f857af5743c6e6364cc,7,2,1,6172,,,0,"Removed concurency from Quotas.nova_update_and_delete

For some bug or design issue nova doesn't allow do update quotas
simultaneously for one user

To avoid fails in Rally gates remove concurency

Change-Id: I0a7fb9fbf0c415aa357a2d24d1d674e3208b4a75
Closes-Bug: #1354761
",git fetch https://review.opendev.org/openstack/rally refs/changes/03/113103/1 && git format-patch -1 --stdout FETCH_HEAD,['rally-scenarios/rally.yaml'],1,64f4295be2d4240487a94f857af5743c6e6364cc,bug/1354761, times: 4 concurrency: 1, times: 10 concurrency: 2,2,2
openstack%2Fkeystone~master~Icec01fc7e3bcf3df03c1f8a589d13f8955c64380,openstack/keystone,master,Icec01fc7e3bcf3df03c1f8a589d13f8955c64380,Remove fixture from openstack-common.conf,MERGED,2014-06-27 22:10:07.000000000,2014-08-10 02:31:19.000000000,2014-08-10 02:31:18.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-27 22:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cd69cb6f82bf65bc9ee2e45139bc901adb511530', 'message': ""Remove fixture from openstack-common.conf\n\nKeystone doesn't use anything in fixture, so remove it from\nopenstack-common.conf and re-sync with oslo-incubator e9bb0b59 to\nremove unused parts.\n\nChange-Id: Icec01fc7e3bcf3df03c1f8a589d13f8955c64380\n""}, {'number': 2, 'created': '2014-07-08 14:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a234570158364975ca51de8a3dcf0ebf81512e4c', 'message': ""Remove fixture from openstack-common.conf\n\nKeystone doesn't use anything in fixture, so remove it from\nopenstack-common.conf and re-sync with oslo-incubator e9bb0b59 to\nremove unused parts.\n\nChange-Id: Icec01fc7e3bcf3df03c1f8a589d13f8955c64380\n""}, {'number': 3, 'created': '2014-07-13 19:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6df88abff565b77081458b698392deadc26d8dbb', 'message': ""Remove fixture from openstack-common.conf\n\nKeystone doesn't use anything in fixture, so remove it from\nopenstack-common.conf and re-sync with oslo-incubator e9bb0b59 to\nremove unused parts.\n\nChange-Id: Icec01fc7e3bcf3df03c1f8a589d13f8955c64380\n""}, {'number': 4, 'created': '2014-07-17 01:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d567743e5b53728ad12df06ac6d656f5d3d4ef67', 'message': ""Remove fixture from openstack-common.conf\n\nKeystone doesn't use anything in fixture, so remove it from\nopenstack-common.conf and re-sync with oslo-incubator e9bb0b59 to\nremove unused parts.\n\nChange-Id: Icec01fc7e3bcf3df03c1f8a589d13f8955c64380\n""}, {'number': 5, 'created': '2014-07-28 21:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/91e9b23e044534b1510386967814356883449964', 'message': ""Remove fixture from openstack-common.conf\n\nKeystone doesn't use anything in fixture, so remove it from\nopenstack-common.conf and re-sync with oslo-incubator 5fa2da to\nremove unused parts.\n\nChange-Id: Icec01fc7e3bcf3df03c1f8a589d13f8955c64380\n""}, {'number': 6, 'created': '2014-07-29 21:30:43.000000000', 'files': ['keystone/openstack/common/fixture/__init__.py', 'keystone/openstack/common/fixture/moxstubout.py', 'keystone/openstack/common/fixture/logging.py', 'openstack-common.conf', 'keystone/openstack/common/fixture/lockutils.py', 'keystone/openstack/common/fixture/mockpatch.py', 'keystone/openstack/common/lockutils.py', 'keystone/openstack/common/fixture/config.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2ac6008a371e63aa10ab9cadedd99be0abe2b4a5', 'message': ""Remove fixture from openstack-common.conf\n\nKeystone doesn't use anything in fixture, so remove it from\nopenstack-common.conf and re-sync with oslo-incubator 5fa2da to\nremove unused parts.\n\nChange-Id: Icec01fc7e3bcf3df03c1f8a589d13f8955c64380\n""}]",0,103255,2ac6008a371e63aa10ab9cadedd99be0abe2b4a5,27,5,6,6486,,,0,"Remove fixture from openstack-common.conf

Keystone doesn't use anything in fixture, so remove it from
openstack-common.conf and re-sync with oslo-incubator 5fa2da to
remove unused parts.

Change-Id: Icec01fc7e3bcf3df03c1f8a589d13f8955c64380
",git fetch https://review.opendev.org/openstack/keystone refs/changes/55/103255/3 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/openstack/common/fixture/__init__.py', 'keystone/openstack/common/fixture/moxstubout.py', 'keystone/openstack/common/fixture/logging.py', 'openstack-common.conf', 'keystone/openstack/common/fixture/lockutils.py', 'keystone/openstack/common/fixture/mockpatch.py', 'keystone/openstack/common/fixture/config.py', 'keystone/openstack/common/lockutils.py']",8,cd69cb6f82bf65bc9ee2e45139bc901adb511530,openstack/requirements,,"# Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import contextlib import errno import fcntl import functools import os import shutil import subprocess import sys import tempfile import threading import time import weakref from oslo.config import cfg from keystone.openstack.common import fileutils from keystone.openstack.common.gettextutils import _, _LE, _LI from keystone.openstack.common import log as logging LOG = logging.getLogger(__name__) util_opts = [ cfg.BoolOpt('disable_process_locking', default=False, help='Enables or disables inter-process locks.'), cfg.StrOpt('lock_path', default=os.environ.get(""KEYSTONE_LOCK_PATH""), help='Directory to use for lock files.') ] CONF = cfg.CONF CONF.register_opts(util_opts) def set_defaults(lock_path): cfg.set_defaults(util_opts, lock_path=lock_path) class _FileLock(object): """"""Lock implementation which allows multiple locks, working around issues like bugs.debian.org/cgi-bin/bugreport.cgi?bug=632857 and does not require any cleanup. Since the lock is always held on a file descriptor rather than outside of the process, the lock gets dropped automatically if the process crashes, even if __exit__ is not executed. There are no guarantees regarding usage by multiple green threads in a single process here. This lock works only between processes. Exclusive access between local threads should be achieved using the semaphores in the @synchronized decorator. Note these locks are released when the descriptor is closed, so it's not safe to close the file descriptor while another green thread holds the lock. Just opening and closing the lock file can break synchronisation, so lock files must be accessed only using this abstraction. """""" def __init__(self, name): self.lockfile = None self.fname = name def acquire(self): basedir = os.path.dirname(self.fname) if not os.path.exists(basedir): fileutils.ensure_tree(basedir) LOG.info(_LI('Created lock path: %s'), basedir) self.lockfile = open(self.fname, 'w') while True: try: # Using non-blocking locks since green threads are not # patched to deal with blocking locking calls. # Also upon reading the MSDN docs for locking(), it seems # to have a laughable 10 attempts ""blocking"" mechanism. self.trylock() LOG.debug('Got file lock ""%s""', self.fname) return True except IOError as e: if e.errno in (errno.EACCES, errno.EAGAIN): # external locks synchronise things like iptables # updates - give it some time to prevent busy spinning time.sleep(0.01) else: raise threading.ThreadError(_(""Unable to acquire lock on"" "" `%(filename)s` due to"" "" %(exception)s"") % { 'filename': self.fname, 'exception': e, }) def __enter__(self): self.acquire() return self def release(self): try: self.unlock() self.lockfile.close() LOG.debug('Released file lock ""%s""', self.fname) except IOError: LOG.exception(_LE(""Could not release the acquired lock `%s`""), self.fname) def __exit__(self, exc_type, exc_val, exc_tb): self.release() def exists(self): return os.path.exists(self.fname) def trylock(self): raise NotImplementedError() def unlock(self): raise NotImplementedError() class _WindowsLock(_FileLock): def trylock(self): msvcrt.locking(self.lockfile.fileno(), msvcrt.LK_NBLCK, 1) def unlock(self): msvcrt.locking(self.lockfile.fileno(), msvcrt.LK_UNLCK, 1) class _FcntlLock(_FileLock): def trylock(self): fcntl.lockf(self.lockfile, fcntl.LOCK_EX | fcntl.LOCK_NB) def unlock(self): fcntl.lockf(self.lockfile, fcntl.LOCK_UN) class _PosixLock(object): def __init__(self, name): # Hash the name because it's not valid to have POSIX semaphore # names with things like / in them. Then use base64 to encode # the digest() instead taking the hexdigest() because the # result is shorter and most systems can't have shm sempahore # names longer than 31 characters. h = hashlib.sha1() h.update(name.encode('ascii')) self.name = str((b'/' + base64.urlsafe_b64encode( h.digest())).decode('ascii')) def acquire(self, timeout=None): self.semaphore = posix_ipc.Semaphore(self.name, flags=posix_ipc.O_CREAT, initial_value=1) self.semaphore.acquire(timeout) return self def __enter__(self): self.acquire() return self def release(self): self.semaphore.release() self.semaphore.close() def __exit__(self, exc_type, exc_val, exc_tb): self.release() def exists(self): try: semaphore = posix_ipc.Semaphore(self.name) except posix_ipc.ExistentialError: return False else: semaphore.close() return True if os.name == 'nt': import msvcrt InterProcessLock = _WindowsLock FileLock = _WindowsLock else: import base64 import hashlib import posix_ipc InterProcessLock = _PosixLock FileLock = _FcntlLock _semaphores = weakref.WeakValueDictionary() _semaphores_lock = threading.Lock() def _get_lock_path(name, lock_file_prefix, lock_path=None): # NOTE(mikal): the lock name cannot contain directory # separators name = name.replace(os.sep, '_') if lock_file_prefix: sep = '' if lock_file_prefix.endswith('-') else '-' name = '%s%s%s' % (lock_file_prefix, sep, name) local_lock_path = lock_path or CONF.lock_path if not local_lock_path: # NOTE(bnemec): Create a fake lock path for posix locks so we don't # unnecessarily raise the RequiredOptError below. if InterProcessLock is not _PosixLock: raise cfg.RequiredOptError('lock_path') local_lock_path = 'posixlock:/' return os.path.join(local_lock_path, name) def external_lock(name, lock_file_prefix=None, lock_path=None): LOG.debug('Attempting to grab external lock ""%(lock)s""', {'lock': name}) lock_file_path = _get_lock_path(name, lock_file_prefix, lock_path) # NOTE(bnemec): If an explicit lock_path was passed to us then it # means the caller is relying on file-based locking behavior, so # we can't use posix locks for those calls. if lock_path: return FileLock(lock_file_path) return InterProcessLock(lock_file_path) def remove_external_lock_file(name, lock_file_prefix=None): """"""Remove an external lock file when it's not used anymore This will be helpful when we have a lot of lock files """""" with internal_lock(name): lock_file_path = _get_lock_path(name, lock_file_prefix) try: os.remove(lock_file_path) except OSError: LOG.info(_LI('Failed to remove file %(file)s'), {'file': lock_file_path}) def internal_lock(name): with _semaphores_lock: try: sem = _semaphores[name] except KeyError: sem = threading.Semaphore() _semaphores[name] = sem LOG.debug('Got semaphore ""%(lock)s""', {'lock': name}) return sem @contextlib.contextmanager def lock(name, lock_file_prefix=None, external=False, lock_path=None): """"""Context based lock This function yields a `threading.Semaphore` instance (if we don't use eventlet.monkey_patch(), else `semaphore.Semaphore`) unless external is True, in which case, it'll yield an InterProcessLock instance. :param lock_file_prefix: The lock_file_prefix argument is used to provide lock files on disk with a meaningful prefix. :param external: The external keyword argument denotes whether this lock should work across multiple processes. This means that if two different workers both run a method decorated with @synchronized('mylock', external=True), only one of them will execute at a time. """""" int_lock = internal_lock(name) with int_lock: if external and not CONF.disable_process_locking: ext_lock = external_lock(name, lock_file_prefix, lock_path) with ext_lock: yield ext_lock else: yield int_lock LOG.debug('Released semaphore ""%(lock)s""', {'lock': name}) def synchronized(name, lock_file_prefix=None, external=False, lock_path=None): """"""Synchronization decorator. Decorating a method like so:: @synchronized('mylock') def foo(self, *args): ... ensures that only one thread will execute the foo method at a time. Different methods can share the same lock:: @synchronized('mylock') def foo(self, *args): ... @synchronized('mylock') def bar(self, *args): ... This way only one of either foo or bar can be executing at a time. """""" def wrap(f): @functools.wraps(f) def inner(*args, **kwargs): try: with lock(name, lock_file_prefix, external, lock_path): LOG.debug('Got semaphore / lock ""%(function)s""', {'function': f.__name__}) return f(*args, **kwargs) finally: LOG.debug('Semaphore / lock released ""%(function)s""', {'function': f.__name__}) return inner return wrap def synchronized_with_prefix(lock_file_prefix): """"""Partial object generator for the synchronization decorator. Redefine @synchronized in each project like so:: (in nova/utils.py) from nova.openstack.common import lockutils synchronized = lockutils.synchronized_with_prefix('nova-') (in nova/foo.py) from nova import utils @utils.synchronized('mylock') def bar(self, *args): ... The lock_file_prefix argument is used to provide lock files on disk with a meaningful prefix. """""" return functools.partial(synchronized, lock_file_prefix=lock_file_prefix) def main(argv): """"""Create a dir for locks and pass it to command from arguments If you run this: python -m openstack.common.lockutils python setup.py testr <etc> a temporary directory will be created for all your locks and passed to all your tests in an environment variable. The temporary dir will be deleted afterwards and the return value will be preserved. """""" lock_dir = tempfile.mkdtemp() os.environ[""KEYSTONE_LOCK_PATH""] = lock_dir try: ret_val = subprocess.call(argv[1:]) finally: shutil.rmtree(lock_dir, ignore_errors=True) return ret_val if __name__ == '__main__': sys.exit(main(sys.argv)) ",0,655
openstack%2Frally~master~I5f2de2c2bdbbfab12630bbae7b2e7e1cfbaac7c3,openstack/rally,master,I5f2de2c2bdbbfab12630bbae7b2e7e1cfbaac7c3,Test bug #1354761,ABANDONED,2014-08-10 01:13:36.000000000,2014-08-10 02:23:45.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-08-10 01:13:36.000000000', 'files': ['rally-scenarios/rally.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/2af9480919519f03b4e3dc2596868922c22853de', 'message': 'Test bug #1354761\n\nSeems like Quotas.nova_update_and_delete is not thread safe.\nI do think that the real reason is nova.\nSo just bump concurrency to see what will happen\n\nChange-Id: I5f2de2c2bdbbfab12630bbae7b2e7e1cfbaac7c3\n'}]",0,113101,2af9480919519f03b4e3dc2596868922c22853de,4,1,1,6172,,,0,"Test bug #1354761

Seems like Quotas.nova_update_and_delete is not thread safe.
I do think that the real reason is nova.
So just bump concurrency to see what will happen

Change-Id: I5f2de2c2bdbbfab12630bbae7b2e7e1cfbaac7c3
",git fetch https://review.opendev.org/openstack/rally refs/changes/01/113101/1 && git format-patch -1 --stdout FETCH_HEAD,['rally-scenarios/rally.yaml'],1,2af9480919519f03b4e3dc2596868922c22853de,bug/1354761, times: 100 concurrency: 50," times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 Quotas.nova_update: - args: max_quota: 1024 runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 CinderVolumes.create_and_delete_volume: - args: size: 1 runner: type: ""constant"" times: 3 concurrency: 2 context: users: tenants: 2 users_per_tenant: 2 sla: max_failure_percent: 0 CinderVolumes.create_and_list_volume: - args: size: 1 detailed: True runner: type: ""constant"" times: 3 concurrency: 1 users_per_tenant: 1 sla: max_failure_percent: 0 CinderVolumes.create_volume: - args: size: 1 runner: type: ""constant"" times: 2 concurrency: 2 context: users: tenants: 2 GlanceImages.create_and_delete_image: - args: image_location: ""http://download.cirros-cloud.net/0.3.2/cirros-0.3.2-x86_64-disk.img"" container_format: ""bare"" disk_format: ""qcow2"" runner: type: ""constant"" times: 6 concurrency: 3 context: users: tenants: 2 users_per_tenant: 3 sla: max_failure_percent: 0 GlanceImages.create_and_list_image: - args: image_location: ""/home/jenkins/.rally/extra/fake-image.img"" container_format: ""bare"" disk_format: ""qcow2"" runner: type: ""constant"" times: 6 concurrency: 2 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 GlanceImages.create_image_and_boot_instances: - args: image_location: ""http://download.cirros-cloud.net/0.3.2/cirros-0.3.2-x86_64-disk.img"" container_format: ""bare"" disk_format: ""qcow2"" flavor: name: ""m1.tiny"" number_instances: 2 runner: type: ""constant"" times: 4 concurrency: 2 context: users: tenants: 3 users_per_tenant: 1 sla: max_failure_percent: 0 NovaServers.boot_and_delete_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" runner: type: ""constant"" times: 4 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.boot_and_list_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" detailed: True runner: type: ""constant"" times: 1 concurrency: 1 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 NovaServers.resize_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" to_flavor: name: ""m1.small"" confirm: true runner: type: ""constant"" times: 4 concurrency: 2 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 NovaServers.boot_and_bounce_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" actions: - hard_reboot: 1 - soft_reboot: 1 - stop_start: 1 - rescue_unrescue: 1 runner: type: ""constant"" times: 3 concurrency: 3 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.boot_server_from_volume_and_delete: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" volume_size: 1 runner: type: ""constant"" times: 4 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.boot_server_from_volume: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" volume_size: 1 runner: type: ""constant"" times: 4 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.snapshot_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" runner: type: ""constant"" times: 2 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.boot_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" runner: type: ""constant"" times: 4 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 VMTasks.boot_runcommand_delete: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" fixed_network: ""private"" floating_network: ""public"" use_floatingip: true script: ""/home/jenkins/.rally/extra/instance_dd_test.sh"" interpreter: ""/bin/sh"" username: ""cirros"" runner: type: ""constant"" times: 6 concurrency: 3 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" fixed_network: ""private"" use_floatingip: false script: ""/home/jenkins/.rally/extra/instance_dd_test.sh"" interpreter: ""/bin/sh"" username: ""cirros"" runner: type: ""constant"" times: 6 concurrency: 3 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0",2,321
openstack%2Fkeystone~master~Ia31e455c6441cfbfbe33271ccdef1030a8c3d5cc,openstack/keystone,master,Ia31e455c6441cfbfbe33271ccdef1030a8c3d5cc,Remove strutils and timeutils from openstack-common.conf,MERGED,2014-08-05 22:12:00.000000000,2014-08-10 01:32:20.000000000,2014-08-10 01:32:19.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 10697}, {'_account_id': 10873}, {'_account_id': 11387}]","[{'number': 1, 'created': '2014-08-05 22:12:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4c132ba6de2298fbcc86057facb5d0202579775b', 'message': ""Remove strutils and timeutils from openstack-common.conf\n\nSince Keystone is changed to use strutils and timeutils from\noslo.utils, it doesn't directly use these modules from\noslo-incubator anymore, as such, they're removed from\nopenstack-common.conf.\n\nSince these modules are still used internally by oslo-incubator\nmodules, they aren't removed from keystone in a sync.\n\nChange-Id: Ia31e455c6441cfbfbe33271ccdef1030a8c3d5cc\n""}, {'number': 2, 'created': '2014-08-09 12:49:31.000000000', 'files': ['openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/keystone/commit/1ed54951a3f6c7ee6d5964c6d1ab0a2fc3e278cc', 'message': ""Remove strutils and timeutils from openstack-common.conf\n\nSince Keystone is changed to use strutils and timeutils from\noslo.utils, it doesn't directly use these modules from\noslo-incubator anymore, as such, they're removed from\nopenstack-common.conf.\n\nSince these modules are still used internally by oslo-incubator\nmodules, they aren't removed from keystone in a sync.\n\nChange-Id: Ia31e455c6441cfbfbe33271ccdef1030a8c3d5cc\n""}]",0,112158,1ed54951a3f6c7ee6d5964c6d1ab0a2fc3e278cc,23,9,2,6486,,,0,"Remove strutils and timeutils from openstack-common.conf

Since Keystone is changed to use strutils and timeutils from
oslo.utils, it doesn't directly use these modules from
oslo-incubator anymore, as such, they're removed from
openstack-common.conf.

Since these modules are still used internally by oslo-incubator
modules, they aren't removed from keystone in a sync.

Change-Id: Ia31e455c6441cfbfbe33271ccdef1030a8c3d5cc
",git fetch https://review.opendev.org/openstack/keystone refs/changes/58/112158/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack-common.conf'],1,4c132ba6de2298fbcc86057facb5d0202579775b,oslo.utils,,module=strutilsmodule=timeutils,0,2
openstack%2Fkeystone~master~I39365042de913e1b3edaf849e3f5578cef0b7b02,openstack/keystone,master,I39365042de913e1b3edaf849e3f5578cef0b7b02,Use functions in oslo.utils,MERGED,2014-08-05 22:12:00.000000000,2014-08-10 01:32:12.000000000,2014-08-10 01:32:12.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 10697}, {'_account_id': 10873}, {'_account_id': 11387}]","[{'number': 1, 'created': '2014-08-05 22:12:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/866602e50ecb6f47c3b2354ce8c9aa652a7aaeea', 'message': 'Use functions in oslo.utils\n\nKeystone was using functions in oslo-incubator that have been\ngraduated into oslo.utils. This changes the function calls to use\nthe functions in oslo.utils.\n\nChange-Id: I39365042de913e1b3edaf849e3f5578cef0b7b02\n'}, {'number': 2, 'created': '2014-08-09 12:49:31.000000000', 'files': ['keystone/auth/controllers.py', 'keystone/models/token_model.py', 'keystone/auth/plugins/token.py', 'keystone/trust/backends/sql.py', 'keystone/contrib/revoke/model.py', 'keystone/tests/unit/token/test_token_model.py', 'keystone/trust/backends/kvs.py', 'keystone/tests/test_v3.py', 'keystone/common/sql/migrate_repo/versions/042_endpoint_enabled.py', 'keystone/tests/test_backend.py', 'keystone/token/controllers.py', 'keystone/token/providers/common.py', 'keystone/token/persistence/core.py', 'keystone/tests/test_revoke.py', 'keystone/trust/controllers.py', 'keystone/tests/test_v3_os_revoke.py', 'keystone/contrib/access/core.py', 'keystone/token/persistence/backends/kvs.py', 'keystone/auth/plugins/oauth1.py', 'keystone/tests/test_auth.py', 'keystone/token/provider.py', 'keystone/tests/test_keystoneclient.py', 'keystone/token/persistence/backends/sql.py', 'keystone/common/cache/backends/mongo.py', 'keystone/contrib/oauth1/backends/sql.py', 'keystone/contrib/revoke/controllers.py', 'keystone/tests/test_token_provider.py', 'keystone/tests/test_v3_auth.py', 'keystone/contrib/revoke/core.py', 'keystone/common/sql/migrate_repo/versions/044_service_enabled.py', 'keystone/tests/test_backend_kvs.py', 'keystone/contrib/revoke/backends/kvs.py', 'keystone/exception.py', 'keystone/contrib/federation/utils.py', 'keystone/contrib/oauth1/controllers.py', 'keystone/common/utils.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/b763d613b411b89d98088a1800f12e572fc4da5a', 'message': 'Use functions in oslo.utils\n\nKeystone was using functions in oslo-incubator that have been\ngraduated into oslo.utils. This changes the function calls to use\nthe functions in oslo.utils.\n\nChange-Id: I39365042de913e1b3edaf849e3f5578cef0b7b02\n'}]",0,112157,b763d613b411b89d98088a1800f12e572fc4da5a,20,7,2,6486,,,0,"Use functions in oslo.utils

Keystone was using functions in oslo-incubator that have been
graduated into oslo.utils. This changes the function calls to use
the functions in oslo.utils.

Change-Id: I39365042de913e1b3edaf849e3f5578cef0b7b02
",git fetch https://review.opendev.org/openstack/keystone refs/changes/57/112157/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/auth/controllers.py', 'keystone/models/token_model.py', 'keystone/auth/plugins/token.py', 'keystone/trust/backends/sql.py', 'keystone/contrib/revoke/model.py', 'keystone/tests/unit/token/test_token_model.py', 'keystone/trust/backends/kvs.py', 'keystone/tests/test_v3.py', 'keystone/common/sql/migrate_repo/versions/042_endpoint_enabled.py', 'keystone/tests/test_backend.py', 'keystone/token/controllers.py', 'keystone/token/providers/common.py', 'keystone/token/persistence/core.py', 'keystone/tests/test_revoke.py', 'keystone/trust/controllers.py', 'keystone/tests/test_v3_os_revoke.py', 'keystone/contrib/access/core.py', 'keystone/token/persistence/backends/kvs.py', 'keystone/auth/plugins/oauth1.py', 'keystone/tests/test_auth.py', 'keystone/token/provider.py', 'keystone/tests/test_keystoneclient.py', 'keystone/token/persistence/backends/sql.py', 'keystone/common/cache/backends/mongo.py', 'keystone/contrib/oauth1/backends/sql.py', 'keystone/contrib/revoke/controllers.py', 'keystone/tests/test_token_provider.py', 'keystone/tests/test_v3_auth.py', 'keystone/contrib/revoke/core.py', 'keystone/common/sql/migrate_repo/versions/044_service_enabled.py', 'keystone/tests/test_backend_kvs.py', 'keystone/contrib/revoke/backends/kvs.py', 'keystone/exception.py', 'keystone/contrib/federation/utils.py', 'keystone/contrib/oauth1/controllers.py', 'keystone/common/utils.py']",36,866602e50ecb6f47c3b2354ce8c9aa652a7aaeea,oslo.utils,from oslo.utils import strutils,from keystone.openstack.common import strutils,48,37
openstack%2Foslo-incubator~master~I6b0c5157d40642d871c4bb77deef040a574266a0,openstack/oslo-incubator,master,I6b0c5157d40642d871c4bb77deef040a574266a0,Centralize bash-completion in Novaclient,MERGED,2014-06-20 00:12:28.000000000,2014-08-10 00:28:18.000000000,2014-08-10 00:28:17.000000000,"[{'_account_id': 3}, {'_account_id': 475}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-06-20 00:12:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/47fb8928929eed962fe3e2d14660a58fbbf1fc65', 'message': ""Centralize bash-completion in Novaclient\n\nCurrently the bash-completion code lives partly in Oslo and partly in\nNovaclient which makes it difficult to improve the code as the changes need to\nbe made to two separate projects.\n\nAs there aren't any other clients using bash-completion yet, we should\ncentralize the code in Novaclient while we improve it, and when the API\nstabilizes, move it back *in it's entirety*.\n\nThis corresponding patch to centralize the functionality in Novaclient is\nhere:\n\n    https://review.openstack.org/#/c/101373/\n\nChange-Id: I6b0c5157d40642d871c4bb77deef040a574266a0\nClose-Bug: 1332270\n""}, {'number': 2, 'created': '2014-06-20 00:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/f8bf3688d8fe7b84272ad5f6e64f42770a0529d5', 'message': ""Centralize bash-completion in Novaclient\n\nCurrently the bash-completion code lives partly in Oslo and partly in\nNovaclient which makes it difficult to improve the code as the changes need to\nbe made to two separate projects.\n\nAs there aren't any other clients using bash-completion yet, we should\ncentralize the code in Novaclient while we improve it, and when the API\nstabilizes, move it back *in it's entirety*.\n\nThis corresponding patch to centralize the functionality in Novaclient is\nhere:\n\n    https://review.openstack.org/#/c/101373/\n\nChange-Id: I6b0c5157d40642d871c4bb77deef040a574266a0\nClose-Bug: 1332270\n""}, {'number': 3, 'created': '2014-08-08 21:59:39.000000000', 'files': ['openstack/common/apiclient/base.py', 'tests/unit/apiclient/test_base.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/5e006857ea9860176f786a80bff826c05a14b89b', 'message': ""Centralize bash-completion in Novaclient\n\nCurrently the bash-completion code lives partly in Oslo and partly in\nNovaclient which makes it difficult to improve the code as the changes need to\nbe made to two separate projects.\n\nAs there aren't any other clients using bash-completion yet, we should\ncentralize the code in Novaclient while we improve it, and when the API\nstabilizes, move it back *in it's entirety*.\n\nThis corresponding patch to centralize the functionality in Novaclient is\nhere:\n\n    https://review.openstack.org/#/c/101373/\n\nChange-Id: I6b0c5157d40642d871c4bb77deef040a574266a0\nCloses-Bug: 1332270\n""}]",0,101376,5e006857ea9860176f786a80bff826c05a14b89b,28,5,3,475,,,0,"Centralize bash-completion in Novaclient

Currently the bash-completion code lives partly in Oslo and partly in
Novaclient which makes it difficult to improve the code as the changes need to
be made to two separate projects.

As there aren't any other clients using bash-completion yet, we should
centralize the code in Novaclient while we improve it, and when the API
stabilizes, move it back *in it's entirety*.

This corresponding patch to centralize the functionality in Novaclient is
here:

    https://review.openstack.org/#/c/101373/

Change-Id: I6b0c5157d40642d871c4bb77deef040a574266a0
Closes-Bug: 1332270
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/76/101376/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/apiclient/base.py'],1,47fb8928929eed962fe3e2d14660a58fbbf1fc65,bug/1332270,,"from openstack.common import uuidutils self._init_completion_cache() def _init_completion_cache(self): cache_write = getattr(self.manager, 'write_to_completion_cache', None) if not cache_write: return # NOTE(sirp): ensure `id` is already present because if it isn't we'll # enter an infinite loop of __getattr__ -> get -> __init__ -> # __getattr__ -> ... if 'id' in self.__dict__ and uuidutils.is_uuid_like(self.id): cache_write('uuid', self.id) if self.human_id: cache_write('human_id', self.human_id)",0,16
openstack%2Fcinder~master~I39d60d1cc7d6c37455852de24356e3e262da8a86,openstack/cinder,master,I39d60d1cc7d6c37455852de24356e3e262da8a86,Imported Translations from Transifex,MERGED,2014-07-06 06:03:14.000000000,2014-08-10 00:26:42.000000000,2014-08-09 15:05:17.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 2243}, {'_account_id': 6547}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 9751}, {'_account_id': 10327}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12018}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}]","[{'number': 1, 'created': '2014-07-06 06:03:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/47899187f49d1cd8d425cf94feeaeefa1dfb53bf', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 2, 'created': '2014-07-07 06:03:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0c9d42c0e2fc3468378392153918fbb8c35af750', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 3, 'created': '2014-07-08 06:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ae73a4a9fad85fbaca035f153643be9e3b753443', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 4, 'created': '2014-07-09 06:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/94f911f98f4bc66f45f1400428309d7a1c66c2e1', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 5, 'created': '2014-07-10 06:03:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/731fe9c563dfaa00ec0edd2e3bae9e0e964d986a', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 6, 'created': '2014-07-11 06:03:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/84e6d099f428f636f36716692f70135c919fd1b7', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 7, 'created': '2014-07-15 06:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5c4f220f1e4fa0a03670913c548c5079d2a8a378', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 8, 'created': '2014-07-16 06:08:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b0e495739decc7c569f3e7cefde50aabb412fec9', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 9, 'created': '2014-07-17 06:07:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/64f79f9071cef552cf3314a667dd6351fbb46b64', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 10, 'created': '2014-07-18 06:08:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b596955ead4b6dde0cbd4119d330d0cdaf625dbe', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 11, 'created': '2014-07-19 06:07:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ebe06b581ab04c61df8908b09d86da48a162be9a', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 12, 'created': '2014-07-20 06:07:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0ccfc4053dbfb4f306444b35d2728133f4edcd77', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 13, 'created': '2014-07-21 06:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/65f1da54e9dab4efef7612dd9b4473a895428226', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 14, 'created': '2014-07-22 06:09:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5f6923656ace6d8e72080b26e2f376662926efe7', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 15, 'created': '2014-07-23 06:11:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/87da9e7d597f7764895ceadb9499636a2bfa2664', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 16, 'created': '2014-07-24 06:08:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e5277a5677bebfee4fd6bd849849639a776337de', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 17, 'created': '2014-07-25 06:08:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3a4d81a94816d39be1cd43b9740659fd5abd3c76', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 18, 'created': '2014-07-27 06:08:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/660372261335a6388a56027b835670a744c94305', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 19, 'created': '2014-07-28 06:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1a3f178c5a1f5bc79e95c61cbde6e37974882bbc', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 20, 'created': '2014-07-29 06:06:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c38836a82850b88b6878346f9e3709245d665d47', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 21, 'created': '2014-07-30 06:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c20b6a7c33fa619867871828115a3011c7ead487', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 22, 'created': '2014-07-31 06:08:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8cfc2a1c82374dd711d7361d207ec2a66cab1d50', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 23, 'created': '2014-08-01 06:08:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cb659389b3739f4232888f40468f3d73d78f0dab', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 24, 'created': '2014-08-02 06:08:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/39c592499f8ecd427918f8cc28b8901137622102', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 25, 'created': '2014-08-03 06:08:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/60c1ba165dc1ca13efed7f8bffe78c7728ecb505', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 26, 'created': '2014-08-04 06:07:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fea66b63ace0eefa9bfa71816e1ee3c6547e8e12', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 27, 'created': '2014-08-05 06:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/79abdff03b48c2572e560adc27ad9be062b5bc5b', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 28, 'created': '2014-08-06 06:08:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f8165ec2ffa0a16dc1e7bfca47ad3db13a907eb7', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 29, 'created': '2014-08-08 06:08:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dce9dc3815b7cc8ec27beb65983830a89da671f9', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}, {'number': 30, 'created': '2014-08-09 06:08:20.000000000', 'files': ['cinder/locale/tr_TR/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/ko_KR/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/pt_BR/LC_MESSAGES/cinder-log-info.po', 'cinder/locale/zh_CN/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/te_IN/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/en_GB/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/zh_CN/LC_MESSAGES/cinder-log-info.po', 'cinder/locale/it/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/ko_KR/LC_MESSAGES/cinder-log-info.po', 'cinder/locale/es/LC_MESSAGES/cinder-log-info.po', 'cinder/locale/en_US/LC_MESSAGES/cinder.po', 'cinder/locale/te_IN/LC_MESSAGES/cinder-log-info.po', 'cinder/locale/te_IN/LC_MESSAGES/cinder-log-warning.po', 'cinder/locale/cinder.pot', 'cinder/locale/en_GB/LC_MESSAGES/cinder-log-info.po', 'cinder/locale/en_GB/LC_MESSAGES/cinder-log-warning.po', 'cinder/locale/fr/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/pt_BR/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/cinder-log-warning.pot', 'cinder/locale/de/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/fr/LC_MESSAGES/cinder-log-warning.po', 'cinder/locale/ja/LC_MESSAGES/cinder-log-info.po', 'cinder/locale/ru/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/cinder-log-info.pot', 'cinder/locale/it/LC_MESSAGES/cinder-log-info.po', 'cinder/locale/cs/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/zh_TW/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/es/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/ja/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/en_AU/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/en_AU/LC_MESSAGES/cinder-log-info.po', 'cinder/locale/te_IN/LC_MESSAGES/cinder-log-critical.po', 'cinder/locale/cinder-log-error.pot', 'cinder/locale/de/LC_MESSAGES/cinder-log-info.po', 'cinder/locale/zh_TW/LC_MESSAGES/cinder-log-info.po', 'cinder/locale/en_GB/LC_MESSAGES/cinder-log-critical.po', 'cinder/locale/fr/LC_MESSAGES/cinder-log-info.po'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3802cec04f5aa7c96ed4d3e742a2495f00b7933c', 'message': 'Imported Translations from Transifex\n\nChange-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86\n'}]",0,105000,3802cec04f5aa7c96ed4d3e742a2495f00b7933c,194,17,30,11131,,,0,"Imported Translations from Transifex

Change-Id: I39d60d1cc7d6c37455852de24356e3e262da8a86
",git fetch https://review.opendev.org/openstack/cinder refs/changes/00/105000/25 && git format-patch -1 --stdout FETCH_HEAD,['cinder/locale/cs/LC_MESSAGES/cinder-log-error.po'],1,47899187f49d1cd8d425cf94feeaeefa1dfb53bf,transifex/translations,"# Translations template for cinder. # Copyright (C) 2014 ORGANIZATION # This file is distributed under the same license as the cinder project. # # Translators: # Zbynk Schwarz <zbynek.schwarz@gmail.com>, 2014 msgid """" msgstr """" ""Project-Id-Version: Cinder\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2014-07-06 06:03+0000\n"" ""PO-Revision-Date: 2014-07-05 19:02+0000\n"" ""Last-Translator: Zbynk Schwarz <zbynek.schwarz@gmail.com>\n"" ""Language-Team: Czech (http://www.transifex.com/projects/p/cinder/language/"" ""cs/)\n"" ""Language: cs\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 1.3\n"" ""Plural-Forms: nplurals=3; plural=(n==1) ? 0 : (n>=2 && n<=4) ? 1 : 2;\n"" #: cinder/openstack/common/periodic_task.py:179 #, python-format msgid ""Error during %(full_task_name)s: %(e)s"" msgstr ""Chyba pi %(full_task_name)s: %(e)s"" #: cinder/openstack/common/db/api.py:72 msgid ""DB exceeded retry limit."" msgstr ""DB pekroila limit novch pokus"" #: cinder/openstack/common/db/api.py:76 msgid ""DB connection error."" msgstr ""Chyba pipojen k DB."" #: cinder/openstack/common/db/sqlalchemy/session.py:460 msgid ""DB exception wrapped."" msgstr ""Vyjmka DB zabalena."" #: cinder/openstack/common/db/sqlalchemy/test_migrations.py:267 #, python-format msgid ""Failed to migrate to version %s on engine %s"" msgstr ""Nelze pejt na verzi %s v databzovm jdru %s"" ",,43,0
openstack%2Foslo-incubator~master~Ibd4c678d068ca10a53a72520f7eeffcc84133f07,openstack/oslo-incubator,master,Ibd4c678d068ca10a53a72520f7eeffcc84133f07,Handle non-openstack errors gracefully,MERGED,2014-08-06 17:23:35.000000000,2014-08-10 00:25:37.000000000,2014-08-10 00:25:36.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-08-06 17:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/65878dea8b16e1aca0b7d78738462ae0e04c2052', 'message': 'Handle non-openstack errors gracefully\n\nThe http error is not guaranteed to come directly from an OpenStack\nservice. Even if it does, it may not conform to the usual structure.\nThat kind of response should be handled properly anyway.\n\nChange-Id: Ibd4c678d068ca10a53a72520f7eeffcc84133f07\nCloses-bug: 1353594\n'}, {'number': 2, 'created': '2014-08-06 17:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/0a667bb75c11f083da9410a50edef0e604139fe3', 'message': 'Handle non-openstack errors gracefully\n\nThe http error is not guaranteed to come directly from an OpenStack\nservice. Even if it does, it may not conform to the usual structure.\nThat kind of response should be handled properly anyway.\n\nChange-Id: Ibd4c678d068ca10a53a72520f7eeffcc84133f07\nCloses-bug: 1353594\n'}, {'number': 3, 'created': '2014-08-06 17:34:58.000000000', 'files': ['openstack/common/apiclient/exceptions.py', 'tests/unit/apiclient/test_exceptions.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/4ef01931d5e8207133ef25150ef800430d5e91d1', 'message': 'Handle non-openstack errors gracefully\n\nThe http error is not guaranteed to come directly from an OpenStack\nservice. Even if it does, it may not conform to the usual structure.\nThat kind of response should be handled properly anyway.\n\nChange-Id: Ibd4c678d068ca10a53a72520f7eeffcc84133f07\nCloses-bug: 1277565\n'}]",0,112364,4ef01931d5e8207133ef25150ef800430d5e91d1,14,3,3,1528,,,0,"Handle non-openstack errors gracefully

The http error is not guaranteed to come directly from an OpenStack
service. Even if it does, it may not conform to the usual structure.
That kind of response should be handled properly anyway.

Change-Id: Ibd4c678d068ca10a53a72520f7eeffcc84133f07
Closes-bug: 1277565
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/64/112364/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/apiclient/exceptions.py', 'tests/unit/apiclient/test_exceptions.py']",2,65878dea8b16e1aca0b7d78738462ae0e04c2052,bug/1277565," def assert_exception(self, ex_cls, method, url, status_code, json_data, check_description=True): if check_description: self.assertEqual(ex.message, json_data[""error""][""message""]) self.assertEqual(ex.details, json_data[""error""][""details""]) def test_from_response_non_openstack(self): method = ""POST"" url = ""/fake-unknown"" status_code = 400 json_data = {""alien"": 123} self.assert_exception( exceptions.BadRequest, method, url, status_code, json_data, check_description=False)"," def assert_exception(self, ex_cls, method, url, status_code, json_data): self.assertEqual(ex.message, json_data[""error""][""message""]) self.assertEqual(ex.details, json_data[""error""][""details""])",16,5
openstack%2Fneutron~master~Ib1f1ee16e0178d0362ff2b731957f1f52dd9a596,openstack/neutron,master,Ib1f1ee16e0178d0362ff2b731957f1f52dd9a596,ofagent: Remove network_delete method,MERGED,2014-07-29 02:49:41.000000000,2014-08-09 22:49:06.000000000,2014-08-08 19:32:32.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 704}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 11825}]","[{'number': 1, 'created': '2014-07-29 02:49:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a1e61e7f7185303905ad6f51bf6fe66c5f36a26e', 'message': ""ofagent: Remove network_delete method\n\nRemoving local_vlan_map entry here makes later port_unbound no-op.\nWhile it isn't a problem right now, it will be when per-port cleanup\nis introduced.\nThis commit simply removes network_delete method.  The local_vlan_map\nwill be cleaned up when the last port on the network is removed.\n\nRelated: blueprint ofagent-merge-bridges\nChange-Id: Ib1f1ee16e0178d0362ff2b731957f1f52dd9a596\n""}, {'number': 2, 'created': '2014-08-04 03:13:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3d88432853e9004d82dbb3f5431d2d6d06ed2928', 'message': ""ofagent: Remove network_delete method\n\nRemoving local_vlan_map entry here makes later port_unbound no-op.\nWhile it isn't a problem right now, it will be when per-port cleanup\nis introduced.\nThis commit simply removes network_delete method.  The local_vlan_map\nwill be cleaned up when the last port on the network is removed.\n\nRelated: blueprint ofagent-merge-bridges\nChange-Id: Ib1f1ee16e0178d0362ff2b731957f1f52dd9a596\n""}, {'number': 3, 'created': '2014-08-06 16:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/016d085f1a5dad483ce6daf5687c2837bff8e636', 'message': ""ofagent: Remove network_delete method\n\nRemoving local_vlan_map entry here makes later port_unbound no-op.\nWhile it isn't a problem right now, it will be when per-port cleanup\nis introduced.\nThis commit simply removes network_delete method.  The local_vlan_map\nwill be cleaned up when the last port on the network is removed.\n\nRelated: blueprint ofagent-merge-bridges\nChange-Id: Ib1f1ee16e0178d0362ff2b731957f1f52dd9a596\n""}, {'number': 4, 'created': '2014-08-08 15:38:42.000000000', 'files': ['neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/tests/unit/ofagent/test_ofa_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/afe9097666274f8f589e283b5671caa81863b246', 'message': ""ofagent: Remove network_delete method\n\nRemoving local_vlan_map entry here makes later port_unbound no-op.\nWhile it isn't a problem right now, it will be when per-port cleanup\nis introduced.\nThis commit simply removes network_delete method.  The local_vlan_map\nwill be cleaned up when the last port on the network is removed.\n\nRelated: blueprint ofagent-merge-bridges\nChange-Id: Ib1f1ee16e0178d0362ff2b731957f1f52dd9a596\n""}]",0,110188,afe9097666274f8f589e283b5671caa81863b246,78,23,4,6854,,,0,"ofagent: Remove network_delete method

Removing local_vlan_map entry here makes later port_unbound no-op.
While it isn't a problem right now, it will be when per-port cleanup
is introduced.
This commit simply removes network_delete method.  The local_vlan_map
will be cleaned up when the last port on the network is removed.

Related: blueprint ofagent-merge-bridges
Change-Id: Ib1f1ee16e0178d0362ff2b731957f1f52dd9a596
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/110188/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/tests/unit/ofagent/test_ofa_neutron_agent.py']",2,a1e61e7f7185303905ad6f51bf6fe66c5f36a26e,bp/ofagent-merge-bridges,," def test_network_delete(self): with contextlib.nested( mock.patch.object(self.agent, ""reclaim_local_vlan""), mock.patch.object(self.agent.tun_br, ""cleanup_tunnel_port"") ) as (recl_fn, clean_tun_fn): self.agent.network_delete(""unused_context"", network_id=""123"") self.assertFalse(recl_fn.called) self.agent.local_vlan_map[""123""] = ""LVM object"" self.agent.network_delete(""unused_context"", network_id=""123"") self.assertFalse(clean_tun_fn.called) recl_fn.assert_called_with(""123"") ",0,24
openstack%2Fcinder~master~I1f361a8321fb02f03b4f3f3e2ef688fcf19514a3,openstack/cinder,master,I1f361a8321fb02f03b4f3f3e2ef688fcf19514a3,Use oslo.i18n,MERGED,2014-08-07 15:37:03.000000000,2014-08-09 22:43:52.000000000,2014-08-09 15:04:13.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 6601}, {'_account_id': 7198}, {'_account_id': 9751}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}]","[{'number': 1, 'created': '2014-08-07 15:37:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c321058c7622615a0db03c2d99be6d8db440d02b', 'message': ""Use oslo.i18n\n\noslo.i18n provides the i18n function that were provided by\noslo-incubator's gettextutils module.\n\nChange-Id: I1f361a8321fb02f03b4f3f3e2ef688fcf19514a3\n""}, {'number': 2, 'created': '2014-08-07 17:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/535c9d6070a41b3a45f3e1e2df9d230b60b545be', 'message': ""Use oslo.i18n\n\noslo.i18n provides the i18n function that were provided by\noslo-incubator's gettextutils module.\n\nChange-Id: I1f361a8321fb02f03b4f3f3e2ef688fcf19514a3\n""}, {'number': 3, 'created': '2014-08-08 22:26:43.000000000', 'files': ['cinder/scheduler/filter_scheduler.py', 'cinder/service.py', 'cinder/tests/test_misc.py', 'cinder/db/sqlalchemy/migrate_repo/manage.py', 'cinder/api/v1/volume_metadata.py', 'cinder/db/sqlalchemy/api.py', 'cinder/volume/drivers/ibm/ibmnas.py', 'cinder/volume/drivers/nfs.py', 'cinder/tests/api/contrib/test_backups.py', 'cinder/api/openstack/__init__.py', 'cinder/api/openstack/urlmap.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/windows/windows_utils.py', 'cinder/api/contrib/volume_actions.py', 'cinder/tests/test_ibm_xiv_ds8k.py', 'doc/source/devref/il8n.rst', 'cinder/volume/drivers/netapp/utils.py', 'cinder/scheduler/driver.py', 'cinder/transfer/api.py', 'cinder/policy.py', 'cinder/tests/api/middleware/test_faults.py', 'cinder/api/contrib/qos_specs_manage.py', 'cinder/volume/drivers/emc/emc_smis_iscsi.py', 'cinder/volume/drivers/netapp/eseries/iscsi.py', 'cinder/volume/drivers/hds/hds.py', 'cinder/volume/utils.py', 'cinder/tests/test_backup_ceph.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/tests/brick/test_brick_remotefs.py', 'cinder/api/contrib/types_manage.py', 'cinder/volume/drivers/ibm/storwize_svc/__init__.py', 'cinder/volume/drivers/huawei/huawei_utils.py', 'cinder/tests/test_glusterfs.py', 'cinder/brick/local_dev/lvm.py', 'cinder/zonemanager/utils.py', 'cinder/scheduler/flows/create_volume.py', 'bin/cinder-api', 'cinder/zonemanager/fc_zone_manager.py', 'cinder/keymgr/conf_key_mgr.py', 'cinder/scheduler/host_manager.py', 'cinder/volume/drivers/vmware/read_write_util.py', 'cinder/tests/test_volume_types.py', 'requirements.txt', 'cinder/api/v2/volumes.py', 'cinder/db/sqlalchemy/migrate_repo/versions/009_add_snapshot_metadata_table.py', 'cinder/api/contrib/volume_manage.py', 'cinder/tests/brick/test_brick_connector.py', 'cinder/api/common.py', 'cinder/wsgi.py', 'cinder/volume/drivers/san/hp/hp_lefthand_rest_proxy.py', 'cinder/scheduler/filters/capacity_filter.py', 'cinder/volume/drivers/huawei/huawei_t.py', 'cinder/volume/flows/api/create_volume.py', 'cinder/scheduler/manager.py', 'cinder/scheduler/scheduler_options.py', 'cinder/volume/drivers/huawei/rest_common.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py', 'cinder/db/sqlalchemy/migrate_repo/versions/001_cinder_init.py', 'cinder/volume/drivers/sheepdog.py', 'cinder/tests/integrated/api/client.py', 'cinder/volume/drivers/vmware/error_util.py', 'cinder/volume/drivers/san/hp/hp_3par_iscsi.py', 'cinder/volume/drivers/rbd.py', 'cinder/volume/drivers/pure.py', 'cinder/context.py', 'cinder/tests/test_netapp_nfs.py', 'cinder/volume/drivers/nexenta/nfs.py', 'cinder/volume/drivers/emc/emc_smis_common.py', 'cinder/volume/drivers/hds/iscsi.py', 'cinder/volume/flows/common.py', 'cinder/brick/initiator/linuxscsi.py', 'bin/cinder-rtstool', 'cinder/backup/drivers/tsm.py', 'cinder/volume/drivers/scality.py', 'cinder/volume/api.py', 'bin/cinder-manage', 'cinder/backup/manager.py', 'cinder/volume/drivers/block_device.py', 'cinder/api/contrib/volume_type_encryption.py', 'cinder/tests/test_backup_swift.py', 'cinder/brick/initiator/linuxfc.py', 'cinder/db/sqlalchemy/migrate_repo/versions/020_add_volume_admin_metadata_table.py', 'bin/cinder-volume', 'cinder/api/openstack/volume/__init__.py', 'cinder/quota.py', 'cinder/tests/fake_driver.py', 'cinder/volume/drivers/ibm/gpfs.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/volume/drivers/nexenta/jsonrpc.py', 'bin/cinder-volume-usage-audit', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/api/v2/snapshot_metadata.py', 'bin/cinder-all', 'cinder/api/contrib/services.py', 'cinder/volume/driver.py', 'cinder/api/middleware/sizelimit.py', 'cinder/volume/drivers/vmware/vmware_images.py', 'cinder/volume/qos_specs.py', 'cinder/tests/test_wsgi.py', 'cinder/api/xmlutil.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_client_cli.py', 'cinder/volume/manager.py', 'cinder/backup/api.py', 'cinder/volume/drivers/vmware/vim.py', 'cinder/volume/drivers/nimble.py', 'cinder/brick/iscsi/iscsi.py', 'cinder/brick/remotefs/remotefs.py', 'cinder/db/sqlalchemy/migrate_repo/versions/021_add_default_quota_class.py', 'cinder/volume/drivers/netapp/api.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/api/contrib/volume_unmanage.py', 'cinder/api/contrib/extended_snapshot_attributes.py', 'cinder/api/v2/limits.py', 'cinder/volume/drivers/san/hp/hp_lefthand_iscsi.py', 'cinder/exception.py', 'cinder/brick/exception.py', 'cinder/volume/drivers/coraid.py', 'cinder/volume/drivers/zadara.py', 'cinder/db/sqlalchemy/migrate_repo/versions/023_add_expire_reservations_index.py', 'cinder/volume/drivers/nexenta/iscsi.py', 'cinder/volume/iscsi.py', 'cinder/api/contrib/scheduler_hints.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_san_lookup_service.py', 'cinder/api/v1/limits.py', 'cinder/db/sqlalchemy/migrate_repo/versions/010_add_transfers_table.py', 'cinder/volume/drivers/san/hp/hp_msa_common.py', 'cinder/volume/drivers/windows/vhdutils.py', 'cinder/db/sqlalchemy/migrate_repo/versions/017_add_encryption_information.py', 'cinder/volume/drivers/vmware/io_util.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py', 'cinder/i18n.py', 'cinder/tests/test_netapp.py', 'cinder/api/sizelimit.py', 'cinder/db/sqlalchemy/migrate_repo/versions/008_add_backup.py', 'cinder/volume/drivers/lvm.py', 'cinder/api/extensions.py', 'cinder/api/v1/volumes.py', 'cinder/brick/initiator/connector.py', 'cinder/volume/drivers/eqlx.py', 'bin/cinder-backup', 'cinder/db/sqlalchemy/migrate_repo/versions/015_drop_migrations_table.py', 'cinder/backup/drivers/swift.py', 'cinder/image/image_utils.py', 'cinder/api/contrib/backups.py', 'cinder/volume/drivers/san/solaris.py', 'cinder/api/contrib/volume_transfer.py', 'cinder/api/v2/snapshots.py', 'cinder/api/openstack/wsgi.py', 'cinder/volume/drivers/huawei/__init__.py', 'cinder/api/contrib/quotas.py', 'cinder/api/middleware/fault.py', 'cinder/api/contrib/admin_actions.py', 'cinder/api/v2/types.py', 'cinder/api/contrib/types_extra_specs.py', 'cinder/volume/drivers/vmware/api.py', 'cinder/db/sqlalchemy/migrate_repo/versions/016_drop_sm_tables.py', 'cinder/volume/drivers/solidfire.py', 'cinder/zonemanager/fc_san_lookup_service.py', 'cinder/api/contrib/snapshot_actions.py', 'cinder/ssh_utils.py', 'cinder/backup/driver.py', 'cinder/volume/drivers/huawei/ssh_common.py', 'cinder/tests/test_storwize_svc.py', 'cinder/db/sqlalchemy/migrate_repo/versions/018_add_qos_specs.py', 'cinder/volume/drivers/ibm/storwize_svc/ssh.py', 'cinder/volume/drivers/san/hp/hp_3par_fc.py', 'cinder/api/contrib/quota_classes.py', 'cinder/common/sqlalchemyutils.py', 'cinder/tests/test_rbd.py', 'cinder/volume/drivers/hds/nfs.py', 'cinder/volume/drivers/nexenta/utils.py', 'tox.ini', 'cinder/api/middleware/auth.py', 'cinder/api/v1/snapshot_metadata.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_driver.py', 'cinder/volume/drivers/netapp/eseries/client.py', 'cinder/api/v2/volume_metadata.py', 'cinder/volume/volume_types.py', 'cinder/volume/drivers/san/san.py', 'cinder/api/auth.py', 'cinder/tests/zonemanager/test_brcd_fc_zone_driver.py', 'cinder/volume/drivers/san/hp/hp_lefthand_cliq_proxy.py', 'cinder/db/sqlalchemy/migrate_repo/versions/003_glance_metadata.py', 'cinder/volume/drivers/netapp/ssc_utils.py', 'cinder/volume/flows/manager/manage_existing.py', 'cinder/api/openstack/volume/versions.py', 'cinder/backup/drivers/ceph.py', 'cinder/volume/drivers/ibm/storwize_svc/helpers.py', 'bin/cinder-scheduler', 'cinder/common/config.py', 'cinder/quota_utils.py', 'cinder/db/sqlalchemy/migrate_repo/versions/002_quota_class.py', 'cinder/image/glance.py', 'cinder/flow_utils.py', 'cinder/db/sqlalchemy/migration.py', 'cinder/volume/drivers/vmware/volumeops.py', 'cinder/volume/drivers/netapp/common.py', 'cinder/api/contrib/hosts.py', 'cinder/utils.py', 'cinder/api/v1/snapshots.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ac33ad9ec9e3516ff1bc837a308848b403d7e7a6', 'message': ""Use oslo.i18n\n\noslo.i18n provides the i18n function that were provided by\noslo-incubator's gettextutils module.\n\nChange-Id: I1f361a8321fb02f03b4f3f3e2ef688fcf19514a3\n""}]",2,112613,ac33ad9ec9e3516ff1bc837a308848b403d7e7a6,29,12,3,6601,,,0,"Use oslo.i18n

oslo.i18n provides the i18n function that were provided by
oslo-incubator's gettextutils module.

Change-Id: I1f361a8321fb02f03b4f3f3e2ef688fcf19514a3
",git fetch https://review.opendev.org/openstack/cinder refs/changes/13/112613/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/scheduler/filter_scheduler.py', 'cinder/service.py', 'cinder/tests/test_misc.py', 'cinder/db/sqlalchemy/migrate_repo/manage.py', 'cinder/api/v1/volume_metadata.py', 'cinder/db/sqlalchemy/api.py', 'cinder/volume/drivers/ibm/ibmnas.py', 'cinder/volume/drivers/nfs.py', 'cinder/tests/api/contrib/test_backups.py', 'cinder/api/openstack/__init__.py', 'cinder/api/openstack/urlmap.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/windows/windows_utils.py', 'cinder/api/contrib/volume_actions.py', 'cinder/tests/test_ibm_xiv_ds8k.py', 'cinder/volume/drivers/netapp/utils.py', 'cinder/scheduler/driver.py', 'cinder/transfer/api.py', 'cinder/policy.py', 'cinder/tests/api/middleware/test_faults.py', 'cinder/api/contrib/qos_specs_manage.py', 'cinder/volume/drivers/emc/emc_smis_iscsi.py', 'cinder/volume/drivers/netapp/eseries/iscsi.py', 'cinder/volume/drivers/hds/hds.py', 'cinder/volume/utils.py', 'cinder/tests/test_backup_ceph.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/tests/brick/test_brick_remotefs.py', 'cinder/api/contrib/types_manage.py', 'cinder/volume/drivers/ibm/storwize_svc/__init__.py', 'cinder/volume/drivers/huawei/huawei_utils.py', 'cinder/tests/test_glusterfs.py', 'cinder/brick/local_dev/lvm.py', 'cinder/zonemanager/utils.py', 'cinder/scheduler/flows/create_volume.py', 'cinder/zonemanager/fc_zone_manager.py', 'cinder/keymgr/conf_key_mgr.py', 'cinder/scheduler/host_manager.py', 'cinder/volume/drivers/vmware/read_write_util.py', 'cinder/tests/test_volume_types.py', 'requirements.txt', 'cinder/api/v2/volumes.py', 'cinder/db/sqlalchemy/migrate_repo/versions/009_add_snapshot_metadata_table.py', 'cinder/api/contrib/volume_manage.py', 'cinder/tests/brick/test_brick_connector.py', 'cinder/api/common.py', 'cinder/wsgi.py', 'cinder/volume/drivers/san/hp/hp_lefthand_rest_proxy.py', 'cinder/scheduler/filters/capacity_filter.py', 'cinder/volume/drivers/huawei/huawei_t.py', 'cinder/volume/flows/api/create_volume.py', 'cinder/scheduler/manager.py', 'cinder/scheduler/scheduler_options.py', 'cinder/volume/drivers/huawei/rest_common.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py', 'cinder/db/sqlalchemy/migrate_repo/versions/001_cinder_init.py', 'cinder/volume/drivers/sheepdog.py', 'cinder/tests/integrated/api/client.py', 'cinder/volume/drivers/vmware/error_util.py', 'cinder/volume/drivers/san/hp/hp_3par_iscsi.py', 'cinder/volume/drivers/rbd.py', 'cinder/context.py', 'cinder/tests/test_netapp_nfs.py', 'cinder/volume/drivers/nexenta/nfs.py', 'cinder/volume/drivers/emc/emc_smis_common.py', 'cinder/volume/drivers/hds/iscsi.py', 'cinder/volume/flows/common.py', 'cinder/brick/initiator/linuxscsi.py', 'bin/cinder-rtstool', 'cinder/backup/drivers/tsm.py', 'cinder/volume/drivers/scality.py', 'cinder/volume/api.py', 'bin/cinder-manage', 'cinder/backup/manager.py', 'cinder/volume/drivers/block_device.py', 'cinder/api/contrib/volume_type_encryption.py', 'cinder/tests/test_backup_swift.py', 'cinder/brick/initiator/linuxfc.py', 'cinder/db/sqlalchemy/migrate_repo/versions/020_add_volume_admin_metadata_table.py', 'cinder/api/openstack/volume/__init__.py', 'cinder/quota.py', 'cinder/tests/fake_driver.py', 'cinder/volume/drivers/ibm/gpfs.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/volume/drivers/nexenta/jsonrpc.py', 'bin/cinder-volume-usage-audit', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/api/v2/snapshot_metadata.py', 'bin/cinder-all', 'cinder/api/contrib/services.py', 'cinder/volume/driver.py', 'cinder/api/middleware/sizelimit.py', 'cinder/volume/drivers/vmware/vmware_images.py', 'cinder/volume/qos_specs.py', 'cinder/tests/test_wsgi.py', 'cinder/api/xmlutil.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_client_cli.py', 'cinder/volume/manager.py', 'cinder/backup/api.py', 'cinder/volume/drivers/vmware/vim.py', 'cinder/volume/drivers/nimble.py', 'cinder/brick/iscsi/iscsi.py', 'cinder/brick/remotefs/remotefs.py', 'cinder/db/sqlalchemy/migrate_repo/versions/021_add_default_quota_class.py', 'cinder/volume/drivers/netapp/api.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/api/contrib/volume_unmanage.py', 'cinder/api/contrib/extended_snapshot_attributes.py', 'cinder/api/v2/limits.py', 'cinder/volume/drivers/san/hp/hp_lefthand_iscsi.py', 'cinder/exception.py', 'cinder/brick/exception.py', 'cinder/volume/drivers/coraid.py', 'cinder/volume/drivers/zadara.py', 'cinder/db/sqlalchemy/migrate_repo/versions/023_add_expire_reservations_index.py', 'cinder/volume/drivers/nexenta/iscsi.py', 'cinder/volume/iscsi.py', 'cinder/api/contrib/scheduler_hints.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_san_lookup_service.py', 'cinder/api/v1/limits.py', 'cinder/db/sqlalchemy/migrate_repo/versions/010_add_transfers_table.py', 'cinder/volume/drivers/san/hp/hp_msa_common.py', 'cinder/volume/drivers/windows/vhdutils.py', 'cinder/db/sqlalchemy/migrate_repo/versions/017_add_encryption_information.py', 'cinder/volume/drivers/vmware/io_util.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py', 'cinder/i18n.py', 'cinder/tests/test_netapp.py', 'cinder/api/sizelimit.py', 'cinder/db/sqlalchemy/migrate_repo/versions/008_add_backup.py', 'cinder/volume/drivers/lvm.py', 'cinder/api/extensions.py', 'cinder/api/v1/volumes.py', 'cinder/brick/initiator/connector.py', 'cinder/volume/drivers/eqlx.py', 'cinder/db/sqlalchemy/migrate_repo/versions/015_drop_migrations_table.py', 'cinder/backup/drivers/swift.py', 'cinder/image/image_utils.py', 'cinder/api/contrib/backups.py', 'cinder/volume/drivers/san/solaris.py', 'cinder/api/contrib/volume_transfer.py', 'cinder/api/v2/snapshots.py', 'cinder/api/openstack/wsgi.py', 'cinder/volume/drivers/huawei/__init__.py', 'cinder/api/contrib/quotas.py', 'cinder/api/middleware/fault.py', 'cinder/api/contrib/admin_actions.py', 'cinder/api/v2/types.py', 'cinder/api/contrib/types_extra_specs.py', 'cinder/volume/drivers/vmware/api.py', 'cinder/db/sqlalchemy/migrate_repo/versions/016_drop_sm_tables.py', 'cinder/volume/drivers/solidfire.py', 'cinder/zonemanager/fc_san_lookup_service.py', 'cinder/api/contrib/snapshot_actions.py', 'cinder/backup/driver.py', 'cinder/volume/drivers/huawei/ssh_common.py', 'cinder/tests/test_storwize_svc.py', 'cinder/db/sqlalchemy/migrate_repo/versions/018_add_qos_specs.py', 'cinder/volume/drivers/ibm/storwize_svc/ssh.py', 'cinder/volume/drivers/san/hp/hp_3par_fc.py', 'cinder/api/contrib/quota_classes.py', 'cinder/common/sqlalchemyutils.py', 'cinder/tests/test_rbd.py', 'cinder/volume/drivers/hds/nfs.py', 'cinder/volume/drivers/nexenta/utils.py', 'tox.ini', 'cinder/api/middleware/auth.py', 'cinder/api/v1/snapshot_metadata.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_driver.py', 'cinder/volume/drivers/netapp/eseries/client.py', 'cinder/api/v2/volume_metadata.py', 'cinder/volume/volume_types.py', 'cinder/volume/drivers/san/san.py', 'cinder/api/auth.py', 'cinder/tests/zonemanager/test_brcd_fc_zone_driver.py', 'cinder/volume/drivers/san/hp/hp_lefthand_cliq_proxy.py', 'cinder/db/sqlalchemy/migrate_repo/versions/003_glance_metadata.py', 'cinder/volume/drivers/netapp/ssc_utils.py', 'cinder/volume/flows/manager/manage_existing.py', 'cinder/api/openstack/volume/versions.py', 'cinder/backup/drivers/ceph.py', 'cinder/volume/drivers/ibm/storwize_svc/helpers.py', 'cinder/common/config.py', 'cinder/quota_utils.py', 'cinder/db/sqlalchemy/migrate_repo/versions/002_quota_class.py', 'cinder/image/glance.py', 'cinder/flow_utils.py', 'cinder/db/sqlalchemy/migration.py', 'cinder/volume/drivers/vmware/volumeops.py', 'cinder/volume/drivers/netapp/common.py', 'cinder/api/contrib/hosts.py', 'cinder/utils.py', 'cinder/api/v1/snapshots.py']",193,c321058c7622615a0db03c2d99be6d8db440d02b,i18n-library,from cinder.i18n import _,from cinder.openstack.common.gettextutils import _,302,209
openstack%2Ftempest~master~Ife983aab3cd79531c18ba5104a6dd8f1aaca6cd4,openstack/tempest,master,Ife983aab3cd79531c18ba5104a6dd8f1aaca6cd4,Remove skipping test_list_servers_by_admin_with_all_tenants test,MERGED,2014-08-07 22:58:46.000000000,2014-08-09 22:38:43.000000000,2014-08-09 22:38:42.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 6167}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-07 22:58:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0c5ea33f4c76ddc5ee44a2c60f047dc451d13a3d', 'message': ""Remove skiping test_list_servers_by_admin_with_all_tenants test\n\nAt change Ibb71c3a966f6c09b93e821781d4266d56d65950b, skip the\ntest_list_servers_by_admin_with_all_tenants test for changing\n'tenant' to 'project' in nova v3 REST API. But the v3 API plan is\nchanged, this kind of change will be introduce back when we have\nmicro-version. So remove the skip decorator.\n\nChange-Id: Ife983aab3cd79531c18ba5104a6dd8f1aaca6cd4\n""}, {'number': 2, 'created': '2014-08-07 23:04:53.000000000', 'files': ['tempest/api/compute/v3/admin/test_servers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/fac1bd6f6f715f4976d270996b041a01aa429d5f', 'message': ""Remove skipping test_list_servers_by_admin_with_all_tenants test\n\nAt change Ibb71c3a966f6c09b93e821781d4266d56d65950b, skip the\ntest_list_servers_by_admin_with_all_tenants test for changing\n'tenant' to 'project' in nova v3 REST API. But the v3 API plan is\nchanged, this kind of change will be introduce back when we have\nmicro-version. So remove the skip decorator.\n\nChange-Id: Ife983aab3cd79531c18ba5104a6dd8f1aaca6cd4\n""}]",0,112717,fac1bd6f6f715f4976d270996b041a01aa429d5f,14,5,2,5754,,,0,"Remove skipping test_list_servers_by_admin_with_all_tenants test

At change Ibb71c3a966f6c09b93e821781d4266d56d65950b, skip the
test_list_servers_by_admin_with_all_tenants test for changing
'tenant' to 'project' in nova v3 REST API. But the v3 API plan is
changed, this kind of change will be introduce back when we have
micro-version. So remove the skip decorator.

Change-Id: Ife983aab3cd79531c18ba5104a6dd8f1aaca6cd4
",git fetch https://review.opendev.org/openstack/tempest refs/changes/17/112717/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/v3/admin/test_servers.py'],1,0c5ea33f4c76ddc5ee44a2c60f047dc451d13a3d,(detached,, @test.skip_because(bug='1265416'),0,1
openstack%2Fnova~master~If1381f99fd7db420380288faf7b2f57553f69136,openstack/nova,master,If1381f99fd7db420380288faf7b2f57553f69136,Add extensible resources to resource tracker (2),MERGED,2014-07-25 16:02:08.000000000,2014-08-09 22:18:36.000000000,2014-08-07 12:17:21.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1030}, {'_account_id': 1849}, {'_account_id': 1926}, {'_account_id': 2271}, {'_account_id': 2835}, {'_account_id': 4573}, {'_account_id': 5170}, {'_account_id': 7166}, {'_account_id': 7461}, {'_account_id': 7641}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9107}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10373}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-25 16:02:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8618dcba6cc1b9f317810ada8b01bdf0cf0530a7', 'message': 'Add extensible resources to resource tracker (2)\n\nA resource plugin extension point is added to the resource\ntracker to allow the types of resources allocated at the compute\nnode to be extensible. Information maintained by these plug-ins\nis written to the compute_nodes table in the database. The\nscheduler uses the information in the compute_nodes table to\ndetermine scheduling decisions.\n\nA plugin that implements vcpu resource tracking is included\nand all other code for tracking vcpu has been removed. This\nexample ensures the plugins are tested in gate jobs.\n\nThis was previous merged and reverted due to a bug affecting\nironic CI. The bug was pre-existing but was exposed by the\nthat patch. This version is based on the bug fix.\n\nCo-Authored-By: Andrea Rosa  <andrea.rosa@hp.com>\nCo-Authored-By: Paul Murray  <pmurray@hp.com>\nThis is part of: blueprint extensible-resource-tracking\n\nChange-Id: If1381f99fd7db420380288faf7b2f57553f69136\n'}, {'number': 2, 'created': '2014-07-25 16:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c7d4dd5e4cd2c99019636f6b49c08133a6e263e6', 'message': 'Add extensible resources to resource tracker (2)\n\nA resource plugin extension point is added to the resource\ntracker to allow the types of resources allocated at the compute\nnode to be extensible. Information maintained by these plug-ins\nis written to the compute_nodes table in the database. The\nscheduler uses the information in the compute_nodes table to\ndetermine scheduling decisions.\n\nA plugin that implements vcpu resource tracking is included\nand all other code for tracking vcpu has been removed. This\nexample ensures the plugins are tested in gate jobs.\n\nThis was previously merged and reverted due to a bug affecting\nironic CI. The bug was pre-existing but was exposed by the\nthat patch. This change is based on the bug fix here:\nIcb19148660bca542a8120ecab064551d67ac28af and the previous\nversion of this change is here:\nI64108338e3c958ba1276aaf113a68861cbe286f5\n\nCo-Authored-By: Andrea Rosa  <andrea.rosa@hp.com>\nCo-Authored-By: Paul Murray  <pmurray@hp.com>\nThis is part of: blueprint extensible-resource-tracking\n\nChange-Id: If1381f99fd7db420380288faf7b2f57553f69136\n'}, {'number': 3, 'created': '2014-07-29 10:18:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1910797b016774c681c934d2af2a4a072e99a690', 'message': 'Add extensible resources to resource tracker (2)\n\nA resource plugin extension point is added to the resource\ntracker to allow the types of resources allocated at the compute\nnode to be extensible. Information maintained by these plug-ins\nis written to the compute_nodes table in the database. The\nscheduler uses the information in the compute_nodes table to\ndetermine scheduling decisions.\n\nA plugin that implements vcpu resource tracking is included\nand all other code for tracking vcpu has been removed. This\nexample ensures the plugins are tested in gate jobs.\n\nThis was previously merged and reverted due to a bug affecting\nironic CI. The bug was pre-existing but was exposed by the\nthat patch. This change is based on the bug fix here:\nIcb19148660bca542a8120ecab064551d67ac28af and the previous\nversion of this change is here:\nI64108338e3c958ba1276aaf113a68861cbe286f5\n\nCo-Authored-By: Andrea Rosa  <andrea.rosa@hp.com>\nCo-Authored-By: Paul Murray  <pmurray@hp.com>\nThis is part of: blueprint extensible-resource-tracking\n\nChange-Id: If1381f99fd7db420380288faf7b2f57553f69136\n'}, {'number': 4, 'created': '2014-07-31 13:20:52.000000000', 'files': ['nova/compute/resources/__init__.py', 'nova/tests/compute/test_resource_tracker.py', 'nova/compute/claims.py', 'nova/tests/compute/test_resources.py', 'nova/tests/compute/test_claims.py', 'nova/tests/compute/fake_resource_tracker.py', 'nova/tests/compute/test_stats.py', 'nova/compute/stats.py', 'nova/compute/resources/base.py', 'setup.cfg', 'nova/compute/resource_tracker.py', 'nova/compute/resources/vcpu.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/50c2d3d5d266e724c3f53d9a5323093a0a19b71a', 'message': 'Add extensible resources to resource tracker (2)\n\nA resource plugin extension point is added to the resource\ntracker to allow the types of resources allocated at the compute\nnode to be extensible. Information maintained by these plug-ins\nis written to the compute_nodes table in the database. The\nscheduler uses the information in the compute_nodes table to\ndetermine scheduling decisions.\n\nA plugin that implements vcpu resource tracking is included\nand all other code for tracking vcpu has been removed. This\nexample ensures the plugins are tested in gate jobs.\n\nThis was previously merged and reverted due to a bug affecting\nironic CI. The bug was pre-existing but was exposed by the\nthat patch. This change is based on the bug fix here:\nIcb19148660bca542a8120ecab064551d67ac28af and the previous\nversion of this change is here:\nI64108338e3c958ba1276aaf113a68861cbe286f5\n\nCo-Authored-By: Andrea Rosa  <andrea.rosa@hp.com>\nCo-Authored-By: Paul Murray  <pmurray@hp.com>\nThis is part of: blueprint extensible-resource-tracking\n\nChange-Id: If1381f99fd7db420380288faf7b2f57553f69136\n'}]",2,109643,50c2d3d5d266e724c3f53d9a5323093a0a19b71a,79,21,4,7461,,,0,"Add extensible resources to resource tracker (2)

A resource plugin extension point is added to the resource
tracker to allow the types of resources allocated at the compute
node to be extensible. Information maintained by these plug-ins
is written to the compute_nodes table in the database. The
scheduler uses the information in the compute_nodes table to
determine scheduling decisions.

A plugin that implements vcpu resource tracking is included
and all other code for tracking vcpu has been removed. This
example ensures the plugins are tested in gate jobs.

This was previously merged and reverted due to a bug affecting
ironic CI. The bug was pre-existing but was exposed by the
that patch. This change is based on the bug fix here:
Icb19148660bca542a8120ecab064551d67ac28af and the previous
version of this change is here:
I64108338e3c958ba1276aaf113a68861cbe286f5

Co-Authored-By: Andrea Rosa  <andrea.rosa@hp.com>
Co-Authored-By: Paul Murray  <pmurray@hp.com>
This is part of: blueprint extensible-resource-tracking

Change-Id: If1381f99fd7db420380288faf7b2f57553f69136
",git fetch https://review.opendev.org/openstack/nova refs/changes/43/109643/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/resources/__init__.py', 'nova/tests/compute/test_resource_tracker.py', 'nova/compute/claims.py', 'nova/tests/compute/test_resources.py', 'nova/tests/compute/test_claims.py', 'nova/tests/compute/fake_resource_tracker.py', 'nova/tests/compute/test_stats.py', 'nova/compute/stats.py', 'nova/compute/resources/base.py', 'setup.cfg', 'nova/compute/resource_tracker.py', 'nova/compute/resources/vcpu.py']",12,8618dcba6cc1b9f317810ada8b01bdf0cf0530a7,bp/extensible-resource-tracking,"# Copyright (c) 2013 Hewlett-Packard Development Company, L.P. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from nova.compute.resources import base from nova.openstack.common import log as logging LOG = logging.getLogger(__name__) class VCPU(base.Resource): """"""VCPU compute resource plugin. This is effectively a simple counter based on the vcpu requirement of each instance. """""" def __init__(self): # initialize to a 'zero' resource. # reset will be called to set real resource values self._total = 0 self._used = 0 def reset(self, resources, driver): # total vcpu is reset to the value taken from resources. self._total = int(resources['vcpus']) self._used = 0 def _get_requested(self, usage): return int(usage.get('vcpus', 0)) def _get_limit(self, limits): if limits and 'vcpu' in limits: return int(limits.get('vcpu')) def test(self, usage, limits): requested = self._get_requested(usage) limit = self._get_limit(limits) LOG.debug('Total CPUs: %(total)d VCPUs, used: %(used).02f VCPUs' % {'total': self._total, 'used': self._used}) if limit is None: # treat resource as unlimited: LOG.debug('CPUs limit not specified, defaulting to unlimited') return free = limit - self._used # Oversubscribed resource policy info: LOG.debug('CPUs limit: %(limit).02f VCPUs, free: %(free).02f VCPUs' % {'limit': limit, 'free': free}) if requested > free: return ('Free CPUs %(free).02f VCPUs < ' 'requested %(requested)d VCPUs' % {'free': free, 'requested': requested}) def add_instance(self, usage): requested = int(usage.get('vcpus', 0)) self._used += requested def remove_instance(self, usage): requested = int(usage.get('vcpus', 0)) self._used -= requested def write(self, resources): resources['vcpus'] = self._total resources['vcpus_used'] = self._used def report_free(self): free_vcpus = self._total - self._used LOG.debug('Free VCPUs: %s' % free_vcpus) ",,762,92
openstack%2Fopenstack-manuals~master~If818f00aaf06539749d4f28e8a8c5c8290e847a2,openstack/openstack-manuals,master,If818f00aaf06539749d4f28e8a8c5c8290e847a2,Arch Design Edits,MERGED,2014-08-08 19:01:51.000000000,2014-08-09 21:17:56.000000000,2014-08-09 21:17:55.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-08-08 19:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ccce1ef011c25a08449f1563502238455d19fc18', 'message': 'Arch Design Edits\n\nCleanup markup.\nImprove usage of project names and their capitalization.\nUse legacy networking (nova-networking) and OpenStack Networking in a\nconsistent way.\n\nChange-Id: If818f00aaf06539749d4f28e8a8c5c8290e847a2\n'}, {'number': 2, 'created': '2014-08-09 21:00:47.000000000', 'files': ['doc/arch-design/specialized/section_multi_hypervisor_specialized.xml', 'doc/arch-design/generalpurpose/section_tech_considerations_general_purpose.xml', 'doc/arch-design/storage_focus/section_architecture_storage_focus.xml', 'doc/arch-design/storage_focus/section_tech_considerations_storage_focus.xml', 'doc/arch-design/hybrid/section_tech_considerations_hybrid.xml', 'doc/arch-design/multi_site/section_tech_considerations_multi_site.xml', 'doc/arch-design/network_focus/section_prescriptive_examples_network_focus.xml', 'doc/arch-design/storage_focus/section_user_requirements_storage_focus.xml', 'doc/arch-design/network_focus/section_architecture_network_focus.xml', 'doc/arch-design/network_focus/section_tech_considerations_network_focus.xml', 'doc/arch-design/compute_focus/section_tech_considerations_compute_focus.xml', 'doc/arch-design/generalpurpose/section_architecture_general_purpose.xml', 'doc/arch-design/multi_site/section_prescriptive_examples_multi_site.xml', 'doc/arch-design/compute_focus/section_architecture_compute_focus.xml', 'doc/arch-design/compute_focus/section_prescriptive_examples_compute_focus.xml', 'doc/arch-design/storage_focus/section_operational_considerations_storage_focus.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/056398f6788a8cafbca59c19550985c1579bcefd', 'message': 'Arch Design Edits\n\nCleanup markup.\nImprove usage of project names and their capitalization.\nUse legacy networking (nova-networking) and OpenStack Networking in a\nconsistent way.\n\nChange-Id: If818f00aaf06539749d4f28e8a8c5c8290e847a2\n'}]",0,113000,056398f6788a8cafbca59c19550985c1579bcefd,14,4,2,6547,,,0,"Arch Design Edits

Cleanup markup.
Improve usage of project names and their capitalization.
Use legacy networking (nova-networking) and OpenStack Networking in a
consistent way.

Change-Id: If818f00aaf06539749d4f28e8a8c5c8290e847a2
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/00/113000/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/arch-design/specialized/section_multi_hypervisor_specialized.xml', 'doc/arch-design/generalpurpose/section_tech_considerations_general_purpose.xml', 'doc/arch-design/storage_focus/section_architecture_storage_focus.xml', 'doc/arch-design/storage_focus/section_tech_considerations_storage_focus.xml', 'doc/arch-design/hybrid/section_tech_considerations_hybrid.xml', 'doc/arch-design/multi_site/section_tech_considerations_multi_site.xml', 'doc/arch-design/network_focus/section_prescriptive_examples_network_focus.xml', 'doc/arch-design/storage_focus/section_user_requirements_storage_focus.xml', 'doc/arch-design/network_focus/section_architecture_network_focus.xml', 'doc/arch-design/network_focus/section_tech_considerations_network_focus.xml', 'doc/arch-design/compute_focus/section_tech_considerations_compute_focus.xml', 'doc/arch-design/generalpurpose/section_architecture_general_purpose.xml', 'doc/arch-design/multi_site/section_prescriptive_examples_multi_site.xml', 'doc/arch-design/compute_focus/section_architecture_compute_focus.xml', 'doc/arch-design/compute_focus/section_prescriptive_examples_compute_focus.xml', 'doc/arch-design/storage_focus/section_operational_considerations_storage_focus.xml']",16,ccce1ef011c25a08449f1563502238455d19fc18,arch-design-edits, available database solution to store the Block Storage databases is, available database solution to store the Cinder databases is,278,145
openstack%2Fpython-keystoneclient~master~Ic495e0f929b07f285240305d98f7d0fa73ecffce,openstack/python-keystoneclient,master,Ic495e0f929b07f285240305d98f7d0fa73ecffce,Fixes import grouping,MERGED,2014-08-06 13:41:09.000000000,2014-08-09 20:59:10.000000000,2014-08-09 20:59:09.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8978}]","[{'number': 1, 'created': '2014-08-06 13:41:09.000000000', 'files': ['keystoneclient/v3/contrib/federation/base.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/6c545ec37ddd42d526daebfc062528ed5710192e', 'message': 'Fixes import grouping\n\nLeft over from https://review.openstack.org/107393\n\nChange-Id: Ic495e0f929b07f285240305d98f7d0fa73ecffce\n'}]",0,112299,6c545ec37ddd42d526daebfc062528ed5710192e,39,6,1,7725,,,0,"Fixes import grouping

Left over from https://review.openstack.org/107393

Change-Id: Ic495e0f929b07f285240305d98f7d0fa73ecffce
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/99/112299/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/v3/contrib/federation/base.py'],1,6c545ec37ddd42d526daebfc062528ed5710192e,list_federated_projects,,,1,0
openstack%2Fopenstack-manuals~master~Ic82ae5235e1306fc13be81fa4971710321da5072,openstack/openstack-manuals,master,Ic82ae5235e1306fc13be81fa4971710321da5072,"Arch Design: Add glossentries, use common glossary",MERGED,2014-08-07 19:08:51.000000000,2014-08-09 20:57:47.000000000,2014-08-09 20:57:46.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 7751}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-08-07 19:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/df93b16f3bcc7c14413b6a921cd1527e06a4c8a1', 'message': 'WIP: Arch Design: Add glossentries, use common glossary\n\nUse the common documentation glossary.\nMove entries from ch_glossary to the common documentation glossary and\nadd glossterm so that the entry gets displayed in the glossary.\nRemove entries from the Arch Design specific glossary that are fully\nexplained in the text.\nRemove entries that are already in the common glossary and add glossterm\nfor them in the text.\nAdd glossary as final chapter to the manual.\n\nChange-Id: Ic82ae5235e1306fc13be81fa4971710321da5072\n'}, {'number': 2, 'created': '2014-08-07 19:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e379dad4f49d54c1cc82d9ce22c7f9f25af22a82', 'message': 'WIP: Arch Design: Add glossentries, use common glossary\n\nUse the common documentation glossary.\nMove entries from ch_glossary to the common documentation glossary and\nadd glossterm so that the entry gets displayed in the glossary.\nRemove entries from the Arch Design specific glossary that are fully\nexplained in the text.\nRemove entries that are already in the common glossary and add glossterm\nfor them in the text.\nAdd glossary as final chapter to the manual.\n\nChange-Id: Ic82ae5235e1306fc13be81fa4971710321da5072\n'}, {'number': 3, 'created': '2014-08-07 19:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/da7888961ac6de110a86cdabf311873a52c29912', 'message': 'WIP: Arch Design: Add glossentries, use common glossary\n\nUse the common documentation glossary.\nMove entries from ch_glossary to the common documentation glossary and\nadd glossterm so that the entry gets displayed in the glossary.\nRemove entries from the Arch Design specific glossary that are fully\nexplained in the text.\nRemove entries that are already in the common glossary and add glossterm\nfor them in the text.\nAdd glossary as final chapter to the manual.\n\nChange-Id: Ic82ae5235e1306fc13be81fa4971710321da5072\n'}, {'number': 4, 'created': '2014-08-07 19:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a24a5e02526d371279c52704a277a0a5b699bb80', 'message': 'WIP: Arch Design: Add glossentries, use common glossary\n\nUse the common documentation glossary.\nMove entries from ch_glossary to the common documentation glossary and\nadd glossterm so that the entry gets displayed in the glossary.\nRemove entries from the Arch Design specific glossary that are fully\nexplained in the text.\nRemove entries that are already in the common glossary and add glossterm\nfor them in the text.\nAdd glossary as final chapter to the manual.\n\nChange-Id: Ic82ae5235e1306fc13be81fa4971710321da5072\n'}, {'number': 5, 'created': '2014-08-07 20:05:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a311ccf99c2e25d7e30b33668471825af8da5665', 'message': 'WIP: Arch Design: Add glossentries, use common glossary\n\nUse the common documentation glossary.\nMove entries from ch_glossary to the common documentation glossary and\nadd glossterm so that the entry gets displayed in the glossary.\nRemove entries from the Arch Design specific glossary that are fully\nexplained in the text.\nRemove entries that are already in the common glossary and add glossterm\nfor them in the text.\nAdd glossary as final chapter to the manual.\n\nChange-Id: Ic82ae5235e1306fc13be81fa4971710321da5072\n'}, {'number': 6, 'created': '2014-08-08 09:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/03d18abf0483cf7e8b2daf451c50ba1b826f1eaa', 'message': 'WIP: Arch Design: Add glossentries, use common glossary\n\nUse the common documentation glossary.\nMove entries from ch_glossary to the common documentation glossary and\nadd glossterm so that the entry gets displayed in the glossary.\nRemove entries from the Arch Design specific glossary that are fully\nexplained in the text.\nRemove entries that are already in the common glossary and add glossterm\nfor them in the text.\nAdd glossary as final chapter to the manual.\n\nChange-Id: Ic82ae5235e1306fc13be81fa4971710321da5072\n'}, {'number': 7, 'created': '2014-08-08 10:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fcb7391f1a49fa8bd7718112ecf46fcabea05d1e', 'message': 'Arch Design: Add glossentries, use common glossary\n\nUse the common documentation glossary.\nMove entries from ch_glossary to the common documentation glossary and\nadd glossterm so that the entry gets displayed in the glossary.\nRemove entries from the Arch Design specific glossary that are fully\nexplained in the text.\nRemove entries that are already in the common glossary and add glossterm\nfor them in the text.\nAdd glossary as final chapter to the manual.\n\nThe remaining glossary entries need some further discussion.\n\nChange-Id: Ic82ae5235e1306fc13be81fa4971710321da5072\n'}, {'number': 8, 'created': '2014-08-08 19:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/64195e48c672557f06c765acc7c2a94d1274f2c9', 'message': 'Arch Design: Add glossentries, use common glossary\n\nUse the common documentation glossary.\nMove entries from ch_glossary to the common documentation glossary and\nadd glossterm so that the entry gets displayed in the glossary.\nRemove entries from the Arch Design specific glossary that are fully\nexplained in the text.\nRemove entries that are already in the common glossary and add glossterm\nfor them in the text.\nAdd glossary as final chapter to the manual.\n\nThe remaining glossary entries need some further discussion.\n\nPartial-Bug: #1354566\nChange-Id: Ic82ae5235e1306fc13be81fa4971710321da5072\n'}, {'number': 9, 'created': '2014-08-09 18:14:12.000000000', 'files': ['doc/arch-design/bk-openstack-arch-design.xml', 'doc/arch-design/massively_scalable/section_tech_considerations_massively_scalable.xml', 'doc/arch-design/generalpurpose/section_tech_considerations_general_purpose.xml', 'doc/arch-design/storage_focus/section_tech_considerations_storage_focus.xml', 'doc/arch-design/hybrid/section_architecture_hybrid.xml', 'doc/arch-design/network_focus/section_architecture_network_focus.xml', 'doc/arch-design/specialized/section_networking_specialized.xml', 'doc/arch-design/network_focus/section_tech_considerations_network_focus.xml', 'doc/glossary/glossary-terms.xml', 'doc/arch-design/ch_specialized.xml', 'doc/arch-design/generalpurpose/section_operational_considerations_general_purpose.xml', 'doc/arch-design/ch_glossary.xml', 'doc/arch-design/generalpurpose/section_architecture_general_purpose.xml', 'doc/arch-design/introduction/section_how_this_book_is_organized.xml', 'doc/arch-design/compute_focus/section_architecture_compute_focus.xml', 'doc/arch-design/compute_focus/section_prescriptive_examples_compute_focus.xml', 'doc/arch-design/ch_hybrid.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/20d15b80df3ab4d4a3eb7fe1731f5fd5482943e6', 'message': 'Arch Design: Add glossentries, use common glossary\n\nUse the common documentation glossary.\nMove entries from ch_glossary to the common documentation glossary and\nadd glossterm so that the entry gets displayed in the glossary.\nRemove entries from the Arch Design specific glossary that are fully\nexplained in the text.\nRemove entries that are already in the common glossary and add glossterm\nfor them in the text.\nAdd glossary as final chapter to the manual.\n\nThe remaining glossary entries need some further discussion.\n\nChange-Id: Ic82ae5235e1306fc13be81fa4971710321da5072\n'}]",2,112659,20d15b80df3ab4d4a3eb7fe1731f5fd5482943e6,41,7,9,6547,,,0,"Arch Design: Add glossentries, use common glossary

Use the common documentation glossary.
Move entries from ch_glossary to the common documentation glossary and
add glossterm so that the entry gets displayed in the glossary.
Remove entries from the Arch Design specific glossary that are fully
explained in the text.
Remove entries that are already in the common glossary and add glossterm
for them in the text.
Add glossary as final chapter to the manual.

The remaining glossary entries need some further discussion.

Change-Id: Ic82ae5235e1306fc13be81fa4971710321da5072
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/59/112659/8 && git format-patch -1 --stdout FETCH_HEAD,"['doc/arch-design/bk-openstack-arch-design.xml', 'doc/arch-design/massively_scalable/section_tech_considerations_massively_scalable.xml', 'doc/arch-design/ch_glossary.xml', 'doc/arch-design/generalpurpose/section_architecture_general_purpose.xml', 'doc/arch-design/network_focus/section_architecture_network_focus.xml', 'doc/arch-design/compute_focus/section_prescriptive_examples_compute_focus.xml', 'doc/arch-design/network_focus/section_tech_considerations_network_focus.xml', 'doc/glossary/glossary-terms.xml', 'doc/arch-design/ch_hybrid.xml']",9,df93b16f3bcc7c14413b6a921cd1527e06a4c8a1,glossary-move," interacts with Amazon Web Services). <glossterm baseform=""bursting"">Bursting</glossterm> into an external", interacts with Amazon Web Services). Bursting into an external,111,55
openstack%2Fnova~master~I2c19268ce6a20eaaed99eda97f63cd1babd5e380,openstack/nova,master,I2c19268ce6a20eaaed99eda97f63cd1babd5e380,Convert glance unit tests to not use stubs,MERGED,2014-07-28 02:07:40.000000000,2014-08-09 20:41:08.000000000,2014-08-09 20:41:06.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 642}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 8247}, {'_account_id': 8412}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-28 02:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b07636ecbe6b98629b217f2606c8c9c09ff18077', 'message': 'Convert glance unit tests to not use stubs\n\nTakes unit tests that were testing some helper functions in the\nnova.image.glance module out of the TestGlanceImageService test case\nclass and puts them in separate test classes that do not use the\nnova.tests.glance.stubs module -- instead, I converted them to just use\nthe simpler mock library and only test the specific things that the unit\ntests were supposed to test.\n\nChange-Id: I2c19268ce6a20eaaed99eda97f63cd1babd5e380\n'}, {'number': 2, 'created': '2014-07-30 16:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d1a6b62de665d153c28ca1c716443bb296caf6d0', 'message': 'Convert glance unit tests to not use stubs\n\nTakes unit tests that were testing some helper functions in the\nnova.image.glance module out of the TestGlanceImageService test case\nclass and puts them in separate test classes that do not use the\nnova.tests.glance.stubs module -- instead, I converted them to just use\nthe simpler mock library and only test the specific things that the unit\ntests were supposed to test.\n\nChange-Id: I2c19268ce6a20eaaed99eda97f63cd1babd5e380\n'}, {'number': 3, 'created': '2014-08-05 00:46:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/33c704787651012e521dc10176f6af328ecc0de0', 'message': 'Convert glance unit tests to not use stubs\n\nTakes unit tests that were testing some helper functions in the\nnova.image.glance module out of the TestGlanceImageService test case\nclass and puts them in separate test classes that do not use the\nnova.tests.glance.stubs module -- instead, I converted them to just use\nthe simpler mock library and only test the specific things that the unit\ntests were supposed to test.\n\nChange-Id: I2c19268ce6a20eaaed99eda97f63cd1babd5e380\n'}, {'number': 4, 'created': '2014-08-07 12:00:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2bf0ead6782d5e1e6d77325f8fb2303f405a075d', 'message': 'Convert glance unit tests to not use stubs\n\nTakes unit tests that were testing some helper functions in the\nnova.image.glance module out of the TestGlanceImageService test case\nclass and puts them in separate test classes that do not use the\nnova.tests.glance.stubs module -- instead, I converted them to just use\nthe simpler mock library and only test the specific things that the unit\ntests were supposed to test.\n\nChange-Id: I2c19268ce6a20eaaed99eda97f63cd1babd5e380\n'}, {'number': 5, 'created': '2014-08-07 15:30:33.000000000', 'files': ['nova/tests/image/test_glance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4113bc37984e7552c92e22c63d15f6f30d7c7d29', 'message': 'Convert glance unit tests to not use stubs\n\nTakes unit tests that were testing some helper functions in the\nnova.image.glance module out of the TestGlanceImageService test case\nclass and puts them in separate test classes that do not use the\nnova.tests.glance.stubs module -- instead, I converted them to just use\nthe simpler mock library and only test the specific things that the unit\ntests were supposed to test.\n\nChange-Id: I2c19268ce6a20eaaed99eda97f63cd1babd5e380\n'}]",7,109892,4113bc37984e7552c92e22c63d15f6f30d7c7d29,61,10,5,7,,,0,"Convert glance unit tests to not use stubs

Takes unit tests that were testing some helper functions in the
nova.image.glance module out of the TestGlanceImageService test case
class and puts them in separate test classes that do not use the
nova.tests.glance.stubs module -- instead, I converted them to just use
the simpler mock library and only test the specific things that the unit
tests were supposed to test.

Change-Id: I2c19268ce6a20eaaed99eda97f63cd1babd5e380
",git fetch https://review.opendev.org/openstack/nova refs/changes/92/109892/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/image/test_glance.py'],1,b07636ecbe6b98629b217f2606c8c9c09ff18077,bye-bye-image-service-stubs,"NOW_GLANCE_FORMAT = ""2010-10-11T10:30:22.000000"" class tzinfo(datetime.tzinfo): @staticmethod def utcoffset(*args, **kwargs): return datetime.timedelta() NOW_DATETIME = datetime.datetime(2010, 10, 11, 10, 30, 22, tzinfo=tzinfo()) class TestConversions(test.NoDBTestCase): def test_convert_timestamps_to_datetimes(self): fixture = {'name': None, 'properties': {}, 'status': None, 'is_public': None, 'created_at': NOW_GLANCE_FORMAT, 'updated_at': NOW_GLANCE_FORMAT, 'deleted_at': NOW_GLANCE_FORMAT} result = glance._convert_timestamps_to_datetimes(fixture) self.assertEqual(result['created_at'], NOW_DATETIME) self.assertEqual(result['updated_at'], NOW_DATETIME) self.assertEqual(result['deleted_at'], NOW_DATETIME) def test_extracting_missing_attributes(self): # Verify behavior from glance objects that are missing attributes class MyFakeGlanceImage(glance_stubs.FakeImage): def __init__(self, metadata): IMAGE_ATTRIBUTES = ['size', 'owner', 'id', 'created_at', 'updated_at', 'status', 'min_disk', 'min_ram', 'is_public'] raw = dict.fromkeys(IMAGE_ATTRIBUTES) raw.update(metadata) self.__dict__['raw'] = raw metadata = { 'id': 1, 'created_at': NOW_DATETIME, 'updated_at': NOW_DATETIME, } image = MyFakeGlanceImage(metadata) observed = glance._extract_attributes(image) expected = { 'id': 1, 'name': None, 'is_public': None, 'size': None, 'min_disk': None, 'min_ram': None, 'disk_format': None, 'container_format': None, 'checksum': None, 'created_at': NOW_DATETIME, 'updated_at': NOW_DATETIME, 'deleted_at': None, 'deleted': None, 'status': None, 'properties': {}, 'owner': None, } self.assertEqual(expected, observed) class TestExceptionTranslations(test.NoDBTestCase): def test_client_forbidden_to_imagenotauthed(self): in_exc = glanceclient.exc.Forbidden('123') out_exc = glance._translate_image_exception('123', in_exc) self.assertIsInstance(out_exc, exception.ImageNotAuthorized) def test_client_httpforbidden_converts_to_imagenotauthed(self): in_exc = glanceclient.exc.HTTPForbidden('123') out_exc = glance._translate_image_exception('123', in_exc) self.assertIsInstance(out_exc, exception.ImageNotAuthorized) def test_client_notfound_converts_to_imagenotfound(self): in_exc = glanceclient.exc.NotFound('123') out_exc = glance._translate_image_exception('123', in_exc) self.assertIsInstance(out_exc, exception.ImageNotFound) def test_client_httpnotfound_converts_to_imagenotfound(self): in_exc = glanceclient.exc.HTTPNotFound('123') out_exc = glance._translate_image_exception('123', in_exc) self.assertIsInstance(out_exc, exception.ImageNotFound)class TestGetImageService(test.NoDBTestCase): @mock.patch.object(glance.GlanceClientWrapper, '__init__', return_value=None) def test_get_remote_service_from_id(self, gcwi_mocked): id_or_uri = '123' _ignored, image_id = glance.get_remote_image_service( mock.sentinel.ctx, id_or_uri) self.assertEqual(image_id, id_or_uri) gcwi_mocked.assert_called_once_with() @mock.patch.object(glance.GlanceClientWrapper, '__init__', return_value=None) def test_get_remote_service_from_href(self, gcwi_mocked): id_or_uri = 'http://127.0.0.1/123' _ignored, image_id = glance.get_remote_image_service( mock.sentinel.ctx, id_or_uri) self.assertEqual('123', image_id) gcwi_mocked.assert_called_once_with(context=mock.sentinel.ctx, host='127.0.0.1', port=80, use_ssl=False) class NullWriter(object): """"""Used to test ImageService.get which takes a writer object."""""" def write(self, *arg, **kwargs): pass "," class NullWriter(object): """"""Used to test ImageService.get which takes a writer object."""""" def write(self, *arg, **kwargs): pass NOW_GLANCE_OLD_FORMAT = ""2010-10-11T10:30:22"" NOW_GLANCE_FORMAT = ""2010-10-11T10:30:22.000000"" class tzinfo(datetime.tzinfo): @staticmethod def utcoffset(*args, **kwargs): return datetime.timedelta() NOW_DATETIME = datetime.datetime(2010, 10, 11, 10, 30, 22, tzinfo=tzinfo()) @staticmethod def _make_fixture(**kwargs): fixture = {'name': None, 'properties': {}, 'status': None, 'is_public': None} fixture.update(kwargs) return fixture def _make_datetime_fixture(self): return self._make_fixture(created_at=self.NOW_GLANCE_FORMAT, updated_at=self.NOW_GLANCE_FORMAT, deleted_at=self.NOW_GLANCE_FORMAT) def test_show_makes_datetimes(self): fixture = self._make_datetime_fixture() image_id = self.service.create(self.context, fixture)['id'] image_meta = self.service.show(self.context, image_id) self.assertEqual(image_meta['created_at'], self.NOW_DATETIME) self.assertEqual(image_meta['updated_at'], self.NOW_DATETIME) def test_detail_makes_datetimes(self): fixture = self._make_datetime_fixture() self.service.create(self.context, fixture) image_meta = self.service.detail(self.context)[0] self.assertEqual(image_meta['created_at'], self.NOW_DATETIME) self.assertEqual(image_meta['updated_at'], self.NOW_DATETIME) def test_client_forbidden_converts_to_imagenotauthed(self): class MyGlanceStubClient(glance_stubs.StubGlanceClient): """"""A client that raises a Forbidden exception."""""" def get(self, image_id): raise glanceclient.exc.Forbidden(image_id) client = MyGlanceStubClient() service = self._create_image_service(client) image_id = 1 # doesn't matter self.assertRaises(exception.ImageNotAuthorized, service.download, self.context, image_id, dst_path=os.devnull) def test_client_httpforbidden_converts_to_imagenotauthed(self): class MyGlanceStubClient(glance_stubs.StubGlanceClient): """"""A client that raises a HTTPForbidden exception."""""" def get(self, image_id): raise glanceclient.exc.HTTPForbidden(image_id) client = MyGlanceStubClient() service = self._create_image_service(client) image_id = 1 # doesn't matter self.assertRaises(exception.ImageNotAuthorized, service.download, self.context, image_id, dst_path=os.devnull) def test_client_notfound_converts_to_imagenotfound(self): class MyGlanceStubClient(glance_stubs.StubGlanceClient): """"""A client that raises a NotFound exception."""""" def get(self, image_id): raise glanceclient.exc.NotFound(image_id) client = MyGlanceStubClient() service = self._create_image_service(client) image_id = 1 # doesn't matter self.assertRaises(exception.ImageNotFound, service.download, self.context, image_id, dst_path=os.devnull) def test_client_httpnotfound_converts_to_imagenotfound(self): class MyGlanceStubClient(glance_stubs.StubGlanceClient): """"""A client that raises a HTTPNotFound exception."""""" def get(self, image_id): raise glanceclient.exc.HTTPNotFound(image_id) client = MyGlanceStubClient() service = self._create_image_service(client) image_id = 1 # doesn't matter self.assertRaises(exception.ImageNotFound, service.download, self.context, image_id, dst_path=os.devnull) def test_glance_client_image_id(self): fixture = self._make_fixture(name='test image') image_id = self.service.create(self.context, fixture)['id'] (service, same_id) = glance.get_remote_image_service( self.context, image_id) self.assertEqual(same_id, image_id) def test_glance_client_image_ref(self): fixture = self._make_fixture(name='test image') image_id = self.service.create(self.context, fixture)['id'] image_url = 'http://something-less-likely/%s' % image_id (service, same_id) = glance.get_remote_image_service( self.context, image_url) self.assertEqual(same_id, image_id) self.assertEqual(service._client.host, 'something-less-likely') def test_extracting_missing_attributes(self): """"""Verify behavior from glance objects that are missing attributes This fakes the image class and is missing attribute as the client can return if they're not set in the database. """""" class MyFakeGlanceImage(glance_stubs.FakeImage): def __init__(self, metadata): IMAGE_ATTRIBUTES = ['size', 'owner', 'id', 'created_at', 'updated_at', 'status', 'min_disk', 'min_ram', 'is_public'] raw = dict.fromkeys(IMAGE_ATTRIBUTES) raw.update(metadata) self.__dict__['raw'] = raw metadata = { 'id': 1, 'created_at': self.NOW_DATETIME, 'updated_at': self.NOW_DATETIME, } image = MyFakeGlanceImage(metadata) observed = glance._extract_attributes(image) expected = { 'id': 1, 'name': None, 'is_public': None, 'size': None, 'min_disk': None, 'min_ram': None, 'disk_format': None, 'container_format': None, 'checksum': None, 'created_at': self.NOW_DATETIME, 'updated_at': self.NOW_DATETIME, 'deleted_at': None, 'deleted': None, 'status': None, 'properties': {}, 'owner': None, } self.assertEqual(expected, observed) ",112,147
openstack%2Fnova~master~Icb19148660bca542a8120ecab064551d67ac28af,openstack/nova,master,Icb19148660bca542a8120ecab064551d67ac28af,Fix Resource tracker should report virt driver stats,MERGED,2014-07-25 05:10:02.000000000,2014-08-09 19:56:30.000000000,2014-07-31 10:51:23.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 642}, {'_account_id': 782}, {'_account_id': 2835}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 7166}, {'_account_id': 7461}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10373}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-25 05:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28306ec65d0d3c79dd3d0f0f99b6886aa8258c21', 'message': ""Fix Resource tracker should report virt driver stats\n\nIf the virt driver provides any data for resource stats it is\nlost whenever the resource tracker updates its own view of stats.\nMoreover, if the resource tracker has not instances to track it\nonly reports the dirver's view, which might be nothing.\n\nThis fix keeps a copy of the dirver's view to merge with the\nresource trackers making sure all stats get reported to the\nscheduler.\n\nChange-Id: Icb19148660bca542a8120ecab064551d67ac28af\nCloses-bug: #1348288\n""}, {'number': 2, 'created': '2014-07-25 12:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e8a301e658f63197e9fc9bfc4dc0ad3856b13088', 'message': ""Fix Resource tracker should report virt driver stats\n\nIf the virt driver provides any data for resource stats it is\nlost whenever the resource tracker updates its own view of stats.\nMoreover, if the resource tracker has not instances to track it\nonly reports the dirver's view, which might be nothing.\n\nThis fix keeps a copy of the dirver's view to merge with the\nresource trackers making sure all stats get reported to the\nscheduler.\n\nChange-Id: Icb19148660bca542a8120ecab064551d67ac28af\nCloses-bug: #1348288\n""}, {'number': 3, 'created': '2014-07-25 14:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01a2c84ab2e8216b943d618ab711b5a1d467f9a6', 'message': ""Fix Resource tracker should report virt driver stats\n\nIf the virt driver provides any data for resource stats it is\nlost whenever the resource tracker updates its own view of stats.\nMoreover, if the resource tracker has not instances to track it\nonly reports the dirver's view, which might be nothing.\n\nThis fix keeps a copy of the dirver's view to merge with the\nresource trackers making sure all stats get reported to the\nscheduler.\n\nChange-Id: Icb19148660bca542a8120ecab064551d67ac28af\nCloses-bug: #1348288\n""}, {'number': 4, 'created': '2014-07-25 15:36:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/715425a99e67bd9e0dd48bb86224f1c195fe553c', 'message': ""Fix Resource tracker should report virt driver stats\n\nIf the virt driver provides any data for resource stats it is\nlost whenever the resource tracker updates its own view of stats.\nMoreover, if the resource tracker has not instances to track it\nonly reports the dirver's view, which might be nothing.\n\nThis fix keeps a copy of the dirver's view to merge with the\nresource trackers making sure all stats get reported to the\nscheduler.\n\nChange-Id: Icb19148660bca542a8120ecab064551d67ac28af\nCloses-bug: #1348288\n""}, {'number': 5, 'created': '2014-07-29 09:27:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b12492ac129a945ea8d6210fc4eb27b5ae554d4e', 'message': ""Fix Resource tracker should report virt driver stats\n\nIf the virt driver provides any data for resource stats it is\nlost whenever the resource tracker updates its own view of stats.\nMoreover, if the resource tracker has not instances to track it\nonly reports the dirver's view, which might be nothing.\n\nThis fix adds the dirver's view of stats to the resource tracker\nstats to make sure they are correctly handled.\n\nChange-Id: Icb19148660bca542a8120ecab064551d67ac28af\nCloses-bug: #1348288\n""}, {'number': 6, 'created': '2014-07-30 12:22:58.000000000', 'files': ['nova/compute/stats.py', 'nova/tests/compute/test_resource_tracker.py', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c363dae6a2b878db6801b502cced1fcc6aad2d0c', 'message': ""Fix Resource tracker should report virt driver stats\n\nIf the virt driver provides any data for resource stats it is\nlost whenever the resource tracker updates its own view of stats.\nMoreover, if the resource tracker has not instances to track it\nonly reports the driver's view, which might be nothing.\n\nThis fix adds the driver's view of stats to the resource tracker\nstats to make sure they are correctly handled.\n\nChange-Id: Icb19148660bca542a8120ecab064551d67ac28af\nCloses-bug: #1348288\n""}]",10,109489,c363dae6a2b878db6801b502cced1fcc6aad2d0c,88,16,6,7461,,,0,"Fix Resource tracker should report virt driver stats

If the virt driver provides any data for resource stats it is
lost whenever the resource tracker updates its own view of stats.
Moreover, if the resource tracker has not instances to track it
only reports the driver's view, which might be nothing.

This fix adds the driver's view of stats to the resource tracker
stats to make sure they are correctly handled.

Change-Id: Icb19148660bca542a8120ecab064551d67ac28af
Closes-bug: #1348288
",git fetch https://review.opendev.org/openstack/nova refs/changes/89/109489/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/resource_tracker.py'],1,28306ec65d0d3c79dd3d0f0f99b6886aa8258c21,bug/1348288," self.driver_stats = {} self.compute_node['stats'] = self._merge_stats() def _merge_stats(self): _stats = {} _stats.update(self.driver_stats) _stats.update(self.stats) return jsonutils.dumps(_stats) def _collect_driver_stats(self, resources): """"""Keep a copy of the driver view of stats and update by merging the resource tracker view of stats. """""" # We keep the copy as a dict but in resources # it is held as a json string. if 'stats' not in resources: self.driver_stats = {} elif isinstance(resources['stats'], str): self.driver_stats = jsonutils.loads(resources['stats']) elif isinstance(resources['stats'], dict): self.driver_stats = resources['stats'] resources['stats'] = self._merge_stats() self._collect_driver_stats(resources) resources['stats'] = self._merge_stats() resources['stats'] = self._merge_stats()", self.compute_node['stats'] = jsonutils.dumps(self.stats) resources['stats'] = jsonutils.dumps(self.stats) resources['stats'] = jsonutils.dumps(self.stats),26,3
openstack%2Frally~master~Idb5497552772ed9e82ebebbfc0b3ea3a85af752b,openstack/rally,master,Idb5497552772ed9e82ebebbfc0b3ea3a85af752b,Fixes the check for admin role to be case-insenstive,MERGED,2014-08-08 18:49:42.000000000,2014-08-09 18:20:21.000000000,2014-08-09 18:20:20.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 10068}, {'_account_id': 11105}]","[{'number': 1, 'created': '2014-08-08 18:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bb2379f982e061ee74d62dfe4c3b996b1f19f25d', 'message': 'Lowercases every item from the role list that is compared with admin\nhttps://bugs.launchpad.net/rally/+bug/1354549\n\nChange-Id: Idb5497552772ed9e82ebebbfc0b3ea3a85af752b\n'}, {'number': 2, 'created': '2014-08-08 19:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6f1d6dc20d5b269e7ad0f82fd9dbb71ee05be66b', 'message': 'Fixes the check for admin role to be case-insenstive.\nLowercases every item from the role list that is compared with admin\nCloses-bug: #1354549\n\nChange-Id: Idb5497552772ed9e82ebebbfc0b3ea3a85af752b\n'}, {'number': 3, 'created': '2014-08-08 19:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/40a07724ecbf5b90c92325941260241f6ab3ebb4', 'message': 'Fixes the check for admin role to be case-insenstive.\n\nLowercases every item from the role list that is compared with admin\nCloses-bug: #1354549\n\nChange-Id: Idb5497552772ed9e82ebebbfc0b3ea3a85af752b\n'}, {'number': 4, 'created': '2014-08-09 03:56:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9839ecd0bd0763a3b16a2ec9fa34a12a0128ac76', 'message': 'Fixes the check for admin role to be case-insenstive.\n\nLowercases every item from the role list that is compared with admin\nFixed pep8 error within osclients.py\nCloses-bug: #1354549\n\nChange-Id: Idb5497552772ed9e82ebebbfc0b3ea3a85af752b\n'}, {'number': 5, 'created': '2014-08-09 15:44:38.000000000', 'files': ['rally/osclients.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/4767eeea3be1952112a0c3a88ea7327de8689e80', 'message': 'Fixes the check for admin role to be case-insenstive\n\nLowercases every item from the role list that is compared with admin\nCloses-bug: #1354549\n\nChange-Id: Idb5497552772ed9e82ebebbfc0b3ea3a85af752b\n'}]",2,112999,4767eeea3be1952112a0c3a88ea7327de8689e80,31,4,5,11486,,,0,"Fixes the check for admin role to be case-insenstive

Lowercases every item from the role list that is compared with admin
Closes-bug: #1354549

Change-Id: Idb5497552772ed9e82ebebbfc0b3ea3a85af752b
",git fetch https://review.opendev.org/openstack/rally refs/changes/99/112999/4 && git format-patch -1 --stdout FETCH_HEAD,['rally/osclients.py'],1,bb2379f982e061ee74d62dfe4c3b996b1f19f25d,fix-bug-1354549, if 'admin' not in [role.lower() for role in client.auth_ref.role_names]:, if 'admin' not in client.auth_ref.role_names:,1,1
openstack%2Fcinder~master~I45d77c4243339e8fc76969042634c6c45899fbae,openstack/cinder,master,I45d77c4243339e8fc76969042634c6c45899fbae,Add CHAP support for 3PAR ISCSI,MERGED,2014-07-22 18:46:57.000000000,2014-08-09 16:44:20.000000000,2014-08-09 00:48:49.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 4992}, {'_account_id': 5997}, {'_account_id': 6043}, {'_account_id': 7198}, {'_account_id': 7860}, {'_account_id': 8857}, {'_account_id': 9624}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 11903}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12018}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12492}]","[{'number': 1, 'created': '2014-07-22 18:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/39ba7f12e5ec4348e235485553e967a3ed25fe0a', 'message': 'Add CHAP support for 3PAR ISCSI\n\nAdds CHAP support to 3PAR ISCSI.  Volume metadata will store\nCHAP credentials to allow volumes to be attached to hosts on\na 3PAR backend.  Credentials are generated when the first volume\nis attached.  Subsequent volumes lookup the CHAP credentials\nfrom an existing volume already attached to the host.\n\nImplements: blueprint add-chap-support-3par-iscsi\n\nChange-Id: I45d77c4243339e8fc76969042634c6c45899fbae\n'}, {'number': 2, 'created': '2014-07-23 20:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ef3f86606ccc1122637c2839eb5afc775f91598a', 'message': 'Add CHAP support for 3PAR ISCSI\n\nAdds CHAP support to 3PAR ISCSI.  Volume metadata will store\nCHAP credentials to allow volumes to be attached to hosts on\na 3PAR backend.  Credentials are generated when the first volume\nis attached.  Subsequent volumes lookup the CHAP credentials\nfrom an existing volume already attached to the host.\n\nImplements: blueprint add-chap-support-3par-iscsi\n\nChange-Id: I45d77c4243339e8fc76969042634c6c45899fbae\n'}, {'number': 3, 'created': '2014-07-24 18:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ff6f5bcefb230f13576ad9bb9a5cc6f7920b7bd4', 'message': 'Add CHAP support for 3PAR ISCSI\n\nAdds CHAP support to 3PAR ISCSI.  Volume metadata will store\nCHAP credentials to allow volumes to be attached to hosts on\na 3PAR backend.  Credentials are generated when the first volume\nis attached.  Subsequent volumes lookup the CHAP credentials\nfrom an existing volume already attached to the host.\n\nImplements: blueprint add-chap-support-3par-iscsi\n\nChange-Id: I45d77c4243339e8fc76969042634c6c45899fbae\n'}, {'number': 4, 'created': '2014-07-31 23:20:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7ad03e9305d99d77cd0bec732b192731601ac983', 'message': 'Add CHAP support for 3PAR ISCSI\n\nAdds CHAP support to 3PAR ISCSI.  Volume metadata will store\nCHAP credentials to allow volumes to be attached to hosts on\na 3PAR backend.  Credentials are generated when the first volume\nis attached.  Subsequent volumes lookup the CHAP credentials\nfrom an existing volume already attached to the host.\n\nImplements: blueprint add-chap-support-3par-iscsi\n\nChange-Id: I45d77c4243339e8fc76969042634c6c45899fbae\n'}, {'number': 5, 'created': '2014-08-01 04:54:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c1a7fbcd723d2b8fe7b1032388e868d54830dc22', 'message': 'Add CHAP support for 3PAR ISCSI\n\nAdds CHAP support to 3PAR ISCSI.  Volume metadata will store\nCHAP credentials to allow volumes to be attached to hosts on\na 3PAR backend.  Credentials are generated when the first volume\nis attached.  Subsequent volumes lookup the CHAP credentials\nfrom an existing volume already attached to the host.\n\nImplements: blueprint add-chap-support-3par-iscsi\n\nChange-Id: I45d77c4243339e8fc76969042634c6c45899fbae\n'}, {'number': 6, 'created': '2014-08-04 23:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/399ad38c80b9beb52e8f1ff4449c363435b58226', 'message': 'Add CHAP support for 3PAR ISCSI\n\nAdds CHAP support to 3PAR ISCSI.  Volume metadata will store\nCHAP credentials to allow volumes to be attached to hosts on\na 3PAR backend.  Credentials are generated when the first volume\nis attached.  Subsequent volumes lookup the CHAP credentials\nfrom an existing volume already attached to the host.\n\nImplements: blueprint add-chap-support-3par-iscsi\n\nChange-Id: I45d77c4243339e8fc76969042634c6c45899fbae\n'}, {'number': 7, 'created': '2014-08-05 03:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9b1d44ae962f21ffe832f96730005a21e0c3252e', 'message': 'Add CHAP support for 3PAR ISCSI\n\nAdds CHAP support to 3PAR ISCSI.  Volume metadata will store\nCHAP credentials to allow volumes to be attached to hosts on\na 3PAR backend.  Credentials are generated when the first volume\nis attached.  Subsequent volumes lookup the CHAP credentials\nfrom an existing volume already attached to the host.\n\nImplements: blueprint add-chap-support-3par-iscsi\n\nChange-Id: I45d77c4243339e8fc76969042634c6c45899fbae\n'}, {'number': 8, 'created': '2014-08-05 22:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ab63aeb0ba54507b363a5d61b832f4e4832385ae', 'message': 'Add CHAP support for 3PAR ISCSI\n\nAdds CHAP support to 3PAR ISCSI.  Volume metadata will store\nCHAP credentials to allow volumes to be attached to hosts on\na 3PAR backend.  Credentials are generated when the first volume\nis attached.  Subsequent volumes lookup the CHAP credentials\nfrom an existing volume already attached to the host.\n\nImplements: blueprint add-chap-support-3par-iscsi\n\nChange-Id: I45d77c4243339e8fc76969042634c6c45899fbae\n'}, {'number': 9, 'created': '2014-08-08 18:53:37.000000000', 'files': ['etc/cinder/cinder.conf.sample', 'cinder/tests/fake_hp_3par_client.py', 'cinder/volume/drivers/san/hp/hp_3par_iscsi.py', 'cinder/tests/test_hp3par.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/992a2f4eeec08cad3a2d5e340c8f0c06833f4ac4', 'message': 'Add CHAP support for 3PAR ISCSI\n\nAdds CHAP support to 3PAR ISCSI.  Volume metadata will store\nCHAP credentials to allow volumes to be attached to hosts on\na 3PAR backend.  Credentials are generated when the first volume\nis attached.  Subsequent volumes lookup the CHAP credentials\nfrom an existing volume already attached to the host.\n\nImplements: blueprint add-chap-support-3par-iscsi\nDocImpact\n\nChange-Id: I45d77c4243339e8fc76969042634c6c45899fbae\n'}]",49,108803,992a2f4eeec08cad3a2d5e340c8f0c06833f4ac4,104,18,9,11903,,,0,"Add CHAP support for 3PAR ISCSI

Adds CHAP support to 3PAR ISCSI.  Volume metadata will store
CHAP credentials to allow volumes to be attached to hosts on
a 3PAR backend.  Credentials are generated when the first volume
is attached.  Subsequent volumes lookup the CHAP credentials
from an existing volume already attached to the host.

Implements: blueprint add-chap-support-3par-iscsi
DocImpact

Change-Id: I45d77c4243339e8fc76969042634c6c45899fbae
",git fetch https://review.opendev.org/openstack/cinder refs/changes/03/108803/6 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/san/hp/hp_3par_iscsi.py', 'cinder/tests/test_hp3par.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py']",3,39ba7f12e5ec4348e235485553e967a3ed25fe0a,bp/add-chap-support-3par-iscsi," help=""List of target iSCSI addresses to use.""), cfg.BoolOpt('hp3par_iscsi_chap_enabled', default=False, help=""Enable CHAP authentication for iSCSI connections.""), 2.0.14 - Added CHAP support VERSION = ""2.0.14"""," help=""List of target iSCSI addresses to use."") VERSION = ""2.0.13""",650,11
openstack%2Fopenstack-manuals~master~Iacd5c68c639e60e8c711cb18351543e477444299,openstack/openstack-manuals,master,Iacd5c68c639e60e8c711cb18351543e477444299,Clean Common,MERGED,2014-08-07 09:25:57.000000000,2014-08-09 16:39:20.000000000,2014-08-09 16:39:19.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-08-07 09:25:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/34a40797379064517ec986cad657a3a9e3cdc769', 'message': 'Clean Common\n\nThis patch works several files that were not in common use back\ninto the documents they should live with.\n\nThe intended end result of this activity is to make common as lean as\npossible so it can be more easily translated.\n\nChange-Id: Iacd5c68c639e60e8c711cb18351543e477444299\n'}, {'number': 2, 'created': '2014-08-07 09:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a512f73013d576728afe7dce3f167f410ff4a057', 'message': 'Clean Common\n\nThis patch works several files that were not in common use back\ninto the documents they should live with.\n\nThe intended end result of this activity is to make common as lean as\npossible so it can be more easily translated.\n\nChange-Id: Iacd5c68c639e60e8c711cb18351543e477444299\n'}, {'number': 3, 'created': '2014-08-07 09:40:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4f9d433d096ddc33d02c5f28458d968db9510fdd', 'message': 'Clean Common\n\nThis patch works several files that were not in common use back\ninto the documents they should live with.\n\nThe intended end result of this activity is to make common as lean as\npossible so it can be more easily translated.\n\nChange-Id: Iacd5c68c639e60e8c711cb18351543e477444299\n'}, {'number': 4, 'created': '2014-08-07 09:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9ed18748565510125103ab3d14fb011ab0e3dcf3', 'message': 'Clean Common\n\nThis patch works several files that were not in common use back\ninto the documents they should live with.\n\nThe intended end result of this activity is to make common as lean as\npossible so it can be more easily translated.\n\nChange-Id: Iacd5c68c639e60e8c711cb18351543e477444299\n'}, {'number': 5, 'created': '2014-08-07 09:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/85f2bb838d3b36d62ee1134eb6041624b32113ee', 'message': 'Clean Common\n\nThis patch works several files that were not in common use back\ninto the documents they should live with.\n\nThe intended end result of this activity is to make common as lean as\npossible so it can be more easily translated.\n\nChange-Id: Iacd5c68c639e60e8c711cb18351543e477444299\n'}, {'number': 6, 'created': '2014-08-07 10:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/45bf061479d286c58e6d2fb70a59ae951e4e0d4c', 'message': 'Clean Common\n\nThis patch works several files that were not in common use back\ninto the documents they should live with.\n\nThe intended end result of this activity is to make common as lean as\npossible so it can be more easily translated.\n\nChange-Id: Iacd5c68c639e60e8c711cb18351543e477444299\n'}, {'number': 7, 'created': '2014-08-07 10:20:17.000000000', 'files': ['doc/common/ch_getstart.xml', 'doc/user-guide/section_cli_nova_config-drive.xml', 'doc/user-guide-admin/section_cli_manage_services.xml', 'doc/config-reference/compute/section_xapi-ami-setup.xml', 'doc/user-guide/section_cli_nova_baremetal.xml', 'doc/config-reference/networking/section_networking-options-reference.xml', 'doc/user-guide/section_cli_nova_userdata.xml', 'doc/user-guide/section_cli_nova_reboot.xml', 'doc/config-reference/compute/section_introduction-to-xen.xml', 'doc/admin-guide-cloud/compute/section_compute_config-firewalls.xml', 'doc/user-guide/section_cli_nova_startstop.xml', 'doc/admin-guide-cloud/compute/section_compute-security.xml', 'doc/config-reference/compute/section_xapi-install-plugins.xml', 'doc/user-guide/section_cli_nova_terminate.xml', 'doc/user-guide/ch_cli.xml', 'doc/config-reference/ch_computeconfigure.xml', 'doc/user-guide-admin/section_cli_keystone_services.xml', 'doc/config-reference/compute/section_xen-install.xml', 'doc/user-guide/section_cli_nova_manage_instances.xml', 'doc/user-guide/section_cli_nova_resizerebuild.xml', 'doc/admin-guide-cloud/compute/section_compute-system-admin.xml', 'doc/user-guide/section_cli_nova_boot.xml', 'doc/config-reference/compute/section_compute-configure-console.xml', 'doc/user-guide/section_cli_nova_search_ip.xml', 'doc/admin-guide-cloud/compute/section_trusted-compute-pools.xml', 'doc/config-reference/compute/section_rpc.xml', 'doc/config-reference/networking/section_rpc-for-networking.xml', 'doc/config-reference/compute/section_xapi-resize-setup.xml', 'doc/user-guide/section_cli_nova_get_console.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4bf765758ceaff1e837df31f44b9f6a862aecfe8', 'message': ""Clean Common\n\nThis patch works several files that were not in common use back\ninto the documents they should live with.\n\nThe intended end result of this activity is to make common as lean as\npossible so it can be more easily translated.\n\nAlso: Don't include configdrive table in user-guide since it's not\nrelevant for audience\n\nChange-Id: Iacd5c68c639e60e8c711cb18351543e477444299\n""}]",4,112530,4bf765758ceaff1e837df31f44b9f6a862aecfe8,27,6,7,612,,,0,"Clean Common

This patch works several files that were not in common use back
into the documents they should live with.

The intended end result of this activity is to make common as lean as
possible so it can be more easily translated.

Also: Don't include configdrive table in user-guide since it's not
relevant for audience

Change-Id: Iacd5c68c639e60e8c711cb18351543e477444299
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/30/112530/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/user-guide/section_cli_nova_config-drive.xml', 'doc/user-guide-admin/section_cli_manage_services.xml', 'doc/user-guide/section_cli_nova_baremetal.xml', 'doc/config-reference/networking/section_networking-options-reference.xml', 'doc/user-guide/section_cli_nova_userdata.xml', 'doc/user-guide/section_cli_nova_reboot.xml', 'doc/admin-guide-cloud/compute/section_compute_config-firewalls.xml', 'doc/user-guide/section_cli_nova_startstop.xml', 'doc/user-guide/section_cli_nova_usage_statistics.xml', 'doc/admin-guide-cloud/compute/section_compute-security.xml', 'doc/user-guide/section_cli_nova_terminate.xml', 'doc/user-guide/ch_cli.xml', 'doc/config-reference/ch_computeconfigure.xml', 'doc/user-guide-admin/section_cli_keystone_services.xml', 'doc/user-guide/section_cli_nova_manage_instances.xml', 'doc/user-guide/section_cli_nova_resizerebuild.xml', 'doc/admin-guide-cloud/compute/section_compute-system-admin.xml', 'doc/user-guide/section_cli_nova_boot.xml', 'doc/config-reference/compute/section_compute-configure-console.xml', 'doc/user-guide/section_cli_nova_search_ip.xml', 'doc/admin-guide-cloud/compute/section_trusted-compute-pools.xml', 'doc/config-reference/compute/section_rpc.xml', 'doc/config-reference/networking/section_rpc-for-networking.xml', 'doc/user-guide/section_cli_nova_get_console.xml']",24,34a40797379064517ec986cad657a3a9e3cdc769,free-config,,,31,53
openstack%2Fopenstack-manuals~master~Ib687f8d46897f2375e2994bfedad286a8e0a8a12,openstack/openstack-manuals,master,Ib687f8d46897f2375e2994bfedad286a8e0a8a12,centos image example was wrong,MERGED,2014-08-04 18:51:57.000000000,2014-08-09 16:11:07.000000000,2014-08-09 16:11:06.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 9770}, {'_account_id': 12208}]","[{'number': 1, 'created': '2014-08-04 18:51:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e2deb96d856d0ef20d183470f6a79d78203db609', 'message': 'centos image example was wrong\n\nThe following page had an incorrect\nvirt-install example for creating a\ncentos image:\n\nhttp://docs.openstack.org/image-guide/content/centos-image.html\n\nI fixed the example as described in the\nassociated bug, 350564.\n\nChange-Id: Ib687f8d46897f2375e2994bfedad286a8e0a8a12\nCloses-Bug: #1350564\n'}, {'number': 2, 'created': '2014-08-04 18:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/379e723de004503c458eb35e08ba54cab8328862', 'message': 'centos image example was wrong\n\nThe following page had an incorrect\nvirt-install example for creating a\ncentos image:\n\nhttp://docs.openstack.org/image-guide/content/centos-image.html\n\nI fixed the example as described in the\nassociated bug, 350564.\n\nChange-Id: Ib687f8d46897f2375e2994bfedad286a8e0a8a12\nCloses-Bug: #1350564\n'}, {'number': 3, 'created': '2014-08-05 19:02:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/df2c77fa326121260ff2ab17ae03485e0821919a', 'message': 'centos image example was wrong\n\nThe following page had an incorrect\nvirt-install example for creating a\ncentos image:\n\nhttp://docs.openstack.org/image-guide/content/centos-image.html\n\nI fixed the example as described in the\nassociated bug, 350564.\n\nChange-Id: Ib687f8d46897f2375e2994bfedad286a8e0a8a12\nCloses-Bug: #1350564\n'}, {'number': 4, 'created': '2014-08-06 21:46:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/776815c5c21be784d8df99563d46e00a60e34e40', 'message': 'centos image example was wrong\n\nThe following page had an incorrect\nvirt-install example for creating a\ncentos image:\n\nhttp://docs.openstack.org/image-guide/content/centos-image.html\n\nI fixed the example as described in the\nassociated bug, 350564.\n\nChange-Id: Ib687f8d46897f2375e2994bfedad286a8e0a8a12\nCloses-Bug: #1350564\n'}, {'number': 5, 'created': '2014-08-07 03:14:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7b29cc57f5511f9198766898e32258df90a2237f', 'message': 'centos image example was wrong\n\nThe following page had an incorrect\nvirt-install example for creating a\ncentos image:\n\nhttp://docs.openstack.org/image-guide/content/centos-image.html\n\nI fixed the example as described in the\nassociated bug, 1350564.\n\nChange-Id: Ib687f8d46897f2375e2994bfedad286a8e0a8a12\nCloses-Bug: #1350564\n'}, {'number': 6, 'created': '2014-08-07 20:20:58.000000000', 'files': ['doc/image-guide/section_centos-example.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/09737ed1f402f654f53d2297cd5b0fb2cb29ce24', 'message': 'centos image example was wrong\n\nThe following page had an incorrect\nvirt-install example for creating a\ncentos image:\n\nhttp://docs.openstack.org/image-guide/content/centos-image.html\n\nI fixed the example as described in the\nassociated bug, 1350564.\n\nChange-Id: Ib687f8d46897f2375e2994bfedad286a8e0a8a12\nCloses-Bug: #1350564\n'}]",17,111801,09737ed1f402f654f53d2297cd5b0fb2cb29ce24,34,6,6,9770,,,0,"centos image example was wrong

The following page had an incorrect
virt-install example for creating a
centos image:

http://docs.openstack.org/image-guide/content/centos-image.html

I fixed the example as described in the
associated bug, 1350564.

Change-Id: Ib687f8d46897f2375e2994bfedad286a8e0a8a12
Closes-Bug: #1350564
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/01/111801/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/image-guide/section_centos-example.xml'],1,e2deb96d856d0ef20d183470f6a79d78203db609,fix-bug-1350564," <para>Assume that the name of your virtual machine image is <literal>centos-6.5-x86_64-serial</literal>; <para>If you use <command>virt-install</command>, the command should look something like<prompt>#</prompt> <userinput>virt-install --virt-type kvm --name centos-6.5-x86_64-serial --ram 1024 \ --disk path=KVM-VM/centos6.5-serial.raw,size=10,format=raw \ --network network=default --graphics vnc,listen=0.0.0.0 --noautoconsole \ --os-type=linux --os-variant=rhel6 \ --extra-args=""console=tty0 console=ttyS0,115200n8 serial"" \ --location=ISO/CentOS-6.5-x86_64-bin-DVD1.iso</userinput></screen>"," <para>Assume that the name of your virtual machine image is <literal>centos-6.4</literal>; <para>If you use <command>virt-install</command>, the commands should look something like<prompt>#</prompt> <userinput>virt-install --virt-type kvm --name centos-6.4 --ram 1024 \ --cdrom=/data/isos/CentOS-6.4-x86_64-netinstall.iso \ --disk /tmp/centos-6.4.qcow2,format=qcow2 \ --network network=default \ --graphics vnc,listen=0.0.0.0 --noautoconsole \ --os-type=linux --os-variant=rhel6</userinput></screen>",8,8
openstack%2Fcinder~stable%2Ficehouse~I2e69fc4103559d49d2cee16ea04787a252dbf879,openstack/cinder,stable/icehouse,I2e69fc4103559d49d2cee16ea04787a252dbf879,vmware: Force chunked transfer for upload-to-image,MERGED,2014-08-04 07:38:11.000000000,2014-08-09 16:06:22.000000000,2014-08-09 16:06:21.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 7198}, {'_account_id': 12033}, {'_account_id': 12641}]","[{'number': 1, 'created': '2014-08-04 07:38:11.000000000', 'files': ['cinder/tests/test_vmware_io_util.py', 'cinder/volume/drivers/vmware/io_util.py', 'cinder/volume/drivers/vmware/read_write_util.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/360705a76c1352aae338466ca705dc3d317cae28', 'message': 'vmware: Force chunked transfer for upload-to-image\n\nThe upload-to-image operation downloads (using stream-optimized HTTP NFC\ntransfer) the virtual disk corresponding to the volume to a pipe from\nwhere the glance image client reads the data for upload. Due to a recent\nchange in the glance image client, success in seeking the input file\nobject results in forgoing the chunked transfer in favor of regular\ntransfer. The glance image client expects an IOError if the input file\nobject is a pipe. Currently the pipe seek() is a NOP and this results in\nupload-to-image failure. This changes fixes such failures by throwing\nan IOError indicating an illegal seek.\n\nConflicts:\n\tcinder/volume/drivers/vmware/read_write_util.py\n\nChange-Id: I2e69fc4103559d49d2cee16ea04787a252dbf879\nCloses-Bug: #1295239\n(cherry picked from commit cf18199571b7965a8fe77db3d910b0e798f12946)\n'}]",0,111662,360705a76c1352aae338466ca705dc3d317cae28,13,5,1,9171,,,0,"vmware: Force chunked transfer for upload-to-image

The upload-to-image operation downloads (using stream-optimized HTTP NFC
transfer) the virtual disk corresponding to the volume to a pipe from
where the glance image client reads the data for upload. Due to a recent
change in the glance image client, success in seeking the input file
object results in forgoing the chunked transfer in favor of regular
transfer. The glance image client expects an IOError if the input file
object is a pipe. Currently the pipe seek() is a NOP and this results in
upload-to-image failure. This changes fixes such failures by throwing
an IOError indicating an illegal seek.

Conflicts:
	cinder/volume/drivers/vmware/read_write_util.py

Change-Id: I2e69fc4103559d49d2cee16ea04787a252dbf879
Closes-Bug: #1295239
(cherry picked from commit cf18199571b7965a8fe77db3d910b0e798f12946)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/62/111662/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_vmware_io_util.py', 'cinder/volume/drivers/vmware/io_util.py', 'cinder/volume/drivers/vmware/read_write_util.py']",3,360705a76c1352aae338466ca705dc3d317cae28,bug/1295239," data = self.file_handle.read(READ_CHUNKSIZE) self._progress += len(data) LOG.debug(""Read %s bytes from vmdk."" % self._progress) return data"," self._progress += READ_CHUNKSIZE LOG.debug(_(""Read %s bytes from vmdk."") % self._progress) return self.file_handle.read(READ_CHUNKSIZE)",75,4
openstack%2Fcinder~master~I32b86d7edd836310c6da7adffa46e915361668f0,openstack/cinder,master,I32b86d7edd836310c6da7adffa46e915361668f0,Update ref used for notifications,MERGED,2014-07-29 16:00:34.000000000,2014-08-09 15:57:54.000000000,2014-08-09 15:57:53.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 6094}, {'_account_id': 8874}, {'_account_id': 12033}, {'_account_id': 12641}]","[{'number': 1, 'created': '2014-07-29 16:00:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9e33e0a5eaba621b130c33e06a819697e1b124a1', 'message': ""Update ref used for notifications\n\nWhen we update a snapshot status in the db, we need to\nuse the newly updated snapshot-ref object in the following\nnotification method call.  Otherwise we're sending a\nnotifciation message with the old/outdated status\ninformation.\n\nNOTE: This also fixes the unit test that was written to\npass with the bug that existed in the notification.\n\nChange-Id: I32b86d7edd836310c6da7adffa46e915361668f0\n""}, {'number': 2, 'created': '2014-07-29 17:00:35.000000000', 'files': ['cinder/volume/manager.py', 'cinder/tests/test_volume.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5ee167c14c9978409db059054a02635de35a2e93', 'message': ""Update ref used for notifications\n\nWhen we update a snapshot status in the db, we need to\nuse the newly updated snapshot-ref object in the following\nnotification method call.  Otherwise we're sending a\nnotifciation message with the old/outdated status\ninformation.\n\nNOTE: This also fixes the unit test that was written to\npass with the bug that existed in the notification.\n\nCloses-Bug: #1349805\n\nChange-Id: I32b86d7edd836310c6da7adffa46e915361668f0\n""}]",0,110351,5ee167c14c9978409db059054a02635de35a2e93,19,7,2,2243,,,0,"Update ref used for notifications

When we update a snapshot status in the db, we need to
use the newly updated snapshot-ref object in the following
notification method call.  Otherwise we're sending a
notifciation message with the old/outdated status
information.

NOTE: This also fixes the unit test that was written to
pass with the bug that existed in the notification.

Closes-Bug: #1349805

Change-Id: I32b86d7edd836310c6da7adffa46e915361668f0
",git fetch https://review.opendev.org/openstack/cinder refs/changes/51/110351/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/manager.py', 'cinder/tests/test_volume.py']",2,9e33e0a5eaba621b130c33e06a819697e1b124a1,bug/1349805, expected['status'] = 'available',,5,3
openstack%2Fcinder~master~I1d84f1d596ebf014c0e3ea4202902ff515b3172a,openstack/cinder,master,I1d84f1d596ebf014c0e3ea4202902ff515b3172a,Fix snapshot id for snapshot_destroy,MERGED,2014-08-03 13:37:41.000000000,2014-08-09 15:57:46.000000000,2014-08-09 15:57:45.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 8415}, {'_account_id': 8874}, {'_account_id': 9366}, {'_account_id': 9533}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12641}]","[{'number': 1, 'created': '2014-08-03 13:37:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dbc01541bb1914001fe464d9a0af79be86d3374d', 'message': ""Fix snapshot id for snapshot_destroy\n\nThe id passed to snapshot_destroy should be snapshot['id'],\nnot volume['id'].\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: I1d84f1d596ebf014c0e3ea4202902ff515b3172a\n""}, {'number': 2, 'created': '2014-08-03 23:44:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5a0f65afa39409c28aab49e0befb1258d132f150', 'message': ""Fix snapshot id for snapshot_destroy\n\nThe id passed to snapshot_destroy should be snapshot['id'],\nnot volume['id'].\n\nCCLA SCHEDULE B SUBMISSION\n\nCloses-Bug: 1351997\n\nChange-Id: I1d84f1d596ebf014c0e3ea4202902ff515b3172a\n""}, {'number': 3, 'created': '2014-08-04 04:02:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/07b31cf46e46e400f99b212c1d47fc570e7313d4', 'message': ""Fix snapshot id for snapshot_destroy\n\nThe id passed to snapshot_destroy should be snapshot['id'],\nnot volume['id'].\n\nCCLA SCHEDULE B SUBMISSION\n\nCloses-Bug: 1351997\n\nChange-Id: I1d84f1d596ebf014c0e3ea4202902ff515b3172a\n""}, {'number': 4, 'created': '2014-08-06 14:48:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d5275b2787759d65a7e272fea564a65f8196536b', 'message': ""Fix snapshot id for snapshot_destroy\n\nThe id passed to snapshot_destroy should be snapshot['id'],\nnot volume['id'].\n\nCCLA SCHEDULE B SUBMISSION\n\nCloses-Bug: 1351997\n\nChange-Id: I1d84f1d596ebf014c0e3ea4202902ff515b3172a\n""}, {'number': 5, 'created': '2014-08-06 14:51:25.000000000', 'files': ['cinder/tests/test_volume.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d3ccb0ea7f73ae1d65469c476af03f7daaeef41e', 'message': ""Fix snapshot id for snapshot_destroy\n\nThe id passed to snapshot_destroy should be snapshot['id'],\nnot volume['id'].\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: I1d84f1d596ebf014c0e3ea4202902ff515b3172a\nCloses-Bug: 1351997\n""}]",3,111564,d3ccb0ea7f73ae1d65469c476af03f7daaeef41e,60,16,5,6491,,,0,"Fix snapshot id for snapshot_destroy

The id passed to snapshot_destroy should be snapshot['id'],
not volume['id'].

CCLA SCHEDULE B SUBMISSION

Change-Id: I1d84f1d596ebf014c0e3ea4202902ff515b3172a
Closes-Bug: 1351997
",git fetch https://review.opendev.org/openstack/cinder refs/changes/64/111564/4 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/api.py'],1,dbc01541bb1914001fe464d9a0af79be86d3374d,bug/1351997," self.db.snapshot_destroy(context, snapshot['id'])"," self.db.snapshot_destroy(context, volume['id'])",1,1
openstack%2Fcinder~stable%2Ficehouse~I65a087895be6652ae8a2683728722566e3f42f58,openstack/cinder,stable/icehouse,I65a087895be6652ae8a2683728722566e3f42f58,Bump stable/icehouse next version to 2014.1.3,MERGED,2014-08-08 14:28:04.000000000,2014-08-09 15:04:07.000000000,2014-08-09 15:04:06.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12492}]","[{'number': 1, 'created': '2014-08-08 14:28:04.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/cinder/commit/16f4ef86db691af700d073980145e2f48bc4d9e2', 'message': 'Bump stable/icehouse next version to 2014.1.3\n\nBump stable/icehouse next version to 2014.1.3\n\nChange-Id: I65a087895be6652ae8a2683728722566e3f42f58\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}]",0,112891,16f4ef86db691af700d073980145e2f48bc4d9e2,13,7,1,24,,,0,"Bump stable/icehouse next version to 2014.1.3

Bump stable/icehouse next version to 2014.1.3

Change-Id: I65a087895be6652ae8a2683728722566e3f42f58
Signed-off-by: Chuck Short <chuck.short@canonical.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/91/112891/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,16f4ef86db691af700d073980145e2f48bc4d9e2,,version = 2014.1.3,version = 2014.1.2,1,1
openstack%2Ftraining-guides~master~I63ffedf4f8be0efafc900e319b2a45fc2aa8562b,openstack/training-guides,master,I63ffedf4f8be0efafc900e319b2a45fc2aa8562b,Adds glance scripts for training labs,MERGED,2014-08-08 05:23:11.000000000,2014-08-09 14:46:12.000000000,2014-08-09 14:46:12.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2014-08-08 05:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/4a3dc58d29ace28bf952030153e1cb6a29897f53', 'message': 'Adds glance scripts for training labs\n\nAdds glance scripts for training labs which will install and configure glance\nand also populate the glance database.\n\nChange-Id: I63ffedf4f8be0efafc900e319b2a45fc2aa8562b\nCo-Authored-By: Roger Luethi <rl@patchworkscience.org>\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}, {'number': 2, 'created': '2014-08-08 05:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/a7ea52155316367d0cc3bbb393662a872aadbe3a', 'message': 'Adds glance scripts for training labs\n\nAdds glance scripts for training labs which will install and configure glance\nand also populate the glance database.\n\nChange-Id: I63ffedf4f8be0efafc900e319b2a45fc2aa8562b\nCo-Authored-By: Roger Luethi <rl@patchworkscience.org>\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}, {'number': 3, 'created': '2014-08-08 06:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/a2422d25bf9e1455efdfd300d8cc2374a5937d8f', 'message': 'Adds glance scripts for training labs\n\nAdds glance scripts for training labs which will install and configure glance\nand also populate the glance database.\n\nChange-Id: I63ffedf4f8be0efafc900e319b2a45fc2aa8562b\nCo-Authored-By: Roger Luethi <rl@patchworkscience.org>\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}, {'number': 4, 'created': '2014-08-08 06:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/7c2030d343e17577d62f51f21d98f5616aaab5f9', 'message': 'Adds glance scripts for training labs\n\nAdds glance scripts for training labs which will install and configure glance\nand also populate the glance database.\n\nChange-Id: I63ffedf4f8be0efafc900e319b2a45fc2aa8562b\nCo-Authored-By: Roger Luethi <rl@patchworkscience.org>\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}, {'number': 5, 'created': '2014-08-09 07:47:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/4b835afd66be7535b97613f1ce09bf79f5ef9e6e', 'message': 'Adds glance scripts for training labs\n\nAdds glance scripts for training labs which will install and configure glance\nand also populate the glance database.\n\nChange-Id: I63ffedf4f8be0efafc900e319b2a45fc2aa8562b\nCo-Authored-By: Roger Luethi <rl@patchworkscience.org>\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}, {'number': 6, 'created': '2014-08-09 10:37:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/9aa613398ce1c877502fbeee5ac9d724ef76b532', 'message': 'Adds glance scripts for training labs\n\nAdds glance scripts for training labs which will install and configure glance\nand also populate the glance database.\n\nChange-Id: I63ffedf4f8be0efafc900e319b2a45fc2aa8562b\nCo-Authored-By: Roger Luethi <rl@patchworkscience.org>\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}, {'number': 7, 'created': '2014-08-09 11:12:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/4a4033bee84ec97acd2446cae95d7168e93239c4', 'message': 'Adds glance scripts for training labs\n\nAdds glance scripts for training labs which will install and configure glance\nand also populate the glance database.\n\nChange-Id: I63ffedf4f8be0efafc900e319b2a45fc2aa8562b\nCo-Authored-By: Roger Luethi <rl@patchworkscience.org>\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}, {'number': 8, 'created': '2014-08-09 12:55:50.000000000', 'files': ['labs/config/scripts.controller', 'labs/scripts/setup_glance.sh'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/9343ce32a1bf41979fcb758ed571c23070e9a489', 'message': 'Adds glance scripts for training labs\n\nAdds glance scripts for training labs which will install and configure\nglance and also populate the glance database.\n\nChange-Id: I63ffedf4f8be0efafc900e319b2a45fc2aa8562b\nCo-Authored-By: Roger Luethi <rl@patchworkscience.org>\nPartial-Bug: 1312764\nImplements: blueprint openstack-training-labs\n'}]",7,112758,9343ce32a1bf41979fcb758ed571c23070e9a489,37,4,8,7007,,,0,"Adds glance scripts for training labs

Adds glance scripts for training labs which will install and configure
glance and also populate the glance database.

Change-Id: I63ffedf4f8be0efafc900e319b2a45fc2aa8562b
Co-Authored-By: Roger Luethi <rl@patchworkscience.org>
Partial-Bug: 1312764
Implements: blueprint openstack-training-labs
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/58/112758/8 && git format-patch -1 --stdout FETCH_HEAD,"['labs/config/scripts.controller', 'labs/scripts/setup_glance.sh']",2,4a3dc58d29ace28bf952030153e1cb6a29897f53,bug/1312764,"#!/usr/bin/env bash TOP_DIR=$(cd $(dirname ""$0"")/.. && pwd) source ""$TOP_DIR/config/paths"" source ""$CONFIG_DIR/credentials"" source ""$LIB_DIR/functions.guest"" exec_logfile indicate_current_auto #------------------------------------------------------------------------------ # Set up glance for controller node #------------------------------------------------------------------------------ echo ""Installing glance."" sudo apt-get install -y glance echo ""Removing default SQLite database."" sudo rm -f /var/lib/glance/glance.db echo ""Setting up database for glance."" setup_database glance function get_database_url { local user_name=$(service_to_user_name glance) local user_password=$(service_to_user_password glance) local database_host=controller-mgmt echo ""mysql://$user_name:$user_password@$database_host/glance"" } database_url=$(get_database_url) echo ""Configuring /etc/glance/glance.conf."" echo ""Setting database connection: $database_url."" iniset_sudo /etc/glance/glance.conf database connection ""$database_url"" auth_port = 35357 auth_protocol = http admin_tenant_name = service admin_user = glance admin_password = service_pass [paste_deploy] flavor = keystone echo ""Configuring glance.conf"" iniset_sudo /etc/glance/glance.conf keystone_authtoken auth_host controller-mgmt iniset_sudo /etc/glance/glance.conf keystone_authtoken auth_port ""35357"" iniset_sudo /etc/glance/glance.conf keystone_authtoken auth_protocol ""http"" iniset_sudo /etc/glance/glance.conf keystone_authtoken admin_tenant_name ""service"" iniset_sudo /etc/glance/glance.conf keystone_authtoken admin_user ""glance"" iniset_sudo /etc/glance/glance.conf keystone_authtoken admin_password ""service_pass"" iniset_sudo /etc/glance/glance.conf paste_deploy flavor ""keystone"" sudo service glance-api restart sudo service glance-registry restart echo ""Creating the database tables for glance."" sudo glance-manage db_sync #------------------------------------------------------------------------------ # Configure glance users, roles, and endpoints for authentication. #------------------------------------------------------------------------------ echo ""Using OS_SERVICE_TOKEN, OS_SERVICE_ENDPOINT for authentication."" export OS_SERVICE_TOKEN=$ADMIN_TOKEN export OS_SERVICE_ENDPOINT=""http://controller-mgmt:35357/v2.0"" echo ""Creating glance service."" glance service-create \ --name glance \ --type identity \ --description 'OpenStack Identity' echo ""Creating endpoints for glance."" glance_service_id=$(glance service-list | awk '/ glance / {print $2}') glance endpoint-create \ --service-id ""$glance_service_id"" \ --publicurl ""http://controller-api:5000/v2.0"" \ --adminurl ""http://controller-mgmt:35357/v2.0"" \ --internalurl ""http://controller-mgmt:5000/v2.0"" echo ""Add Cirros image to glance"" glance image-create --name Cirros_x86_64 --is-public true --container-format bare \ --disk-format qcow2 < /home/osbash/img/cirros-0.3.2-x86_64-disk.img ",,90,0
openstack%2Ftraining-guides~master~Ia72012a09da36df5f52454c289775a8b050f9e1a,openstack/training-guides,master,Ia72012a09da36df5f52454c289775a8b050f9e1a,Adds Keystone service tenant,MERGED,2014-08-08 04:52:11.000000000,2014-08-09 14:33:42.000000000,2014-08-09 14:33:42.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2014-08-08 04:52:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/48d12b42439199d4ab3c804a567953cfb7f522a5', 'message': 'Adds Keystone service tenant\n\nKeystone service tenant is required by OpenStack services to\nauthenticate. We could reuse admin tenant for the same but it\nwill provide OpenStack services with unnecessary privileges.\n\nChange-Id: Ia72012a09da36df5f52454c289775a8b050f9e1a\n'}, {'number': 2, 'created': '2014-08-08 06:16:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/db50615d17a847923b5de2c99945025e65bb7855', 'message': 'Adds Keystone service tenant\n\nKeystone service tenant is required by OpenStack services to\nauthenticate. We could reuse admin tenant for the same but it\nwill provide OpenStack services with unnecessary privileges.\n\nChange-Id: Ia72012a09da36df5f52454c289775a8b050f9e1a\n'}, {'number': 3, 'created': '2014-08-08 06:52:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/815c9738730effb7c3822edd4e2ffee35f4422ce', 'message': 'Adds Keystone service tenant\n\nKeystone service tenant is required by OpenStack services to\nauthenticate. We could reuse admin tenant for the same but it\nwill provide OpenStack services with unnecessary privileges.\n\nChange-Id: Ia72012a09da36df5f52454c289775a8b050f9e1a\n'}, {'number': 4, 'created': '2014-08-09 07:11:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/556bc1331950e34dff8499378490fb17d5d19da1', 'message': 'Adds Keystone service tenant\n\nKeystone service tenant is required by OpenStack services to\nauthenticate. We could reuse admin tenant for the same but it\nwill provide OpenStack services with unnecessary privileges.\n\nChange-Id: Ia72012a09da36df5f52454c289775a8b050f9e1a\n'}, {'number': 5, 'created': '2014-08-09 07:37:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/1d5aec690a5cda0cbe34d0773c5c86f21ad61a59', 'message': 'Adds Keystone service tenant\n\nKeystone service tenant is required by OpenStack services to\nauthenticate. We could reuse admin tenant for the same but it\nwill provide OpenStack services with unnecessary privileges.\n\nChange-Id: Ia72012a09da36df5f52454c289775a8b050f9e1a\n'}, {'number': 6, 'created': '2014-08-09 08:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/107b18face8c7e9656ccc0976d2e35c8b10dab58', 'message': 'Adds Keystone service tenant\n\nKeystone service tenant is required by OpenStack services to\nauthenticate. We could reuse admin tenant for the same but it\nwill provide OpenStack services with unnecessary privileges.\n\nImplements: blueprint openstack-training-labs\nChange-Id: Ia72012a09da36df5f52454c289775a8b050f9e1a\n'}, {'number': 7, 'created': '2014-08-09 08:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/ad14cb66da1376eb8f29edc526f75ce437fd2060', 'message': 'Adds Keystone service tenant\n\nKeystone service tenant is required by OpenStack services to\nauthenticate. We could reuse admin tenant for the same but it\nwill provide OpenStack services with unnecessary privileges.\n\nImplements: blueprint openstack-training-labs\nChange-Id: Ia72012a09da36df5f52454c289775a8b050f9e1a\n'}, {'number': 8, 'created': '2014-08-09 09:14:15.000000000', 'files': ['labs/config/credentials', 'labs/scripts/setup_keystone.sh'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/e0d970e40d7b4b4532fd3c2a6b617da5d8f23674', 'message': 'Adds Keystone service tenant\n\nKeystone service tenant is required by OpenStack services to\nauthenticate. We could reuse admin tenant for the same but it\nwill provide OpenStack services with unnecessary privileges.\n\nImplements: blueprint openstack-training-labs\nChange-Id: Ia72012a09da36df5f52454c289775a8b050f9e1a\n'}]",16,112757,e0d970e40d7b4b4532fd3c2a6b617da5d8f23674,32,3,8,7007,,,0,"Adds Keystone service tenant

Keystone service tenant is required by OpenStack services to
authenticate. We could reuse admin tenant for the same but it
will provide OpenStack services with unnecessary privileges.

Implements: blueprint openstack-training-labs
Change-Id: Ia72012a09da36df5f52454c289775a8b050f9e1a
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/57/112757/3 && git format-patch -1 --stdout FETCH_HEAD,['labs/scripts/setup_keystone.sh'],1,48d12b42439199d4ab3c804a567953cfb7f522a5,bp/openstack-training-labs,"echo ""Adding service tenant."" keystone tenant-create --name ""$SERVICE_TENANT_NAME"" --description ""Service Tenant"" echo ""Creating service user."" keystone user-create --name ""$SERVICE_USER_NAME"" --pass ""$SERVICE_PASSWORD"" --email service@domain.com echo ""Creating service roles."" keystone role-create --name ""$SERVICE_ROLE_NAME"" echo ""Adding service roles to service user."" keystone user-role-add \ --tenant ""$SERVICE_TENANT_NAME"" \ --user ""$SERVICE_USER_NAME"" \ --role ""$SERVICE_ROLE_NAME"" ",,16,0
openstack%2Frally~master~I327f23e460737ffe3a4fec42afcfbb387ae81bfb,openstack/rally,master,I327f23e460737ffe3a4fec42afcfbb387ae81bfb,Fix rally-gate.sh exit status,MERGED,2014-08-08 14:20:58.000000000,2014-08-09 14:00:59.000000000,2014-08-09 14:00:58.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-08-08 14:20:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7f55e386c654dc5ccdd5b8be661f242f65c53987', 'message': 'Fix rally-gate.sh exit status\n\nExit status should be set to non-zero if rally sla_check was not\nsuccessful. Bash option pipefail save any non-zero exit status\nfrom piped commands.\n\nChange-Id: I327f23e460737ffe3a4fec42afcfbb387ae81bfb\n'}, {'number': 2, 'created': '2014-08-08 15:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/81d4c2908844be86542276e02d44f26e87f33ed6', 'message': 'Fix rally-gate.sh exit status\n\nExit status should be set to non-zero if rally sla_check was not\nsuccessful. Bash option pipefail save any non-zero exit status\nfrom piped commands.\n\nChange-Id: I327f23e460737ffe3a4fec42afcfbb387ae81bfb\n'}, {'number': 3, 'created': '2014-08-09 12:17:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/cf2c061217da74336d47dfd7fe065d14ffdf2848', 'message': 'Fix rally-gate.sh exit status\n\nExit status should be set to non-zero if rally sla_check was not\nsuccessful. Bash option pipefail save any non-zero exit status\nfrom piped commands.\n\nChange-Id: I327f23e460737ffe3a4fec42afcfbb387ae81bfb\n'}, {'number': 4, 'created': '2014-08-09 12:56:58.000000000', 'files': ['rally-scenarios/rally.yaml', 'tests_ci/rally-gate.sh'], 'web_link': 'https://opendev.org/openstack/rally/commit/cb5295c3a6d79edc0b76a2d0f7988d53b582aad0', 'message': 'Fix rally-gate.sh exit status\n\nExit status should be set to non-zero if rally sla_check was not\nsuccessful. Bash option pipefail save any non-zero exit status\nfrom piped commands.\n\nChanged some default scenarios runners agrument\n\nRemove SLA from 2 non working benchmark scenarios.\nRelated-Bug: #1354683\n\nChange-Id: I327f23e460737ffe3a4fec42afcfbb387ae81bfb\n'}]",0,112887,cb5295c3a6d79edc0b76a2d0f7988d53b582aad0,25,3,4,7369,,,0,"Fix rally-gate.sh exit status

Exit status should be set to non-zero if rally sla_check was not
successful. Bash option pipefail save any non-zero exit status
from piped commands.

Changed some default scenarios runners agrument

Remove SLA from 2 non working benchmark scenarios.
Related-Bug: #1354683

Change-Id: I327f23e460737ffe3a4fec42afcfbb387ae81bfb
",git fetch https://review.opendev.org/openstack/rally refs/changes/87/112887/1 && git format-patch -1 --stdout FETCH_HEAD,['tests_ci/rally-gate.sh'],1,7f55e386c654dc5ccdd5b8be661f242f65c53987,bug/1354683,env set -o pipefail ,env ,3,2
openstack%2Fopenstack-manuals~master~Ic7b246e79275ba851695302dc6030492e5eb4db8,openstack/openstack-manuals,master,Ic7b246e79275ba851695302dc6030492e5eb4db8,Networking Guide introduction content,MERGED,2014-08-09 08:37:46.000000000,2014-08-09 10:38:17.000000000,2014-08-09 10:38:16.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-09 08:37:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/358be7ae9b845ce4012f2a910a79614843b579e0', 'message': 'Networking Guide introduction content\n\nAdding content written by docs team for the networking\nintroduction. Some editing for the content\n\nChange-Id: Ic7b246e79275ba851695302dc6030492e5eb4db8\nbackport: none\nimplements: OpenStack Networking Guide BLUEPRINT\n'}, {'number': 2, 'created': '2014-08-09 09:23:00.000000000', 'files': ['doc/networking-guide/ch_intro.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f03491f44ef68de36b2f2f21455f0b44ae8b905b', 'message': 'Networking Guide introduction content\n\nAdding content written by docs team for the networking\nintroduction. Editing some of the. Adjusted commit message\nwith correct blueprint name.\n\nChange-Id: Ic7b246e79275ba851695302dc6030492e5eb4db8\nimplements: bp create-networking-guide\n'}]",4,113081,f03491f44ef68de36b2f2f21455f0b44ae8b905b,11,2,2,10897,,,0,"Networking Guide introduction content

Adding content written by docs team for the networking
introduction. Editing some of the. Adjusted commit message
with correct blueprint name.

Change-Id: Ic7b246e79275ba851695302dc6030492e5eb4db8
implements: bp create-networking-guide
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/81/113081/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/ch_intro.xml'],1,358be7ae9b845ce4012f2a910a79614843b579e0,networkJR0908," The OpenStack Networking service provides an API that allows users to set up and define network connectivity and addressing in the cloud. The project code-name for Networking services is neutron. OpenStack Networking handles the creation and management of a virtual networking infrastructure, including networks, switches, subnets, and routers for devices managed by the OpenStack Compute service (nova). Advanced services such as firewalls or virtual private networks (VPNs) can also be used. <para> OpenStack Networking consists of the <systemitem class=""service"">neutron-server</systemitem>, a database for persistent storage, and any number of plugin <firstterm>agents</firstterm>, which provide other services such as interfacing with native Linux networking mechanisms, external devices, or SDN controllers. </para> <para> OpenStack Networking is entirely standalone and can be deployed to a dedicated host. If your deployment uses a controller host to run centralized Compute components, however, you can deploy the Networking server to that specific host instead. </para> <para> OpenStack Networking integrates with various other OpenStack components: </para> <itemizedlist> <listitem> <para>OpenStack Identity (keystone) is used for authentication and authorization of API requests.</para> </listitem> <listitem> <para>OpenStack Compute (nova) is used to plug each virtual NIC on the VM into a particular network.</para> </listitem> <listitem> <para>OpenStack Dashboard (horizon) for administrators and tenant users to create and manage network services through a web-based graphical interface.</para> </listitem> </itemizedlist> "," Bacon ipsum dolor sit amet biltong meatloaf andouille, turducken bresaola pork belly beef ribs ham hock capicola tail prosciutto landjaeger meatball pork loin. Swine turkey jowl, porchetta doner boudin meatloaf. Shoulder capicola prosciutto, shank landjaeger short ribs sirloin turducken pork belly boudin frankfurter chuck. Salami shankle bresaola cow filet mignon ham hock shank.",42,6
openstack%2Fopenstack-manuals~master~I9870875386d552420ecf778c6084e9b8281888e9,openstack/openstack-manuals,master,I9870875386d552420ecf778c6084e9b8281888e9,Trivial grammar fix,MERGED,2014-08-09 09:47:52.000000000,2014-08-09 10:38:10.000000000,2014-08-09 10:38:09.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-09 09:47:52.000000000', 'files': ['doc/common/section_getstart_image.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3f850f81429c89d82fd867d5c5950ece58c32361', 'message': 'Trivial grammar fix\n\n""Replication services ensures consistency"" becomes ""Replication services\nensure consistency"".\n\nChange-Id: I9870875386d552420ecf778c6084e9b8281888e9\n'}]",0,113085,3f850f81429c89d82fd867d5c5950ece58c32361,7,2,1,11109,,,0,"Trivial grammar fix

""Replication services ensures consistency"" becomes ""Replication services
ensure consistency"".

Change-Id: I9870875386d552420ecf778c6084e9b8281888e9
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/85/113085/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/section_getstart_image.xml'],1,3f850f81429c89d82fd867d5c5950ece58c32361,master, support caching. Replication services ensure consistency and, support caching. Replication services ensures consistency and,1,1
openstack%2Fnova~master~If829d483561f304db51e598ac14faadfc6b21e3a,openstack/nova,master,If829d483561f304db51e598ac14faadfc6b21e3a,Resize should give guests a chance to shutdown,ABANDONED,2014-07-25 13:52:25.000000000,2014-08-09 09:14:40.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-25 13:52:25.000000000', 'files': ['nova/virt/hyperv/driver.py', 'nova/virt/libvirt/driver.py', 'nova/virt/xenapi/driver.py', 'nova/virt/fake.py', 'nova/virt/vmwareapi/driver.py', 'nova/virt/driver.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/879b9c310df1b88032c08f7881b285d283cb7938', 'message': ""Resize should give guests a chance to shutdown\n\nCurrently in libvirt operations which power off an instance such as stop,\nshelve, rescue, and resize simply destroy the underlying VM. Some\nGuestOS's do not react well to this type of power failure, and so it would\nbe better if these operations followed the same approach as soft_reboot\nand give the guest as chance to shutdown gracefully.\n\nThis is one of a set of changes that will eventually expose the choice\nof whether to give the GuestOS a chance to shutdown via the API.\n\nThis change implements the changes to resize for libvirt\n\nPartially-Implements: blueprint user-defined-shutdown\nDocImpact\n\nChange-Id: If829d483561f304db51e598ac14faadfc6b21e3a\n""}]",0,109583,879b9c310df1b88032c08f7881b285d283cb7938,9,6,1,1501,,,0,"Resize should give guests a chance to shutdown

Currently in libvirt operations which power off an instance such as stop,
shelve, rescue, and resize simply destroy the underlying VM. Some
GuestOS's do not react well to this type of power failure, and so it would
be better if these operations followed the same approach as soft_reboot
and give the guest as chance to shutdown gracefully.

This is one of a set of changes that will eventually expose the choice
of whether to give the GuestOS a chance to shutdown via the API.

This change implements the changes to resize for libvirt

Partially-Implements: blueprint user-defined-shutdown
DocImpact

Change-Id: If829d483561f304db51e598ac14faadfc6b21e3a
",git fetch https://review.opendev.org/openstack/nova refs/changes/83/109583/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/hyperv/driver.py', 'nova/virt/libvirt/driver.py', 'nova/virt/xenapi/driver.py', 'nova/virt/fake.py', 'nova/virt/vmwareapi/driver.py', 'nova/virt/driver.py', 'nova/compute/manager.py']",7,879b9c310df1b88032c08f7881b285d283cb7938,bp/user-defined-shutdown," reservations, migration, instance_type, clean_shutdown=True): timeout, retry_interval = self._get_power_off_values(context, instance, clean_shutdown) block_device_info, timeout, retry_interval)"," reservations, migration, instance_type) block_device_info)",26,10
openstack%2Fkeystone~master~I744a4c82dc84bb1a8d29d0314e3c51cc43c077a2,openstack/keystone,master,I744a4c82dc84bb1a8d29d0314e3c51cc43c077a2,Class for V3 router packages,MERGED,2014-08-03 15:03:20.000000000,2014-08-09 09:04:39.000000000,2014-08-09 09:04:38.000000000,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 8978}]","[{'number': 1, 'created': '2014-08-03 15:03:20.000000000', 'files': ['keystone/auth/routers.py', 'keystone/service.py', 'keystone/assignment/routers.py', 'keystone/catalog/routers.py', 'keystone/trust/routers.py', 'keystone/policy/routers.py', 'keystone/credential/routers.py', 'keystone/common/wsgi.py', 'keystone/identity/routers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/dd70a5548ef4a110841474d264a82bba4a5cb76a', 'message': 'Class for V3 router packages\n\nThe V3 routes were being added by the append_v3_routers function in\neach controller package, so the only way state could be stored is in\na global variable which makes unit testing difficult. With this\nchange, the append_v3_routers functions are put into a class in each\npackage. This will eventually be used to store JSON Home data.\n\nbp json-home\n\nChange-Id: I744a4c82dc84bb1a8d29d0314e3c51cc43c077a2\n'}]",1,111567,dd70a5548ef4a110841474d264a82bba4a5cb76a,16,6,1,6486,,,0,"Class for V3 router packages

The V3 routes were being added by the append_v3_routers function in
each controller package, so the only way state could be stored is in
a global variable which makes unit testing difficult. With this
change, the append_v3_routers functions are put into a class in each
package. This will eventually be used to store JSON Home data.

bp json-home

Change-Id: I744a4c82dc84bb1a8d29d0314e3c51cc43c077a2
",git fetch https://review.opendev.org/openstack/keystone refs/changes/67/111567/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/auth/routers.py', 'keystone/service.py', 'keystone/assignment/routers.py', 'keystone/catalog/routers.py', 'keystone/trust/routers.py', 'keystone/credential/routers.py', 'keystone/policy/routers.py', 'keystone/common/wsgi.py', 'keystone/identity/routers.py']",9,dd70a5548ef4a110841474d264a82bba4a5cb76a,bp/json-home,"class Routers(wsgi.RoutersBase): def append_v3_routers(self, mapper, routers): user_controller = controllers.UserV3() routers.append( router.Router(user_controller, 'users', 'user')) mapper.connect('/users/{user_id}/password', controller=user_controller, action='change_password', conditions=dict(method=['POST'])) mapper.connect('/groups/{group_id}/users', controller=user_controller, action='list_users_in_group', conditions=dict(method=['GET'])) mapper.connect('/groups/{group_id}/users/{user_id}', controller=user_controller, action='add_user_to_group', conditions=dict(method=['PUT'])) mapper.connect('/groups/{group_id}/users/{user_id}', controller=user_controller, action='check_user_in_group', conditions=dict(method=['GET', 'HEAD'])) mapper.connect('/groups/{group_id}/users/{user_id}', controller=user_controller, action='remove_user_from_group', conditions=dict(method=['DELETE'])) group_controller = controllers.GroupV3() routers.append( router.Router(group_controller, 'groups', 'group')) mapper.connect('/users/{user_id}/groups', controller=group_controller, action='list_groups_for_user', conditions=dict(method=['GET']))","def append_v3_routers(mapper, routers): user_controller = controllers.UserV3() routers.append( router.Router(user_controller, 'users', 'user')) mapper.connect('/users/{user_id}/password', controller=user_controller, action='change_password', conditions=dict(method=['POST'])) mapper.connect('/groups/{group_id}/users', controller=user_controller, action='list_users_in_group', conditions=dict(method=['GET'])) mapper.connect('/groups/{group_id}/users/{user_id}', controller=user_controller, action='add_user_to_group', conditions=dict(method=['PUT'])) mapper.connect('/groups/{group_id}/users/{user_id}', controller=user_controller, action='check_user_in_group', conditions=dict(method=['GET', 'HEAD'])) mapper.connect('/groups/{group_id}/users/{user_id}', controller=user_controller, action='remove_user_from_group', conditions=dict(method=['DELETE'])) group_controller = controllers.GroupV3() routers.append( router.Router(group_controller, 'groups', 'group')) mapper.connect('/users/{user_id}/groups', controller=group_controller, action='list_groups_for_user', conditions=dict(method=['GET']))",253,212
openstack%2Fopenstack-manuals~master~I2598fb8b70f9750d3206f2ea4678c7e11312fc23,openstack/openstack-manuals,master,I2598fb8b70f9750d3206f2ea4678c7e11312fc23,Imported Translations from Transifex,ABANDONED,2014-08-09 06:09:58.000000000,2014-08-09 07:58:27.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-09 06:09:58.000000000', 'files': ['doc/install-guide/locale/install-guide.pot', 'doc/config-reference/locale/config-reference.pot', 'doc/networking-guide/locale/networking-guide.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3478731add5d42c51b6271c86e7be4e0e9721d9b', 'message': 'Imported Translations from Transifex\n\nChange-Id: I2598fb8b70f9750d3206f2ea4678c7e11312fc23\n'}]",0,113072,3478731add5d42c51b6271c86e7be4e0e9721d9b,8,3,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I2598fb8b70f9750d3206f2ea4678c7e11312fc23
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/72/113072/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/install-guide.pot', 'doc/config-reference/locale/config-reference.pot', 'doc/networking-guide/locale/networking-guide.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po']",6,3478731add5d42c51b6271c86e7be4e0e9721d9b,transifex/translations,"""POT-Creation-Date: 2014-08-09 05:25+0000\n"" ""PO-Revision-Date: 2014-08-09 02:12+0000\n""msgstr """"msgstr """"","""POT-Creation-Date: 2014-08-05 15:21+0000\n"" ""PO-Revision-Date: 2014-08-06 01:31+0000\n""msgstr """"msgstr """"",2200,111
openstack%2Fopenstack-manuals~master~I3e399318c32914b862d26c335fc6536d00d70084,openstack/openstack-manuals,master,I3e399318c32914b862d26c335fc6536d00d70084,Inserting image for deployment file,MERGED,2014-08-09 04:56:47.000000000,2014-08-09 07:50:11.000000000,2014-08-09 07:50:11.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-09 04:56:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cdc7ba5a492a5d123e37c168f8d2e91a458539c7', 'message': 'Inserting image for deployment file\n\nInserting diagram for deployment overview section.\n\nChange-Id: I3e399318c32914b862d26c335fc6536d00d70084\n'}, {'number': 2, 'created': '2014-08-09 07:33:42.000000000', 'files': ['doc/networking-guide/Images/deployment_architecture.png'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0fdeeb39296ac346de462b11001762d7cc67cb3b', 'message': 'Inserting image for deployment file\n\nInserting diagram for deployment overview section.\n\nChange-Id: I3e399318c32914b862d26c335fc6536d00d70084\n'}]",0,113067,0fdeeb39296ac346de462b11001762d7cc67cb3b,12,3,2,10607,,,0,"Inserting image for deployment file

Inserting diagram for deployment overview section.

Change-Id: I3e399318c32914b862d26c335fc6536d00d70084
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/67/113067/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/Images/deployment_architecture.png'],1,cdc7ba5a492a5d123e37c168f8d2e91a458539c7,asettleTHING,,,0,0
openstack%2Fdevstack-gate~master~I7dffa587784297ec65596a36c0600473cfa591c6,openstack/devstack-gate,master,I7dffa587784297ec65596a36c0600473cfa591c6,add tox to the tree for doing bashate checking,MERGED,2014-06-19 17:52:27.000000000,2014-08-09 07:27:57.000000000,2014-08-06 13:18:46.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-19 17:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/ca94f1d261e52dff12a1224fb3bbd2cc93818f77', 'message': 'add tox to the tree for doing bashate checking\n\nthis enables a bashate rule for doing style checking. Fixes for\nissues found will come in a second patch so any rules that people\nwant ignored could be debated there.\n\nChange-Id: I7dffa587784297ec65596a36c0600473cfa591c6\n'}, {'number': 2, 'created': '2014-07-24 11:02:32.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/5ca0a8700b83e3c8424b44b4dfcc4873cd8b7300', 'message': 'add tox to the tree for doing bashate checking\n\nthis enables a bashate rule for doing style checking. Fixes for\nissues found will come in a second patch so any rules that people\nwant ignored could be debated there.\n\nChange-Id: I7dffa587784297ec65596a36c0600473cfa591c6\n'}]",1,101267,5ca0a8700b83e3c8424b44b4dfcc4873cd8b7300,32,9,2,2750,,,0,"add tox to the tree for doing bashate checking

this enables a bashate rule for doing style checking. Fixes for
issues found will come in a second patch so any rules that people
want ignored could be debated there.

Change-Id: I7dffa587784297ec65596a36c0600473cfa591c6
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/67/101267/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,ca94f1d261e52dff12a1224fb3bbd2cc93818f77,bashate,"[tox] envlist = bashate minversion = 1.6 skipsdist = True [testenv] install_command = pip install -U {opts} {packages} setenv = VIRTUAL_ENV={envdir} deps = -r{toxinidir}/test-requirements.txt [testenv:bashate] commands = bash -c ""ls *.sh | xargs bash8 -v {posargs}"" ",,14,0
openstack%2Ftraining-guides~master~I730eab475bee843767984b6c64bab88a94c0156e,openstack/training-guides,master,I730eab475bee843767984b6c64bab88a94c0156e,labs: unified login/password handling,MERGED,2014-08-09 07:02:17.000000000,2014-08-09 07:24:21.000000000,2014-08-09 07:24:20.000000000,"[{'_account_id': 3}, {'_account_id': 7007}]","[{'number': 1, 'created': '2014-08-09 07:02:17.000000000', 'files': ['labs/lib/functions.guest', 'labs/scripts/setup_keystone.sh'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/8aab6f82ded5acd20925712259eac1d796b257be', 'message': 'labs: unified login/password handling\n\nThe labs scripts need two sets of login/password for each service:\none for the (MySQL) database used by the service, and one for\nauthentication with keystone.\n\nFor the labs scripts login names and passwords are simple functions\nof the service names: for the first set (database), we have\n${service}User/${service}Pass, for the second set (keystone auth)\n${service}/${service}_pass.\n\nThis changeset adds two functions for producing the second set of\ncredentials and renames the existing functions (as well as related\nvariables) for producing the first set.\n\nThis prevents us from having to store login names and passwords in the\nservice scripts. It also keeps those things in one location where they\ncan be changed easily should we ever want to do so.\n\nImplements: blueprint openstack-training-labs\nChange-Id: I730eab475bee843767984b6c64bab88a94c0156e\n'}]",0,113078,8aab6f82ded5acd20925712259eac1d796b257be,7,2,1,11109,,,0,"labs: unified login/password handling

The labs scripts need two sets of login/password for each service:
one for the (MySQL) database used by the service, and one for
authentication with keystone.

For the labs scripts login names and passwords are simple functions
of the service names: for the first set (database), we have
${service}User/${service}Pass, for the second set (keystone auth)
${service}/${service}_pass.

This changeset adds two functions for producing the second set of
credentials and renames the existing functions (as well as related
variables) for producing the first set.

This prevents us from having to store login names and passwords in the
service scripts. It also keeps those things in one location where they
can be changed easily should we ever want to do so.

Implements: blueprint openstack-training-labs
Change-Id: I730eab475bee843767984b6c64bab88a94c0156e
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/78/113078/1 && git format-patch -1 --stdout FETCH_HEAD,"['labs/lib/functions.guest', 'labs/scripts/setup_keystone.sh']",2,8aab6f82ded5acd20925712259eac1d796b257be,bp/openstack-training-labs," local db_user=$(service_to_db_user keystone) local db_password=$(service_to_db_password keystone) echo ""mysql://$db_user:$db_password@$database_host/keystone"""," local user_name=$(service_to_user_name keystone) local user_password=$(service_to_user_password keystone) echo ""mysql://$user_name:$user_password@$database_host/keystone""",24,8
openstack%2Fkeystone~master~I43028d326f17ea8cd0aaf7a3b80bf291d2bf0982,openstack/keystone,master,I43028d326f17ea8cd0aaf7a3b80bf291d2bf0982,swap import order of lxml,MERGED,2014-08-08 15:04:47.000000000,2014-08-09 06:57:38.000000000,2014-08-09 06:57:37.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 9954}, {'_account_id': 11434}]","[{'number': 1, 'created': '2014-08-08 15:04:47.000000000', 'files': ['keystone/common/serializer.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/7d1eed2bd5960a99897829290cdacb15c645ee28', 'message': 'swap import order of lxml\n\nlxml is a third party library, so attempt to import it with six rather\nthan first, which makes it look like a package from stdlib.\n\nChange-Id: I43028d326f17ea8cd0aaf7a3b80bf291d2bf0982\n'}]",2,112915,7d1eed2bd5960a99897829290cdacb15c645ee28,9,6,1,4,,,0,"swap import order of lxml

lxml is a third party library, so attempt to import it with six rather
than first, which makes it look like a package from stdlib.

Change-Id: I43028d326f17ea8cd0aaf7a3b80bf291d2bf0982
",git fetch https://review.opendev.org/openstack/keystone refs/changes/15/112915/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/serializer.py'],1,7d1eed2bd5960a99897829290cdacb15c645ee28,bug/1351016,import re import six ,import re import six ,4,4
openstack%2Frequirements~master~I89bb65ea257e03da22b5558298e1e7f2ff3a72a6,openstack/requirements,master,I89bb65ea257e03da22b5558298e1e7f2ff3a72a6,graduate oslo middleware,MERGED,2014-08-06 19:23:28.000000000,2014-08-09 06:57:30.000000000,2014-08-09 06:57:30.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6537}, {'_account_id': 7680}]","[{'number': 1, 'created': '2014-08-06 19:23:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/902335141b04da6daef880066d2adc0c842aacdb', 'message': 'graduate oslo middleware\n\nChange-Id: I89bb65ea257e03da22b5558298e1e7f2ff3a72a6\n'}, {'number': 2, 'created': '2014-08-06 19:42:21.000000000', 'files': ['projects.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/fd6027ab1f7caf9018d81c2bd5cb88f119b18043', 'message': 'graduate oslo middleware\n\nChange-Id: I89bb65ea257e03da22b5558298e1e7f2ff3a72a6\n'}]",0,112388,fd6027ab1f7caf9018d81c2bd5cb88f119b18043,17,4,2,6537,,,0,"graduate oslo middleware

Change-Id: I89bb65ea257e03da22b5558298e1e7f2ff3a72a6
",git fetch https://review.opendev.org/openstack/requirements refs/changes/88/112388/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,902335141b04da6daef880066d2adc0c842aacdb,graduate-oslo-middleware,oslo.middleware,,1,0
openstack%2Fcinder~master~I82bac9695c8138cff858013b3affeb0557dfcc02,openstack/cinder,master,I82bac9695c8138cff858013b3affeb0557dfcc02,EMC: Fix minor issue in VNX driver and unit tests,MERGED,2014-08-08 08:29:40.000000000,2014-08-09 05:59:01.000000000,2014-08-09 00:26:05.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 2759}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 9924}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12202}]","[{'number': 1, 'created': '2014-08-08 08:29:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/50323b85f53504d00179d55b095fd43103e38a46', 'message': 'Address comments on emc-vnx-direct-driver-juno-update\n\nAlthough https://review.openstack.org/#/c/104413/ is approved,\nreviewers still have some minor comments on Patch 14.\n\nThis fix is to address the comments after the driver update is\nmerged.\n\nChange-Id: I82bac9695c8138cff858013b3affeb0557dfcc02\nCloses-Bug: #1354272\n'}, {'number': 2, 'created': '2014-08-08 11:06:20.000000000', 'files': ['etc/cinder/cinder.conf.sample', 'cinder/tests/test_emc_vnxdirect.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/86fc539a23b0b2cdd6e0803aa3a3cb10fc5758a6', 'message': 'EMC: Fix minor issue in VNX driver and unit tests\n\nThere were some minor issues in initial commit of VNX Direct Driver\nJuno Update (https://review.openstack.org/#/c/104413/), such as typo,\nunclear config option help message and missing period.\n\nThis change fix these issues.\n\nChange-Id: I82bac9695c8138cff858013b3affeb0557dfcc02\nCloses-Bug: #1354272\n'}]",2,112790,86fc539a23b0b2cdd6e0803aa3a3cb10fc5758a6,25,11,2,9924,,,0,"EMC: Fix minor issue in VNX driver and unit tests

There were some minor issues in initial commit of VNX Direct Driver
Juno Update (https://review.openstack.org/#/c/104413/), such as typo,
unclear config option help message and missing period.

This change fix these issues.

Change-Id: I82bac9695c8138cff858013b3affeb0557dfcc02
Closes-Bug: #1354272
",git fetch https://review.opendev.org/openstack/cinder refs/changes/90/112790/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cinder/cinder.conf.sample', 'cinder/tests/test_emc_vnxdirect.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py']",3,50323b85f53504d00179d55b095fd43103e38a46,bug/1354272," help='Storage pool name.'), 'For example, LUN migration is a typical long ' 'running operation, which depends on the LUN size and ' 'the load of the array. ' 'An upper bound in the specific deployment can be set to ' 'avoid unnecessary long wait. '"," help='Storage pool name'),",19,10
openstack%2Fnova~master~I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6,openstack/nova,master,I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6,Allow to unshelve instance booted from volume,MERGED,2014-04-02 16:44:29.000000000,2014-08-09 05:38:13.000000000,2014-08-05 14:38:15.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 360}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2813}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5511}, {'_account_id': 5754}, {'_account_id': 7350}, {'_account_id': 7730}, {'_account_id': 8163}, {'_account_id': 8290}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9236}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-04-02 16:44:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d84deb59803ae6c65ca4a57a5b63cbab395cf7f5', 'message': 'Allow to unshelve instance booted from volume\n\nBecause when we shelve an instance volume are not detached from cinder.\nWe must not check if volume is free, because already used by the shelved\ninstance and we must not try to reattach the volume in cinder because is\nalready attached.\n\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\nCloses-bug: #1287447\n'}, {'number': 2, 'created': '2014-04-03 14:33:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5a91b8d29f76ad8979ce7af57fabddffc9c09e59', 'message': 'Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder.\nWe must not check if the volumes are free, because they are already used\nby the shelved instance and we must not tried to reattach the volume\nin cinder because they are already attached.\n\nCo-Author: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1287447\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n'}, {'number': 3, 'created': '2014-04-04 07:37:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d71726964e91d8a729e034d9d412c6b88e752604', 'message': 'Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder.\nWe must not check if the volumes are free, because they are already used\nby the shelved instance and we must not try to reattach the volume\nin cinder because they are already attached.\n\nCo-Author: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1287447\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n'}, {'number': 4, 'created': '2014-04-07 12:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a5af56c5d41b0509c0d7c9cd316d4f5c0c1f542', 'message': 'Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder.\nWe must not check if the volumes are free, because they are already used\nby the shelved instance and we must not try to reattach the volume\nin cinder because they are already attached.\n\nCo-Author: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1287447\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n'}, {'number': 5, 'created': '2014-04-07 13:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c68f1878e34805192f8c006bc4ccbc69f2bc8871', 'message': 'Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder.\nWe must not check if the volumes are free, because they are already used\nby the shelved instance and we must not try to reattach the volume\nin cinder because they are already attached.\n\nCo-Author: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1287447\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n'}, {'number': 6, 'created': '2014-04-07 13:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/05968eea7dde15b2629e03cdc406227094b81a20', 'message': 'Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder.\nWe must not check if the volumes are free, because they are already used\nby the shelved instance and we must not try to reattach the volume\nin cinder because they are already attached.\n\nCo-Author: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1287447\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n'}, {'number': 7, 'created': '2014-04-07 15:38:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/71ce3deb294ad7c30946c6860b4e2ff8ced0b625', 'message': 'Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder.\nWe must not check if the volumes are free, because they are already used\nby the shelved instance and we must not try to reattach the volume\nin cinder because they are already attached.\n\nCo-Author: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1287447\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n'}, {'number': 8, 'created': '2014-04-14 08:55:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/321d116199c66b250be3d2eed44100796a1acb43', 'message': 'Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder.\nWe must not check if the volumes are free, because they are already used\nby the shelved instance and we must not try to reattach the volume\nin cinder because they are already attached.\n\nCo-Authored-By: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1287447\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n'}, {'number': 9, 'created': '2014-04-18 11:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9ee9ba548563fe09469bd5a64b0676f1015db2bb', 'message': 'Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder.\nWe must not check if the volumes are free, because they are already used\nby the shelved instance and we must not try to reattach the volume\nin cinder because they are already attached.\n\nCo-Authored-By: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1287447\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n'}, {'number': 10, 'created': '2014-04-22 08:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd9cbd82b6d8dbe89d6110a875799785a3225f5f', 'message': 'Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder.\nWe must not check if the volumes are free, because they are already used\nby the shelved instance and we must not try to reattach the volume\nin cinder because they are already attached.\n\nCo-Authored-By: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1287447\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n'}, {'number': 11, 'created': '2014-04-28 08:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/598060463583a0ad538c27a97b2a0a1d4f193012', 'message': 'Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder.\nWe must not check if the volumes are free, because they are already used\nby the shelved instance and we must not try to reattach the volume\nin cinder because they are already attached.\n\nAnd because shelve_offload_instance is called directly in case of boot\nfrom volume, we need to set some missing instance informations: shelved_*,\nhost, and node.\n\nCo-Authored-By: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1287447\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n'}, {'number': 12, 'created': '2014-04-28 08:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f495c1287ea179e9eca17a3f7471419e3abb737d', 'message': 'Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder.\nWe must not check if the volumes are free, because they are already used\nby the shelved instance and we must not try to reattach the volume\nin cinder because they are already attached.\n\nAnd because shelve_offload_instance is called directly in case of boot\nfrom volume, we need to set some missing instance informations: shelved_*,\nhost, and node.\n\nCo-Authored-By: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1287447\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n'}, {'number': 13, 'created': '2014-04-29 11:09:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b8e2f6502857b05bff72da9af0513de35646614', 'message': 'Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder.\nWe must not check if the volumes are free, because they are already used\nby the shelved instance and we must not try to reattach the volume\nin cinder because they are already attached.\n\nCo-Authored-By: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1305399\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n'}, {'number': 14, 'created': '2014-05-07 14:12:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28d314634fc88e84581f75e2b3813fd7ad1e4f30', 'message': ""Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder to kept\nthem 'In-Use' in cinder\nBut when you unshelve this instance, nova ask cinder the reattach theses\nvolumes. This fails, because volume cannot be attached twice.\n\nThis patch permits when we ask the libvirt DriverBlockDevice to attach a\ndevice to the instance to bypass the cinder attachement code that is not needed\nwhen we unshelve an instance, because the cinder volume is kept 'In-use'\nduring the 'shelved' state.\n\nCo-Authored-By: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1305399\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n""}, {'number': 15, 'created': '2014-05-13 03:37:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f26009e11d2552c634a35a1ff1f28a5917962c4', 'message': ""Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder to kept\nthem 'In-Use' in cinder\nBut when you unshelve this instance, nova ask cinder the reattach theses\nvolumes. This fails, because volume cannot be attached twice.\n\nThis patch permits when we ask the libvirt DriverBlockDevice to attach a\ndevice to the instance to bypass the cinder attachement code that is not needed\nwhen we unshelve an instance, because the cinder volume is kept 'In-use'\nduring the 'shelved' state.\n\nCo-Authored-By: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1305399\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n""}, {'number': 16, 'created': '2014-05-28 08:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/22fd6866cdb1e1e52388b02deeac36d8297829b8', 'message': ""Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder to kept\nthem 'In-Use' in cinder\nBut when you unshelve this instance, nova ask cinder the reattach theses\nvolumes. This fails, because volume cannot be attached twice.\n\nThis patch permits when we ask the libvirt DriverBlockDevice to attach a\ndevice to the instance to bypass the cinder attachement code that is not needed\nwhen we unshelve an instance, because the cinder volume is kept 'In-use'\nduring the 'shelved' state.\n\nCo-Authored-By: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1305399\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n""}, {'number': 17, 'created': '2014-06-10 14:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f104f40489909aa0e822df49592ed0143c17a1a1', 'message': ""Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder to kept\nthem 'In-Use' in cinder\nBut when you unshelve this instance, nova ask cinder the reattach theses\nvolumes. This fails, because volume cannot be attached twice.\n\nThis patch permits when we ask the libvirt DriverBlockDevice to attach a\ndevice to the instance to bypass the cinder attachement code that is not needed\nwhen we unshelve an instance, because the cinder volume is kept 'In-use'\nduring the 'shelved' state.\n\nCo-Authored-By: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1305399\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n""}, {'number': 18, 'created': '2014-07-25 12:57:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/54cd0da7abd86717c877a9d51ba5bfcb59202431', 'message': ""Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder to kept\nthem 'In-Use' in cinder\nBut when you unshelve this instance, nova ask cinder the reattach theses\nvolumes. This fails, because volume cannot be attached twice.\n\nThis patch permits when we ask the libvirt DriverBlockDevice to attach a\ndevice to the instance to bypass the cinder attachement code that is not needed\nwhen we unshelve an instance, because the cinder volume is kept 'In-use'\nduring the 'shelved' state.\n\nCo-Authored-By: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1305399\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n""}, {'number': 19, 'created': '2014-07-29 14:42:07.000000000', 'files': ['nova/tests/virt/test_block_device.py', 'nova/tests/compute/test_shelve.py', 'nova/compute/manager.py', 'nova/tests/compute/test_compute.py', 'nova/virt/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8831f3d0e2e2a81a6b406cc9c8bf89bc15989065', 'message': ""Allow to unshelve instance booted from volume\n\nWhen we shelve an instance, volumes are not detached from cinder to kept\nthem 'In-Use' in cinder\nBut when you unshelve this instance, nova ask cinder the reattach theses\nvolumes. This fails, because volume cannot be attached twice.\n\nThis patch permits when we ask the libvirt DriverBlockDevice to attach a\ndevice to the instance to bypass the cinder attachement code that is not needed\nwhen we unshelve an instance, because the cinder volume is kept 'In-use'\nduring the 'shelved' state.\n\nCo-Authored-By: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>\nCloses-bug: #1305399\nChange-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6\n""}]",41,84793,8831f3d0e2e2a81a6b406cc9c8bf89bc15989065,250,24,19,2813,,,0,"Allow to unshelve instance booted from volume

When we shelve an instance, volumes are not detached from cinder to kept
them 'In-Use' in cinder
But when you unshelve this instance, nova ask cinder the reattach theses
volumes. This fails, because volume cannot be attached twice.

This patch permits when we ask the libvirt DriverBlockDevice to attach a
device to the instance to bypass the cinder attachement code that is not needed
when we unshelve an instance, because the cinder volume is kept 'In-use'
during the 'shelved' state.

Co-Authored-By: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@cloudwatt.com>
Closes-bug: #1305399
Change-Id: I780a9407feeb48ecd3e295508ce3e6bc3b09d3e6
",git fetch https://review.opendev.org/openstack/nova refs/changes/93/84793/17 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/test_block_device.py', 'nova/conductor/manager.py', 'nova/compute/manager.py', 'nova/tests/compute/test_shelve.py', 'nova/virt/block_device.py']",5,d84deb59803ae6c65ca4a57a5b63cbab395cf7f5,sileht/1287447-shelve," do_check_attach=True, do_driver_attach=False, do_volume_attach=True): if do_volume_attach: volume_api.attach(context, volume_id, instance['uuid'], self['mount_device']) virt_driver, wait_func=None, do_check_attach=True, do_volume_attach=True): super(DriverImageBlockDevice, self).attach( context, instance, volume_api, virt_driver, do_check_attach=do_check_attach, do_volume_attach=do_volume_attach)"," do_check_attach=True, do_driver_attach=False): volume_api.attach(context, volume_id, instance['uuid'], self['mount_device']) virt_driver, wait_func=None): super(DriverImageBlockDevice, self).attach(context, instance, volume_api, virt_driver)",51,26
openstack%2Fkeystone~master~I62cc1d5efbe0869fd0e501aaa9405ff0b0da0e5e,openstack/keystone,master,I62cc1d5efbe0869fd0e501aaa9405ff0b0da0e5e,Make token_provider_api contain token persistence,MERGED,2014-07-23 17:03:58.000000000,2014-08-09 05:26:52.000000000,2014-08-09 05:26:52.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8978}]","[{'number': 1, 'created': '2014-07-23 17:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/abf038b7a3d41dc7c9760ad74ceeadccff8a0b96', 'message': 'Make token_provider_api contain token persistence\n\nThe token_provider_api now houses the token persistence manager\ndirectly. A new token_api provider has been created that just\nproxies to token_provider_api.persistence.\n\nThis is in support of deprecating use of token_api internal to\nKeystone and migrating direct uses of token_api to gate through\nthe token_provider_api methods.\n\nUses of the token_api within the provider and provider drivers\nhas been lifted up to the token_provider_api manager and now\nutilize the persistence manager directly.\n\nChange-Id: I62cc1d5efbe0869fd0e501aaa9405ff0b0da0e5e\nbp: non-persistent-tokens\n'}, {'number': 2, 'created': '2014-07-23 17:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/46ef2910f69ae6bdcd662fdbfa74645e5f851b16', 'message': 'Make token_provider_api contain token persistence\n\nThe token_provider_api now houses the token persistence manager\ndirectly. A new token_api provider has been created that just\nproxies to token_provider_api.persistence.\n\nThis is in support of deprecating use of token_api internal to\nKeystone and migrating direct uses of token_api to gate through\nthe token_provider_api methods.\n\nUses of the token_api within the provider and provider drivers\nhas been lifted up to the token_provider_api manager and now\nutilize the persistence manager directly.\n\nChange-Id: I62cc1d5efbe0869fd0e501aaa9405ff0b0da0e5e\nbp: non-persistent-tokens\n'}, {'number': 3, 'created': '2014-07-24 01:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a88ea82eb1d933d920f81d7458cf83f3766efa2f', 'message': 'Make token_provider_api contain token persistence\n\nThe token_provider_api now houses the token persistence manager\ndirectly. A new token_api provider has been created that just\nproxies to token_provider_api.persistence.\n\nThis is in support of deprecating use of token_api internal to\nKeystone and migrating direct uses of token_api to gate through\nthe token_provider_api methods.\n\nUses of the token_api within the provider and provider drivers\nhas been lifted up to the token_provider_api manager and now\nutilize the persistence manager directly.\n\nChange-Id: I62cc1d5efbe0869fd0e501aaa9405ff0b0da0e5e\nbp: non-persistent-tokens\n'}, {'number': 4, 'created': '2014-07-24 03:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4f1085420d57df7807f0b5d94105214eade87273', 'message': 'Make token_provider_api contain token persistence\n\nThe token_provider_api now houses the token persistence manager\ndirectly. A new token_api provider has been created that just\nproxies to token_provider_api.persistence.\n\nThis is in support of deprecating use of token_api internal to\nKeystone and migrating direct uses of token_api to gate through\nthe token_provider_api methods.\n\nUses of the token_api within the provider and provider drivers\nhas been lifted up to the token_provider_api manager and now\nutilize the persistence manager directly.\n\nChange-Id: I62cc1d5efbe0869fd0e501aaa9405ff0b0da0e5e\nbp: non-persistent-tokens\n'}, {'number': 5, 'created': '2014-07-24 23:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/05c83c2c9053588ac0f77508aa8f5ba38c47c02b', 'message': 'Make token_provider_api contain token persistence\n\nThe token_provider_api now houses the token persistence manager\ndirectly. A new token_api provider has been created that just\nproxies to token_provider_api.persistence.\n\nThis is in support of deprecating use of token_api internal to\nKeystone and migrating direct uses of token_api to gate through\nthe token_provider_api methods.\n\nUses of the token_api within the provider and provider drivers\nhas been lifted up to the token_provider_api manager and now\nutilize the persistence manager directly.\n\nChange-Id: I62cc1d5efbe0869fd0e501aaa9405ff0b0da0e5e\nbp: non-persistent-tokens\n'}, {'number': 6, 'created': '2014-07-25 16:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c0211c4c42def27372520469034738082c2ac39e', 'message': 'Make token_provider_api contain token persistence\n\nThe token_provider_api now houses the token persistence manager\ndirectly. A new token_api provider has been created that just\nproxies to token_provider_api.persistence.\n\nThis is in support of deprecating use of token_api internal to\nKeystone and migrating direct uses of token_api to gate through\nthe token_provider_api methods.\n\nUses of the token_api within the provider and provider drivers\nhas been lifted up to the token_provider_api manager and now\nutilize the persistence manager directly.\n\nChange-Id: I62cc1d5efbe0869fd0e501aaa9405ff0b0da0e5e\nbp: non-persistent-tokens\n'}, {'number': 7, 'created': '2014-08-04 17:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/65c02a9dc9c89654fb173df5a8a9b6803215c2e5', 'message': 'Make token_provider_api contain token persistence\n\nThe token_provider_api now houses the token persistence manager\ndirectly. A new token_api provider has been created that just\nproxies to token_provider_api.persistence.\n\nThis is in support of deprecating use of token_api internal to\nKeystone and migrating direct uses of token_api to gate through\nthe token_provider_api methods.\n\nUses of the token_api within the provider and provider drivers\nhas been lifted up to the token_provider_api manager and now\nutilize the persistence manager directly.\n\nChange-Id: I62cc1d5efbe0869fd0e501aaa9405ff0b0da0e5e\nbp: non-persistent-tokens\n'}, {'number': 8, 'created': '2014-08-05 17:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d313b238d5eace8a89b9b3cdce0de4039e4c76e3', 'message': 'Make token_provider_api contain token persistence\n\nThe token_provider_api now houses the token persistence manager\ndirectly. A new token_api provider has been created that just\nproxies to token_provider_api.persistence.\n\nThis is in support of deprecating use of token_api internal to\nKeystone and migrating direct uses of token_api to gate through\nthe token_provider_api methods.\n\nUses of the token_api within the provider and provider drivers\nhas been lifted up to the token_provider_api manager and now\nutilize the persistence manager directly.\n\nChange-Id: I62cc1d5efbe0869fd0e501aaa9405ff0b0da0e5e\nbp: non-persistent-tokens\n'}, {'number': 9, 'created': '2014-08-06 16:49:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4a60fbdce16d78b4360e1a3353dcad35faa18204', 'message': 'Make token_provider_api contain token persistence\n\nThe token_provider_api now houses the token persistence manager\ndirectly. A new token_api provider has been created that just\nproxies to token_provider_api.persistence.\n\nThis is in support of deprecating use of token_api internal to\nKeystone and migrating direct uses of token_api to gate through\nthe token_provider_api methods.\n\nUses of the token_api within the provider and provider drivers\nhas been lifted up to the token_provider_api manager and now\nutilize the persistence manager directly.\n\nChange-Id: I62cc1d5efbe0869fd0e501aaa9405ff0b0da0e5e\nbp: non-persistent-tokens\n'}, {'number': 10, 'created': '2014-08-06 23:23:09.000000000', 'files': ['keystone/token/provider.py', 'keystone/token/providers/common.py', 'keystone/token/persistence/core.py', 'keystone/tests/unit/token/test_token_persistence_proxy.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/718d64ef45e8cefaf22b59ee216040073719f8d5', 'message': 'Make token_provider_api contain token persistence\n\nThe token_provider_api now houses the token persistence manager\ndirectly. A new token_api provider has been created that just\nproxies to token_provider_api.persistence.\n\nThis is in support of deprecating use of token_api internal to\nKeystone and migrating direct uses of token_api to gate through\nthe token_provider_api methods.\n\nUses of the token_api within the provider and provider drivers\nhas been lifted up to the token_provider_api manager and now\nutilize the persistence manager directly.\n\nChange-Id: I62cc1d5efbe0869fd0e501aaa9405ff0b0da0e5e\nbp: non-persistent-tokens\n'}]",22,109041,718d64ef45e8cefaf22b59ee216040073719f8d5,58,12,10,2903,,,0,"Make token_provider_api contain token persistence

The token_provider_api now houses the token persistence manager
directly. A new token_api provider has been created that just
proxies to token_provider_api.persistence.

This is in support of deprecating use of token_api internal to
Keystone and migrating direct uses of token_api to gate through
the token_provider_api methods.

Uses of the token_api within the provider and provider drivers
has been lifted up to the token_provider_api manager and now
utilize the persistence manager directly.

Change-Id: I62cc1d5efbe0869fd0e501aaa9405ff0b0da0e5e
bp: non-persistent-tokens
",git fetch https://review.opendev.org/openstack/keystone refs/changes/41/109041/9 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/token/provider.py', 'keystone/token/providers/common.py', 'keystone/token/persistence/core.py', 'keystone/tests/unit/token/test_token_persistence_proxy.py']",4,abf038b7a3d41dc7c9760ad74ceeadccff8a0b96,bp/non-persistent-tokens, manager = token.persistence.PersistenceManager() manager = token.persistence.PersistenceManager() manager = token.persistence.PersistenceManager(), manager = token.persistence.Manager() manager = token.persistence.Manager() manager = token.persistence.Manager(),163,142
openstack%2Fopenstack-manuals~master~Ifd0fd09dc745b0c8fc809961e9c821d9e11e4d06,openstack/openstack-manuals,master,Ifd0fd09dc745b0c8fc809961e9c821d9e11e4d06,Remove VMware ESX driver,MERGED,2014-08-07 19:46:15.000000000,2014-08-09 05:24:55.000000000,2014-08-09 05:24:55.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 3153}]","[{'number': 1, 'created': '2014-08-07 19:46:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/11077b3625c67d224deb50e30666d1455127a870', 'message': 'Remove VMware ESX driver\n\nJuno removes the ESX driver, remove it from the docu.\n\nChange-Id: Ifd0fd09dc745b0c8fc809961e9c821d9e11e4d06\nCloses-Bug: #1353847\n'}, {'number': 2, 'created': '2014-08-07 19:46:41.000000000', 'files': ['doc/config-reference/compute/section_hypervisor_vmware.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/91f738dc2221f7d3c23f718c9abc8547ef7f0d9a', 'message': 'Remove VMware ESX driver\n\nJuno removes the ESX driver, remove it from the docu.\n\nChange-Id: Ifd0fd09dc745b0c8fc809961e9c821d9e11e4d06\nCloses-Bug: #1353847\n'}]",0,112665,91f738dc2221f7d3c23f718c9abc8547ef7f0d9a,13,4,2,6547,,,0,"Remove VMware ESX driver

Juno removes the ESX driver, remove it from the docu.

Change-Id: Ifd0fd09dc745b0c8fc809961e9c821d9e11e4d06
Closes-Bug: #1353847
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/65/112665/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/compute/section_hypervisor_vmware.xml'],1,11077b3625c67d224deb50e30666d1455127a870,bug/1353847,," <section xml:id=""VMwareESXDriver_details""> <title>VMware ESX driver</title> <para>This section covers details of using the VMwareESXDriver. The ESX Driver has not been extensively tested and is not recommended. To configure the VMware vCenter driver instead, see <xref linkend=""VMwareVCDriver_details""/>.</para> <warning> <para> The VMware ESX driver has been deprecated in the Icehouse release and will be removed with the Juno release.</para> </warning> <section xml:id=""VMwareESXDriver_configuration_options""> <title>VMwareESXDriver configuration options</title> <para>When you use the VMwareESXDriver (no vCenter) with OpenStack Compute, add the following VMware-specific configuration options to the <filename>nova.conf</filename> file:</para> <programlisting language=""ini"">[DEFAULT] compute_driver=vmwareapi.VMwareESXDriver [vmware] host_ip=&lt;ESXi host IP&gt; host_username=&lt;ESXi host username&gt; host_password=&lt;ESXi host password&gt; wsdl_location=http://127.0.0.1:8080/vmware/SDK/wsdl/vim25/vimService.wsdl</programlisting> <para>Remember that you must have one <systemitem class=""service"">nova-compute</systemitem> service for each ESXi host. It is recommended that this host run as a VM on the same ESXi host that it manages.</para> <note> <para>Many <filename>nova.conf</filename> options are relevant to libvirt but do not apply to this driver.</para> </note> </section> <section xml:id=""VMwareESXDriver_limitations""> <title>Requirements and limitations</title> <para>The ESXDriver cannot use many of the vSphere platform advanced capabilities, namely vMotion, high availability, and DRS.</para> </section> </section>",0,40
openstack%2Fopenstack-manuals~stable%2Ficehouse~I9c8f0658e437645cdae17600071cb3652fc2e104,openstack/openstack-manuals,stable/icehouse,I9c8f0658e437645cdae17600071cb3652fc2e104,"Remove errant ""apt-get install python-novaclient""",MERGED,2014-08-09 00:10:32.000000000,2014-08-09 05:08:08.000000000,2014-08-09 05:08:08.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-09 00:10:32.000000000', 'files': ['doc/common/section_cli_install.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9d0abbfa0b29c68c9e4b4728032197274eabf860', 'message': 'Remove errant ""apt-get install python-novaclient""\n\nI removed the paragraph associated with an errant\n""apt-get install python-novaclient"" in the common client\ninstallation section. The existing ""Ubuntu and Debian""\nparagraph provides suitable instructions.\n\nChange-Id: I9c8f0658e437645cdae17600071cb3652fc2e104\nPartial-Bug: #1341203\n'}]",0,113048,9d0abbfa0b29c68c9e4b4728032197274eabf860,8,3,1,9515,,,0,"Remove errant ""apt-get install python-novaclient""

I removed the paragraph associated with an errant
""apt-get install python-novaclient"" in the common client
installation section. The existing ""Ubuntu and Debian""
paragraph provides suitable instructions.

Change-Id: I9c8f0658e437645cdae17600071cb3652fc2e104
Partial-Bug: #1341203
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/48/113048/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/section_cli_install.xml'],1,9d0abbfa0b29c68c9e4b4728032197274eabf860,bug/1341203,, <title>Ubuntu 12.04/14.04</title> <para>A packaged version enables you to use <package>dpkg</package> or <package>apt-get</package> to install the <package>python-novaclient</package>: <screen><prompt>#</prompt> <userinput>apt-get install python-novaclient</userinput></screen> </para> </formalpara> <formalpara>,0,10
openstack%2Fopenstack-manuals~master~I4b860b2c69a247fe307c1d602b8f8e5792be33fa,openstack/openstack-manuals,master,I4b860b2c69a247fe307c1d602b8f8e5792be33fa,Added network troubleshooting steps,ABANDONED,2014-08-09 04:45:31.000000000,2014-08-09 04:48:32.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-08-09 04:45:31.000000000', 'files': ['doc/networking-guide/ch_debugging.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/66d1f1851f7bb107aaa78ab5ad7838f1f10496e2', 'message': 'Added network troubleshooting steps\n\nChange-Id: I4b860b2c69a247fe307c1d602b8f8e5792be33fa\n'}]",0,113065,66d1f1851f7bb107aaa78ab5ad7838f1f10496e2,3,1,1,9930,,,0,"Added network troubleshooting steps

Change-Id: I4b860b2c69a247fe307c1d602b8f8e5792be33fa
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/65/113065/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/ch_debugging.xml'],1,66d1f1851f7bb107aaa78ab5ad7838f1f10496e2,Neutron-Debugging, following:</para>, following:</para> ,1,3
openstack%2Fopenstack-manuals~master~I880e08c2ce2c41d44e402dbaa6433e4f5ba871f1,openstack/openstack-manuals,master,I880e08c2ce2c41d44e402dbaa6433e4f5ba871f1,(WIP) Adding content to deployment file,ABANDONED,2014-08-09 04:21:06.000000000,2014-08-09 04:35:10.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-08-09 04:21:06.000000000', 'files': ['doc/networking-guide/ch_deployment.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d8e9dea4861a19f7dae94556b8a2e70695f54c30', 'message': '(WIP) Adding content to deployment file\n\nAdding new images folder and file, adding in new content,\nfixing XML errors.\n\nChange-Id: I880e08c2ce2c41d44e402dbaa6433e4f5ba871f1\n'}]",0,113062,d8e9dea4861a19f7dae94556b8a2e70695f54c30,4,1,1,10607,,,0,"(WIP) Adding content to deployment file

Adding new images folder and file, adding in new content,
fixing XML errors.

Change-Id: I880e08c2ce2c41d44e402dbaa6433e4f5ba871f1
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/62/113062/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/ch_deployment.xml'],1,d8e9dea4861a19f7dae94556b8a2e70695f54c30,asettleSWARM," xml:id=""ch_deployment""> <section xml:id=""deployment_overview""> that consists of these types of nodes:</para></section> "," xml:id=""ch_deployment""> that consists of these types of nodes:",5,2
openstack%2Fopenstack-manuals~master~I426ab04c3e70ef5dcee22bc6a1681c7566aa23da,openstack/openstack-manuals,master,I426ab04c3e70ef5dcee22bc6a1681c7566aa23da,Adding new content to deployment file and new images folder,ABANDONED,2014-08-09 03:35:22.000000000,2014-08-09 04:15:10.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-08-09 03:35:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a96641e5e32cc6a0ffb3cd073c8323529a15ddb7', 'message': 'Adding new content to deployment file and new images folder\n\nThis patch includes content from Red Hat documentation and\nadds in first image.\n\nChange-Id: I426ab04c3e70ef5dcee22bc6a1681c7566aa23da\n'}, {'number': 2, 'created': '2014-08-09 03:53:47.000000000', 'files': ['doc/networking-guide/ch_deployment.xml', 'doc/networking-guide/Images/deployment_architecture.png'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/527854ab2b11ee6dd71dbd245812e9d3caf090e7', 'message': 'Adding new content to deployment file and new images folder\n\nThis patch includes content from Red Hat documentation and\nadds in first image.\n\nChange-Id: I426ab04c3e70ef5dcee22bc6a1681c7566aa23da\n'}]",0,113057,527854ab2b11ee6dd71dbd245812e9d3caf090e7,7,1,2,10607,,,0,"Adding new content to deployment file and new images folder

This patch includes content from Red Hat documentation and
adds in first image.

Change-Id: I426ab04c3e70ef5dcee22bc6a1681c7566aa23da
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/57/113057/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/networking-guide/ch_deployment.xml', 'doc/networking-guide/Images/deployment_architecture.png']",2,a96641e5e32cc6a0ffb3cd073c8323529a15ddb7,asettleSWARM,,,39,6
openstack%2Fnova~master~Ib505314486c9dd352a7902fcfb4154863ac6eccf,openstack/nova,master,Ib505314486c9dd352a7902fcfb4154863ac6eccf,Implement Libvirt Storage Pools Image Backend,ABANDONED,2014-08-02 07:30:02.000000000,2014-08-09 03:57:56.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 7677}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-02 07:30:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4cfb7ec7544ec7144d185efd4cf9ac027e9ffd2b', 'message': 'Implement Libvirt Storage Pools Image Backend\n\nThis commit introduces support for using libvirt storage\npools as the default image backend for the libvirt driver.\nThe image cache for the libvirt driver has been updated to\ntake advantage of this functionality.\n\nNote: As introduced in this commit (at the time of writing)\n      using libvirt storage pools with Ceph requires an extra\n      class, to be introduced in a follow-up commit.\n\nImplements bp: use-libvirt-storage-pools\n\nChange-Id: Ib505314486c9dd352a7902fcfb4154863ac6eccf\n'}, {'number': 2, 'created': '2014-08-04 14:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/26b0a4420e9a501123f9b7f931235bc49d990767', 'message': 'Implement Libvirt Storage Pools Image Backend\n\nThis commit introduces support for using libvirt storage\npools as the default image backend for the libvirt driver.\nThe image cache for the libvirt driver has been updated to\ntake advantage of this functionality.\n\nNote: As introduced in this commit (at the time of writing)\n      using libvirt storage pools with Ceph requires an extra\n      class, to be introduced in a follow-up commit.\n\nImplements bp: use-libvirt-storage-pools\n\nChange-Id: Ib505314486c9dd352a7902fcfb4154863ac6eccf\n'}, {'number': 3, 'created': '2014-08-04 18:06:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d469e5387d2d0cd67da85d018a3d5743dbe12201', 'message': 'Implement Libvirt Storage Pools Image Backend\n\nThis commit introduces support for using libvirt storage\npools as the default image backend for the libvirt driver.\nThe image cache for the libvirt driver has been updated to\ntake advantage of this functionality.\n\nNote: As introduced in this commit (at the time of writing)\n      using libvirt storage pools with Ceph requires an extra\n      class, to be introduced in a follow-up commit.\n\nImplements bp: use-libvirt-storage-pools\n\nChange-Id: Ib505314486c9dd352a7902fcfb4154863ac6eccf\n'}, {'number': 4, 'created': '2014-08-04 18:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4df311032360fe515ee448f7a8d78f3005c61a06', 'message': 'Implement Libvirt Storage Pools Image Backend\n\nThis commit introduces support for using libvirt storage\npools as the default image backend for the libvirt driver.\nThe image cache for the libvirt driver has been updated to\ntake advantage of this functionality.\n\nNote: As introduced in this commit (at the time of writing)\n      using libvirt storage pools with Ceph requires an extra\n      class, to be introduced in a follow-up commit.\n\nImplements bp: use-libvirt-storage-pools\n\nChange-Id: Ib505314486c9dd352a7902fcfb4154863ac6eccf\n'}, {'number': 5, 'created': '2014-08-04 19:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/239099523fc160ba377431ca5846bd3a85212b44', 'message': 'Implement Libvirt Storage Pools Image Backend\n\nThis commit introduces support for using libvirt storage\npools as the default image backend for the libvirt driver.\nThe image cache for the libvirt driver has been updated to\ntake advantage of this functionality.\n\nNote: As introduced in this commit (at the time of writing)\n      using libvirt storage pools with Ceph requires an extra\n      class, to be introduced in a follow-up commit.\n\nImplements bp: use-libvirt-storage-pools\n\nChange-Id: Ib505314486c9dd352a7902fcfb4154863ac6eccf\n'}, {'number': 6, 'created': '2014-08-04 20:56:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/755d81a2ed7302406b27f4753e6adebcaf50d855', 'message': 'Implement Libvirt Storage Pools Image Backend\n\nThis commit introduces support for using libvirt storage\npools as the default image backend for the libvirt driver.\nThe image cache for the libvirt driver has been updated to\ntake advantage of this functionality.\n\nNote: As introduced in this commit (at the time of writing)\n      using libvirt storage pools with Ceph requires an extra\n      class, to be introduced in a follow-up commit.\n\nImplements bp: use-libvirt-storage-pools\n\nChange-Id: Ib505314486c9dd352a7902fcfb4154863ac6eccf\n'}, {'number': 7, 'created': '2014-08-05 18:24:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/efce6111585fb5d809bb6af0c733243cc4596c19', 'message': 'Implement Libvirt Storage Pools Image Backend\n\nThis commit introduces support for using libvirt storage\npools as the default image backend for the libvirt driver.\nThe image cache for the libvirt driver has been updated to\ntake advantage of this functionality.\n\nNote: As introduced in this commit (at the time of writing)\n      using libvirt storage pools with Ceph requires an extra\n      class, to be introduced in a follow-up commit.\n\nImplements bp: use-libvirt-storage-pools\n\nChange-Id: Ib505314486c9dd352a7902fcfb4154863ac6eccf\n'}, {'number': 8, 'created': '2014-08-05 18:33:55.000000000', 'files': ['nova/virt/libvirt/imagecache.py', 'nova/tests/virt/libvirt/test_imagebackend.py', 'nova/virt/fake.py', 'nova/tests/virt/libvirt/fakelibvirt.py', 'nova/virt/libvirt/config.py', 'nova/virt/driver.py', 'nova/tests/virt/libvirt/fake_libvirt_utils.py', 'nova/virt/libvirt/utils.py', 'nova/tests/compute/test_compute.py', 'nova/virt/disk/api.py', 'nova/virt/hyperv/driver.py', 'nova/virt/libvirt/driver.py', 'nova/virt/xenapi/driver.py', 'nova/virt/baremetal/imagecache.py', 'nova/virt/vmwareapi/driver.py', 'nova/tests/compute/test_rpcapi.py', 'nova/tests/virt/libvirt/fake_imagebackend.py', 'nova/tests/virt/libvirt/test_imagecache.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/tests/virt/libvirt/test_driver.py', 'nova/virt/baremetal/driver.py', 'nova/virt/libvirt/imagebackend.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b742b7e25122218e3c211fe57e960a07a43688d6', 'message': 'Implement Libvirt Storage Pools Image Backend\n\nThis commit introduces support for using libvirt storage\npools as the default image backend for the libvirt driver.\nThe image cache for the libvirt driver has been updated to\ntake advantage of this functionality.\n\nNote: As introduced in this commit (at the time of writing)\n      using libvirt storage pools with Ceph requires an extra\n      class, to be introduced in a follow-up commit.\n\nImplements bp: use-libvirt-storage-pools\n\nChange-Id: Ib505314486c9dd352a7902fcfb4154863ac6eccf\n'}]",0,111459,b742b7e25122218e3c211fe57e960a07a43688d6,39,6,8,7677,,,0,"Implement Libvirt Storage Pools Image Backend

This commit introduces support for using libvirt storage
pools as the default image backend for the libvirt driver.
The image cache for the libvirt driver has been updated to
take advantage of this functionality.

Note: As introduced in this commit (at the time of writing)
      using libvirt storage pools with Ceph requires an extra
      class, to be introduced in a follow-up commit.

Implements bp: use-libvirt-storage-pools

Change-Id: Ib505314486c9dd352a7902fcfb4154863ac6eccf
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/111459/7 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/imagecache.py', 'nova/tests/virt/libvirt/test_imagebackend.py', 'nova/virt/fake.py', 'nova/tests/virt/libvirt/fakelibvirt.py', 'nova/virt/libvirt/config.py', 'nova/virt/driver.py', 'nova/tests/virt/libvirt/fake_libvirt_utils.py', 'nova/virt/libvirt/utils.py', 'nova/virt/disk/api.py', 'nova/virt/hyperv/driver.py', 'nova/virt/libvirt/driver.py', 'nova/virt/xenapi/driver.py', 'nova/virt/vmwareapi/driver.py', 'nova/tests/virt/libvirt/test_imagecache.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/tests/virt/libvirt/test_driver.py', 'nova/virt/libvirt/imagebackend.py']",18,4cfb7ec7544ec7144d185efd4cf9ac027e9ffd2b,bp/use-libvirt-storage-pools,"import libvirtCONF.import_opt('instances_path', 'nova.compute.manager')def _dict_from_line(line): if not line: return {} try: return jsonutils.loads(line) except (TypeError, ValueError) as e: msg = (_(""Could not load line %(line)s, got error "" ""%(error)s"") % {'line': line, 'error': unicode(e)}) raise exception.InvalidDiskInfo(reason=msg) def _write_disk_info_to_file(self, image, driver_format): @utils.synchronized(self.disk_info_path, external=False, lock_path=self.lock_path) def write_disk_info_to_file_sync(): # Use os.open to create it without group or world write permission. fd = os.open(self.disk_info_path, os.O_RDONLY | os.O_CREAT, 0o644) with os.fdopen(fd, ""r"") as disk_info_file: line = disk_info_file.read().rstrip() dct = _dict_from_line(line) if image in dct: msg = _(""Attempted overwrite of an existing value."") raise exception.InvalidDiskInfo(reason=msg) dct.update({image: driver_format}) tmp_path = self.disk_info_path + "".tmp"" fd = os.open(tmp_path, os.O_WRONLY | os.O_CREAT, 0o644) with os.fdopen(fd, ""w"") as tmp_file: tmp_file.write('%s\n' % jsonutils.dumps(dct)) os.rename(tmp_path, self.disk_info_path) if self.disk_info_path is not None: try: fileutils.ensure_tree(os.path.dirname(self.disk_info_path)) write_disk_info_to_file_sync() except OSError as e: raise exception.DiskInfoReadWriteFail(reason=unicode(e)) def _read_disk_info_from_file(self, image): if (self.disk_info_path is not None and os.path.exists(self.disk_info_path)): try: with open(self.disk_info_path) as disk_info_file: line = disk_info_file.read().rstrip() dct = _dict_from_line(line) for img, driver_format in dct.iteritems(): if img == image: return driver_format except OSError as e: raise exception.DiskInfoReadWriteFail(reason=unicode(e)) return None driver_format = self._read_disk_info_from_file(self.path) if driver_format is None: self._write_disk_info_to_file(self.path, driver_format) def is_shared_block_storage(self):class LibvirtVolume(Image): NAME_FMT = ""%(instance)s_%(name)s"" POOL_NAME = 'nova-disks-pool' CACHE_POOL_NAME = 'nova-base-images-pool' FILE_BASED_POOLS = ('dir', 'fs', 'netfs', 'gluster') NET_BASED_POOLS = ('netfs', 'gluster', 'sheepdog', 'rbd') FORMATS_WITH_BACKING_STORES = ('cow', 'qcow', 'qcow2', 'qed') @classmethod def name_volume(cls, instance, disk_name): return cls.NAME_FMT % {'instance': instance['uuid'], 'name': disk_name} @classmethod def refresh_pool(cls, conn): pool = conn.storagePoolLookupByName(cls.POOL_NAME) pool.refresh() @classmethod def check_volume_exists_in_pool(cls, pool, volume_name): try: pool.storageVolLookupByName(volume_name) except libvirt.libvirtError as e: if e.get_error_code() == libvirt.VIR_ERR_NO_STORAGE_VOL: return False else: raise e else: return True @classmethod def extract_disk_name(cls, vol_name): return vol_name.split('_', 1)[1] @classmethod def try_get_volume_by_name(cls, conn, vol_name, pool_name=None): if pool_name is None: pool_name = cls.POOL_NAME pool = conn.storagePoolLookupByName(pool_name) try: return pool.storageVolLookupByName(vol_name) except libvirt.libvirtError as e: if e.get_error_code() == libvirt.VIR_ERR_NO_STORAGE_VOL: return None else: raise e @classmethod def get_parsed_volume_by_name(cls, conn, vol_name, pool_name=None): if pool_name is None: pool_name = cls.POOL_NAME pool = conn.storagePoolLookupByName(pool_name) vol = pool.storageVolLookupByName(vol_name) vol_parsed = vconfig.LibvirtConfigStorageVolume() vol_parsed.parse_str(vol.XMLDesc(0)) return vol_parsed @classmethod def volumes_for_instance(cls, conn, instance): pattern = instance['uuid'] + '_' pool = conn.storagePoolLookupByName(cls.POOL_NAME) for vol in pool.listAllVolumes(): if vol.name().startswith(pattern): yield vol @classmethod @contextlib.contextmanager def temp_pool(self, conn, base_dir, prefix=''): target_name = os.path.basename(base_dir) pool_name = 'nova-temp-%(pr)s%(name)s-pool' % {'pr': prefix, 'name': target_name} # create a pool in the temp directory pool_desc = vconfig.LibvirtConfigStoragePool() pool_desc.name = pool_name pool_desc.type = 'dir' pool_desc.target['path'] = base_dir temp_pool = conn.storagePoolCreateXML(pool_desc.to_xml(), 0) try: yield temp_pool finally: temp_pool.destroy() def _temp_pool(self, base_dir, prefix=''): return self.temp_pool(self._conn, base_dir, prefix) def __init__(self, conn, instance=None, disk_name=None, volume_name=None, volume_type=None, write_format=True): self.lock_path = os.path.join(CONF.instances_path, 'locks') self._conn = conn self.pool = conn.storagePoolLookupByName(self.POOL_NAME) self.pool_parsed = vconfig.LibvirtConfigStoragePool() self.pool_parsed.parse_str(self.pool.XMLDesc(0)) self.cache_pool = conn.storagePoolLookupByName(self.CACHE_POOL_NAME) self.cache_pool_parsed = vconfig.LibvirtConfigStoragePool() self.cache_pool_parsed.parse_str(self.cache_pool.XMLDesc(0)) if volume_name is None: self.volume_name = self.name_volume(instance, disk_name) else: self.volume_name = volume_name if self.pool_parsed.type in self.FILE_BASED_POOLS: self.disk_info_path = os.path.join(CONF.instances_path, instance['uuid'], 'disk.info') else: self.disk_info_path = None # if we're not in a file-based pool, we might get # passed raw or qcow2 anyway because images_type # was set to 'libvirt-storage' if (self.pool_parsed.type in self.FILE_BASED_POOLS or self.pool_parsed.type == 'disk'): self.volume_type = volume_type else: self.volume_type = None self.preallocate = (self.pool_parsed.type in self.FILE_BASED_POOLS and CONF.preallocate_images != 'none') if not self.pool.isActive(): self.pool.create() # NB(sross): don't write the format on snapshots, because # we don't necessarily have an instance directory self.write_format = write_format self.driver_format = None self.correct_format() # avoid the pitfalls of raw def delete(self): """"""Delete the volume associated with this image."""""" vol = self.pool.storageVolLookupByName(self.volume_name) vol.delete() @property def is_block_dev(self): return self.pool_parsed.type not in self.FILE_BASED_POOLS def libvirt_info(self, disk_bus, disk_dev, device_type, cache_mode, extra_specs, hypervisor_version): info = vconfig.LibvirtConfigGuestDisk() info.source_type = 'volume' info.source_volume = self.volume_name info.source_pool = self.pool.name() info.source_device = device_type info.target_bus = disk_bus info.target_dev = disk_dev info.driver_cache = cache_mode info.driver_format = self.driver_format driver_name = libvirt_utils.pick_disk_driver_name(hypervisor_version, self.is_block_dev) info.driver_name = driver_name tune_items = ['disk_read_bytes_sec', 'disk_read_iops_sec', 'disk_write_bytes_sec', 'disk_write_iops_sec', 'disk_total_bytes_sec', 'disk_total_iops_sec'] # Note(yaguang): Currently, the only tuning available is Block I/O # throttling for qemu. for key, value in extra_specs.iteritems(): scope = key.split(':') if len(scope) > 1 and scope[0] == 'quota': if scope[1] in tune_items: setattr(info, scope[1], value) return info def check_image_exists(self): if self.is_shared_block_storage(): self.pool.refresh() return self.check_volume_exists_in_pool(self.pool, self.volume_name) def cache(self, fetch_func, filename, size=None, *args, **kwargs): @utils.synchronized(filename, external=True, lock_path=self.lock_path) def fetch_func_sync(target, *args, **kwargs): target_path = os.path.join(self.cache_pool_parsed.target['path'], target) fetch_func(target=target_path, *args, **kwargs) self.cache_pool.refresh() if (not self.check_image_exists() or not self.check_volume_exists_in_pool(self.cache_pool, filename)): self.create_image(fetch_func_sync, filename, size, *args, **kwargs) def _check_supports_backing_store(self): return (self.pool_parsed.type in self.FILE_BASED_POOLS and self.volume_type in self.FORMATS_WITH_BACKING_STORES) def _make_libvirt_volume_copier(self, base_name, target_pool, use_backing_store): @utils.synchronized(base_name, external=True, lock_path=self.lock_path) def copy_libvirt_volume(base, target_name, size, target_format=None, permissions=None): vol_info = vconfig.LibvirtConfigStorageVolume() vol_info.name = target_name vol_info.capacity = size or base.info()[1] flags = 0 # no allocation element means full allocation if not self.preallocate: vol_info.allocation = 0 vol_info.target['permissions'] = permissions # NB(sross): qcow2 doesn't actually support preallocation, # and preallocating metadata with a backing store # does not work vol_info.target['format'] = target_format or self.volume_type if use_backing_store: vol_info.backing_store = {'path': base.path()} res = target_pool.createXML(vol_info.to_xml(), flags) else: res = target_pool.createXMLFrom(vol_info.to_xml(), base, flags) # attempt to resize the fs if necessary and possible if res and size is not None and size != base.info()[1]: self._try_resize_fs(res, size) return copy_libvirt_volume def _try_resize_fs(self, vol, new_size): # NB(sross): currently, we can only resize the filesystems # of file-based volumes and LVM-based volumes if (self.pool_parsed.type in self.FILE_BASED_POOLS + ('logical',)): vol_parsed = vconfig.LibvirtConfigStorageVolume() vol_parsed.parse_str(vol.XMLDesc(0)) target_path = vol_parsed.target['path'] use_cow = (vol_parsed.target['format'] in self.FORMATS_WITH_BACKING_STORES) disk.try_resize_fs(target_path, use_cow) def create_empty_image(self, size): """"""Creates an empty image of the specified size."""""" vol_info = vconfig.LibvirtConfigStorageVolume() vol_info.name = self.volume_name vol_info.capacity = size vol_info.target['format'] = self.volume_type vol_info.target['permissions'] = {'owner': os.getuid(), 'group': os.getgid()} return self.pool.createXML(vol_info.to_xml(), 0) # NB(sross): unlike elsewhere, base is just a volume name here, not a path def create_image(self, prepare_template, base, size, *args, **kwargs): try: base_vol = self.cache_pool.storageVolLookupByName(base) except libvirt.libvirtError as e: if e.get_error_code() != libvirt.VIR_ERR_NO_STORAGE_VOL: raise e else: prepare_template(target=base, max_size=size, *args, **kwargs) base_vol = self.cache_pool.storageVolLookupByName(base) self.verify_base_size(base_vol, size) if not self.check_image_exists(): use_backing_store = self._check_supports_backing_store() copier = self._make_libvirt_volume_copier(base, self.pool, use_backing_store) copier(base_vol, self.volume_name, size) self.correct_format() def transition_from_volume(self, volume, new_size=None, delete=True): copier = self._make_libvirt_volume_copier(volume.name(), self.pool, False) size = new_size or volume.info()[1] res = copier(volume, self.volume_name, size) if res is not None: self.correct_format() if delete: volume.delete() return res def transition_from_file(self, file_path, new_size=None, delete=True): """"""Transition from a file-based backend to a Libvirt volume."""""" file_dir = os.path.dirname(file_path) file_name = os.path.basename(file_path) with self._temp_pool(file_dir, prefix='backend-trans-') as pool: base_vol = pool.storageVolLookupByName(file_name) base_vol_parsed = vconfig.LibvirtConfigStorageVolume() base_vol_parsed.parse_str(base_vol.XMLDesc(0)) vol_info = vconfig.LibvirtConfigStorageVolume() vol_info.name = self.volume_name vol_info.capacity = new_size or base_vol_parsed.capacity vol_info.allocation = base_vol_parsed.allocation vol_info.target['format'] = self.volume_type if self.pool_parsed.type in self.FILE_BASED_POOLS: if base_vol_parsed.backing_store is not None: backing_store_path = base_vol_parsed.backing_store['path'] vol_info.backing_store = {'path': backing_store_path} res = self.pool.createXMLFrom(vol_info.to_xml(), base_vol, 0) if res is not None: # NB(sross): only remove if we were successfull if delete: os.remove(file_path) # run correct_format so we have an entry for later self.correct_format() if new_size is not None: self._try_resize_fs(res, new_size) return res def snapshot_extract(self, target, out_format): # convert target to a name target_dir = os.path.dirname(target) target_name = os.path.basename(target) with self._temp_pool(target_dir, prefix='snapshot-') as snapshot_pool: # make a volume copier to do the copying properly copier = self._make_libvirt_volume_copier(self.volume_name, snapshot_pool, False) # make sure we have an output format if out_format is None: out_format = self.driver_format or 'raw' base_vol = self.pool.storageVolLookupByName(self.volume_name) copier(base_vol, target_name, None, out_format, permissions={'owner': os.getuid(), 'group': os.getgid()}) def _can_fallocate(self): raise NotImplementedError() @staticmethod def verify_base_size(base, size): if size is None: return base_size = base.info()[1] if size < base_size: msg = _LE('%(base)s virtual size %(base_size)s ' 'larger than flavor root disk size %(size)s') LOG.error(msg % {'base': base.name(), 'base_size': base_size, 'size': size}) raise exception.FlavorDiskTooSmall() def _get_driver_format_from_vol(self): vol = self.pool.storageVolLookupByName(self.volume_name) vol_parsed = vconfig.LibvirtConfigStorageVolume() vol_parsed.parse_str(vol.XMLDesc(0)) return vol_parsed.target.get('format', 'raw') def resolve_driver_format(self, write=True): driver_format = self._read_disk_info_from_file(self.volume_name) if driver_format is None: driver_format = self._get_driver_format_from_vol() if write: self._write_disk_info_to_file(self.volume_name, driver_format) return driver_format def correct_format(self): if self.pool_parsed.type not in self.FILE_BASED_POOLS: self.driver_format = 'raw' elif self.check_image_exists(): self.driver_format = self.resolve_driver_format(self.write_format) else: # if we're in a file-based pool, we can safely guess # driver_format == volume_type self.driver_format = self.volume_type def is_shared_block_storage(self): return self.pool_parsed.type in self.NET_BASED_POOLS def is_shared_block_storage(self): def __init__(self, use_cow, get_connection): 'rbd': Rbd } self.use_cow = use_cow self._get_connection = get_connection @property def _conn(self): return self._get_connection() def _resolve_image_type(self, img_type): if img_type is None: img_type = CONF.libvirt.images_type if img_type in ('default', 'libvirt-storage') or img_type is None: if self.use_cow: return 'qcow2' else: return 'raw' else: return img_type @classmethod def is_instance_disk_libvirt_volume(cls, conn, instance, disk_name): vol_name = LibvirtVolume.name_volume(instance, disk_name) return cls._autodetect_libvirt_volume(conn, vol_name) @classmethod def _autodetect_libvirt_volume(cls, conn, vol_name): pool = conn.storagePoolLookupByName(LibvirtVolume.POOL_NAME) return LibvirtVolume.check_volume_exists_in_pool(pool, vol_name) image_type = self._resolve_image_type(image_type) def image(self, instance, disk_name, image_type=None, is_volume=True): :conn: a raw libvirt connection :is_volume: should we use the new backend? (default is True) if is_volume is None: is_volume = self.is_instance_disk_libvirt_volume(self._conn, instance, disk_name) image_type = self._resolve_image_type(image_type) if is_volume: return LibvirtVolume(instance=instance, disk_name=disk_name, volume_type=image_type, conn=self._conn) else: backend = self.backend(image_type) return backend(instance=instance, disk_name=disk_name) def snapshot(self, disk_path, image_type=None, is_volume=None, instance=None, write_format=True): :path: path to image or the volume name if is_volume is None: is_volume = self._autodetect_libvirt_volume(self._conn, disk_path) image_type = self._resolve_image_type(image_type) if is_volume: return LibvirtVolume(volume_name=disk_path, volume_type=image_type, conn=self._conn, instance=instance, write_format=write_format) else: backend = self.backend(image_type) return backend(path=disk_path)"," def _dict_from_line(line): if not line: return {} try: return jsonutils.loads(line) except (TypeError, ValueError) as e: msg = (_(""Could not load line %(line)s, got error "" ""%(error)s"") % {'line': line, 'error': unicode(e)}) raise exception.InvalidDiskInfo(reason=msg) @utils.synchronized(self.disk_info_path, external=False, lock_path=self.lock_path) def write_to_disk_info_file(): # Use os.open to create it without group or world write permission. fd = os.open(self.disk_info_path, os.O_RDONLY | os.O_CREAT, 0o644) with os.fdopen(fd, ""r"") as disk_info_file: line = disk_info_file.read().rstrip() dct = _dict_from_line(line) if self.path in dct: msg = _(""Attempted overwrite of an existing value."") raise exception.InvalidDiskInfo(reason=msg) dct.update({self.path: driver_format}) tmp_path = self.disk_info_path + "".tmp"" fd = os.open(tmp_path, os.O_WRONLY | os.O_CREAT, 0o644) with os.fdopen(fd, ""w"") as tmp_file: tmp_file.write('%s\n' % jsonutils.dumps(dct)) os.rename(tmp_path, self.disk_info_path) try: if (self.disk_info_path is not None and os.path.exists(self.disk_info_path)): with open(self.disk_info_path) as disk_info_file: line = disk_info_file.read().rstrip() dct = _dict_from_line(line) for path, driver_format in dct.iteritems(): if path == self.path: return driver_format if self.disk_info_path is not None: fileutils.ensure_tree(os.path.dirname(self.disk_info_path)) write_to_disk_info_file() except OSError as e: raise exception.DiskInfoReadWriteFail(reason=unicode(e)) @staticmethod def is_shared_block_storage(): @staticmethod def is_shared_block_storage(): def __init__(self, use_cow): 'rbd': Rbd, 'default': Qcow2 if use_cow else Raw } def image(self, instance, disk_name, image_type=None): backend = self.backend(image_type) return backend(instance=instance, disk_name=disk_name) def snapshot(self, disk_path, image_type=None): :path: path to image backend = self.backend(image_type) return backend(path=disk_path)",2812,820
openstack%2Fkeystone~master~Ibcb12a4a9db45351127458a96de1161de55d5a18,openstack/keystone,master,Ibcb12a4a9db45351127458a96de1161de55d5a18,Add an OS-FEDERATION section to scoped federation tokens,MERGED,2014-07-31 20:19:35.000000000,2014-08-09 03:00:24.000000000,2014-08-09 03:00:23.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 8978}]","[{'number': 1, 'created': '2014-07-31 20:19:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a1e1efcefcece8f91158ba78c98e85b2e4f33727', 'message': 'Add an OS-FEDERATION section to scoped federation tokens\n\nIn this change, we add an OS-FEDERATION section to the user\nsection in a scoped federation token. We currently do the same\nfor unscoped tokens. This will also help with revocation events,\nspecifically revoking tokens based on IDP id.\n\nChange-Id: Ibcb12a4a9db45351127458a96de1161de55d5a18\nCloses-Bug: #1351038\n'}, {'number': 2, 'created': '2014-08-08 18:58:25.000000000', 'files': ['keystone/token/providers/common.py', 'keystone/tests/test_v3_federation.py', 'keystone/auth/plugins/saml2.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/9847ebd90ec450052cebbd55e5351be3fc05fcd5', 'message': 'Add an OS-FEDERATION section to scoped federation tokens\n\nIn this change, we add an OS-FEDERATION section to the user\nsection in a scoped federation token. We currently do the same\nfor unscoped tokens. This will also help with revocation events,\nspecifically revoking tokens based on IDP id.\n\nChange-Id: Ibcb12a4a9db45351127458a96de1161de55d5a18\nCloses-Bug: #1351038\n'}]",0,111070,9847ebd90ec450052cebbd55e5351be3fc05fcd5,30,8,2,6482,,,0,"Add an OS-FEDERATION section to scoped federation tokens

In this change, we add an OS-FEDERATION section to the user
section in a scoped federation token. We currently do the same
for unscoped tokens. This will also help with revocation events,
specifically revoking tokens based on IDP id.

Change-Id: Ibcb12a4a9db45351127458a96de1161de55d5a18
Closes-Bug: #1351038
",git fetch https://review.opendev.org/openstack/keystone refs/changes/70/111070/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/token/providers/common.py', 'keystone/tests/test_v3_federation.py', 'keystone/auth/plugins/saml2.py']",3,a1e1efcefcece8f91158ba78c98e85b2e4f33727,dm," 'group_ids': group_ids, federation.IDENTITY_PROVIDER: identity_provider, federation.PROTOCOL: protocol", 'group_ids': group_ids,17,10
openstack%2Fcinder~master~Ib7e9fae81d69d2fe490a4b603337f3d5cee1138c,openstack/cinder,master,Ib7e9fae81d69d2fe490a4b603337f3d5cee1138c,VMware: Volume from non-streamOptimized image,MERGED,2014-07-11 11:17:24.000000000,2014-08-09 02:30:38.000000000,2014-08-09 02:30:37.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 5538}, {'_account_id': 6491}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9171}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12018}, {'_account_id': 12033}]","[{'number': 1, 'created': '2014-07-11 11:17:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2b9fe62abc1966825d83b918511740764397cbbe', 'message': 'VMware: Volume from non-streamOptimized image\n\nVolume creation from non-streamOptimized images (preallocated/thin/sparse)\nhas following problems:\n\n1) Sparse vmdk image is not converted to appropriate virtual disk type\n   suitable for attaching to a nova instance.\n2) The adapter type in image meta-data is ignored while creating volumes.\n3) The vmware:vmdk_type extra_spec property is ignored.\n4) Virtual disk extent operation is called with a wrong parameter which\n   might result in unwanted disk provisioning type conversion.\n\nThis patch fixes the first 3 problems using the following workflow:\n\na) Create a disk-less backing.\nb) Create a virtual disk (single flat extent) from the non-streamOptimized\n   image\nc) Attach the virtual disk to the backing\nd) Clone the backing (if needed) to perform disk provisioning type conversion\n\nCloses-Bug: #1287176\nCloses-Bug: #1287185\nCloses-Bug: #1284284\nChange-Id: Ib7e9fae81d69d2fe490a4b603337f3d5cee1138c\n'}, {'number': 2, 'created': '2014-07-14 10:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6985f4a12184cce5ff0141d1f09efc6ac5930b31', 'message': 'VMware: Volume from non-streamOptimized image\n\nVolume creation from non-streamOptimized images (preallocated/thin/sparse)\nhas following problems:\n\n1) Sparse vmdk image is not converted to appropriate virtual disk type\n   suitable for attaching to a nova instance.\n2) The adapter type in image meta-data is ignored while creating volumes.\n3) The vmware:vmdk_type extra_spec property is ignored.\n4) Virtual disk extent operation is called with a wrong parameter which\n   might result in unwanted disk provisioning type conversion.\n\nThis patch fixes the first 3 problems using the following workflow:\n\na) Create a disk-less backing.\nb) Create a virtual disk (single flat extent) from the non-streamOptimized\n   image\nc) Attach the virtual disk to the backing\nd) Clone the backing (if needed) to perform disk provisioning type conversion\n\nCloses-Bug: #1287176\nCloses-Bug: #1287185\nCloses-Bug: #1284284\nChange-Id: Ib7e9fae81d69d2fe490a4b603337f3d5cee1138c\n'}, {'number': 3, 'created': '2014-07-23 16:26:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a2324c783313c3719e9ddf9dfbf7cde88bb03404', 'message': 'VMware: Volume from non-streamOptimized image\n\nVolume creation from non-streamOptimized images (preallocated/thin/sparse)\nhas following problems:\n\n1) Sparse vmdk image is not converted to appropriate virtual disk type\n   suitable for attaching to a nova instance.\n2) The adapter type in image meta-data is ignored while creating volumes.\n3) The vmware:vmdk_type extra_spec property is ignored.\n4) Virtual disk extent operation is called with a wrong parameter which\n   might result in unwanted disk provisioning type conversion.\n\nThis patch fixes the first 3 problems using the following workflow:\n\na) Create a disk-less backing.\nb) Create a virtual disk (single flat extent) from the non-streamOptimized\n   image\nc) Attach the virtual disk to the backing\nd) Clone the backing (if needed) to perform disk provisioning type conversion\n\nCloses-Bug: #1287176\nCloses-Bug: #1287185\nCloses-Bug: #1284284\nChange-Id: Ib7e9fae81d69d2fe490a4b603337f3d5cee1138c\n'}, {'number': 4, 'created': '2014-07-24 06:52:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/245005aa0b79f5d7dceeefc743b1bc725595162d', 'message': 'VMware: Volume from non-streamOptimized image\n\nVolume creation from non-streamOptimized images (preallocated/thin/sparse)\nhas following problems:\n\n1) Sparse vmdk image is not converted to appropriate virtual disk type\n   suitable for attaching to a nova instance.\n2) The adapter type in image meta-data is ignored while creating volumes.\n3) The vmware:vmdk_type extra_spec property is ignored.\n4) Virtual disk extent operation is called with a wrong parameter which\n   might result in unwanted disk provisioning type conversion.\n\nThis patch fixes the first 3 problems using the following workflow:\n\na) Create a disk-less backing.\nb) Create a virtual disk (single flat extent) from the non-streamOptimized\n   image\nc) Attach the virtual disk to the backing\nd) Clone the backing (if needed) to perform disk provisioning type conversion\n\nCloses-Bug: #1287176\nCloses-Bug: #1287185\nCloses-Bug: #1284284\nChange-Id: Ib7e9fae81d69d2fe490a4b603337f3d5cee1138c\n'}, {'number': 5, 'created': '2014-08-01 10:30:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3f8358089cabc804d187decba2da4ddc974e3b0f', 'message': 'VMware: Volume from non-streamOptimized image\n\nVolume creation from non-streamOptimized images (preallocated/thin/sparse)\nhas following problems:\n\n1) Sparse vmdk image is not converted to appropriate virtual disk type\n   suitable for attaching to a nova instance.\n2) The adapter type in image meta-data is ignored while creating volumes.\n3) The vmware:vmdk_type extra_spec property is ignored.\n4) Virtual disk extent operation is called with a wrong parameter which\n   might result in unwanted disk provisioning type conversion.\n\nThis patch fixes the first 3 problems using the following workflow:\n\na) Create a disk-less backing.\nb) Create a virtual disk (single flat extent) from the non-streamOptimized\n   image\nc) Attach the virtual disk to the backing\nd) Clone the backing (if needed) to perform disk provisioning type conversion\n\nCloses-Bug: #1287176\nCloses-Bug: #1287185\nCloses-Bug: #1284284\nChange-Id: Ib7e9fae81d69d2fe490a4b603337f3d5cee1138c\n'}, {'number': 6, 'created': '2014-08-01 13:44:40.000000000', 'files': ['cinder/volume/drivers/vmware/vmdk.py', 'cinder/tests/test_vmware_vmdk.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5eac161aa81a68e7cc4adb92798f6c3e849da81c', 'message': 'VMware: Volume from non-streamOptimized image\n\nVolume creation from non-streamOptimized images (preallocated/thin/sparse)\nhas following problems:\n\n1) Sparse vmdk image is not converted to appropriate virtual disk type\n   suitable for attaching to a nova instance.\n2) The adapter type in image meta-data is ignored while creating volumes.\n3) The vmware:vmdk_type extra_spec property is ignored.\n4) Virtual disk extent operation is called with a wrong parameter which\n   might result in unwanted disk provisioning type conversion.\n\nThis patch fixes the first 3 problems using the following workflow:\n\na) Create a disk-less backing.\nb) Create a virtual disk (single flat extent) from the non-streamOptimized\n   image\nc) Attach the virtual disk to the backing\nd) Clone the backing (if needed) to perform disk provisioning type conversion\n\nCloses-Bug: #1287176\nCloses-Bug: #1287185\nCloses-Bug: #1284284\nChange-Id: Ib7e9fae81d69d2fe490a4b603337f3d5cee1138c\n'}]",22,106334,5eac161aa81a68e7cc4adb92798f6c3e849da81c,79,15,6,9171,,,0,"VMware: Volume from non-streamOptimized image

Volume creation from non-streamOptimized images (preallocated/thin/sparse)
has following problems:

1) Sparse vmdk image is not converted to appropriate virtual disk type
   suitable for attaching to a nova instance.
2) The adapter type in image meta-data is ignored while creating volumes.
3) The vmware:vmdk_type extra_spec property is ignored.
4) Virtual disk extent operation is called with a wrong parameter which
   might result in unwanted disk provisioning type conversion.

This patch fixes the first 3 problems using the following workflow:

a) Create a disk-less backing.
b) Create a virtual disk (single flat extent) from the non-streamOptimized
   image
c) Attach the virtual disk to the backing
d) Clone the backing (if needed) to perform disk provisioning type conversion

Closes-Bug: #1287176
Closes-Bug: #1287185
Closes-Bug: #1284284
Change-Id: Ib7e9fae81d69d2fe490a4b603337f3d5cee1138c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/34/106334/6 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/vmware/vmdk.py', 'cinder/tests/test_vmware_vmdk.py']",2,2b9fe62abc1966825d83b918511740764397cbbe,non-stream-opt-img-to-vol," @mock.patch('cinder.openstack.common.uuidutils.generate_uuid') @mock.patch.object(VMDK_DRIVER, '_select_ds_for_volume') @mock.patch.object(VMDK_DRIVER, '_create_virtual_disk_from_preallocated_image') @mock.patch.object(VMDK_DRIVER, '_create_virtual_disk_from_sparse_image') @mock.patch( 'cinder.volume.drivers.vmware.vmdk.VMwareEsxVmdkDriver._get_disk_type') @mock.patch.object(VMDK_DRIVER, '_get_ds_name_folder_path') @mock.patch.object(VMDK_DRIVER, '_create_backing_in_inventory') def test_copy_image_to_volume_non_stream_optimized( self, create_backing, get_ds_name_folder_path, get_disk_type, create_disk_from_sparse_image, create_disk_from_preallocated_image, vops, select_ds_for_volume, generate_uuid): self._test_copy_image_to_volume_non_stream_optimized( create_backing, get_ds_name_folder_path, get_disk_type, create_disk_from_sparse_image, create_disk_from_preallocated_image, vops, select_ds_for_volume, generate_uuid) def _test_copy_image_to_volume_non_stream_optimized( self, create_backing, get_ds_name_folder_path, get_disk_type, create_disk_from_sparse_image, create_disk_from_preallocated_image, vops, select_ds_for_volume, generate_uuid): image_size_in_bytes = 2 * units.Gi adapter_type = 'lsiLogic' image_meta = {'disk_format': 'vmdk', 'size': image_size_in_bytes, 'properties': {'vmware_disktype': 'sparse', 'vmwware_adaptertype': adapter_type}} image_service.show.return_value = image_meta backing = mock.Mock() def create_backing_mock(volume, create_params): self.assertTrue(create_params[vmdk.CREATE_PARAM_DISK_LESS]) return backing create_backing.side_effect = create_backing_mock ds_name = mock.Mock() folder_path = mock.Mock() get_ds_name_folder_path.return_value = (ds_name, folder_path) summary = mock.Mock() select_ds_for_volume.return_value = (mock.sentinel.host, mock.sentinel.rp, mock.sentinel.folder, summary) uuid = ""6b77b25a-9136-470e-899e-3c930e570d8e"" generate_uuid.return_value = uuid host = mock.Mock() dc_ref = mock.Mock() vops.get_host.return_value = host vops.get_dc.return_value = dc_ref disk_type = vmdk.EAGER_ZEROED_THICK_VMDK_TYPE get_disk_type.return_value = disk_type path = mock.Mock() create_disk_from_sparse_image.return_value = path create_disk_from_preallocated_image.return_value = path context = mock.Mock() volume = {'name': 'volume_name', 'id': 'volume_id', 'size': image_size_in_bytes} image_id = mock.Mock() self._driver.copy_image_to_volume( context, volume, image_service, image_id) create_params = {vmdk.CREATE_PARAM_DISK_LESS: True, vmdk.CREATE_PARAM_BACKING_NAME: uuid} create_backing.assert_called_once_with(volume, create_params) create_disk_from_sparse_image.assert_called_once_with( context, image_service, image_id, image_size_in_bytes, dc_ref, ds_name, folder_path, uuid) vops.attach_disk_to_backing.assert_called_once_with( backing, image_size_in_bytes / units.Ki, disk_type, adapter_type, path.get_descriptor_ds_file_path()) select_ds_for_volume.assert_called_once_with(volume) vops.clone_backing.assert_called_once_with( volume['name'], backing, None, volumeops.FULL_CLONE_TYPE, summary.datastore, disk_type) vops.delete_backing.assert_called_once_with(backing) create_backing.reset_mock() vops.attach_disk_to_backing.reset_mock() vops.delete_backing.reset_mock() image_meta['properties']['vmware_disktype'] = 'preallocated' self._driver.copy_image_to_volume( context, volume, image_service, image_id) del create_params[vmdk.CREATE_PARAM_BACKING_NAME] create_backing.assert_called_once_with(volume, create_params) create_disk_from_preallocated_image.assert_called_once_with( context, image_service, image_id, image_size_in_bytes, dc_ref, ds_name, folder_path, volume['name'], adapter_type) vops.attach_disk_to_backing.assert_called_once_with( backing, image_size_in_bytes / units.Ki, disk_type, adapter_type, path.get_descriptor_ds_file_path()) create_disk_from_preallocated_image.side_effect = ( error_util.VimException(""Error"")) self.assertRaises(error_util.VimException, context, volume, image_service, image_id) vops.delete_backing.assert_called_once_with(backing) @mock.patch( 'cinder.volume.drivers.vmware.volumeops.FlatExtentVirtualDiskPath') @mock.patch.object(VMDK_DRIVER, '_copy_image') @mock.patch.object(VMDK_DRIVER, 'volumeops') def test_create_virtual_disk_from_preallocated_image( self, vops, copy_image, flat_extent_path): self._test_create_virtual_disk_from_preallocated_image( vops, copy_image, flat_extent_path) def _test_create_virtual_disk_from_preallocated_image( self, vops, copy_image, flat_extent_path): context = mock.Mock() image_service = mock.Mock() image_id = mock.Mock() image_size_in_bytes = 2 * units.Gi dc_ref = mock.Mock() ds_name = ""nfs"" folder_path = ""A/B/"" disk_name = ""disk-1"" adapter_type = ""ide"" src_path = mock.Mock() flat_extent_path.return_value = src_path ret = self._driver._create_virtual_disk_from_preallocated_image( context, image_service, image_id, image_size_in_bytes, dc_ref, ds_name, folder_path, disk_name, adapter_type) create_descriptor = vops.create_flat_extent_virtual_disk_descriptor create_descriptor.assert_called_once_with( dc_ref, src_path, image_size_in_bytes / units.Ki, adapter_type, vmdk.EAGER_ZEROED_THICK_VMDK_TYPE) copy_image.assert_called_once_with( context, dc_ref, image_service, image_id, image_size_in_bytes, ds_name, src_path.get_flat_extent_file_path()) self.assertEqual(src_path, ret) create_descriptor.reset_mock() copy_image.reset_mock() copy_image.side_effect = error_util.VimException(""error"") self.assertRaises( error_util.VimException, self._driver._create_virtual_disk_from_preallocated_image, context, image_service, image_id, image_size_in_bytes, dc_ref, ds_name, folder_path, disk_name, adapter_type) vops.delete_file.assert_called_once_with( src_path.get_descriptor_ds_file_path(), dc_ref) @mock.patch( 'cinder.volume.drivers.vmware.volumeops.' 'MonolithicSparseVirtualDiskPath') @mock.patch( 'cinder.volume.drivers.vmware.volumeops.FlatExtentVirtualDiskPath') @mock.patch.object(VMDK_DRIVER, '_copy_temp_virtual_disk') @mock.patch.object(VMDK_DRIVER, '_copy_image') def test_create_virtual_disk_from_sparse_image( self, copy_image, copy_temp_virtual_disk, flat_extent_path, sparse_path): self._test_create_virtual_disk_from_sparse_image( copy_image, copy_temp_virtual_disk, flat_extent_path, sparse_path) def _test_create_virtual_disk_from_sparse_image( self, copy_image, copy_temp_virtual_disk, flat_extent_path, sparse_path): context = mock.Mock() image_service = mock.Mock() image_id = mock.Mock() image_size_in_bytes = 2 * units.Gi dc_ref = mock.Mock() ds_name = ""nfs"" folder_path = ""A/B/"" disk_name = ""disk-1"" src_path = mock.Mock() sparse_path.return_value = src_path dest_path = mock.Mock() flat_extent_path.return_value = dest_path ret = self._driver._create_virtual_disk_from_sparse_image( context, image_service, image_id, image_size_in_bytes, dc_ref, ds_name, folder_path, disk_name) copy_image.assert_called_once_with( context, dc_ref, image_service, image_id, image_size_in_bytes, ds_name, src_path.get_descriptor_file_path()) copy_temp_virtual_disk.assert_called_once_with( dc_ref, src_path, dest_path) self.assertEqual(dest_path, ret) vol_id = '12345' fake_volume = {'name': vol_name, 'id': vol_id, 'size': fake_volume_size, @mock.patch('cinder.openstack.common.uuidutils.generate_uuid') @mock.patch.object(VMDK_DRIVER, '_select_ds_for_volume') @mock.patch.object(VMDK_DRIVER, '_create_virtual_disk_from_preallocated_image') @mock.patch.object(VMDK_DRIVER, '_create_virtual_disk_from_sparse_image') @mock.patch( 'cinder.volume.drivers.vmware.vmdk.VMwareEsxVmdkDriver._get_disk_type') @mock.patch.object(VMDK_DRIVER, '_get_ds_name_folder_path') @mock.patch.object(VMDK_DRIVER, '_create_backing_in_inventory') def test_copy_image_to_volume_non_stream_optimized( self, create_backing, get_ds_name_folder_path, get_disk_type, create_disk_from_sparse_image, create_disk_from_preallocated_image, vops, select_ds_for_volume, generate_uuid): self._test_copy_image_to_volume_non_stream_optimized( create_backing, get_ds_name_folder_path, get_disk_type, create_disk_from_sparse_image, create_disk_from_preallocated_image, vops, select_ds_for_volume, generate_uuid) @mock.patch( 'cinder.volume.drivers.vmware.volumeops.FlatExtentVirtualDiskPath') @mock.patch.object(VMDK_DRIVER, '_copy_image') @mock.patch.object(VMDK_DRIVER, 'volumeops') def test_create_virtual_disk_from_preallocated_image( self, vops, copy_image, flat_extent_path): self._test_create_virtual_disk_from_preallocated_image( vops, copy_image, flat_extent_path) @mock.patch( 'cinder.volume.drivers.vmware.volumeops.' 'MonolithicSparseVirtualDiskPath') @mock.patch( 'cinder.volume.drivers.vmware.volumeops.FlatExtentVirtualDiskPath') @mock.patch.object(VMDK_DRIVER, '_copy_temp_virtual_disk') @mock.patch.object(VMDK_DRIVER, '_copy_image') def test_create_virtual_disk_from_sparse_image( self, copy_image, copy_temp_virtual_disk, flat_extent_path, sparse_path): self._test_create_virtual_disk_from_sparse_image( copy_image, copy_temp_virtual_disk, flat_extent_path, sparse_path) vops.create_backing.reset_mock() backing_name = ""temp-vol"" create_params = {vmdk.CREATE_PARAM_BACKING_NAME: backing_name} self._driver._create_backing(volume, host, create_params) vops.create_backing.assert_called_once_with(backing_name, units.Mi, vmdk.THIN_VMDK_TYPE, folder, resource_pool, host, summary.name, None, 'lsiLogic') class ImageDiskTypeTest(test.TestCase): """"""Unit tests for ImageDiskType."""""" def test_is_valid(self): self.assertTrue(vmdk.ImageDiskType.is_valid(""thin"")) self.assertTrue(vmdk.ImageDiskType.is_valid(""preallocated"")) self.assertTrue(vmdk.ImageDiskType.is_valid(""streamOptimized"")) self.assertTrue(vmdk.ImageDiskType.is_valid(""sparse"")) self.assertFalse(vmdk.ImageDiskType.is_valid(""thick"")) def test_validate(self): vmdk.ImageDiskType.validate(""thin"") vmdk.ImageDiskType.validate(""preallocated"") vmdk.ImageDiskType.validate(""streamOptimized"") vmdk.ImageDiskType.validate(""sparse"") self.assertRaises(exception.ImageUnacceptable, vmdk.ImageDiskType.validate, ""thick"")"," @mock.patch.object(vmware_images, 'fetch_flat_image') @mock.patch.object(VMDK_DRIVER, '_extend_vmdk_virtual_disk') @mock.patch.object(VMDK_DRIVER, '_get_ds_name_flat_vmdk_path') @mock.patch.object(VMDK_DRIVER, '_create_backing_in_inventory') @mock.patch.object(VMDK_DRIVER, 'session') def test_copy_image_to_volume_vmdk(self, volume_ops, session, _create_backing_in_inventory, _get_ds_name_flat_vmdk_path, _extend_vmdk_virtual_disk, fetch_flat_image): """"""Test copy_image_to_volume with an acceptable vmdk disk format."""""" self._test_copy_image_to_volume_vmdk(volume_ops, session, _create_backing_in_inventory, _get_ds_name_flat_vmdk_path, _extend_vmdk_virtual_disk, fetch_flat_image) def _test_copy_image_to_volume_vmdk(self, volume_ops, session, _create_backing_in_inventory, _get_ds_name_flat_vmdk_path, _extend_vmdk_virtual_disk, fetch_flat_image): cookies = session.vim.client.options.transport.cookiejar fake_context = mock.sentinel.context fake_image_id = 'image-id' fake_image_meta = {'disk_format': 'vmdk', 'size': 2 * units.Gi, 'properties': {'vmware_disktype': 'preallocated'}} fake_size = 3 fake_volume = {'name': 'volume_name', 'size': fake_size} fake_backing = mock.sentinel.backing fake_datastore_name = 'datastore1' flat_vmdk_path = 'myvolumes/myvm-flat.vmdk' fake_host = mock.sentinel.host fake_datacenter = mock.sentinel.datacenter fake_datacenter_name = mock.sentinel.datacenter_name timeout = self._config.vmware_image_transfer_timeout_secs image_service.show.return_value = fake_image_meta _create_backing_in_inventory.return_value = fake_backing _get_ds_name_flat_vmdk_path.return_value = (fake_datastore_name, flat_vmdk_path) volume_ops.get_host.return_value = fake_host volume_ops.get_dc.return_value = fake_datacenter volume_ops.get_entity_name.return_value = fake_datacenter_name # If the volume size is greater than the image size, # _extend_vmdk_virtual_disk will be called. self._driver.copy_image_to_volume(fake_context, fake_volume, image_service, fake_image_id) image_service.show.assert_called_with(fake_context, fake_image_id) _create_backing_in_inventory.assert_called_with(fake_volume) _get_ds_name_flat_vmdk_path.assert_called_with(fake_backing, fake_volume['name']) volume_ops.get_host.assert_called_with(fake_backing) volume_ops.get_dc.assert_called_with(fake_host) volume_ops.get_entity_name.assert_called_with(fake_datacenter) fetch_flat_image.assert_called_with(fake_context, timeout, image_service, fake_image_id, image_size=fake_image_meta['size'], host=self.IP, data_center_name= fake_datacenter_name, datastore_name=fake_datastore_name, cookies=cookies, file_path=flat_vmdk_path) _extend_vmdk_virtual_disk.assert_called_with(fake_volume['name'], fake_size) self.assertFalse(volume_ops.delete_backing.called) # If the volume size is not greater then than the image size, # _extend_vmdk_virtual_disk will not be called. _extend_vmdk_virtual_disk.reset_mock() fake_size = 2 fake_volume['size'] = fake_size self._driver.copy_image_to_volume(fake_context, fake_volume, image_service, fake_image_id) self.assertFalse(_extend_vmdk_virtual_disk.called) self.assertFalse(volume_ops.delete_backing.called) # If fetch_flat_image raises an Exception, delete_backing # will be called. fetch_flat_image.side_effect = exception.CinderException self.assertRaises(exception.CinderException, fake_context, fake_volume, image_service, fake_image_id) volume_ops.delete_backing.assert_called_with(fake_backing) fake_volume = {'name': vol_name, 'size': fake_volume_size, @mock.patch.object(vmware_images, 'fetch_flat_image') @mock.patch.object(VMDK_DRIVER, '_extend_vmdk_virtual_disk') @mock.patch.object(VMDK_DRIVER, '_get_ds_name_flat_vmdk_path') @mock.patch.object(VMDK_DRIVER, '_create_backing_in_inventory') @mock.patch.object(VMDK_DRIVER, 'session') def test_copy_image_to_volume_vmdk(self, volume_ops, session, _create_backing_in_inventory, _get_ds_name_flat_vmdk_path, _extend_vmdk_virtual_disk, fetch_flat_image): """"""Test copy_image_to_volume with an acceptable vmdk disk format."""""" self._test_copy_image_to_volume_vmdk(volume_ops, session, _create_backing_in_inventory, _get_ds_name_flat_vmdk_path, _extend_vmdk_virtual_disk, fetch_flat_image)",594,174
openstack%2Fnova~master~Ib6b82d90bb163f7ee06c916e52d3dd40ff2ba34d,openstack/nova,master,Ib6b82d90bb163f7ee06c916e52d3dd40ff2ba34d,DB: use assertIsNotNone for unit test,MERGED,2014-08-05 18:40:04.000000000,2014-08-09 02:30:21.000000000,2014-08-09 02:30:19.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-05 18:40:04.000000000', 'files': ['nova/tests/db/test_db_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/37952d0804b5bd1db2bab7633c22ac8bd3379ccc', 'message': 'DB: use assertIsNotNone for unit test\n\nCommit 48de2895b9a550a0944b31212349275605a4061d added a\nvalidation that should have used assertIsNotNone.\n\nTrivialFix\n\nChange-Id: Ib6b82d90bb163f7ee06c916e52d3dd40ff2ba34d\n'}]",0,112110,37952d0804b5bd1db2bab7633c22ac8bd3379ccc,15,8,1,1653,,,0,"DB: use assertIsNotNone for unit test

Commit 48de2895b9a550a0944b31212349275605a4061d added a
validation that should have used assertIsNotNone.

TrivialFix

Change-Id: Ib6b82d90bb163f7ee06c916e52d3dd40ff2ba34d
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/112110/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/db/test_db_api.py'],1,37952d0804b5bd1db2bab7633c22ac8bd3379ccc,doubles, self.assertIsNotNone(floating_ref)," self.assertIsNot(floating_ref, None)",1,1
openstack%2Fopenstack-manuals~master~I6a3f56385c90006db445e02897c6e62a26792c42,openstack/openstack-manuals,master,I6a3f56385c90006db445e02897c6e62a26792c42,Clarify MySQL Python library installation,MERGED,2014-08-09 00:39:17.000000000,2014-08-09 02:04:56.000000000,2014-08-09 02:04:55.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-09 00:39:17.000000000', 'files': ['doc/install-guide/section_basics-database.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/41b5d614e5d25285a0bfecfb5a148ea32e858267', 'message': 'Clarify MySQL Python library installation\n\nI clarified the MySQL Python library installation instructions\nfor the controller nodes and other nodes.\n\nChange-Id: I6a3f56385c90006db445e02897c6e62a26792c42\nCloses-Bug: #1341174\n'}]",0,113050,41b5d614e5d25285a0bfecfb5a148ea32e858267,8,3,1,9515,,,0,"Clarify MySQL Python library installation

I clarified the MySQL Python library installation instructions
for the controller nodes and other nodes.

Change-Id: I6a3f56385c90006db445e02897c6e62a26792c42
Closes-Bug: #1341174
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/50/113050/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_basics-database.xml'],1,41b5d614e5d25285a0bfecfb5a148ea32e858267,bug/1341174," install the MySQL database on the controller node. You must also <title>Controller node</title> <title>Other nodes</title> <para>On nodes other than the controller node, you only need to install the MySQL Python library:</para>"," install the MySQL database on the controller node. You must <title>Controller setup</title> <title>Node setup</title> <para>On all nodes other than the controller node, install the MySQL Python library:</para>",5,5
openstack%2Ftripleo-image-elements~master~Idb8a97180045869595416cf0b17aec70a63d9055,openstack/tripleo-image-elements,master,Idb8a97180045869595416cf0b17aec70a63d9055,Update the cinder-lio element to use the venv dir,MERGED,2014-07-11 02:02:20.000000000,2014-08-09 01:58:31.000000000,2014-08-09 01:58:31.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 7471}, {'_account_id': 7582}, {'_account_id': 9369}]","[{'number': 1, 'created': '2014-07-11 02:02:20.000000000', 'files': ['elements/cinder-lio/install.d/cinder-source-install/73-cinder-rtstool'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/b42cb229a3fa8142421c25400a15ca7e5b4d05e1', 'message': 'Update the cinder-lio element to use the venv dir\n\nThis updates the cinder-lio element to make use of the\nCINDER_VENV_DIR variable which is set by the cinder element.\n\nThis allows source installs of this element to work correctly\nwhen using common-env or a custom Cinder venv directory.\n\nChange-Id: Idb8a97180045869595416cf0b17aec70a63d9055\n'}]",0,106229,b42cb229a3fa8142421c25400a15ca7e5b4d05e1,39,7,1,360,,,0,"Update the cinder-lio element to use the venv dir

This updates the cinder-lio element to make use of the
CINDER_VENV_DIR variable which is set by the cinder element.

This allows source installs of this element to work correctly
when using common-env or a custom Cinder venv directory.

Change-Id: Idb8a97180045869595416cf0b17aec70a63d9055
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/29/106229/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/cinder-lio/install.d/cinder-source-install/73-cinder-rtstool'],1,b42cb229a3fa8142421c25400a15ca7e5b4d05e1,cinder_lio_venv_fix,ln -sf $CINDER_VENV_DIR/bin/cinder-rtstool /usr/local/bin/cinder-rtstool ,ln -sf /opt/stack/venvs/cinder/bin/cinder-rtstool /usr/local/bin/cinder-rtstool,1,1
openstack%2Fopenstack-manuals~master~Ie06427673fa56687378a94ad991f7913e064cc20,openstack/openstack-manuals,master,Ie06427673fa56687378a94ad991f7913e064cc20,Stubbing out DocBook sections and XIncluding some possibly content,MERGED,2014-08-08 19:13:13.000000000,2014-08-09 01:55:10.000000000,2014-08-09 01:55:10.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7751}, {'_account_id': 9162}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-08-08 19:13:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cae8eb1c86d18dd0273d9915e0a36d82e93bf0d4', 'message': 'Stubbing out DocBook sections and XIncluding some possibly content\n\nChange-Id: Ie06427673fa56687378a94ad991f7913e064cc20\n'}, {'number': 2, 'created': '2014-08-08 20:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b86a45307c351c726e9085e58197e96c9fa6b20d', 'message': 'Stubbing out DocBook sections and XIncluding some possibly content\n\nChange-Id: Ie06427673fa56687378a94ad991f7913e064cc20\n'}, {'number': 3, 'created': '2014-08-09 00:31:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bc19bf580a108926e073eac13ca5bd301a7be393', 'message': 'Stubbing out DocBook sections and XIncluding some possibly content\n\nChange-Id: Ie06427673fa56687378a94ad991f7913e064cc20\n'}, {'number': 4, 'created': '2014-08-09 01:07:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/da320849c434b6fcba4d4e7e66e622d6ab2a2ac4', 'message': 'Stubbing out DocBook sections and XIncluding some possibly content\n\nChange-Id: Ie06427673fa56687378a94ad991f7913e064cc20\n'}, {'number': 5, 'created': '2014-08-09 01:36:31.000000000', 'files': ['doc/networking-guide/ch_advanced.xml', 'doc/networking-guide/section_deployment-scenarios.xml', 'doc/networking-guide/section_architecture-plug-in.xml', 'doc/networking-guide/section_architecture-server.xml', 'doc/networking-guide/section_plugins-proprietary.xml', 'doc/networking-guide/section_intro-tunnel.xml', 'doc/networking-guide/section_ha-dvr.xml', 'doc/networking-guide/bk-networking.xml', 'doc/networking-guide/section_intro-layers.xml', 'doc/networking-guide/section_architecture-overview.xml', 'doc/networking-guide/ch_deployment.xml', 'doc/networking-guide/section_architecture-agents.xml', 'doc/networking-guide/ch_plugins.xml', 'doc/networking-guide/section_ha-l3.xml', 'doc/networking-guide/section_intro-switches.xml', 'doc/networking-guide/ch_scalability-HA.xml', 'doc/networking-guide/section_intro-routers.xml', 'doc/networking-guide/section_intro-firewalls.xml', 'doc/networking-guide/ch_intro.xml', 'doc/networking-guide/section_intro-neutron.xml', 'doc/networking-guide/section_intro-namespaces.xml', 'doc/networking-guide/section_deployment-architecture.xml', 'doc/networking-guide/section_plugins-ml2.xml', 'doc/networking-guide/section_ha-dhcp.xml', 'doc/networking-guide/ch_networking-architecture.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/aeb4e447617d14a1dd8e3c9f40562f5b06bc5cca', 'message': 'Stubbing out DocBook sections and XIncluding some possibly content\n\nChange-Id: Ie06427673fa56687378a94ad991f7913e064cc20\n'}]",9,113004,aeb4e447617d14a1dd8e3c9f40562f5b06bc5cca,24,5,5,8369,,,0,"Stubbing out DocBook sections and XIncluding some possibly content

Change-Id: Ie06427673fa56687378a94ad991f7913e064cc20
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/04/113004/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/networking-guide/ch_advanced.xml', 'doc/networking-guide/section_deployment-scenarios.xml', 'doc/networking-guide/section_architecture-plug-in.xml', 'doc/networking-guide/section_architecture-server.xml', 'doc/networking-guide/section_plugins-proprietary.xml', 'doc/networking-guide/section_intro-tunnel.xml', 'doc/networking-guide/section_ha-dvr.xml', 'doc/networking-guide/bk-networking.xml', 'doc/networking-guide/section_intro-layers.xml', 'doc/networking-guide/section_architecture-overview.xml', 'doc/networking-guide/ch_deployment.xml', 'doc/networking-guide/section_architecture-agents.xml', 'doc/networking-guide/ch_plugins.xml', 'doc/networking-guide/section_ha-l3.xml', 'doc/networking-guide/section_intro-switches.xml', 'doc/networking-guide/ch_scalability-HA.xml', 'doc/networking-guide/section_intro-routers.xml', 'doc/networking-guide/section_intro-firewalls.xml', 'doc/networking-guide/ch_intro.xml', 'doc/networking-guide/section_intro-neutron.xml', 'doc/networking-guide/section_intro-namespaces.xml', 'doc/networking-guide/section_deployment-architecture.xml', 'doc/networking-guide/section_plugins-ml2.xml', 'doc/networking-guide/section_ha-dhcp.xml', 'doc/networking-guide/ch_networking-architecture.xml']",25,cae8eb1c86d18dd0273d9915e0a36d82e93bf0d4,113004," <xi:include href=""section_architecture-overview.xml""/> <xi:include href=""section_architecture-server.xml""/> <xi:include href=""section_architecture-plug-in.xml""/> <xi:include href=""section_architecture-agents.xml""/>",,576,1
openstack%2Fkeystone~master~Ic4ac0d2558ced56eeadd6241159188c49fcceb6e,openstack/keystone,master,Ic4ac0d2558ced56eeadd6241159188c49fcceb6e,Remove S3 middleware tests from tox.ini,MERGED,2014-08-06 19:21:53.000000000,2014-08-09 01:43:47.000000000,2014-08-09 01:43:46.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6482}, {'_account_id': 8978}, {'_account_id': 10873}, {'_account_id': 11333}, {'_account_id': 11387}]","[{'number': 1, 'created': '2014-08-06 19:21:53.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/8084b2ce6f5572dcd869947d676a8368bc2e5cef', 'message': 'Remove S3 middleware tests from tox.ini\n\nThe middleware was moved to the keystonemiddleware project and no longer\nneeds to be tested here.\n\nChange-Id: Ic4ac0d2558ced56eeadd6241159188c49fcceb6e\n'}]",0,112387,8084b2ce6f5572dcd869947d676a8368bc2e5cef,19,7,1,7725,,,0,"Remove S3 middleware tests from tox.ini

The middleware was moved to the keystonemiddleware project and no longer
needs to be tested here.

Change-Id: Ic4ac0d2558ced56eeadd6241159188c49fcceb6e
",git fetch https://review.opendev.org/openstack/keystone refs/changes/87/112387/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,8084b2ce6f5572dcd869947d676a8368bc2e5cef,other-py3,, keystone/tests/test_s3_token_middleware.py \,0,1
openstack%2Fbarbican~master~I4ab224e0484c99fbfdf5c6ea3d10e69a8c762d88,openstack/barbican,master,I4ab224e0484c99fbfdf5c6ea3d10e69a8c762d88,Make transport_key an optional arg in SecretDTO,MERGED,2014-08-08 23:06:13.000000000,2014-08-09 01:26:31.000000000,2014-08-09 01:26:31.000000000,"[{'_account_id': 3}, {'_account_id': 7789}, {'_account_id': 9234}, {'_account_id': 9914}]","[{'number': 1, 'created': '2014-08-08 23:06:13.000000000', 'files': ['barbican/plugin/interface/secret_store.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/e246a74c52d7d8941f971ef8000764fcaa161e0f', 'message': 'Make transport_key an optional arg in SecretDTO\n\nChange-Id: I4ab224e0484c99fbfdf5c6ea3d10e69a8c762d88\nCloses-Bug: #1354603\n'}]",0,113044,e246a74c52d7d8941f971ef8000764fcaa161e0f,10,4,1,10273,,,0,"Make transport_key an optional arg in SecretDTO

Change-Id: I4ab224e0484c99fbfdf5c6ea3d10e69a8c762d88
Closes-Bug: #1354603
",git fetch https://review.opendev.org/openstack/barbican refs/changes/44/113044/1 && git format-patch -1 --stdout FETCH_HEAD,['barbican/plugin/interface/secret_store.py'],1,e246a74c52d7d8941f971ef8000764fcaa161e0f,," def __init__(self, type, secret, key_spec, content_type, transport_key=None):"," def __init__(self, type, secret, key_spec, content_type, transport_key):",2,1
openstack%2Fcinder~master~I1481209a85fa6db0343d0111e2b19d9fab4538a7,openstack/cinder,master,I1481209a85fa6db0343d0111e2b19d9fab4538a7,"Enable checks for E711, E712 and E713",MERGED,2014-08-01 12:34:58.000000000,2014-08-09 01:07:46.000000000,2014-08-09 01:07:45.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 170}, {'_account_id': 2759}, {'_account_id': 6491}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 11903}, {'_account_id': 12033}]","[{'number': 1, 'created': '2014-08-01 12:34:58.000000000', 'files': ['cinder/volume/drivers/eqlx.py', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/api/fakes.py', 'cinder/tests/api/v2/test_volumes.py', 'cinder/volume/drivers/emc/emc_smis_common.py', 'cinder/tests/test_hds_iscsi.py', 'cinder/tests/keymgr/test_key.py', 'tox.ini', 'bin/cinder-rtstool', 'cinder/utils.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/1be1da1020281a83d6285173a6d6078ffe979194', 'message': ""Enable checks for E711, E712 and E713\n\n* E711 comparison to None should be 'if cond is None:'\n* E712 comparison to True should be 'if cond is True:' or 'if cond:'\n* E713 test for membership should be 'not in'\n\nChange-Id: I1481209a85fa6db0343d0111e2b19d9fab4538a7\n""}]",0,111260,1be1da1020281a83d6285173a6d6078ffe979194,25,9,1,167,,,0,"Enable checks for E711, E712 and E713

* E711 comparison to None should be 'if cond is None:'
* E712 comparison to True should be 'if cond is True:' or 'if cond:'
* E713 test for membership should be 'not in'

Change-Id: I1481209a85fa6db0343d0111e2b19d9fab4538a7
",git fetch https://review.opendev.org/openstack/cinder refs/changes/60/111260/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/eqlx.py', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/api/fakes.py', 'cinder/tests/api/v2/test_volumes.py', 'cinder/volume/drivers/emc/emc_smis_common.py', 'cinder/tests/test_hds_iscsi.py', 'cinder/tests/keymgr/test_key.py', 'tox.ini', 'bin/cinder-rtstool', 'cinder/utils.py', 'cinder/volume/api.py']",12,1be1da1020281a83d6285173a6d6078ffe979194,enable_checks, if filters is None:, if filters == None:,21,21
openstack%2Fdevstack~master~I9b143c9883b947397b435a671f13703f78019d23,openstack/devstack,master,I9b143c9883b947397b435a671f13703f78019d23,Adds support for Hyper-V image formats,MERGED,2014-08-06 23:07:59.000000000,2014-08-09 00:35:06.000000000,2014-08-09 00:35:05.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 10385}, {'_account_id': 10635}]","[{'number': 1, 'created': '2014-08-06 23:07:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/825b7c1d8e7877abbd60214cfcbedc79a399b4d1', 'message': 'Adds support for Hyper-V image formats\n\nAdds support for VHD and VHDX image formats, including gz compression.\n\nChange-Id: I9b143c9883b947397b435a671f13703f78019d23\nCloses-bug: #1353726\n'}, {'number': 2, 'created': '2014-08-07 00:18:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e308d9cb879ecde62949ae3b0f83f8fc963c0a8b', 'message': 'Adds support for Hyper-V image formats\n\nAdds support for VHD and VHDX image formats, including gz compression.\n\nChange-Id: I9b143c9883b947397b435a671f13703f78019d23\nCloses-bug: #1353726\n'}, {'number': 3, 'created': '2014-08-07 16:30:56.000000000', 'files': ['functions'], 'web_link': 'https://opendev.org/openstack/devstack/commit/ca8239449fbdbc3a73f691683be2ec9d4a941ff6', 'message': 'Adds support for Hyper-V image formats\n\nAdds support for VHD and VHDX image formats, including gz compression.\n\nChange-Id: I9b143c9883b947397b435a671f13703f78019d23\nCloses-bug: #1353726\n'}]",0,112434,ca8239449fbdbc3a73f691683be2ec9d4a941ff6,18,5,3,3185,,,0,"Adds support for Hyper-V image formats

Adds support for VHD and VHDX image formats, including gz compression.

Change-Id: I9b143c9883b947397b435a671f13703f78019d23
Closes-bug: #1353726
",git fetch https://review.opendev.org/openstack/devstack refs/changes/34/112434/1 && git format-patch -1 --stdout FETCH_HEAD,['functions'],1,825b7c1d8e7877abbd60214cfcbedc79a399b4d1,bug/1353726," *.vhd|*.vhdx|*.vhd.gz|*.vhdx.gz) extension=""${IMAGE_FNAME#*.}"" IMAGE_NAME=$(basename ""$IMAGE"" "".$extension"") DISK_FORMAT=vhd CONTAINER_FORMAT=bare if [ ""${IMAGE_FNAME##*.}"" == ""gz"" ]; then UNPACK=zcat fi ;;",,9,0
openstack%2Fpython-openstackclient~master~If62daf2539ff69323c905c12c19e041f83ef8eb2,openstack/python-openstackclient,master,If62daf2539ff69323c905c12c19e041f83ef8eb2,Updated from global requirements,MERGED,2014-08-02 21:00:29.000000000,2014-08-09 00:34:59.000000000,2014-08-09 00:34:58.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-08-02 21:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/08db718c7dfd58516b351ded22a49ef8b9131d2c', 'message': 'Updated from global requirements\n\nChange-Id: If62daf2539ff69323c905c12c19e041f83ef8eb2\n'}, {'number': 2, 'created': '2014-08-04 03:28:17.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/40013f3c0214e7724e574c2c598bce1f0ccbe714', 'message': 'Updated from global requirements\n\nChange-Id: If62daf2539ff69323c905c12c19e041f83ef8eb2\n'}]",0,111527,40013f3c0214e7724e574c2c598bce1f0ccbe714,27,3,2,11131,,,0,"Updated from global requirements

Change-Id: If62daf2539ff69323c905c12c19e041f83ef8eb2
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/27/111527/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,08db718c7dfd58516b351ded22a49ef8b9131d2c,openstack/requirements,"python-neutronclient>=2.3.6,<3","python-neutronclient>=2.3.5,<3",1,1
openstack%2Fkeystone~master~I0467ed68f894e7075bc25ff3e779351fab9ed4c3,openstack/keystone,master,I0467ed68f894e7075bc25ff3e779351fab9ed4c3,Add oslo.utils requirement,MERGED,2014-08-05 22:12:00.000000000,2014-08-09 00:34:52.000000000,2014-08-09 00:34:51.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 11333}, {'_account_id': 11387}]","[{'number': 1, 'created': '2014-08-05 22:12:00.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/69faae2154f1b93f0d384a741355826c9e14abd1', 'message': 'Add oslo.utils requirement\n\nThis will allow Keystone to use functions out of oslo.utils.\n\nChange-Id: I0467ed68f894e7075bc25ff3e779351fab9ed4c3\n'}]",0,112156,69faae2154f1b93f0d384a741355826c9e14abd1,16,7,1,6486,,,0,"Add oslo.utils requirement

This will allow Keystone to use functions out of oslo.utils.

Change-Id: I0467ed68f894e7075bc25ff3e779351fab9ed4c3
",git fetch https://review.opendev.org/openstack/keystone refs/changes/56/112156/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,69faae2154f1b93f0d384a741355826c9e14abd1,oslo.utils,oslo.utils>=0.1.1,,1,0
openstack%2Fpython-ceilometerclient~master~I0aaafc6f599a67b242ade25efb3e667738bd71fd,openstack/python-ceilometerclient,master,I0aaafc6f599a67b242ade25efb3e667738bd71fd,Add endpoint opt into auth_plugin,MERGED,2014-08-08 15:23:57.000000000,2014-08-09 00:32:48.000000000,2014-08-09 00:32:48.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 4491}, {'_account_id': 6172}, {'_account_id': 6537}, {'_account_id': 9545}, {'_account_id': 10987}, {'_account_id': 12015}]","[{'number': 1, 'created': '2014-08-08 15:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/74e253ab79736e2746583858f7e2e2c9306ee544', 'message': 'Add endpoint opt into auth_plugin\n\nEndpoint should be present in auth_plugin options to allow\nconnect to ceilometer through specified endpoint and token\n\nChange-Id: I0aaafc6f599a67b242ade25efb3e667738bd71fd\n'}, {'number': 2, 'created': '2014-08-08 16:03:01.000000000', 'files': ['ceilometerclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/2ddcff4ee2ae964028c26956a4905596f18a5dbc', 'message': 'Add endpoint opt into auth_plugin\n\nEndpoint should be present in auth_plugin options to allow\nconnect to ceilometer through specified endpoint and token\n\nCloses-Bug: #1354507\nChange-Id: I0aaafc6f599a67b242ade25efb3e667738bd71fd\n'}]",0,112943,2ddcff4ee2ae964028c26956a4905596f18a5dbc,21,9,2,9550,,,0,"Add endpoint opt into auth_plugin

Endpoint should be present in auth_plugin options to allow
connect to ceilometer through specified endpoint and token

Closes-Bug: #1354507
Change-Id: I0aaafc6f599a67b242ade25efb3e667738bd71fd
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/43/112943/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometerclient/client.py'],1,74e253ab79736e2746583858f7e2e2c9306ee544,," 'password', 'username', 'endpoint']"," 'password', 'username']",1,1
openstack%2Ffuel-docs~master~Ia2f835a68c7ecbf812fb916a143d50423f126d40,openstack/fuel-docs,master,Ia2f835a68c7ecbf812fb916a143d50423f126d40,correct statement about CPU utilization and GRE,MERGED,2014-08-08 15:46:35.000000000,2014-08-09 00:17:46.000000000,2014-08-09 00:17:46.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8935}, {'_account_id': 8967}, {'_account_id': 8971}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-08-08 15:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4198cbe85bda68741da6ee405071e6556b6f7530', 'message': 'correct statement about CPU utilization and GRE\n\n- according to discussion on mailing list\n  (https://lists.launchpad.net/fuel-dev/msg01084.html) usage of GRE\n  protocol *increases* CPU utilization on endpoint nodes, our\n  documentation states the opposite, which is wrong.\n\nChange-Id: Ia2f835a68c7ecbf812fb916a143d50423f126d40\n'}, {'number': 2, 'created': '2014-08-09 00:14:02.000000000', 'files': ['pages/planning-guide/4200-net-topology.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/faf83ea6e8ac5fb3193c839bb7f81547bb30e1cd', 'message': 'correct statement about CPU utilization and GRE\n\n- according to discussion on mailing list\n  (https://lists.launchpad.net/fuel-dev/msg01084.html) usage of GRE\n  protocol *increases* CPU utilization on endpoint nodes, our\n  documentation states the opposite, which is wrong.\n\nChange-Id: Ia2f835a68c7ecbf812fb916a143d50423f126d40\n'}]",0,112950,faf83ea6e8ac5fb3193c839bb7f81547bb30e1cd,15,6,2,11427,,,0,"correct statement about CPU utilization and GRE

- according to discussion on mailing list
  (https://lists.launchpad.net/fuel-dev/msg01084.html) usage of GRE
  protocol *increases* CPU utilization on endpoint nodes, our
  documentation states the opposite, which is wrong.

Change-Id: Ia2f835a68c7ecbf812fb916a143d50423f126d40
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/50/112950/2 && git format-patch -1 --stdout FETCH_HEAD,['pages/planning-guide/4200-net-topology.rst'],1,4198cbe85bda68741da6ee405071e6556b6f7530,GRE-CPU-utilization, and increases the CPU utilization on the Compute and Controller nodes., and decreases the CPU utilization of the Compute and Controller nodes.,1,1
openstack%2Ffuel-docs~master~I1cb7727da0f87bcf4ed689c4bcc82ae94a4ae7fa,openstack/fuel-docs,master,I1cb7727da0f87bcf4ed689c4bcc82ae94a4ae7fa,run `aspell' against our documentation,MERGED,2014-08-08 17:52:47.000000000,2014-08-09 00:09:28.000000000,2014-08-09 00:09:28.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-08-08 17:52:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/5f1e7ae646839f4ad872540876cf21a297e87478', 'message': ""run `aspell' against our documentation\n\nChange-Id: I1cb7727da0f87bcf4ed689c4bcc82ae94a4ae7fa\n""}, {'number': 2, 'created': '2014-08-08 18:21:08.000000000', 'files': ['pages/reference-architecture/ovs/0100-neutron-ref-model.rst', 'pages/reference-architecture/storage/0100-object-store-for-images.rst', 'pages/release-notes/v5-0/040-resolved-issues.rst', 'pages/terminology/s/stateless-and-stateful-services.rst', 'pages/terminology/r/resource-agents.rst', 'pages/reference-architecture/bonding/0100-theory.rst', 'pages/user-guide/create-environment/1500-name-distro.rst', 'pages/operations/5400-puppet-custom-attributes.rst', 'pages/operations/2410-galera-autorebuild.rst', 'pages/reference-architecture/1700-ceph.rst', 'pages/operations/murano/7485-test-details.rst', 'pages/terminology/o/overcommit.rst', 'pages/reference-architecture/neutron-intro/0260-neutron-config.rst', 'pages/operations/7400-murano.rst', 'pages/reference-architecture/1200-mysql-galera.rst', 'pages/reference-architecture/7000-vcenter.rst', 'pages/install-guide/install/0200-install-bare-metal.rst', 'pages/operations/docker-on-master.rst', 'pages/reference-architecture/ha-notes/0110-corosync-settings.rst', 'pages/install-guide/0060-download-fuel/0200-download.rst', 'pages/planning-guide/7000-vcenter-plan.rst', 'pages/user-guide/2000-install-boot.rst', 'pages/user-guide/cli.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/6b2cd4851302c91feaebc4aa60fef3dba1217912', 'message': ""run `aspell' against our documentation\n\nChange-Id: I1cb7727da0f87bcf4ed689c4bcc82ae94a4ae7fa\n""}]",0,112986,6b2cd4851302c91feaebc4aa60fef3dba1217912,15,4,2,11427,,,0,"run `aspell' against our documentation

Change-Id: I1cb7727da0f87bcf4ed689c4bcc82ae94a4ae7fa
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/86/112986/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/reference-architecture/ovs/0100-neutron-ref-model.rst', 'pages/reference-architecture/storage/0100-object-store-for-images.rst', 'pages/release-notes/v5-0/040-resolved-issues.rst', 'pages/terminology/s/stateless-and-stateful-services.rst', 'pages/terminology/r/resource-agents.rst', 'pages/reference-architecture/bonding/0100-theory.rst', 'pages/user-guide/create-environment/1500-name-distro.rst', 'pages/operations/5400-puppet-custom-attributes.rst', 'pages/operations/2410-galera-autorebuild.rst', 'pages/reference-architecture/1700-ceph.rst', 'pages/operations/murano/7485-test-details.rst', 'pages/terminology/o/overcommit.rst', 'pages/reference-architecture/neutron-intro/0260-neutron-config.rst', 'pages/operations/7400-murano.rst', 'pages/reference-architecture/1200-mysql-galera.rst', 'pages/reference-architecture/7000-vcenter.rst', 'pages/install-guide/install/0200-install-bare-metal.rst', 'pages/operations/docker-on-master.rst', 'pages/reference-architecture/ha-notes/0110-corosync-settings.rst', 'pages/install-guide/0060-download-fuel/0200-download.rst', 'pages/planning-guide/7000-vcenter-plan.rst', 'pages/user-guide/2000-install-boot.rst', 'pages/user-guide/cli.rst']",23,5f1e7ae646839f4ad872540876cf21a297e87478,aspell-run,Get list of all available releases:Assign some nodes to environment with with specific rolesAlso you can do it without ``--env`` or ``--node`` to remove some nodes without knowing their environment and remove all nodes of some environment respectively.Finally you can deploying environment changes with,Get list of all avaliable releases:Assign some nodes to environemnt with with specific rolesAlso you can do it without ``--env`` or ``--node`` to remove some nodes without knowing their environment and remove all nodes of some environment respectevly.Finally you can deploying environmnet changes with,36,36
openstack%2Fnova~master~If5229ec3059076dbc9f4abb6625504e8864c265e,openstack/nova,master,If5229ec3059076dbc9f4abb6625504e8864c265e,Do not pass instances without host to compute API,MERGED,2014-07-25 11:23:00.000000000,2014-08-08 23:58:19.000000000,2014-07-25 18:27:39.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1849}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-25 11:23:00.000000000', 'files': ['nova/api/openstack/compute/contrib/server_external_events.py', 'nova/tests/api/openstack/compute/contrib/test_server_external_events.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5e4a5f0d8c62ca6e94ae6db16e9fbe0428805158', 'message': 'Do not pass instances without host to compute API\n\nEven if the server external events extension filters out events\nwhose related instance does not have a host, the corresponding\ninstance is still sent to the compute API module.\nAs this might result in KeyError, instance without host should\nbe filtered out before calling the compute API module.\n\nChange-Id: If5229ec3059076dbc9f4abb6625504e8864c265e\nCloses-Bug: #1348584\n'}]",0,109551,5e4a5f0d8c62ca6e94ae6db16e9fbe0428805158,16,9,1,261,,,0,"Do not pass instances without host to compute API

Even if the server external events extension filters out events
whose related instance does not have a host, the corresponding
instance is still sent to the compute API module.
As this might result in KeyError, instance without host should
be filtered out before calling the compute API module.

Change-Id: If5229ec3059076dbc9f4abb6625504e8864c265e
Closes-Bug: #1348584
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/109551/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/contrib/server_external_events.py', 'nova/tests/api/openstack/compute/contrib/test_server_external_events.py']",2,5e4a5f0d8c62ca6e94ae6db16e9fbe0428805158,bug1348584," # the instance without host should not be passed to the compute layer [fake_instance_uuids[1]],"," [fake_instance_uuids[1], fake_instance_uuids[-1]],",8,6
openstack%2Frequirements~stable%2Ficehouse~I9e61adfac71f159e3a6aa77cbcbb26279dc42869,openstack/requirements,stable/icehouse,I9e61adfac71f159e3a6aa77cbcbb26279dc42869,Add new library oslo.utils,MERGED,2014-08-06 16:07:20.000000000,2014-08-08 23:53:27.000000000,2014-08-08 23:53:27.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6486}, {'_account_id': 6873}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-08-06 16:07:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/724b130fe9483023e5577f77f806392932879b89', 'message': 'Add new library oslo.utils\n\nAdd the new library oslo.utils so projects can start adopting it.\n\nConflicts:\n\n\tglobal-requirements.txt\n\nChange-Id: I9e61adfac71f159e3a6aa77cbcbb26279dc42869\n(cherry picked from commit 10d2dfd4511dd4c7ba9c50d302058c33d6b6b778)\n'}, {'number': 2, 'created': '2014-08-06 17:35:39.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/daef7ed90d043c918f4fe4c5b5ae606998bb3055', 'message': ""Add new library oslo.utils\n\nAdd the new library oslo.utils so projects can start adopting it.\n\nIn order to use oslo.utils in python-keystoneclient (and probably in\nother clients), the requirement has to be in stable/icehouse otherwise\nthe check-tempest-dsvm-full-icehouse-* jobs fail with an error:\n\n 'oslo.utils' is not a global requirement but it should be,something\n went wrong\n\nConflicts:\n\n\tglobal-requirements.txt\n\nChange-Id: I9e61adfac71f159e3a6aa77cbcbb26279dc42869\n(cherry picked from commit 10d2dfd4511dd4c7ba9c50d302058c33d6b6b778)\n""}]",0,112337,daef7ed90d043c918f4fe4c5b5ae606998bb3055,17,6,2,6486,,,0,"Add new library oslo.utils

Add the new library oslo.utils so projects can start adopting it.

In order to use oslo.utils in python-keystoneclient (and probably in
other clients), the requirement has to be in stable/icehouse otherwise
the check-tempest-dsvm-full-icehouse-* jobs fail with an error:

 'oslo.utils' is not a global requirement but it should be,something
 went wrong

Conflicts:

	global-requirements.txt

Change-Id: I9e61adfac71f159e3a6aa77cbcbb26279dc42869
(cherry picked from commit 10d2dfd4511dd4c7ba9c50d302058c33d6b6b778)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/37/112337/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,724b130fe9483023e5577f77f806392932879b89,oslo.utils,oslo.utils>=0.1.1 # Apache-2.0,,1,0
openstack%2Ftempest~master~Ic598f49657c704c1cc9a882504766671aabe685a,openstack/tempest,master,Ic598f49657c704c1cc9a882504766671aabe685a,Add tempest post-run cleanup script,ABANDONED,2014-08-07 17:50:17.000000000,2014-08-08 23:52:27.000000000,,"[{'_account_id': 3}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-07 17:50:17.000000000', 'files': ['tempest/clients.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/0048ff8e42f886dc59e869838ec6e2e8597e7ebb', 'message': ""Add tempest post-run cleanup script\n\nImplemented all features defined in blueprint.\n\nAdded TenantManager Manager object in clients that uses\n **kwargs for its credentials so it can accept any username,\npassword an tenant_name combination for managing any\ntenant's objects\n\nChange-Id: Ic598f49657c704c1cc9a882504766671aabe685a\nImplements: blueprint post-run-cleanup\n""}]",0,112641,0048ff8e42f886dc59e869838ec6e2e8597e7ebb,5,3,1,10644,,,0,"Add tempest post-run cleanup script

Implemented all features defined in blueprint.

Added TenantManager Manager object in clients that uses
 **kwargs for its credentials so it can accept any username,
password an tenant_name combination for managing any
tenant's objects

Change-Id: Ic598f49657c704c1cc9a882504766671aabe685a
Implements: blueprint post-run-cleanup
",git fetch https://review.opendev.org/openstack/tempest refs/changes/41/112641/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/clients.py'],1,0048ff8e42f886dc59e869838ec6e2e8597e7ebb,bp/post-run-cleanup,"class TenantManager(Manager): """""" Manager object that uses **kwargs for its credentials so it can accept any username, password an tenant_name combination for managing any tenant's objects """""" def __init__(self, interface='json', service=None, **kwargs): super(TenantManager, self).__init__( credentials=auth.get_credentials(**kwargs), interface=interface, service=service) ",,14,0
openstack%2Fnova~master~I111b1c8a492f12587f86ab83825060029605390d,openstack/nova,master,I111b1c8a492f12587f86ab83825060029605390d,Pass errors from detach methods back to api proc,MERGED,2014-07-08 15:19:54.000000000,2014-08-08 23:45:03.000000000,2014-07-25 22:28:59.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 8190}, {'_account_id': 8412}, {'_account_id': 8430}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 9970}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-08 15:19:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cfdc04ddae8014e994e299057c50708c8e9e8fd7', 'message': ""Pass errors from detach methods back to api proc\n\nThe initial implementation of the detach_volume and detach_interface\nmethods were built as cast invocations.  Their respective attach methods\nwere built as call invocations.  What this led to was, if the user\nattempted to attach in incorrect port, that error would be passed back\nup to the API properly.\n\nHowever, if the user attempted to detach an invalid interface, the\nresponse from the API would be an HTTP 202 (because the cast assumes\nsuccess).  The root error may be logged in the respective nova compute\nlog, but it did not make its way back up to the user.\n\nThis change set changes the detach to follow the precedent of their\nrespective attach methods and flips them to 'call' (synchronous).  This\nwill properly pass the error messages up to the invoker.\n\nChange-Id: I111b1c8a492f12587f86ab83825060029605390d\nCloses-Bug: #1339098\n""}, {'number': 2, 'created': '2014-07-08 16:45:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/145c60b6111eff281a167ff25d73fdb8aa25a380', 'message': ""Pass errors from detach methods back to api proc\n\nThe initial implementation of the detach_interface method was built\nas cast invocations.  The respective attach method was built as a call\ninvocation.  What this led to was, if the user attempted to attach an\nincorrect port, that error would be passed back up to the API properly.\n\nHowever, if the user attempted to detach an invalid interface, the\nresponse from the API would be an HTTP 202 (because the cast assumes\nsuccess).  The root error may be logged in the respective nova compute\nlog, but it did not make its way back up to the user.\n\nThis change updates the decorators to the manager methods to update the\ninstance's fault when the attach or detach encounters an issue.\n\nChange-Id: I111b1c8a492f12587f86ab83825060029605390d\nCloses-Bug: #1339098\n""}, {'number': 3, 'created': '2014-07-14 21:10:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e525054ae6934c08431faafc74d395884d7d016c', 'message': ""Pass errors from detach methods back to api proc\n\nThe initial implementation of the detach_interface method was built\nas cast invocations.  The respective attach method was built as a call\ninvocation.  What this led to was, if the user attempted to attach an\nincorrect port, that error would be passed back up to the API properly.\n\nHowever, if the user attempted to detach an invalid interface, the\nresponse from the API would be an HTTP 202 (because the cast assumes\nsuccess).  The root error may be logged in the respective nova compute\nlog, but it did not make its way back up to the user.\n\nThis change updates the decorators to the manager methods to update the\ninstance's fault when the attach or detach encounters an issue.\n\nChange-Id: I111b1c8a492f12587f86ab83825060029605390d\nCloses-Bug: #1339098\n""}, {'number': 4, 'created': '2014-07-19 13:50:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d5a4eee25b7605fd0fe4fd47b0d88c8208037470', 'message': ""Pass errors from detach methods back to api proc\n\nThe initial implementation of the detach_interface method was built\nas cast invocations.  The respective attach method was built as a call\ninvocation.  What this led to was, if the user attempted to attach an\nincorrect port, that error would be passed back up to the API properly.\n\nHowever, if the user attempted to detach an invalid interface, the\nresponse from the API would be an HTTP 202 (because the cast assumes\nsuccess).  The root error may be logged in the respective nova compute\nlog, but it did not make its way back up to the user.\n\nThis change updates the decorators to the manager methods to update the\ninstance's fault when the attach or detach encounters an issue.\n\nChange-Id: I111b1c8a492f12587f86ab83825060029605390d\nCloses-Bug: #1339098\n""}, {'number': 5, 'created': '2014-07-25 11:04:22.000000000', 'files': ['nova/tests/compute/test_compute_mgr.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4f040295814c7c4bb694411ad6baf2d1c0db62a4', 'message': ""Pass errors from detach methods back to api proc\n\nThe initial implementation of the detach_interface method was built as\ncast invocations.  The respective attach method was built as a call\ninvocation.  What this led to was, if the user attempted to attach an\nincorrect port, that error would be passed back up to the API\nproperly.\n\nHowever, if the user attempted to detach an invalid interface, the\nresponse from the API would be an HTTP 202 (because the cast assumes\nsuccess).  The root error may be logged in the respective nova compute\nlog, but it did not make its way back up to the user.\n\nThis change updates the decorators to the manager methods to update\nthe instance's fault when the attach or detach encounters an issue.\n\nChange-Id: I111b1c8a492f12587f86ab83825060029605390d\nCloses-Bug: #1339098\n""}]",4,105485,4f040295814c7c4bb694411ad6baf2d1c0db62a4,80,18,5,8190,,,0,"Pass errors from detach methods back to api proc

The initial implementation of the detach_interface method was built as
cast invocations.  The respective attach method was built as a call
invocation.  What this led to was, if the user attempted to attach an
incorrect port, that error would be passed back up to the API
properly.

However, if the user attempted to detach an invalid interface, the
response from the API would be an HTTP 202 (because the cast assumes
success).  The root error may be logged in the respective nova compute
log, but it did not make its way back up to the user.

This change updates the decorators to the manager methods to update
the instance's fault when the attach or detach encounters an issue.

Change-Id: I111b1c8a492f12587f86ab83825060029605390d
Closes-Bug: #1339098
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/105485/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_rpcapi.py', 'nova/compute/rpcapi.py']",2,cfdc04ddae8014e994e299057c50708c8e9e8fd7,bug/1339098," return cctxt.call(ctxt, 'detach_interface', instance=instance, port_id=port_id) return cctxt.call(ctxt, 'detach_volume', instance=instance, volume_id=volume_id)"," cctxt.cast(ctxt, 'detach_interface', instance=instance, port_id=port_id) cctxt.cast(ctxt, 'detach_volume', instance=instance, volume_id=volume_id)",8,8
openstack%2Frally~master~I3ba0deeb5a2793b8c45f6160fe0eda22250a1ece,openstack/rally,master,I3ba0deeb5a2793b8c45f6160fe0eda22250a1ece,Split user and admin cleanup to 2 separate classes,MERGED,2014-06-17 15:08:46.000000000,2014-08-08 23:23:40.000000000,2014-08-08 23:23:40.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 6124}, {'_account_id': 6172}, {'_account_id': 6536}, {'_account_id': 7369}, {'_account_id': 9545}, {'_account_id': 9601}, {'_account_id': 11105}]","[{'number': 1, 'created': '2014-06-17 15:08:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/307c17e045dd68d5c33df0dd7d5bd890702d4cd9', 'message': 'Split user and admin cleanup to 2 separate classes\n\nChange-Id: I3ba0deeb5a2793b8c45f6160fe0eda22250a1ece\n'}, {'number': 2, 'created': '2014-06-18 15:44:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1afcb73367c9eaa057e3a807c61caa7573f8abfa', 'message': 'Split user and admin cleanup to 2 separate classes\n\nblueprint: bp/benchmark-context-cleanup-refactor\nChange-Id: I3ba0deeb5a2793b8c45f6160fe0eda22250a1ece\n'}, {'number': 3, 'created': '2014-07-04 09:55:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1e332bc9f40ef793d792e3b1f91c43f463e49828', 'message': 'Split user and admin cleanup to 2 separate classes\n\nblueprint: bp/benchmark-context-cleanup-refactor\nChange-Id: I3ba0deeb5a2793b8c45f6160fe0eda22250a1ece\n'}, {'number': 4, 'created': '2014-07-04 10:01:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b8b43994a13648e9075efa9b57e8858039f50820', 'message': 'Split user and admin cleanup to 2 separate classes\n\nblueprint: bp/benchmark-context-cleanup-refactor\nChange-Id: I3ba0deeb5a2793b8c45f6160fe0eda22250a1ece\n'}, {'number': 5, 'created': '2014-07-30 08:56:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3880f9f394d74a50748f69fddd296e81d9c62bef', 'message': 'Split user and admin cleanup to 2 separate classes\n\nblueprint: bp/benchmark-context-cleanup-refactor\nChange-Id: I3ba0deeb5a2793b8c45f6160fe0eda22250a1ece\n'}, {'number': 6, 'created': '2014-08-04 18:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b88b3ed1c7055633b14618b10ee7a0d0cb8f0bff', 'message': 'Split user and admin cleanup to 2 separate classes\n\nPartially implements: blueprint bp/benchmark-context-cleanup-refactor\nChange-Id: I3ba0deeb5a2793b8c45f6160fe0eda22250a1ece\n'}, {'number': 7, 'created': '2014-08-05 10:29:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6f2c78fc332366398d5696d4468b205d01da18f5', 'message': 'Split user and admin cleanup to 2 separate classes\n\nPartially implements: blueprint bp/benchmark-context-cleanup-refactor\nChange-Id: I3ba0deeb5a2793b8c45f6160fe0eda22250a1ece\n'}, {'number': 8, 'created': '2014-08-06 20:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/96a11eadf84da6713ec60c6c8d739dd5f0543cb5', 'message': 'Split user and admin cleanup to 2 separate classes\n\nPartially implements: blueprint bp/benchmark-context-cleanup-refactor\nChange-Id: I3ba0deeb5a2793b8c45f6160fe0eda22250a1ece\n'}, {'number': 9, 'created': '2014-08-07 08:53:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/be080f502b91d8a705aab20c7b71ca6c3417dcae', 'message': 'Split user and admin cleanup to 2 separate classes\n\nPartially implements: blueprint benchmark-context-cleanup-refactor\nChange-Id: I3ba0deeb5a2793b8c45f6160fe0eda22250a1ece\n'}, {'number': 10, 'created': '2014-08-08 15:04:27.000000000', 'files': ['tests/benchmark/context/cleanup/test_admin_cleanup.py', 'rally/benchmark/context/cleanup/utils.py', 'tests/benchmark/context/cleanup/test_cleanup.py', 'rally/benchmark/context/cleanup/admin_cleanup.py', 'rally/benchmark/context/cleanup/user_cleanup.py', 'rally/benchmark/scenarios/keystone/basic.py', 'rally/benchmark/context/cleanup/cleanup.py', 'tests/benchmark/context/cleanup/test_user_cleanup.py', 'rally/benchmark/scenarios/quotas/quotas.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/2fb4ba41d5c08c6f81a99e375fc95030a2e10357', 'message': 'Split user and admin cleanup to 2 separate classes\n\nPartially implements: blueprint benchmark-context-cleanup-refactor\nChange-Id: I3ba0deeb5a2793b8c45f6160fe0eda22250a1ece\n'}]",59,100590,2fb4ba41d5c08c6f81a99e375fc95030a2e10357,63,9,10,6536,,,0,"Split user and admin cleanup to 2 separate classes

Partially implements: blueprint benchmark-context-cleanup-refactor
Change-Id: I3ba0deeb5a2793b8c45f6160fe0eda22250a1ece
",git fetch https://review.opendev.org/openstack/rally refs/changes/90/100590/8 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/context/cleanup/admin_cleanup.py', 'rally/benchmark/context/base.py', 'rally/benchmark/context/cleanup/user_cleanup.py', 'rally/benchmark/context/cleanup/cleanup.py']",4,307c17e045dd68d5c33df0dd7d5bd890702d4cd9,bp/benchmark-context-cleanup-refactor,"from admin_cleanup import AdminResourceCleaner from user_cleanup import UserResourceCleaner """"""Context class for resource cleanup (both admin and non-admin). Format: {'admin': {'endpoint': <rally.objects.endpoint.Endpoint object at 0x*>}, 'scenario_name': 'CeilometerBasic.create_and_delete_alarm', 'task': <rally.objects.task.Task object at 0x7f5891734610>, 'config': {'cleanup': ['ceilometer'], 'users': {} } } """""" # __ctx_name__ = ""cleanup"" # __ctx_order__ = 200 # __ctx_hidden__ = True # # CONFIG_SCHEMA = { # ""type"": ""array"", # ""$schema"": rutils.JSON_SCHEMA, # ""items"": { # ""type"": ""string"", # ""enum"": [""nova"", ""glance"", ""cinder"", # ""quotas"", ""neutron"", ""ceilometer"", ""heat""] # }, # ""uniqueItems"": True # } # # def __init__(self, context): # super(ResourceCleaner, self).__init__(context) # self.admin = [] # self.users = [] # @rutils.log_task_wrapper(LOG.info, _(""Cleanup users resources."")) # def _cleanup_users_resources(self): # for user in self.users: # clients = osclients.Clients(user) # admin_clients = functools.partial(osclients.Clients, self.admin) # tenant_id = clients.keystone().tenant_id # cleanup_methods = { # ""nova"": (utils.delete_nova_resources, clients.nova), # ""glance"": (utils.delete_glance_resources, clients.glance, # tenant_id), # ""cinder"": (utils.delete_cinder_resources, clients.cinder), # ""quotas"": (utils.delete_quotas, admin_clients, # tenant_id), # ""neutron"": (utils.delete_neutron_resources, clients.neutron, # tenant_id), # ""ceilometer"": (utils.delete_ceilometer_resources, # clients.ceilometer, tenant_id), # ""heat"": (utils.delete_heat_resources, clients.heat) # } # # for service_name in self.config: # try: # service = cleanup_methods[service_name] # method = service[0] # client = service[1]() # args = service[2:] # method(client, *args) # except Exception as e: # LOG.debug(""Not all resources were cleaned."", # exc_info=sys.exc_info()) # LOG.warning(_('Unable to fully cleanup the cloud: %s') % # (six.text_type(e))) # # @rutils.log_task_wrapper(LOG.info, _(""Cleanup admin resources."")) # def _cleanup_admin_resources(self): # try: # admin = osclients.Clients(self.admin) # utils.delete_keystone_resources(admin.keystone()) # except Exception as e: # LOG.debug(""Not all resources were cleaned."", # exc_info=sys.exc_info()) # LOG.warning(_('Unable to fully cleanup keystone service: %s') % # (six.text_type(e))) # @rutils.log_task_wrapper(LOG.info, _(""Enter context: `cleanup`"")) # def setup(self): # if ""admin"" in self.context and self.context[""admin""]: # self.admin = self.context[""admin""][""endpoint""] # if ""users"" in self.context and self.context[""users""]: # self.users = [u[""endpoint""] for u in self.context[""users""]] # # @rutils.log_task_wrapper(LOG.info, _(""Exit context: `cleanup`"")) # def cleanup(self): # if self.users and self.config: # self._cleanup_users_resources() # if self.admin: # self._cleanup_admin_resources()"," """"""Context class for resource cleanup (both admin and non-admin)."""""" __ctx_name__ = ""cleanup"" __ctx_order__ = 200 __ctx_hidden__ = True CONFIG_SCHEMA = { ""type"": ""array"", ""$schema"": rutils.JSON_SCHEMA, ""items"": { ""type"": ""string"", ""enum"": [""nova"", ""glance"", ""cinder"", ""quotas"", ""neutron"", ""ceilometer"", ""heat""] }, ""uniqueItems"": True } def __init__(self, context): super(ResourceCleaner, self).__init__(context) self.admin = [] self.users = [] @rutils.log_task_wrapper(LOG.info, _(""Cleanup users resources."")) def _cleanup_users_resources(self): for user in self.users: clients = osclients.Clients(user) admin_clients = functools.partial(osclients.Clients, self.admin) tenant_id = clients.keystone().tenant_id cleanup_methods = { ""nova"": (utils.delete_nova_resources, clients.nova), ""glance"": (utils.delete_glance_resources, clients.glance, tenant_id), ""cinder"": (utils.delete_cinder_resources, clients.cinder), ""quotas"": (utils.delete_quotas, admin_clients, tenant_id), ""neutron"": (utils.delete_neutron_resources, clients.neutron, tenant_id), ""ceilometer"": (utils.delete_ceilometer_resources, clients.ceilometer, tenant_id), ""heat"": (utils.delete_heat_resources, clients.heat) } for service_name in self.config: try: service = cleanup_methods[service_name] method = service[0] client = service[1]() args = service[2:] method(client, *args) except Exception as e: LOG.debug(""Not all resources were cleaned."", exc_info=sys.exc_info()) LOG.warning(_('Unable to fully cleanup the cloud: %s') % (six.text_type(e))) @rutils.log_task_wrapper(LOG.info, _(""Cleanup admin resources."")) def _cleanup_admin_resources(self): try: admin = osclients.Clients(self.admin) utils.delete_keystone_resources(admin.keystone()) except Exception as e: LOG.debug(""Not all resources were cleaned."", exc_info=sys.exc_info()) LOG.warning(_('Unable to fully cleanup keystone service: %s') % (six.text_type(e))) @rutils.log_task_wrapper(LOG.info, _(""Enter context: `cleanup`"")) def setup(self): if ""admin"" in self.context and self.context[""admin""]: self.admin = self.context[""admin""][""endpoint""] if ""users"" in self.context and self.context[""users""]: self.users = [u[""endpoint""] for u in self.context[""users""]] @rutils.log_task_wrapper(LOG.info, _(""Exit context: `cleanup`"")) def cleanup(self): if self.users and self.config: self._cleanup_users_resources() if self.admin: self._cleanup_admin_resources()",238,75
openstack%2Foslo-specs~master~I5c323d0bb09e415375c8091b070926f498afa016,openstack/oslo-specs,master,I5c323d0bb09e415375c8091b070926f498afa016,fix the name of the pylockfile spec,MERGED,2014-08-08 23:03:15.000000000,2014-08-08 23:05:45.000000000,2014-08-08 23:05:45.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2014-08-08 23:03:15.000000000', 'files': ['specs/juno/pylockfile-adoption.rst'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/902adfb9431cdcc602b2d6dcbbfc30971a89996b', 'message': 'fix the name of the pylockfile spec\n\nChange-Id: I5c323d0bb09e415375c8091b070926f498afa016\n'}]",0,113043,902adfb9431cdcc602b2d6dcbbfc30971a89996b,7,2,1,2472,,,0,"fix the name of the pylockfile spec

Change-Id: I5c323d0bb09e415375c8091b070926f498afa016
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/43/113043/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/pylockfile-adoption.rst'],1,902adfb9431cdcc602b2d6dcbbfc30971a89996b,fix-pylockfile-name,,,0,0
openstack%2Foslo-specs~master~I786fefce461abff8e2ba98d2b4473cc60314255e,openstack/oslo-specs,master,I786fefce461abff8e2ba98d2b4473cc60314255e,pylockfile adoption,MERGED,2014-06-24 12:06:55.000000000,2014-08-08 23:02:04.000000000,2014-08-08 23:02:04.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1297}, {'_account_id': 1561}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 6928}, {'_account_id': 8041}, {'_account_id': 9107}, {'_account_id': 9712}, {'_account_id': 9796}]","[{'number': 1, 'created': '2014-06-24 12:06:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/1cbd46ab30125a28953c4661ab438a0eeace3474', 'message': 'pylockfile adoption\n\nChange-Id: I786fefce461abff8e2ba98d2b4473cc60314255e\n'}, {'number': 2, 'created': '2014-07-24 15:19:52.000000000', 'files': ['specs/juno/pylockfile.rst'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/220bc8965a1638713b84092dcc5ce546b0098914', 'message': 'pylockfile adoption\n\nChange-Id: I786fefce461abff8e2ba98d2b4473cc60314255e\n'}]",4,102202,220bc8965a1638713b84092dcc5ce546b0098914,24,15,2,1669,,,0,"pylockfile adoption

Change-Id: I786fefce461abff8e2ba98d2b4473cc60314255e
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/02/102202/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/pylockfile.rst'],1,1cbd46ab30125a28953c4661ab438a0eeace3474,jd/pylockfile,"============================= Adoption of pylockfile ============================= https://blueprints.launchpad.net/oslo/+spec/pylockfile-adoption Problem description =================== The pylockfile library is used by at least oslo.db instead of oslo-incubator/lockutils. This library has seen a few maintenance issues in the last months, which caused problem. The current maintainer is looking for help to maintain it in the future. Proposed change =============== The proposed change is to adopt this library under the Oslo program so we can maintain it and merge it with oslo-incubator/lockutils. Alternatives ------------ We could stop using pylockutils altogether and release a new lock library based on oslo-incubator/lockutils. Implementation ============== Assignee(s) ----------- Primary assignee: jdanjou Other contributors: None Milestones ---------- juno-2 Work Items ---------- - Create a repository on OpenStack infra - Add oslo-core to pylockfile-core on Gerrit - Release a new version of pylockutils References ========== * Request from current pylockfile maintainer for help: https://github.com/smontanaro/pylockfile/issues/11#issuecomment-45634012 * openstack-dev thread: http://lists.openstack.org/pipermail/openstack-dev/2014-June/038387.html * Review to create pylockfile repository: https://review.openstack.org/#/c/101911/ .. note:: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ",,68,0
openstack%2Fnova~master~I284ae7a84384f19131703c4ad44e0e5f5b03f5d4,openstack/nova,master,I284ae7a84384f19131703c4ad44e0e5f5b03f5d4,Enable terminate for EC2 InstanceInitiatedShutdownBehavior,MERGED,2013-07-21 18:28:13.000000000,2014-08-08 22:45:47.000000000,2014-08-07 20:25:49.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 642}, {'_account_id': 1030}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 5652}, {'_account_id': 6661}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2013-07-21 18:28:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f933d510a45571897f0178134e55a8c72ab2231', 'message': ""Enable EC2 InstanceInitiatedShutdownBehavior of terminate\n\nThe EC2 API supports an instance attribute called\nInstanceInitiatedShutdownBehavior (IISB) which can be set to\n'stop' or 'terminate' (default: 'stop').  When the instance\ninitiates its own shutdown, this determines whether or not\nthe instance hangs around in the Shutoff state or is\nterminated by the system.\n\nIn nova, this is handled by the shutdown_terminate boolean.\nIISB = stop      => shutdown_terminate = False\nIISB = terminate => shutdown_terminate = True\n\nsync_power_state now invokes terminate_instance if\nshutdown_terminate = True and we detect the image power state\nhas gone from Running to Shutdown.\n\nFixes bug #1131395\n\nChange-Id: I284ae7a84384f19131703c4ad44e0e5f5b03f5d4\n""}, {'number': 2, 'created': '2013-07-29 21:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7bc4060fdc91fcd0a0f3f29f9b7d9d706b206ed7', 'message': ""Enable terminate for EC2 InstanceInitiatedShutdownBehavior\n\nThe EC2 API supports an instance attribute called\nInstanceInitiatedShutdownBehavior (IISB) which can be set to\n'stop' or 'terminate' (default: 'stop').  When the instance\ninitiates its own shutdown, this determines whether or not\nthe instance hangs around in the Shutoff state or is\nterminated by the system.\n\nIn nova, this is handled by the shutdown_terminate boolean.\nIISB = stop      => shutdown_terminate = False\nIISB = terminate => shutdown_terminate = True\n\nThis commit adds compute_delete to the conductor API;\nsync_instance_power_state now invokes compute_delete if\nshutdown_terminate = True and we detect the image power state\nhas gone from Running to Shutdown.\n\nFixes bug #1131395\n\nChange-Id: I284ae7a84384f19131703c4ad44e0e5f5b03f5d4\n""}, {'number': 3, 'created': '2013-07-30 01:56:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba9906f5e600657bd4cc36e03e77fa01f3eb4e59', 'message': ""Enable terminate for EC2 InstanceInitiatedShutdownBehavior\n\nThe EC2 API supports an instance attribute called\nInstanceInitiatedShutdownBehavior (IISB) which can be set to\n'stop' or 'terminate' (default: 'stop').  When the instance\ninitiates its own shutdown, this determines whether or not\nthe instance hangs around in the Shutoff state or is\nterminated by the system.\n\nIn nova, this is handled by the shutdown_terminate boolean.\nIISB = stop      => shutdown_terminate = False\nIISB = terminate => shutdown_terminate = True\n\nThis commit adds compute_delete to the conductor API;\nsync_instance_power_state now invokes compute_delete if\nshutdown_terminate = True and we detect the image power state\nhas gone from Running to Shutdown.\n\nFixes bug #1131395\n\nChange-Id: I284ae7a84384f19131703c4ad44e0e5f5b03f5d4\n""}, {'number': 4, 'created': '2013-07-30 13:15:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6ed260878acdb2b17ea9dd770b1b43455ea8312f', 'message': ""Enable terminate for EC2 InstanceInitiatedShutdownBehavior\n\nThe EC2 API supports an instance attribute called\nInstanceInitiatedShutdownBehavior (IISB) which can be set to\n'stop' or 'terminate' (default: 'stop').  When the instance\ninitiates its own shutdown, this determines whether or not\nthe instance hangs around in the Shutoff state or is\nterminated by the system.\n\nIn nova, this is handled by the shutdown_terminate boolean.\nIISB = stop      => shutdown_terminate = False\nIISB = terminate => shutdown_terminate = True\n\nThis commit adds compute_delete to the conductor API;\nsync_instance_power_state now invokes compute_delete if\nshutdown_terminate = True and we detect the instance power state\nhas gone from Running to Shutdown.\n\nFixes bug #1131395\n\nChange-Id: I284ae7a84384f19131703c4ad44e0e5f5b03f5d4\n""}, {'number': 5, 'created': '2014-07-14 04:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f59c8d037483c246ec80e5a98b312a613e22ef5e', 'message': ""Enable terminate for EC2 InstanceInitiatedShutdownBehavior\n\nThe EC2 API supports an instance attribute called\nInstanceInitiatedShutdownBehavior (IISB) which can be set to\n'stop' or 'terminate' (default: 'stop').  When the instance\ninitiates its own shutdown, this determines whether or not\nthe instance hangs around in the Shutoff state or is\nterminated by the system.\n\nIn nova, this is handled by the shutdown_terminate boolean.\nIISB = stop      => shutdown_terminate = False\nIISB = terminate => shutdown_terminate = True\n\nsync_instance_power_state now invokes compute_api.delete if\nshutdown_terminate = True and we detect the instance power state\nhas gone from Running to Shutdown.\n\nCloses-bug #1131395\nChange-Id: I284ae7a84384f19131703c4ad44e0e5f5b03f5d4\n""}, {'number': 6, 'created': '2014-07-14 21:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/de7cd148f3ca5eaa21f94fce80fd17309224e609', 'message': ""Enable terminate for EC2 InstanceInitiatedShutdownBehavior\n\nThe EC2 API supports an instance attribute called\nInstanceInitiatedShutdownBehavior (IISB) which can be set to\n'stop' or 'terminate' (default: 'stop').  When the instance\ninitiates its own shutdown, this determines whether or not\nthe instance hangs around in the Shutoff state or is\nterminated by the system.\n\nIn nova, this is handled by the shutdown_terminate boolean.\nIISB = stop      => shutdown_terminate = False\nIISB = terminate => shutdown_terminate = True\n\nsync_instance_power_state now invokes compute_api.delete if\nshutdown_terminate = True and we detect the instance power state\nhas gone from Running to Shutdown.\n\nCloses-bug #1131395\nChange-Id: I284ae7a84384f19131703c4ad44e0e5f5b03f5d4\n""}, {'number': 7, 'created': '2014-07-17 14:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c19423e0086ab4c9506e67bf85bad2f887ce61fa', 'message': ""Enable terminate for EC2 InstanceInitiatedShutdownBehavior\n\nThe EC2 API supports an instance attribute called\nInstanceInitiatedShutdownBehavior (IISB) which can be set to\n'stop' or 'terminate' (default: 'stop').  When the instance\ninitiates its own shutdown, this determines whether or not\nthe instance hangs around in the Shutoff state or is\nterminated by the system.\n\nIn nova, this is handled by the shutdown_terminate boolean.\nIISB = stop      => shutdown_terminate = False\nIISB = terminate => shutdown_terminate = True\n\nsync_instance_power_state now invokes compute_api.delete if\nshutdown_terminate = True and we detect the instance power state\nhas gone from Running to Shutdown.\n\nCloses-Bug: #1131395\nChange-Id: I284ae7a84384f19131703c4ad44e0e5f5b03f5d4\n""}, {'number': 8, 'created': '2014-08-04 22:00:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cab680c44e60480afb6c0e67cfb2e8ff800368be', 'message': ""Enable terminate for EC2 InstanceInitiatedShutdownBehavior\n\nThe EC2 API supports an instance attribute called\nInstanceInitiatedShutdownBehavior (IISB) which can be set to\n'stop' or 'terminate' (default: 'stop').  When the instance\ninitiates its own shutdown, this determines whether or not\nthe instance hangs around in the Shutoff state or is\nterminated by the system.\n\nIn nova, this is handled by the shutdown_terminate boolean.\nIISB = stop      => shutdown_terminate = False\nIISB = terminate => shutdown_terminate = True\n\nsync_instance_power_state now invokes compute_api.delete if\nshutdown_terminate = True and we detect the instance power state\nhas gone from Running to Shutdown.\n\nCloses-Bug: #1131395\nChange-Id: I284ae7a84384f19131703c4ad44e0e5f5b03f5d4\n""}, {'number': 9, 'created': '2014-08-05 15:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01099b5867638bd1b14d41f904b80c3e8b845917', 'message': ""Enable terminate for EC2 InstanceInitiatedShutdownBehavior\n\nThe EC2 API supports an instance attribute called\nInstanceInitiatedShutdownBehavior (IISB) which can be set to\n'stop' or 'terminate' (default: 'stop').  When the instance\ninitiates its own shutdown, this determines whether or not\nthe instance hangs around in the Shutoff state or is\nterminated by the system.\n\nIn nova, this is handled by the shutdown_terminate boolean.\nIISB = stop      => shutdown_terminate = False\nIISB = terminate => shutdown_terminate = True\n\nsync_instance_power_state now invokes compute_api.delete if\nshutdown_terminate = True and we detect the instance power state\nhas gone from Running to Shutdown.\n\nCloses-Bug: #1131395\nChange-Id: I284ae7a84384f19131703c4ad44e0e5f5b03f5d4\n""}, {'number': 10, 'created': '2014-08-05 17:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f4212ae09e50bf2d2a6ba07825552ffe80ee2060', 'message': ""Enable terminate for EC2 InstanceInitiatedShutdownBehavior\n\nThe EC2 API supports an instance attribute called\nInstanceInitiatedShutdownBehavior (IISB) which can be set to\n'stop' or 'terminate' (default: 'stop').  When the instance\ninitiates its own shutdown, this determines whether or not\nthe instance hangs around in the Shutoff state or is\nterminated by the system.\n\nIn nova, this is handled by the shutdown_terminate boolean.\nIISB = stop      => shutdown_terminate = False\nIISB = terminate => shutdown_terminate = True\n\nsync_instance_power_state now invokes compute_api.delete if\nshutdown_terminate = True and we detect the instance power state\nhas gone from Running to Shutdown.\n\nCloses-Bug: #1131395\nChange-Id: I284ae7a84384f19131703c4ad44e0e5f5b03f5d4\n""}, {'number': 11, 'created': '2014-08-06 14:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c4c0dbfc7307e58fc859bfefbe6a8bd84d38b20', 'message': ""Enable terminate for EC2 InstanceInitiatedShutdownBehavior\n\nThe EC2 API supports an instance attribute called\nInstanceInitiatedShutdownBehavior (IISB) which can be set to\n'stop' or 'terminate' (default: 'stop').  When the instance\ninitiates its own shutdown, this determines whether or not\nthe instance hangs around in the Shutoff state or is\nterminated by the system.\n\nIn nova, this is handled by the shutdown_terminate boolean.\nIISB = stop      => shutdown_terminate = False\nIISB = terminate => shutdown_terminate = True\n\nsync_instance_power_state now invokes compute_api.delete if\nshutdown_terminate = True and we detect the instance power state\nhas gone from Running to Shutdown.\n\nCloses-Bug: #1131395\nChange-Id: I284ae7a84384f19131703c4ad44e0e5f5b03f5d4\n""}, {'number': 12, 'created': '2014-08-07 16:47:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32a2eb8a648c04625701b2c9373947e541a03648', 'message': ""Enable terminate for EC2 InstanceInitiatedShutdownBehavior\n\nThe EC2 API supports an instance attribute called\nInstanceInitiatedShutdownBehavior (IISB) which can be set to\n'stop' or 'terminate' (default: 'stop').  When the instance\ninitiates its own shutdown, this determines whether or not\nthe instance hangs around in the Shutoff state or is\nterminated by the system.\n\nIn nova, this is handled by the shutdown_terminate boolean.\nIISB = stop      => shutdown_terminate = False\nIISB = terminate => shutdown_terminate = True\n\nsync_instance_power_state now invokes compute_api.delete if\nshutdown_terminate = True and we detect the instance power state\nhas gone from Running to Shutdown.\n\nCloses-Bug: #1131395\nChange-Id: I284ae7a84384f19131703c4ad44e0e5f5b03f5d4\n""}, {'number': 13, 'created': '2014-08-07 16:56:49.000000000', 'files': ['nova/tests/compute/test_compute_api.py', 'nova/tests/compute/test_compute_mgr.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/api/ec2/cloud.py', 'nova/compute/manager.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6132f991bdc8515aa665db16fef260ff71a618e6', 'message': ""Enable terminate for EC2 InstanceInitiatedShutdownBehavior\n\nThe EC2 API supports an instance attribute called\nInstanceInitiatedShutdownBehavior (IISB) which can be set to\n'stop' or 'terminate' (default: 'stop').  When the instance\ninitiates its own shutdown, this determines whether or not\nthe instance hangs around in the Shutoff state or is\nterminated by the system.\n\nIn nova, this is handled by the shutdown_terminate boolean.\nIISB = stop      => shutdown_terminate = False\nIISB = terminate => shutdown_terminate = True\n\nsync_instance_power_state now invokes compute_api.delete if\nshutdown_terminate = True and we detect the instance power state\nhas gone from Running to Shutdown.\n\nCloses-Bug: #1131395\nChange-Id: I284ae7a84384f19131703c4ad44e0e5f5b03f5d4\n""}]",21,38081,6132f991bdc8515aa665db16fef260ff71a618e6,127,18,13,6661,,,0,"Enable terminate for EC2 InstanceInitiatedShutdownBehavior

The EC2 API supports an instance attribute called
InstanceInitiatedShutdownBehavior (IISB) which can be set to
'stop' or 'terminate' (default: 'stop').  When the instance
initiates its own shutdown, this determines whether or not
the instance hangs around in the Shutoff state or is
terminated by the system.

In nova, this is handled by the shutdown_terminate boolean.
IISB = stop      => shutdown_terminate = False
IISB = terminate => shutdown_terminate = True

sync_instance_power_state now invokes compute_api.delete if
shutdown_terminate = True and we detect the instance power state
has gone from Running to Shutdown.

Closes-Bug: #1131395
Change-Id: I284ae7a84384f19131703c4ad44e0e5f5b03f5d4
",git fetch https://review.opendev.org/openstack/nova refs/changes/81/38081/12 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_mgr.py', 'nova/tests/api/ec2/test_cloud.py', 'nova/api/ec2/cloud.py', 'nova/compute/manager.py', 'nova/compute/api.py']",5,8f933d510a45571897f0178134e55a8c72ab2231,bug/1131395," block_device_mapping, shutdown_terminate): num_instances, i, shutdown_terminate=shutdown_terminate) reservation_id=None, scheduler_hints=None, shutdown_terminate=None): block_device_mapping, shutdown_terminate=shutdown_terminate) block_device_mapping, shutdown_terminate): if shutdown_terminate: instance['shutdown_terminate'] = True else: index, shutdown_terminate=None): block_device_mapping, shutdown_terminate) auto_disk_config=None, scheduler_hints=None, shutdown_terminate=None): scheduler_hints=scheduler_hints, shutdown_terminate=shutdown_terminate)"," block_device_mapping): num_instances, i) reservation_id=None, scheduler_hints=None): block_device_mapping) block_device_mapping): image_properties = image.get('properties', {}) if (block_device_mapping or image_properties.get('mappings') or image_properties.get('block_device_mapping')): index): block_device_mapping) auto_disk_config=None, scheduler_hints=None): scheduler_hints=scheduler_hints)",48,20
openstack%2Fnova~master~I1f83b4b584d36aa6f894180d43aee24f096b4f78,openstack/nova,master,I1f83b4b584d36aa6f894180d43aee24f096b4f78,Remove useless check in _add_retry_host,MERGED,2014-06-06 07:11:17.000000000,2014-08-08 22:38:22.000000000,2014-08-05 02:59:27.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 642}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 7166}, {'_account_id': 7494}, {'_account_id': 7641}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-06 07:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93cef15fff1bae78613a2ce79c43b6ff01c804d6', 'message': 'Remove useless check in _add_retry_host\n\nIn populate_retry, the code already check the case with force_hosts\nand force_nodes. So the check in _add_retry_host is useless.\n\nChange-Id: I1f83b4b584d36aa6f894180d43aee24f096b4f78\n'}, {'number': 2, 'created': '2014-06-06 08:44:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2897aa02537fa41b980041604141eda89afe0c23', 'message': 'Remove useless check in _add_retry_host\n\nIn populate_retry, the code already check the case with force_hosts\nand force_nodes. So the check in _add_retry_host is useless.\n\nChange-Id: I1f83b4b584d36aa6f894180d43aee24f096b4f78\n'}, {'number': 3, 'created': '2014-06-07 02:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/123d81769fb2c0168d0b2673834a562ea807c6fa', 'message': 'Remove useless check in _add_retry_host\n\nIn populate_retry, the code already check the case with force_hosts\nand force_nodes. So the check in _add_retry_host is useless.\n\nChange-Id: I1f83b4b584d36aa6f894180d43aee24f096b4f78\n'}, {'number': 4, 'created': '2014-06-10 07:22:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c1c31c8a2c7b8c77bc1c314df95c4168854612d7', 'message': 'Remove useless check in _add_retry_host\n\nIn populate_retry, the code already check the case with force_hosts\nand force_nodes. So the check in _add_retry_host is useless.\n\nChange-Id: I1f83b4b584d36aa6f894180d43aee24f096b4f78\n'}, {'number': 5, 'created': '2014-06-10 13:21:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/808e64d5b969588c39e7baede5926a26dbe899f7', 'message': 'Remove useless check in _add_retry_host\n\nIn populate_retry, the code already check the case with force_hosts\nand force_nodes. So the check in _add_retry_host is useless.\n\nChange-Id: I1f83b4b584d36aa6f894180d43aee24f096b4f78\n'}, {'number': 6, 'created': '2014-07-23 02:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/75d202bca88f6514bb258bcf37e9e2a8b284f9c7', 'message': 'Remove useless check in _add_retry_host\n\nIn populate_retry, the code already check the case with force_hosts\nand force_nodes. So the checking in _add_retry_host is useless.\n\nChange-Id: I1f83b4b584d36aa6f894180d43aee24f096b4f78\n'}, {'number': 7, 'created': '2014-07-25 10:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/085c06eea93c0e3df7d642b95a389b2e8ef671d3', 'message': 'Remove useless check in _add_retry_host\n\nIn populate_retry, the code already check the case with force_hosts\nand force_nodes. So the checking in _add_retry_host is useless.\n\nChange-Id: I1f83b4b584d36aa6f894180d43aee24f096b4f78\n'}, {'number': 8, 'created': '2014-07-29 01:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a5098dbae523415fd3b5be58168d300328761e9', 'message': ""Remove useless check in _add_retry_host\n\nIn populate_retry, the code already check the case with force_hosts\nand force_nodes. (https://github.com/openstack/nova/blob/418398dcca5\n52497c8488dbbf54a06e21202b295/nova/scheduler/utils.py#L134)\nIf the retry is disable, populate_retry won't add retry info into\nfilter_properties.\n\n_add_retry_host is called later than populate_retry. It also check\nthe force_hosts and force_nodes, that is useless. (https://github.com\n/openstack/nova/blob/418398dcca552497c8488dbbf54a06e21202b295/nova/\nscheduler/utils.py#L193) It only check whether retry info exist in\nfilter_properties or not.\n\nChange-Id: I1f83b4b584d36aa6f894180d43aee24f096b4f78\n""}, {'number': 9, 'created': '2014-07-29 01:46:49.000000000', 'files': ['nova/scheduler/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/83275a61caed11b521e87c80f59f913474146441', 'message': ""Remove useless check in _add_retry_host\n\nIn populate_retry, the code already check the case with force_hosts\nand force_nodes. (https://github.com/openstack/nova/blob/418398dcca5\n52497c8488dbbf54a06e21202b295/nova/scheduler/utils.py#L134)\nIf the retry is disable, populate_retry won't add retry info into\nfilter_properties.\n\n_add_retry_host is called later than populate_retry. It also check\nthe force_hosts and force_nodes, that is useless. (https://github.com\n/openstack/nova/blob/418398dcca552497c8488dbbf54a06e21202b295/nova/\nscheduler/utils.py#L193) It only need check whether retry info exist\nin filter_properties or not.\n\nChange-Id: I1f83b4b584d36aa6f894180d43aee24f096b4f78\n""}]",4,98310,83275a61caed11b521e87c80f59f913474146441,98,16,9,5754,,,0,"Remove useless check in _add_retry_host

In populate_retry, the code already check the case with force_hosts
and force_nodes. (https://github.com/openstack/nova/blob/418398dcca5
52497c8488dbbf54a06e21202b295/nova/scheduler/utils.py#L134)
If the retry is disable, populate_retry won't add retry info into
filter_properties.

_add_retry_host is called later than populate_retry. It also check
the force_hosts and force_nodes, that is useless. (https://github.com
/openstack/nova/blob/418398dcca552497c8488dbbf54a06e21202b295/nova/
scheduler/utils.py#L193) It only need check whether retry info exist
in filter_properties or not.

Change-Id: I1f83b4b584d36aa6f894180d43aee24f096b4f78
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/98310/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/utils.py'],1,93cef15fff1bae78613a2ce79c43b6ff01c804d6,(detached, if not retry:," force_hosts = filter_properties.get('force_hosts', []) force_nodes = filter_properties.get('force_nodes', []) if not retry or force_hosts or force_nodes:",1,3
openstack%2Fheat-specs~master~I7672def06ad428b73e7642bbe79e66f64e76f845,openstack/heat-specs,master,I7672def06ad428b73e7642bbe79e66f64e76f845,Display stack owner information with the stacks,MERGED,2014-06-23 18:04:15.000000000,2014-08-08 22:35:43.000000000,2014-08-08 22:35:42.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7193}, {'_account_id': 7230}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 8246}, {'_account_id': 9189}]","[{'number': 1, 'created': '2014-06-23 18:04:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/7c0771c1db812531ddefb80d9ceb5414c7bf7767', 'message': 'Display username in unscoped stack lists\n\nIt is helpful to display the usernames of the stack owners in an\nunscoped stack list to be able to more easily identify customers in such\nlists.\n\nChange-Id: I7672def06ad428b73e7642bbe79e66f64e76f845\n'}, {'number': 2, 'created': '2014-07-09 17:21:17.000000000', 'files': ['specs/stack-display-fields.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/11c3ded6ff68eff90dc33883c393e35e0da037ef', 'message': 'Display stack owner information with the stacks\n\nIt is helpful to display more detailed stack owner information with\nstacks to be able to more easily identify customers in such lists.\n\nChange-Id: I7672def06ad428b73e7642bbe79e66f64e76f845\n'}]",8,101968,11c3ded6ff68eff90dc33883c393e35e0da037ef,24,10,2,9189,,,0,"Display stack owner information with the stacks

It is helpful to display more detailed stack owner information with
stacks to be able to more easily identify customers in such lists.

Change-Id: I7672def06ad428b73e7642bbe79e66f64e76f845
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/68/101968/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/global-tenant-username.rst'],1,7c0771c1db812531ddefb80d9ceb5414c7bf7767,stack-display-fields,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/heat/+spec/awesome-thing should be named awesome-thing.rst . Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html =============================================================== Display the username of the stack owner in unscoped stack lists =============================================================== https://blueprints.launchpad.net/heat/+spec/global-tenant-username When trying to support stacks using unscoped lists, the list only contains the tenant ID associated with each stack. Since humans are much better with names than they are with numbers, it would be great if this list also contained the username of the tenant as well. Problem description =================== When listing unscoped stacks (with the flag ``global_tenant=True``), all stacks are returned, regardless of the tenant who owns them. This list contains information about the stacks, including some info about the stack owner (namely, the Tenant ID). This is helpful for cloud providers to be able to more easily support their customers. However, humans are better at dealing with names than with numbers, so returning just the Tenant ID is not ideal. In order to make it possible for supporters to eaily identify their clients, it would be a great feature to also include the username of the stack owners in the stack information returned in a ``global_tenant`` call. Proposed change =============== The proposed implementation would add the extra information when formatting a stack to display in a ``global_tenant`` call. Currently, the username is already saved to the database but not parsed back into the stack when loaded from the DB. This would parse it back from the DB into the stack at all times, but only exposed to the API response when formatting stacks to a ``global_tenant`` call:: { ""stacks"": [ { ""creation_time"": ""..."", ""description"": ""..."", ""id"": ""..."", ""links"": [...], ""project"": ""TENANT_ID"", ""username"": ""USERNAME"", // This is the only change ""stack_name"": ""..."", ""stack_status"": ""..."", ""stack_status_reason"": ""..."", ""updated_time"": ""..."" } ] } The necessary changes will primarily reside in: * heat.api.openstack.v1.views.stacks_view.py * heat.engine.api.py * heat.engine.parser.py * heat.engine.service.py * heat.rpc.api.py Alternatives ------------ If it makes sense, the username can be included at all times, given that in the next version of the API, when domains are fully supported, the stack list will possibly contain stacks from a tenant other than the one making the call. Implementation ============== Assignee(s) ----------- Primary assignees: * rblee88 * andersonvom Milestones ---------- Target Milestone for completion: Juno-2 Work Items ---------- * Read username into the Stack back from the DB * Display username on ``global_tenant`` calls Dependencies ============ None ",,118,0
openstack%2Fkeystone~master~Ic447056d8572d8d444e5199e7bd63e2f7f7ce97b,openstack/keystone,master,Ic447056d8572d8d444e5199e7bd63e2f7f7ce97b,Refactor names in catalog backends,MERGED,2014-08-06 18:35:34.000000000,2014-08-08 22:24:19.000000000,2014-08-08 22:24:18.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 9751}, {'_account_id': 10873}, {'_account_id': 11387}]","[{'number': 1, 'created': '2014-08-06 18:35:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1f4b39d1603d6f0210fb8e28e5b33da17fdcf247', 'message': 'Refactor some names in templated catalog backend\n\nChange-Id: Ic447056d8572d8d444e5199e7bd63e2f7f7ce97b\n'}, {'number': 2, 'created': '2014-08-07 23:43:49.000000000', 'files': ['keystone/catalog/backends/templated.py', 'keystone/catalog/backends/sql.py', 'keystone/catalog/core.py', 'keystone/contrib/endpoint_filter/backends/catalog_sql.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/a96158a2dbec620c69c71c37248a5729982e050d', 'message': 'Refactor names in catalog backends\n\nChange-Id: Ic447056d8572d8d444e5199e7bd63e2f7f7ce97b\n'}]",2,112377,a96158a2dbec620c69c71c37248a5729982e050d,24,9,2,7725,,,0,"Refactor names in catalog backends

Change-Id: Ic447056d8572d8d444e5199e7bd63e2f7f7ce97b
",git fetch https://review.opendev.org/openstack/keystone refs/changes/77/112377/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/catalog/backends/templated.py'],1,1f4b39d1603d6f0210fb8e28e5b33da17fdcf247,catalog-refactor," context = dict(six.iteritems(CONF)) context.update({'tenant_id': tenant_id, 'user_id': user_id}) catalog = {} for region, region_ref in six.iteritems(self.templates): catalog[region] = {} service_data[k] = core.format_url(v, context) catalog[region][service] = service_data return catalog"," d = dict(six.iteritems(CONF)) d.update({'tenant_id': tenant_id, 'user_id': user_id}) o = {} for region, region_ref in six.iteritems(self.templates): o[region] = {} service_data[k] = core.format_url(v, d) o[region][service] = service_data return o",7,8
openstack%2Ftempest~master~I2f5da22b5f1bbd3910e4226b96e73106aa75c65a,openstack/tempest,master,I2f5da22b5f1bbd3910e4226b96e73106aa75c65a,"Update compute attach tests to use ""volume_device_name""",MERGED,2014-07-21 21:16:11.000000000,2014-08-08 22:24:11.000000000,2014-08-08 22:24:10.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8302}, {'_account_id': 8556}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-21 21:16:11.000000000', 'files': ['tempest/api/compute/v3/servers/test_server_rescue_negative.py', 'tempest/api/compute/servers/test_server_rescue_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/92a6f4d4e8011f6f75d3df81bcc269fdd1d7ae13', 'message': 'Update compute attach tests to use ""volume_device_name""\n\nSome attach tests in the compute suites are using hard-coded\nvalues for the volume device name. These should be replaced\nwith the compute.volume_device_name in tempest.conf.\n\nChange-Id: I2f5da22b5f1bbd3910e4226b96e73106aa75c65a\n'}]",0,108498,92a6f4d4e8011f6f75d3df81bcc269fdd1d7ae13,24,8,1,8302,,,0,"Update compute attach tests to use ""volume_device_name""

Some attach tests in the compute suites are using hard-coded
values for the volume device name. These should be replaced
with the compute.volume_device_name in tempest.conf.

Change-Id: I2f5da22b5f1bbd3910e4226b96e73106aa75c65a
",git fetch https://review.opendev.org/openstack/tempest refs/changes/98/108498/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/v3/servers/test_server_rescue_negative.py', 'tempest/api/compute/servers/test_server_rescue_negative.py']",2,92a6f4d4e8011f6f75d3df81bcc269fdd1d7ae13,, cls.device = CONF.compute.volume_device_name, cls.device = 'vdf',2,2
openstack%2Frally~master~I371db495da0b14ddaa8e9473dd559880d4990752,openstack/rally,master,I371db495da0b14ddaa8e9473dd559880d4990752,Fix copyright in doc/source/config.py,MERGED,2014-08-08 18:00:17.000000000,2014-08-08 22:17:08.000000000,2014-08-08 22:17:08.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-08-08 18:00:17.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/d06f7c01ca8228cb0534b77e387b87bf222393b7', 'message': 'Fix copyright in doc/source/config.py\n\nMirantis is raplaced by OpenStack Foundation\n\nhttps://trello.com/c/RdKHZqlq\n\nChange-Id: I371db495da0b14ddaa8e9473dd559880d4990752\n'}]",0,112987,d06f7c01ca8228cb0534b77e387b87bf222393b7,13,3,1,11105,,,0,"Fix copyright in doc/source/config.py

Mirantis is raplaced by OpenStack Foundation

https://trello.com/c/RdKHZqlq

Change-Id: I371db495da0b14ddaa8e9473dd559880d4990752
",git fetch https://review.opendev.org/openstack/rally refs/changes/87/112987/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,d06f7c01ca8228cb0534b77e387b87bf222393b7,trelloRdKHZqlq,"copyright = u'%d, OpenStack Foundation' % datetime.datetime.now().year","copyright = u'%d, Mirantis Inc.' % datetime.datetime.now().year",1,1
openstack%2Fnova~master~Iec02d4a5906a5851c1e9c8258a2d77f908ec65bc,openstack/nova,master,Iec02d4a5906a5851c1e9c8258a2d77f908ec65bc,Add unit tests to cells conductor link,MERGED,2014-07-25 21:05:30.000000000,2014-08-08 22:16:11.000000000,2014-08-08 22:16:09.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 8412}, {'_account_id': 8430}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-25 21:05:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/37439382b9783ed911226da2e5cd7e6836cf519a', 'message': ""Add unit tests to cells conductor link\n\nAdding unit tests to verify ConductorTaskRPCAPIRedirect\nand compute/api.py are properly hooked.  If they become out\nof alignment then calls can be potentially ignored.  We can't\nblindly error in the case of ignoring as this is used\nlegitimately in other cases.\n\nChange-Id: Iec02d4a5906a5851c1e9c8258a2d77f908ec65bc\nPartial-Bug: 1348642\n""}, {'number': 2, 'created': '2014-07-28 19:10:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/99d711d984861efd1ed4863784437a54ef529394', 'message': ""Add unit tests to cells conductor link\n\nAdding unit tests to verify ConductorTaskRPCAPIRedirect\nand compute/api.py are properly hooked.  If they become out\nof alignment then calls can be potentially ignored.  We can't\nblindly error in the case of ignoring as this is used\nlegitimately in other cases.\n\nChange-Id: Iec02d4a5906a5851c1e9c8258a2d77f908ec65bc\nPartial-Bug: 1348642\n""}, {'number': 3, 'created': '2014-07-30 23:31:16.000000000', 'files': ['nova/tests/compute/test_compute_cells.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cf024616111aab8c5f9dfdb350ab9cdff0633f91', 'message': ""Add unit tests to cells conductor link\n\nAdding unit tests to verify ConductorTaskRPCAPIRedirect\nand compute/api.py are properly hooked.  If they become out\nof alignment then calls can be potentially ignored.  We can't\nblindly error in the case of ignoring as this is used\nlegitimately in other cases.\n\nChange-Id: Iec02d4a5906a5851c1e9c8258a2d77f908ec65bc\nPartial-Bug: 1348642\n""}]",5,109730,cf024616111aab8c5f9dfdb350ab9cdff0633f91,33,8,3,8430,,,0,"Add unit tests to cells conductor link

Adding unit tests to verify ConductorTaskRPCAPIRedirect
and compute/api.py are properly hooked.  If they become out
of alignment then calls can be potentially ignored.  We can't
blindly error in the case of ignoring as this is used
legitimately in other cases.

Change-Id: Iec02d4a5906a5851c1e9c8258a2d77f908ec65bc
Partial-Bug: 1348642
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/109730/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/compute/test_compute_cells.py'],1,37439382b9783ed911226da2e5cd7e6836cf519a,bug/1348642,"import inspectfrom nova.compute import flavors from nova.compute import vm_states from nova import contextfrom nova import objects from nova.openstack.common import timeutilsfrom nova import testfrom nova.tests import fake_instanceclass CellsConductorAPIRPCRedirect(test.NoDBTestCase): def setUp(self): super(CellsConductorAPIRPCRedirect, self).setUp() self.compute_api = compute_cells_api.ComputeCellsAPI() self.cells_rpcapi = mock.MagicMock() self.compute_api._compute_task_api.cells_rpcapi = self.cells_rpcapi self.context = context.RequestContext('fake', 'fake') @mock.patch.object(compute_api.API, '_record_action_start') @mock.patch.object(compute_api.API, '_provision_instances') @mock.patch.object(compute_api.API, '_check_and_transform_bdm') @mock.patch.object(compute_api.API, '_get_image') @mock.patch.object(compute_api.API, '_validate_and_build_base_options') def test_build_instances(self, _validate, _get_image, _check_bdm, _provision, _record_action_start): _get_image.return_value = (None, 'fake-image') _validate.return_value = (None, 1) _check_bdm.return_value = 'bdms' _provision.return_value = 'instances' self.compute_api.create(self.context, 'fake-flavor', 'fake-image') self.assertTrue(self.cells_rpcapi.build_instances.called) @mock.patch.object(compute_api.API, '_record_action_start') @mock.patch.object(compute_api.API, '_resize_cells_support') @mock.patch.object(compute_api.API, '_reserve_quota_delta') @mock.patch.object(compute_api.API, '_upsize_quota_delta') @mock.patch.object(objects.Instance, 'save') @mock.patch.object(flavors, 'extract_flavor') @mock.patch.object(compute_api.API, '_check_auto_disk_config') def test_resize_instance(self, _check, _extract, _save, _upsize, _reserve, _cells, _record): _extract.return_value = {'name': 'fake', 'id': 'fake'} orig_system_metadata = {} instance = fake_instance.fake_instance_obj(self.context, vm_state=vm_states.ACTIVE, cell_name='fake-cell', launched_at=timeutils.utcnow(), system_metadata=orig_system_metadata, expected_attrs=['system_metadata']) self.compute_api.resize(self.context, instance) self.assertTrue(self.cells_rpcapi.resize_instance.called) @mock.patch.object(objects.Instance, 'save') def test_live_migrate_instance(self, instance_save): orig_system_metadata = {} instance = fake_instance.fake_instance_obj(self.context, vm_state=vm_states.ACTIVE, cell_name='fake-cell', launched_at=timeutils.utcnow(), system_metadata=orig_system_metadata, expected_attrs=['system_metadata']) self.compute_api.live_migrate(self.context, instance, True, True, 'fake_dest_host') self.assertTrue(self.cells_rpcapi.live_migrate_instance.called) def test_check_equal(self): task_api = self.compute_api.compute_task_api tests = set() for (name, value) in inspect.getmembers(self, inspect.ismethod): if name.startswith('test_') and name != 'test_check_equal': tests.add(name[5:]) if tests != set(task_api.cells_compatible): self.fail(""Testcases not equivalent to cells_compatible list"") ",,78,0
openstack%2Fpycadf~master~Icfab2820f9f4282fd07e7ce4152142f5bbd476e2,openstack/pycadf,master,Icfab2820f9f4282fd07e7ce4152142f5bbd476e2,Fix typo comments,MERGED,2014-07-23 05:02:35.000000000,2014-08-08 22:03:28.000000000,2014-08-08 22:03:28.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6537}, {'_account_id': 6928}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-07-23 05:02:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/bc1bb70853bd431efb5f586e8599256a62fd8e97', 'message': 'Fix typo comments is pycadf\n\nWhile looking at the pycadf source I notice some typos in\na few of the comments.  So I went ahead and fixed them\n\nChange-Id: Icfab2820f9f4282fd07e7ce4152142f5bbd476e2\n'}, {'number': 2, 'created': '2014-07-23 05:03:59.000000000', 'files': ['pycadf/middleware/audit.py', 'pycadf/eventfactory.py'], 'web_link': 'https://opendev.org/openstack/pycadf/commit/9e5ce3dcdabf1d2b5f4f1ecf5bd4d43f1295f3ce', 'message': 'Fix typo comments\n\nWhile looking at the pycadf source I notice some typos in\na few of the comments.  So I went ahead and fixed them\n\nChange-Id: Icfab2820f9f4282fd07e7ce4152142f5bbd476e2\n'}]",1,108889,9e5ce3dcdabf1d2b5f4f1ecf5bd4d43f1295f3ce,19,5,2,6460,,,0,"Fix typo comments

While looking at the pycadf source I notice some typos in
a few of the comments.  So I went ahead and fixed them

Change-Id: Icfab2820f9f4282fd07e7ce4152142f5bbd476e2
",git fetch https://review.opendev.org/openstack/pycadf refs/changes/89/108889/1 && git format-patch -1 --stdout FETCH_HEAD,"['pycadf/middleware/audit.py', 'pycadf/eventfactory.py']",2,bc1bb70853bd431efb5f586e8599256a62fd8e97,typos_1, :param eventType: eventType of event. Defaults to 'activity', :param eventType: eventType of event. Defaults to 'activitiy',3,3
openstack%2Fkeystone~master~I04817c992fe66d4937960a3e5dedb954606a4334,openstack/keystone,master,I04817c992fe66d4937960a3e5dedb954606a4334,Ensure roles created by unit tests have correct attributes.,MERGED,2014-08-08 16:19:40.000000000,2014-08-08 22:03:20.000000000,2014-08-08 22:03:19.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6482}, {'_account_id': 11333}]","[{'number': 1, 'created': '2014-08-08 16:19:40.000000000', 'files': ['keystone/tests/test_v3.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/5b2475807ef383655e7e4afe234eb2f8b72c2487', 'message': 'Ensure roles created by unit tests have correct attributes.\n\nChange-Id: I04817c992fe66d4937960a3e5dedb954606a4334\nCloses-bug: 1354417\n'}]",0,112965,5b2475807ef383655e7e4afe234eb2f8b72c2487,10,4,1,5707,,,0,"Ensure roles created by unit tests have correct attributes.

Change-Id: I04817c992fe66d4937960a3e5dedb954606a4334
Closes-bug: 1354417
",git fetch https://review.opendev.org/openstack/keystone refs/changes/65/112965/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/test_v3.py'],1,5b2475807ef383655e7e4afe234eb2f8b72c2487,bug/1354417," # Roles don't have a description or the enabled flag del ref['description'] del ref['enabled'] self.assertValidEntity(role, keys_to_check=['name'])", self.assertValidEntity(role),4,1
openstack%2Fkeystone~master~Ifcc43dcccaa9d56e03922ce8cf0bf7fb8e93bdcc,openstack/keystone,master,Ifcc43dcccaa9d56e03922ce8cf0bf7fb8e93bdcc,Update control_exchange value in keystone.conf,MERGED,2014-08-01 06:19:10.000000000,2014-08-08 22:03:12.000000000,2014-08-08 22:03:11.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 11333}, {'_account_id': 11387}]","[{'number': 1, 'created': '2014-08-01 06:19:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8fdd7c42816b0cdbcebd95e328836ba4d5dcdbed', 'message': ""Update control_exchange value in keystone.conf\n\nThe control_exchange comes from oslo and is set to 'openstack' by\ndefault. This should be overridden by the projects that use\noslo messaging, since projects should be placing notifications\non project specific exchanges.\n\nChange-Id: Ifcc43dcccaa9d56e03922ce8cf0bf7fb8e93bdcc\n""}, {'number': 2, 'created': '2014-08-01 14:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8dbdb45f4ea6fde5f34d00bf8207f8154a5f3b76', 'message': ""Update control_exchange value in keystone.conf\n\nThe control_exchange comes from oslo and is set to 'openstack' by\ndefault. This should be overridden by the projects that use\noslo messaging, since projects should be placing notifications\non project specific exchanges.\n\nNova performs the override in the same manner:\nhttps://github.com/openstack/nova/blob/master/nova/config.py#L33\nhttps://github.com/openstack/nova/blob/master/nova/rpc.py#L77\n\nChange-Id: Ifcc43dcccaa9d56e03922ce8cf0bf7fb8e93bdcc\n""}, {'number': 3, 'created': '2014-08-01 15:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6e8d1b2ad086025371426a54fd7e9945d00f9771', 'message': ""Update control_exchange value in keystone.conf\n\nThe control_exchange comes from oslo and is set to 'openstack' by\ndefault. This should be overridden by the projects that use\noslo messaging, since projects should be placing notifications\non project specific exchanges.\n\nNova performs the override in the same manner:\nhttps://github.com/openstack/nova/blob/master/nova/config.py#L33\nhttps://github.com/openstack/nova/blob/master/nova/rpc.py#L77\n\nChange-Id: Ifcc43dcccaa9d56e03922ce8cf0bf7fb8e93bdcc\n""}, {'number': 4, 'created': '2014-08-02 07:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a55ecbde771cd0ba49c1408f681a777ff29630c8', 'message': ""Update control_exchange value in keystone.conf\n\nThe control_exchange comes from oslo and is set to 'openstack' by\ndefault. This should be overridden by the projects that use\noslo.messaging, since projects should be placing notifications\non project specific exchanges.\n\nNova performs the override in the same manner:\nhttps://github.com/openstack/nova/blob/master/nova/config.py#L33\nhttps://github.com/openstack/nova/blob/master/nova/rpc.py#L77\n\nChange-Id: Ifcc43dcccaa9d56e03922ce8cf0bf7fb8e93bdcc\n""}, {'number': 5, 'created': '2014-08-08 15:47:29.000000000', 'files': ['etc/keystone.conf.sample', 'keystone/common/config.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/87bf6822b56ca56cf1913be147f644c7b405a069', 'message': ""Update control_exchange value in keystone.conf\n\nThe control_exchange comes from oslo and is set to 'openstack' by\ndefault. This should be overridden by the projects that use\noslo.messaging, since projects should be placing notifications\non project specific exchanges.\n\nNova performs the override in the same manner:\nhttps://github.com/openstack/nova/blob/master/nova/config.py#L33\nhttps://github.com/openstack/nova/blob/master/nova/rpc.py#L77\n\nChange-Id: Ifcc43dcccaa9d56e03922ce8cf0bf7fb8e93bdcc\n""}]",2,111170,87bf6822b56ca56cf1913be147f644c7b405a069,38,15,5,6482,,,0,"Update control_exchange value in keystone.conf

The control_exchange comes from oslo and is set to 'openstack' by
default. This should be overridden by the projects that use
oslo.messaging, since projects should be placing notifications
on project specific exchanges.

Nova performs the override in the same manner:
https://github.com/openstack/nova/blob/master/nova/config.py#L33
https://github.com/openstack/nova/blob/master/nova/rpc.py#L77

Change-Id: Ifcc43dcccaa9d56e03922ce8cf0bf7fb8e93bdcc
",git fetch https://review.opendev.org/openstack/keystone refs/changes/70/111170/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/keystone.conf.sample', 'keystone/common/config.py']",2,8fdd7c42816b0cdbcebd95e328836ba4d5dcdbed,bk,from oslo import messagingmessaging.set_transport_defaults('keystone'),,3,1
openstack%2Frequirements~master~I35d74f13af9c5cac936bf711e4d2f646531eae60,openstack/requirements,master,I35d74f13af9c5cac936bf711e4d2f646531eae60,Include tempurls in python-swiftclient,MERGED,2014-07-22 17:04:16.000000000,2014-08-08 22:03:08.000000000,2014-08-08 22:03:08.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 7680}, {'_account_id': 10342}, {'_account_id': 10343}]","[{'number': 1, 'created': '2014-07-22 17:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/497dd0ccb905d3cee461bda2f95c8da199129d74', 'message': 'Include tempurls in python-swiftclient\n\npython-swiftclient 2.2.0 adds support for tempurls, which is a blocker for\nthe new (aiming for default) Ironic driver using the Ironic Python Agent.\nThe Agent needs a temporary URL generated for a Glance image to avoid\npassing around admin auth tokens to every machine that is being deployed\nto.\n\nChange-Id: I35d74f13af9c5cac936bf711e4d2f646531eae60\n'}, {'number': 2, 'created': '2014-07-22 17:10:42.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/994f8354d0510b52ab18a6bc28b02f064134b7ec', 'message': 'Include tempurls in python-swiftclient\n\npython-swiftclient 2.2.0 adds support for tempurls, which is a blocker for\nthe new (aiming for default) Ironic driver using the Ironic Python Agent.\nThe Agent needs a temporary URL generated for a Glance image to avoid\npassing around admin auth tokens to every machine that is being deployed\nto.\n\nBlocked Ironic patch: https://review.openstack.org/#/c/81391/\n\nChange-Id: I35d74f13af9c5cac936bf711e4d2f646531eae60\n'}]",0,108775,994f8354d0510b52ab18a6bc28b02f064134b7ec,18,5,2,10380,,,0,"Include tempurls in python-swiftclient

python-swiftclient 2.2.0 adds support for tempurls, which is a blocker for
the new (aiming for default) Ironic driver using the Ironic Python Agent.
The Agent needs a temporary URL generated for a Glance image to avoid
passing around admin auth tokens to every machine that is being deployed
to.

Blocked Ironic patch: https://review.openstack.org/#/c/81391/

Change-Id: I35d74f13af9c5cac936bf711e4d2f646531eae60
",git fetch https://review.opendev.org/openstack/requirements refs/changes/75/108775/2 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,497dd0ccb905d3cee461bda2f95c8da199129d74,,python-swiftclient>=2.2.0,python-swiftclient>=2.0.2,1,1
openstack%2Frally~master~I055962487732a47d25abf629965c5a479a55df7e,openstack/rally,master,I055962487732a47d25abf629965c5a479a55df7e,changed image name for nova test,ABANDONED,2014-08-08 18:14:59.000000000,2014-08-08 22:00:48.000000000,,"[{'_account_id': 3}, {'_account_id': 6172}]","[{'number': 1, 'created': '2014-08-08 18:14:59.000000000', 'files': ['rally-scenarios/rally-neutron.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/60363edd1668466d5ff26836c772303e6c0081a8', 'message': 'changed image name for nova test\n\nChange-Id: I055962487732a47d25abf629965c5a479a55df7e\n'}]",1,112989,60363edd1668466d5ff26836c772303e6c0081a8,5,2,1,12722,,,0,"changed image name for nova test

Change-Id: I055962487732a47d25abf629965c5a479a55df7e
",git fetch https://review.opendev.org/openstack/rally refs/changes/89/112989/1 && git format-patch -1 --stdout FETCH_HEAD,['rally-scenarios/rally-neutron.yaml'],1,60363edd1668466d5ff26836c772303e6c0081a8,neutron_yaml_modification," sla: max_failure_percent: 0 NovaServers.boot_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.boot_and_delete_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.boot_and_list_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" detailed: True runner: type: ""constant"" times: 1 concurrency: 1 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 NovaServers.boot_and_bounce_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" actions: - hard_reboot: 1 - soft_reboot: 1 - stop_start: 1 - rescue_unrescue: 1 runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.boot_server_from_volume_and_delete: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" volume_size: 10 runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.boot_server_from_volume: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" volume_size: 10 runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.snapshot_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.resize_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" to_flavor: name: ""m1.small"" confirm: true runner: type: ""constant"" times: 10 concurrency: 5 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0",,161,0
openstack%2Fnova~master~Iead5235c739f2029609788f2331a49d0d30d5795,openstack/nova,master,Iead5235c739f2029609788f2331a49d0d30d5795,"Revert ""Increase min required libvirt to 0.9.11""",ABANDONED,2014-07-30 20:19:58.000000000,2014-08-08 21:53:57.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 4146}, {'_account_id': 5170}, {'_account_id': 5263}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-30 20:19:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5a12b2a5f03de878f916a9c145b0e1cf826b1aaf', 'message': 'Revert ""Increase min required libvirt to 0.9.11""\n\nThis reverts commit 842b2abfe76dede55b3b61ebaad5a90c356c5ace.\n\nThis patch along with I2890702869f05a02ad5e2ecb419db06433231b36 broke\nMinesweeper along with several folks who don\'t have a new enough\nlibvirt. Revert the change before this causes pain for more people.\n\nA change like this should go through a standard deprecation cycle with a\nwarning instead of just dropping support and forcing people to upgrade\nlibvirt.\n\nChange-Id: Iead5235c739f2029609788f2331a49d0d30d5795\n'}, {'number': 2, 'created': '2014-08-07 16:46:36.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/vif.py', 'nova/tests/virt/libvirt/test_vif.py', 'nova/tests/virt/libvirt/fakelibvirt.py', 'nova/tests/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/48fb20dcf3d0e24d26bdf6d9cfac427e43f92ffa', 'message': 'Revert ""Increase min required libvirt to 0.9.11""\n\nThis reverts commit 842b2abfe76dede55b3b61ebaad5a90c356c5ace.\n\nThis patch broke Minesweeper along with several folks who don\'t have a new\nenough libvirt. Minesweeper broke because it is running with libvirt 0.9.8 on\nubuntu 12.04, which this patch breaks. Revert the change before this causes\npain for more people.\n\nLeaves the libvirt test-requirements bump from Ibe8d2117e1246e4097d1bedeadcd6d99618f8400\n\nA change like this should go through a standard deprecation cycle with a\nwarning instead of just dropping support and forcing people to upgrade\nlibvirt.\n\nChange-Id: Iead5235c739f2029609788f2331a49d0d30d5795\n'}]",0,110774,48fb20dcf3d0e24d26bdf6d9cfac427e43f92ffa,22,11,2,1849,,,0,"Revert ""Increase min required libvirt to 0.9.11""

This reverts commit 842b2abfe76dede55b3b61ebaad5a90c356c5ace.

This patch broke Minesweeper along with several folks who don't have a new
enough libvirt. Minesweeper broke because it is running with libvirt 0.9.8 on
ubuntu 12.04, which this patch breaks. Revert the change before this causes
pain for more people.

Leaves the libvirt test-requirements bump from Ibe8d2117e1246e4097d1bedeadcd6d99618f8400

A change like this should go through a standard deprecation cycle with a
warning instead of just dropping support and forcing people to upgrade
libvirt.

Change-Id: Iead5235c739f2029609788f2331a49d0d30d5795
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/110774/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/virt/libvirt/test_vif.py', 'nova/virt/libvirt/vif.py', 'nova/tests/virt/libvirt/fakelibvirt.py', 'nova/tests/virt/libvirt/test_driver.py']",5,5a12b2a5f03de878f916a9c145b0e1cf826b1aaf,revert," def test_get_guest_cpu_config_host_passthrough_new(self): def get_lib_version_stub(): return (0 * 1000 * 1000) + (9 * 1000) + 11 self.stubs.Set(self.conn, ""getLibVersion"", get_lib_version_stub) def test_get_guest_cpu_config_host_model_new(self): def get_lib_version_stub(): return (0 * 1000 * 1000) + (9 * 1000) + 11 self.stubs.Set(self.conn, ""getLibVersion"", get_lib_version_stub) def test_get_guest_cpu_config_custom_new(self): def get_lib_version_stub(): return (0 * 1000 * 1000) + (9 * 1000) + 11 self.stubs.Set(self.conn, ""getLibVersion"", get_lib_version_stub) def test_get_guest_cpu_config_host_passthrough_old(self): def get_lib_version_stub(): return (0 * 1000 * 1000) + (9 * 1000) + 7 self.stubs.Set(self.conn, ""getLibVersion"", get_lib_version_stub) conn = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) instance_ref = db.instance_create(self.context, self.test_instance) self.flags(cpu_mode=""host-passthrough"", group='libvirt') disk_info = blockinfo.get_disk_info(CONF.libvirt.virt_type, instance_ref) self.assertRaises(exception.NovaException, conn._get_guest_config, instance_ref, _fake_network_info(self.stubs, 1), {}, disk_info) def test_get_guest_cpu_config_host_model_old(self): def get_lib_version_stub(): return (0 * 1000 * 1000) + (9 * 1000) + 7 # Ensure we have a predictable host CPU def get_host_capabilities_stub(self): cpu = vconfig.LibvirtConfigGuestCPU() cpu.model = ""Opteron_G4"" cpu.vendor = ""AMD"" cpu.add_feature(vconfig.LibvirtConfigGuestCPUFeature(""tm2"")) cpu.add_feature(vconfig.LibvirtConfigGuestCPUFeature(""ht"")) caps = vconfig.LibvirtConfigCaps() caps.host = vconfig.LibvirtConfigCapsHost() caps.host.cpu = cpu return caps self.stubs.Set(self.conn, ""getLibVersion"", get_lib_version_stub) self.stubs.Set(libvirt_driver.LibvirtDriver, ""_get_host_capabilities"", get_host_capabilities_stub) conn = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) instance_ref = db.instance_create(self.context, self.test_instance) self.flags(cpu_mode=""host-model"", group='libvirt') disk_info = blockinfo.get_disk_info(CONF.libvirt.virt_type, instance_ref) conf = conn._get_guest_config(instance_ref, _fake_network_info(self.stubs, 1), {}, disk_info) self.assertIsInstance(conf.cpu, vconfig.LibvirtConfigGuestCPU) self.assertIsNone(conf.cpu.mode) self.assertEqual(conf.cpu.model, ""Opteron_G4"") self.assertEqual(conf.cpu.vendor, ""AMD"") self.assertEqual(len(conf.cpu.features), 2) self.assertEqual(conf.cpu.features.pop().name, ""tm2"") self.assertEqual(conf.cpu.features.pop().name, ""ht"") self.assertEqual(conf.cpu.sockets, 1) self.assertEqual(conf.cpu.cores, 1) self.assertEqual(conf.cpu.threads, 1) def test_get_guest_cpu_config_custom_old(self): def get_lib_version_stub(): return (0 * 1000 * 1000) + (9 * 1000) + 7 self.stubs.Set(self.conn, ""getLibVersion"", get_lib_version_stub) conn = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) instance_ref = db.instance_create(self.context, self.test_instance) self.flags(cpu_mode=""custom"", cpu_model=""Penryn"", group='libvirt') disk_info = blockinfo.get_disk_info(CONF.libvirt.virt_type, instance_ref) conf = conn._get_guest_config(instance_ref, _fake_network_info(self.stubs, 1), {}, disk_info) self.assertIsInstance(conf.cpu, vconfig.LibvirtConfigGuestCPU) self.assertIsNone(conf.cpu.mode) self.assertEqual(conf.cpu.model, ""Penryn"") self.assertEqual(conf.cpu.sockets, 1) self.assertEqual(conf.cpu.cores, 1) self.assertEqual(conf.cpu.threads, 1) return 9007 return 9007", def test_get_guest_cpu_config_host_passthrough(self): def test_get_guest_cpu_config_host_model(self): def test_get_guest_cpu_config_custom(self): return 9011 return 9011,199,16
openstack%2Fkeystone~master~I652eb6c545deede33622b64fb4810c319d480f7a,openstack/keystone,master,I652eb6c545deede33622b64fb4810c319d480f7a,Fix documentation link,MERGED,2014-08-07 04:59:47.000000000,2014-08-08 21:38:23.000000000,2014-08-08 21:38:22.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 9101}, {'_account_id': 11045}, {'_account_id': 11333}]","[{'number': 1, 'created': '2014-08-07 04:59:47.000000000', 'files': ['doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/0d4a70fb28311edb56b3c217f6232fc0c8d3056e', 'message': 'Fix documentation link\n\nWithout the :py: prefix the mod part of the string ends up in the\ndocumentation.\n\nChange-Id: I652eb6c545deede33622b64fb4810c319d480f7a\n'}]",0,112472,0d4a70fb28311edb56b3c217f6232fc0c8d3056e,15,7,1,7191,,,0,"Fix documentation link

Without the :py: prefix the mod part of the string ends up in the
documentation.

Change-Id: I652eb6c545deede33622b64fb4810c319d480f7a
",git fetch https://review.opendev.org/openstack/keystone refs/changes/72/112472/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration.rst'],1,0d4a70fb28311edb56b3c217f6232fc0c8d3056e,link-fix, * :py:mod:`keystone.common.cache.backends.mongo`, * :mod:`keystone.common.cache.backends.mongo`,1,1
openstack%2Fec2-api~master~I9f4f2a5104e4814496e183ac94b3b65a41658c34,openstack/ec2-api,master,I9f4f2a5104e4814496e183ac94b3b65a41658c34,Adding instances,MERGED,2014-08-08 15:01:47.000000000,2014-08-08 21:30:47.000000000,2014-08-08 21:30:47.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-08-08 15:01:47.000000000', 'files': ['ec2api/api/instance.py', 'ec2api/api/cloud.py', 'ec2api/tests/test_instance.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/5fbcc1b7b3bc9243a43425e79ec52ae85d1d47b0', 'message': 'Adding instances\n\nChange-Id: I9f4f2a5104e4814496e183ac94b3b65a41658c34\n'}]",0,112913,5fbcc1b7b3bc9243a43425e79ec52ae85d1d47b0,7,4,1,9312,,,0,"Adding instances

Change-Id: I9f4f2a5104e4814496e183ac94b3b65a41658c34
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/13/112913/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/instance.py', 'ec2api/api/cloud.py', 'ec2api/tests/test_instance.py']",3,5fbcc1b7b3bc9243a43425e79ec52ae85d1d47b0,,"# Copyright 2014 Cloudscaling Group, Inc # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import copy import itertools import mock from ec2api.api import ec2utils from ec2api.tests import base from ec2api.tests import fakes from ec2api.tests import matchers class InstanceTestCase(base.ApiTestCase): # TODO(ft): make negative tests on invalid parameters def setUp(self): super(InstanceTestCase, self).setUp() create_network_interface_patcher = ( mock.patch('ec2api.api.network_interface.' 'create_network_interface')) self.create_network_interface = ( create_network_interface_patcher.start()) self.addCleanup(create_network_interface_patcher.stop) def test_run_instances(self): """"""Run instance with various network interface settings."""""" self.db_api.get_item_by_id.side_effect = ( fakes.get_db_api_get_item_by_id( {fakes.ID_DB_SUBNET_1: fakes.DB_SUBNET_1, fakes.ID_DB_NETWORK_INTERFACE_1: copy.deepcopy(fakes.DB_NETWORK_INTERFACE_1)})) self.neutron.list_ports.return_value = ( {'ports': [fakes.OS_PORT_1, fakes.OS_PORT_2]}) self.create_network_interface.return_value = ( {'networkInterface': fakes.EC2_NETWORK_INTERFACE_1}) self.ec2.run_instances.return_value = ( fakes.gen_ec2_reservation([fakes.gen_ec2_instance( fakes.ID_EC2_INSTANCE_1, private_ip_address=None)])) self.isotime.return_value = fakes.TIME_ATTACH_NETWORK_INTERFACE def do_check(params, new_port=True, delete_on_termination=None): params.update({'ImageId': 'fake_image', 'MinCount': '1', 'MaxCount': '1'}) resp = self.execute('RunInstances', params) self.assertEqual(200, resp['status']) resp.pop('status') delete_port_on_termination = (new_port if delete_on_termination is None else delete_on_termination) db_attached_eni = fakes.gen_db_network_interface( fakes.ID_DB_NETWORK_INTERFACE_1, fakes.ID_OS_PORT_1, fakes.ID_DB_VPC_1, fakes.ID_DB_SUBNET_1, fakes.IP_NETWORK_INTERFACE_1, fakes.DESCRIPTION_NETWORK_INTERFACE_1, instance_id=fakes.ID_DB_INSTANCE_1, delete_on_termination=delete_port_on_termination) eni = fakes.gen_ec2_network_interface( fakes.ID_EC2_NETWORK_INTERFACE_1, fakes.EC2_SUBNET_1, [fakes.IP_NETWORK_INTERFACE_1], description=fakes.DESCRIPTION_NETWORK_INTERFACE_1, ec2_instance_id=fakes.ID_EC2_INSTANCE_1, delete_on_termination=delete_port_on_termination, for_instance_output=True) expected_reservation = fakes.gen_ec2_reservation([ fakes.gen_ec2_instance( fakes.ID_EC2_INSTANCE_1, private_ip_address=None, ec2_network_interfaces=[eni])]) self.assertThat(resp, matchers.DictMatches(expected_reservation)) if new_port: self.create_network_interface.assert_called_once_with( mock.ANY, fakes.EC2_SUBNET_1['subnetId']) self.ec2.run_instances.assert_called_once_with( image_id='fake_image', min_count=1, max_count=1, security_group=None, network_interface=[ {'network_interface_id': fakes.ID_OS_PORT_1}]) self.db_api.update_item.assert_called_once_with( mock.ANY, db_attached_eni) self.isotime.assert_called_once_with(None, True) self.create_network_interface.reset_mock() self.ec2.reset_mock() self.db_api.reset_mock() self.isotime.reset_mock() do_check({'SubnetId': fakes.EC2_SUBNET_1['subnetId']}) do_check({'NetworkInterface.1.SubnetId': fakes.EC2_SUBNET_1['subnetId']}) do_check({'NetworkInterface.1.SubnetId': fakes.EC2_SUBNET_1['subnetId'], 'NetworkInterface.1.DeleteOnTermination': 'False'}, delete_on_termination=False) do_check({'NetworkInterface.1.NetworkInterfaceId': fakes.EC2_NETWORK_INTERFACE_1['networkInterfaceId']}, new_port=False) def test_run_instances_multiple_networks(self): """"""Run 2 instances at once on 2 subnets in all combinations."""""" self._build_multiple_data_model() ec2os_reservations = [ fakes.gen_ec2_reservation([ fakes.gen_ec2_instance(ec2_instance_id, private_ip_address=None)]) for ec2_instance_id in self.IDS_EC2_INSTANCE] ec2_instances = [ fakes.gen_ec2_instance( ec2_instance_id, private_ip_address=None, ec2_network_interfaces=eni_pair) for ec2_instance_id, eni_pair in zip( self.IDS_EC2_INSTANCE, zip(*[iter(self.EC2_ATTACHED_ENIS)] * 2))] ec2_reservation = fakes.gen_ec2_reservation(ec2_instances) fakes_db_items = dict((eni['id'], eni) for eni in self.DB_DETACHED_ENIS) fakes_db_items.update({ fakes.ID_DB_SUBNET_1: fakes.DB_SUBNET_1, fakes.ID_DB_SUBNET_2: fakes.DB_SUBNET_2}) self.db_api.get_item_by_id.side_effect = ( fakes.get_db_api_get_item_by_id(fakes_db_items)) self.create_network_interface.side_effect = ( [{'networkInterface': eni} for eni in self.EC2_DETACHED_ENIS]) self.ec2.run_instances.side_effect = ( [copy.deepcopy(r) for r in ec2os_reservations]) self.neutron.list_ports.return_value = ( {'ports': self.OS_DETACHED_PORTS + [self.OS_FAKE_PORT]}) self.isotime.return_value = fakes.TIME_ATTACH_NETWORK_INTERFACE resp = self.execute( 'RunInstances', {'ImageId': 'fake_image', 'MinCount': '2', 'MaxCount': '2', 'NetworkInterface.1.SubnetId': fakes.ID_EC2_SUBNET_1, 'NetworkInterface.2.SubnetId': fakes.ID_EC2_SUBNET_2, 'NetworkInterface.2.DeleteOnTermination': 'False'}) self.assertEqual(200, resp['status']) resp.pop('status') self.assertThat(resp, matchers.DictMatches(ec2_reservation)) self.create_network_interface.assert_has_calls([ mock.call(mock.ANY, ec2_subnet_id) for ec2_subnet_id in self.IDS_EC2_SUBNET_BY_PORT]) self.ec2.run_instances.assert_has_calls([ mock.call(image_id='fake_image', min_count=1, max_count=1, security_group=None, network_interface=[ {'network_interface_id': port_id} for port_id in port_ids]) for port_ids in zip(*[iter(self.IDS_OS_PORT)] * 2)]) self.db_api.update_item.assert_has_calls([ mock.call(mock.ANY, eni) for eni in self.DB_ATTACHED_ENIS]) self.isotime.assert_called_once_with(None, True) @mock.patch('ec2api.api.network_interface.delete_network_interface') @mock.patch('ec2api.api.instance._format_instance') def test_run_instances_rollback(self, format_instance, delete_network_interface): self.db_api.get_item_by_id.side_effect = ( fakes.get_db_api_get_item_by_id( {fakes.ID_DB_SUBNET_1: fakes.DB_SUBNET_1, fakes.ID_DB_NETWORK_INTERFACE_1: copy.deepcopy(fakes.DB_NETWORK_INTERFACE_1)})) self.neutron.list_ports.return_value = ( {'ports': [fakes.OS_PORT_1, fakes.OS_PORT_2]}) self.create_network_interface.return_value = ( {'networkInterface': fakes.EC2_NETWORK_INTERFACE_1}) self.ec2.run_instances.return_value = ( fakes.gen_ec2_reservation([fakes.gen_ec2_instance( fakes.ID_EC2_INSTANCE_1, private_ip_address=None)])) self.isotime.return_value = fakes.TIME_ATTACH_NETWORK_INTERFACE format_instance.side_effect = Exception() def do_check(params, new_port=True, delete_on_termination=None): params.update({'ImageId': 'fake_image', 'MinCount': '1', 'MaxCount': '1'}) self.execute('RunInstances', params) # TODO(ft): check sequence of calling # neutron update port must be the first if new_port: delete_network_interface.assert_called_once_with( mock.ANY, network_interface_id=fakes.ID_EC2_NETWORK_INTERFACE_1) else: self.neutron.update_port.assert_called_once_with( fakes.ID_OS_PORT_1, {'port': {'device_id': '', 'device_owner': ''}}) self.ec2.terminate_instances.assert_called_once_with( instance_id=fakes.ID_EC2_INSTANCE_1) self.db_api.update_item.assert_any_call( mock.ANY, fakes.DB_NETWORK_INTERFACE_1) delete_network_interface.reset_mock() self.neutron.reset_mock() self.ec2.reset_mock() self.db_api.reset_mock() do_check({'SubnetId': fakes.EC2_SUBNET_1['subnetId']}) do_check({'NetworkInterface.1.SubnetId': fakes.EC2_SUBNET_1['subnetId']}) do_check({'NetworkInterface.1.SubnetId': fakes.EC2_SUBNET_1['subnetId'], 'NetworkInterface.1.DeleteOnTermination': 'False'}, delete_on_termination=False) do_check({'NetworkInterface.1.NetworkInterfaceId': fakes.EC2_NETWORK_INTERFACE_1['networkInterfaceId']}, new_port=False) def test_terminate_instances(self): """"""Terminate 2 instances in one request."""""" ec2_terminate_instances_result = { 'instancesSet': [{'instanceId': fakes.ID_EC2_INSTANCE_1, 'fakeKey': 'fakeValue'}, {'instanceId': fakes.ID_EC2_INSTANCE_2, 'fakeKey': 'fakeValue'}]} os_instance_ids_dict = {fakes.ID_DB_INSTANCE_1: fakes.ID_OS_INSTANCE_1, fakes.ID_DB_INSTANCE_2: fakes.ID_OS_INSTANCE_2} self.get_instance_uuid_from_int_id.side_effect = ( lambda _, inst_id: os_instance_ids_dict[inst_id]) self.neutron.list_ports.return_value = {'ports': [fakes.OS_PORT_2]} self.db_api.get_items.return_value = ( [copy.deepcopy(fakes.DB_NETWORK_INTERFACE_1), copy.deepcopy(fakes.DB_NETWORK_INTERFACE_2)]) self.ec2.terminate_instances.return_value = ( ec2_terminate_instances_result) resp = self.execute('TerminateInstances', {'InstanceId.1': fakes.ID_EC2_INSTANCE_1, 'InstanceId.2': fakes.ID_EC2_INSTANCE_2}) self.assertEqual(200, resp['status']) resp.pop('status') self.assertThat(resp, matchers.DictMatches( ec2_terminate_instances_result)) self.get_instance_uuid_from_int_id.assert_any_call( mock.ANY, fakes.ID_DB_INSTANCE_1) self.get_instance_uuid_from_int_id.assert_any_call( mock.ANY, fakes.ID_DB_INSTANCE_2) self._assert_list_ports_is_called_with_filter( [fakes.ID_OS_INSTANCE_1, fakes.ID_OS_INSTANCE_2]) self.neutron.update_port.assert_called_once_with( fakes.ID_OS_PORT_2, {'port': {'device_id': '', 'device_owner': ''}}) self.ec2.terminate_instances.assert_called_once_with( instance_id=[fakes.ID_EC2_INSTANCE_1, fakes.ID_EC2_INSTANCE_2]) def test_terminate_instances_multiple_networks(self): """"""Terminate an instance with various combinations of ports."""""" self._build_multiple_data_model() ec2_terminate_instances_result = { 'instancesSet': [{'instanceId': fakes.ID_EC2_INSTANCE_1, 'fakeKey': 'fakeValue'}, {'instanceId': fakes.ID_EC2_INSTANCE_2, 'fakeKey': 'fakeValue'}]} os_instance_ids_dict = {fakes.ID_DB_INSTANCE_1: fakes.ID_OS_INSTANCE_1, fakes.ID_DB_INSTANCE_2: fakes.ID_OS_INSTANCE_2} self.get_instance_uuid_from_int_id.side_effect = ( lambda _, inst_id: os_instance_ids_dict[inst_id]) self.ec2.terminate_instances.return_value = ( ec2_terminate_instances_result) def do_check(mock_port_list=[], mock_eni_list=[], updated_ports=[], deleted_ports=[]): self.neutron.list_ports.return_value = {'ports': mock_port_list} self.db_api.get_items.return_value = ( copy.deepcopy(mock_eni_list) + [self.DB_FAKE_ENI]) resp = self.execute('TerminateInstances', {'InstanceId.1': fakes.ID_EC2_INSTANCE_1, 'InstanceId.2': fakes.ID_EC2_INSTANCE_2}) self.assertEqual(200, resp['status']) resp.pop('status') self.assertThat(resp, matchers.DictMatches( ec2_terminate_instances_result)) for inst_id in self.IDS_DB_INSTANCE: self.get_instance_uuid_from_int_id.assert_any_call( mock.ANY, inst_id) self._assert_list_ports_is_called_with_filter(self.IDS_OS_INSTANCE) self.ec2.terminate_instances.assert_called_once_with( instance_id=self.IDS_EC2_INSTANCE) self.assertEqual(len(updated_ports), self.neutron.update_port.call_count) self.assertEqual(len(updated_ports), self.db_api.update_item.call_count) for port in updated_ports: self.neutron.update_port.assert_any_call( port['os_id'], {'port': {'device_id': '', 'device_owner': ''}}) self.db_api.update_item.assert_any_call( mock.ANY, port) self.assertEqual(len(deleted_ports), self.db_api.delete_item.call_count) for port in deleted_ports: self.db_api.delete_item.assert_any_call( mock.ANY, port['id']) self.get_instance_uuid_from_int_id.reset_mock() self.neutron.list_ports.reset_mock() self.neutron.update_port.reset_mock() self.ec2.terminate_instances.reset_mock() self.db_api.delete_item.reset_mock() self.db_api.update_item.reset_mock() # NOTE(ft): 2 instances; the first has 2 correct ports; # the second has the first port attached by EC2 API but later detached # by OpenStack and the second port created through EC2 API but # attached by OpenStack only do_check( mock_port_list=[ self.OS_ATTACHED_PORTS[0], self.OS_ATTACHED_PORTS[1], self.OS_ATTACHED_PORTS[3]], mock_eni_list=[ self.DB_ATTACHED_ENIS[0], self.DB_ATTACHED_ENIS[1], self.DB_ATTACHED_ENIS[2], self.DB_DETACHED_ENIS[3]], updated_ports=[self.DB_DETACHED_ENIS[1]], deleted_ports=[self.DB_ATTACHED_ENIS[0], self.DB_ATTACHED_ENIS[2]]) # NOTE(ft): 2 instances: the first has the first port attached by # OpenStack only, EC2 layer of OpenStack displays its IP address as # IP address of the instance, the second port is attached correctly; # the second instance has one port created and attached by OpenStack # only do_check( mock_port_list=[ self.OS_ATTACHED_PORTS[0], self.OS_ATTACHED_PORTS[1], self.OS_ATTACHED_PORTS[3]], mock_eni_list=[self.DB_ATTACHED_ENIS[1]], updated_ports=[self.DB_DETACHED_ENIS[1]], deleted_ports=[]) def test_describe_instances(self): """"""Describe 2 instances, one of which is vpc instance."""""" self.ec2.describe_instances.return_value = ( {'reservationSet': [fakes.EC2OS_RESERVATION_1, fakes.EC2OS_RESERVATION_2], 'fakeKey': 'fakeValue'}) self.ec2_inst_id_to_uuid.side_effect = [fakes.ID_OS_INSTANCE_1, fakes.ID_OS_INSTANCE_2] self.neutron.list_ports.return_value = {'ports': [fakes.OS_PORT_2]} self.db_api.get_items.side_effect = ( lambda _, kind: [fakes.DB_NETWORK_INTERFACE_1, fakes.DB_NETWORK_INTERFACE_2] if kind == 'eni' else [fakes.DB_ADDRESS_1, fakes.DB_ADDRESS_2] if kind == 'eipalloc' else []) self.neutron.list_floatingips.return_value = ( {'floatingips': [fakes.OS_FLOATING_IP_1, fakes.OS_FLOATING_IP_2]}) resp = self.execute('DescribeInstances', {}) self.assertEqual(200, resp['status']) resp.pop('status') self.ec2.describe_instances.assert_called_once_with( instance_id=None, filter=None) self.assertThat(resp, matchers.DictMatches( {'reservationSet': [fakes.EC2_RESERVATION_1, fakes.EC2_RESERVATION_2], 'fakeKey': 'fakeValue'})) self.ec2_inst_id_to_uuid.assert_any_call( mock.ANY, fakes.ID_EC2_INSTANCE_1) self.ec2_inst_id_to_uuid.assert_any_call( mock.ANY, fakes.ID_EC2_INSTANCE_2) self._assert_list_ports_is_called_with_filter( [fakes.ID_OS_INSTANCE_1, fakes.ID_OS_INSTANCE_2]) def test_describe_instances_mutliple_networks(self): """"""Describe 2 instances with various combinations of network."""""" self._build_multiple_data_model() ips_instance = [fakes.IP_FIRST_SUBNET_1, fakes.IP_FIRST_SUBNET_2] def do_check(separate_reservations=False, mock_port_list=[], mock_eni_list=[], ec2_enis_by_instance=[], is_instance_ip_in_vpc_by_instance=[True, True]): def gen_reservation_set(instances): if separate_reservations: return [fakes.gen_ec2_reservation([instances[0]]), fakes.gen_ec2_reservation([instances[1]])] else: return [fakes.gen_ec2_reservation([instances[0], instances[1]])] instances = [fakes.gen_ec2_instance(inst_id, private_ip_address=ip) for inst_id, ip in zip( self.IDS_EC2_INSTANCE, ips_instance)] reservation_set = gen_reservation_set([instances[0], instances[1]]) self.ec2.describe_instances.return_value = ( {'reservationSet': reservation_set, 'fakeKey': 'fakeValue'}) self.ec2_inst_id_to_uuid.side_effect = self.IDS_OS_INSTANCE self.neutron.list_ports.return_value = {'ports': mock_port_list} self.db_api.get_items.return_value = ( mock_eni_list + [self.DB_FAKE_ENI]) resp = self.execute('DescribeInstances', {}) self.assertEqual(200, resp['status']) resp.pop('status') instances = [fakes.gen_ec2_instance(inst_id, private_ip_address=ip, ec2_network_interfaces=enis, is_private_ip_in_vpc=ip_in_vpc) for inst_id, ip, enis, ip_in_vpc in zip( self.IDS_EC2_INSTANCE, ips_instance, ec2_enis_by_instance, is_instance_ip_in_vpc_by_instance)] reservation_set = gen_reservation_set([instances[0], instances[1]]) self.assertThat({'reservationSet': reservation_set, 'fakeKey': 'fakeValue'}, matchers.DictMatches(resp), verbose=True) self.ec2.describe_instances.assert_called_once_with( instance_id=None, filter=None) for inst_id in self.IDS_EC2_INSTANCE: self.ec2_inst_id_to_uuid.assert_any_call( mock.ANY, inst_id) self._assert_list_ports_is_called_with_filter(self.IDS_OS_INSTANCE) self.ec2.describe_instances.reset_mock() self.neutron.list_ports.reset_mock() # NOTE(ft): 2 instances; the first has 2 correct ports; # the second has the first port attached by EC2 API but later detached # by OpenStack and the second port created through EC2 API but # attached by OpenStack only do_check( separate_reservations=False, mock_port_list=[ self.OS_ATTACHED_PORTS[0], self.OS_ATTACHED_PORTS[1], self.OS_ATTACHED_PORTS[3]], mock_eni_list=[ self.DB_ATTACHED_ENIS[0], self.DB_ATTACHED_ENIS[1], self.DB_ATTACHED_ENIS[2], self.DB_DETACHED_ENIS[3]], ec2_enis_by_instance=[ [self.EC2_ATTACHED_ENIS[0], self.EC2_ATTACHED_ENIS[1]], None], is_instance_ip_in_vpc_by_instance=[True, None]) # NOTE(ft): 2 instances: the first has the first port attached by # OpenStack only, EC2 layer of OpenStack displays its IP address as # IP address of the instance, the second port is attached correctly; # the second instance has one port created and attached by OpenStack # only do_check( separate_reservations=True, mock_port_list=[ self.OS_ATTACHED_PORTS[0], self.OS_ATTACHED_PORTS[1], self.OS_ATTACHED_PORTS[3]], mock_eni_list=[self.DB_ATTACHED_ENIS[1]], ec2_enis_by_instance=[[self.EC2_ATTACHED_ENIS[1]], None], is_instance_ip_in_vpc_by_instance=[False, None]) def _build_multiple_data_model(self): # NOTE(ft): generate necessary fake data # We need 4 detached ports in 2 subnets. # Sequence of all ports list is s1i1, s2i1, s1i2, s2i2, # where sNiM - port info of instance iM on subnet sN. # We generate port ids but use subnet and instance ids since # fakes contain enough ids for subnets an instances, but not for ports. instances_count = 2 subnets_count = 2 ports_count = instances_count * subnets_count ids_db_eni = [fakes.random_db_id() for _ in range(ports_count)] ids_os_port = [fakes.random_os_id() for _ in range(ports_count)] ids_db_subnet = (fakes.ID_DB_SUBNET_1, fakes.ID_DB_SUBNET_2) ids_db_subnet_by_port = ids_db_subnet * 2 ids_ec2_subnet = (fakes.ID_EC2_SUBNET_1, fakes.ID_EC2_SUBNET_2) ids_ec2_subnet_by_port = ids_ec2_subnet * 2 ips = (fakes.IP_FIRST_SUBNET_1, fakes.IP_FIRST_SUBNET_2, fakes.IP_LAST_SUBNET_1, fakes.IP_LAST_SUBNET_2) ids_db_instance = [fakes.ID_DB_INSTANCE_1, fakes.ID_DB_INSTANCE_2] ids_db_instance_by_port = list( itertools.chain(*map(lambda i: [i] * subnets_count, ids_db_instance))) ids_os_instance = [fakes.ID_OS_INSTANCE_1, fakes.ID_OS_INSTANCE_2] ids_os_instance_by_port = list( itertools.chain(*map(lambda i: [i] * subnets_count, ids_os_instance))) ids_ec2_instance = [fakes.ID_EC2_INSTANCE_1, fakes.ID_EC2_INSTANCE_2] ids_ec2_instance_by_port = list( itertools.chain(*map(lambda i: [i] * subnets_count, ids_ec2_instance))) dots_by_port = [True, False] * instances_count db_attached_enis = [ fakes.gen_db_network_interface( db_id, os_id, fakes.ID_DB_VPC_1, subnet_db_id, ip, instance_id=instance_db_id, delete_on_termination=dot) for db_id, os_id, subnet_db_id, ip, instance_db_id, dot in zip( ids_db_eni, ids_os_port, ids_db_subnet_by_port, ips, ids_db_instance_by_port, dots_by_port)] db_detached_enis = [ fakes.gen_db_network_interface( db_id, os_id, fakes.ID_DB_VPC_1, subnet_db_id, ip) for db_id, os_id, subnet_db_id, ip in zip( ids_db_eni, ids_os_port, ids_db_subnet_by_port, ips)] ec2_attached_enis = [ fakes.gen_ec2_network_interface( ec2utils.get_ec2_id(db_eni['id'], 'eni'), None, # ec2_subnet [db_eni['private_ip_address']], ec2_instance_id=ec2_instance_id, delete_on_termination=dot, for_instance_output=True, ec2_subnet_id=ec2_subnet_id, ec2_vpc_id=fakes.ID_EC2_VPC_1) for db_eni, dot, ec2_subnet_id, ec2_instance_id in zip( db_attached_enis, dots_by_port, ids_ec2_subnet_by_port, ids_ec2_instance_by_port)] ec2_detached_enis = [ fakes.gen_ec2_network_interface( ec2utils.get_ec2_id(db_eni['id'], 'eni'), None, # ec2_subnet [db_eni['private_ip_address']], ec2_subnet_id=ec2_subnet_id, ec2_vpc_id=fakes.ID_EC2_VPC_1) for db_eni, ec2_subnet_id in zip( db_detached_enis, ids_ec2_subnet_by_port)] os_attached_ports = [ fakes.gen_os_port( os_id, ec2_eni, subnet_os_id, [ec2_eni['privateIpAddress']], os_instance_id=os_instance_id) for os_id, ec2_eni, subnet_os_id, os_instance_id in zip( ids_os_port, ec2_attached_enis, ids_db_subnet_by_port, ids_os_instance_by_port)] os_detached_ports = [ fakes.gen_os_port( os_id, ec2_eni, subnet_os_id, [ec2_eni['privateIpAddress']]) for os_id, ec2_eni, subnet_os_id in zip( ids_os_port, ec2_detached_enis, ids_db_subnet_by_port)] self.IDS_DB_ENI = ids_db_eni self.IDS_OS_PORT = ids_os_port self.IDS_DB_INSTANCE = ids_db_instance self.IDS_OS_INSTANCE = ids_os_instance self.IDS_EC2_INSTANCE = ids_ec2_instance self.IDS_EC2_SUBNET_BY_PORT = ids_ec2_subnet_by_port self.OS_ATTACHED_PORTS = os_attached_ports self.OS_DETACHED_PORTS = os_detached_ports self.DB_ATTACHED_ENIS = db_attached_enis self.DB_DETACHED_ENIS = db_detached_enis self.EC2_ATTACHED_ENIS = ec2_attached_enis self.EC2_DETACHED_ENIS = ec2_detached_enis # NOTE(ft): additional fake data to check filtering, etc self.DB_FAKE_ENI = fakes.gen_db_network_interface( fakes.random_db_id(), fakes.random_os_id(), fakes.ID_DB_VPC_1, fakes.ID_DB_SUBNET_2, 'fake_ip') ec2_fake_eni = fakes.gen_ec2_network_interface( ec2utils.get_ec2_id(self.DB_FAKE_ENI['id'], 'eni'), fakes.EC2_SUBNET_2, ['fake_ip']) self.OS_FAKE_PORT = fakes.gen_os_port( fakes.random_os_id(), ec2_fake_eni, fakes.ID_OS_SUBNET_2, ['fake_ip']) def _assert_list_ports_is_called_with_filter(self, instance_ids): # NOTE(ft): compare manually due to the order of instance ids in # list_ports call depends of values of instance EC2 ids # But neither assert_any_called nor matchers.DictMatches can not # compare lists excluding the order of elements list_ports_calls = self.neutron.list_ports.mock_calls self.assertEqual(1, len(list_ports_calls)) self.assertEqual((), list_ports_calls[0][1]) list_ports_kwargs = list_ports_calls[0][2] self.assertEqual(len(list_ports_kwargs), 1) self.assertIn('device_id', list_ports_kwargs) self.assertEqual(sorted(instance_ids), sorted(list_ports_kwargs['device_id'])) class InstanceIntegrationTestCase(base.ApiTestCase): def test_run_instances(self): self.db_api.get_item_by_id.side_effect = ( fakes.get_db_api_get_item_by_id( {fakes.ID_DB_SUBNET_1: fakes.DB_SUBNET_1, fakes.ID_DB_VPC_1: fakes.DB_VPC_1, fakes.ID_DB_NETWORK_INTERFACE_1: fakes.DB_NETWORK_INTERFACE_1})) self.db_api.add_item.return_value = fakes.DB_NETWORK_INTERFACE_1 self.neutron.show_subnet.return_value = {'subnet': fakes.OS_SUBNET_1} self.neutron.create_port.return_value = {'port': fakes.OS_PORT_1} self.neutron.list_ports.return_value = {'ports': [fakes.OS_PORT_1]} self.ec2.run_instances.return_value = ( fakes.gen_ec2_reservation([fakes.gen_ec2_instance( fakes.ID_EC2_INSTANCE_1, private_ip_address=None)])) self.isotime.return_value = fakes.TIME_ATTACH_NETWORK_INTERFACE resp = self.execute('RunInstances', {'ImageId': 'fake_image', 'MinCount': '1', 'MaxCount': '1', 'SubnetId': fakes.ID_EC2_SUBNET_1}) self.assertEqual(200, resp['status']) ",,1208,0
openstack%2Fheat~master~I4339067e3b8927573acff0ab5968de61a3253d07,openstack/heat,master,I4339067e3b8927573acff0ab5968de61a3253d07,"Add ""index_var"" property to the resource group resource",MERGED,2014-04-18 17:28:30.000000000,2014-08-08 21:06:19.000000000,2014-08-08 21:06:18.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 4257}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 7233}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7404}, {'_account_id': 7714}, {'_account_id': 8871}, {'_account_id': 9165}]","[{'number': 1, 'created': '2014-04-18 17:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bb46e28c4943654520cd60d2c508dca35768d618', 'message': 'Add ""index_var"" property to the resource group resource\n\nThis property allows a template author to replace values in the\nnested resource_ref with the index of the specific instance of\nthat resource in the group. This allows a user to, for example,\nadd the index of the resource to server names in order to make\nthem more easily distinguishable when listed outside of Heat.\n\nImplemements: blueprint override-resource-name-in-resource-group\nChange-Id: I4339067e3b8927573acff0ab5968de61a3253d07\n'}, {'number': 2, 'created': '2014-04-30 15:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/92c60060cd7b29566e945e7420f50a25cea3d55a', 'message': 'Add ""index_var"" property to the resource group resource\n\nThis property allows a template author to replace values in the\nnested resource_ref with the index of the specific instance of\nthat resource in the group. This allows a user to, for example,\nadd the index of the resource to server names in order to make\nthem more easily distinguishable when listed outside of Heat.\n\nImplemements: blueprint override-resource-name-in-resource-group\nChange-Id: I4339067e3b8927573acff0ab5968de61a3253d07\n'}, {'number': 3, 'created': '2014-05-02 18:31:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b36cab2694542b48fedbbb9d3e41a0f6cfdc2438', 'message': 'Add ""index_var"" property to the resource group resource\n\nThis property allows a template author to replace values in the\nnested resource_ref with the index of the specific instance of\nthat resource in the group. This allows a user to, for example,\nadd the index of the resource to server names in order to make\nthem more easily distinguishable when listed outside of Heat.\n\nImplemements: blueprint override-resource-name-in-resource-group\nChange-Id: I4339067e3b8927573acff0ab5968de61a3253d07\n'}, {'number': 4, 'created': '2014-05-19 21:36:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cc272e68bbc3261135c1d0a945aaa6830a61194e', 'message': 'Add ""index_var"" property to the resource group resource\n\nThis property allows a template author to replace values in the\nnested resource_ref with the index of the specific instance of\nthat resource in the group. This allows a user to, for example,\nadd the index of the resource to server names in order to make\nthem more easily distinguishable when listed outside of Heat.\n\nImplemements: blueprint override-resource-name-in-resource-group\nChange-Id: I4339067e3b8927573acff0ab5968de61a3253d07\n'}, {'number': 5, 'created': '2014-05-28 19:29:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5d88bd1d27f38a323840054090169ddc11437a9a', 'message': 'Add ""index_var"" property to the resource group resource\n\nThis property allows a template author to replace values in the\nnested resource_ref with the index of the specific instance of\nthat resource in the group. This allows a user to, for example,\nadd the index of the resource to server names in order to make\nthem more easily distinguishable when listed outside of Heat.\n\nImplemements: blueprint override-resource-name-in-resource-group\nChange-Id: I4339067e3b8927573acff0ab5968de61a3253d07\n'}, {'number': 6, 'created': '2014-06-05 20:51:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2c4c5891fa19f1ccde246bc6f4392bcea6933fac', 'message': 'Add ""index_var"" property to the resource group resource\n\nThis property allows a template author to replace values in the\nnested resource_ref with the index of the specific instance of\nthat resource in the group. This allows a user to, for example,\nadd the index of the resource to server names in order to make\nthem more easily distinguishable when listed outside of Heat.\n\nImplemements: blueprint override-resource-name-in-resource-group\nChange-Id: I4339067e3b8927573acff0ab5968de61a3253d07\n'}, {'number': 7, 'created': '2014-06-10 22:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3de9be3dd31b8c3d1e1c5f37c3826559348cfb07', 'message': 'Add ""index_var"" property to the resource group resource\n\nThis property allows a template author to replace values in the\nnested resource_ref with the index of the specific instance of\nthat resource in the group. This allows a user to, for example,\nadd the index of the resource to server names in order to make\nthem more easily distinguishable when listed outside of Heat.\n\nImplemements: blueprint override-resource-name-in-resource-group\nChange-Id: I4339067e3b8927573acff0ab5968de61a3253d07\n'}, {'number': 8, 'created': '2014-06-10 23:48:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/41bf1963ec5c3b6bf6f22c2b06b363ba5e8ef748', 'message': 'Add ""index_var"" property to the resource group resource\n\nThis property allows a template author to replace values in the\nnested resource_ref with the index of the specific instance of\nthat resource in the group. This allows a user to, for example,\nadd the index of the resource to server names in order to make\nthem more easily distinguishable when listed outside of Heat.\n\nImplemements: blueprint override-resource-name-in-resource-group\nChange-Id: I4339067e3b8927573acff0ab5968de61a3253d07\n'}, {'number': 9, 'created': '2014-07-10 23:13:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d5bc4259447907dc8d31d4abee88025585f3d008', 'message': 'Add ""index_var"" property to the resource group resource\n\nThis property allows a template author to replace values in the\nnested resource_ref with the index of the specific instance of\nthat resource in the group. This allows a user to, for example,\nadd the index of the resource to server names in order to make\nthem more easily distinguishable when listed outside of Heat.\n\nImplemements: blueprint override-resource-name-in-resource-group\nChange-Id: I4339067e3b8927573acff0ab5968de61a3253d07\n'}, {'number': 10, 'created': '2014-07-29 21:39:58.000000000', 'files': ['heat/engine/resources/resource_group.py', 'heat/tests/test_resource_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/b58c9a54b1d390b684c41723e08be634b94aff93', 'message': 'Add ""index_var"" property to the resource group resource\n\nThis property allows a template author to replace values in the\nnested resource_ref with the index of the specific instance of\nthat resource in the group. This allows a user to, for example,\nadd the index of the resource to server names in order to make\nthem more easily distinguishable when listed outside of Heat.\n\nImplemements: blueprint override-resource-name-in-resource-group\nChange-Id: I4339067e3b8927573acff0ab5968de61a3253d07\n'}]",3,88636,b58c9a54b1d390b684c41723e08be634b94aff93,83,12,10,7256,,,0,"Add ""index_var"" property to the resource group resource

This property allows a template author to replace values in the
nested resource_ref with the index of the specific instance of
that resource in the group. This allows a user to, for example,
add the index of the resource to server names in order to make
them more easily distinguishable when listed outside of Heat.

Implemements: blueprint override-resource-name-in-resource-group
Change-Id: I4339067e3b8927573acff0ab5968de61a3253d07
",git fetch https://review.opendev.org/openstack/heat refs/changes/36/88636/6 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/resource_group.py', 'heat/tests/test_resource_group.py']",2,bb46e28c4943654520cd60d2c508dca35768d618,bp/override-resource-name-in-resource-group,"template_repl = { ""heat_template_version"": ""2013-05-23"", ""resources"": { ""group1"": { ""type"": ""OS::Heat::ResourceGroup"", ""properties"": { ""count"": 2, ""resource_def"": { ""type"": ""dummy.resource"", ""properties"": { ""Foo"": ""Bar_%index%"" } } } } } } def test_index_var(self): stack = utils.parse_stack(template_repl) snip = stack.t['Resources']['group1'] resg = resource_group.ResourceGroup('test', snip, stack) expect = { ""heat_template_version"": ""2013-05-23"", ""resources"": { ""0"": { ""type"": ""dummy.resource"", ""properties"": { ""Foo"": ""Bar_0"" } }, ""1"": { ""type"": ""dummy.resource"", ""properties"": { ""Foo"": ""Bar_1"" } }, ""2"": { ""type"": ""dummy.resource"", ""properties"": { ""Foo"": ""Bar_2"" } } } } self.assertEqual(expect, resg._assemble_nested(3)) def test_custom_index_var(self): templ = copy.deepcopy(template_repl) templ['resources']['group1']['properties']['index_var'] = ""__foo__"" stack = utils.parse_stack(templ) snip = stack.t['Resources']['group1'] resg = resource_group.ResourceGroup('test', snip, stack) expect = { ""heat_template_version"": ""2013-05-23"", ""resources"": { ""0"": { ""type"": ""dummy.resource"", ""properties"": { ""Foo"": ""Bar_%index%"" } } } } self.assertEqual(expect, resg._assemble_nested(1)) res_def = snip['Properties']['resource_def'] res_def['properties']['Foo'] = ""Bar___foo__"" resg = resource_group.ResourceGroup('test', snip, stack) expect = { ""heat_template_version"": ""2013-05-23"", ""resources"": { ""0"": { ""type"": ""dummy.resource"", ""properties"": { ""Foo"": ""Bar_0"" } } } } self.assertEqual(expect, resg._assemble_nested(1)) ",,110,4
openstack%2Fbarbican~master~Ieb207f91c8251d8ec6601fa113f2501869382e74,openstack/barbican,master,Ieb207f91c8251d8ec6601fa113f2501869382e74,Add Certificate Interface & Symantec Plugin,MERGED,2014-07-15 22:08:28.000000000,2014-08-08 20:50:00.000000000,2014-08-08 20:49:59.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7354}, {'_account_id': 7355}, {'_account_id': 7687}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 8623}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 9946}, {'_account_id': 10873}, {'_account_id': 11661}, {'_account_id': 11860}, {'_account_id': 11970}]","[{'number': 1, 'created': '2014-07-15 22:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/12a7d520499002a1d08afeaf554eecb144d56213', 'message': 'Add state machine and unit tests for symantec plugin\n\nChange-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74\n'}, {'number': 2, 'created': '2014-07-28 23:32:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/8f503843ebb931f0ff5eff32d4d6a9d967a15968', 'message': 'Add Certificate Interface & Symantec Plugin\n\nAdding the new Certificate interface and Symantec plugin.\nThis includes unit tests as well as a part of the tasking.\n\nChange-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74\n'}, {'number': 3, 'created': '2014-07-29 06:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/d23aecf54d549a02e19ab32c2e6d5411f1435cab', 'message': 'Add Certificate Interface & Symantec Plugin\n\nAdding the new Certificate interface and Symantec plugin.\nThis includes unit tests as well as a part of the tasking.\n\nImplements: blueprint add-ssl-ca-support\nChange-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74\n'}, {'number': 4, 'created': '2014-07-29 06:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/ee58fe1f0007b4f332db184db52f4a7ce5ddb05d', 'message': 'Add Certificate Interface & Symantec Plugin\n\nAdding the new Certificate interface and Symantec plugin.\nThis includes unit tests as well as a part of the tasking.\n\nImplements: blueprint add-ssl-ca-support\nChange-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74\n'}, {'number': 5, 'created': '2014-08-01 17:51:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/e0f9859c4f135a07a279a060255d84c6fa145b0f', 'message': 'Add Certificate Interface & Symantec Plugin\n\nAdding the new Certificate interface and Symantec plugin.\nThis includes unit tests as well as a part of the tasking.\n\nImplements: blueprint add-ssl-ca-support\nChange-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74\n'}, {'number': 6, 'created': '2014-08-01 20:36:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/d9c791b125a6fbc4a36b20f90715b7097092de79', 'message': 'Add Certificate Interface & Symantec Plugin\n\nAdding the new Certificate interface and Symantec plugin.\nThis includes unit tests as well as a part of the tasking.\n\nImplements: blueprint add-ssl-ca-support\nChange-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74\n'}, {'number': 7, 'created': '2014-08-01 22:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/3dc1267de565e467d8dbb35b7c2ec21d3b4db2e3', 'message': 'Add Certificate Interface & Symantec Plugin\n\nAdding the new Certificate interface and Symantec plugin.\nThis includes unit tests as well as a part of the tasking.\n\nImplements: blueprint add-ssl-ca-support\nChange-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74\n'}, {'number': 8, 'created': '2014-08-05 20:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/fd927e47e0b12a6569ddfeb7ab2c3b85aa83dac0', 'message': 'Add Certificate Interface & Symantec Plugin\n\nAdding the new Certificate interface and Symantec plugin.\nThis includes unit tests as well as a part of the tasking.\n\nImplements: blueprint add-ssl-ca-support\nChange-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74\n'}, {'number': 9, 'created': '2014-08-05 23:24:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/0dfc4e6dc06dd3e5b9e16706d365df9e5dccf59f', 'message': 'Add Certificate Interface & Symantec Plugin\n\nAdding the new Certificate interface and Symantec plugin.\nThis includes unit tests as well as a part of the tasking.\n\nImplements: blueprint add-ssl-ca-support\nChange-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74\n'}, {'number': 10, 'created': '2014-08-06 16:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/a01aa59efa45da781e99a7fc4aaa8d369398be27', 'message': 'Add Certificate Interface & Symantec Plugin\n\nAdding the new Certificate interface and Symantec plugin.\nThis includes unit tests as well as a part of the tasking.\n\nImplements: blueprint add-ssl-ca-support\nChange-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74\n'}, {'number': 11, 'created': '2014-08-06 20:20:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/9b8b36cce43335cc93967697d7fa7ee37a907fb3', 'message': 'Add Certificate Interface & Symantec Plugin\n\nAdding the new Certificate interface and Symantec plugin.\nThis includes unit tests as well as a part of the tasking.\n\nImplements: blueprint add-ssl-ca-support\nChange-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74\n'}, {'number': 12, 'created': '2014-08-06 20:21:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/e58a3f76f0d88df6d3eb37acd9afe2d9f6ec5594', 'message': 'Add Certificate Interface & Symantec Plugin\n\nAdding the new Certificate interface and Symantec plugin.\nThis includes unit tests as well as a part of the tasking.\n\nImplements: blueprint add-ssl-ca-support\nChange-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74\n'}, {'number': 13, 'created': '2014-08-06 21:31:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/7a0030a02acc11201104db334b3a7d06c466c864', 'message': 'Add Certificate Interface & Symantec Plugin\n\nAdding the new Certificate interface and Symantec plugin.\nThis includes unit tests as well as a part of the tasking.\n\nImplements: blueprint add-ssl-ca-support\nChange-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74\n'}, {'number': 14, 'created': '2014-08-07 01:52:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/3b26e70724e622ce97b98bc0156a7ae54ffa95e7', 'message': 'Add Certificate Interface & Symantec Plugin\n\nAdding the new Certificate interface and Symantec plugin.\nThis includes unit tests as well as a part of the tasking.\n\nImplements: blueprint add-ssl-ca-support\nChange-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74\n'}, {'number': 15, 'created': '2014-08-07 04:23:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/144f1c0bf1adbbea6c056a46968fd68637ced0f7', 'message': 'Add Certificate Interface & Symantec Plugin\n\nAdding the new Certificate interface and Symantec plugin.\nThis includes unit tests as well as a part of the tasking.\n\nImplements: blueprint add-ssl-ca-support\nChange-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74\n'}, {'number': 16, 'created': '2014-08-07 19:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/c2b3a551e24acfa4498258f2af68c7bae68ee6ad', 'message': 'Add Certificate Interface & Symantec Plugin\n\nAdding the new Certificate interface and Symantec plugin.\nThis includes unit tests as well as a part of the tasking.\n\nImplements: blueprint add-ssl-ca-support\nChange-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74\n'}, {'number': 17, 'created': '2014-08-08 18:14:28.000000000', 'files': ['barbican/plugin/symantec.py', 'barbican/tests/tasks/test_certificate_resources.py', 'barbican/tasks/certificate_resources.py', 'barbican/plugin/interface/certificates.py', 'barbican/tests/plugin/test_symantec.py', 'barbican/plugin/interface/secret_store.py', 'barbican/plugin/interface/certificate_manager.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/a40ee256b577905c66938469666cf5c242ac28b6', 'message': 'Add Certificate Interface & Symantec Plugin\n\nAdding the new Certificate interface and Symantec plugin.\nThis includes unit tests as well as a part of the tasking.\n\nImplements: blueprint add-ssl-ca-support\nChange-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74\n'}]",83,107190,a40ee256b577905c66938469666cf5c242ac28b6,101,18,17,11970,,,0,"Add Certificate Interface & Symantec Plugin

Adding the new Certificate interface and Symantec plugin.
This includes unit tests as well as a part of the tasking.

Implements: blueprint add-ssl-ca-support
Change-Id: Ieb207f91c8251d8ec6601fa113f2501869382e74
",git fetch https://review.opendev.org/openstack/barbican refs/changes/90/107190/8 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/plugin/symantec.py', 'barbican/plugin/interface/certificates.py', 'barbican/tests/plugin/test_symantec.py']",3,12a7d520499002a1d08afeaf554eecb144d56213,bp/add-ssl-ca-support,"# Copyright (c) 2013-2014 Rackspace, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import mock import testtools import barbican.plugin.symantec as sym class WhenTestingSymantecPlugin(testtools.TestCase): def setUp(self): super(WhenTestingSymantecPlugin, self).setUp() #TODO(chellygel) Mock data? #Is a CSR provided or are we generating one? self.order_meta = { 'cert_type': 'ssl123', 'organization': 'Shinra Corp', 'phone': '555-555-5555', 'so many things...': 'more...' } self.event_publisher = mock.MagicMock() self.cert_store = mock.MagicMock() self.tasking = mock.MagicMock() self.error_msg = 'Error Message Here' self.symantec = sym.SymantecCertificatePlugin() @mock.patch('barbican.plugin.symantec._ca_create_order') def test_successful_initial_order(self, mock_ca_create_order): mock_ca_create_order.return_value = (True, None, None) order_id = '1234' plugin_meta = dict() self.symantec.initiate_order( order_id, self.order_meta, plugin_meta, self.event_publisher, self.cert_store, self.tasking ) self.event_publisher.notify_ca_order_sent.assert_called_once_with() @mock.patch('barbican.plugin.symantec._ca_create_order') def test_unsuccessful_initial_order_can_retry(self, mock_ca_create_order): mock_ca_create_order.return_value = (False, self.error_msg, True) order_id = '1234' plugin_meta = dict() self.symantec.initiate_order( order_id, self.order_meta, plugin_meta, self.event_publisher, self.cert_store, self.tasking ) self.event_publisher.notify_issue_with_certificate_authority\ .assert_called_once_with(self.error_msg, True) @mock.patch('barbican.plugin.symantec._ca_create_order') def test_unsuccessful_initial_order_without_retry(self, mock_ca_create_order): mock_ca_create_order.return_value = (False, self.error_msg, False) order_id = '1234' plugin_meta = dict() self.symantec.initiate_order( order_id, self.order_meta, plugin_meta, self.event_publisher, self.cert_store, self.tasking ) self.event_publisher.notify_issue_with_certificate_authority\ .assert_called_once_with(self.error_msg, False) def test_should_raise_unsupported_initial_order(self): order_id = '1234' plugin_meta = dict() self.assertRaises( NotImplementedError, self.symantec.request_order_status, order_id, self.order_meta, plugin_meta, self.event_publisher, self.cert_store, self.tasking ) ",,564,4
openstack%2Ftripleo-image-elements~master~Ica4ef7ad6b4356f7f8e987465d29c46a5a95b1e2,openstack/tripleo-image-elements,master,Ica4ef7ad6b4356f7f8e987465d29c46a5a95b1e2,Add passthrough to etc/swift.conf,MERGED,2014-07-25 11:59:50.000000000,2014-08-08 20:39:55.000000000,2014-08-08 20:39:55.000000000,"[{'_account_id': 3}, {'_account_id': 1253}, {'_account_id': 6928}, {'_account_id': 6969}, {'_account_id': 7134}, {'_account_id': 7144}, {'_account_id': 7471}, {'_account_id': 8532}, {'_account_id': 10373}]","[{'number': 1, 'created': '2014-07-25 11:59:50.000000000', 'files': ['elements/swift/os-apply-config/etc/swift/swift.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/97ecaef2b3ea5034d3c73e99b54d9dd4b98a449a', 'message': 'Add passthrough to etc/swift.conf\n\nAllowing passthrough to be used to add swift storage policies.\n\nChange-Id: Ica4ef7ad6b4356f7f8e987465d29c46a5a95b1e2\n'}]",0,109558,97ecaef2b3ea5034d3c73e99b54d9dd4b98a449a,33,9,1,1253,,,0,"Add passthrough to etc/swift.conf

Allowing passthrough to be used to add swift storage policies.

Change-Id: Ica4ef7ad6b4356f7f8e987465d29c46a5a95b1e2
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/58/109558/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/swift/os-apply-config/etc/swift/swift.conf'],1,97ecaef2b3ea5034d3c73e99b54d9dd4b98a449a,passthrough-in-swift-conf, {{#swift}} {{#config}} [{{{section}}}] {{#values}} {{#comment}} # {{{.}}} {{/comment}} {{#option}} {{{option}}} = {{{value}}} {{/option}} {{/values}} {{/config}} {{/swift}},,15,0
openstack%2Fpython-muranoclient~master~I905bfb80642bfe19d7ebbdeb0fb8aaa92baefeb2,openstack/python-muranoclient,master,I905bfb80642bfe19d7ebbdeb0fb8aaa92baefeb2,Convert muranoclient to 'requests',MERGED,2014-07-30 20:42:36.000000000,2014-08-08 20:24:58.000000000,2014-08-08 20:24:57.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7227}, {'_account_id': 7600}, {'_account_id': 8824}]","[{'number': 1, 'created': '2014-07-30 20:42:36.000000000', 'files': ['muranoclient/tests/test_common_http.py', 'muranoclient/v1/environments.py', 'muranoclient/tests/fakes.py', 'muranoclient/common/exceptions.py', 'muranoclient/tests/test_methods.py', 'muranoclient/common/base.py', 'muranoclient/v1/packages.py', 'muranoclient/common/http.py'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/92b76428820c529dd26bb1e90449f43dc3989970', 'message': ""Convert muranoclient to 'requests'\n\nConverts common/http.py to use requests, and adds unit tests. Most\nof the code and tests were lifted from Heat (tests translated from\nmox to mocks).\n\nBecause requests uses 'data' as its attribute for passing data to\nrequests, all uses of 'body' (for requests, not responses) have been\nconverted to use 'data'. This creates an incompatibility where 'body'\nis explicitly passed to managers but these should be very rare. If\n'body' is used, it will be converted to 'data' and a deprecation\nwarning issued.\n\nChange-Id: I905bfb80642bfe19d7ebbdeb0fb8aaa92baefeb2\nCloses-Bug: 1326804\n""}]",0,110781,92b76428820c529dd26bb1e90449f43dc3989970,22,6,1,10063,,,0,"Convert muranoclient to 'requests'

Converts common/http.py to use requests, and adds unit tests. Most
of the code and tests were lifted from Heat (tests translated from
mox to mocks).

Because requests uses 'data' as its attribute for passing data to
requests, all uses of 'body' (for requests, not responses) have been
converted to use 'data'. This creates an incompatibility where 'body'
is explicitly passed to managers but these should be very rare. If
'body' is used, it will be converted to 'data' and a deprecation
warning issued.

Change-Id: I905bfb80642bfe19d7ebbdeb0fb8aaa92baefeb2
Closes-Bug: 1326804
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/81/110781/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranoclient/tests/test_common_http.py', 'muranoclient/v1/environments.py', 'muranoclient/tests/fakes.py', 'muranoclient/common/exceptions.py', 'muranoclient/tests/test_methods.py', 'muranoclient/common/base.py', 'muranoclient/v1/packages.py', 'muranoclient/common/http.py']",8,92b76428820c529dd26bb1e90449f43dc3989970,bug/1326804," import requests import six from six.moves.urllib import parsefrom muranoclient.openstack.common import jsonutilsdef get_system_ca_file(): """"""Return path to system default CA file."""""" # Standard CA file locations for Debian/Ubuntu, RedHat/Fedora, # Suse, FreeBSD/OpenBSD, MacOSX, and the bundled ca ca_path = ['/etc/ssl/certs/ca-certificates.crt', '/etc/pki/tls/certs/ca-bundle.crt', '/etc/ssl/ca-bundle.pem', '/etc/ssl/cert.pem', '/System/Library/OpenSSL/certs/cacert.pem', requests.certs.where()] for ca in ca_path: LOG.debug(""Looking for ca file %s"", ca) if os.path.exists(ca): LOG.debug(""Using ca file %s"", ca) return ca LOG.warn(""System ca file could not be found."") self.auth_url = kwargs.get('auth_url') self.username = kwargs.get('username') self.password = kwargs.get('password') self.region_name = kwargs.get('region_name') self.include_pass = kwargs.get('include_pass') self.endpoint_url = endpoint self.cert_file = kwargs.get('cert_file') self.key_file = kwargs.get('key_file') self.timeout = kwargs.get('timeout') self.ssl_connection_params = { 'ca_file': kwargs.get('ca_file'), 'cert_file': kwargs.get('cert_file'), 'key_file': kwargs.get('key_file'), 'insecure': kwargs.get('insecure'), } self.verify_cert = None if parse.urlparse(endpoint).scheme == ""https"": if kwargs.get('insecure'): self.verify_cert = False else: self.verify_cert = kwargs.get('ca_file', get_system_ca_file()) header = '-H \'%s: %s\'' % (strutils.safe_decode(key), strutils.safe_decode(value)) ('ca_file', '--cacert %s'), value = self.ssl_connection_params.get(key) if self.ssl_connection_params.get('insecure'): if 'data' in kwargs: curl.append('-d \'%s\'' % kwargs['data']) LOG.debug(' '.join(curl)) def log_http_response(resp): status = (resp.raw.version / 10.0, resp.status_code, resp.reason) dump.extend(['%s: %s' % (k, v) for k, v in resp.headers.items()]) if resp.content: content = resp.content if isinstance(content, six.binary_type): content = content.decode() dump.extend([content, '']) LOG.debug('\n'.join(dump)) Wrapper around requests.request to handle tasks such else: kwargs['headers'].update(self.credentials_headers()) if self.auth_url: kwargs['headers'].setdefault('X-Auth-Url', self.auth_url) if self.region_name: kwargs['headers'].setdefault('X-Region-Name', self.region_name) if self.cert_file and self.key_file: kwargs['cert'] = (self.cert_file, self.key_file) if self.verify_cert is not None: kwargs['verify'] = self.verify_cert if self.timeout is not None: kwargs['timeout'] = float(self.timeout) # Allow the option not to follow redirects follow_redirects = kwargs.pop('follow_redirects', True) # Since requests does not follow the RFC when doing redirection to sent # back the same method on a redirect we are simply bypassing it. For # example if we do a DELETE/POST/PUT on a URL and we get a 302 RFC says # that we should follow that URL with the same method as before, # requests doesn't follow that and send a GET instead for the method. # Hopefully this could be fixed as they say in a comment in a future # point version i.e.: 3.x # See issue: https://github.com/kennethreitz/requests/issues/1704 allow_redirects = False resp = requests.request( method, self.endpoint_url + url, allow_redirects=allow_redirects, **kwargs) except socket.gaierror as e: message = (""Error finding address for %(url)s: %(e)s"" % {'url': self.endpoint_url + url, 'e': e}) message = (""Error communicating with %(endpoint)s %(e)s"" % {'endpoint': endpoint, 'e': e}) self.log_http_response(resp) if not 'X-Auth-Key' in kwargs['headers'] and \ (resp.status_code == 401 or (resp.status_code == 500 and ""(HTTP 401)"" in resp.content)): raise exc.HTTPUnauthorized(""Authentication failed. Please try"" "" again.\n%s"" % resp.content) elif 400 <= resp.status_code < 600: raise exc.from_response(resp) elif resp.status_code in (301, 302, 305): # Redirected. Reissue the request to the new location, # unless caller specified follow_redirects=False if follow_redirects: location = resp.headers.get('location') path = self.strip_endpoint(location) resp = self._http_request(path, method, **kwargs) elif resp.status_code == 300: return resp def strip_endpoint(self, location): if location is None: message = ""Location not returned with 302"" raise exc.InvalidEndpoint(message=message) elif location.startswith(self.endpoint): return location[len(self.endpoint):] else: message = ""Prohibited endpoint redirect %s"" % location raise exc.InvalidEndpoint(message=message) def credentials_headers(self): creds = {} if self.username: creds['X-Auth-User'] = self.username if self.password: creds['X-Auth-Key'] = self.password return creds def json_request(self, method, url, content_type='application/json', **kwargs): # Don't set Accept because we aren't always dealing in JSON if 'data' in kwargs: raise ValueError(""Can't provide both 'data' and "" ""'body' to a request"") LOG.warning(""Use of 'body' is deprecated; use 'data' instead"") kwargs['data'] = kwargs.pop('body') if 'data' in kwargs: kwargs['data'] = jsonutils.dumps(kwargs['data']) resp = self._http_request(url, method, **kwargs) body = resp.content if 'application/json' in resp.headers.get('content-type', None): try: body = resp.json() return self.json_request( if 'data' in kwargs: raise ValueError(""Can't provide both 'data' and "" ""'body' to a request"") LOG.warning(""Use of 'body' is deprecated; use 'data' instead"") kwargs['data'] = kwargs.pop('body') # Chunking happens automatically if 'body' is a # file-like object def client_request(self, method, url, **kwargs): resp, body = self.json_request(method, url, **kwargs) return resp def head(self, url, **kwargs): return self.client_request(""HEAD"", url, **kwargs) def get(self, url, **kwargs): return self.client_request(""GET"", url, **kwargs) def post(self, url, **kwargs): return self.client_request(""POST"", url, **kwargs) def put(self, url, **kwargs): return self.client_request(""PUT"", url, **kwargs) def delete(self, url, **kwargs): return self.raw_request(""DELETE"", url, **kwargs) def patch(self, url, **kwargs): return self.client_request(""PATCH"", url, **kwargs)","import errno import hashlibimport posixpath from six.moves.urllib import parseimport struct import sys if sys.version_info >= (3, 0): import http.client as httplib import io as StringIO import urllib.parse as urlparse else: import httplib import StringIO import urlparse # Python 2.5 compat fix if not hasattr(urlparse, 'parse_qsl'): import cgi urlparse.parse_qsl = cgi.parse_qsl try: import json except ImportError: import simplejson as json import OpenSSLfrom muranoclient.common import utilstry: from eventlet import patcher # Handle case where we are running in a monkey patched environment if patcher.is_monkey_patched('socket'): from eventlet.green.httplib import HTTPSConnection # noqa from eventlet.green.OpenSSL.SSL import GreenConnection as Connection from eventlet.greenio import GreenSocket # noqa # TODO(mclaren): A getsockopt workaround: see 'getsockopt' doc string GreenSocket.getsockopt = utils.getsockopt else: raise ImportError except ImportError: if sys.version_info >= (3, 0): from http.client import HTTPSConnection else: from httplib import HTTPSConnection # noqa from OpenSSL.SSL import Connection as Connection # noqa endpoint_parts = self.parse_endpoint(self.endpoint) self.endpoint_scheme = endpoint_parts.scheme self.endpoint_hostname = endpoint_parts.hostname self.endpoint_port = endpoint_parts.port self.endpoint_path = endpoint_parts.path self.connection_class = self.get_connection_class(self.endpoint_scheme) self.connection_kwargs = self.get_connection_kwargs( self.endpoint_scheme, **kwargs) self.identity_headers = kwargs.get('identity_headers') if self.identity_headers: if self.identity_headers.get('X-Auth-Token'): self.auth_token = self.identity_headers.get('X-Auth-Token') del self.identity_headers['X-Auth-Token'] self.proxy_url = self.get_proxy_url() @staticmethod def parse_endpoint(endpoint): return urlparse.urlparse(endpoint) @staticmethod def get_connection_class(scheme): if scheme == 'https': return VerifiedHTTPSConnection else: return httplib.HTTPConnection @staticmethod def get_connection_kwargs(scheme, **kwargs): _kwargs = {'timeout': float(kwargs.get('timeout', 600))} if scheme == 'https': _kwargs['cacert'] = kwargs.get('cacert', None) _kwargs['cert_file'] = kwargs.get('cert_file', None) _kwargs['key_file'] = kwargs.get('key_file', None) _kwargs['insecure'] = kwargs.get('insecure', False) _kwargs['ssl_compression'] = kwargs.get('ssl_compression', True) return _kwargs def get_connection(self): _class = self.connection_class try: if self.proxy_url: proxy_parts = parse.urlparse(self.proxy_url) return _class(proxy_parts.hostname, proxy_parts.port, **self.connection_kwargs) else: return _class(self.endpoint_hostname, self.endpoint_port, **self.connection_kwargs) except httplib.InvalidURL: raise exc.InvalidEndpoint() header = '-H \'%s: %s\'' % (key, value) ('cacert', '--cacert %s'), value = self.connection_kwargs.get(key) if self.connection_kwargs.get('insecure'): if kwargs.get('body') is not None: curl.append('-d \'%s\'' % kwargs['body']) LOG.debug(strutils.safe_encode(' '.join(curl))) def log_http_response(resp, body=None): status = (resp.version / 10.0, resp.status, resp.reason) dump.extend(['%s: %s' % (k, v) for k, v in resp.getheaders()]) if body: dump.extend([body, '']) LOG.debug(strutils.safe_encode('\n'.join(dump))) @staticmethod def encode_headers(headers): """"""Encodes headers. Note: This should be used right before sending anything out. :param headers: Headers to encode :returns: Dictionary with encoded headers' names and values """""" to_str = strutils.safe_encode return dict([(to_str(h), to_str(v)) for h, v in headers.iteritems()]) Wrapper around httplib.HTTP(S)Connection.request to handle tasks such if self.identity_headers: for k, v in self.identity_headers.iteritems(): kwargs['headers'].setdefault(k, v) conn = self.get_connection() # Note(flaper87): Before letting headers / url fly, # they should be encoded otherwise httplib will # complain. If we decide to rely on python-request # this wont be necessary anymore. kwargs['headers'] = self.encode_headers(kwargs['headers']) if self.proxy_url: url = '{0}/{1}'.format(self.endpoint, url) elif self.endpoint_path: url = '{0}/{1}'.format(self.endpoint_path, url) conn_url = posixpath.normpath(url) # Note(flaper87): Ditto, headers / url # encoding to make httplib happy. conn_url = strutils.safe_encode(conn_url) if kwargs['headers'].get('Transfer-Encoding') == 'chunked': conn.putrequest(method, conn_url) for header, value in kwargs['headers'].items(): conn.putheader(header, value) conn.endheaders() chunk = kwargs['body'].read(CHUNKSIZE) # Chunk it, baby... while chunk: conn.send('%x\r\n%s\r\n' % (len(chunk), chunk)) chunk = kwargs['body'].read(CHUNKSIZE) conn.send('0\r\n\r\n') else: conn.request(method, conn_url, **kwargs) resp = conn.getresponse() except socket.gaierror as e: message = ""Error finding address for %s: %s"" % ( self.endpoint_hostname, e) message = ""Error communicating with %s %s"" % (endpoint, e) body_iter = ResponseBodyIterator(resp) # Read body into string if it isn't obviously image data if resp.getheader('content-type', None) != 'application/octet-stream': body_str = ''.join([chunk for chunk in body_iter]) self.log_http_response(resp, body_str) body_iter = StringIO.StringIO(body_str) else: self.log_http_response(resp) if 400 <= resp.status < 600: LOG.error(""Request returned failure status."") raise exc.from_response(resp, body_str) elif resp.status in (301, 302, 305): # Redirected. Reissue the request to the new location. return self._http_request(resp['location'], method, **kwargs) elif resp.status == 300: return resp, body_iter def base_json_request(self, method, url, content_type='application/json', **kwargs): kwargs['body'] = json.dumps(kwargs['body']) resp, body_iter = self._http_request(url, method, **kwargs) if 'application/json' in resp.getheader('content-type', None): body = ''.join([chunk for chunk in body_iter]) try: body = json.loads(body) def json_request(self, method, url, **kwargs): return self.base_json_request(method, url, **kwargs) return self.base_json_request( if (hasattr(kwargs['body'], 'read') and method.lower() in ('post', 'put')): # We use 'Transfer-Encoding: chunked' because # body size may not always be known in advance. kwargs['headers']['Transfer-Encoding'] = 'chunked' def get_proxy_url(self): scheme = parse.urlparse(self.endpoint).scheme if scheme == 'https': return (os.environ.get('HTTPS_PROXY') or os.environ.get('https_proxy')) elif scheme == 'http': return (os.environ.get('HTTP_PROXY') or os.environ.get('http_proxy')) msg = 'Unsupported scheme: {0} ({1})'.format(scheme, self.endpoint) raise exc.InvalidEndpoint(msg) class OpenSSLConnectionDelegator(object): """"""An OpenSSL.SSL.Connection delegator. Supplies an additional 'makefile' method which httplib requires and is not present in OpenSSL.SSL.Connection. Note: Since it is not possible to inherit from OpenSSL.SSL.Connection a delegator must be used. """""" def __init__(self, *args, **kwargs): self.connection = Connection(*args, **kwargs) def __getattr__(self, name): return getattr(self.connection, name) def makefile(self, *args, **kwargs): # Making sure socket is closed when this file is closed # since we now avoid closing socket on connection close # see new close method under VerifiedHTTPSConnection kwargs['close'] = True return socket._fileobject(self.connection, *args, **kwargs) class VerifiedHTTPSConnection(HTTPSConnection): """"""Extended HTTPSConnection which uses the OpenSSL library for enhanced SSL support. Note: Much of this functionality can eventually be replaced with native Python 3.3 code. """""" def __init__(self, host, port=None, key_file=None, cert_file=None, cacert=None, timeout=None, insecure=False, ssl_compression=True): HTTPSConnection.__init__(self, host, port, key_file=key_file, cert_file=cert_file) self.key_file = key_file self.cert_file = cert_file self.timeout = timeout self.insecure = insecure self.ssl_compression = ssl_compression self.cacert = cacert self.setcontext() @staticmethod def host_matches_cert(host, x509): """"""Verify that the the x509 certificate we have received from 'host' correctly identifies the server we are connecting to, ie that the certificate's Common Name or a Subject Alternative Name matches 'host'. """""" common_name = x509.get_subject().commonName # First see if we can match the CN if common_name == host: return True # Support single wildcard matching if common_name.startswith('*.') and host.find('.') > 0: if common_name[2:] == host.split('.', 1)[1]: return True # Also try Subject Alternative Names for a match san_list = None for i in xrange(x509.get_extension_count()): ext = x509.get_extension(i) if ext.get_short_name() == 'subjectAltName': san_list = str(ext) for san in ''.join(san_list.split()).split(','): if san == ""DNS:%s"" % host: return True # Server certificate does not match host msg = ('Host ""%s"" does not match x509 certificate contents: ' 'CommonName ""%s""' % (host, x509.get_subject().commonName)) if san_list is not None: msg = msg + ', subjectAltName ""%s""' % san_list raise exc.SSLCertificateError(msg) def verify_callback(self, connection, x509, errnum, depth, preverify_ok): # NOTE(leaman): preverify_ok may be a non-boolean type preverify_ok = bool(preverify_ok) if x509.has_expired(): msg = ""SSL Certificate expired on '%s'"" % x509.get_notAfter() raise exc.SSLCertificateError(msg) if depth == 0 and preverify_ok: # We verify that the host matches against the last # certificate in the chain return self.host_matches_cert(self.host, x509) else: # Pass through OpenSSL's default result return preverify_ok def setcontext(self): """"""Set up the OpenSSL context."""""" self.context = OpenSSL.SSL.Context(OpenSSL.SSL.SSLv23_METHOD) if self.ssl_compression is False: self.context.set_options(0x20000) # SSL_OP_NO_COMPRESSION if self.insecure is not True: self.context.set_verify(OpenSSL.SSL.VERIFY_PEER, self.verify_callback) else: self.context.set_verify(OpenSSL.SSL.VERIFY_NONE, lambda *args: True) if self.cert_file: try: self.context.use_certificate_file(self.cert_file) except Exception as e: msg = 'Unable to load cert from ""%s"" %s' % (self.cert_file, e) raise exc.SSLConfigurationError(msg) if self.key_file is None: # We support having key and cert in same file try: self.context.use_privatekey_file(self.cert_file) except Exception as e: msg = ('No key file specified and unable to load key ' 'from ""%s"" %s' % (self.cert_file, e)) raise exc.SSLConfigurationError(msg) if self.key_file: try: self.context.use_privatekey_file(self.key_file) except Exception as e: msg = 'Unable to load key from ""%s"" %s' % (self.key_file, e) raise exc.SSLConfigurationError(msg) if self.cacert: try: self.context.load_verify_locations(self.cacert) except Exception as e: msg = 'Unable to load CA from ""%s""' % (self.cacert, e) raise exc.SSLConfigurationError(msg) else: self.context.set_default_verify_paths() def connect(self): """"""Connect to an SSL port using the OpenSSL library and apply per-connection parameters. """""" sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) if self.timeout is not None: # '0' microseconds sock.setsockopt(socket.SOL_SOCKET, socket.SO_RCVTIMEO, struct.pack('fL', self.timeout, 0)) self.sock = OpenSSLConnectionDelegator(self.context, sock) self.sock.connect((self.host, self.port)) def close(self): if self.sock: # Removing reference to socket but don't close it yet. # Response close will close both socket and associated # file. Closing socket too soon will cause response # reads to fail with socket IO error 'Bad file descriptor'. self.sock = None # Calling close on HTTPConnection to continue doing that cleanup. HTTPSConnection.close(self) class ResponseBodyIterator(object): """"""A class that acts as an iterator over an HTTP response. This class will also check response body integrity when iterating over the instance and if a checksum was supplied using `set_checksum` method, else by default the class will not do any integrity check. """""" def __init__(self, resp): self._resp = resp self._checksum = None self._size = int(resp.getheader('content-length', 0)) self._end_reached = False def set_checksum(self, checksum): """"""Set checksum to check against when iterating over this instance. :raise: AttributeError if iterator is already consumed. """""" if self._end_reached: raise AttributeError(""Can't set checksum for an already consumed"" "" iterator"") self._checksum = checksum def __len__(self): return int(self._size) def __iter__(self): md5sum = hashlib.md5() while True: try: chunk = self.next() except StopIteration: self._end_reached = True # NOTE(mouad): Check image integrity when the end of response # body is reached. md5sum = md5sum.hexdigest() if self._checksum is not None and md5sum != self._checksum: raise IOError(errno.EPIPE, 'Corrupted image. Checksum was %s ' 'expected %s' % (md5sum, self._checksum)) raise else: yield chunk md5sum.update(chunk) def next(self): chunk = self._resp.read(CHUNKSIZE) if chunk: return chunk else: raise StopIteration()",708,433
openstack%2Fironic~master~I52fc73117c8fa57e67c5dad142a39170e8117b23,openstack/ironic,master,I52fc73117c8fa57e67c5dad142a39170e8117b23,Add option to allow soft power off,ABANDONED,2014-07-17 17:25:23.000000000,2014-08-08 20:24:19.000000000,,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 6773}, {'_account_id': 7711}]","[{'number': 1, 'created': '2014-07-17 17:25:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a4441de9649b18bd7b301de3b3e763d153f1d754', 'message': ""Add option to allow soft power off\n\nIronic's current ipmi power off old supports hard power off. This\nthis patch add a conf option to allow soft power off's. This is needed\nfor databases and other applacations that do not like to be hard powered\noff.\n\nChange-Id: I52fc73117c8fa57e67c5dad142a39170e8117b23\n""}, {'number': 2, 'created': '2014-07-17 17:41:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7301f7e639615f609750811fd7089bde68736442', 'message': ""Add option to allow soft power off\n\nIronic's current ipmi power off old supports hard power off. This\nthis patch add a conf option to allow soft power off's. This is needed\nfor databases and other applacations that do not like to be hard powered\noff.\n\nChange-Id: I52fc73117c8fa57e67c5dad142a39170e8117b23\n""}, {'number': 3, 'created': '2014-07-21 13:20:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3899f8c173a1719d48a05e83d7907de4ca641e7f', 'message': ""Add option to allow soft power off\n\nIronic's current ipmi power off old supports hard power off. This\nthis patch add a conf option to allow soft power off's. This is needed\nfor databases and other applacations that do not like to be hard powered\noff.\n\nChange-Id: I52fc73117c8fa57e67c5dad142a39170e8117b23\n""}, {'number': 4, 'created': '2014-07-21 15:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0b9b4cb4b26eef5160a53c6feb8195569ab9caab', 'message': ""Add option to allow soft power off\n\nIronic's current ipmi power off old supports hard power off. This\nthis patch add a conf option to allow soft power off's. This is needed\nfor databases and other applacations that do not like to be hard powered\noff.\n\nChange-Id: I52fc73117c8fa57e67c5dad142a39170e8117b23\n""}, {'number': 5, 'created': '2014-07-21 18:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7947d348f914f3b868eb28d9ce326dd7898c53a9', 'message': ""Add option to allow soft power off\n\nIronic's current ipmi power off old supports hard power off. This\nthis patch add a conf option to allow soft power off's. This is needed\nfor databases and other applacations that do not like to be hard powered\noff.\n\nChange-Id: I52fc73117c8fa57e67c5dad142a39170e8117b23\n""}, {'number': 6, 'created': '2014-07-22 13:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a9beafa5818291254816e30ee746225aa520b455', 'message': ""Add option to allow soft power off\n\nIronic's current ipmi power off only supports hard power off. This\nthis patch adds a conf option to allow soft power off's. This is\nneeded for databases and other applacations that do not like to be\nhard powered off.\n\nChange-Id: I52fc73117c8fa57e67c5dad142a39170e8117b23\n""}, {'number': 7, 'created': '2014-07-22 14:13:10.000000000', 'files': ['etc/ironic/ironic.conf.sample', 'ironic/drivers/modules/ipmitool.py', 'ironic/drivers/modules/ipminative.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/5cbbefe0c24896293ceb6a767fbe72ecc4a58313', 'message': ""Add option to allow soft power off\n\nIronic's current ipmi power off only supports hard power off. This\nthis patch adds a conf option to allow soft power off's. This is\nneeded for databases and other applacations that do not like to be\nhard powered off.\n\nChange-Id: I52fc73117c8fa57e67c5dad142a39170e8117b23\n""}]",5,107778,5cbbefe0c24896293ceb6a767fbe72ecc4a58313,37,4,7,5805,,,0,"Add option to allow soft power off

Ironic's current ipmi power off only supports hard power off. This
this patch adds a conf option to allow soft power off's. This is
needed for databases and other applacations that do not like to be
hard powered off.

Change-Id: I52fc73117c8fa57e67c5dad142a39170e8117b23
",git fetch https://review.opendev.org/openstack/ironic refs/changes/78/107778/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/ironic/ironic.conf.sample', 'ironic/drivers/modules/ipmitool.py', 'ironic/drivers/modules/ipminative.py']",3,a4441de9649b18bd7b301de3b3e763d153f1d754,softpower," cfg.BoolOpt('soft_power_down', default=False, help='Use soft powerdown for rebuilds.'),",,14,1
openstack%2Fheat~master~Icb37344c64c21bcac536e8f2916b102eb9754851,openstack/heat,master,Icb37344c64c21bcac536e8f2916b102eb9754851,Parse RST in plug-in class docs,MERGED,2014-07-10 23:13:29.000000000,2014-08-08 20:23:45.000000000,2014-08-08 20:23:43.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 6488}, {'_account_id': 7256}, {'_account_id': 7404}]","[{'number': 1, 'created': '2014-07-10 23:13:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/dcf53e7f16a12f07153d0515937c46a7f300451e', 'message': 'Parse RST in plug-in class docs\n\nIn order to make the generated documentation for resource plug-ins more\nreadable, parse the class comments as RST and append to the section.\n\nChange-Id: Icb37344c64c21bcac536e8f2916b102eb9754851\n'}, {'number': 2, 'created': '2014-07-29 21:39:45.000000000', 'files': ['doc/source/ext/resources.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/6367aab293e600dd6865d9d77b6590c78d260415', 'message': 'Parse RST in plug-in class docs\n\nIn order to make the generated documentation for resource plug-ins more\nreadable, parse the class comments as RST and append to the section.\n\nChange-Id: Icb37344c64c21bcac536e8f2916b102eb9754851\n'}]",0,106198,6367aab293e600dd6865d9d77b6590c78d260415,19,5,2,7256,,,0,"Parse RST in plug-in class docs

In order to make the generated documentation for resource plug-ins more
readable, parse the class comments as RST and append to the section.

Change-Id: Icb37344c64c21bcac536e8f2916b102eb9754851
",git fetch https://review.opendev.org/openstack/heat refs/changes/98/106198/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/ext/resources.py'],1,dcf53e7f16a12f07153d0515937c46a7f300451e,bp/override-resource-name-in-resource-group,from docutils import core # allow for rst in the class comments cls_nodes = core.publish_doctree(cls_doc).children section.extend(cls_nodes)," para = nodes.paragraph('', cls_doc) section.append(para)",4,2
openstack%2Ffuel-specs~master~I583a967bafc7451fcf7d782c6b86f1da10f334e2,openstack/fuel-specs,master,I583a967bafc7451fcf7d782c6b86f1da10f334e2,Blueprint: galera-improvements,MERGED,2014-07-14 07:37:02.000000000,2014-08-08 20:12:05.000000000,2014-08-08 20:12:05.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 10489}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-07-14 07:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/67f841b10ddcac16018ba8f2e52f9f576581c7de', 'message': 'Blueprint: galera-improvements\n\nChange-Id: I583a967bafc7451fcf7d782c6b86f1da10f334e2\n'}, {'number': 2, 'created': '2014-07-22 10:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/b0f7171c3478a68702ac3bbfea79aa48cddd8066', 'message': 'Blueprint: galera-improvements\n\nChange-Id: I583a967bafc7451fcf7d782c6b86f1da10f334e2\n'}, {'number': 3, 'created': '2014-08-08 17:35:17.000000000', 'files': ['specs/5.1/galera-improvements.rst'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/27180939f35fdf0f1a6f4df828287185127908ad', 'message': 'Blueprint: galera-improvements\n\nChange-Id: I583a967bafc7451fcf7d782c6b86f1da10f334e2\n'}]",1,106699,27180939f35fdf0f1a6f4df828287185127908ad,21,10,3,11090,,,0,"Blueprint: galera-improvements

Change-Id: I583a967bafc7451fcf7d782c6b86f1da10f334e2
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/99/106699/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/5.1/galera-improvements.rst'],1,67f841b10ddcac16018ba8f2e52f9f576581c7de,bp/galera-improvements,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================= Improve Galera Cluster Management ================================= https://blueprints.launchpad.net/fuel/+spec/galera-improvements [1]_ Problem description =================== Galera Cluster implementation has some issues when a new controller is added to the cluster. This case usually happens during cluster deployment or new member addition. Here are the issues in current implementation of Galera Cluster Management: - Current implementation uses mysqldump as State Snapshot Transfer (SST) which blocks ""Donor"" during the `process <http://galeracluster.com/documentation-webpages/nodeprovisioning.html #comparison-of-state-snapshot-transfer-methods>`_. Donor is locked while mysqldump is running during State Snapshot Transfer (SST). Due to this it's not possible to deploy Fuel Controllers in parallel, as Primary Controller can perform SST with one controller only. All other controllers won't be able to synchronize their state with Primary Controller. - Haproxy doesnt detect whether controlleris out of sync during SST/IST. It's not a problem during the deployment, but it may be a significant problem on new controller addition. Proposed change =============== - Use **xtrabackup-v2** as a default method for SST. - Use Percona's HAProxy `clustercheck script <https://github.com/olafz/percona-clustercheck/blob/master/clustercheck>`_ Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Upgrade impact -------------- Security impact --------------- Port 49000 will be opened. Anyone will be able to obtain the status of Galera Cluster. Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ During normal operations the perfomance will be the same. On new controller addition the perfomance will be improved as ""xtrabackup"" won't lock donor and faster than mysqldump SST method Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== None Assignee(s) ----------- Primary assignee: sgolovatiuk@mirantis.com Work Items ---------- None Dependencies ============ None Testing ======= None Documentation Impact ==================== None References ========== .. [1] https://blueprints.launchpad.net/fuel/+spec/galera-improvements ",,129,0
openstack%2Fhorizon~master~If0274b9dfcb9582a8e99735eb4e2f3e09b06f977,openstack/horizon,master,If0274b9dfcb9582a8e99735eb4e2f3e09b06f977,Fixed cannot delete router port because of permission denied.,MERGED,2014-08-05 01:37:43.000000000,2014-08-08 20:11:58.000000000,2014-08-08 20:11:57.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 9576}, {'_account_id': 12237}]","[{'number': 1, 'created': '2014-08-05 01:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/15d820416ea8c8b2b41959501fcfdf26ca386526', 'message': 'Fixed cannot delete router port because of permission denied.\n\nRemoved the condition check in allowed function that is defined in the RemoveInterface class\nwhich makes no sense because it is set in the delete function that runs after allowed function.\n\nChange-Id: If0274b9dfcb9582a8e99735eb4e2f3e09b06f977\nCloses-Bug: #1234447\n'}, {'number': 2, 'created': '2014-08-05 06:23:00.000000000', 'files': ['openstack_dashboard/dashboards/project/routers/ports/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e7774702a18c02874dea60a16de94efae85cdc08', 'message': 'Fixed cannot delete router port because of permission denied.\n\nRemoved the condition check in allowed function that is defined in the RemoveInterface class\nwhich makes no sense because it is set in the delete function that runs after allowed function.\n\nChange-Id: If0274b9dfcb9582a8e99735eb4e2f3e09b06f977\nCloses-Bug: #1234447\n'}]",5,111882,e7774702a18c02874dea60a16de94efae85cdc08,19,6,2,12237,,,0,"Fixed cannot delete router port because of permission denied.

Removed the condition check in allowed function that is defined in the RemoveInterface class
which makes no sense because it is set in the delete function that runs after allowed function.

Change-Id: If0274b9dfcb9582a8e99735eb4e2f3e09b06f977
Closes-Bug: #1234447
",git fetch https://review.opendev.org/openstack/horizon refs/changes/82/111882/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/routers/ports/tables.py'],1,15d820416ea8c8b2b41959501fcfdf26ca386526,master,, if datum and datum['device_owner'] == 'network:router_gateway': return False,0,2
openstack%2Fdevstack~master~I6244040dd2abea016556cd515e06f53edbb993a0,openstack/devstack,master,I6244040dd2abea016556cd515e06f53edbb993a0,Makes vpn plugin configurable,MERGED,2014-07-10 03:23:09.000000000,2014-08-08 20:11:54.000000000,2014-08-08 20:11:54.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 6854}, {'_account_id': 8871}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-10 03:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ffcf6fb67b9ee7d07c533d762dcf8e679af17c86', 'message': 'Makes vpn plugin configurable\n\nCurrently, it is hardcoded and not good for those who have their\nown vpn plugin developed.\n\nChange-Id: I6244040dd2abea016556cd515e06f53edbb993a0\nCloses-bug: 1339977\n'}, {'number': 2, 'created': '2014-08-07 04:07:15.000000000', 'files': ['lib/neutron_plugins/services/vpn'], 'web_link': 'https://opendev.org/openstack/devstack/commit/5988e623c390eef76292870b148ee56230f1a5a1', 'message': 'Makes vpn plugin configurable\n\nCurrently, it is hardcoded and not good for those who have their\nown vpn plugin developed.\n\nChange-Id: I6244040dd2abea016556cd515e06f53edbb993a0\nCloses-bug: 1339977\n'}]",0,105956,5988e623c390eef76292870b148ee56230f1a5a1,22,7,2,2874,,,0,"Makes vpn plugin configurable

Currently, it is hardcoded and not good for those who have their
own vpn plugin developed.

Change-Id: I6244040dd2abea016556cd515e06f53edbb993a0
Closes-bug: 1339977
",git fetch https://review.opendev.org/openstack/devstack refs/changes/56/105956/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron_plugins/services/vpn'],1,ffcf6fb67b9ee7d07c533d762dcf8e679af17c86,bug/1339977,"VPN_PLUGIN=${VPN_PLUGIN:-""neutron.services.vpn.plugin.VPNDriverPlugin""}","VPN_PLUGIN=""neutron.services.vpn.plugin.VPNDriverPlugin""",1,1
openstack%2Ftooz~master~I32409c09153b8abaf2b36c31f0bbf658a9d653bc,openstack/tooz,master,I32409c09153b8abaf2b36c31f0bbf658a9d653bc,Switch to URL for loading backends,MERGED,2014-08-04 13:54:27.000000000,2014-08-08 19:55:55.000000000,2014-08-08 19:55:55.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 7450}, {'_account_id': 8122}, {'_account_id': 9107}]","[{'number': 1, 'created': '2014-08-04 13:54:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/f6545e7be3b8d2a911714fa07d3c499434012c39', 'message': 'Switch to URL for loading backends\n\nThis allow to pass options in a single string, which is going to be\neasier for managing options.\n\nChange-Id: I32409c09153b8abaf2b36c31f0bbf658a9d653bc\n'}, {'number': 2, 'created': '2014-08-04 15:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/1a3e0084e7b0fd70949494f9a8b1c429c29f52c8', 'message': 'Switch to URL for loading backends\n\nThis allow to pass options in a single string, which is going to be\neasier for managing options.\n\nChange-Id: I32409c09153b8abaf2b36c31f0bbf658a9d653bc\n'}, {'number': 3, 'created': '2014-08-04 16:03:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/00926539c8223b0f95d57f78bf33aa139c3cf486', 'message': 'Switch to URL for loading backends\n\nThis allow to pass options in a single string, which is going to be\neasier for managing options.\n\nChange-Id: I32409c09153b8abaf2b36c31f0bbf658a9d653bc\n'}, {'number': 4, 'created': '2014-08-06 15:48:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/6c4e907ebb102d8abcbb59ddae55cd2d6d138b9a', 'message': 'Switch to URL for loading backends\n\nThis allow to pass options in a single string, which is going to be\neasier for managing options.\n\nChange-Id: I32409c09153b8abaf2b36c31f0bbf658a9d653bc\n'}, {'number': 5, 'created': '2014-08-06 16:19:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/557c27e14fac64cca46ed68d8e60e46dfeea74f1', 'message': 'Switch to URL for loading backends\n\nThis allow to pass options in a single string, which is going to be\neasier for managing options.\n\nChange-Id: I32409c09153b8abaf2b36c31f0bbf658a9d653bc\n'}, {'number': 6, 'created': '2014-08-07 14:18:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/52305640f490fc84c3b77014c78e7f2beeb06ef8', 'message': 'Switch to URL for loading backends\n\nThis allow to pass options in a single string, which is going to be\neasier for managing options.\n\nChange-Id: I32409c09153b8abaf2b36c31f0bbf658a9d653bc\n'}, {'number': 7, 'created': '2014-08-07 15:08:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/c5adf60686df4e6226bbb3d94c955f3195a85663', 'message': 'Switch to URL for loading backends\n\nThis allow to pass options in a single string, which is going to be\neasier for managing options.\n\nChange-Id: I32409c09153b8abaf2b36c31f0bbf658a9d653bc\n'}, {'number': 8, 'created': '2014-08-07 16:07:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/6367c67240aa8d4545330eb64863a71af68b898f', 'message': 'Switch to URL for loading backends\n\nThis allow to pass options in a single string, which is going to be\neasier for managing options.\n\nChange-Id: I32409c09153b8abaf2b36c31f0bbf658a9d653bc\n'}, {'number': 9, 'created': '2014-08-07 16:12:59.000000000', 'files': ['examples/coordinator.py', 'tooz/tests/test_coordination.py', 'examples/leader_election.py', 'requirements.txt', 'tooz/drivers/ipc.py', 'tooz/drivers/zookeeper.py', 'examples/group_membership_watch.py', 'examples/group_membership.py', 'tooz/drivers/memcached.py', 'tooz/coordination.py', 'examples/coordinator_heartbeat.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/d38fe0301d991300a29ab09175f110356fe47653', 'message': 'Switch to URL for loading backends\n\nThis allow to pass options in a single string, which is going to be\neasier for managing options.\n\nChange-Id: I32409c09153b8abaf2b36c31f0bbf658a9d653bc\n'}]",0,111737,d38fe0301d991300a29ab09175f110356fe47653,36,7,9,1669,,,0,"Switch to URL for loading backends

This allow to pass options in a single string, which is going to be
easier for managing options.

Change-Id: I32409c09153b8abaf2b36c31f0bbf658a9d653bc
",git fetch https://review.opendev.org/openstack/tooz refs/changes/37/111737/9 && git format-patch -1 --stdout FETCH_HEAD,"['examples/coordinator.py', 'tooz/tests/test_coordination.py', 'examples/leader_election.py', 'tooz/drivers/zookeeper.py', 'examples/group_membership_watch.py', 'examples/group_membership.py', 'tooz/drivers/memcached.py', 'tooz/coordination.py', 'examples/coordinator_heartbeat.py']",9,f6545e7be3b8d2a911714fa07d3c499434012c39,jd/url,"coordinator = coordination.get_coordinator('memcached://localhost', b'host-1')","coordinator = coordination.get_coordinator('memcached', b'host-1')",74,103
openstack%2Ftooz~master~Ic3bc51a6dc3c7ce04405d1f5c1a67a491fcfaa77,openstack/tooz,master,Ic3bc51a6dc3c7ce04405d1f5c1a67a491fcfaa77,Import network_utils from Oslo,MERGED,2014-08-07 14:18:58.000000000,2014-08-08 19:53:08.000000000,2014-08-08 19:53:08.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 7450}]","[{'number': 1, 'created': '2014-08-07 14:18:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/7399e882a54c861136bcf91fa0a3178e72688285', 'message': 'Import network_utils from Oslo\n\nThis to avoid the URL parsing bug in old Python 2.7.\n\nChange-Id: Ic3bc51a6dc3c7ce04405d1f5c1a67a491fcfaa77\n'}, {'number': 2, 'created': '2014-08-07 16:12:59.000000000', 'files': ['tooz/openstack/common/network_utils.py', 'openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/tooz/commit/30588b877a813d1ced820313855dfb9826e2c083', 'message': 'Import network_utils from Oslo\n\nThis to avoid the URL parsing bug in old Python 2.7.\n\nChange-Id: Ic3bc51a6dc3c7ce04405d1f5c1a67a491fcfaa77\n'}]",0,112587,30588b877a813d1ced820313855dfb9826e2c083,13,3,2,1669,,,0,"Import network_utils from Oslo

This to avoid the URL parsing bug in old Python 2.7.

Change-Id: Ic3bc51a6dc3c7ce04405d1f5c1a67a491fcfaa77
",git fetch https://review.opendev.org/openstack/tooz refs/changes/87/112587/2 && git format-patch -1 --stdout FETCH_HEAD,"['tooz/openstack/common/network_utils.py', 'tooz/openstack/common/__init__.py', 'tooz/openstack/__init__.py', 'openstack-common.conf', 'tooz/openstack/common/gettextutils.py']",5,7399e882a54c861136bcf91fa0a3178e72688285,jd/url,"# Copyright 2012 Red Hat, Inc. # Copyright 2013 IBM Corp. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" gettext for openstack-common modules. Usual usage in an openstack.common module: from tooz.openstack.common.gettextutils import _ """""" import copy import gettext import locale from logging import handlers import os from babel import localedata import six _AVAILABLE_LANGUAGES = {} # FIXME(dhellmann): Remove this when moving to oslo.i18n. USE_LAZY = False class TranslatorFactory(object): """"""Create translator functions """""" def __init__(self, domain, localedir=None): """"""Establish a set of translation functions for the domain. :param domain: Name of translation domain, specifying a message catalog. :type domain: str :param lazy: Delays translation until a message is emitted. Defaults to False. :type lazy: Boolean :param localedir: Directory with translation catalogs. :type localedir: str """""" self.domain = domain if localedir is None: localedir = os.environ.get(domain.upper() + '_LOCALEDIR') self.localedir = localedir def _make_translation_func(self, domain=None): """"""Return a new translation function ready for use. Takes into account whether or not lazy translation is being done. The domain can be specified to override the default from the factory, but the localedir from the factory is always used because we assume the log-level translation catalogs are installed in the same directory as the main application catalog. """""" if domain is None: domain = self.domain t = gettext.translation(domain, localedir=self.localedir, fallback=True) # Use the appropriate method of the translation object based # on the python version. m = t.gettext if six.PY3 else t.ugettext def f(msg): """"""oslo.i18n.gettextutils translation function."""""" if USE_LAZY: return Message(msg, domain=domain) return m(msg) return f @property def primary(self): ""The default translation function."" return self._make_translation_func() def _make_log_translation_func(self, level): return self._make_translation_func(self.domain + '-log-' + level) @property def log_info(self): ""Translate info-level log messages."" return self._make_log_translation_func('info') @property def log_warning(self): ""Translate warning-level log messages."" return self._make_log_translation_func('warning') @property def log_error(self): ""Translate error-level log messages."" return self._make_log_translation_func('error') @property def log_critical(self): ""Translate critical-level log messages."" return self._make_log_translation_func('critical') # NOTE(dhellmann): When this module moves out of the incubator into # oslo.i18n, these global variables can be moved to an integration # module within each application. # Create the global translation functions. _translators = TranslatorFactory('tooz') # The primary translation function using the well-known name ""_"" _ = _translators.primary # Translators for log levels. # # The abbreviated names are meant to reflect the usual use of a short # name like '_'. The ""L"" is for ""log"" and the other letter comes from # the level. _LI = _translators.log_info _LW = _translators.log_warning _LE = _translators.log_error _LC = _translators.log_critical # NOTE(dhellmann): End of globals that will move to the application's # integration module. def enable_lazy(): """"""Convenience function for configuring _() to use lazy gettext Call this at the start of execution to enable the gettextutils._ function to use lazy gettext functionality. This is useful if your project is importing _ directly instead of using the gettextutils.install() way of importing the _ function. """""" global USE_LAZY USE_LAZY = True def install(domain): """"""Install a _() function using the given translation domain. Given a translation domain, install a _() function using gettext's install() function. The main difference from gettext.install() is that we allow overriding the default localedir (e.g. /usr/share/locale) using a translation-domain-specific environment variable (e.g. NOVA_LOCALEDIR). Note that to enable lazy translation, enable_lazy must be called. :param domain: the translation domain """""" from six import moves tf = TranslatorFactory(domain) moves.builtins.__dict__['_'] = tf.primary class Message(six.text_type): """"""A Message object is a unicode object that can be translated. Translation of Message is done explicitly using the translate() method. For all non-translation intents and purposes, a Message is simply unicode, and can be treated as such. """""" def __new__(cls, msgid, msgtext=None, params=None, domain='tooz', *args): """"""Create a new Message object. In order for translation to work gettext requires a message ID, this msgid will be used as the base unicode text. It is also possible for the msgid and the base unicode text to be different by passing the msgtext parameter. """""" # If the base msgtext is not given, we use the default translation # of the msgid (which is in English) just in case the system locale is # not English, so that the base text will be in that locale by default. if not msgtext: msgtext = Message._translate_msgid(msgid, domain) # We want to initialize the parent unicode with the actual object that # would have been plain unicode if 'Message' was not enabled. msg = super(Message, cls).__new__(cls, msgtext) msg.msgid = msgid msg.domain = domain msg.params = params return msg def translate(self, desired_locale=None): """"""Translate this message to the desired locale. :param desired_locale: The desired locale to translate the message to, if no locale is provided the message will be translated to the system's default locale. :returns: the translated message in unicode """""" translated_message = Message._translate_msgid(self.msgid, self.domain, desired_locale) if self.params is None: # No need for more translation return translated_message # This Message object may have been formatted with one or more # Message objects as substitution arguments, given either as a single # argument, part of a tuple, or as one or more values in a dictionary. # When translating this Message we need to translate those Messages too translated_params = _translate_args(self.params, desired_locale) translated_message = translated_message % translated_params return translated_message @staticmethod def _translate_msgid(msgid, domain, desired_locale=None): if not desired_locale: system_locale = locale.getdefaultlocale() # If the system locale is not available to the runtime use English if not system_locale[0]: desired_locale = 'en_US' else: desired_locale = system_locale[0] locale_dir = os.environ.get(domain.upper() + '_LOCALEDIR') lang = gettext.translation(domain, localedir=locale_dir, languages=[desired_locale], fallback=True) if six.PY3: translator = lang.gettext else: translator = lang.ugettext translated_message = translator(msgid) return translated_message def __mod__(self, other): # When we mod a Message we want the actual operation to be performed # by the parent class (i.e. unicode()), the only thing we do here is # save the original msgid and the parameters in case of a translation params = self._sanitize_mod_params(other) unicode_mod = super(Message, self).__mod__(params) modded = Message(self.msgid, msgtext=unicode_mod, params=params, domain=self.domain) return modded def _sanitize_mod_params(self, other): """"""Sanitize the object being modded with this Message. - Add support for modding 'None' so translation supports it - Trim the modded object, which can be a large dictionary, to only those keys that would actually be used in a translation - Snapshot the object being modded, in case the message is translated, it will be used as it was when the Message was created """""" if other is None: params = (other,) elif isinstance(other, dict): # Merge the dictionaries # Copy each item in case one does not support deep copy. params = {} if isinstance(self.params, dict): for key, val in self.params.items(): params[key] = self._copy_param(val) for key, val in other.items(): params[key] = self._copy_param(val) else: params = self._copy_param(other) return params def _copy_param(self, param): try: return copy.deepcopy(param) except Exception: # Fallback to casting to unicode this will handle the # python code-like objects that can't be deep-copied return six.text_type(param) def __add__(self, other): msg = _('Message objects do not support addition.') raise TypeError(msg) def __radd__(self, other): return self.__add__(other) if six.PY2: def __str__(self): # NOTE(luisg): Logging in python 2.6 tries to str() log records, # and it expects specifically a UnicodeError in order to proceed. msg = _('Message objects do not support str() because they may ' 'contain non-ascii characters. ' 'Please use unicode() or translate() instead.') raise UnicodeError(msg) def get_available_languages(domain): """"""Lists the available languages for the given translation domain. :param domain: the domain to get languages for """""" if domain in _AVAILABLE_LANGUAGES: return copy.copy(_AVAILABLE_LANGUAGES[domain]) localedir = '%s_LOCALEDIR' % domain.upper() find = lambda x: gettext.find(domain, localedir=os.environ.get(localedir), languages=[x]) # NOTE(mrodden): en_US should always be available (and first in case # order matters) since our in-line message strings are en_US language_list = ['en_US'] # NOTE(luisg): Babel <1.0 used a function called list(), which was # renamed to locale_identifiers() in >=1.0, the requirements master list # requires >=0.9.6, uncapped, so defensively work with both. We can remove # this check when the master list updates to >=1.0, and update all projects list_identifiers = (getattr(localedata, 'list', None) or getattr(localedata, 'locale_identifiers')) locale_identifiers = list_identifiers() for i in locale_identifiers: if find(i) is not None: language_list.append(i) # NOTE(luisg): Babel>=1.0,<1.3 has a bug where some OpenStack supported # locales (e.g. 'zh_CN', and 'zh_TW') aren't supported even though they # are perfectly legitimate locales: # https://github.com/mitsuhiko/babel/issues/37 # In Babel 1.3 they fixed the bug and they support these locales, but # they are still not explicitly ""listed"" by locale_identifiers(). # That is why we add the locales here explicitly if necessary so that # they are listed as supported. aliases = {'zh': 'zh_CN', 'zh_Hant_HK': 'zh_HK', 'zh_Hant': 'zh_TW', 'fil': 'tl_PH'} for (locale_, alias) in six.iteritems(aliases): if locale_ in language_list and alias not in language_list: language_list.append(alias) _AVAILABLE_LANGUAGES[domain] = language_list return copy.copy(language_list) def translate(obj, desired_locale=None): """"""Gets the translated unicode representation of the given object. If the object is not translatable it is returned as-is. If the locale is None the object is translated to the system locale. :param obj: the object to translate :param desired_locale: the locale to translate the message to, if None the default system locale will be used :returns: the translated object in unicode, or the original object if it could not be translated """""" message = obj if not isinstance(message, Message): # If the object to translate is not already translatable, # let's first get its unicode representation message = six.text_type(obj) if isinstance(message, Message): # Even after unicoding() we still need to check if we are # running with translatable unicode before translating return message.translate(desired_locale) return obj def _translate_args(args, desired_locale=None): """"""Translates all the translatable elements of the given arguments object. This method is used for translating the translatable values in method arguments which include values of tuples or dictionaries. If the object is not a tuple or a dictionary the object itself is translated if it is translatable. If the locale is None the object is translated to the system locale. :param args: the args to translate :param desired_locale: the locale to translate the args to, if None the default system locale will be used :returns: a new args object with the translated contents of the original """""" if isinstance(args, tuple): return tuple(translate(v, desired_locale) for v in args) if isinstance(args, dict): translated_dict = {} for (k, v) in six.iteritems(args): translated_v = translate(v, desired_locale) translated_dict[k] = translated_v return translated_dict return translate(args, desired_locale) class TranslationHandler(handlers.MemoryHandler): """"""Handler that translates records before logging them. The TranslationHandler takes a locale and a target logging.Handler object to forward LogRecord objects to after translating them. This handler depends on Message objects being logged, instead of regular strings. The handler can be configured declaratively in the logging.conf as follows: [handlers] keys = translatedlog, translator [handler_translatedlog] class = handlers.WatchedFileHandler args = ('/var/log/api-localized.log',) formatter = context [handler_translator] class = openstack.common.log.TranslationHandler target = translatedlog args = ('zh_CN',) If the specified locale is not available in the system, the handler will log in the default locale. """""" def __init__(self, locale=None, target=None): """"""Initialize a TranslationHandler :param locale: locale to use for translating messages :param target: logging.Handler object to forward LogRecord objects to after translation """""" # NOTE(luisg): In order to allow this handler to be a wrapper for # other handlers, such as a FileHandler, and still be able to # configure it using logging.conf, this handler has to extend # MemoryHandler because only the MemoryHandlers' logging.conf # parsing is implemented such that it accepts a target handler. handlers.MemoryHandler.__init__(self, capacity=0, target=target) self.locale = locale def setFormatter(self, fmt): self.target.setFormatter(fmt) def emit(self, record): # We save the message from the original record to restore it # after translation, so other handlers are not affected by this original_msg = record.msg original_args = record.args try: self._translate_and_log_record(record) finally: record.msg = original_msg record.args = original_args def _translate_and_log_record(self, record): record.msg = translate(record.msg, self.locale) # In addition to translating the message, we also need to translate # arguments that were passed to the log method that were not part # of the main message e.g., log.info(_('Some message %s'), this_one)) record.args = _translate_args(record.args, self.locale) self.target.emit(record) ",,662,0
openstack%2Fironic~master~I9bdf526891a67287792e392a2491dbd004d7fb04,openstack/ironic,master,I9bdf526891a67287792e392a2491dbd004d7fb04,Imported Translations from Transifex,MERGED,2014-08-06 06:10:41.000000000,2014-08-08 19:42:18.000000000,2014-08-08 19:42:17.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 5805}, {'_account_id': 7882}, {'_account_id': 10342}]","[{'number': 1, 'created': '2014-08-06 06:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d8fe5bcd177cffbf8ed2c72dc01139845c692228', 'message': 'Imported Translations from Transifex\n\nChange-Id: I9bdf526891a67287792e392a2491dbd004d7fb04\n'}, {'number': 2, 'created': '2014-08-08 06:11:02.000000000', 'files': ['ironic/locale/en_AU/LC_MESSAGES/ironic-log-error.po', 'ironic/locale/de/LC_MESSAGES/ironic-log-warning.po', 'ironic/locale/fr/LC_MESSAGES/ironic-log-error.po', 'ironic/locale/ironic-log-info.pot', 'ironic/locale/fr/LC_MESSAGES/ironic-log-warning.po', 'ironic/locale/de/LC_MESSAGES/ironic-log-error.po', 'ironic/locale/pt_BR/LC_MESSAGES/ironic-log-error.po', 'ironic/locale/ironic.pot', 'ironic/locale/en_GB/LC_MESSAGES/ironic-log-warning.po', 'ironic/locale/ironic-log-error.pot', 'ironic/locale/ironic-log-warning.pot', 'ironic/locale/it/LC_MESSAGES/ironic-log-error.po', 'ironic/locale/en_GB/LC_MESSAGES/ironic-log-error.po', 'ironic/locale/zh_CN/LC_MESSAGES/ironic-log-error.po', 'ironic/locale/en_AU/LC_MESSAGES/ironic.po', 'ironic/locale/en_US/LC_MESSAGES/ironic.po', 'ironic/locale/es/LC_MESSAGES/ironic-log-error.po', 'ironic/locale/vi_VN/LC_MESSAGES/ironic-log-error.po', 'ironic/locale/zh_TW/LC_MESSAGES/ironic-log-error.po', 'ironic/locale/ja/LC_MESSAGES/ironic-log-error.po', 'ironic/locale/ko_KR/LC_MESSAGES/ironic-log-error.po'], 'web_link': 'https://opendev.org/openstack/ironic/commit/4f527fd78400052288ff20ad9aaca3d11c4734f9', 'message': 'Imported Translations from Transifex\n\nChange-Id: I9bdf526891a67287792e392a2491dbd004d7fb04\n'}]",0,112210,4f527fd78400052288ff20ad9aaca3d11c4734f9,16,5,2,11131,,,0,"Imported Translations from Transifex

Change-Id: I9bdf526891a67287792e392a2491dbd004d7fb04
",git fetch https://review.opendev.org/openstack/ironic refs/changes/10/112210/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/locale/ironic.pot', 'ironic/locale/en_AU/LC_MESSAGES/ironic.po', 'ironic/locale/en_US/LC_MESSAGES/ironic.po']",3,d8fe5bcd177cffbf8ed2c72dc01139845c692228,transifex/translations,"""POT-Creation-Date: 2014-08-06 06:10+0000\n""#: ironic/common/images.py:87#: ironic/common/images.py:93#: ironic/common/images.py:108#: ironic/openstack/common/imageutils.py:75 #, python-format msgid ""Invalid input value \""%s\""."" msgstr """" #: ironic/openstack/common/imageutils.py:104 msgid ""Snapshot list encountered but no header found!"" msgstr """" #: ironic/openstack/common/strutils.py:114#: ironic/openstack/common/strutils.py:219msgid ""Invalid unit system: \""%s\""""#: ironic/openstack/common/strutils.py:228msgid ""Invalid string format: %s""","""POT-Creation-Date: 2014-08-04 06:10+0000\n""#: ironic/common/images.py:110 msgid ""Snapshot list encountered but no header found!"" msgstr """" #: ironic/common/images.py:203#: ironic/common/images.py:209#: ironic/common/images.py:224#: ironic/openstack/common/strutils.py:88#: ironic/openstack/common/strutils.py:184msgid ""Invalid string format: %s""#: ironic/openstack/common/strutils.py:191msgid ""Unknown byte multiplier: %s""",57,42
openstack%2Foslo-incubator~master~Ib90dadce3ea89ae869d8d795872d4fc10159cdfc,openstack/oslo-incubator,master,Ib90dadce3ea89ae869d8d795872d4fc10159cdfc,Use oslosphinx to generate documentation,MERGED,2014-08-05 05:30:35.000000000,2014-08-08 19:38:59.000000000,2014-08-08 19:38:58.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1561}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 6482}, {'_account_id': 6928}, {'_account_id': 7725}, {'_account_id': 9107}]","[{'number': 1, 'created': '2014-08-05 05:30:35.000000000', 'files': ['doc/source/static/tweaks.css', 'doc/source/static/nature.css', 'test-requirements.txt', 'doc/source/_templates/.placeholder', 'doc/source/conf.py', 'doc/source/static/header-line.gif', 'doc/source/static/header_bg.jpg', 'doc/source/static/jquery.tweet.js', 'doc/source/_theme/theme.conf', 'doc/source/_theme/layout.html', 'doc/source/static/basic.css', 'doc/source/static/openstack_logo.png', 'doc/source/static/default.css'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/a986603035d83f44ca2ebebe6a014a52e3426fde', 'message': 'Use oslosphinx to generate documentation\n\nRather than host different and possibly out of date versions of\nstatic and theme files, use oslosphinx to generate the docs.\n\nChange-Id: Ib90dadce3ea89ae869d8d795872d4fc10159cdfc\n'}]",0,111910,a986603035d83f44ca2ebebe6a014a52e3426fde,16,13,1,6482,,,0,"Use oslosphinx to generate documentation

Rather than host different and possibly out of date versions of
static and theme files, use oslosphinx to generate the docs.

Change-Id: Ib90dadce3ea89ae869d8d795872d4fc10159cdfc
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/10/111910/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/static/tweaks.css', 'doc/source/static/nature.css', 'test-requirements.txt', 'doc/source/_templates/.placeholder', 'doc/source/conf.py', 'doc/source/static/header-line.gif', 'doc/source/static/header_bg.jpg', 'doc/source/static/jquery.tweet.js', 'doc/source/_theme/theme.conf', 'doc/source/_theme/layout.html', 'doc/source/static/basic.css', 'doc/source/static/openstack_logo.png', 'doc/source/static/default.css']",13,a986603035d83f44ca2ebebe6a014a52e3426fde,use_oslosphinx,,"/** * Sphinx stylesheet -- default theme * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ */ @import url(""basic.css""); /* -- page layout ----------------------------------------------------------- */ body { font-family: sans-serif; font-size: 100%; background-color: #11303d; color: #000; margin: 0; padding: 0; } div.document { background-color: #1c4e63; } div.documentwrapper { float: left; width: 100%; } div.bodywrapper { margin: 0 0 0 230px; } div.body { background-color: #ffffff; color: #000000; padding: 0 20px 30px 20px; } div.footer { color: #ffffff; width: 100%; padding: 9px 0 9px 0; text-align: center; font-size: 75%; } div.footer a { color: #ffffff; text-decoration: underline; } div.related { background-color: #133f52; line-height: 30px; color: #ffffff; } div.related a { color: #ffffff; } div.sphinxsidebar { } div.sphinxsidebar h3 { font-family: 'Trebuchet MS', sans-serif; color: #ffffff; font-size: 1.4em; font-weight: normal; margin: 0; padding: 0; } div.sphinxsidebar h3 a { color: #ffffff; } div.sphinxsidebar h4 { font-family: 'Trebuchet MS', sans-serif; color: #ffffff; font-size: 1.3em; font-weight: normal; margin: 5px 0 0 0; padding: 0; } div.sphinxsidebar p { color: #ffffff; } div.sphinxsidebar p.topless { margin: 5px 10px 10px 10px; } div.sphinxsidebar ul { margin: 10px; padding: 0; color: #ffffff; } div.sphinxsidebar a { color: #98dbcc; } div.sphinxsidebar input { border: 1px solid #98dbcc; font-family: sans-serif; font-size: 1em; } /* -- body styles ----------------------------------------------------------- */ a { color: #355f7c; text-decoration: none; } a:hover { text-decoration: underline; } div.body p, div.body dd, div.body li { text-align: left; line-height: 130%; } div.body h1, div.body h2, div.body h3, div.body h4, div.body h5, div.body h6 { font-family: 'Trebuchet MS', sans-serif; background-color: #f2f2f2; font-weight: normal; color: #20435c; border-bottom: 1px solid #ccc; margin: 20px -20px 10px -20px; padding: 3px 0 3px 10px; } div.body h1 { margin-top: 0; font-size: 200%; } div.body h2 { font-size: 160%; } div.body h3 { font-size: 140%; } div.body h4 { font-size: 120%; } div.body h5 { font-size: 110%; } div.body h6 { font-size: 100%; } a.headerlink { color: #c60f0f; font-size: 0.8em; padding: 0 4px 0 4px; text-decoration: none; } a.headerlink:hover { background-color: #c60f0f; color: white; } div.body p, div.body dd, div.body li { text-align: left; line-height: 130%; } div.admonition p.admonition-title + p { display: inline; } div.admonition p { margin-bottom: 5px; } div.admonition pre { margin-bottom: 5px; } div.admonition ul, div.admonition ol { margin-bottom: 5px; } div.note { background-color: #eee; border: 1px solid #ccc; } div.seealso { background-color: #ffc; border: 1px solid #ff6; } div.topic { background-color: #eee; } div.warning { background-color: #ffe4e4; border: 1px solid #f66; } p.admonition-title { display: inline; } p.admonition-title:after { content: "":""; } pre { padding: 5px; background-color: #eeffcc; color: #333333; line-height: 120%; border: 1px solid #ac9; border-left: none; border-right: none; } tt { background-color: #ecf0f3; padding: 0 1px 0 1px; font-size: 0.95em; } .warning tt { background: #efc2c2; } .note tt { background: #d6d6d6; } ",6,1230
openstack%2Ffuel-main~stable%2F5.0~I97e5535508f1416f36175880d1d3a13042a0ccdb,openstack/fuel-main,stable/5.0,I97e5535508f1416f36175880d1d3a13042a0ccdb,add python-rabbit to requirements,MERGED,2014-08-07 20:25:04.000000000,2014-08-08 19:27:17.000000000,2014-08-08 19:27:17.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-08-07 20:25:04.000000000', 'files': ['requirements-rpm.txt', 'requirements-deb.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4fbdbf3684bb50ea94ce37718c7bb6672299613b', 'message': 'add python-rabbit to requirements\n\nNeeded for rabbitmq-connections-cleanup.py\n(https://review.openstack.org/112677).\n\nChange-Id: I97e5535508f1416f36175880d1d3a13042a0ccdb\nRelated-Bug: #856764\n'}]",0,112680,4fbdbf3684bb50ea94ce37718c7bb6672299613b,10,3,1,8787,,,0,"add python-rabbit to requirements

Needed for rabbitmq-connections-cleanup.py
(https://review.openstack.org/112677).

Change-Id: I97e5535508f1416f36175880d1d3a13042a0ccdb
Related-Bug: #856764
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/80/112680/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements-rpm.txt', 'requirements-deb.txt']",2,4fbdbf3684bb50ea94ce37718c7bb6672299613b,,python-rabbit,,2,0
openstack%2Ffuel-main~master~I97e5535508f1416f36175880d1d3a13042a0ccdb,openstack/fuel-main,master,I97e5535508f1416f36175880d1d3a13042a0ccdb,add python-rabbit to requirements,MERGED,2014-08-07 20:22:33.000000000,2014-08-08 19:27:05.000000000,2014-08-08 19:27:05.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9582}]","[{'number': 1, 'created': '2014-08-07 20:22:33.000000000', 'files': ['requirements-rpm.txt', 'requirements-deb.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/e94a7c287ca982c72f2787e9bbf91ca47c91ed7e', 'message': 'add python-rabbit to requirements\n\nNeeded for rabbitmq-connections-cleanup.py\n(https://review.openstack.org/112677).\n\nChange-Id: I97e5535508f1416f36175880d1d3a13042a0ccdb\nRelated-Bug: #856764\n'}]",0,112679,e94a7c287ca982c72f2787e9bbf91ca47c91ed7e,17,5,1,8787,,,0,"add python-rabbit to requirements

Needed for rabbitmq-connections-cleanup.py
(https://review.openstack.org/112677).

Change-Id: I97e5535508f1416f36175880d1d3a13042a0ccdb
Related-Bug: #856764
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/79/112679/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements-rpm.txt', 'requirements-deb.txt']",2,e94a7c287ca982c72f2787e9bbf91ca47c91ed7e,bug/856764,python-rabbit,,2,0
openstack%2Ffuel-main~master~Ia414f9f5bbb0a5efbab537f7f2a1b381dc7387ca,openstack/fuel-main,master,Ia414f9f5bbb0a5efbab537f7f2a1b381dc7387ca,Missed renaming for Sahara system tests,MERGED,2014-08-06 11:37:30.000000000,2014-08-08 19:24:35.000000000,2014-08-08 19:24:35.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7109}, {'_account_id': 7227}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9977}]","[{'number': 1, 'created': '2014-08-06 11:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/031d2351208283b8fb2da5931b77ee59375f0089', 'message': 'Missed renaming for Sahara system tests\n\nWe can still see the word ""savanna"" in the names of variables, methods\nand classes in system tests for Sahara. This fact causes errors when\nrunning OSTF tests because all variables, methods and classes have been\nrenamed in OSTF tests for Sahara.\n\nChange-Id: Ia414f9f5bbb0a5efbab537f7f2a1b381dc7387ca\nCloses-Bug: #1353433\n'}, {'number': 2, 'created': '2014-08-06 11:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/63d47ef115468c68e9eeb36dcb4bbb4a1ace3d7b', 'message': 'Missed renaming for Sahara system tests\n\nWe can still see the word ""savanna"" in the names of variables, methods\nand classes in system tests for Sahara. This fact causes errors when\nrunning OSTF tests because all variables, methods and classes have been\nrenamed in OSTF tests for Sahara.\n\nChange-Id: Ia414f9f5bbb0a5efbab537f7f2a1b381dc7387ca\nCloses-Bug: #1353433\n'}, {'number': 3, 'created': '2014-08-06 11:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/e7d247fdf2792a7712d4917dec2ee4568dbf7e52', 'message': 'Missed renaming for Sahara system tests\n\nWe can still see the word ""savanna"" in the names of variables, methods\nand classes in system tests for Sahara. This fact causes errors when\nrunning OSTF tests because all variables, methods and classes have been\nrenamed in OSTF tests for Sahara.\n\nIn addition, variable SERVTEST_SAVANNA_SERVER_URL has been removed \nbecause there is no code fragment where this variable is used.\n\nCloses-Bug: #1353433\n\nChange-Id: Ia414f9f5bbb0a5efbab537f7f2a1b381dc7387ca\n'}, {'number': 4, 'created': '2014-08-07 12:42:00.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_huge_environments.py', 'fuelweb_ui_test/tests/test_env_wizard.py', 'fuelweb_test/tests/test_services.py', 'fuelweb_test/ostf_test_mapping.py', 'fuelweb_ui_test/pageobjects/settings.py', 'fuelweb_ui_test/tests/test_env_settings.py', 'utils/pairwise_testcases.py', 'fuelweb_ui_test/pageobjects/environments.py', 'fuelweb_ui_test/tests/test_environment.py', 'fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8d8eedcdba96cfc5afc0ecaf810ec58d4c636eb8', 'message': 'Missed renaming for Sahara system tests\n\nWe can still see the word ""savanna"" in the names of variables, methods\nand classes in system tests for Sahara. This fact causes errors when\nrunning OSTF tests because all variables, methods and classes have been\nrenamed in OSTF tests for Sahara.\n\nIn addition, variable SERVTEST_SAVANNA_SERVER_URL has been removed\nbecause there is no code fragment where this variable is used.\n\nCloses-Bug: #1353433\n\nChange-Id: Ia414f9f5bbb0a5efbab537f7f2a1b381dc7387ca\n'}]",1,112268,8d8eedcdba96cfc5afc0ecaf810ec58d4c636eb8,31,7,4,7428,,,0,"Missed renaming for Sahara system tests

We can still see the word ""savanna"" in the names of variables, methods
and classes in system tests for Sahara. This fact causes errors when
running OSTF tests because all variables, methods and classes have been
renamed in OSTF tests for Sahara.

In addition, variable SERVTEST_SAVANNA_SERVER_URL has been removed
because there is no code fragment where this variable is used.

Closes-Bug: #1353433

Change-Id: Ia414f9f5bbb0a5efbab537f7f2a1b381dc7387ca
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/68/112268/2 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/tests_strength/test_huge_environments.py', 'fuelweb_ui_test/tests/test_env_wizard.py', 'fuelweb_test/tests/test_services.py', 'fuelweb_test/ostf_test_mapping.py', 'fuelweb_ui_test/pageobjects/settings.py', 'fuelweb_ui_test/tests/test_env_settings.py', 'utils/pairwise_testcases.py', 'fuelweb_ui_test/pageobjects/environments.py', 'fuelweb_ui_test/tests/test_environment.py', 'fuelweb_test/settings.py']",10,031d2351208283b8fb2da5931b77ee59375f0089,bug/1353433,"SERVTEST_SAHARA_IMAGE = 'savanna-0.3-vanilla-1.2.1-ubuntu-13.04.qcow2' SERVTEST_SAHARA_IMAGE_NAME = 'sahara' SERVTEST_SAHARA_IMAGE_MD5 = '9ab37ec9a13bb005639331c4275a308d' SERVTEST_SAHARA_IMAGE_META = {'_sahara_tag_1.2.1': 'True',","SERVTEST_SAVANNA_SERVER_URL = 'http://savanna-files.mirantis.com' SERVTEST_SAVANNA_IMAGE = 'savanna-0.3-vanilla-1.2.1-ubuntu-13.04.qcow2' SERVTEST_SAVANNA_IMAGE_NAME = 'sahara' SERVTEST_SAVANNA_IMAGE_MD5 = '9ab37ec9a13bb005639331c4275a308d' SERVTEST_SAVANNA_IMAGE_META = {'_sahara_tag_1.2.1': 'True',",40,41
openstack%2Fnova~master~I1f726637561e80253e03c0fbc086d064a8f7f8cb,openstack/nova,master,I1f726637561e80253e03c0fbc086d064a8f7f8cb,Add couple of french translations,ABANDONED,2014-07-30 23:00:38.000000000,2014-08-08 19:22:01.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1812}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-30 23:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3de8d1221b813a2e47bed9779618539ff052166d', 'message': 'Add couple of french translations\n\nChange-Id: I1f726637561e80253e03c0fbc086d064a8f7f8cb\n'}, {'number': 2, 'created': '2014-07-30 23:05:15.000000000', 'files': ['nova/locale/fr/LC_MESSAGES/nova-log-critical.po', 'nova/locale/fr/LC_MESSAGES/nova-log-error.po', 'nova/locale/fr/LC_MESSAGES/nova-log-info.po'], 'web_link': 'https://opendev.org/openstack/nova/commit/81378938a06abc27ffd89d366b2e68689bea22a3', 'message': 'Add couple of french translations\n\nChange-Id: I1f726637561e80253e03c0fbc086d064a8f7f8cb\n'}]",0,110804,81378938a06abc27ffd89d366b2e68689bea22a3,12,7,2,6723,,,0,"Add couple of french translations

Change-Id: I1f726637561e80253e03c0fbc086d064a8f7f8cb
",git fetch https://review.opendev.org/openstack/nova refs/changes/04/110804/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/locale/fr/LC_MESSAGES/nova-log-critical.po', 'nova/locale/fr/LC_MESSAGES/nova-log-error.po', 'nova/locale/fr/LC_MESSAGES/nova-log-info.po']",3,3de8d1221b813a2e47bed9779618539ff052166d,locales-fr,"""PO-Revision-Date: 2014-07-31 00:31+0100\n""""Pendant la synchronisation de l'tat de fonctionnement (sync_power_state), "" ""l'instance a une tche en cours: (%(task)s). Ignore.""""La chaine de l'instance %s a disparue durant le rafrachissement, ignore.""msgstr ""L'instance a t dtruite avec succs.""msgstr ""Utilisation du priphrique de config""""Configuration du fuseau horaire pour l'instance Windows  l'heure locale""""Domaine introuvable dans la libvirt pour l'instance %s. Impossible d'obtenir "" ""les statistiques de bloc pour le priphrique""msgstr ""Information CPU de l'instance lance : %s""msgstr ""Suppression des fichiers de l'instance %s""msgstr ""Echec de la suppression de %s""msgstr ""Suppression de %s termine""msgstr ""Suppression du fichier de base : %s""msgstr ""L'outil findmnt n'est pas install""","""PO-Revision-Date: 2014-07-16 14:42+0000\n""msgstr ""Instance dtruite avec succs.""msgstr ""Utilisation de l'unit de config""""Domaine introuvable dans libvirt pour l'instance %s. Impossible d'obtenir "" ""les stats de bloc pour l'unit""msgstr """"msgstr """"msgstr """"msgstr """"msgstr ""Retrait du fichier de base : %s""msgstr """"",50,31
openstack%2Fcinder~master~I7227bb0051836e537bff2f0f97662c06452d5af6,openstack/cinder,master,I7227bb0051836e537bff2f0f97662c06452d5af6,Improve regex for _ import hacking check,MERGED,2014-08-03 17:39:09.000000000,2014-08-08 19:15:47.000000000,2014-08-08 19:15:46.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2759}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 6601}, {'_account_id': 9751}, {'_account_id': 11811}, {'_account_id': 12033}]","[{'number': 1, 'created': '2014-08-03 17:39:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8249842db9f6df7fcd3910371fe2f4ce720eeff1', 'message': 'Improve regex for _ import hacking check\n\nCommit 3e2b1117 added a check to make sure that the _\nfunction was being explicitly imported so that translation would\nwork properly.\n\nI have discovered that those regexes/code would not work in some cases.\nParticularly if the import line imported multiple things from\ngettextutils or i18n.  Also the check being used to find lines using\nthe _ function was not right.\n\nThis commit fixes the issues and adds appropriate tests.  It also\nadds the hacking check to HACKING.rst which should have been done the\nfirst time around.\n\nChange-Id: I7227bb0051836e537bff2f0f97662c06452d5af6\n'}, {'number': 2, 'created': '2014-08-07 21:00:41.000000000', 'files': ['cinder/tests/test_hacking.py', 'cinder/hacking/checks.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/53474391420cdd8c02967a862b0218b37c84b561', 'message': 'Improve regex for _ import hacking check\n\nCommit 3e2b1117 added a check to make sure that the _\nfunction was being explicitly imported so that translation would\nwork properly.\n\nI have discovered that those regexes/code would not work in some cases.\nParticularly if the import line imported multiple things from\ngettextutils or i18n.  Also the check being used to find lines using\nthe _ function was not right.\n\nThis commit fixes the issues and adds appropriate tests.  It also\nadds the hacking check to HACKING.rst which should have been done the\nfirst time around.\n\nChange-Id: I7227bb0051836e537bff2f0f97662c06452d5af6\n'}]",1,111587,53474391420cdd8c02967a862b0218b37c84b561,20,9,2,7198,,,0,"Improve regex for _ import hacking check

Commit 3e2b1117 added a check to make sure that the _
function was being explicitly imported so that translation would
work properly.

I have discovered that those regexes/code would not work in some cases.
Particularly if the import line imported multiple things from
gettextutils or i18n.  Also the check being used to find lines using
the _ function was not right.

This commit fixes the issues and adds appropriate tests.  It also
adds the hacking check to HACKING.rst which should have been done the
first time around.

Change-Id: I7227bb0051836e537bff2f0f97662c06452d5af6
",git fetch https://review.opendev.org/openstack/cinder refs/changes/87/111587/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_hacking.py', 'cinder/hacking/checks.py', 'HACKING.rst']",3,8249842db9f6df7fcd3910371fe2f4ce720eeff1,better_underscore_regex,- [N323] Add check for explicit import of _() to ensure proper translation.,,22,3
openstack%2Fglance~master~I8ee9e9254c8371bbbce8b28d643e3d474b2361bc,openstack/glance,master,I8ee9e9254c8371bbbce8b28d643e3d474b2361bc,Adding status field to image location -- scrubber changes,MERGED,2014-01-16 11:49:29.000000000,2014-08-08 19:12:39.000000000,2014-08-08 19:12:38.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6549}, {'_account_id': 8127}, {'_account_id': 8759}, {'_account_id': 8871}, {'_account_id': 9263}, {'_account_id': 9751}, {'_account_id': 10585}]","[{'number': 1, 'created': '2014-01-16 11:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/435512dd70925e7e06d21839a01c843c6a6e314b', 'message': ""Adding status field to image location\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is third part of this change which covered scrubber DB queue\nenablement and double queue supporting.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I8ee9e9254c8371bbbce8b28d643e3d474b2361bc\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>""}, {'number': 2, 'created': '2014-04-29 05:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a124ce538a11621c9b6494cc76a9c06dc42bddf8', 'message': ""Adding status field to image location -- scrubber changes\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is third part of this change which covered scrubber DB queue\nenablement and double queue supporting.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I8ee9e9254c8371bbbce8b28d643e3d474b2361bc\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 3, 'created': '2014-05-05 09:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ddba39c824bc03d71e99b6125d55f7c289f7921f', 'message': ""Adding status field to image location -- scrubber changes\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is third part of this change which covered scrubber DB queue\nenablement and double queue supporting.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I8ee9e9254c8371bbbce8b28d643e3d474b2361bc\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 4, 'created': '2014-05-29 14:17:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4adf33b295fe7725390098586c5078fd63478ec5', 'message': ""Adding status field to image location -- scrubber changes\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is third part of this change which covered scrubber DB queue\nenablement and double queue supporting.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I8ee9e9254c8371bbbce8b28d643e3d474b2361bc\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 5, 'created': '2014-06-30 11:10:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8c5b1330b93129f0913699558d90dcb97b3e0977', 'message': ""Adding status field to image location -- scrubber changes\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is third part of this change which covered scrubber DB queue\nenablement and double queue supporting.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I8ee9e9254c8371bbbce8b28d643e3d474b2361bc\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 6, 'created': '2014-07-02 16:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/04ba19e6925b2456bac71eb7ac5c16e191eb57f4', 'message': ""Adding status field to image location -- scrubber changes\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is third part of this change which covered scrubber DB queue\nenablement and double queue supporting.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I8ee9e9254c8371bbbce8b28d643e3d474b2361bc\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 7, 'created': '2014-07-04 08:10:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/95844edbe1ed8dc1b6006470fe2551e273b79081', 'message': ""Adding status field to image location -- scrubber changes\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is third part of this change which covered scrubber DB queue\nenablement and double queue supporting.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I8ee9e9254c8371bbbce8b28d643e3d474b2361bc\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 8, 'created': '2014-07-11 08:35:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1c52171b83f5dfdc31b0c5e6281904f5c8908b04', 'message': ""Adding status field to image location -- scrubber changes\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is third part of this change which covered scrubber DB queue\nenablement and double queue supporting.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I8ee9e9254c8371bbbce8b28d643e3d474b2361bc\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 9, 'created': '2014-07-14 15:31:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/56ba80b1ed02adea9341cc2b74041c239d133c6d', 'message': ""Adding status field to image location -- scrubber changes\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is third part of this change which covered scrubber DB queue\nenablement and double queue supporting.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I8ee9e9254c8371bbbce8b28d643e3d474b2361bc\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 10, 'created': '2014-07-21 06:10:03.000000000', 'files': ['glance/registry/client/v1/client.py', 'glance/tests/functional/test_scrubber.py', 'glance/tests/functional/__init__.py', 'etc/glance-scrubber.conf', 'glance/tests/unit/test_scrubber.py', 'glance/scrubber.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/70e0a246f9b3d2920dd80766240e8c23f245fe95', 'message': ""Adding status field to image location -- scrubber changes\n\nAdding a status field to image's each location property, each location\nstatus can be 'active', 'pending_delete' and 'deleted'.\n\nUnder location's status information Scrubber service can make cleanup\nbased on DB records also but not a dedicated queue-file for each image.\n\nThis is third part of this change which covered scrubber DB queue\nenablement and double queue supporting.\n\nPartially-Implements BP: image-location-status\n\nChange-Id: I8ee9e9254c8371bbbce8b28d643e3d474b2361bc\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}]",11,67122,70e0a246f9b3d2920dd80766240e8c23f245fe95,77,11,10,6549,,,0,"Adding status field to image location -- scrubber changes

Adding a status field to image's each location property, each location
status can be 'active', 'pending_delete' and 'deleted'.

Under location's status information Scrubber service can make cleanup
based on DB records also but not a dedicated queue-file for each image.

This is third part of this change which covered scrubber DB queue
enablement and double queue supporting.

Partially-Implements BP: image-location-status

Change-Id: I8ee9e9254c8371bbbce8b28d643e3d474b2361bc
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>
",git fetch https://review.opendev.org/openstack/glance refs/changes/22/67122/9 && git format-patch -1 --stdout FETCH_HEAD,"['glance/store/scrubber.py', 'etc/glance-scrubber.conf', 'glance/tests/unit/test_scrubber.py']",3,435512dd70925e7e06d21839a01c843c6a6e314b,," uri = 'file://some/path/%s' % uuid.uuid4() id, [(id, '-', uri)])"," fname = lambda: str(uuid.uuid4()) uri = 'file://some/path/%s' % (fname) id, [(id, uri)])",162,57
openstack%2Fkeystonemiddleware~master~I014ef5f974835d52dbb4598c7d357ecafa1da8a2,openstack/keystonemiddleware,master,I014ef5f974835d52dbb4598c7d357ecafa1da8a2,Use oslosphinx in keystonemiddlware for documentation,MERGED,2014-08-05 05:28:13.000000000,2014-08-08 18:17:03.000000000,2014-08-08 18:17:02.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-08-05 05:28:13.000000000', 'files': ['doc/source/static/tweaks.css', 'doc/source/static/nature.css', 'test-requirements.txt', 'doc/source/_templates/.placeholder', 'doc/source/conf.py', 'doc/source/static/header-line.gif', 'doc/source/static/header_bg.jpg', 'doc/source/static/jquery.tweet.js', 'doc/source/_theme/theme.conf', 'doc/source/_theme/layout.html', 'doc/source/static/basic.css', 'doc/source/static/openstack_logo.png', 'doc/source/static/default.css'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/28e1b2c909c7ca2b447e0132b2472277bf2eb06e', 'message': 'Use oslosphinx in keystonemiddlware for documentation\n\nStart using oslosphinx to generate the themes and static content,\nrather than hosting our own copies.\n\nChange-Id: I014ef5f974835d52dbb4598c7d357ecafa1da8a2\n'}]",0,111909,28e1b2c909c7ca2b447e0132b2472277bf2eb06e,23,12,1,6482,,,0,"Use oslosphinx in keystonemiddlware for documentation

Start using oslosphinx to generate the themes and static content,
rather than hosting our own copies.

Change-Id: I014ef5f974835d52dbb4598c7d357ecafa1da8a2
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/09/111909/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/static/tweaks.css', 'doc/source/static/nature.css', 'test-requirements.txt', 'doc/source/_templates/.placeholder', 'doc/source/conf.py', 'doc/source/static/header-line.gif', 'doc/source/static/header_bg.jpg', 'doc/source/static/jquery.tweet.js', 'doc/source/_theme/theme.conf', 'doc/source/_theme/layout.html', 'doc/source/static/basic.css', 'doc/source/static/openstack_logo.png', 'doc/source/static/default.css']",13,28e1b2c909c7ca2b447e0132b2472277bf2eb06e,use_oslosphinx,,"/** * Sphinx stylesheet -- default theme * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ */ @import url(""basic.css""); /* -- page layout ----------------------------------------------------------- */ body { font-family: sans-serif; font-size: 100%; background-color: #11303d; color: #000; margin: 0; padding: 0; } div.document { background-color: #1c4e63; } div.documentwrapper { float: left; width: 100%; } div.bodywrapper { margin: 0 0 0 230px; } div.body { background-color: #ffffff; color: #000000; padding: 0 20px 30px 20px; } div.footer { color: #ffffff; width: 100%; padding: 9px 0 9px 0; text-align: center; font-size: 75%; } div.footer a { color: #ffffff; text-decoration: underline; } div.related { background-color: #133f52; line-height: 30px; color: #ffffff; } div.related a { color: #ffffff; } div.sphinxsidebar { } div.sphinxsidebar h3 { font-family: 'Trebuchet MS', sans-serif; color: #ffffff; font-size: 1.4em; font-weight: normal; margin: 0; padding: 0; } div.sphinxsidebar h3 a { color: #ffffff; } div.sphinxsidebar h4 { font-family: 'Trebuchet MS', sans-serif; color: #ffffff; font-size: 1.3em; font-weight: normal; margin: 5px 0 0 0; padding: 0; } div.sphinxsidebar p { color: #ffffff; } div.sphinxsidebar p.topless { margin: 5px 10px 10px 10px; } div.sphinxsidebar ul { margin: 10px; padding: 0; color: #ffffff; } div.sphinxsidebar a { color: #98dbcc; } div.sphinxsidebar input { border: 1px solid #98dbcc; font-family: sans-serif; font-size: 1em; } /* -- body styles ----------------------------------------------------------- */ a { color: #355f7c; text-decoration: none; } a:hover { text-decoration: underline; } div.body p, div.body dd, div.body li { text-align: left; line-height: 130%; } div.body h1, div.body h2, div.body h3, div.body h4, div.body h5, div.body h6 { font-family: 'Trebuchet MS', sans-serif; background-color: #f2f2f2; font-weight: normal; color: #20435c; border-bottom: 1px solid #ccc; margin: 20px -20px 10px -20px; padding: 3px 0 3px 10px; } div.body h1 { margin-top: 0; font-size: 200%; } div.body h2 { font-size: 160%; } div.body h3 { font-size: 140%; } div.body h4 { font-size: 120%; } div.body h5 { font-size: 110%; } div.body h6 { font-size: 100%; } a.headerlink { color: #c60f0f; font-size: 0.8em; padding: 0 4px 0 4px; text-decoration: none; } a.headerlink:hover { background-color: #c60f0f; color: white; } div.body p, div.body dd, div.body li { text-align: left; line-height: 130%; } div.admonition p.admonition-title + p { display: inline; } div.admonition p { margin-bottom: 5px; } div.admonition pre { margin-bottom: 5px; } div.admonition ul, div.admonition ol { margin-bottom: 5px; } div.note { background-color: #eee; border: 1px solid #ccc; } div.seealso { background-color: #ffc; border: 1px solid #ff6; } div.topic { background-color: #eee; } div.warning { background-color: #ffe4e4; border: 1px solid #f66; } p.admonition-title { display: inline; } p.admonition-title:after { content: "":""; } pre { padding: 5px; background-color: #eeffcc; color: #333333; line-height: 120%; border: 1px solid #ac9; border-left: none; border-right: none; } tt { background-color: #ecf0f3; padding: 0 1px 0 1px; font-size: 0.95em; } .warning tt { background: #efc2c2; } .note tt { background: #d6d6d6; } ",6,1230
openstack%2Ffuel-library~stable%2F5.0~Ie7cee823fac70f9c2dd46c04f8651cec6bddccc4,openstack/fuel-library,stable/5.0,Ie7cee823fac70f9c2dd46c04f8651cec6bddccc4,Fix live migration for File/Volume based Instances,MERGED,2014-08-08 10:32:22.000000000,2014-08-08 18:13:36.000000000,2014-08-08 18:13:36.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11827}]","[{'number': 1, 'created': '2014-08-08 10:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9b4353bb2469112648f3cdf1be626619c99fdc96', 'message': 'Fix live migration for File/Volume based Instances\n\n- Open libvirt ports for migration http://wiki.libvirt.org/page/FAQ\n- Add python-novaclient for compute nodes to provide nova CLI\n- Change libvirt_disk_cachemodes to""file=directsync"",""block=none"".\n\nThis allows live block migration, as DirectSync mode is like writethrough, but it bypasses the host page cache.\n\nCloses-Bug: 1329953\nChange-Id: Ie7cee823fac70f9c2dd46c04f8651cec6bddccc4\n'}, {'number': 2, 'created': '2014-08-08 12:45:52.000000000', 'files': ['deployment/puppet/openstack/manifests/all.pp', 'deployment/puppet/ceph/manifests/ephemeral.pp', 'deployment/puppet/nova/manifests/compute/libvirt.pp', 'deployment/puppet/openstack/manifests/compute.pp', 'deployment/puppet/openstack/manifests/firewall.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fa6b19963023b2e8d70f3fba300c75322f7bb476', 'message': 'Fix live migration for File/Volume based Instances\n\n- Open libvirt ports for migration http://wiki.libvirt.org/page/FAQ\n- Add python-novaclient for compute nodes to provide nova CLI\n- Change libvirt_disk_cachemodes to""file=directsync"",""block=none"".\n\nThis allows live block migration, as DirectSync mode is like writethrough, but it bypasses the host page cache.\n\nCloses-Bug: 1329953\nChange-Id: Ie7cee823fac70f9c2dd46c04f8651cec6bddccc4\n'}]",1,112819,fa6b19963023b2e8d70f3fba300c75322f7bb476,23,7,2,11090,,,0,"Fix live migration for File/Volume based Instances

- Open libvirt ports for migration http://wiki.libvirt.org/page/FAQ
- Add python-novaclient for compute nodes to provide nova CLI
- Change libvirt_disk_cachemodes to""file=directsync"",""block=none"".

This allows live block migration, as DirectSync mode is like writethrough, but it bypasses the host page cache.

Closes-Bug: 1329953
Change-Id: Ie7cee823fac70f9c2dd46c04f8651cec6bddccc4
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/19/112819/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/manifests/all.pp', 'deployment/puppet/ceph/manifests/ephemeral.pp', 'deployment/puppet/nova/manifests/compute/libvirt.pp', 'deployment/puppet/openstack/manifests/compute.pp', 'deployment/puppet/openstack/manifests/firewall.pp']",5,9b4353bb2469112648f3cdf1be626619c99fdc96,bug/1329953," port => $libvirt_ports, proto => 'tcp', action => 'accept', } firewall {'118 libvirt migration': port => '49152-49215', port => '5900-6100',"," port => $libvirt_port, port => ""5900-6100"",",35,20
openstack%2Fzaqar~master~Ibb3d0a847a74e2c1fb54a82a2673632002b23421,openstack/zaqar,master,Ibb3d0a847a74e2c1fb54a82a2673632002b23421,Make `admin_mode` a cli option,MERGED,2014-08-08 07:44:44.000000000,2014-08-08 18:06:39.000000000,2014-08-08 18:06:39.000000000,"[{'_account_id': 3}, {'_account_id': 6413}, {'_account_id': 6427}]","[{'number': 1, 'created': '2014-08-08 07:44:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/b437aa5ce108081bfc05d971fe40359182ec729b', 'message': 'Make `admin_mode` a cli option\n\nChange-Id: Ibb3d0a847a74e2c1fb54a82a2673632002b23421\nCloses-bug: #1244228\n'}, {'number': 2, 'created': '2014-08-08 08:21:04.000000000', 'files': ['zaqar/queues/bootstrap.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/da0f51a930b8eedf82687868e72d0d8ca0a6e6de', 'message': 'Make `admin_mode` a cli option\n\nChange-Id: Ibb3d0a847a74e2c1fb54a82a2673632002b23421\nCloses-bug: #1244228\n'}]",0,112781,da0f51a930b8eedf82687868e72d0d8ca0a6e6de,13,3,2,6159,,,0,"Make `admin_mode` a cli option

Change-Id: Ibb3d0a847a74e2c1fb54a82a2673632002b23421
Closes-bug: #1244228
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/81/112781/1 && git format-patch -1 --stdout FETCH_HEAD,['zaqar/queues/bootstrap.py'],1,b437aa5ce108081bfc05d971fe40359182ec729b,admin-mode," cfg.BoolOpt('admin_mode', default=False, help='Activate endpoints to manage pool registry.'),"," cfg.BoolOpt('admin_mode', default=False, help='Activate endpoints to manage pool registry.'),",2,2
openstack%2Fkeystone~master~I0b0e48fa04d08b1023984b6d2169322060fcee9e,openstack/keystone,master,I0b0e48fa04d08b1023984b6d2169322060fcee9e,Delete intersphinx mappings,MERGED,2014-08-07 06:05:22.000000000,2014-08-08 18:00:58.000000000,2014-08-08 18:00:57.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 8978}, {'_account_id': 11333}, {'_account_id': 11387}]","[{'number': 1, 'created': '2014-08-07 06:05:22.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/578647cb40aa3d7705d2615a3946a4769d2fbc01', 'message': 'Delete intersphinx mappings\n\nThe documenatation does not use intersphinx mappings so remove these so\nas not to download them.\n\nRelated-Bug: #1353817\nChange-Id: I0b0e48fa04d08b1023984b6d2169322060fcee9e\n'}]",0,112485,578647cb40aa3d7705d2615a3946a4769d2fbc01,14,6,1,7191,,,0,"Delete intersphinx mappings

The documenatation does not use intersphinx mappings so remove these so
as not to download them.

Related-Bug: #1353817
Change-Id: I0b0e48fa04d08b1023984b6d2169322060fcee9e
",git fetch https://review.opendev.org/openstack/keystone refs/changes/85/112485/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,578647cb40aa3d7705d2615a3946a4769d2fbc01,doc-sites,,"intersphinx_mapping = {'python': ('http://docs.python.org/', None), 'nova': ('http://nova.openstack.org', None), 'swift': ('http://swift.openstack.org', None), 'glance': ('http://glance.openstack.org', None)}",0,4
openstack%2Frally~master~Iaae33e9e1d76b0feb5dc9d6c8f7132fb621e7409,openstack/rally,master,Iaae33e9e1d76b0feb5dc9d6c8f7132fb621e7409,changed image name for nova test,ABANDONED,2014-08-08 17:48:24.000000000,2014-08-08 17:54:49.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-08-08 17:48:24.000000000', 'files': ['rally-scenarios/rally-neutron.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/6c2c5bed4b456d6bb361bd076ed590473948e9d3', 'message': 'changed image name for nova test\n\nChange-Id: Iaae33e9e1d76b0feb5dc9d6c8f7132fb621e7409\n'}]",0,112983,6c2c5bed4b456d6bb361bd076ed590473948e9d3,3,1,1,12722,,,0,"changed image name for nova test

Change-Id: Iaae33e9e1d76b0feb5dc9d6c8f7132fb621e7409
",git fetch https://review.opendev.org/openstack/rally refs/changes/83/112983/1 && git format-patch -1 --stdout FETCH_HEAD,['rally-scenarios/rally-neutron.yaml'],1,6c2c5bed4b456d6bb361bd076ed590473948e9d3,neutron_yaml_modification," sla: max_failure_percent: 0 NovaServers.boot_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.boot_and_delete_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.boot_and_list_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" detailed: True runner: type: ""constant"" times: 1 concurrency: 1 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 NovaServers.boot_and_bounce_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" actions: - hard_reboot: 1 - soft_reboot: 1 - stop_start: 1 - rescue_unrescue: 1 runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.boot_server_from_volume_and_delete: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" volume_size: 10 runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.boot_server_from_volume: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" volume_size: 10 runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.snapshot_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 3 users_per_tenant: 2 sla: max_failure_percent: 0 NovaServers.resize_server: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" to_flavor: name: ""m1.small"" confirm: true runner: type: ""constant"" times: 10 concurrency: 5 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0",,161,0
openstack%2Fbarbican~master~I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d,openstack/barbican,master,I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d,Add support to Barbican for consumer registration,MERGED,2014-07-17 22:52:31.000000000,2014-08-08 17:52:04.000000000,2014-08-08 17:52:04.000000000,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 7874}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 8623}, {'_account_id': 9234}, {'_account_id': 10273}, {'_account_id': 10750}, {'_account_id': 10850}, {'_account_id': 10873}, {'_account_id': 10980}, {'_account_id': 11628}, {'_account_id': 11685}, {'_account_id': 11970}]","[{'number': 1, 'created': '2014-07-17 22:52:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/b0772082ac0340a442656eb6d9e62aec514809de', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 2, 'created': '2014-07-18 22:57:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/eefac8192e203b6e0e83b728bd097ec777626c7a', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 3, 'created': '2014-07-18 23:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/f08e96ecf009217acc872c70b948fa7f59311b9d', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 4, 'created': '2014-07-24 00:17:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/970d0fc44caea1b84800d068b6b0108922e5e61f', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 5, 'created': '2014-07-25 21:37:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/c9729124386ba2d95e3b8668f3a2fb83c020bbe0', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 6, 'created': '2014-07-28 20:52:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/2b8090a8b0c29fff153ead58a019f4720b9ca63a', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 7, 'created': '2014-07-30 00:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/a2128f3875a9e9b0d9e1ace6ed28e3fbb4ebc97d', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 8, 'created': '2014-07-30 16:27:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/c13d4d0f086bb36d43a0f52ff757e45a607f86bf', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 9, 'created': '2014-07-30 20:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/ab97de55a6e1012930f3d75114a704baec1976d2', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 10, 'created': '2014-07-30 21:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/f7ff316ce47af201f5bd5d376e390aad680d8f75', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 11, 'created': '2014-07-31 19:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/a3a0fa921442f53e947143dfe24e0e1d74a4c1e7', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 12, 'created': '2014-07-31 22:38:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/c0bb894fc2ec7dbe55e8fa4a0e24474b5ad562fd', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 13, 'created': '2014-07-31 23:40:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/22c7d5dd875d991d6514a6ff5c83b62cc78af9fa', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 14, 'created': '2014-08-01 05:15:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/fb6edd4be17c477dbb5823cc3f2cce660a240600', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 15, 'created': '2014-08-01 21:03:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/ce3b23dfb0225c4f8063cdb60110efc3c71e6de0', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 16, 'created': '2014-08-01 23:34:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/180907ac1351cc5e353a05e8dcabcedc6c654caa', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 17, 'created': '2014-08-04 21:34:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/6f9ba25cd94e0c065034182af38f1a5dc385aa7c', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 18, 'created': '2014-08-04 23:16:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/54fd9942d4d2b503b06727e15b94eb0f458b9f9b', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 19, 'created': '2014-08-05 21:18:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/9ad3dd9662c481bc17a2670a365188a00e329a88', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 20, 'created': '2014-08-06 22:45:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/98703ee8351e098931885ff8e0db432a5b2cdee6', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 21, 'created': '2014-08-06 23:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/8cc92d72f23bf67ee76213beaf627fa8a9507295', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 22, 'created': '2014-08-07 00:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/668e4860e95f2fd0209c7013e93358d75ae907cc', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 23, 'created': '2014-08-07 00:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/1ada41f0d373950f0852a4b4b0ca6e553082bc6e', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 24, 'created': '2014-08-07 00:39:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/afa03a28c60d0b0f824bf83dc7b4bfdea8e1c005', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 25, 'created': '2014-08-07 01:03:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/aa1b3e4063082d1fce4e78c887f08384fbc9ba17', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 26, 'created': '2014-08-07 14:14:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/44d4a9a8a1c992074648056aff8c3ba37a7d4c4c', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 27, 'created': '2014-08-08 00:28:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/719d7dac351a42c4238559ea3e1f05e85213edc7', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}, {'number': 28, 'created': '2014-08-08 00:30:50.000000000', 'files': ['barbican/model/repositories.py', 'barbican/common/validators.py', 'etc/barbican/policy.json', 'barbican/tests/api/test_resources_policy.py', 'barbican/model/models.py', 'barbican/api/controllers/consumers.py', 'barbican/tests/common/test_validators.py', 'barbican/api/controllers/containers.py', 'functionaltests/api/v1/test_consumers.py', 'barbican/tests/model/test_models.py', 'barbican/tests/api/test_resources.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/fd9901b460b94f48ca2cb69717f41a1828eca3b7', 'message': 'Add support to Barbican for consumer registration\n\nAllow consumers to register interest in Barbican\ncontainers and secrets.\n\nChange-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d\nImplements: blueprint api-add-container-registration\n'}]",101,107845,fd9901b460b94f48ca2cb69717f41a1828eca3b7,245,17,28,10273,,,0,"Add support to Barbican for consumer registration

Allow consumers to register interest in Barbican
containers and secrets.

Change-Id: I5d0a1f0aacaa503a6c1e1d3b599b40cf2d88bf9d
Implements: blueprint api-add-container-registration
",git fetch https://review.opendev.org/openstack/barbican refs/changes/45/107845/26 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/model/repositories.py', 'barbican/common/validators.py', 'etc/barbican/policy.json', 'barbican/model/models.py', 'barbican/api/controllers/consumers.py', 'barbican/api/controllers/containers.py', 'barbican/tests/api/test_resources.py']",7,b0772082ac0340a442656eb6d9e62aec514809de,112735,"def create_consumer(container_id, id_ref): """"""Generate a ContainerConsumerMetadatum entity instance."""""" consumer = models.ContainerConsumerMetadatum(container_id) consumer.id = id_ref consumer.name = 'test name' consumer.URL = 'http://test/url' return consumer self.tenant_repo, self.container_repo, self.secret_repo, self.consumer_repo self.consumer_repo = mock.MagicMock() self.consumer_repo.create_from.return_value = None self.tenant_repo, self.container_repo, self.secret_repo, self.consumer_repo self.consumer_repo = mock.MagicMock() class WhenCreatingConsumersUsingConsumersResource(FunctionalTest): def setUp(self): super( WhenCreatingConsumersUsingConsumersResource, self ).setUp() self.app = webtest.TestApp(app.PecanAPI(self.root)) @property def root(self): self._init() class RootController(object): containers = controllers.containers.ContainersController( self.tenant_repo, self.container_repo, self.secret_repo, self.consumer_repo ) return RootController() def _init(self): self.name = 'test container name' self.type = 'generic' self.secret_refs = [ { 'name': 'test secret 1', 'secret_ref': '1231' }, { 'name': 'test secret 2', 'secret_ref': '1232' }, { 'name': 'test secret 3', 'secret_ref': '1233' } ] self.consumer_ref = { 'name': 'test_consumer', 'URL': 'http://consumer/1' } self.tenant_internal_id = 'tenantid1234' self.tenant_keystone_id = 'keystoneid1234' self.container = create_container(id_ref='id1') self.tenant = models.Tenant() self.tenant.id = self.tenant_internal_id self.tenant.keystone_id = self.tenant_keystone_id self.tenant_repo = mock.MagicMock() self.tenant_repo.get.return_value = self.tenant self.container_repo = mock.MagicMock() self.container_repo.get.return_value = self.container self.secret_repo = mock.MagicMock() self.secret_repo.create_from.return_value = None self.consumer_repo = mock.MagicMock() self.consumer_repo.create_from.return_value = None self.container_req = {'name': self.name, 'type': self.type, 'secret_refs': self.secret_refs} def test_should_add_new_consumer(self): resp = self.app.post_json( '/%s/containers/%s/consumers/' % (self.tenant_keystone_id, self.container.id), self.consumer_ref ) self.assertEqual(resp.status_int, 200) args, kwargs = self.consumer_repo.create_from.call_args consumer = args[0] self.assertIsInstance(consumer, models.ContainerConsumerMetadatum) def test_should_fail_consumer_bad_json(self): resp = self.app.post( '/%s/containers/%s/consumers/' % (self.tenant_keystone_id, self.container.id), '', expect_errors=True ) self.assertEqual(resp.status_int, 400) def test_should_throw_exception_when_container_ref_doesnt_exist(self): self.container_repo.get.return_value = None resp = self.app.post_json( '/%s/containers/%s/consumers/' % (self.tenant_keystone_id, self.container.id), self.consumer_ref, expect_errors=True ) self.assertEqual(resp.status_int, 404) class WhenGettingOrDeletingConsumersUsingConsumerResource(FunctionalTest): def setUp(self): super( WhenGettingOrDeletingConsumersUsingConsumerResource, self ).setUp() self.app = webtest.TestApp(app.PecanAPI(self.root)) @property def root(self): self._init() class RootController(object): containers = controllers.containers.ContainersController( self.tenant_repo, self.container_repo, self.secret_repo, self.consumer_repo ) return RootController() def _init(self): self.tenant_keystone_id = 'keystoneid1234' self.tenant_internal_id = 'tenantid1234' self.tenant = models.Tenant() self.tenant.id = self.tenant_internal_id self.tenant.keystone_id = self.tenant_keystone_id self.tenant_repo = mock.MagicMock() self.tenant_repo.get.return_value = self.tenant self.consumer_repo = mock.MagicMock() self.container = create_container(id_ref='id1') self.consumer = create_consumer(self.container.id, id_ref='id2') self.consumer_ref = { 'name': self.consumer.name, 'URL': self.consumer.URL } self.container_repo = mock.MagicMock() self.container_repo.get.return_value = self.container self.consumer_repo.get_by_container_id.return_value = \ ([self.consumer], 0, 0, 1) self.consumer_repo.get_by_values.return_value = self.consumer self.consumer_repo.delete_entity_by_id.return_value = None self.secret_repo = mock.MagicMock() def test_should_get_consumer(self): resp = self.app.get('/%s/containers/%s/consumers/' % ( self.tenant_keystone_id, self.container.id )) self.assertEqual(resp.status_int, 200) self.consumer_repo.get_by_container_id \ .assert_called_once_with(self.container.id, limit_arg=None, offset_arg=0, suppress_exception=True) self.assertEqual(self.consumer.name, resp.json['consumers'][0]['name']) self.assertEqual(self.consumer.URL, resp.json['consumers'][0]['URL']) def test_should_delete_consumer(self): self.app.delete_json('/%s/containers/%s/consumers/' % ( self.tenant_keystone_id, self.container.id ), self.consumer_ref) self.consumer_repo.delete_entity_by_id \ .assert_called_once_with(self.consumer.id, self.tenant_keystone_id) # def test_should_throw_exception_for_get_when_container_not_found(self): # resp = self.app.get('/%s/containers/%s/consumers/' % ( # self.tenant_keystone_id, self.container.id # ), expect_errors=True) # self.assertEqual(resp.status_int, 404) def test_should_throw_exception_for_delete_when_consumer_not_found(self): self.consumer_repo.delete_entity_by_id.side_effect = excep.NotFound( ""Test not found exception"") resp = self.app.delete_json('/%s/containers/%s/consumers/' % ( self.tenant_keystone_id, self.container.id ), self.consumer_ref, expect_errors=True) self.assertEqual(resp.status_int, 404) #Error response should have json content type self.assertEqual(resp.content_type, ""application/json"") self.tenant_repo, self.container_repo, self.secret_repo, self.consumer_repo self.consumer_repo = mock.MagicMock()"," self.tenant_repo, self.container_repo, self.secret_repo self.tenant_repo, self.container_repo, self.secret_repo self.tenant_repo, self.container_repo, self.secret_repo",573,9
openstack%2Fneutron~master~If5324dc068765442836d7ba4b9d25a431ba32d7a,openstack/neutron,master,If5324dc068765442836d7ba4b9d25a431ba32d7a,Fix l2pop DVR regression,ABANDONED,2014-08-05 09:55:55.000000000,2014-08-08 17:49:22.000000000,,"[{'_account_id': 3}, {'_account_id': 304}, {'_account_id': 748}, {'_account_id': 2888}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 6876}, {'_account_id': 7448}, {'_account_id': 9361}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-08-05 09:55:55.000000000', 'files': ['neutron/tests/unit/agent/test_l2population_rpc.py', 'neutron/plugins/ml2/drivers/l2pop/mech_driver.py', 'neutron/tests/unit/agent/l2population_rpc_base.py', 'neutron/tests/unit/openvswitch/test_ovs_neutron_agent.py', 'neutron/agent/l2population_rpc.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b22a184add000d81cf8134aecb1ba00c225bccad', 'message': 'Fix l2pop DVR regression\n\nCloses-Bug: #1352801\nChange-Id: If5324dc068765442836d7ba4b9d25a431ba32d7a\n'}]",7,111966,b22a184add000d81cf8134aecb1ba00c225bccad,28,25,1,6854,,,0,"Fix l2pop DVR regression

Closes-Bug: #1352801
Change-Id: If5324dc068765442836d7ba4b9d25a431ba32d7a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/66/111966/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/agent/test_l2population_rpc.py', 'neutron/plugins/ml2/drivers/l2pop/mech_driver.py', 'neutron/tests/unit/agent/l2population_rpc_base.py', 'neutron/tests/unit/openvswitch/test_ovs_neutron_agent.py', 'neutron/agent/l2population_rpc.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py']",6,b22a184add000d81cf8134aecb1ba00c225bccad,bug/1352801, if not self.dvr_agent.is_dvr_router_interface(port_info[2]):, if not self.dvr_agent.is_dvr_router_interface(port_info[1]):,54,35
openstack%2Fironic~master~I069a74ea60ba678fb128f27858db169f4dac89a6,openstack/ironic,master,I069a74ea60ba678fb128f27858db169f4dac89a6,Correct `op.drop_constraint` parameters,MERGED,2014-08-08 14:36:09.000000000,2014-08-08 17:35:52.000000000,2014-08-08 17:35:52.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6773}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-08-08 14:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2378f5e31fdf66d29dba9bb97575b84b797187b7', 'message': 'Correct `op.drop_constraint` parameters\n\n`drop_constraint` method require `type_` parameter, when called with\nMySQL.\n\n> type_  optional, required on MySQL. can be ""foreignkey"", ""primary"",\n""unique"", or ""check"".\n\nChange-Id: I069a74ea60ba678fb128f27858db169f4dac89a6\nCloses-Bug: # 1354463\n'}, {'number': 2, 'created': '2014-08-08 14:39:51.000000000', 'files': ['ironic/db/sqlalchemy/alembic/versions/3bea56f25597_add_unique_constraint_to_instance_uuid.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/480df3fd8cc55d926c8167891ce46670d79b82bc', 'message': 'Correct `op.drop_constraint` parameters\n\n`drop_constraint` method require `type_` parameter, when called with\nMySQL.\n\n> type_  optional, required on MySQL. can be ""foreignkey"", ""primary"",\n""unique"", or ""check"".\n\nChange-Id: I069a74ea60ba678fb128f27858db169f4dac89a6\nCloses-Bug: #1354463\n'}]",0,112896,480df3fd8cc55d926c8167891ce46670d79b82bc,12,4,2,7536,,,0,"Correct `op.drop_constraint` parameters

`drop_constraint` method require `type_` parameter, when called with
MySQL.

> type_  optional, required on MySQL. can be ""foreignkey"", ""primary"",
""unique"", or ""check"".

Change-Id: I069a74ea60ba678fb128f27858db169f4dac89a6
Closes-Bug: #1354463
",git fetch https://review.opendev.org/openstack/ironic refs/changes/96/112896/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/db/sqlalchemy/alembic/versions/3bea56f25597_add_unique_constraint_to_instance_uuid.py'],1,2378f5e31fdf66d29dba9bb97575b84b797187b7,test_alembic_migrations_oslo," op.drop_constraint(""uniq_nodes0instance_uuid"", ""nodes"", type_='unique')"," op.drop_constraint(""uniq_nodes0instance_uuid"", ""nodes"")",1,1
openstack%2Fironic-specs~master~Ic2856a349f57dd15126740c128a2e24b7270810a,openstack/ironic-specs,master,Ic2856a349f57dd15126740c128a2e24b7270810a,iLO Virtual Media IPA Deploy Driver,MERGED,2014-07-21 17:19:59.000000000,2014-08-08 17:25:43.000000000,2014-08-08 17:25:41.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 9315}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 10343}]","[{'number': 1, 'created': '2014-07-21 17:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/039f6f858ea5da95e87c9d3866c7ab2ed04322ab', 'message': 'iLO-IPA Deploy Driver\n\nThis spec talks about creating a new driver which will use iLO virtual\nmedia as the boot mechanism and IPA as the deploy engine.\n\nChange-Id: Ic2856a349f57dd15126740c128a2e24b7270810a\n'}, {'number': 2, 'created': '2014-07-31 17:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/aeec2db797a15536cf110a42bff14eba5ec11517', 'message': 'iLO-IPA Deploy Driver\n\nThis spec talks about creating a new driver which will use iLO virtual\nmedia as the boot mechanism and IPA as the deploy engine.\n\nChange-Id: Ic2856a349f57dd15126740c128a2e24b7270810a\n'}, {'number': 3, 'created': '2014-07-31 18:11:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/0bc2e689fd601febbf141c622c201924ec9afb1a', 'message': 'iLO-IPA Deploy Driver\n\nThis spec talks about creating a new driver which will use iLO virtual\nmedia as the boot mechanism and IPA as the deploy engine.\n\nChange-Id: Ic2856a349f57dd15126740c128a2e24b7270810a\n'}, {'number': 4, 'created': '2014-08-01 18:11:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/53d25af3e8ba46cbad9ddd3ec9e9e7d133b54999', 'message': 'iLO-IPA Deploy Driver\n\nThis spec talks about creating a new driver which will use iLO virtual\nmedia as the boot mechanism and IPA as the deploy engine.\n\nChange-Id: Ic2856a349f57dd15126740c128a2e24b7270810a\n'}, {'number': 5, 'created': '2014-08-01 20:08:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/d74ac125cb327dcbed976be6f01bea97b655fe29', 'message': 'iLO-IPA Deploy Driver\n\nThis spec talks about creating a new driver which will use iLO virtual\nmedia as the boot mechanism and IPA as the deploy engine.\n\nChange-Id: Ic2856a349f57dd15126740c128a2e24b7270810a\n'}, {'number': 6, 'created': '2014-08-06 17:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/47c4dbe66a3488abf5d53fd66d832b0d923cdf72', 'message': 'iLO Virtual Media IPA Deploy Driver\n\nAdd ability to provision proliant baremetal nodes (having iLO4 and\nbeyond) by booting the baremetal node with virtual media and using\nIPA to deploy the image.\n\nChange-Id: Ic2856a349f57dd15126740c128a2e24b7270810a\n'}, {'number': 7, 'created': '2014-08-08 06:54:32.000000000', 'files': ['specs/juno/ilo-virtualmedia-ipa.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/820506329a00f00bf5abd0d854713cd3c98bb5b4', 'message': 'iLO Virtual Media IPA Deploy Driver\n\nAdd ability to provision proliant baremetal nodes (having iLO4 and\nbeyond) by booting the baremetal node with virtual media and using\nIPA to deploy the image.\n\nChange-Id: Ic2856a349f57dd15126740c128a2e24b7270810a\n'}]",36,108445,820506329a00f00bf5abd0d854713cd3c98bb5b4,45,6,7,9315,,,0,"iLO Virtual Media IPA Deploy Driver

Add ability to provision proliant baremetal nodes (having iLO4 and
beyond) by booting the baremetal node with virtual media and using
IPA to deploy the image.

Change-Id: Ic2856a349f57dd15126740c128a2e24b7270810a
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/45/108445/7 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/ilo-ipa-deploy-driver.rst'],1,039f6f858ea5da95e87c9d3866c7ab2ed04322ab,vmedia_ipa,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ===================== iLO IPA Deploy Driver ===================== This spec talks about creating a new driver which will use iLO virtual media as the boot mechanism and IPA as the deploy engine. Problem description =================== IPA project provides a more powerful ramdisk for doing deploy from the conductor node. But IPA has the following issues: - Some customer's don't prefer PXE protocol in their environment because of it unreliability and security issues. - Deployers require an extra tftp service to be running on the conductor node. Proposed change =============== The below review introduced a new mechanism for booting proliant machines with virtual media. https://review.openstack.org/#/c/97744 IPA build mechanism can be changed to build up an ISO image comprising of the IPA kernel and IPA agent ramdisk. The class ``VirtualMediaBootManager`` introduced in the above review can be used to boot up a baremetal node with the deploy ISO image. A new class ``IloVirtualMediaAgentDeploy`` can be added which will setup the machine to be booted with virtual media instead of PXE. The vendor interface ``AgentVendorInterface`` can be reused to continue the deploy and complete it. Alternatives ------------ The proliant machines can continue to work booting the agent ramdisk with PXE, but virtual media customers can take advantage of it. Data model impact ----------------- The new deploy driver will use two new parameters: - driver_info['deploy_iso'] - This will be used to boot up the node before the deploy. REST API impact --------------- None. Driver API impact ----------------- None. Nova driver impact ------------------ None. Security impact --------------- None. Other end user impact --------------------- None. Scalability impact ------------------ None. Performance Impact ------------------ None. Other deployer impact --------------------- This method of deploy doesn't require an extra service (like tftp service incase of pxe driver) to be running on the conductor node. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: rameshg87 Work Items ---------- * Add ``IloVirtualMediaAgentDeploy`` which implements base.DeployInterface. Dependencies ============ * iLO Virtual Media iSCSI Deploy Driver: https://review.openstack.org/#/c/97744 Testing ======= Unit tests will be added for all the code. Tempest tests need to be added for carrying out deploy, but will be decided later. Documentation Impact ==================== The procedure for configuring the proliant baremetal node will need to be documented. This will be documented in rst format in doc/ directory in ironic source tree. The contents of this file can be put in ironic wiki as well. References ========== None.",,118,0
openstack-attic%2Fidentity-api~master~Ie056297f713f71eb7dd47e6cdea87579c600cfae,openstack-attic/identity-api,master,Ie056297f713f71eb7dd47e6cdea87579c600cfae,Add OS-FEDERATION section to scoped federation tokens,MERGED,2014-08-05 00:34:08.000000000,2014-08-08 17:22:41.000000000,2014-08-08 17:22:40.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 8978}, {'_account_id': 9162}]","[{'number': 1, 'created': '2014-08-05 00:34:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/73336da0f95193f49344f9185f711605d19fa735', 'message': 'Add OS-FEDERATION section to scoped federation tokens\n\nAdd an OS-FEDERATION section to the user section in a scoped\nfederation token. We currently do the same for unscoped tokens.\n\nChange-Id: Ie056297f713f71eb7dd47e6cdea87579c600cfae\nPartial-Bug: #1351038\n'}, {'number': 2, 'created': '2014-08-06 12:53:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/c42dea66e5b6694efa6cb72008137c1721b67b64', 'message': 'Add OS-FEDERATION section to scoped federation tokens\n\nAdd an OS-FEDERATION section to the user section in a scoped\nfederation token. We currently do the same for unscoped tokens.\n\nChange-Id: Ie056297f713f71eb7dd47e6cdea87579c600cfae\nPartial-Bug: #1351038\n'}, {'number': 3, 'created': '2014-08-07 20:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/85cda2cbb51c821703883513c2fa43221c8f707a', 'message': 'Add OS-FEDERATION section to scoped federation tokens\n\nAdd an OS-FEDERATION section to the user section in a scoped\nfederation token. We currently do the same for unscoped tokens.\n\nChange-Id: Ie056297f713f71eb7dd47e6cdea87579c600cfae\nPartial-Bug: #1351038\n'}, {'number': 4, 'created': '2014-08-08 14:55:29.000000000', 'files': ['v3/src/markdown/identity-api-v3-os-federation-ext.md'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/b37dfa66eb1b31e4eaab2d82585e75e60be28570', 'message': 'Add OS-FEDERATION section to scoped federation tokens\n\nAdd an OS-FEDERATION section to the user section in a scoped\nfederation token. We currently do the same for unscoped tokens.\n\nChange-Id: Ie056297f713f71eb7dd47e6cdea87579c600cfae\nPartial-Bug: #1351038\n'}]",6,111873,b37dfa66eb1b31e4eaab2d82585e75e60be28570,30,7,4,6482,,,0,"Add OS-FEDERATION section to scoped federation tokens

Add an OS-FEDERATION section to the user section in a scoped
federation token. We currently do the same for unscoped tokens.

Change-Id: Ie056297f713f71eb7dd47e6cdea87579c600cfae
Partial-Bug: #1351038
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/73/111873/1 && git format-patch -1 --stdout FETCH_HEAD,['v3/src/markdown/identity-api-v3-os-federation-ext.md'],1,73336da0f95193f49344f9185f711605d19fa735,hn," Similarly to the returned unscoped token, the returned scoped token will have an `OS-FEDERATION` section added to the `user` portion of the token. Example of an OS-FEDERATION token: { ""token"": { ""methods"": [ ""saml2"" ], ""project"": { ""domain"": { ""id"": ""1789d1"", ""links"": { ""self"": ""http://identity:35357/v3/domains/1789d1"" }, ""name"": ""example.com"" }, ""id"": ""263fd9"", ""links"": { ""self"": ""http://identity:35357/v3/projects/263fd9"" }, ""name"": ""project-x"" }, ""user"": { ""id"": ""username%40example.com"", ""name"": ""username@example.com"", ""OS-FEDERATION"": { ""identity_provider"": ""ACME"", ""protocol"": ""SAML"", ""groups"": [ {""id"": ""abc123""}, {""id"": ""bcd234""} ] } } } }",,39,0
openstack%2Fheat~master~Ia761c08cd11f7772518e4c60bee6a1232c2d86c7,openstack/heat,master,Ia761c08cd11f7772518e4c60bee6a1232c2d86c7,Maintain compatibility with plugin_dirs config option,ABANDONED,2014-08-01 21:19:14.000000000,2014-08-08 17:15:40.000000000,,"[{'_account_id': 3}, {'_account_id': 7253}, {'_account_id': 10487}]","[{'number': 1, 'created': '2014-08-01 21:19:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a940287b9e2c215acd5edeb0b7ad2dd1cb9815e0', 'message': ""Maintain compatibility with plugin_dirs config option\n\nDon't let the plugin loader try to load setup.py as a resource plugin.\n\nblueprint client-plugins\n\nChange-Id: Ia761c08cd11f7772518e4c60bee6a1232c2d86c7\n""}, {'number': 2, 'created': '2014-08-01 21:21:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4d3d2a81c65cb4da423d015eaf5a78d24f12c98e', 'message': ""Maintain compatibility with plugin_dirs config option\n\nDon't let the plugin loader try to load setup.py as a resource plugin.\n\nblueprint client-plugins\n\nChange-Id: Ia761c08cd11f7772518e4c60bee6a1232c2d86c7\n""}, {'number': 3, 'created': '2014-08-04 17:31:51.000000000', 'files': ['heat/common/plugin_loader.py', 'heat/tests/test_plugin_loader.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/254081ebcc52ff93432a9a0719e713ce3c9064ff', 'message': ""Maintain compatibility with plugin_dirs config option\n\nDon't let the plugin loader try to load setup.py as a resource plugin.\n\nblueprint client-plugins\n\nChange-Id: Ia761c08cd11f7772518e4c60bee6a1232c2d86c7\n""}]",2,111393,254081ebcc52ff93432a9a0719e713ce3c9064ff,14,3,3,7253,,,0,"Maintain compatibility with plugin_dirs config option

Don't let the plugin loader try to load setup.py as a resource plugin.

blueprint client-plugins

Change-Id: Ia761c08cd11f7772518e4c60bee6a1232c2d86c7
",git fetch https://review.opendev.org/openstack/heat refs/changes/93/111393/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/common/plugin_loader.py'],1,a940287b9e2c215acd5edeb0b7ad2dd1cb9815e0,bp/client-plugins, # Maintain compatibility with plugin_dirs config option if '.setup' in module_name: continue ,,4,0
openstack%2Foslo-specs~master~Ib761d240fd8bae1ffdcfd004501d5ccdf6484ef0,openstack/oslo-specs,master,Ib761d240fd8bae1ffdcfd004501d5ccdf6484ef0,clean up toctree now that we are publishing,MERGED,2014-08-06 14:23:34.000000000,2014-08-08 17:12:05.000000000,2014-08-08 17:12:05.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2014-08-06 14:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/feb39303485cdc5702fc1a225213a7c0022ba926', 'message': 'clean up toctree now that we are publishing\n\nChange-Id: Ib761d240fd8bae1ffdcfd004501d5ccdf6484ef0\n'}, {'number': 2, 'created': '2014-08-08 15:06:36.000000000', 'files': ['specs/index.rst', 'doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/4fb6fde9e8049d4cda2eceef3582eeef0c2d719a', 'message': 'clean up toctree now that we are publishing\n\nChange-Id: Ib761d240fd8bae1ffdcfd004501d5ccdf6484ef0\n'}]",0,112317,4fb6fde9e8049d4cda2eceef3582eeef0c2d719a,11,2,2,2472,,,0,"clean up toctree now that we are publishing

Change-Id: Ib761d240fd8bae1ffdcfd004501d5ccdf6484ef0
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/17/112317/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,feb39303485cdc5702fc1a225213a7c0022ba926,fix-toctree,Juno ==== :maxdepth: 1 specs/juno/* :maxdepth: 1 Sample Feature Template <specs/template> Sample Graduation Template <specs/graduation-template>, :maxdepth: 2 specs/* :maxdepth: 2 Sample Template <specs/template>,8,4
openstack%2Fneutron~master~I4735e20f5b8b23c5b2a9d896415c2e84561a279c,openstack/neutron,master,I4735e20f5b8b23c5b2a9d896415c2e84561a279c,Fix to throw correct error code for bad attribute,MERGED,2014-08-05 14:12:51.000000000,2014-08-08 17:03:11.000000000,2014-08-08 17:03:09.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5950}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 7293}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 8190}, {'_account_id': 8344}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9775}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 9970}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12441}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-08-05 14:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0062e5dc4df24bb4811dd2aa520af419d4012c21', 'message': 'Fix to throw correct error code for bad attribute\n\nCurrently the neutron network API throws up error code 500 for\nthe extended attribute for segmentation id. This can be reproduced\nif the user types in a random string in place of an integer value\nfor the segmentation id. The proper behavior should throw an error\ncode 400 with the appropriate failure message. This patch fixes the\nsame issue and covers it with a test case.\n\nChange-Id: I4735e20f5b8b23c5b2a9d896415c2e84561a279c\nCloses-bug: #1348056\n'}, {'number': 2, 'created': '2014-08-05 17:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3d5ae4f3c8a15e90423e858af3e9d89d72b84df3', 'message': 'Fix to throw correct error code for bad attribute\n\nCurrently the neutron network API throws up error code 500 for\nthe extended attribute for segmentation id. This can be reproduced\nif the user types in a random string in place of an integer value\nfor the segmentation id. The proper behavior should throw an error\ncode 400 with the appropriate failure message. This patch fixes the\nsame issue and covers it with a test case.\n\nChange-Id: I4735e20f5b8b23c5b2a9d896415c2e84561a279c\nCloses-bug: #1348056\n'}, {'number': 3, 'created': '2014-08-06 03:41:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3fe535540fc1bdc6dacf8863d813bb7e373cba9b', 'message': 'Fix to throw correct error code for bad attribute\n\nCurrently the neutron network API throws up error code 500 for\nthe extended attribute for segmentation id. This can be reproduced\nif the user types in a random string in place of an integer value\nfor the segmentation id. The proper behavior should throw an error\ncode 400 with the appropriate failure message. This patch fixes the\nsame issue and covers it with a test case.\n\nChange-Id: I4735e20f5b8b23c5b2a9d896415c2e84561a279c\nCloses-bug: #1348056\n'}, {'number': 4, 'created': '2014-08-06 08:59:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/24c9aa2185a636db06019f55964e24342223b62f', 'message': 'Fix to throw correct error code for bad attribute\n\nCurrently the neutron network API throws up error code 500 for\nthe extended attribute for segmentation id. This can be reproduced\nif the user types in a random string in place of an integer value\nfor the segmentation id. The proper behavior should throw an error\ncode 400 with the appropriate failure message. This patch fixes the\nsame issue and covers it with a test case.\n\nChange-Id: I4735e20f5b8b23c5b2a9d896415c2e84561a279c\nCloses-bug: #1348056\n'}, {'number': 5, 'created': '2014-08-08 05:00:31.000000000', 'files': ['neutron/tests/unit/test_extension_pnet.py', 'neutron/extensions/providernet.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6b8a5f0e1d26d2721e7ad7fc67099ff8b880d9ec', 'message': 'Fix to throw correct error code for bad attribute\n\nCurrently the neutron network API throws up error code 500 for\nthe extended attribute for segmentation id. This can be reproduced\nif the user types in a random string in place of an integer value\nfor the segmentation id. The proper behavior should throw an error\ncode 400 with the appropriate failure message. This patch fixes the\nsame issue and covers it with a test case.\n\nChange-Id: I4735e20f5b8b23c5b2a9d896415c2e84561a279c\nCloses-bug: #1348056\n'}]",9,112031,6b8a5f0e1d26d2721e7ad7fc67099ff8b880d9ec,130,31,5,9775,,,0,"Fix to throw correct error code for bad attribute

Currently the neutron network API throws up error code 500 for
the extended attribute for segmentation id. This can be reproduced
if the user types in a random string in place of an integer value
for the segmentation id. The proper behavior should throw an error
code 400 with the appropriate failure message. This patch fixes the
same issue and covers it with a test case.

Change-Id: I4735e20f5b8b23c5b2a9d896415c2e84561a279c
Closes-bug: #1348056
",git fetch https://review.opendev.org/openstack/neutron refs/changes/31/112031/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_extension_pnet.py', 'neutron/extensions/providernet.py']",2,0062e5dc4df24bb4811dd2aa520af419d4012c21,bug/1348056," def convert_to_int(data): try: return int(data) except (ValueError, TypeError): msg = _(""'%s' is not a integer"") % data raise n_exc.InvalidInput(error_message=msg) 'convert_to': convert_to_int,"," 'convert_to': int,",28,1
openstack%2Fos-collect-config~master~I0e58e8c631ffe8b63e8b4117df2c9ce2f413044f,openstack/os-collect-config,master,I0e58e8c631ffe8b63e8b4117df2c9ce2f413044f,Add a local data collector,MERGED,2014-07-24 22:04:46.000000000,2014-08-08 16:59:36.000000000,2014-08-08 16:59:35.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6449}, {'_account_id': 7144}, {'_account_id': 11655}]","[{'number': 1, 'created': '2014-07-24 22:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/37920cd405e505f92b77aa9f77b2b50f39aee779', 'message': 'Add a local data collector\n\nThis collector will collect data from the local system, allowing image\nbuilds or simple processes to influence the metadata.\n\nimplements bp tripleo-juno-occ-localdatasource\n\nChange-Id: I0e58e8c631ffe8b63e8b4117df2c9ce2f413044f\n'}, {'number': 2, 'created': '2014-07-24 22:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/1cf5de6bfc63255f4fedff2681b660e02683372f', 'message': 'Add a local data collector\n\nThis collector will collect data from the local system, allowing image\nbuilds or simple processes to influence the metadata.\n\nimplements bp tripleo-juno-occ-localdatasource\n\nChange-Id: I0e58e8c631ffe8b63e8b4117df2c9ce2f413044f\n'}, {'number': 3, 'created': '2014-07-25 03:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/ef35cb36a7f95942d9e3b153a083210f950e6a95', 'message': 'Add a local data collector\n\nThis collector will collect data from the local system, allowing image\nbuilds or simple processes to influence the metadata.\n\nimplements bp tripleo-juno-occ-localdatasource\n\nChange-Id: I0e58e8c631ffe8b63e8b4117df2c9ce2f413044f\n'}, {'number': 4, 'created': '2014-07-29 19:15:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/bbc550ddc58722faba5249e70d69fa0babfce2e4', 'message': 'Add a local data collector\n\nThis collector will collect data from the local system, allowing image\nbuilds or simple processes to influence the metadata.\n\nimplements bp tripleo-juno-occ-localdatasource\n\nChange-Id: I0e58e8c631ffe8b63e8b4117df2c9ce2f413044f\n'}, {'number': 5, 'created': '2014-07-29 19:23:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/415bf1a0b8a8adda2216d56b0a541fe89c03f54a', 'message': 'Add a local data collector\n\nThis collector will collect data from the local system, allowing image\nbuilds or simple processes to influence the metadata.\n\nimplements bp tripleo-juno-occ-localdatasource\n\nChange-Id: I0e58e8c631ffe8b63e8b4117df2c9ce2f413044f\n'}, {'number': 6, 'created': '2014-08-08 14:30:38.000000000', 'files': ['os_collect_config/tests/test_local.py', 'os_collect_config/collect.py', 'os_collect_config/exc.py', 'os_collect_config/local.py'], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/4696fd4f933b5aec1d7da39ec8fef336d6217734', 'message': 'Add a local data collector\n\nThis collector will collect data from the local system, allowing image\nbuilds or simple processes to influence the metadata.\n\nimplements bp tripleo-juno-occ-localdatasource\n\nChange-Id: I0e58e8c631ffe8b63e8b4117df2c9ce2f413044f\n'}]",13,109431,4696fd4f933b5aec1d7da39ec8fef336d6217734,36,5,6,6488,,,0,"Add a local data collector

This collector will collect data from the local system, allowing image
builds or simple processes to influence the metadata.

implements bp tripleo-juno-occ-localdatasource

Change-Id: I0e58e8c631ffe8b63e8b4117df2c9ce2f413044f
",git fetch https://review.opendev.org/openstack/os-collect-config refs/changes/31/109431/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_collect_config/tests/test_local.py', 'os_collect_config/collect.py', 'os_collect_config/exc.py', 'os_collect_config/local.py']",4,37920cd405e505f92b77aa9f77b2b50f39aee779,bp/tripleo-juno-occ-localdatasource,"# Copyright (c) 2014 Hewlett-Packard Development Company, L.P. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import json import locale import os from oslo.config import cfg import stat from openstack.common import log from os_collect_config import exc HEAT_METADATA_PATH = '/var/lib/os-collect-config/local-data' CONF = cfg.CONF opts = [ cfg.StrOpt('path', default=HEAT_METADATA_PATH, help='Local directory to scan for Metadata files.') ] name = 'local' logger = log.getLogger(__name__) class Collector(object): def __init__(self, requests_impl=None): pass def collect(self): if cfg.CONF.local.path is None: raise exc.LocalMetadataNotAvailable final_content = None for path in os.listdir(cfg.CONF.local.path): if path.startswith('.'): continue if os.path.isdir(path): continue path = os.path.join(cfg.CONF.local.path, path) st = os.stat(path) if st.st_mode & stat.S_IWOTH: logger.error('%s is world writable. This is a security risk.') raise exc.LocalMetadataNotAvailable with open(path) as metadata: try: value = json.loads(metadata.read()) except ValueError as e: logger.error('%s is not valid JSON (%s)' % (path, e)) raise exc.LocalMetadataNotAvailable basename = os.path.basename(path) if final_content is None: final_content = [] final_content.append((basename, value)) if not final_content: logger.warn('No local metadata found (%s)' % cfg.CONF.local.path) # Now sort specifically by C locale def locale_aware_by_first_item(data): return locale.strxfrm(data[0]) save_locale = locale.getlocale(locale.LC_ALL) locale.setlocale(locale.LC_ALL, 'C') sorted_content = sorted(final_content, key=locale_aware_by_first_item) locale.setlocale(locale.LC_ALL, save_locale) return sorted_content ",,204,1
openstack%2Fheat~master~Ic4f482e566f3552b3fdf7129b8447e7def036441,openstack/heat,master,Ic4f482e566f3552b3fdf7129b8447e7def036441,Add config file for performance gate job,MERGED,2014-08-01 13:12:12.000000000,2014-08-08 16:51:49.000000000,2014-08-08 16:51:48.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4715}, {'_account_id': 6172}, {'_account_id': 6577}, {'_account_id': 7369}]","[{'number': 1, 'created': '2014-08-01 13:12:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/576bfd00b2f275ebf4b42b0058970b3f1a0a144f', 'message': 'Add config file for performance gate job\n\nThis job is called gate-rally-dsvm-fakevirt-heat\n\nChange-Id: Ic4f482e566f3552b3fdf7129b8447e7def036441\n'}, {'number': 2, 'created': '2014-08-01 14:44:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a61d177956e550ab5cb00a18bb0ceaf069940fac', 'message': 'Add config file for performance gate job\n\nThis job is called gate-rally-dsvm-fakevirt-heat.\nAlso added readme and plugin sample.\n\nChange-Id: Ic4f482e566f3552b3fdf7129b8447e7def036441\n'}, {'number': 3, 'created': '2014-08-04 08:04:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a875c86aa082c886bd24aa8a4489386b34884ba6', 'message': 'Add config file for performance gate job\n\nThis job is called gate-rally-dsvm-fakevirt-heat.\nAlso added readme and plugin sample.\n\nChange-Id: Ic4f482e566f3552b3fdf7129b8447e7def036441\n'}, {'number': 4, 'created': '2014-08-04 08:39:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d7fc44f0817a6bd7e3a9fb91d0afd3b3685639c7', 'message': 'Add config file for performance gate job\n\nThis job is called gate-rally-dsvm-fakevirt-heat.\nAlso added readme and plugin sample.\n\nChange-Id: Ic4f482e566f3552b3fdf7129b8447e7def036441\n'}, {'number': 5, 'created': '2014-08-07 20:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/731515c21a3b33cdc66e9271a8fcbb36c476ecdf', 'message': 'Add config file for performance gate job\n\nThis job is called gate-rally-dsvm-fakevirt-heat.\nAlso added readme and plugin sample.\n\nChange-Id: Ic4f482e566f3552b3fdf7129b8447e7def036441\n'}, {'number': 6, 'created': '2014-08-07 22:23:02.000000000', 'files': ['rally-scenarios/heat-fakevirt.yaml', 'rally-scenarios/README.rst', 'rally-scenarios/extra/README.rst', 'rally-scenarios/plugins/sample_plugin.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d7cb4cad0c472a56b235b17f4dea15ec1da3b457', 'message': 'Add config file for performance gate job\n\nThis job is called gate-rally-dsvm-fakevirt-heat.\nAlso added readme and plugin sample.\n\nChange-Id: Ic4f482e566f3552b3fdf7129b8447e7def036441\n'}]",2,111273,d7cb4cad0c472a56b235b17f4dea15ec1da3b457,35,6,6,7369,,,0,"Add config file for performance gate job

This job is called gate-rally-dsvm-fakevirt-heat.
Also added readme and plugin sample.

Change-Id: Ic4f482e566f3552b3fdf7129b8447e7def036441
",git fetch https://review.opendev.org/openstack/heat refs/changes/73/111273/3 && git format-patch -1 --stdout FETCH_HEAD,"['rally-scenarios/README.rst', 'rally-scenarios/heat.yaml']",2,576bfd00b2f275ebf4b42b0058970b3f1a0a144f,rally,"--- HeatStacks.create_and_list_stack: - runner: type: ""constant"" times: 10 concurrency: 1 context: users: tenants: 1 users_per_tenant: 1 HeatStacks.create_and_delete_stack: - runner: type: ""constant"" times: 10 concurrency: 2 context: users: tenants: 2 users_per_tenant: 3 ",,27,0
openstack%2Fhorizon~master~Ie5ff663b3032e7fbbd587238d729eda430b0ea43,openstack/horizon,master,Ie5ff663b3032e7fbbd587238d729eda430b0ea43,Sync config module from oslo-incubator,ABANDONED,2014-02-25 10:21:58.000000000,2014-08-08 16:47:14.000000000,,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 10513}]","[{'number': 1, 'created': '2014-02-25 10:21:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/69b9ca078a4961df73a30c4afe7397ebc239e157', 'message': 'Sync common module from oslo-incubator (WORKINPROGRESS)\n\nOur horizon code is out of date, need to be updated.\n\nChange-Id: Ie5ff663b3032e7fbbd587238d729eda430b0ea43\n'}, {'number': 2, 'created': '2014-02-26 03:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c4464c3625f5ec1a7f7552b4976f06b1ef47df24', 'message': 'ync common module from oslo-incubator (WORKINPROGRESS)\n\nOur horizon code is out of date, need to be updated.\n\nChange-Id: Ie5ff663b3032e7fbbd587238d729eda430b0ea43\n'}, {'number': 3, 'created': '2014-02-26 04:16:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d5ff5d66bbb2e568b17dc728640ff1bcc3f73f98', 'message': 'Sync config module from oslo-incubator (WORKINPROGRESS)\n\nOur horizon code is out of date, need to be updated.\n\nChange-Id: Ie5ff663b3032e7fbbd587238d729eda430b0ea43\n'}, {'number': 4, 'created': '2014-02-26 05:12:24.000000000', 'files': ['openstack_dashboard/openstack/common/importutils.py', 'openstack_dashboard/openstack/common/gettextutils.py', 'openstack_dashboard/openstack/common/__init__.py', 'openstack_dashboard/openstack/common/config/generator.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/671c7455ff64dc41d600cee2fc9b98c0ae96cb1c', 'message': 'Sync config module from oslo-incubator\n\nOur horizon code is out of date, need to be updated.\n\nImplements: blueprint horizon-sync-oslo\nChange-Id: Ie5ff663b3032e7fbbd587238d729eda430b0ea43\n'}]",0,76147,671c7455ff64dc41d600cee2fc9b98c0ae96cb1c,13,3,4,10513,,,0,"Sync config module from oslo-incubator

Our horizon code is out of date, need to be updated.

Implements: blueprint horizon-sync-oslo
Change-Id: Ie5ff663b3032e7fbbd587238d729eda430b0ea43
",git fetch https://review.opendev.org/openstack/horizon refs/changes/47/76147/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/openstack/common/rpc/common.py', 'openstack_dashboard/openstack/common/rpc/impl_fake.py', 'openstack_dashboard/openstack/common/versionutils.py', 'openstack_dashboard/openstack/common/network_utils.py', 'openstack_dashboard/openstack/common/rpc/proxy.py', 'openstack_dashboard/openstack/common/sslutils.py', 'openstack_dashboard/openstack/common/rpc/matchmaker.py', 'openstack_dashboard/openstack/common/threadgroup.py', 'tools/config/generate_sample.sh', 'openstack_dashboard/openstack/common/gettextutils.py', 'openstack_dashboard/openstack/common/rpc/impl_zmq.py', 'openstack_dashboard/openstack/common/timeutils.py', 'openstack_dashboard/openstack/common/context.py', 'openstack_dashboard/openstack/common/eventlet_backdoor.py', 'openstack_dashboard/openstack/common/rpc/dispatcher.py', 'tools/config/check_uptodate.sh', 'openstack_dashboard/openstack/common/rpc/__init__.py', 'openstack-common.conf', 'openstack_dashboard/openstack/common/notifier/api.py', 'openstack_dashboard/openstack/common/rpc/impl_qpid.py', 'openstack_dashboard/openstack/common/loopingcall.py', 'openstack_dashboard/openstack/common/notifier/log_notifier.py', 'openstack_dashboard/openstack/common/policy.py', 'openstack_dashboard/openstack/common/jsonutils.py', 'openstack_dashboard/openstack/common/rpc/amqp.py', 'openstack_dashboard/openstack/common/service.py', 'openstack_dashboard/openstack/common/rpc/zmq_receiver.py', 'openstack_dashboard/openstack/common/importutils.py', 'openstack_dashboard/openstack/common/rpc/impl_kombu.py', 'openstack_dashboard/openstack/common/notifier/test_notifier.py', 'openstack_dashboard/openstack/common/notifier/proxy.py', 'openstack_dashboard/openstack/common/local.py', 'openstack_dashboard/openstack/common/log.py', 'openstack_dashboard/openstack/common/rpc/serializer.py', 'openstack_dashboard/openstack/common/rpc/service.py', 'openstack_dashboard/openstack/common/notifier/rpc_notifier.py', 'openstack_dashboard/openstack/common/__init__.py', 'openstack_dashboard/openstack/common/excutils.py', 'openstack_dashboard/openstack/common/config/generator.py', 'openstack_dashboard/openstack/common/fileutils.py', 'openstack_dashboard/openstack/common/notifier/rpc_notifier2.py', 'openstack_dashboard/openstack/common/rpc/matchmaker_redis.py', 'openstack_dashboard/openstack/common/rpc/matchmaker_ring.py', 'openstack_dashboard/openstack/common/uuidutils.py']",44,69b9ca078a4961df73a30c4afe7397ebc239e157,bp/horizon-sync-oslo,,# vim: tabstop=4 shiftwidth=4 softtabstop=4 ,2471,1135
openstack%2Fhorizon~master~Ib8cc71d635099a61eeff8e601b80f02aa6fef12a,openstack/horizon,master,Ib8cc71d635099a61eeff8e601b80f02aa6fef12a,Sync notifier module from oslo-incubator,ABANDONED,2014-02-26 05:20:17.000000000,2014-08-08 16:47:02.000000000,,"[{'_account_id': 3}, {'_account_id': 1941}]","[{'number': 1, 'created': '2014-02-26 05:20:17.000000000', 'files': ['openstack_dashboard/openstack/common/rpc/common.py', 'openstack_dashboard/openstack/common/rpc/impl_fake.py', 'openstack_dashboard/openstack/common/versionutils.py', 'openstack_dashboard/openstack/common/network_utils.py', 'openstack_dashboard/openstack/common/rpc/proxy.py', 'openstack_dashboard/openstack/common/sslutils.py', 'openstack_dashboard/openstack/common/rpc/matchmaker.py', 'openstack_dashboard/openstack/common/threadgroup.py', 'openstack_dashboard/openstack/common/gettextutils.py', 'openstack_dashboard/openstack/common/rpc/impl_zmq.py', 'openstack_dashboard/openstack/common/timeutils.py', 'openstack_dashboard/openstack/common/context.py', 'openstack_dashboard/openstack/common/eventlet_backdoor.py', 'openstack_dashboard/openstack/common/rpc/dispatcher.py', 'openstack_dashboard/openstack/common/rpc/__init__.py', 'openstack_dashboard/openstack/common/notifier/api.py', 'openstack_dashboard/openstack/common/rpc/impl_qpid.py', 'openstack_dashboard/openstack/common/loopingcall.py', 'openstack_dashboard/openstack/common/notifier/log_notifier.py', 'openstack_dashboard/openstack/common/jsonutils.py', 'openstack_dashboard/openstack/common/rpc/amqp.py', 'openstack_dashboard/openstack/common/service.py', 'openstack_dashboard/openstack/common/rpc/zmq_receiver.py', 'openstack_dashboard/openstack/common/importutils.py', 'openstack_dashboard/openstack/common/rpc/impl_kombu.py', 'openstack_dashboard/openstack/common/notifier/test_notifier.py', 'openstack_dashboard/openstack/common/notifier/proxy.py', 'openstack_dashboard/openstack/common/local.py', 'openstack_dashboard/openstack/common/log.py', 'openstack_dashboard/openstack/common/rpc/serializer.py', 'openstack_dashboard/openstack/common/rpc/service.py', 'openstack_dashboard/openstack/common/notifier/rpc_notifier.py', 'openstack_dashboard/openstack/common/__init__.py', 'openstack_dashboard/openstack/common/excutils.py', 'openstack_dashboard/openstack/common/notifier/rpc_notifier2.py', 'openstack_dashboard/openstack/common/rpc/matchmaker_redis.py', 'openstack_dashboard/openstack/common/rpc/matchmaker_ring.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/92273bd2fa849c08da6929f93426e98880fc286c', 'message': 'Sync notifier module from oslo-incubator\n\nOur horizon code is out of date, need to be updated.\n\nChange-Id: Ib8cc71d635099a61eeff8e601b80f02aa6fef12a\nImplements: blueprint horizon-sync-oslo\n'}]",0,76439,92273bd2fa849c08da6929f93426e98880fc286c,5,2,1,10513,,,0,"Sync notifier module from oslo-incubator

Our horizon code is out of date, need to be updated.

Change-Id: Ib8cc71d635099a61eeff8e601b80f02aa6fef12a
Implements: blueprint horizon-sync-oslo
",git fetch https://review.opendev.org/openstack/horizon refs/changes/39/76439/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/openstack/common/rpc/common.py', 'openstack_dashboard/openstack/common/rpc/impl_fake.py', 'openstack_dashboard/openstack/common/versionutils.py', 'openstack_dashboard/openstack/common/network_utils.py', 'openstack_dashboard/openstack/common/rpc/proxy.py', 'openstack_dashboard/openstack/common/sslutils.py', 'openstack_dashboard/openstack/common/rpc/matchmaker.py', 'openstack_dashboard/openstack/common/threadgroup.py', 'openstack_dashboard/openstack/common/gettextutils.py', 'openstack_dashboard/openstack/common/rpc/impl_zmq.py', 'openstack_dashboard/openstack/common/timeutils.py', 'openstack_dashboard/openstack/common/context.py', 'openstack_dashboard/openstack/common/eventlet_backdoor.py', 'openstack_dashboard/openstack/common/rpc/dispatcher.py', 'openstack_dashboard/openstack/common/rpc/__init__.py', 'openstack_dashboard/openstack/common/notifier/api.py', 'openstack_dashboard/openstack/common/rpc/impl_qpid.py', 'openstack_dashboard/openstack/common/loopingcall.py', 'openstack_dashboard/openstack/common/notifier/log_notifier.py', 'openstack_dashboard/openstack/common/jsonutils.py', 'openstack_dashboard/openstack/common/rpc/amqp.py', 'openstack_dashboard/openstack/common/service.py', 'openstack_dashboard/openstack/common/rpc/zmq_receiver.py', 'openstack_dashboard/openstack/common/importutils.py', 'openstack_dashboard/openstack/common/rpc/impl_kombu.py', 'openstack_dashboard/openstack/common/notifier/test_notifier.py', 'openstack_dashboard/openstack/common/notifier/proxy.py', 'openstack_dashboard/openstack/common/local.py', 'openstack_dashboard/openstack/common/log.py', 'openstack_dashboard/openstack/common/rpc/serializer.py', 'openstack_dashboard/openstack/common/rpc/service.py', 'openstack_dashboard/openstack/common/notifier/rpc_notifier.py', 'openstack_dashboard/openstack/common/__init__.py', 'openstack_dashboard/openstack/common/excutils.py', 'openstack_dashboard/openstack/common/notifier/rpc_notifier2.py', 'openstack_dashboard/openstack/common/rpc/matchmaker_redis.py', 'openstack_dashboard/openstack/common/rpc/matchmaker_ring.py']",37,92273bd2fa849c08da6929f93426e98880fc286c,bp/horizon-sync-oslo,"from openstack_dashboard.openstack.common.gettextutils import _LW """"""Match Maker where hosts are loaded from a static JSON formatted file. with open(CONF.matchmaker_ring.ringfile, 'r') as fh: self.ring = json.load(fh) return key in self.ring0 _LW(""No key defining hosts for topic '%s', "" ""see ringfile"") % (key, ) _LW(""No key defining hosts for topic '%s', "" ""see ringfile"") % (nkey, ) """"""Match Maker where hosts are loaded from a static hashmap.""""""","# vim: tabstop=4 shiftwidth=4 softtabstop=4 from openstack_dashboard.openstack.common.gettextutils import _ """""" Match Maker where hosts are loaded from a static file containing a hashmap (JSON formatted). fh = open(CONF.matchmaker_ring.ringfile, 'r') self.ring = json.load(fh) fh.close() if key in self.ring0: return True return False _(""No key defining hosts for topic '%s', "" ""see ringfile"") % (key, ) _(""No key defining hosts for topic '%s', "" ""see ringfile"") % (nkey, ) """""" Match Maker where hosts are loaded from a static hashmap. """"""",2106,1036
openstack%2Fhorizon~master~I3021d67dcb20968b785a8a98ed639a128e3412f2,openstack/horizon,master,I3021d67dcb20968b785a8a98ed639a128e3412f2,Make some new strings translator friendly,MERGED,2014-08-07 18:27:17.000000000,2014-08-08 16:43:41.000000000,2014-08-08 16:43:40.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 9317}, {'_account_id': 9531}]","[{'number': 1, 'created': '2014-08-07 18:27:17.000000000', 'files': ['horizon/templates/horizon/common/_usage_summary.html', 'openstack_dashboard/dashboards/admin/images/templates/images/properties/_edit.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/1c84b18d192766a26b4375d4f7a2cf152d991e74', 'message': 'Make some new strings translator friendly\n\n_usage_summary.html:\nblocktrans contains non-simple HTML tags and the range\nof blocktrans seems natural. This commit split blocktrans\ninto the start and end part of the period.\n\ntemplates/images/properties/_edit.html:\nThe sensence and the value are concatenated in the code\nand translators cannot control the word order.\n\nChange-Id: I3021d67dcb20968b785a8a98ed639a128e3412f2\nCloses-Bug: #1354125\n'}]",3,112647,1c84b18d192766a26b4375d4f7a2cf152d991e74,11,5,1,841,,,0,"Make some new strings translator friendly

_usage_summary.html:
blocktrans contains non-simple HTML tags and the range
of blocktrans seems natural. This commit split blocktrans
into the start and end part of the period.

templates/images/properties/_edit.html:
The sensence and the value are concatenated in the code
and translators cannot control the word order.

Change-Id: I3021d67dcb20968b785a8a98ed639a128e3412f2
Closes-Bug: #1354125
",git fetch https://review.opendev.org/openstack/horizon refs/changes/47/112647/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/templates/horizon/common/_usage_summary.html', 'openstack_dashboard/dashboards/admin/images/templates/images/properties/_edit.html']",2,1c84b18d192766a26b4375d4f7a2cf152d991e74,bug/1354125, <p>{% blocktrans with key=key %}Update the custom property value for &quot;{{ key }}&quot;{% endblocktrans %}</p>, <p>{% trans 'Update the custom property value for' %} &quot;{{ key }}&quot;</p>,4,3
openstack%2Foslo.db~master~Ic977b564c5de9261686503506f4edec4a8d8682d,openstack/oslo.db,master,Ic977b564c5de9261686503506f4edec4a8d8682d,Restore correct source file encodings,MERGED,2014-08-07 23:45:36.000000000,2014-08-08 16:33:01.000000000,2014-08-08 16:33:00.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6849}, {'_account_id': 6928}, {'_account_id': 11816}]","[{'number': 1, 'created': '2014-08-07 23:45:36.000000000', 'files': ['oslo/db/sqlalchemy/migration.py', 'tests/sqlalchemy/test_sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/deeda384471b860884ab126a1eb1a699d791b7ba', 'message': 'Restore correct source file encodings\n\nmigration.py includes a non-ASCII character in the top source\ncomments, so a ""coding"" directive is needed.  Additionally,\nthe word ""coding"" is now used in test_sqlalchemy.py instead\nof ""encoding"".\n\nChange-Id: Ic977b564c5de9261686503506f4edec4a8d8682d\n'}]",0,112730,deeda384471b860884ab126a1eb1a699d791b7ba,9,5,1,11816,,,0,"Restore correct source file encodings

migration.py includes a non-ASCII character in the top source
comments, so a ""coding"" directive is needed.  Additionally,
the word ""coding"" is now used in test_sqlalchemy.py instead
of ""encoding"".

Change-Id: Ic977b564c5de9261686503506f4edec4a8d8682d
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/30/112730/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/db/sqlalchemy/migration.py', 'tests/sqlalchemy/test_sqlalchemy.py']",2,deeda384471b860884ab126a1eb1a699d791b7ba,restore-necessary-source-encodings,# coding=utf-8,# encoding=UTF8,3,1
openstack%2Fcookbook-openstack-compute~master~I9b2161e65b4434130d998e8766dc64a49707ac91,openstack/cookbook-openstack-compute,master,I9b2161e65b4434130d998e8766dc64a49707ac91,"Use ChefSpec 4.0.0, update ChefSpec",ABANDONED,2014-06-17 11:26:26.000000000,2014-08-08 16:31:39.000000000,,"[{'_account_id': 3}, {'_account_id': 26}, {'_account_id': 1032}, {'_account_id': 7128}, {'_account_id': 9884}, {'_account_id': 10110}]","[{'number': 1, 'created': '2014-06-17 11:26:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/c2ae140626616e3929b06311415373042828b247', 'message': 'WIP Use ChefSpec 4.0.0 to make things faster\n\nTo remove deprecation warnings, I used transpec to convert the specs.\nIts output was:\n\nConvert specs to RSpec 3.0.1 syntax with Transpec\n\nThis conversion is done by Transpec 1.10.3 with the following command:\n    transpec spec\n\n* 16 conversions\n    from: Klass.any_instance.stub(:message)\n      to: allow_any_instance_of(Klass).to receive(:message)\n\n* 3 conversions\n    from: obj.stub(:message)\n      to: allow(obj).to receive(:message)\n\nChange-Id: I9b2161e65b4434130d998e8766dc64a49707ac91\n'}, {'number': 2, 'created': '2014-06-17 14:43:45.000000000', 'files': ['spec/spec_helper.rb', 'Gemfile.lock', 'Gemfile', 'spec/libvirt-suse_spec.rb', 'spec/nova-setup_spec.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/fa626c267e5af1f4c57a2479a0518514214e8007', 'message': 'Use ChefSpec 4.0.0, update ChefSpec\n\nTo remove deprecation warnings, I used transpec to convert the specs.\nIts output was:\n\nConvert specs to RSpec 3.0.1 syntax with Transpec\n\nThis conversion is done by Transpec 1.10.3 with the following command:\n    transpec spec\n\n* 16 conversions\n    from: Klass.any_instance.stub(:message)\n      to: allow_any_instance_of(Klass).to receive(:message)\n\n* 3 conversions\n    from: obj.stub(:message)\n      to: allow(obj).to receive(:message)\n\nChange-Id: I9b2161e65b4434130d998e8766dc64a49707ac91\n'}]",0,100502,fa626c267e5af1f4c57a2479a0518514214e8007,18,6,2,10110,,,0,"Use ChefSpec 4.0.0, update ChefSpec

To remove deprecation warnings, I used transpec to convert the specs.
Its output was:

Convert specs to RSpec 3.0.1 syntax with Transpec

This conversion is done by Transpec 1.10.3 with the following command:
    transpec spec

* 16 conversions
    from: Klass.any_instance.stub(:message)
      to: allow_any_instance_of(Klass).to receive(:message)

* 3 conversions
    from: obj.stub(:message)
      to: allow(obj).to receive(:message)

Change-Id: I9b2161e65b4434130d998e8766dc64a49707ac91
",git fetch https://review.opendev.org/openstack/cookbook-openstack-compute refs/changes/02/100502/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/spec_helper.rb', 'Gemfile.lock', 'Gemfile', 'spec/libvirt-suse_spec.rb', 'spec/nova-setup_spec.rb']",5,c2ae140626616e3929b06311415373042828b247,fix_slow_chefspec, allow_any_instance_of(Chef::Resource::Execute).to receive(:should_skip?).and_return(false), Chef::Resource::Execute.any_instance.stub(:should_skip?).and_return(false),81,86
openstack%2Fpython-keystoneclient~master~Iadab479a896bc4b1682ee8d207cc50a01dca8255,openstack/python-keystoneclient,master,Iadab479a896bc4b1682ee8d207cc50a01dca8255,Mark auth plugin options as secret,MERGED,2014-08-07 03:41:24.000000000,2014-08-08 16:25:11.000000000,2014-08-08 16:25:11.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6486}, {'_account_id': 7191}]","[{'number': 1, 'created': '2014-08-07 03:41:24.000000000', 'files': ['keystoneclient/auth/token_endpoint.py', 'keystoneclient/auth/identity/v3.py', 'keystoneclient/auth/identity/v2.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/a8cca7e889a244b1bbdf90cce85fd6cb56b79a22', 'message': ""Mark auth plugin options as secret\n\nBy marking the options as secret they don't get printed out in things\nlike the debug log when loading the application.\n\nChange-Id: Iadab479a896bc4b1682ee8d207cc50a01dca8255\n""}]",0,112462,a8cca7e889a244b1bbdf90cce85fd6cb56b79a22,17,4,1,7191,,,0,"Mark auth plugin options as secret

By marking the options as secret they don't get printed out in things
like the debug log when loading the application.

Change-Id: Iadab479a896bc4b1682ee8d207cc50a01dca8255
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/62/112462/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/auth/token_endpoint.py', 'keystoneclient/auth/identity/v3.py', 'keystoneclient/auth/identity/v2.py']",3,a8cca7e889a244b1bbdf90cce85fd6cb56b79a22,secret-opts," cfg.StrOpt('password', secret=True, help='Password to use'), cfg.StrOpt('token', secret=True, help='Token'),"," cfg.StrOpt('password', help='Password to use'), cfg.StrOpt('token', help='Token'),",9,5
openstack%2Fglance~master~I040959e9d1e36f524e88174c9cbbeb7db2f4b66b,openstack/glance,master,I040959e9d1e36f524e88174c9cbbeb7db2f4b66b,Fix rally performance job in glance,MERGED,2014-08-07 22:09:57.000000000,2014-08-08 16:25:04.000000000,2014-08-08 16:25:04.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 6549}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-08-07 22:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/27c7b5cd6667318c47b492aef251edceb374eeb0', 'message': 'Fix rally performance job in glance\n\nRecently we merged non backward compability change in rally\nhttps://review.openstack.org/#/c/112045/\n\nSo we need to fix plugin\n\nAs well change name to something reasonable\n\nChange-Id: I040959e9d1e36f524e88174c9cbbeb7db2f4b66b\n'}, {'number': 2, 'created': '2014-08-07 22:58:04.000000000', 'files': ['rally-scenarios/plugins/plugin_sample.py', 'rally-scenarios/glance.yaml'], 'web_link': 'https://opendev.org/openstack/glance/commit/66195fa2c2ef7767390b72260a3e53ed8e445abf', 'message': 'Fix rally performance job in glance\n\nRecently we merged non backward compability change in rally\nhttps://review.openstack.org/#/c/112045/\n\nSo we need to fix plugin\n\nAs well change name to something reasonable\n\nChange-Id: I040959e9d1e36f524e88174c9cbbeb7db2f4b66b\n'}]",0,112706,66195fa2c2ef7767390b72260a3e53ed8e445abf,11,4,2,6172,,,0,"Fix rally performance job in glance

Recently we merged non backward compability change in rally
https://review.openstack.org/#/c/112045/

So we need to fix plugin

As well change name to something reasonable

Change-Id: I040959e9d1e36f524e88174c9cbbeb7db2f4b66b
",git fetch https://review.opendev.org/openstack/glance refs/changes/06/112706/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally-scenarios/plugins/plugin_sample.py', 'rally-scenarios/glance.yaml']",2,27c7b5cd6667318c47b492aef251edceb374eeb0,, GlancePlugin.create_and_list:, GlancePlugin.your_mega_benchmark:,4,5
openstack%2Fheat~master~If7abd129dc7819c6ac01f9bf7dfdbe397ec09c65,openstack/heat,master,If7abd129dc7819c6ac01f9bf7dfdbe397ec09c65,Always convert string type params to string,MERGED,2014-08-06 22:07:45.000000000,2014-08-08 16:23:14.000000000,2014-08-08 16:23:13.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7404}, {'_account_id': 9189}]","[{'number': 1, 'created': '2014-08-06 22:07:45.000000000', 'files': ['heat/tests/test_constraints.py', 'heat/engine/constraints.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/af21176f1a0efdd12400113e66fe9cae0f23af9f', 'message': 'Always convert string type params to string\n\nSchema.to_schema_type() should convert values passed to it to the\nappropriate type.  So if the user passed a version number of 9.4 and\nthey defined it in the template with a string type, we should get the\nstring \'9.4\' back, instead of the error ""The value \'9.4\' is invalid for\ntype \'string\'"".\n\nCo-Authored-By: Richard Lee <rblee88@gmail.com>\nCloses-Bug: #1353701\nChange-Id: If7abd129dc7819c6ac01f9bf7dfdbe397ec09c65\n'}]",0,112425,af21176f1a0efdd12400113e66fe9cae0f23af9f,23,7,1,9189,,,0,"Always convert string type params to string

Schema.to_schema_type() should convert values passed to it to the
appropriate type.  So if the user passed a version number of 9.4 and
they defined it in the template with a string type, we should get the
string '9.4' back, instead of the error ""The value '9.4' is invalid for
type 'string'"".

Co-Authored-By: Richard Lee <rblee88@gmail.com>
Closes-Bug: #1353701
Change-Id: If7abd129dc7819c6ac01f9bf7dfdbe397ec09c65
",git fetch https://review.opendev.org/openstack/heat refs/changes/25/112425/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_constraints.py', 'heat/engine/constraints.py']",2,af21176f1a0efdd12400113e66fe9cae0f23af9f,bug/1353701,," if value and not isinstance(value, basestring): raise ValueError()",6,5
openstack%2Fbarbican~master~I56036768c46f1f727b10c7d231c3470dfa8213ea,openstack/barbican,master,I56036768c46f1f727b10c7d231c3470dfa8213ea,"Force uWSGI to set ""Connection: close"" header",MERGED,2014-08-08 00:26:38.000000000,2014-08-08 16:18:14.000000000,2014-08-08 16:18:14.000000000,"[{'_account_id': 3}, {'_account_id': 7262}, {'_account_id': 7687}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 8005}, {'_account_id': 11970}]","[{'number': 1, 'created': '2014-08-08 00:26:38.000000000', 'files': ['etc/barbican/vassals/barbican-api.ini', 'etc/barbican/vassals/barbican-admin.ini'], 'web_link': 'https://opendev.org/openstack/barbican/commit/680845ffd7c1d9248196640aa536798375f9152e', 'message': 'Force uWSGI to set ""Connection: close"" header\n\nuWSGI is currently not compliant with RFC 2616 section 14.10.\nThis will work around the problem by blindly applying the\ncorrect header to responses, when using the default uWSGI\nvassal configuration files. This does break persistent connections\nin that case, so these configs should probably be changed for\nproduction use (or uWSGI should not be used).\n\nChange-Id: I56036768c46f1f727b10c7d231c3470dfa8213ea\n'}]",0,112735,680845ffd7c1d9248196640aa536798375f9152e,12,7,1,10273,,,0,"Force uWSGI to set ""Connection: close"" header

uWSGI is currently not compliant with RFC 2616 section 14.10.
This will work around the problem by blindly applying the
correct header to responses, when using the default uWSGI
vassal configuration files. This does break persistent connections
in that case, so these configs should probably be changed for
production use (or uWSGI should not be used).

Change-Id: I56036768c46f1f727b10c7d231c3470dfa8213ea
",git fetch https://review.opendev.org/openstack/barbican refs/changes/35/112735/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/barbican/vassals/barbican-api.ini', 'etc/barbican/vassals/barbican-admin.ini']",2,680845ffd7c1d9248196640aa536798375f9152e,,add-header = Connection: close,,2,0
openstack%2Ftempest~master~I8068fa85472259676acebd99b9d191065661e101,openstack/tempest,master,I8068fa85472259676acebd99b9d191065661e101,Make unable to ping log messages appropriate level,MERGED,2014-05-27 16:05:30.000000000,2014-08-08 16:15:21.000000000,2014-08-08 16:15:20.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 7139}, {'_account_id': 7428}, {'_account_id': 8576}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-05-27 16:05:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/45838f973424983e4c97ab1f1e0f636d35733210', 'message': ""Make unable to ping log messages appropriate level\n\nThe ping from an ssh connection checks in _check_remote_connectivity()\naren't necessarily expected to pass on the first attempt. However,\nevery time the ping was unsuccessful the method would log an\nexception which is too severe a log for an expected error. This\ncommit uses a more appropriate log level for this case.\n\nChange-Id: I8068fa85472259676acebd99b9d191065661e101\n""}, {'number': 2, 'created': '2014-05-27 16:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/14cbde9c83eace9dd99995e4169c6d267d7b8011', 'message': ""Make unable to ping log messages appropriate level\n\nThe ping from an ssh connection checks in _check_remote_connectivity()\naren't necessarily expected to pass on the first attempt. However,\nevery time the ping was unsuccessful the method would log an\nexception which is too severe a log for an expected error. This\ncommit uses a more appropriate log level for this case.\n\nChange-Id: I8068fa85472259676acebd99b9d191065661e101\n""}, {'number': 3, 'created': '2014-06-25 21:56:55.000000000', 'files': ['tempest/scenario/manager.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/c4131d818ab82eff218675718e62bd8badd53cca', 'message': ""Make unable to ping log messages appropriate level\n\nThe ping from an ssh connection checks in _check_remote_connectivity()\naren't necessarily expected to pass on the first attempt. However,\nevery time the ping was unsuccessful the method would log an\nexception which is too severe a log for an expected error. This\ncommit uses a more appropriate log level for this case.\n\nChange-Id: I8068fa85472259676acebd99b9d191065661e101\n""}]",12,95815,c4131d818ab82eff218675718e62bd8badd53cca,55,13,3,5196,,,0,"Make unable to ping log messages appropriate level

The ping from an ssh connection checks in _check_remote_connectivity()
aren't necessarily expected to pass on the first attempt. However,
every time the ping was unsuccessful the method would log an
exception which is too severe a log for an expected error. This
commit uses a more appropriate log level for this case.

Change-Id: I8068fa85472259676acebd99b9d191065661e101
",git fetch https://review.opendev.org/openstack/tempest refs/changes/15/95815/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/manager.py'],1,45838f973424983e4c97ab1f1e0f636d35733210,fix-ssh-logs," LOG.WARN('Failed to ping host: %s via a ssh connection to: %s.' % (dest, source.ssh_client.host))", LOG.exception('Failed to ping host via ssh connection'),2,1
openstack%2Fsolum-specs~master~I2c6feb50c3d0fb86555eeebf65664f6c142ae0c6,openstack/solum-specs,master,I2c6feb50c3d0fb86555eeebf65664f6c142ae0c6,Update Solum CAMP API specifiction with Gil's new launchpad ID.,ABANDONED,2014-08-05 22:07:37.000000000,2014-08-08 16:11:26.000000000,,"[{'_account_id': 3}, {'_account_id': 9537}, {'_account_id': 11813}]","[{'number': 1, 'created': '2014-08-05 22:07:37.000000000', 'files': ['specs/juno/solum-camp-api.rst'], 'web_link': 'https://opendev.org/openstack/solum-specs/commit/8d9f81efd9fefa6f96511df024eb19a5bf9564ef', 'message': ""Update Solum CAMP API specifiction with Gil's new launchpad ID.\n\nChange-Id: I2c6feb50c3d0fb86555eeebf65664f6c142ae0c6\n""}]",0,112154,8d9f81efd9fefa6f96511df024eb19a5bf9564ef,6,3,1,11813,,,0,"Update Solum CAMP API specifiction with Gil's new launchpad ID.

Change-Id: I2c6feb50c3d0fb86555eeebf65664f6c142ae0c6
",git fetch https://review.opendev.org/openstack/solum-specs refs/changes/54/112154/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/solum-camp-api.rst'],1,8d9f81efd9fefa6f96511df024eb19a5bf9564ef,camp-api-spec, gilbert.pilz, gilbert-pilz,1,1
openstack%2Fkeystone~master~I3cb46ddffa76be3d4526a175257014ca7f1ab94a,openstack/keystone,master,I3cb46ddffa76be3d4526a175257014ca7f1ab94a,Check for empty string value in REMOTE_USER,MERGED,2014-08-05 08:41:27.000000000,2014-08-08 16:07:28.000000000,2014-08-08 16:07:27.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 8978}, {'_account_id': 12215}]","[{'number': 1, 'created': '2014-08-05 08:41:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ee0b760454f6e8a4db727865ff491e447817669a', 'message': ""Check for empty string value in REMOTE_USER\n\nThe external auth method shouldn't be used if REMOTE_USER is set\nto the empty string value. This happens in some setups of Apache\nand Shibboleth SP, leading to authentication failures with the\nsaml2 auth method unless the external auth method is disabled.\n\nChange-Id: I3cb46ddffa76be3d4526a175257014ca7f1ab94a\nCo-Authored-By: Florent Flament <florent.flament-ext@cloudwatt.com>\n""}, {'number': 2, 'created': '2014-08-06 10:02:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6a1121084cb2e742533b3d635484d3404de24e05', 'message': ""Check for empty string value in REMOTE_USER\n\nThe external auth method shouldn't be used if REMOTE_USER is set\nto the empty string value. This happens in some setups of Apache\nand Shibboleth SP, leading to authentication failures with the\nsaml2 auth method unless the external auth method is disabled.\n\nChange-Id: I3cb46ddffa76be3d4526a175257014ca7f1ab94a\nCo-Authored-By: Florent Flament <florent.flament-ext@cloudwatt.com>\n""}, {'number': 3, 'created': '2014-08-08 08:30:51.000000000', 'files': ['keystone/auth/controllers.py', 'keystone/tests/test_auth.py', 'keystone/token/controllers.py', 'keystone/tests/test_v3_federation.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/c44778084dc2b16f7bab08efd47fb98df3231a2b', 'message': ""Check for empty string value in REMOTE_USER\n\nThe external auth method shouldn't be used if REMOTE_USER is set\nto the empty string value. This happens in some setups of Apache\nand Shibboleth SP, leading to authentication failures with the\nsaml2 auth method unless the external auth method is disabled.\n\nCloses-Bug: #1354315\nChange-Id: I3cb46ddffa76be3d4526a175257014ca7f1ab94a\nCo-Authored-By: Florent Flament <florent.flament-ext@cloudwatt.com>\n""}]",5,111953,c44778084dc2b16f7bab08efd47fb98df3231a2b,26,5,3,7186,,,0,"Check for empty string value in REMOTE_USER

The external auth method shouldn't be used if REMOTE_USER is set
to the empty string value. This happens in some setups of Apache
and Shibboleth SP, leading to authentication failures with the
saml2 auth method unless the external auth method is disabled.

Closes-Bug: #1354315
Change-Id: I3cb46ddffa76be3d4526a175257014ca7f1ab94a
Co-Authored-By: Florent Flament <florent.flament-ext@cloudwatt.com>
",git fetch https://review.opendev.org/openstack/keystone refs/changes/53/111953/3 && git format-patch -1 --stdout FETCH_HEAD,['keystone/auth/controllers.py'],1,ee0b760454f6e8a4db727865ff491e447817669a,EmptyRemoteUserVar," # In some cases the server can set REMOTE_USER as '' instead of # dropping it, so this must be filtered out if context['environment'].get('REMOTE_USER', None):", if 'REMOTE_USER' in context['environment']:,3,1
openstack%2Ftempest~master~Icf2f56f7aa7a2dc736c57daad6d2d5c37e0d9e32,openstack/tempest,master,Icf2f56f7aa7a2dc736c57daad6d2d5c37e0d9e32,Router API Tests Enhancements,MERGED,2014-07-18 13:50:37.000000000,2014-08-08 16:03:45.000000000,2014-08-08 16:03:44.000000000,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 7227}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7350}, {'_account_id': 7872}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11670}, {'_account_id': 11671}, {'_account_id': 12464}]","[{'number': 1, 'created': '2014-07-18 13:50:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ad5f5a870c87a5a9a51480867b6fca488e781279', 'message': 'Router  API Tests Enhancements\n\nAdd test to creaation of router with snat rule\n  - Create a router with defult attributes\n  - Verify the snat attributes\n  - Creating a router using admin priviledges for a tenant\n     with snat value true/false\n  -Verify the snat attributes\n\nChange-Id: Icf2f56f7aa7a2dc736c57daad6d2d5c37e0d9e32\n'}, {'number': 2, 'created': '2014-07-23 10:44:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1ef1647dd322fd7b7567130ff88e0964093581d8', 'message': 'Router  API Tests Enhancements\n\nAdd test to creaation of router with snat rule\n  - Create a router with defult attributes\n  - Verify the snat attributes\n  - Creating a router using admin priviledges for a tenant\n     with snat value true/false\n  -Verify the snat attributes\n\nChange-Id: Icf2f56f7aa7a2dc736c57daad6d2d5c37e0d9e32\n'}, {'number': 3, 'created': '2014-07-24 11:20:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ca8a9fb922f8332d70acab1da7cf2b3a48f87b0d', 'message': 'Router  API Tests Enhancements\n\nAdd test to creaation of router with snat rule\n  - Create a router with defult attributes\n  - Verify the snat attributes\n  - Creating a router using admin priviledges for a tenant\n     with snat value true/false\n  -Verify the snat attributes\n\nChange-Id: Icf2f56f7aa7a2dc736c57daad6d2d5c37e0d9e32\n'}, {'number': 4, 'created': '2014-07-30 11:38:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c0e675b69458c6d1aed630494f337365be855e15', 'message': 'Router  API Tests Enhancements\n\nAdd test to creaation of router with snat rule\n  - Create a router with defult attributes\n  - Verify the snat attributes\n  - Creating a router using admin priviledges for a tenant\n     with snat value true/false\n  -Verify the snat attributes\n\nChange-Id: Icf2f56f7aa7a2dc736c57daad6d2d5c37e0d9e32\n'}, {'number': 5, 'created': '2014-08-01 10:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b59be9c3de33e7f43e41be4bec70efd3f332e9d0', 'message': 'Router  API Tests Enhancements\n\nAdd test to creaation of router with snat rule\n  - Create a router with defult attributes\n  - Verify the snat attributes\n  - Creating a router using admin priviledges for a tenant\n     with snat value true/false\n  -Verify the snat attributes\n\nChange-Id: Icf2f56f7aa7a2dc736c57daad6d2d5c37e0d9e32\n'}, {'number': 6, 'created': '2014-08-05 11:33:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9bd4c58e6208889be474f5159394cf31dfa92bda', 'message': 'Router  API Tests Enhancements\n\nAdd test to creaation of router with snat rule\n  - Create a router with defult attributes\n  - Verify the snat attributes\n  - Creating a router using admin priviledges for a tenant\n     with snat value true/false\n  -Verify the snat attributes\n\nChange-Id: Icf2f56f7aa7a2dc736c57daad6d2d5c37e0d9e32\n'}, {'number': 7, 'created': '2014-08-06 05:49:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5c983a14008af706c251859db15a6e8239ce33b8', 'message': 'Router  API Tests Enhancements\n\nAdd test to creaation of router with snat rule\n  - Create a router with default attributes\n  - Verify the default snat attributes\n  - Creating a router using admin priviledges for a tenant\n     with snat value True/False\n  - Verify routers for snat value True/False by overwriting\n     through admin tenant.\n\nChange-Id: Icf2f56f7aa7a2dc736c57daad6d2d5c37e0d9e32\n'}, {'number': 8, 'created': '2014-08-07 07:17:07.000000000', 'files': ['tempest/api/network/test_routers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/faa3c8d71a581c4c6d034a291896af7551f84cfe', 'message': 'Router API Tests Enhancements\n\nAdd test to creation of router with snat rule\n  - Create a router with default attributes\n  - Verify the default snat attributes\n  - Creating a router using admin priviledges for a tenant\n     with snat value True/False\n  - Verify routers for snat value True/False by overwriting\n     through admin tenant.\n\nChange-Id: Icf2f56f7aa7a2dc736c57daad6d2d5c37e0d9e32\n'}]",18,108010,faa3c8d71a581c4c6d034a291896af7551f84cfe,98,15,8,12464,,,0,"Router API Tests Enhancements

Add test to creation of router with snat rule
  - Create a router with default attributes
  - Verify the default snat attributes
  - Creating a router using admin priviledges for a tenant
     with snat value True/False
  - Verify routers for snat value True/False by overwriting
     through admin tenant.

Change-Id: Icf2f56f7aa7a2dc736c57daad6d2d5c37e0d9e32
",git fetch https://review.opendev.org/openstack/tempest refs/changes/10/108010/4 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/test_routers.py'],1,ad5f5a870c87a5a9a51480867b6fca488e781279,Router-Api_Test-Enhancement," def test_create_router_with_snat_rule(self): # Create a router name = data_utils.rand_name('router-') resp, body = self.client.create_router(name, external_gateway_info={ ""network_id"": CONF.network.public_network_id}) self.assertEqual('201', resp['status']) self._verify_router_gateway(body['router']['id'], {'network_id': CONF.network.public_network_id, 'enable_snat': True}) self.addCleanup(self._delete_router, body['router']['id']) router = body['router'] router_tenant_id = router['tenant_id'] # Creating a router enabling snat attributes enable_snat_states = [False, True] name = data_utils.rand_name('snat-router-') for enable_snat in enable_snat_states: resp, create_body = self.admin_client.create_router( name, tenant_id=router_tenant_id, external_gateway_info={ ""network_id"": CONF.network.public_network_id, ""enable_snat"": enable_snat}) self.assertEqual('201', resp['status']) self.addCleanup(self.client.delete_router, create_body['router']['id']) # Verify snat attributes after router creation self._verify_router_gateway(create_body['router']['id'], {'network_id': CONF.network.public_network_id, 'enable_snat': enable_snat}) @test.attr(type='smoke')",,33,0
openstack%2Ffuel-web~master~I595ac1cdd2c1d6fef02f6a7650d65cf968a7b850,openstack/fuel-web,master,I595ac1cdd2c1d6fef02f6a7650d65cf968a7b850,Supervisord can start already stopped container,MERGED,2014-08-08 14:29:50.000000000,2014-08-08 15:57:13.000000000,2014-08-08 15:57:13.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8971}, {'_account_id': 10391}]","[{'number': 1, 'created': '2014-08-08 14:29:50.000000000', 'files': ['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/engines/docker_engine.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/fbfac1215500515ed0e7ea2648cb5b5067b3db3d', 'message': ""Supervisord can start already stopped container\n\nWe stop containers via supervisord api call.\nAlso we try to stop containers via docker api call due to\nsupervisord bugs. Sometimes supervisord starts stopped\ncontainer again. And new container can't be run due to\nold one container already run. For workaround this supervisord\nbug we switch configs before upgrade.\n\nChange-Id: I595ac1cdd2c1d6fef02f6a7650d65cf968a7b850\nCloses-Bug: #1354465\n""}]",0,112892,fbfac1215500515ed0e7ea2648cb5b5067b3db3d,16,4,1,10959,,,0,"Supervisord can start already stopped container

We stop containers via supervisord api call.
Also we try to stop containers via docker api call due to
supervisord bugs. Sometimes supervisord starts stopped
container again. And new container can't be run due to
old one container already run. For workaround this supervisord
bug we switch configs before upgrade.

Change-Id: I595ac1cdd2c1d6fef02f6a7650d65cf968a7b850
Closes-Bug: #1354465
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/92/112892/1 && git format-patch -1 --stdout FETCH_HEAD,['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/engines/docker_engine.py'],1,fbfac1215500515ed0e7ea2648cb5b5067b3db3d,upgrade_supervisord_old_container_started," # NOTE(akislitsky): fix for bug # https://bugs.launchpad.net/fuel/+bug/1354465 # supervisord can restart old container even if it already stopped # and new container start will be failed. We switch configs # before upgrade, so if supervisord will try to start container # it will be new container. self.switch_to_new_configs() ", self.switch_to_new_configs(),8,1
openstack%2Fironic~master~I53f519570df3351b6acf019d89f67b43d8b637da,openstack/ironic,master,I53f519570df3351b6acf019d89f67b43d8b637da,Use timeutils from one place,MERGED,2014-08-06 13:50:41.000000000,2014-08-08 15:54:46.000000000,2014-08-08 15:54:45.000000000,"[{'_account_id': 3}, {'_account_id': 1994}, {'_account_id': 2889}, {'_account_id': 4190}, {'_account_id': 6623}, {'_account_id': 6773}, {'_account_id': 6849}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 9545}, {'_account_id': 9550}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 12356}]","[{'number': 1, 'created': '2014-08-06 13:50:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/270999f57002fca04b09f4f780ea771f2fd4aa5f', 'message': ""Use timeutils from one place\n\n`oslo.db` can break ironic during porting library to using oslo.utils\n(see https://review.openstack.org/#/c/111701/ )\n\nSo we need to remove all imports 'oslo.db.openstack.common.timeutils' and\ndon't use `oslo.db.sqlalchemy.models.TimestampMixin`, until ironic and\noslo.db will use timeutils from one place.\n\nChange-Id: I53f519570df3351b6acf019d89f67b43d8b637da\n""}, {'number': 2, 'created': '2014-08-06 13:54:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0953f5bafa239afee85f421e21c5906f8e3d374b', 'message': ""Use timeutils from one place\n\n`oslo.db` can break ironic during porting library to using oslo.utils\n(see https://review.openstack.org/#/c/111701/ )\n\nSo we need to remove all imports 'oslo.db.openstack.common.timeutils' and\ndon't use `oslo.db.sqlalchemy.models.TimestampMixin`, until ironic and\noslo.db will use timeutils from one place.\n\nChange-Id: I53f519570df3351b6acf019d89f67b43d8b637da\n""}, {'number': 3, 'created': '2014-08-06 14:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b1086a21c218849d484f32df15d235866fddba76', 'message': ""Use timeutils from one place\n\n`oslo.db` can break ironic during porting library to using oslo.utils\n(see https://review.openstack.org/#/c/111701/ )\n\nSo we need to remove all imports 'oslo.db.openstack.common.timeutils' and\ndon't use `oslo.db.sqlalchemy.models.TimestampMixin`, until ironic and\noslo.db will use timeutils from one place.\n\nChange-Id: I53f519570df3351b6acf019d89f67b43d8b637da\n""}, {'number': 4, 'created': '2014-08-06 14:31:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8f5e4f543a5176f4745afe4b6e1e3fc9acf91a79', 'message': ""Use timeutils from one place\n\nUsage of timutils from different places (from oslo.db and from ironic) \ncan produce errors (for example, during porting oslo.db to using \noslo.utils, see https://review.openstack.org/#/c/111701/ )\n\n\nSo we need to remove all imports 'oslo.db.openstack.common.timeutils' and\ndon't use `oslo.db.sqlalchemy.models.TimestampMixin`, until ironic and\noslo.db will use timeutils from one place.\n\nChange-Id: I53f519570df3351b6acf019d89f67b43d8b637da\n""}, {'number': 5, 'created': '2014-08-06 14:32:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8a55166c7ce5ad266ace6d1ca7905c0f35ca5504', 'message': ""Use timeutils from one place\n\nUsage of timutils from different places (from oslo.db and from ironic) \ncan produce errors (for example, during porting oslo.db to using \noslo.utils, see https://review.openstack.org/#/c/111701/ )\n\nSo we need to remove all imports 'oslo.db.openstack.common.timeutils' and\ndon't use `oslo.db.sqlalchemy.models.TimestampMixin`, until ironic and\noslo.db will use timeutils from one place(from oslo.utils).\n\nChange-Id: I53f519570df3351b6acf019d89f67b43d8b637da\n""}, {'number': 6, 'created': '2014-08-07 08:53:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e2b8ec4bfe8db7996034e3f8a2e7008125e24562', 'message': ""Use timeutils from one place\n\nUsage of timeutils from different places (from oslo.db and from ironic)\ncan produce errors (for example, during porting oslo.db to using\noslo.utils, see https://review.openstack.org/#/c/111701/ )\n\nSo we need to remove all imports 'oslo.db.openstack.common.timeutils' and\ndon't use `oslo.db.sqlalchemy.models.TimestampMixin`, until ironic and\noslo.db will use timeutils from one place(from oslo.utils).\n\nChange-Id: I53f519570df3351b6acf019d89f67b43d8b637da\n""}, {'number': 7, 'created': '2014-08-07 09:41:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/035064a4b7682bd6664d9a4ab220e1a29952cdb0', 'message': ""Use timeutils from one place\n\nUsage of timeutils from different places (from oslo.db and from ironic)\ncan produce errors (for example, during porting oslo.db to using\noslo.utils, see https://review.openstack.org/#/c/111701/ )\n\nSo we need to remove all imports 'oslo.db.openstack.common.timeutils' and\ndon't use `oslo.db.sqlalchemy.models.TimestampMixin`, until ironic and\noslo.db will use timeutils from one place(from oslo.utils).\n\nChange-Id: I53f519570df3351b6acf019d89f67b43d8b637da\n""}, {'number': 8, 'created': '2014-08-07 14:43:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c841c29e5eeb31842459b0fcc4ea70bbb4d60b70', 'message': ""Use timeutils from one place\n\nUsage of timeutils from different places (from oslo.db and from ironic)\ncan produce errors (for example, during porting oslo.db to using\noslo.utils, see https://review.openstack.org/#/c/111701/ )\n\nSo we need to remove all imports 'oslo.db.openstack.common.timeutils' and\ndon't use `oslo.db.sqlalchemy.models.TimestampMixin`, until ironic and\noslo.db will use timeutils from one place(from oslo.utils).\n\nChange-Id: I53f519570df3351b6acf019d89f67b43d8b637da\n""}, {'number': 9, 'created': '2014-08-08 13:16:10.000000000', 'files': ['ironic/tests/api/v1/test_ports.py', 'ironic/tests/api/v1/test_chassis.py', 'ironic/tests/api/v1/test_nodes.py', 'ironic/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c1fbecf05d621618046428a9efb4ca9a4d2d5225', 'message': ""Use timeutils from one place\n\nUsage of timeutils from different places (from oslo.db and from ironic)\ncan produce errors (for example, during porting oslo.db to using\noslo.utils, see https://review.openstack.org/#/c/111701/ )\n\nSo we need to remove all imports 'oslo.db.openstack.common.timeutils' and\ndon't use `oslo.db.sqlalchemy.models.TimestampMixin`, until ironic and\noslo.db will use timeutils from one place(from oslo.utils).\n\nRelated-Bug: #1354443\n\nChange-Id: I53f519570df3351b6acf019d89f67b43d8b637da\n""}]",11,112303,c1fbecf05d621618046428a9efb4ca9a4d2d5225,68,15,9,9545,,,0,"Use timeutils from one place

Usage of timeutils from different places (from oslo.db and from ironic)
can produce errors (for example, during porting oslo.db to using
oslo.utils, see https://review.openstack.org/#/c/111701/ )

So we need to remove all imports 'oslo.db.openstack.common.timeutils' and
don't use `oslo.db.sqlalchemy.models.TimestampMixin`, until ironic and
oslo.db will use timeutils from one place(from oslo.utils).

Related-Bug: #1354443

Change-Id: I53f519570df3351b6acf019d89f67b43d8b637da
",git fetch https://review.opendev.org/openstack/ironic refs/changes/03/112303/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/api/v1/test_ports.py', 'ironic/tests/api/v1/test_chassis.py', 'ironic/tests/api/v1/test_nodes.py', 'ironic/db/sqlalchemy/models.py']",4,270999f57002fca04b09f4f780ea771f2fd4aa5f,fix_timeutils_in_db,"from ironic.openstack.common import timeutils #FIXME(akruilin): remove `created_at` and `updated_at` attributes, when # ironic and oslo.db will use timeutils from one place (oslo.utils). # Related patch in oslo.db : https://review.openstack.org/#/c/111701/ created_at = Column(DateTime, default=lambda: timeutils.utcnow()) updated_at = Column(DateTime, onupdate=lambda: timeutils.utcnow())",,11,8
openstack%2Fdevstack~master~Ie498fae8d1f796c1fc83459c65d0de948d1d50ce,openstack/devstack,master,Ie498fae8d1f796c1fc83459c65d0de948d1d50ce,remove kernel override ability,MERGED,2014-07-31 18:18:01.000000000,2014-08-08 15:54:07.000000000,2014-08-08 15:54:06.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 6854}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-31 18:18:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2d9322e90a64eeb09f14158f650728a3f8d4a9b8', 'message': 'remove kernel override ability\n\nThis was landed to try to address an issue with netns vs nbd during\nicehouse development. It never really got us anywhere, and is now\njust cruft.\n\nChange-Id: Ie498fae8d1f796c1fc83459c65d0de948d1d50ce\n'}, {'number': 2, 'created': '2014-08-05 21:38:05.000000000', 'files': ['tools/fixup_stuff.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/01796fad29d6708ee983102ff7f98cec938180b5', 'message': 'remove kernel override ability\n\nThis was landed to try to address an issue with netns vs nbd during\nicehouse development. It never really got us anywhere, and is now\njust cruft.\n\nChange-Id: Ie498fae8d1f796c1fc83459c65d0de948d1d50ce\n'}]",0,111027,01796fad29d6708ee983102ff7f98cec938180b5,29,7,2,2750,,,0,"remove kernel override ability

This was landed to try to address an issue with netns vs nbd during
icehouse development. It never really got us anywhere, and is now
just cruft.

Change-Id: Ie498fae8d1f796c1fc83459c65d0de948d1d50ce
",git fetch https://review.opendev.org/openstack/devstack refs/changes/27/111027/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/fixup_stuff.sh'],1,2d9322e90a64eeb09f14158f650728a3f8d4a9b8,cleanups,,"# Ubuntu 12.04 # ------------ # We can regularly get kernel crashes on the 12.04 default kernel, so attempt # to install a new kernel if [[ ${DISTRO} =~ (precise) ]]; then # Finally, because we suspect the Precise kernel is problematic, install a new kernel UPGRADE_KERNEL=$(trueorfalse False $UPGRADE_KERNEL) if [[ $UPGRADE_KERNEL == ""True"" ]]; then if [[ ! `uname -r` =~ (^3\.11) ]]; then apt_get install linux-generic-lts-saucy echo ""Installing Saucy LTS kernel, please reboot before proceeding"" exit 1 fi fi fi ",0,18
openstack%2Fpython-keystoneclient~master~Ib3053774e9dd905eb4ef50668d6638ce19750177,openstack/python-keystoneclient,master,Ib3053774e9dd905eb4ef50668d6638ce19750177,move attributes of v3.client.Client into alphabetical order,MERGED,2014-08-05 07:28:20.000000000,2014-08-08 15:47:04.000000000,2014-08-08 15:47:04.000000000,"[{'_account_id': 3}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 9101}]","[{'number': 1, 'created': '2014-08-05 07:28:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/5ecb654c1c8ccdaabb8b0f05d9fd2056c68f9a45', 'message': 'move attributes of v3.client.Client into alphabetical order\n\nJust make self.users be consistent with the other assignments.\n\nChange-Id: Ib3053774e9dd905eb4ef50668d6638ce19750177\n'}, {'number': 2, 'created': '2014-08-07 01:48:58.000000000', 'files': ['keystoneclient/v3/client.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/18ceee96966ff5e5ee2ca9cec81b4706e96a2dd8', 'message': 'move attributes of v3.client.Client into alphabetical order\n\nJust make self.users be consistent with the other assignments.\n\nChange-Id: Ib3053774e9dd905eb4ef50668d6638ce19750177\n'}]",0,111939,18ceee96966ff5e5ee2ca9cec81b4706e96a2dd8,21,4,2,9101,,,0,"move attributes of v3.client.Client into alphabetical order

Just make self.users be consistent with the other assignments.

Change-Id: Ib3053774e9dd905eb4ef50668d6638ce19750177
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/39/111939/2 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/v3/client.py'],1,5ecb654c1c8ccdaabb8b0f05d9fd2056c68f9a45,fix_order, .. py:attribute:: users :py:class:`keystoneclient.v3.users.UserManager` self.users = users.UserManager(self), .. py:attribute:: users :py:class:`keystoneclient.v3.users.UserManager` self.users = users.UserManager(self),5,5
openstack%2Fneutron~master~I9ac7cc1e35205bddc64e7865c45e801df8cd6b33,openstack/neutron,master,I9ac7cc1e35205bddc64e7865c45e801df8cd6b33,ofagent: Add a missing normalized_port_name,MERGED,2014-07-29 02:48:42.000000000,2014-08-08 15:31:45.000000000,2014-08-08 15:31:44.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}]","[{'number': 1, 'created': '2014-07-29 02:48:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/38f47b9eac72c8eaf012cef01b41990183dac924', 'message': 'ofagent: Add a missing normalized_port_name\n\nOtherwise port_unbound can not find Port for non ""tap"" prefixed ports.\n\nChange-Id: I9ac7cc1e35205bddc64e7865c45e801df8cd6b33\n'}, {'number': 2, 'created': '2014-07-29 15:14:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3548abe3c45f42bdd98e4809f574553b26ca2a6a', 'message': 'ofagent: Add a missing normalized_port_name\n\nOtherwise port_unbound can not find Port for non ""tap"" prefixed ports.\n\nCloses-Bug: #1349898\nChange-Id: I9ac7cc1e35205bddc64e7865c45e801df8cd6b33\n'}, {'number': 3, 'created': '2014-08-06 17:03:58.000000000', 'files': ['neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/tests/unit/ofagent/test_ofa_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/de5fa0dd327b1a81cb980d7553001dca244ae7a2', 'message': 'ofagent: Add a missing normalized_port_name\n\nOtherwise port_unbound can not find Port for non ""tap"" prefixed ports.\n\nCloses-Bug: #1349898\nChange-Id: I9ac7cc1e35205bddc64e7865c45e801df8cd6b33\n'}]",0,110187,de5fa0dd327b1a81cb980d7553001dca244ae7a2,66,22,3,6854,,,0,"ofagent: Add a missing normalized_port_name

Otherwise port_unbound can not find Port for non ""tap"" prefixed ports.

Closes-Bug: #1349898
Change-Id: I9ac7cc1e35205bddc64e7865c45e801df8cd6b33
",git fetch https://review.opendev.org/openstack/neutron refs/changes/87/110187/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/tests/unit/ofagent/test_ofa_neutron_agent.py']",2,38f47b9eac72c8eaf012cef01b41990183dac924,bug/1349898," port_name = 'tap96408df7-16' port = _mock_port(True, port_name) self.assertTrue(self.agent.local_vlan_map[net_uuid]. vif_ports[port_name] is port)", port = mock.Mock(),5,2
openstack%2Fneutron~master~I20baee1d533426935c026f5eb68edb7329897688,openstack/neutron,master,I20baee1d533426935c026f5eb68edb7329897688,Move ml2 db models to separate file,ABANDONED,2014-07-30 10:18:28.000000000,2014-08-08 15:23:56.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 8655}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10386}, {'_account_id': 10503}]","[{'number': 1, 'created': '2014-07-30 10:18:28.000000000', 'files': ['neutron/tests/unit/ml2/test_type_vlan.py', 'neutron/db/models/ml2/nexus.py', 'neutron/plugins/ml2/plugin.py', 'neutron/tests/unit/ml2/test_type_gre.py', 'neutron/db/models/ml2/brocade.py', 'neutron/plugins/ml2/drivers/cisco/nexus/nexus_db_v2.py', 'neutron/plugins/ml2/db.py', 'neutron/plugins/ml2/drivers/type_vxlan.py', 'neutron/plugins/ml2/drivers/type_gre.py', 'neutron/tests/unit/ml2/drivers/cisco/apic/test_cisco_apic_mechanism_driver.py', 'neutron/db/migration/models/head.py', 'neutron/db/models/ml2/__init__.py', 'neutron/plugins/ml2/drivers/type_vlan.py', 'neutron/tests/unit/ml2/test_type_vxlan.py', 'neutron/plugins/ml2/drivers/brocade/db/models.py', 'neutron/plugins/ml2/drivers/type_flat.py', 'neutron/tests/unit/ml2/test_helpers.py', 'neutron/plugins/ml2/drivers/cisco/apic/apic_model.py', 'neutron/plugins/ml2/drivers/l2pop/db.py', 'neutron/plugins/ml2/drivers/arista/mechanism_arista.py', 'neutron/plugins/ml2/drivers/arista/db.py', 'neutron/tests/unit/ml2/test_type_flat.py', 'neutron/db/models/ml2/apic.py', 'neutron/tests/unit/ml2/db/test_ml2_dvr_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d93f4485724e1a0cf95e0f56525b544f8270789f', 'message': 'Move ml2 db models to separate file\n\nPartial-Bug: #1346658\nChange-Id: I20baee1d533426935c026f5eb68edb7329897688\nImplements: blueprint db-migration-refactor\n'}]",0,110595,d93f4485724e1a0cf95e0f56525b544f8270789f,21,18,1,8655,,,0,"Move ml2 db models to separate file

Partial-Bug: #1346658
Change-Id: I20baee1d533426935c026f5eb68edb7329897688
Implements: blueprint db-migration-refactor
",git fetch https://review.opendev.org/openstack/neutron refs/changes/95/110595/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/ml2/test_type_vlan.py', 'neutron/db/models/ml2/nexus.py', 'neutron/plugins/ml2/plugin.py', 'neutron/tests/unit/ml2/test_type_gre.py', 'neutron/db/models/ml2/brocade.py', 'neutron/plugins/ml2/drivers/cisco/nexus/nexus_db_v2.py', 'neutron/plugins/ml2/db.py', 'neutron/plugins/ml2/drivers/type_vxlan.py', 'neutron/plugins/ml2/drivers/type_gre.py', 'neutron/tests/unit/ml2/drivers/cisco/apic/test_cisco_apic_mechanism_driver.py', 'neutron/db/migration/models/head.py', 'neutron/db/models/ml2/__init__.py', 'neutron/plugins/ml2/drivers/type_vlan.py', 'neutron/tests/unit/ml2/test_type_vxlan.py', 'neutron/plugins/ml2/drivers/brocade/db/models.py', 'neutron/plugins/ml2/drivers/type_flat.py', 'neutron/tests/unit/ml2/test_helpers.py', 'neutron/plugins/ml2/drivers/cisco/apic/apic_model.py', 'neutron/plugins/ml2/drivers/l2pop/db.py', 'neutron/plugins/ml2/drivers/arista/mechanism_arista.py', 'neutron/plugins/ml2/drivers/arista/db.py', 'neutron/tests/unit/ml2/test_type_flat.py', 'neutron/db/models/ml2/apic.py', 'neutron/tests/unit/ml2/db/test_ml2_dvr_db.py']",24,d93f4485724e1a0cf95e0f56525b544f8270789f,bp/db-migration-refactor,from neutron.db.models import ml2 as ml2_models,from neutron.plugins.ml2 import models as ml2_models,217,324
openstack%2Fneutron~master~If69dcb682d97f246fd570b3e34a3e60aafd809d6,openstack/neutron,master,If69dcb682d97f246fd570b3e34a3e60aafd809d6,Move metaplugin db models to separate file,ABANDONED,2014-07-30 10:18:28.000000000,2014-08-08 15:23:52.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 8655}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10503}]","[{'number': 1, 'created': '2014-07-30 10:18:28.000000000', 'files': ['neutron/db/migration/models/head.py', 'neutron/plugins/metaplugin/meta_db_v2.py', 'neutron/plugins/metaplugin/meta_neutron_plugin.py', 'neutron/db/models/metaplugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/607aa567915f4623292d6f53bb7bde89ab3a2d00', 'message': 'Move metaplugin db models to separate file\n\nPartial-Bug: #1346658\nChange-Id: If69dcb682d97f246fd570b3e34a3e60aafd809d6\nImplements: blueprint db-migration-refactor\n'}]",0,110594,607aa567915f4623292d6f53bb7bde89ab3a2d00,18,16,1,8655,,,0,"Move metaplugin db models to separate file

Partial-Bug: #1346658
Change-Id: If69dcb682d97f246fd570b3e34a3e60aafd809d6
Implements: blueprint db-migration-refactor
",git fetch https://review.opendev.org/openstack/neutron refs/changes/94/110594/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/models/head.py', 'neutron/plugins/metaplugin/meta_db_v2.py', 'neutron/plugins/metaplugin/meta_neutron_plugin.py', 'neutron/db/models/metaplugin.py']",4,607aa567915f4623292d6f53bb7bde89ab3a2d00,bp/db-migration-refactor,,,2,3
openstack%2Fneutron~master~I604be0470b290cb6bdb72004e5e2ab140d6b041c,openstack/neutron,master,I604be0470b290cb6bdb72004e5e2ab140d6b041c,Move linuxbridge db models to separate file,ABANDONED,2014-07-30 10:18:28.000000000,2014-08-08 15:23:48.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 8655}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10503}]","[{'number': 1, 'created': '2014-07-30 10:18:28.000000000', 'files': ['neutron/plugins/linuxbridge/db/l2network_db_v2.py', 'neutron/db/migration/models/head.py', 'neutron/db/models/linuxbridge.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5f1d63aef135ebbc4de7d26d1bb208df9d4a6ee1', 'message': 'Move linuxbridge db models to separate file\n\nPartial-Bug: #1346658\nChange-Id: I604be0470b290cb6bdb72004e5e2ab140d6b041c\nImplements: blueprint db-migration-refactor\n'}]",0,110593,5f1d63aef135ebbc4de7d26d1bb208df9d4a6ee1,18,16,1,8655,,,0,"Move linuxbridge db models to separate file

Partial-Bug: #1346658
Change-Id: I604be0470b290cb6bdb72004e5e2ab140d6b041c
Implements: blueprint db-migration-refactor
",git fetch https://review.opendev.org/openstack/neutron refs/changes/93/110593/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/linuxbridge/db/l2network_db_v2.py', 'neutron/db/migration/models/head.py', 'neutron/db/models/linuxbridge.py']",3,5f1d63aef135ebbc4de7d26d1bb208df9d4a6ee1,bp/db-migration-refactor,,,1,2
openstack%2Fneutron~master~I40f24217dd811a500c4d70b6ec8fa40a053b961f,openstack/neutron,master,I40f24217dd811a500c4d70b6ec8fa40a053b961f,Move hyperv db models to separate file,ABANDONED,2014-07-30 10:18:28.000000000,2014-08-08 15:23:43.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 8655}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10503}]","[{'number': 1, 'created': '2014-07-30 10:18:28.000000000', 'files': ['neutron/db/migration/models/head.py', 'neutron/plugins/hyperv/db.py', 'neutron/db/models/hyperv.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a52c2f5db099b2f1bb16374d3033dced399a6c34', 'message': 'Move hyperv db models to separate file\n\nPartial-Bug: #1346658\nChange-Id: I40f24217dd811a500c4d70b6ec8fa40a053b961f\nImplements: blueprint db-migration-refactor\n'}]",0,110592,a52c2f5db099b2f1bb16374d3033dced399a6c34,18,16,1,8655,,,0,"Move hyperv db models to separate file

Partial-Bug: #1346658
Change-Id: I40f24217dd811a500c4d70b6ec8fa40a053b961f
Implements: blueprint db-migration-refactor
",git fetch https://review.opendev.org/openstack/neutron refs/changes/92/110592/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/models/head.py', 'neutron/plugins/hyperv/db.py', 'neutron/db/models/hyperv.py']",3,a52c2f5db099b2f1bb16374d3033dced399a6c34,bp/db-migration-refactor,,,1,2
openstack%2Fneutron~master~I3697f0955835d6d4c472f2a5c735e41ef4452a2b,openstack/neutron,master,I3697f0955835d6d4c472f2a5c735e41ef4452a2b,Move embrane db models to separate file,ABANDONED,2014-07-30 10:18:28.000000000,2014-08-08 15:23:35.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 8655}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10503}]","[{'number': 1, 'created': '2014-07-30 10:18:28.000000000', 'files': ['neutron/services/loadbalancer/drivers/embrane/db.py', 'neutron/db/migration/models/head.py', 'neutron/db/models/embrane.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8dd1143f85cb00e8b60e7a86648d698c097c7052', 'message': 'Move embrane db models to separate file\n\nPartial-Bug: #1346658\nChange-Id: I3697f0955835d6d4c472f2a5c735e41ef4452a2b\nImplements: blueprint db-migration-refactor\n'}]",0,110591,8dd1143f85cb00e8b60e7a86648d698c097c7052,18,16,1,8655,,,0,"Move embrane db models to separate file

Partial-Bug: #1346658
Change-Id: I3697f0955835d6d4c472f2a5c735e41ef4452a2b
Implements: blueprint db-migration-refactor
",git fetch https://review.opendev.org/openstack/neutron refs/changes/91/110591/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/loadbalancer/drivers/embrane/db.py', 'neutron/db/migration/models/head.py', 'neutron/db/models/embrane.py']",3,8dd1143f85cb00e8b60e7a86648d698c097c7052,bp/db-migration-refactor,,,1,3
openstack%2Fneutron~master~I429acf25ef6813b28e7f561d22068cc14c0f0977,openstack/neutron,master,I429acf25ef6813b28e7f561d22068cc14c0f0977,Move cisco db models to separate file,ABANDONED,2014-07-30 10:18:28.000000000,2014-08-08 15:23:30.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 8655}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10503}]","[{'number': 1, 'created': '2014-07-30 10:18:28.000000000', 'files': ['neutron/db/models/cisco.py', 'neutron/db/migration/models/head.py', 'neutron/db/models/nexus.py', 'neutron/tests/unit/cisco/n1kv/test_n1kv_db.py', 'neutron/db/models/n1kv.py', 'neutron/plugins/cisco/db/network_db_v2.py', 'neutron/tests/unit/cisco/test_nexus_db.py', 'neutron/plugins/cisco/db/nexus_db_v2.py', 'neutron/plugins/cisco/db/n1kv_db_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/de845a38a6b64c62dbd39b1c5339643c86e8c4d9', 'message': 'Move cisco db models to separate file\n\nPartial-Bug: #1346658\nChange-Id: I429acf25ef6813b28e7f561d22068cc14c0f0977\nImplements: blueprint db-migration-refactor\n'}]",0,110590,de845a38a6b64c62dbd39b1c5339643c86e8c4d9,18,16,1,8655,,,0,"Move cisco db models to separate file

Partial-Bug: #1346658
Change-Id: I429acf25ef6813b28e7f561d22068cc14c0f0977
Implements: blueprint db-migration-refactor
",git fetch https://review.opendev.org/openstack/neutron refs/changes/90/110590/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/models/cisco.py', 'neutron/db/migration/models/head.py', 'neutron/db/models/nexus.py', 'neutron/tests/unit/cisco/n1kv/test_n1kv_db.py', 'neutron/db/models/n1kv.py', 'neutron/plugins/cisco/db/network_db_v2.py', 'neutron/tests/unit/cisco/test_nexus_db.py', 'neutron/plugins/cisco/db/nexus_db_v2.py', 'neutron/plugins/cisco/db/n1kv_db_v2.py']",9,de845a38a6b64c62dbd39b1c5339643c86e8c4d9,bp/db-migration-refactor,from neutron.db.models import n1kv as n1kv_models_v2,from neutron.plugins.cisco.db import n1kv_models_v2,6,9
openstack%2Fneutron~master~Ifd4ac16eeefafbf4f2f88780d72062d259ca903f,openstack/neutron,master,Ifd4ac16eeefafbf4f2f88780d72062d259ca903f,Move bigswitch db models to separate file,ABANDONED,2014-07-30 10:18:28.000000000,2014-08-08 15:23:24.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 8655}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10503}]","[{'number': 1, 'created': '2014-07-30 10:18:28.000000000', 'files': ['neutron/db/migration/models/head.py', 'neutron/plugins/bigswitch/routerrule_db.py', 'neutron/db/models/bigswitch.py', 'neutron/plugins/bigswitch/db/consistency_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9b4093baaa38701893dba34131a7f55ae5c1bca3', 'message': 'Move bigswitch db models to separate file\n\nPartial-Bug: #1346658\nChange-Id: Ifd4ac16eeefafbf4f2f88780d72062d259ca903f\nImplements: blueprint db-migration-refactor\n'}]",0,110589,9b4093baaa38701893dba34131a7f55ae5c1bca3,18,16,1,8655,,,0,"Move bigswitch db models to separate file

Partial-Bug: #1346658
Change-Id: Ifd4ac16eeefafbf4f2f88780d72062d259ca903f
Implements: blueprint db-migration-refactor
",git fetch https://review.opendev.org/openstack/neutron refs/changes/89/110589/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/models/head.py', 'neutron/plugins/bigswitch/routerrule_db.py', 'neutron/db/models/bigswitch.py', 'neutron/plugins/bigswitch/db/consistency_db.py']",4,9b4093baaa38701893dba34131a7f55ae5c1bca3,bp/db-migration-refactor,"from neutron.db.models import bigswitch as models res = (self.session.query(models.ConsistencyHash). conhash = models.ConsistencyHash(hash_id=self.hash_id, hash=hash)","import sqlalchemy as safrom neutron.db import model_baseclass ConsistencyHash(model_base.BASEV2): ''' A simple table to store the latest consistency hash received from a server. For now we only support one global state so the hash_id will always be '1' ''' __tablename__ = 'consistencyhashes' hash_id = sa.Column(sa.String(255), primary_key=True) hash = sa.Column(sa.String(255), nullable=False) res = (self.session.query(ConsistencyHash). conhash = ConsistencyHash(hash_id=self.hash_id, hash=hash)",59,45
openstack%2Fneutron~master~Ib7ed1c2d21fa624f26e4b12035787243f70148eb,openstack/neutron,master,Ib7ed1c2d21fa624f26e4b12035787243f70148eb,Move brocade db models to separate file,ABANDONED,2014-07-30 10:18:28.000000000,2014-08-08 15:23:19.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 8655}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10503}]","[{'number': 1, 'created': '2014-07-30 10:18:28.000000000', 'files': ['neutron/plugins/brocade/db/models.py', 'neutron/db/models/__init__.py', 'neutron/db/migration/models/head.py', 'neutron/db/models/brocade.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4128b4781a6c4ec8fc1edc72acdd9cec3ef209cc', 'message': 'Move brocade db models to separate file\n\nPartial-Bug: #1346658\nChange-Id: Ib7ed1c2d21fa624f26e4b12035787243f70148eb\nImplements: blueprint db-migration-refactor\n'}]",0,110588,4128b4781a6c4ec8fc1edc72acdd9cec3ef209cc,18,16,1,8655,,,0,"Move brocade db models to separate file

Partial-Bug: #1346658
Change-Id: Ib7ed1c2d21fa624f26e4b12035787243f70148eb
Implements: blueprint db-migration-refactor
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/110588/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/brocade/db/models.py', 'neutron/db/models/__init__.py', 'neutron/db/migration/models/head.py', 'neutron/db/models/brocade.py']",4,4128b4781a6c4ec8fc1edc72acdd9cec3ef209cc,bp/db-migration-refactor,"# All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import sqlalchemy as sa from neutron.db import model_base from neutron.db import models_v2 class BrocadeNetwork(model_base.BASEV2, models_v2.HasId): """"""Schema for brocade network."""""" vlan = sa.Column(sa.String(10)) class BrocadePort(model_base.BASEV2): """"""Schema for brocade port."""""" port_id = sa.Column(sa.String(36), primary_key=True, default="""", server_default='') network_id = sa.Column(sa.String(36), sa.ForeignKey(""brocadenetworks.id""), nullable=False) admin_state_up = sa.Column(sa.Boolean, nullable=False) physical_interface = sa.Column(sa.String(36)) vlan_id = sa.Column(sa.String(36)) tenant_id = sa.Column(sa.String(36)) ",,60,38
openstack%2Fsahara~master~I65073d37a81a19d076892f3c4ba55cab70b1ff4e,openstack/sahara,master,I65073d37a81a19d076892f3c4ba55cab70b1ff4e,[TEST COMMIT] Disable swift check for CDH,ABANDONED,2014-08-06 15:56:38.000000000,2014-08-08 15:14:01.000000000,,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 7710}]","[{'number': 1, 'created': '2014-08-06 15:56:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/91e741efd1b37817824cba6922e9bf0601b3ae16', 'message': '[TEST COMMIT] Disable swift check for CDH\n\nChange-Id: I65073d37a81a19d076892f3c4ba55cab70b1ff4e\n'}, {'number': 2, 'created': '2014-08-06 16:05:32.000000000', 'files': ['sahara/tests/integration/tests/gating/test_cdh_gating.py', 'sahara/tests/integration/tests/base.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/1787f53921512288dd02b8c62c754d5559223c9a', 'message': '[TEST COMMIT] Disable swift check for CDH\n\nChange-Id: I65073d37a81a19d076892f3c4ba55cab70b1ff4e\n'}]",0,112334,1787f53921512288dd02b8c62c754d5559223c9a,10,3,2,7710,,,0,"[TEST COMMIT] Disable swift check for CDH

Change-Id: I65073d37a81a19d076892f3c4ba55cab70b1ff4e
",git fetch https://review.opendev.org/openstack/sahara refs/changes/34/112334/2 && git format-patch -1 --stdout FETCH_HEAD,['sahara/tests/integration/tests/gating/test_cdh_gating.py'],1,91e741efd1b37817824cba6922e9bf0601b3ae16,cdh-disable-test, #self._check_swift(), self._check_swift(),1,1
openstack%2Ffuel-main~stable%2F5.0~I7631145380f1443117c15519dada5232d9b23217,openstack/fuel-main,stable/5.0,I7631145380f1443117c15519dada5232d9b23217,Refactor network verification method,MERGED,2014-08-08 15:01:04.000000000,2014-08-08 15:11:05.000000000,2014-08-08 15:11:05.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-08-08 15:01:04.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/tests/tests_strength/test_master_node_failover.py', 'fuelweb_test/tests/test_simple.py', 'fuelweb_test/tests/test_environment_action.py', 'fuelweb_test/tests/test_upgrade.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/87f8c05d39cb4457a458121d9a30bcab9fde4c52', 'message': 'Refactor network verification method\n\n- Add default timeout to verify_network method\n- Add success parameter to verify_network method\n- Change run_network_verify to verify_netwrok in tests\n\nChange-Id: I7631145380f1443117c15519dada5232d9b23217\nCloses-Bug: #1352217\n'}]",0,112912,87f8c05d39cb4457a458121d9a30bcab9fde4c52,10,5,1,10136,,,0,"Refactor network verification method

- Add default timeout to verify_network method
- Add success parameter to verify_network method
- Change run_network_verify to verify_netwrok in tests

Change-Id: I7631145380f1443117c15519dada5232d9b23217
Closes-Bug: #1352217
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/12/112912/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/tests/tests_strength/test_master_node_failover.py', 'fuelweb_test/tests/test_simple.py', 'fuelweb_test/tests/test_environment_action.py', 'fuelweb_test/tests/test_upgrade.py']",5,87f8c05d39cb4457a458121d9a30bcab9fde4c52,refactorVerifyNetwork, self.fuel_web.verify_network(cluster_id)," task = self.fuel_web.run_network_verify(cluster_id) self.fuel_web.assert_task_success(task, 60 * 2, interval=10)",13,18
openstack%2Ffuel-web~master~Iffff38e540d098c8e92335ad27204af26d856bef,openstack/fuel-web,master,Iffff38e540d098c8e92335ad27204af26d856bef,restrict Ceph as storage backend for Glance used with vCenter,MERGED,2014-08-08 11:49:47.000000000,2014-08-08 15:08:37.000000000,2014-08-08 15:08:36.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8787}, {'_account_id': 8935}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-08-08 11:49:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/76746473f69910270efb8f6e30b3250beba25295', 'message': ""restrict Ceph as storage backend for Glance used with vCenter\n\n- rename 'vcenter_alert' to 'cinder_vcenter_alert' so we can distinguish\n  one message from another\n- add restriction to glance in openstack.yaml\n- add new alert 'glance_vcenter_alert'\n\nChange-Id: Iffff38e540d098c8e92335ad27204af26d856bef\nCloses-bug: #1351288\n""}, {'number': 2, 'created': '2014-08-08 12:16:23.000000000', 'files': ['nailgun/static/i18n/translation.json', 'nailgun/nailgun/fixtures/openstack.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/180f0c9aff18b33e1e66509451fa95da48426aa9', 'message': ""restrict Ceph as storage backend for Glance used with vCenter\n\n- rename 'vcenter_alert' to 'cinder_vcenter_alert' so we can distinguish\n  one message from another\n- add restriction to glance in openstack.yaml\n- add new alert 'glance_vcenter_alert'\n- add restrictions for Storage block on Settings tab\n\nChange-Id: Iffff38e540d098c8e92335ad27204af26d856bef\nCloses-bug: #1351288\n""}]",0,112834,180f0c9aff18b33e1e66509451fa95da48426aa9,17,5,2,11427,,,0,"restrict Ceph as storage backend for Glance used with vCenter

- rename 'vcenter_alert' to 'cinder_vcenter_alert' so we can distinguish
  one message from another
- add restriction to glance in openstack.yaml
- add new alert 'glance_vcenter_alert'
- add restrictions for Storage block on Settings tab

Change-Id: Iffff38e540d098c8e92335ad27204af26d856bef
Closes-bug: #1351288
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/34/112834/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/i18n/translation.json', 'nailgun/nailgun/fixtures/openstack.yaml']",2,76746473f69910270efb8f6e30b3250beba25295,bug/1351288," - ""Compute.hypervisor == 'vcenter'"": ""dialog.create_cluster_wizard.storage.cinder_vcenter_alert"" - ""Compute.hypervisor == 'vcenter'"": ""dialog.create_cluster_wizard.storage.glance_vcenter_alert"""," - ""Compute.hypervisor == 'vcenter'"": ""dialog.create_cluster_wizard.storage.vcenter_alert""",4,2
openstack%2Fopenstack-manuals~master~I035f66b32c5c8486166c573cd936a3d41434b85e,openstack/openstack-manuals,master,I035f66b32c5c8486166c573cd936a3d41434b85e,Enable translation of Networking Guide,MERGED,2014-08-08 14:04:19.000000000,2014-08-08 15:03:13.000000000,2014-08-08 15:03:12.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-08-08 14:04:19.000000000', 'files': ['doc/networking-guide/locale/networking-guide.pot', '.tx/config'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b912233b3cfea374c2562dde961b5bcda16b9fc4', 'message': 'Enable translation of Networking Guide\n\nSetup the guide so that our scripts work correctly.\n\nChange-Id: I035f66b32c5c8486166c573cd936a3d41434b85e\n'}]",0,112879,b912233b3cfea374c2562dde961b5bcda16b9fc4,9,4,1,6547,,,0,"Enable translation of Networking Guide

Setup the guide so that our scripts work correctly.

Change-Id: I035f66b32c5c8486166c573cd936a3d41434b85e
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/79/112879/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/networking-guide/locale/networking-guide.pot', '.tx/config']",2,b912233b3cfea374c2562dde961b5bcda16b9fc4,networking-guide-i18n,[openstack-manuals-i18n.networking-guide] file_filter = doc/networking-guide/locale/<lang>.po minimum_perc = 75 source_file = doc/networking-guide/locale/networking-guide.pot source_lang = en type = PO ,,7,0
openstack%2Ftrove~master~I22d839f9bbd6faf97bba16616e7f2cbcf725ab1e,openstack/trove,master,I22d839f9bbd6faf97bba16616e7f2cbcf725ab1e,Mocks utils.execute_with_timeout for mongodb tests,MERGED,2014-08-06 16:19:14.000000000,2014-08-08 15:01:13.000000000,2014-08-08 11:30:52.000000000,"[{'_account_id': 3}, {'_account_id': 694}, {'_account_id': 5293}, {'_account_id': 5367}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 10215}]","[{'number': 1, 'created': '2014-08-06 16:19:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f68b12e2d6eb431d918a4157cad8b6316ab5a723', 'message': ""Mocks utils.execute_with_timeout for mongodb tests\n\nThe mongodb test_prepare_from_backup unit test doesn't\nmock utils.execute_with_timeout causing it to prompt\nfor a password and/or hang.\n\nChange-Id: I22d839f9bbd6faf97bba16616e7f2cbcf725ab1e\nCloses-Bug: 1353570\n""}, {'number': 2, 'created': '2014-08-06 16:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/10055b2449b23ce7d7a0ba5f16bfa0fef2988ce1', 'message': ""Mocks utils.execute_with_timeout for mongodb tests\n\nThe mongodb test_prepare_from_backup unit test doesn't\nmock utils.execute_with_timeout causing it to prompt\nfor a password and/or hang.\n\nChange-Id: I22d839f9bbd6faf97bba16616e7f2cbcf725ab1e\nCloses-Bug: 1353570\n""}, {'number': 3, 'created': '2014-08-06 18:20:37.000000000', 'files': ['trove/tests/unittests/guestagent/test_mongodb_manager.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/d2c938510890e6a83a9758bb2e277bfaba35df3b', 'message': ""Mocks utils.execute_with_timeout for mongodb tests\n\nThe mongodb test_prepare_from_backup unit test doesn't\nmock utils.execute_with_timeout causing it to prompt\nfor a password and/or hang.\n\nChange-Id: I22d839f9bbd6faf97bba16616e7f2cbcf725ab1e\nCloses-Bug: 1353570\n""}]",5,112340,d2c938510890e6a83a9758bb2e277bfaba35df3b,30,9,3,4954,,,0,"Mocks utils.execute_with_timeout for mongodb tests

The mongodb test_prepare_from_backup unit test doesn't
mock utils.execute_with_timeout causing it to prompt
for a password and/or hang.

Change-Id: I22d839f9bbd6faf97bba16616e7f2cbcf725ab1e
Closes-Bug: 1353570
",git fetch https://review.opendev.org/openstack/trove refs/changes/40/112340/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/tests/unittests/guestagent/test_mongodb_manager.py'],1,f68b12e2d6eb431d918a4157cad8b6316ab5a723,bug/1353570,from trove.common import utils utils.execute_with_timeout = MagicMock(return_value=None),,2,0
openstack%2Fkeystone~master~Iaaf28e0b5eb0d139e593fa8dc409da56c9dd2824,openstack/keystone,master,Iaaf28e0b5eb0d139e593fa8dc409da56c9dd2824,Fixes eventlet server SIGHUP handling,ABANDONED,2014-08-06 17:45:40.000000000,2014-08-08 14:53:41.000000000,,"[{'_account_id': 3}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-08-06 17:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/600003ca489d3be89e8c3b7ab7007456e5cfea20', 'message': 'Fixes eventlet server SIGHUP handling\n\nWhen running the eventlet server with multiple workers (using config\noptions public_workers or admin_workers) the server would raise a\ntraceback with it received a SIGHUP.\n\nChange-Id: Iaaf28e0b5eb0d139e593fa8dc409da56c9dd2824\nCloses-Bug: #1337850\n'}, {'number': 2, 'created': '2014-08-06 17:47:16.000000000', 'files': ['keystone/common/environment/eventlet_server.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/42c66f4d8961b004c9a9e41ab5d42f7713e749b7', 'message': 'Fixes eventlet server SIGHUP handling\n\nWhen running the eventlet server with multiple workers (using config\noptions public_workers or admin_workers) the server would raise a\ntraceback when it received a SIGHUP.\n\nChange-Id: Iaaf28e0b5eb0d139e593fa8dc409da56c9dd2824\nCloses-Bug: #1337850\n'}]",0,112368,42c66f4d8961b004c9a9e41ab5d42f7713e749b7,7,2,2,7725,,,0,"Fixes eventlet server SIGHUP handling

When running the eventlet server with multiple workers (using config
options public_workers or admin_workers) the server would raise a
traceback when it received a SIGHUP.

Change-Id: Iaaf28e0b5eb0d139e593fa8dc409da56c9dd2824
Closes-Bug: #1337850
",git fetch https://review.opendev.org/openstack/keystone refs/changes/68/112368/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/environment/eventlet_server.py'],1,600003ca489d3be89e8c3b7ab7007456e5cfea20,bug/1337850," sock = self.socket.dup() sock) def reset(self): """"""Required by the service interface. The service interface is used by the launcher when receiving a SIGHUP. The service interface is defined in keystone.openstack.common.service.Service. Keystone does not need to do anything here. """""" ", self.socket),13,1
openstack%2Fec2-api~master~Ifaa3cb56644f85489c82a843f016db91a6ba7c2e,openstack/ec2-api,master,Ifaa3cb56644f85489c82a843f016db91a6ba7c2e,Adding network interfaces and security groups.,MERGED,2014-08-08 13:37:24.000000000,2014-08-08 14:48:18.000000000,2014-08-08 14:48:18.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-08-08 13:37:24.000000000', 'files': ['ec2api/api/network_interface.py', 'ec2api/api/cloud.py', 'ec2api/tests/test_network_interface.py', 'ec2api/api/security_group.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/1a7a3266ea6d231b1da814a54291369a568212d4', 'message': 'Adding network interfaces and security groups.\n\nUnit tests for security groups are coming up later.\n\nChange-Id: Ifaa3cb56644f85489c82a843f016db91a6ba7c2e\n'}]",0,112868,1a7a3266ea6d231b1da814a54291369a568212d4,8,4,1,9312,,,0,"Adding network interfaces and security groups.

Unit tests for security groups are coming up later.

Change-Id: Ifaa3cb56644f85489c82a843f016db91a6ba7c2e
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/68/112868/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/network_interface.py', 'ec2api/api/cloud.py', 'ec2api/tests/test_network_interface.py', 'ec2api/api/security_group.py']",4,1a7a3266ea6d231b1da814a54291369a568212d4,,"# Copyright 2014 Cloudscaling Group, Inc # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from neutronclient.common import exceptions as neutron_exception from oslo.config import cfg from ec2api.api import clients from ec2api.api import ec2client from ec2api.api import ec2utils from ec2api.api import utils from ec2api.db import api as db_api from ec2api import exception from ec2api.openstack.common import log as logging CONF = cfg.CONF LOG = logging.getLogger(__name__) """"""Security Groups related API implementation """""" SECURITY_GROUP_MAP = {'domain-name-servers': 'dns-servers', 'domain-name': 'domain-name', 'ntp-servers': 'ntp-server', 'netbios-name-servers': 'netbios-ns', 'netbios-node-type': 'netbios-nodetype'} def create_security_group(context, group_name, group_description, vpc_id=None): if vpc_id is None: ec2 = ec2client.ec2client(context) return ec2.create_security_groups(group_name=group_name, group_description=group_description) vpc = ec2utils.get_db_item(context, 'vpc', vpc_id) neutron = clients.neutron(context) with utils.OnCrashCleaner() as cleaner: os_security_group = neutron.create_security_group( {'security_group': {'name': group_name, 'description': group_description}})['security_group'] cleaner.addCleanup(neutron.delete_security_group, os_security_group['id']) security_group = db_api.add_item(context, 'sg', {'vpc_id': vpc['id'], 'os_id': os_security_group['id']}) return {'return': 'true', 'groupId': ec2utils.get_ec2_id(security_group['id'], 'sg')} def delete_security_group(context, group_name=None, group_id=None): if group_id is None or not group_id.startswith('sg-'): ec2 = ec2client.ec2client(context) return ec2.delete_security_groups(group_name=group_name, group_id=group_id) security_group = ec2utils.get_db_item(context, 'sg', group_id) # TODO(Alex) Check dependencies - instances and other security groups neutron = clients.neutron(context) with utils.OnCrashCleaner() as cleaner: db_api.delete_item(context, security_group['id']) cleaner.addCleanup(db_api.restore_item, context, 'sg', security_group) try: neutron.delete_security_group(security_group['os_id']) except neutron_exception.NeutronClientException: # TODO(Alex): do log error # TODO(Alex): adjust caught exception classes to catch: # the port doesn't exist # port is in use pass return True def describe_security_groups(context, group_name=None, group_id=None, filter=None): # TODO(Alex): implement filters neutron = clients.neutron(context) os_security_groups = neutron.list_security_groups()['security_groups'] security_groups = ec2utils.get_db_items(context, 'sg', group_id) formatted_security_groups = [] for os_security_group in os_security_groups: security_group = next((g for g in security_groups if g['os_id'] == os_security_group['id']), None) if group_id is not None and security_group is None: continue formatted_security_groups.append( _format_security_group(context, security_group, os_security_group, os_security_groups)) return {'securityGroupInfo': formatted_security_groups} def authorize_security_group_ingress(context, group_id, group_name, ip_permissions): if group_id is None or not group_id.startswith('sg-'): ec2 = ec2client.ec2client(context) return ec2.authorize_security_groups_ingress( group_name=group_name, group_id=group_id, ip_permissions=ip_permissions) return _authorize_security_group(context, group_id, ip_permissions, 'ingress') def authorize_security_group_egress(context, group_id, ip_permissions): return _authorize_security_group(context, group_id, ip_permissions, 'egress') def _authorize_security_group(context, group_id, ip_permissions, direction): rule_body = _build_rule(context, group_id, ip_permissions, direction) neutron = clients.neutron(context) os_security_group_rule = neutron.create_security_group_rule( {'security_group_rule': rule_body})['security_group_rule'] return True def _build_rule(context, group_id, ip_permissions, direction): security_group = ec2utils.get_db_item(context, 'sg', group_id) os_security_group_rule_body = ( {'security_group_id': security_group['os_id'], 'direction': direction, 'ethertype': 'IPv4'}) if ip_permissions is None: ip_permissions = [] for rule in ip_permissions: if rule.get('ip_protocol'): os_security_group_rule_body['protocol'] = rule['ip_protocol'] if rule.get('from_port'): os_security_group_rule_body['port_range_min'] = rule['from_port'] if rule.get('to_port'): os_security_group_rule_body['port_range_max'] = rule['to_port'] # TODO(Alex) AWS protocol claims support of multiple groups and cidrs, # however, neither aws cli, nor neutron support it at the moment. # It's possible in the future to convert list values incoming from # REST API into several neutron rules and squeeze them back into one # for describing. # For now only 1 value is supported for either. if rule.get('groups'): os_security_group_rule_body['remote_group_id'] = ( ec2utils.get_db_item(context, 'sg', rule['groups']['1']['group_id'])['os_id']) elif rule.get('ip_ranges'): os_security_group_rule_body['remote_ip_prefix'] = ( rule['ip_ranges']['1']['cidr_ip']) return os_security_group_rule_body def revoke_security_group_ingress(context, group_id, group_name, ip_permissions): if group_id is None or not group_id.startswith('sg-'): ec2 = ec2client.ec2client(context) return ec2.revoke_security_groups_ingress( group_name=group_name, group_id=group_id, ip_permissions=ip_permissions) return _revoke_security_group(context, group_id, ip_permissions, 'ingress') def revoke_security_group_egress(context, group_id, ip_permissions): return _revoke_security_group(context, group_id, ip_permissions, 'egress') def _are_identical_rules(rule1, rule2): def significant_values(rule): dict = {} for key, value in rule.items(): if (value is not None and value != -1 and key not in ['id', 'tenant_id']): dict[key] = str(value) return dict r1 = significant_values(rule1) r2 = significant_values(rule2) return r1 == r2 def _revoke_security_group(context, group_id, ip_permissions, direction): rule_body = _build_rule(context, group_id, ip_permissions, direction) neutron = clients.neutron(context) os_security_group = neutron.show_security_group( rule_body['security_group_id'])['security_group'] if not os_security_group.get('security_group_rules'): return True for os_rule in os_security_group['security_group_rules']: if _are_identical_rules(os_rule, rule_body): neutron.delete_security_group_rule( os_rule['id']) return True raise exception.InvalidPermissionNotFound() def _format_security_groups_ids_names(context): neutron = clients.neutron(context) os_security_groups = neutron.list_security_groups()['security_groups'] security_groups = db_api.get_items(context, 'sg') ec2_security_groups = {} for os_security_group in os_security_groups: security_group = next((g for g in security_groups if g['os_id'] == os_security_group['id']), None) if security_group is None: continue ec2_security_groups[os_security_group['id']] = ( {'groupId': ec2utils.get_ec2_id(security_group['id'], 'sg'), 'groupName': os_security_group['name']}) return ec2_security_groups def _format_security_group(context, security_group, os_security_group, os_security_groups): ec2_security_group = {} if security_group is not None: ec2_security_group['groupId'] = ( ec2utils.get_ec2_id(security_group['id'], 'sg')) ec2_security_group['vpcId'] = ( ec2utils.get_ec2_id(security_group['vpc_id'], 'vpc')) ec2_security_group['ownerId'] = os_security_group['tenant_id'] ec2_security_group['groupName'] = os_security_group['name'] ec2_security_group['groupDescription'] = os_security_group['description'] ingress_permissions = [] egress_permissions = [] for os_rule in os_security_group['security_group_rules']: # NOTE(Alex) We're skipping IPv6 rules because AWS doesn't support # them. if os_rule.get('ethertype', 'IPv4') == 'IPv6': continue ec2_rule = {'ipProtocol': -1 if os_rule['protocol'] is None else os_rule['protocol'], 'fromPort': -1 if os_rule['port_range_min'] is None else os_rule['port_range_min'], 'toPort': -1 if os_rule['port_range_max'] is None else os_rule['port_range_max']} remote_group_id = os_rule['remote_group_id'] if remote_group_id is not None: ec2_remote_group = {'groupId': remote_group_id} os_remote_group = next((g for g in os_security_groups if g['id'] == remote_group_id), None) if os_remote_group is not None: ec2_remote_group['groupName'] = os_remote_group['name'] ec2_remote_group['userId'] = os_remote_group['tenant_id'] else: # TODO(Alex) Log absence of remote_group pass ec2_rule['groups'] = [ec2_remote_group] elif os_rule['remote_ip_prefix'] is not None: ec2_rule['ipRanges'] = [{'cidrIp': os_rule['remote_ip_prefix']}] if os_rule['direction'] == 'egress': egress_permissions.append(ec2_rule) elif os_rule['direction'] == 'ingress': ingress_permissions.append(ec2_rule) ec2_security_group['ipPermissions'] = ingress_permissions ec2_security_group['ipPermissionsEgress'] = egress_permissions return ec2_security_group ",,1489,0
openstack%2Fnova~master~I349e3b2221fff0ae217a71a91895afd21ff7d18d,openstack/nova,master,I349e3b2221fff0ae217a71a91895afd21ff7d18d,Fix attaching config drive issue on Hyper-V when migrate instances,MERGED,2014-05-21 08:55:29.000000000,2014-08-08 14:40:32.000000000,2014-08-08 14:40:29.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 679}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 3185}, {'_account_id': 5046}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8543}, {'_account_id': 8622}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10635}]","[{'number': 1, 'created': '2014-05-21 08:55:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ea3a896a2b7e529a4ed7998053885df6c806c25', 'message': ""Fix config drive issue on Hyper-V when migrate instances\n\nAfter instance resized or migrated on Hyper-V hyperviosr.\nThe configdrive iso or vhd is copied to resized or migrated\ninstance, but is not attached to instance.\n\nBecause there are configurations for config drive like\nconfig_drive_cdrom, config_drive_format, and the configurations\non different Hyper-V compute node may be different. it will need\nto convert configdrive format after resized or migrated.\nIt is easy to convert from iso9660 or vfat to vhd, but it seems\nimpossible to convert from vhd to iso9660 or vfat.\nSo this commit just ingore the target Hyper-V compute node's\nconfig drive configurations, leave the original config drive format.\n\nChange-Id: I349e3b2221fff0ae217a71a91895afd21ff7d18d\nCloses-Bug: #1321640\n""}, {'number': 2, 'created': '2014-05-21 10:26:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a413d8116ec9331317c3aa22aa1b54149f8a4151', 'message': ""Fix config drive issue on Hyper-V when migrate instances\n\nAfter instance resized or migrated on Hyper-V hyperviosr.\nThe configdrive iso or vhd is copied to resized or migrated\ninstance, but is not attached to instance.\n\nBecause there are configurations for config drive like\nconfig_drive_cdrom, config_drive_format, and the configurations\non different Hyper-V compute node may be different. it will need\nto convert configdrive format after resized or migrated.\nIt is easy to convert from iso9660 or vfat to vhd, but it seems\nimpossible to convert from vhd to iso9660 or vfat.\nSo this commit just ingore the target Hyper-V compute node's\nconfig drive configurations, leave the original config drive format.\n\nChange-Id: I349e3b2221fff0ae217a71a91895afd21ff7d18d\nCloses-Bug: #1321640\n""}, {'number': 3, 'created': '2014-05-21 10:31:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8c6c21e2e758274f035640c84e452456a73b68ac', 'message': ""Fix config drive issue on Hyper-V when migrate instances\n\nAfter instance resized or migrated on Hyper-V hyperviosr.\nThe configdrive iso or vhd is copied to resized or migrated\ninstance, but is not attached to instance.\n\nBecause there are configurations for config drive like\nconfig_drive_cdrom, config_drive_format, and the configurations\non different Hyper-V compute node may be different. it will need\nto convert configdrive format after resized or migrated.\nIt is easy to convert from iso9660 or vfat to vhd, but it seems\nimpossible to convert from vhd to iso9660 or vfat.\nSo this commit just ingore the target Hyper-V compute node's\nconfig drive configurations, leave the original config drive format.\n\nChange-Id: I349e3b2221fff0ae217a71a91895afd21ff7d18d\nCloses-Bug: #1321640\n""}, {'number': 4, 'created': '2014-05-22 06:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c917da26d6ffe305153d5bba44d00f1b87de4695', 'message': ""Fix config drive issue on Hyper-V when migrate instances\n\nAfter instance resized or migrated on Hyper-V hyperviosr.\nThe configdrive iso or vhd is copied to resized or migrated\ninstance, but is not attached to instance.\n\nBecause there are configurations for config drive like\nconfig_drive_cdrom, config_drive_format, and the configurations\non different Hyper-V compute node may be different. it will need\nto convert configdrive format after resized or migrated.\nIt is easy to convert from iso9660 or vfat to vhd, but it seems\nimpossible to convert from vhd to iso9660 or vfat.\nSo this commit just ingore the target Hyper-V compute node's\nconfig drive configurations, leave the original config drive format.\n\nChange-Id: I349e3b2221fff0ae217a71a91895afd21ff7d18d\nCloses-Bug: #1321640\n""}, {'number': 5, 'created': '2014-05-22 20:47:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/98b5b641e7c3a697311c2c069e2c017235e6e28b', 'message': ""Fix config drive issue on Hyper-V when migrate instances\n\nAfter instance resized or migrated on Hyper-V hyperviosr.\nThe configdrive iso or vhd is copied to resized or migrated\ninstance, but is not attached to instance.\n\nBecause there are configurations for config drive like\nconfig_drive_cdrom, config_drive_format, and the configurations\non different Hyper-V compute node may be different. it will need\nto convert configdrive format after resized or migrated.\nIt is easy to convert from iso9660 or vfat to vhd, but it seems\nimpossible to convert from vhd to iso9660 or vfat.\nSo this commit just ingore the target Hyper-V compute node's\nconfig drive configurations, leave the original config drive format.\n\nChange-Id: I349e3b2221fff0ae217a71a91895afd21ff7d18d\nCloses-Bug: #1321640\n""}, {'number': 6, 'created': '2014-05-22 21:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9c6b1b16c717fe7e84fa88070180fcfe831225d4', 'message': ""Fix config drive issue on Hyper-V when migrate instances\n\nAfter instance resized or migrated on Hyper-V hypervisor.\nThe configdrive iso or vhd is copied to resized or migrated\ninstance, but is not attached to instance.\n\nBecause there are configurations for config drive like\nconfig_drive_cdrom, config_drive_format, and the configurations\non different Hyper-V compute node may be different. it will need\nto convert configdrive format after resized or migrated.\nIt is easy to convert from iso9660 or vfat to vhd, but it seems\nimpossible to convert from vhd to iso9660 or vfat.\nSo this commit just ingore the target Hyper-V compute node's\nconfig drive configurations, leave the original config drive format.\n\nChange-Id: I349e3b2221fff0ae217a71a91895afd21ff7d18d\nCloses-Bug: #1321640\n""}, {'number': 7, 'created': '2014-05-23 05:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/021a1d00ddb2ce9fc206625f54a7e67de5d2078d', 'message': ""Fix config drive issue on Hyper-V when migrate instances\n\nAfter instance resized or migrated on Hyper-V hypervisor.\nThe configdrive iso or vhd is copied to resized or migrated\ninstance, but is not attached to instance.\n\nBecause there are configurations for config drive like\nconfig_drive_cdrom, config_drive_format, and the configurations\non different Hyper-V compute node may be different. it will need\nto convert configdrive format after resized or migrated.\nIt is easy to convert from iso9660 or vfat to vhd, but it seems\nimpossible to convert from vhd to iso9660 or vfat.\nSo this commit just ingore the target Hyper-V compute node's\nconfig drive configurations, leave the original config drive format.\n\nChange-Id: I349e3b2221fff0ae217a71a91895afd21ff7d18d\nCloses-Bug: #1321640\n""}, {'number': 8, 'created': '2014-05-23 06:01:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/72c024f7464daaba111eed09bfb70e2303f25581', 'message': ""Fix config drive issue on Hyper-V when migrate instances\n\nAfter instance resized or migrated on Hyper-V hypervisor.\nThe configdrive iso or vhd is copied to resized or migrated\ninstance, but is not attached to instance.\n\nBecause there are configurations for config drive like\nconfig_drive_cdrom, config_drive_format, and the configurations\non different Hyper-V compute node may be different. it will need\nto convert configdrive format after resized or migrated.\nIt is easy to convert from iso9660 or vfat to vhd, but it seems\nimpossible to convert from vhd to iso9660 or vfat.\nSo this commit just ingore the target Hyper-V compute node's\nconfig drive configurations, leave the original config drive format.\n\nChange-Id: I349e3b2221fff0ae217a71a91895afd21ff7d18d\nCloses-Bug: #1321640\n""}, {'number': 9, 'created': '2014-05-23 08:19:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28063297ccd8c464514bcad25f3eae74b7d97d91', 'message': ""Fix config drive issue on Hyper-V when migrate instances\n\nAfter instance resized or migrated on Hyper-V hypervisor.\nThe configdrive iso or vhd is copied to resized or migrated\ninstance, but is not attached to instance.\n\nBecause there are configurations for config drive like\nconfig_drive_cdrom, config_drive_format, and the configurations\non different Hyper-V compute node may be different. it will need\nto convert configdrive format after resized or migrated.\nIt is easy to convert from iso9660 or vfat to vhd, but it seems\nimpossible to convert from vhd to iso9660 or vfat.\nSo this commit just ingore the target Hyper-V compute node's\nconfig drive configurations, leave the original config drive format.\n\nChange-Id: I349e3b2221fff0ae217a71a91895afd21ff7d18d\nCloses-Bug: #1321640\n""}, {'number': 10, 'created': '2014-05-23 15:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3da4956e7c42362c5d97027ad888fa18fb17446d', 'message': ""Fix config drive issue on Hyper-V when migrate instances\n\nAfter instance resized or migrated on Hyper-V hypervisor.\nThe configdrive iso or vhd is copied to resized or migrated\ninstance, but is not attached to instance.\n\nBecause there are configurations for config drive like\nconfig_drive_cdrom, config_drive_format, and the configurations\non different Hyper-V compute node may be different. it will need\nto convert configdrive format after resized or migrated.\nIt is easy to convert from iso9660 or vfat to vhd, but it seems\nimpossible to convert from vhd to iso9660 or vfat.\nSo this commit just ingore the target Hyper-V compute node's\nconfig drive configurations, leave the original config drive format.\n\nChange-Id: I349e3b2221fff0ae217a71a91895afd21ff7d18d\nCloses-Bug: #1321640\n""}, {'number': 11, 'created': '2014-05-27 10:04:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9774aceb7c23fba5fcab954d430c53d7c6dc8093', 'message': ""Fix config drive issue on Hyper-V when migrate instances\n\nAfter instance resized or migrated on Hyper-V hypervisor.\nThe configdrive iso or vhd is copied to resized or migrated\ninstance, but is not attached to instance.\n\nBecause there are configurations for config drive like\nconfig_drive_cdrom, config_drive_format, and the configurations\non different Hyper-V compute node may be different. it will need\nto convert configdrive format after resized or migrated.\nIt is easy to convert from iso9660 or vfat to vhd, but it seems\nimpossible to convert from vhd to iso9660 or vfat.\nSo this commit just ingore the target Hyper-V compute node's\nconfig drive configurations, leave the original config drive format.\n\nChange-Id: I349e3b2221fff0ae217a71a91895afd21ff7d18d\nCloses-Bug: #1321640\n""}, {'number': 12, 'created': '2014-05-28 15:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d18b5502f999c5d248ccb1f6d43e8ce632367ca', 'message': ""Fix config drive issue on Hyper-V when migrate instances\n\nAfter instance resized or migrated on Hyper-V hypervisor.\nThe configdrive iso or vhd is copied to resized or migrated\ninstance, but is not attached to instance.\n\nBecause there are configurations for config drive like\nconfig_drive_cdrom, config_drive_format, and the configurations\non different Hyper-V compute node may be different. it will need\nto convert configdrive format after resized or migrated.\nIt is easy to convert from iso9660 or vfat to vhd, but it seems\nimpossible to convert from vhd to iso9660 or vfat.\nSo this commit just ingore the target Hyper-V compute node's\nconfig drive configurations, leave the original config drive format.\n\nChange-Id: I349e3b2221fff0ae217a71a91895afd21ff7d18d\nCloses-Bug: #1321640\n""}, {'number': 13, 'created': '2014-05-29 07:40:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/573a7b757fb63694780a7042cf0e451fdbe6f3a5', 'message': ""Fix config drive issue on Hyper-V when migrate instances\n\nAfter instance resized or migrated on Hyper-V hypervisor.\nThe configdrive iso or vhd is copied to resized or migrated\ninstance, but is not attached to instance.\n\nBecause there are configurations for config drive like\nconfig_drive_cdrom, config_drive_format, and the configurations\non different Hyper-V compute node may be different. it will need\nto convert configdrive format after resized or migrated.\nIt is easy to convert from iso9660 or vfat to vhd, but it seems\nimpossible to convert from vhd to iso9660 or vfat.\nSo this commit just ingore the target Hyper-V compute node's\nconfig drive configurations, leave the original config drive format.\n\nChange-Id: I349e3b2221fff0ae217a71a91895afd21ff7d18d\nCloses-Bug: #1321640\n""}, {'number': 14, 'created': '2014-06-10 02:55:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f4dc38a1e3ba07b59aff9902ceec3f67743ee170', 'message': ""Fix attaching config drive issue on Hyper-V when migrate instances\n\nAfter instance resized or migrated on Hyper-V hypervisor.\nThe configdrive iso or vhd is copied to resized or migrated\ninstance, but is not attached to instance.\n\nBecause there are configurations for config drive like\nconfig_drive_cdrom, config_drive_format, and the configurations\non different Hyper-V compute node may be different. it will need\nto convert configdrive format after resized or migrated.\nIt is easy to convert from iso9660 or vfat to vhd, but it seems\nimpossible to convert from vhd to iso9660 or vfat.\nSo this commit just ignore the target Hyper-V compute node's\nconfig drive configurations, leave the original config drive format.\n\nChange-Id: I349e3b2221fff0ae217a71a91895afd21ff7d18d\nCloses-Bug: #1321640\n""}, {'number': 15, 'created': '2014-07-29 23:54:28.000000000', 'files': ['nova/tests/virt/hyperv/test_migrationops.py', 'nova/virt/hyperv/pathutils.py', 'nova/tests/virt/hyperv/test_vmops.py', 'nova/virt/hyperv/vmops.py', 'nova/tests/virt/hyperv/fake.py', 'nova/tests/virt/hyperv/test_hypervapi.py', 'nova/tests/virt/hyperv/test_pathutils.py', 'nova/virt/hyperv/constants.py', 'nova/virt/hyperv/migrationops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/513c6bbd36563e57a85d33f9c94f4a20ab7c00f4', 'message': ""Fix attaching config drive issue on Hyper-V when migrate instances\n\nAfter instance resized or migrated on Hyper-V hypervisor.\nThe configdrive iso or vhd is copied to resized or migrated\ninstance, but is not attached to instance.\n\nBecause there are configurations for config drive like\nconfig_drive_cdrom, config_drive_format, and the configurations\non different Hyper-V compute node may be different. it will need\nto convert configdrive format after resized or migrated.\nIt is easy to convert from iso9660 or vfat to vhd, but it seems\nimpossible to convert from vhd to iso9660 or vfat.\nSo this commit just ignore the target Hyper-V compute node's\nconfig drive configurations, leave the original config drive format.\n\nChange-Id: I349e3b2221fff0ae217a71a91895afd21ff7d18d\nCloses-Bug: #1321640\n""}]",88,94556,513c6bbd36563e57a85d33f9c94f4a20ab7c00f4,181,16,15,8622,,,0,"Fix attaching config drive issue on Hyper-V when migrate instances

After instance resized or migrated on Hyper-V hypervisor.
The configdrive iso or vhd is copied to resized or migrated
instance, but is not attached to instance.

Because there are configurations for config drive like
config_drive_cdrom, config_drive_format, and the configurations
on different Hyper-V compute node may be different. it will need
to convert configdrive format after resized or migrated.
It is easy to convert from iso9660 or vfat to vhd, but it seems
impossible to convert from vhd to iso9660 or vfat.
So this commit just ignore the target Hyper-V compute node's
config drive configurations, leave the original config drive format.

Change-Id: I349e3b2221fff0ae217a71a91895afd21ff7d18d
Closes-Bug: #1321640
",git fetch https://review.opendev.org/openstack/nova refs/changes/56/94556/10 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/hyperv/pathutils.py', 'nova/virt/hyperv/vmops.py', 'nova/virt/hyperv/migrationops.py']",3,1ea3a896a2b7e529a4ed7998053885df6c806c25,bug/1321640,"from nova.virt import configdrive if configdrive.required_by(instance): configdrive_path = self._pathutils.lookup_configdrive_path(instance_name) if configdrive_path: self._vmops.attach_config_drive(instance, configdrive_path) if configdrive.required_by(instance): configdrive_path = self._pathutils.lookup_configdrive_path(instance_name) if configdrive_path: self._vmops.attach_config_drive(instance, configdrive_path) ",,47,5
openstack%2Ffuel-main~stable%2F5.0~I1be3e904aec9e74b62763db8236c92f776bf640f,openstack/fuel-main,stable/5.0,I1be3e904aec9e74b62763db8236c92f776bf640f,Skip time synchronization error and print warning,MERGED,2014-08-08 09:28:50.000000000,2014-08-08 14:37:02.000000000,2014-08-08 14:37:02.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}]","[{'number': 1, 'created': '2014-08-08 09:28:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2705bbf1fdd8adbf9422387699742ec7d670f949', 'message': 'Skip time synchronization error and print warning\n\nDo not fail system tests if time synchronization on\nslave nodes fails and print warning message in tests\noutput.\n\nChange-Id: I1be3e904aec9e74b62763db8236c92f776bf640f\nCloses-bug: #1354327\n'}, {'number': 2, 'created': '2014-08-08 09:39:31.000000000', 'files': ['fuelweb_test/models/environment.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c274cafd45d6265b2dc528383d91952dc86ac2e9', 'message': 'Skip time synchronization error and print warning\n\nDo not fail system tests if time synchronization on\nslave nodes fails and print warning message in tests\noutput.\n\nChange-Id: I1be3e904aec9e74b62763db8236c92f776bf640f\nCloses-bug: #1354327\n'}]",0,112809,c274cafd45d6265b2dc528383d91952dc86ac2e9,14,6,2,11081,,,0,"Skip time synchronization error and print warning

Do not fail system tests if time synchronization on
slave nodes fails and print warning message in tests
output.

Change-Id: I1be3e904aec9e74b62763db8236c92f776bf640f
Closes-bug: #1354327
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/09/112809/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/environment.py'],1,2705bbf1fdd8adbf9422387699742ec7d670f949,," logger.warning( 'Exception caught while trying to sync time on {0}:' ' {1}'.format(node.name, e))", logger.error( 'Paramiko exception catched while' ' trying to run ntpd: %s' % e) raise ,3,5
openstack%2Ffuel-main~master~I1be3e904aec9e74b62763db8236c92f776bf640f,openstack/fuel-main,master,I1be3e904aec9e74b62763db8236c92f776bf640f,Skip time synchronization error and print warning,MERGED,2014-08-08 09:26:46.000000000,2014-08-08 14:36:44.000000000,2014-08-08 14:36:44.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}]","[{'number': 1, 'created': '2014-08-08 09:26:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d8b53f0d5dae81748822ac1a5a059108800b3980', 'message': 'Skip time synchronization error and print warning\n\nDo not fail system tests if time synchronization on\nslave nodes fails and print warning message in tests\noutput.\n\nChange-Id: I1be3e904aec9e74b62763db8236c92f776bf640f\nCloses-bug: #1354327\n'}, {'number': 2, 'created': '2014-08-08 09:32:23.000000000', 'files': ['fuelweb_test/models/environment.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/401c77a91351fd2edbb55e8831ee2804326598af', 'message': 'Skip time synchronization error and print warning\n\nDo not fail system tests if time synchronization on\nslave nodes fails and print warning message in tests\noutput.\n\nChange-Id: I1be3e904aec9e74b62763db8236c92f776bf640f\nCloses-bug: #1354327\n'}]",0,112807,401c77a91351fd2edbb55e8831ee2804326598af,16,6,2,11081,,,0,"Skip time synchronization error and print warning

Do not fail system tests if time synchronization on
slave nodes fails and print warning message in tests
output.

Change-Id: I1be3e904aec9e74b62763db8236c92f776bf640f
Closes-bug: #1354327
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/07/112807/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/environment.py'],1,d8b53f0d5dae81748822ac1a5a059108800b3980,bug/1354327," logger.warning( 'Exception caught while trying to sync time on {0}:' ' {1}'.format(node.name, e))", logger.error( 'Paramiko exception catched while' ' trying to run ntpd: %s' % e) raise ,3,5
openstack%2Fcloudkitty~master~Ib20a0c20c93a4d67995d1a1ed848d20d841ec504,openstack/cloudkitty,master,Ib20a0c20c93a4d67995d1a1ed848d20d841ec504,Added cloudkitty-dbsync tool,MERGED,2014-08-08 13:56:52.000000000,2014-08-08 14:34:04.000000000,2014-08-08 14:34:04.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-08 13:56:52.000000000', 'files': ['cloudkitty/cli/dbsync.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/1467304878daf06ef12349e8520ec00f962ff6ba', 'message': 'Added cloudkitty-dbsync tool\n\nChange-Id: Ib20a0c20c93a4d67995d1a1ed848d20d841ec504\n'}]",0,112875,1467304878daf06ef12349e8520ec00f962ff6ba,7,2,1,7042,,,0,"Added cloudkitty-dbsync tool

Change-Id: Ib20a0c20c93a4d67995d1a1ed848d20d841ec504
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/75/112875/1 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/cli/dbsync.py', 'setup.cfg']",2,1467304878daf06ef12349e8520ec00f962ff6ba,feature/dbsync, cloudkitty-dbsync = cloudkitty.cli.dbsync:main,,153,0
openstack%2Frally~master~Id4331761e4f9c4bb6735745ed8461eaa671d0945,openstack/rally,master,Id4331761e4f9c4bb6735745ed8461eaa671d0945,"Adds --json,--pprint flags to cmd",MERGED,2014-07-14 16:41:46.000000000,2014-08-08 14:31:19.000000000,2014-08-08 14:31:18.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 6124}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 9545}, {'_account_id': 11105}]","[{'number': 1, 'created': '2014-07-14 16:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e0cc55e8e7246beacecbfe7a80a87ade7abc6df5', 'message': 'Adds --json,--pprint flags to cmd\n\n* Add flags to output cmd results in json(--json)\n  and pretty print(--pprint) format\n\nChange-Id: Id4331761e4f9c4bb6735745ed8461eaa671d0945\nCloses-Bug: #1341501\n'}, {'number': 2, 'created': '2014-07-16 10:06:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/663612ce922e8a9cf6781991732b5ff1cc311ef1', 'message': 'Adds --json,--pprint flags to cmd\n\n* Add flags to output cmd results in json(--json)\n  and pretty print(--pprint) format\n\nChange-Id: Id4331761e4f9c4bb6735745ed8461eaa671d0945\nCloses-Bug: #1341501\n'}, {'number': 3, 'created': '2014-07-25 09:52:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/58ff21528ae864c5551497b54fe14f8efb28259d', 'message': 'Adds --json,--pprint flags to cmd\n\n* Add flags to output cmd results in json(--json)\n  and pretty print(--pprint) format\n\nChange-Id: Id4331761e4f9c4bb6735745ed8461eaa671d0945\nCloses-Bug: #1341501\n'}, {'number': 4, 'created': '2014-08-08 11:30:26.000000000', 'files': ['tests/cmd/commands/test_deployment.py', 'rally/cmd/commands/deployment.py', 'tests/cmd/commands/test_task.py', 'rally/cmd/commands/task.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/61842b86e0af69d43932ea752618325b67a2444e', 'message': 'Adds --json,--pprint flags to cmd\n\n* Add flags to output cmd results in json(--json)\n  and pretty print(--pprint) format\n\nChange-Id: Id4331761e4f9c4bb6735745ed8461eaa671d0945\nCloses-Bug: #1341501\n'}]",28,106813,61842b86e0af69d43932ea752618325b67a2444e,48,7,4,6124,,,0,"Adds --json,--pprint flags to cmd

* Add flags to output cmd results in json(--json)
  and pretty print(--pprint) format

Change-Id: Id4331761e4f9c4bb6735745ed8461eaa671d0945
Closes-Bug: #1341501
",git fetch https://review.opendev.org/openstack/rally refs/changes/13/106813/4 && git format-patch -1 --stdout FETCH_HEAD,"['rally/cmd/commands/deployment.py', 'rally/cmd/commands/task.py']",2,e0cc55e8e7246beacecbfe7a80a87ade7abc6df5,bug/1341501," @cliutils.args('--pprint', type=bool, dest='output_pprint', required=False, help=('Output in pprint format')) @cliutils.args('--json', type=bool, dest='output_json', required=False, help=('Output in json format')) def results(self, task_id=None, output_pprint=None, output_json=None): :param output_pprint: Output in pprint format :param output_json: Output in json format if not any([output_pprint, output_json]) or output_json: elif output_pprint: print(_('Unsupported output format'))"," @cliutils.args('--pretty', type=str, help=('pretty print (pprint) ' 'or json print (json)')) def results(self, task_id=None, pretty=False): :param pretty: Pretty print (pprint) or not (json) if not pretty or pretty == 'json': elif pretty == 'pprint': print(_(""Wrong value for --pretty=%s"") % pretty)",26,9
openstack%2Ffuel-main~master~I115d7fd909d627d92b1811baebcd776b49e1af11,openstack/fuel-main,master,I115d7fd909d627d92b1811baebcd776b49e1af11,Refactor verify network method,MERGED,2014-08-08 12:49:02.000000000,2014-08-08 14:27:44.000000000,2014-08-08 14:27:44.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-08-08 12:49:02.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/tests/test_simple.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/71d087af48ee2b48206e46981d473f3d826ccf75', 'message': ""Refactor verify network method\n\n- Add 'success' parameter that is true by default\n- Modify verify network method call in tests where it\nshould fail\n\nChange-Id: I115d7fd909d627d92b1811baebcd776b49e1af11\nCloses-Bug: #1352217\n""}]",0,112851,71d087af48ee2b48206e46981d473f3d826ccf75,11,6,1,10136,,,0,"Refactor verify network method

- Add 'success' parameter that is true by default
- Modify verify network method call in tests where it
should fail

Change-Id: I115d7fd909d627d92b1811baebcd776b49e1af11
Closes-Bug: #1352217
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/51/112851/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/tests/test_simple.py']",2,71d087af48ee2b48206e46981d473f3d826ccf75,modifyVerifyNetwork," self.fuel_web.verify_network(cluster_id, success=False) self.fuel_web.verify_network(cluster_id, success=False)", self.fuel_web.verify_network(cluster_id) self.fuel_web.verify_network(cluster_id),7,4
openstack%2Fcloudkitty~master~Id9f02088b9bbb0da730507029c8c375b8a95531d,openstack/cloudkitty,master,Id9f02088b9bbb0da730507029c8c375b8a95531d,Implemented HashMap API,MERGED,2014-08-08 13:54:23.000000000,2014-08-08 14:24:02.000000000,2014-08-08 14:24:01.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-08 13:54:23.000000000', 'files': ['cloudkitty/billing/hash.py', 'cloudkitty/billing/hash/db/sqlalchemy/alembic/script.py.mako', 'cloudkitty/billing/hash/db/sqlalchemy/models.py', 'cloudkitty/billing/hash/db/sqlalchemy/migration.py', 'cloudkitty/billing/hash/db/sqlalchemy/api.py', 'cloudkitty/billing/hash/db/sqlalchemy/__init__.py', 'cloudkitty/billing/hash/db/__init__.py', 'cloudkitty/billing/hash/db/api.py', 'cloudkitty/billing/hash/db/sqlalchemy/alembic/versions/48676342515a_initial_migration.py', 'cloudkitty/billing/hash/db/sqlalchemy/alembic/env.py', 'cloudkitty/billing/hash/__init__.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/204783c2ca99bb1ba3ce20975f89a97fa21c95b6', 'message': 'Implemented HashMap API\n\nChange-Id: Id9f02088b9bbb0da730507029c8c375b8a95531d\n'}]",0,112871,204783c2ca99bb1ba3ce20975f89a97fa21c95b6,7,2,1,7042,,,0,"Implemented HashMap API

Change-Id: Id9f02088b9bbb0da730507029c8c375b8a95531d
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/71/112871/1 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/billing/hash.py', 'cloudkitty/billing/hash/db/sqlalchemy/alembic/script.py.mako', 'cloudkitty/billing/hash/db/sqlalchemy/models.py', 'cloudkitty/billing/hash/db/sqlalchemy/api.py', 'cloudkitty/billing/hash/db/sqlalchemy/migration.py', 'cloudkitty/billing/hash/db/sqlalchemy/__init__.py', 'cloudkitty/billing/hash/db/__init__.py', 'cloudkitty/billing/hash/db/api.py', 'cloudkitty/billing/hash/db/sqlalchemy/alembic/versions/48676342515a_initial_migration.py', 'cloudkitty/billing/hash/db/sqlalchemy/alembic/env.py', 'cloudkitty/billing/hash/__init__.py']",11,204783c2ca99bb1ba3ce20975f89a97fa21c95b6,feature/billing/hashmap_api,"# -*- coding: utf-8 -*- # Copyright 2014 Objectif Libre # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # @author: Stphane Albert # import pecan from pecan import routing from wsme import types as wtypes import wsmeext.pecan as wsme_pecan from cloudkitty import billing from cloudkitty.billing.hash.db import api from cloudkitty.db import api as db_api from cloudkitty.openstack.common import log as logging LOG = logging.getLogger(__name__) MAP_TYPE = wtypes.Enum(wtypes.text, 'flat', 'rate') class Mapping(wtypes.Base): map_type = wtypes.wsattr(MAP_TYPE, default='rate', name='type') value = wtypes.wsattr(float, mandatory=True) class BasicHashMapConfigController(billing.BillingConfigController): @pecan.expose() def _route(self, args, request=None): if len(args) > 2: # Taken from base _route function if request is None: from pecan import request # noqa method = request.params.get('_method', request.method).lower() if request.method == 'GET' and method in ('delete', 'put'): pecan.abort(405) if request.method == 'GET': return routing.lookup_controller(self.get_mapping, args) return super(BasicHashMapConfigController, self)._route(args) @wsme_pecan.wsexpose(Mapping, wtypes.text, wtypes.text, wtypes.text) def get_mapping(self, service, field, key): """"""Return the list of every mappings. """""" hashmap = api.get_instance() try: return hashmap.get_mapping(service, field, key) except (api.NoSuchService, api.NoSuchField, api.NoSuchMapping) as e: pecan.abort(400, str(e)) @wsme_pecan.wsexpose([wtypes.text]) def get(self): hashmap = api.get_instance() return [service.name for service in hashmap.list_services()] @wsme_pecan.wsexpose([wtypes.text], wtypes.text, wtypes.text) def get_one(self, service=None, field=None): """"""Return the list of every sub keys. """""" hashmap = api.get_instance() if field: try: return [mapping.key for mapping in hashmap.list_mappings( service, field)] except (api.NoSuchService, api.NoSuchField) as e: pecan.abort(400, str(e)) else: try: return [f.name for f in hashmap.list_fields(service)] except api.NoSuchService as e: pecan.abort(400, str(e)) # FIXME (sheeprine): Still a problem with our routing and the different # object types. For service/field it's text or a mapping. @wsme_pecan.wsexpose(None, wtypes.text, wtypes.text, wtypes.text, body=Mapping) def post(self, service, field=None, key=None, mapping=None): hashmap = api.get_instance() if field: if key: if mapping: try: # FIXME(sheeprine): We should return the result hashmap.create_mapping( service, field, key, value=mapping.value, map_type=mapping.map_type ) pecan.response.headers['Location'] = pecan.request.path except api.MappingAlreadyExists as e: pecan.abort(409, str(e)) else: e = ValueError('Mapping can\'t be empty.') pecan.abort(400, str(e)) else: try: hashmap.create_field(service, field) pecan.response.headers['Location'] = pecan.request.path except api.FieldAlreadyExists as e: pecan.abort(409, str(e)) else: try: hashmap.create_service(service) pecan.response.headers['Location'] = pecan.request.path except api.ServiceAlreadyExists as e: pecan.abort(409, str(e)) pecan.response.status = 201 @wsme_pecan.wsexpose(None, wtypes.text, wtypes.text, wtypes.text, body=Mapping) def put(self, service, field, key, mapping): hashmap = api.get_instance() try: hashmap.update_mapping( service, field, key, value=mapping.value, map_type=mapping.map_type ) pecan.response.headers['Location'] = pecan.request.path pecan.response.status = 204 except (api.NoSuchService, api.NoSuchField, api.NoSuchMapping) as e: pecan.abort(400, str(e)) @wsme_pecan.wsexpose(None, wtypes.text, wtypes.text, wtypes.text) def delete(self, service, field=None, key=None): """"""Delete the parent and all the sub keys recursively. """""" hashmap = api.get_instance() try: if field: if key: hashmap.delete_mapping(service, field, key) else: hashmap.delete_field(service, field) else: hashmap.delete_service(service) except (api.NoSuchService, api.NoSuchField, api.NoSuchMapping) as e: pecan.abort(400, str(e)) pecan.response.status = 204 class BasicHashMapController(billing.BillingController): config = BasicHashMapConfigController() def get_module_info(self): module = BasicHashMap() infos = { 'name': 'hashmap', 'description': 'Basic hashmap billing module.', 'enabled': module.enabled, 'hot_config': True, } return infos class BasicHashMap(billing.BillingProcessorBase): controller = BasicHashMapController db_api = api.get_instance() def __init__(self): self._billing_info = {} self._load_billing_rates() @property def enabled(self): """"""Check if the module is enabled :returns: bool if module is enabled """""" # FIXME(sheeprine): Hardcoded values to check the state api = db_api.get_instance() module_db = api.get_module_enable_state() return module_db.get_state('hashmap') or False def reload_config(self): self._load_billing_rates() def _load_billing_rates(self): self._billing_info = {} hashmap = api.get_instance() services = hashmap.list_services() for service in services: service = service[0] self._billing_info[service] = {} fields = hashmap.list_fields(service) for field in fields: field = field[0] self._billing_info[service][field] = {} mappings = hashmap.list_mappings(service, field) for mapping in mappings: mapping = mapping[0] mapping_db = hashmap.get_mapping(service, field, mapping) map_dict = {} map_dict['value'] = mapping_db.value map_dict['type'] = mapping_db.map_type self._billing_info[service][field][mapping] = map_dict def process_service(self, name, data): if name not in self._billing_info: return serv_b_info = self._billing_info[name] for entry in data: flat = 0 rate = 1 entry_desc = entry['desc'] for field in serv_b_info: if field not in entry_desc: continue b_info = serv_b_info[field] key = entry_desc[field] value = 0 if key in b_info: value = b_info[key]['value'] elif '_DEFAULT_' in b_info: value = b_info['_DEFAULT_'] if value: if b_info[key]['type'] == 'rate': rate *= value elif b_info[key]['type'] == 'flat': new_flat = 0 new_flat = value if new_flat > flat: flat = new_flat entry['billing'] = {'price': flat * rate} def process(self, data): for cur_data in data: cur_usage = cur_data['usage'] for service in cur_usage: self.process_service(service, cur_usage[service]) return data ",,984,86
openstack%2Ftripleo-image-elements~master~I2b6aebf782b0825b4a980b22763e04dc79593efa,openstack/tripleo-image-elements,master,I2b6aebf782b0825b4a980b22763e04dc79593efa,Ensure Cinder uses the VIP when contacting Glance,MERGED,2014-08-01 02:19:23.000000000,2014-08-08 14:23:18.000000000,2014-08-08 14:23:18.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7582}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-08-01 02:19:23.000000000', 'files': ['elements/cinder/os-apply-config/etc/cinder/cinder.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a6214a237d73f837e696115ae085f919775f30c5', 'message': 'Ensure Cinder uses the VIP when contacting Glance\n\nUpdates cinder.conf so that it will set glance_host and glance_port\nwith data from heat template.\n\nChange-Id: I2b6aebf782b0825b4a980b22763e04dc79593efa\nCloses-Bug: 1351110\n'}]",2,111142,a6214a237d73f837e696115ae085f919775f30c5,16,6,1,6796,,,0,"Ensure Cinder uses the VIP when contacting Glance

Updates cinder.conf so that it will set glance_host and glance_port
with data from heat template.

Change-Id: I2b6aebf782b0825b4a980b22763e04dc79593efa
Closes-Bug: 1351110
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/42/111142/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/cinder/os-apply-config/etc/cinder/cinder.conf'],1,a6214a237d73f837e696115ae085f919775f30c5,bug/1351110,glance_host = {{glance.host}} glance_port = {{glance.port}} ,,3,0
openstack%2Fcloudkitty~master~I073d586120e5970f150a45db77ab85409c7087fc,openstack/cloudkitty,master,I073d586120e5970f150a45db77ab85409c7087fc,Added API service,MERGED,2014-08-08 13:40:14.000000000,2014-08-08 14:22:39.000000000,2014-08-08 14:22:39.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-08 13:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/0f2bed55da430f11d2de19163a2f7cc39047782e', 'message': 'Added API service\n\nChange-Id: I073d586120e5970f150a45db77ab85409c7087fc\n'}, {'number': 2, 'created': '2014-08-08 13:51:32.000000000', 'files': ['cloudkitty/cli/__init__.py', 'etc/cloudkitty/cloudkitty.conf.sample', 'cloudkitty/billing/hash.py', 'cloudkitty/api/controllers/root.py', 'cloudkitty/api/controllers/types.py', 'cloudkitty/cli/api.py', 'cloudkitty/api/app.py', 'cloudkitty/api/config.py', 'cloudkitty/billing/__init__.py', 'cloudkitty/api/__init__.py', 'cloudkitty/api/controllers/__init__.py', 'cloudkitty/billing/noop.py', 'setup.cfg', 'cloudkitty/api/controllers/v1.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/2efb97e9f0a0b057e06f5db14edfcb07b454451b', 'message': 'Added API service\n\nChange-Id: I073d586120e5970f150a45db77ab85409c7087fc\n'}]",0,112869,2efb97e9f0a0b057e06f5db14edfcb07b454451b,9,2,2,7042,,,0,"Added API service

Change-Id: I073d586120e5970f150a45db77ab85409c7087fc
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/69/112869/2 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/cli/__init__.py', 'etc/cloudkitty/cloudkitty.conf.sample', 'cloudkitty/cli/api.py', 'cloudkitty/api/app.py', 'cloudkitty/api/controllers/root.py', 'cloudkitty/api/config.py', 'cloudkitty/api/__init__.py', 'cloudkitty/api/controllers/__init__.py', 'cloudkitty/api/controllers/types.py', 'setup.cfg', 'cloudkitty/api/controllers/v1.py']",11,0f2bed55da430f11d2de19163a2f7cc39047782e,feature/api/adding_api_service,"# -*- coding: utf-8 -*- # Copyright 2014 Objectif Libre # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # @author: Stphane Albert # from oslo.config import cfg from pecan import rest from stevedore import extension from wsme import types as wtypes import wsmeext.pecan as wsme_pecan from cloudkitty.api.controllers import types as cktypes from cloudkitty import config # noqa from cloudkitty.openstack.common import log as logging CONF = cfg.CONF LOG = logging.getLogger(__name__) CLOUDKITTY_SERVICES = wtypes.Enum(wtypes.text, *CONF.collect.services) class ResourceDescriptor(wtypes.Base): service = CLOUDKITTY_SERVICES # FIXME(sheeprine): values should be dynamic # Testing with ironic dynamic type desc = {wtypes.text: cktypes.MultiType(wtypes.text, int, float, dict)} volume = int def to_json(self): res_dict = {} res_dict[self.service] = [{'desc': self.desc, 'vol': {'qty': self.volume, 'unit': 'undef'} }] return res_dict class ModulesController(rest.RestController): def __init__(self): self.extensions = extension.ExtensionManager( 'cloudkitty.billing.processors', # FIXME(sheeprine): don't want to load it here as we just need the # controller invoke_on_load=True ) self.expose_modules() def expose_modules(self): """"""Load billing modules to expose API controllers. """""" for ext in self.extensions: if not hasattr(self, ext.name): setattr(self, ext.name, ext.obj.controller()) @wsme_pecan.wsexpose([wtypes.text]) def get(self): return [ext for ext in self.extensions.names()] class BillingController(rest.RestController): _custom_actions = { 'quote': ['POST'], } modules = ModulesController() @wsme_pecan.wsexpose(float, body=[ResourceDescriptor]) def quote(self, res_data): # TODO(sheeprine): Send RPC request for quote from cloudkitty import extension_manager b_processors = {} processors = extension_manager.EnabledExtensionManager( 'cloudkitty.billing.processors', ) for processor in processors: b_name = processor.name b_obj = processor.obj b_processors[b_name] = b_obj res_dict = {} for res in res_data: if res.service not in res_dict: res_dict[res.service] = [] json_data = res.to_json() res_dict[res.service].extend(json_data[res.service]) for processor in b_processors.values(): processor.process([{'usage': res_dict}]) price = 0.0 for res in res_dict.values(): for data in res: price += data.get('billing', {}).get('price', 0.0) return price class ReportController(rest.RestController): _custom_actions = { 'total': ['GET'] } @wsme_pecan.wsexpose(float) def total(self): # TODO(sheeprine): Get current total from DB return 10.0 class V1Controller(rest.RestController): billing = BillingController() report = ReportController() ",,452,0
openstack%2Frally~master~I2708a5f915d5b13948f50dfad26b2463b9d5249b,openstack/rally,master,I2708a5f915d5b13948f50dfad26b2463b9d5249b,All scenario runs time measurement,MERGED,2014-07-08 01:27:11.000000000,2014-08-08 14:04:09.000000000,2014-08-08 14:04:09.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 6124}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 9180}, {'_account_id': 9601}]","[{'number': 1, 'created': '2014-07-08 01:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e34c9c44b1400f7c3a8ac49b43f272040c099c67', 'message': 'Whole scenario time measurement\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}, {'number': 2, 'created': '2014-07-08 02:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f67b3535efc5d34de8d5c721287dbd6c008f410a', 'message': 'Whole scenario time measurement\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}, {'number': 3, 'created': '2014-07-08 08:36:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/cade6193045acbb937d57bcf817d90b10c92cd22', 'message': 'Whole scenario time measurement\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}, {'number': 4, 'created': '2014-07-08 09:48:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f7878ea0b51a090da613041601b7dbc95ac69102', 'message': 'Whole scenario time measurement\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}, {'number': 5, 'created': '2014-07-08 10:49:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6310949cf2e34a9964706f4b2177f07e284fdbd3', 'message': 'Whole scenario time measurement\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}, {'number': 6, 'created': '2014-07-09 14:26:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6447b589b0f840555df782448bf2eb6212804693', 'message': 'Whole scenario time measurement\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}, {'number': 7, 'created': '2014-07-10 00:18:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d56b429c90692d08105909fc73895e0529728385', 'message': 'Whole scenario time measurement\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}, {'number': 8, 'created': '2014-07-10 01:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7f4a9806329be1b2f03eab8acc7f016f60789224', 'message': 'Whole scenario time measurement\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}, {'number': 9, 'created': '2014-07-17 00:11:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/70c7968ca9d2102732fff2e4d89a4e303e5cec04', 'message': 'Whole scenario time measurement\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}, {'number': 10, 'created': '2014-07-17 00:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7ff75baf501deb69d699cd3372ea19ef9dbeb123', 'message': 'Whole scenario time measurement\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}, {'number': 11, 'created': '2014-07-17 13:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/137ac6015c91e4c15c8b059ad56e8043ebbceedb', 'message': 'Whole scenario time measurement\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}, {'number': 12, 'created': '2014-07-22 23:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/30c8232625a757090aa950e4fb13f554a41bd168', 'message': 'Whole scenario time measurement\n\n  Implements: blueprint collect-runtime-duration\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}, {'number': 13, 'created': '2014-07-23 12:55:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/854622c262ac5fe97a33cc8edf14b48783e14976', 'message': 'Whole scenario time measurement\n\n  Implements: blueprint collect-runtime-duration\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}, {'number': 14, 'created': '2014-08-04 11:02:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/518fdbdd9d5198097edd7e8bb97821100eedc843', 'message': 'Whole scenario time measurement\n\n  Implements: blueprint collect-runtime-duration\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}, {'number': 15, 'created': '2014-08-06 16:55:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/56d768fbce0559c612542ec9c280f09920e2b146', 'message': 'Whole scenario time measurement\n\n  Implements: blueprint collect-runtime-duration\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}, {'number': 16, 'created': '2014-08-07 14:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e3096372c601e61e0a026d25122f916f92feaee8', 'message': 'All scenario runs time measurement\n\n  Partially implements: blueprint collect-runtime-duration\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}, {'number': 17, 'created': '2014-08-07 16:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5cc148195725dd20201d139f04155d43c2682de3', 'message': 'All scenario runs time measurement\n\n  Partially implements: blueprint collect-runtime-duration\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}, {'number': 18, 'created': '2014-08-08 09:26:50.000000000', 'files': ['tests/benchmark/runners/test_base.py', 'rally/benchmark/runners/base.py', 'tests/orchestrator/test_api.py', 'tests/cmd/commands/test_task.py', 'rally/cmd/commands/task.py', 'rally/benchmark/engine.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/7a3ed2104973eb44b32073d0ee4744b56e56966f', 'message': 'All scenario runs time measurement\n\n  Partially implements: blueprint collect-runtime-duration\n\nChange-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b\n'}]",17,105318,7a3ed2104973eb44b32073d0ee4744b56e56966f,75,7,18,9601,,,0,"All scenario runs time measurement

  Partially implements: blueprint collect-runtime-duration

Change-Id: I2708a5f915d5b13948f50dfad26b2463b9d5249b
",git fetch https://review.opendev.org/openstack/rally refs/changes/18/105318/7 && git format-patch -1 --stdout FETCH_HEAD,"['tests/benchmark/runners/test_base.py', 'rally/benchmark/runners/base.py', 'rally/cmd/commands/task.py']",3,e34c9c44b1400f7c3a8ac49b43f272040c099c67,bp/collect-runtime-duration," scenario_time, raw = result[""data""][""raw""] print(""Whole scenario time without context preparation: "", scenario_time) "," raw = result[""data""][""raw""]",16,6
openstack%2Ffuel-main~stable%2F5.0~I743ef9bcf5c1f874bb9e6fbe73a059e3b0ca6240,openstack/fuel-main,stable/5.0,I743ef9bcf5c1f874bb9e6fbe73a059e3b0ca6240,Add check_run method to deploy_ha case,ABANDONED,2014-08-08 11:45:03.000000000,2014-08-08 14:01:31.000000000,,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-08-08 11:45:03.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_failover.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/931189f3b77308175bccddb492f0f18591fd9670', 'message': 'Add check_run method to deploy_ha case\n\nAdd check_run method to deploy_ha case\nto save time on run in case if\ndeploy_ha snapshot already exists.\n\nChange-Id: I743ef9bcf5c1f874bb9e6fbe73a059e3b0ca6240\nCloses-Bug: #1353843\n(cherry picked from commit c20e0bbd98d040798f14bbc6c0cefc3464e2faad)\n'}]",0,112832,931189f3b77308175bccddb492f0f18591fd9670,5,3,1,12129,,,0,"Add check_run method to deploy_ha case

Add check_run method to deploy_ha case
to save time on run in case if
deploy_ha snapshot already exists.

Change-Id: I743ef9bcf5c1f874bb9e6fbe73a059e3b0ca6240
Closes-Bug: #1353843
(cherry picked from commit c20e0bbd98d040798f14bbc6c0cefc3464e2faad)
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/32/112832/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/tests_strength/test_failover.py'],1,931189f3b77308175bccddb492f0f18591fd9670,,"from proboscis import SkipTest try: self.check_run(""deploy_ha"") except SkipTest: self.env.revert_snapshot(""deploy_ha"") return ",,7,0
openstack%2Ftripleo-image-elements~master~I1d552f90d1561de220c779221b890b185e1c85db,openstack/tripleo-image-elements,master,I1d552f90d1561de220c779221b890b185e1c85db,Debug all the things,ABANDONED,2014-06-16 22:37:43.000000000,2014-08-08 14:00:56.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-06-16 22:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9b8436ae22fc4f71ac871a1a2a0cc645858ca3a3', 'message': ""Debug all the things\n\nI don't see anywhere that the debug parameters are exposed in the\nheat templates, so I'm just overriding them directly for now because\nwe need more information for the linked bug.\n\nChange-Id: I1d552f90d1561de220c779221b890b185e1c85db\nRelated-Bug: 1330735\n""}, {'number': 2, 'created': '2014-06-17 16:41:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/b898b75f5b51797fed9ac4fdada3e6a4c8b57f60', 'message': ""Debug all the things\n\nI don't see anywhere that the debug parameters are exposed in the\nheat templates, so I'm just overriding them directly for now because\nwe need more information for the linked bug.\n\nChange-Id: I1d552f90d1561de220c779221b890b185e1c85db\nRelated-Bug: 1292105\n""}, {'number': 3, 'created': '2014-08-07 16:54:25.000000000', 'files': ['elements/keystone/os-apply-config/etc/keystone/keystone.conf', 'elements/cinder/os-apply-config/etc/cinder/cinder.conf', 'elements/neutron/os-apply-config/etc/neutron/neutron.conf', 'elements/heat/os-apply-config/etc/heat/heat.conf', 'elements/nova/os-apply-config/etc/nova/nova.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/435a35569a6f5241675b0eb1c3bfcbce770a1dbd', 'message': ""Debug all the things\n\nCI is in a bad way again, let's get as much info as we can.\n\nChange-Id: I1d552f90d1561de220c779221b890b185e1c85db\nRelated-Bug: 1353953\n""}]",0,100374,435a35569a6f5241675b0eb1c3bfcbce770a1dbd,29,3,3,6928,,,0,"Debug all the things

CI is in a bad way again, let's get as much info as we can.

Change-Id: I1d552f90d1561de220c779221b890b185e1c85db
Related-Bug: 1353953
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/74/100374/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/keystone/os-apply-config/etc/keystone/keystone.conf', 'elements/cinder/os-apply-config/etc/cinder/cinder.conf', 'elements/neutron/os-apply-config/etc/neutron/neutron.conf', 'elements/nova/os-apply-config/etc/nova/nova.conf', 'elements/heat/os-config-applier/etc/heat/heat.conf']",5,9b8436ae22fc4f71ac871a1a2a0cc645858ca3a3,bug/1353953,debug=True,{{#heat.debug}}debug={{heat.debug}} {{/heat.debug}},5,15
openstack%2Ffuel-web~master~I9345a5e9adadead2c149e85fab139ae4e5615cf1,openstack/fuel-web,master,I9345a5e9adadead2c149e85fab139ae4e5615cf1,Store replaced info on node instead of cluster,MERGED,2014-08-06 15:51:43.000000000,2014-08-08 13:58:30.000000000,2014-08-08 13:58:30.000000000,"[{'_account_id': 3}, {'_account_id': 8053}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 10391}, {'_account_id': 10959}]","[{'number': 1, 'created': '2014-08-06 15:51:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e9e83a4e92483c3ef98b57db39d6d3ceb90ae2b6', 'message': 'Store replaced info on node instead of cluster\n\n- deleted replaced_deployment_info/replaced_provisioning_info\n  columns from cluster\n- delete is_customized column from cluster (seems it does not serve\n  any purpose)\n- add necessery columns to node model\n- add replace/get provisioning/deployment info on objects.Cluster\n\nChange-Id: I9345a5e9adadead2c149e85fab139ae4e5615cf1\nCloses-Bug: #1280318\n'}, {'number': 2, 'created': '2014-08-06 16:04:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2398534f2f5cceb694cc3b1fc8bd88bd6a5657a7', 'message': 'Store replaced info on node instead of cluster\n\n- deleted replaced_deployment_info/replaced_provisioning_info\n  columns from cluster\n- add necessery columns to node model\n- add replace/get provisioning/deployment info on objects.Cluster\n\nChange-Id: I9345a5e9adadead2c149e85fab139ae4e5615cf1\nCloses-Bug: #1280318\n'}, {'number': 3, 'created': '2014-08-06 16:54:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3bcce9548b0837f3d18649d2c8747d2eafc7ea7f', 'message': 'Store replaced info on node instead of cluster\n\n- deleted replaced_deployment_info/replaced_provisioning_info\n  columns from cluster\n- add necessery columns to node model\n- add replace/get provisioning/deployment info on objects.Cluster\n\nChange-Id: I9345a5e9adadead2c149e85fab139ae4e5615cf1\nCloses-Bug: #1280318\n'}, {'number': 4, 'created': '2014-08-06 18:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7f2d78b3e0e528efb36c16b556b2b717688fc1ad', 'message': 'Store replaced info on node instead of cluster\n\n- deleted replaced_deployment_info/replaced_provisioning_info\n  columns from cluster\n- add necessery columns to node model\n- add replace/get provisioning/deployment info on objects.Cluster\n\nChange-Id: I9345a5e9adadead2c149e85fab139ae4e5615cf1\nCloses-Bug: #1280318\n'}, {'number': 5, 'created': '2014-08-07 10:06:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1129509b08a56b5ce20f573180557a78aaeacdfe', 'message': 'Store replaced info on node instead of cluster\n\n- add necessery columns to node model\n- add replace/get provisioning/deployment info on objects.Cluster\n- api interaction with cli is not changed\n\nDeploymentInfo treated everywhere as list, because it will consist of\n- multiple yaml files per node, on role basis\n\nProvisioningInfo treated as dict\n- one yaml for cluster section (engine)\n- yaml per node with provisioning params of this node\n\nIt is possible to manage cluster from UI and cli\n\nChange-Id: I9345a5e9adadead2c149e85fab139ae4e5615cf1\nCloses-Bug: #1280318\n'}, {'number': 6, 'created': '2014-08-07 12:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d5b501641674886cc074da7e10d102e4d779cddb', 'message': 'Store replaced info on node instead of cluster\n\n- add necessery columns to node model\n- add replace/get provisioning/deployment info on objects.Cluster\n- api interaction with cli is not changed\n- added migration from old data model to new\n\nDeploymentInfo treated everywhere as list, because it will consist of\n- multiple yaml files per node, on role basis\n\nProvisioningInfo treated as dict\n- one yaml for cluster section (engine)\n- yaml per node with provisioning params of this node\n\nIt is possible to manage cluster from UI and cli\n\nChange-Id: I9345a5e9adadead2c149e85fab139ae4e5615cf1\nCloses-Bug: #1280318\n'}, {'number': 7, 'created': '2014-08-07 13:21:55.000000000', 'files': ['nailgun/nailgun/orchestrator/deployment_serializers.py', 'nailgun/nailgun/test/integration/test_cluster_handler.py', 'nailgun/nailgun/objects/node.py', 'nailgun/nailgun/db/migration/alembic_migrations/versions/fuel_5_1.py', 'nailgun/nailgun/rpc/receiver.py', 'nailgun/nailgun/test/integration/test_orchestrator_handlers.py', 'nailgun/nailgun/db/sqlalchemy/models/cluster.py', 'nailgun/nailgun/task/manager.py', 'nailgun/nailgun/task/task.py', 'nailgun/nailgun/test/unit/test_migration_cluster_replaced_info.py', 'nailgun/nailgun/objects/cluster.py', 'nailgun/nailgun/utils/migration.py', 'nailgun/nailgun/orchestrator/provisioning_serializers.py', 'nailgun/nailgun/db/sqlalchemy/models/node.py', 'nailgun/nailgun/api/v1/handlers/orchestrator.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4cd225ca9d0eb0b1dd398b07ad8202169f9c3ea4', 'message': 'Store replaced info on node instead of cluster\n\n- add necessery columns to node model\n- add replace/get provisioning/deployment info on objects.Cluster\n- api interaction with cli is not changed\n- added migration from old data model to new\n\nDeploymentInfo treated everywhere as list, because it will consist of\n- multiple yaml files per node, on role basis\n\nProvisioningInfo treated as dict\n- one yaml for cluster section (engine)\n- yaml per node with provisioning params of this node\n\nIt is possible to manage cluster from UI and cli\n\nChange-Id: I9345a5e9adadead2c149e85fab139ae4e5615cf1\nCloses-Bug: #1280318\n'}]",10,112333,4cd225ca9d0eb0b1dd398b07ad8202169f9c3ea4,66,10,7,8907,,,0,"Store replaced info on node instead of cluster

- add necessery columns to node model
- add replace/get provisioning/deployment info on objects.Cluster
- api interaction with cli is not changed
- added migration from old data model to new

DeploymentInfo treated everywhere as list, because it will consist of
- multiple yaml files per node, on role basis

ProvisioningInfo treated as dict
- one yaml for cluster section (engine)
- yaml per node with provisioning params of this node

It is possible to manage cluster from UI and cli

Change-Id: I9345a5e9adadead2c149e85fab139ae4e5615cf1
Closes-Bug: #1280318
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/33/112333/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/task/task.py', 'nailgun/nailgun/db/migration/alembic_migrations/versions/fuel_5_1.py', 'nailgun/nailgun/rpc/receiver.py', 'nailgun/nailgun/objects/cluster.py', 'nailgun/nailgun/db/sqlalchemy/models/node.py', 'nailgun/nailgun/api/v1/handlers/orchestrator.py', 'nailgun/nailgun/db/sqlalchemy/models/cluster.py', 'nailgun/nailgun/task/manager.py']",8,e9e83a4e92483c3ef98b57db39d6d3ceb90ae2b6,store_replaced_data_on_node, if (not objects.Cluster.get_provisioning_info(self.cluster) and not objects.Cluster.get_deployment_info(self.cluster)):, if not self.cluster.replaced_provisioning_info and \ not self.cluster.replaced_deployment_info:,65,33
openstack%2Fironic~master~Ia564f7d7653c1abcb732b8261ee9ec99323d0f43,openstack/ironic,master,Ia564f7d7653c1abcb732b8261ee9ec99323d0f43,Add posix_ipc to requirements,MERGED,2014-08-08 01:59:04.000000000,2014-08-08 13:57:53.000000000,2014-08-08 13:57:53.000000000,"[{'_account_id': 3}, {'_account_id': 951}, {'_account_id': 1726}, {'_account_id': 1994}, {'_account_id': 6773}, {'_account_id': 7711}]","[{'number': 1, 'created': '2014-08-08 01:59:04.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/0c873313e58c38272e560251847275b2979e2298', 'message': 'Add posix_ipc to requirements\n\nChange-Id: Ia564f7d7653c1abcb732b8261ee9ec99323d0f43\nCloses-Bug: 1354078\n'}]",0,112746,0c873313e58c38272e560251847275b2979e2298,12,6,1,12459,,,0,"Add posix_ipc to requirements

Change-Id: Ia564f7d7653c1abcb732b8261ee9ec99323d0f43
Closes-Bug: 1354078
",git fetch https://review.opendev.org/openstack/ironic refs/changes/46/112746/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,0c873313e58c38272e560251847275b2979e2298,bug/1354078,posix_ipc,,1,0
openstack%2Fironic~master~I8dc7640a19374a9c4d687877ea6c0ff1ebc13979,openstack/ironic,master,I8dc7640a19374a9c4d687877ea6c0ff1ebc13979,Add iPXE support for Ironic,MERGED,2014-06-11 09:56:23.000000000,2014-08-08 13:57:38.000000000,2014-08-08 13:57:38.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7882}, {'_account_id': 8125}, {'_account_id': 9315}, {'_account_id': 9407}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 11702}]","[{'number': 1, 'created': '2014-06-11 09:56:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/00283a434ba48121ba87d429d809ed13ea66465d', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nThree new configuration options added in the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- http_server: The IP address of the HTTP server\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\n  what this function is about, it fetchs the kernels and ramdisks associated\n  with the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}, {'number': 2, 'created': '2014-06-11 11:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a130831231910875b7153eed8ae32cb47e1e3f0f', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nThree new configuration options added in the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- http_server: The IP address of the HTTP server\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\n  what this function is about, it fetchs the kernels and ramdisks associated\n  with the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}, {'number': 3, 'created': '2014-06-12 15:00:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e09aa551513d8a907b2401f4eb29e89432bfa580', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nThree new configuration options added in the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- http_server: The IP address of the HTTP server\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\n  what this function is about, it fetchs the kernels and ramdisks associated\n  with the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}, {'number': 4, 'created': '2014-06-17 10:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/233c0db7f99760bc3c994b4085a4b04a90bd18bd', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nThree new configuration options added in the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- http_server: The IP address of the HTTP server\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\n  what this function is about, it fetchs the kernels and ramdisks associated\n  with the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}, {'number': 5, 'created': '2014-07-02 12:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b1cd81d6fe9e8e33c82a822d60e08dcd784a1823', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nNew configuration options added to the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- ipxe_boot_script: The path to the main iPXE script file\n- http_server: The IP address of the HTTP server\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\nwhat this function is about, it fetchs the kernels and ramdisks associated\nwith the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}, {'number': 6, 'created': '2014-07-03 15:01:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e99f31fb121fc9d38d5fb22ef851417ed6757775', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nNew configuration options added to the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- ipxe_boot_script: The path to the main iPXE script file\n- http_server: The IP address of the HTTP server\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\nwhat this function is about, it fetchs the kernels and ramdisks associated\nwith the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}, {'number': 7, 'created': '2014-07-04 09:31:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1d9d053a21fbd0f147bf21b6fcb95a723facb50e', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nNew configuration options added to the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- ipxe_boot_script: The path to the main iPXE script file\n- http_server: The IP address of the HTTP server\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\nwhat this function is about, it fetchs the kernels and ramdisks associated\nwith the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}, {'number': 8, 'created': '2014-07-04 10:02:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5047a5753750f57b4e7839432bf9a277ace3c1b4', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nNew configuration options added to the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- ipxe_boot_script: The path to the main iPXE script file\n- http_server: The IP address of the HTTP server\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\nwhat this function is about, it fetchs the kernels and ramdisks associated\nwith the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}, {'number': 9, 'created': '2014-07-14 16:23:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/78e206855c428c6a60e7608511b7d597d1ce94dc', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nNew configuration options added to the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- ipxe_boot_script: The path to the main iPXE script file\n- http_server: The IP address of the HTTP server\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\nwhat this function is about, it fetchs the kernels and ramdisks associated\nwith the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}, {'number': 10, 'created': '2014-07-16 10:00:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ba3e65f0f9f46cf0e271c6c62d84ab78daead3c9', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nNew configuration options added to the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- ipxe_boot_script: The path to the main iPXE script file\n- http_server: The IP address of the HTTP server\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\nwhat this function is about, it fetchs the kernels and ramdisks associated\nwith the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}, {'number': 11, 'created': '2014-07-21 16:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7c3486f40b2ec1bc808241bc86f8719cae3d33dc', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nNew configuration options added to the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- ipxe_boot_script: The path to the main iPXE script file\n- http_server: The IP address of the HTTP server\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\nwhat this function is about, it fetchs the kernels and ramdisks associated\nwith the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}, {'number': 12, 'created': '2014-07-22 09:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c4e377e85f9f044e8200c5817d389f79d6e1ff6f', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nNew configuration options added to the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- ipxe_boot_script: The path to the main iPXE script file\n- http_server: The IP address of the HTTP server\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\nwhat this function is about, it fetchs the kernels and ramdisks associated\nwith the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}, {'number': 13, 'created': '2014-07-29 22:36:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bb9c745cd4e824c3b0d16eff5d37c9cff3fc8018', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nNew configuration options added to the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- ipxe_boot_script: The path to the main iPXE script file\n- http_server: The IP address of the HTTP server\n- http_port: The Port of the HTTP server\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\nwhat this function is about, it fetchs the kernels and ramdisks associated\nwith the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}, {'number': 14, 'created': '2014-07-30 16:37:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/835b03515a3740e31cca63d00e56c1304e827ff2', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nNew configuration options added to the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- ipxe_boot_script: The path to the main iPXE script file\n- http_server: The IP address of the HTTP server\n- http_port: The Port of the HTTP server\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\nwhat this function is about, it fetchs the kernels and ramdisks associated\nwith the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}, {'number': 15, 'created': '2014-08-05 11:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1c5a731e5f8bc2cec79d4b05cc00af2d864ee5c8', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nNew configuration options added to the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- ipxe_boot_script: The path to the main iPXE script file\n- http_server: The IP address of the HTTP server\n- http_port: The Port of the HTTP server\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\nwhat this function is about, it fetchs the kernels and ramdisks associated\nwith the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}, {'number': 16, 'created': '2014-08-05 11:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/74760358ae0e5200995ab4b22263ead18fe960d4', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nNew configuration options added to the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- ipxe_boot_script: The path to the main iPXE script file\n- http_url: The HTTP server URL\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\nwhat this function is about, it fetchs the kernels and ramdisks associated\nwith the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}, {'number': 17, 'created': '2014-08-06 15:28:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4872f020fd97e150fd46ea13262dfba13de8e18d', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nNew configuration options added to the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- ipxe_boot_script: The path to the main iPXE script file\n- http_url: The HTTP server URL\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\nwhat this function is about, it fetchs the kernels and ramdisks associated\nwith the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}, {'number': 18, 'created': '2014-08-08 09:07:25.000000000', 'files': ['etc/ironic/ironic.conf.sample', 'ironic/drivers/modules/deploy_utils.py', 'ironic/drivers/modules/pxe.py', 'ironic/common/pxe_utils.py', 'ironic/tests/drivers/test_pxe.py', 'ironic/tests/test_pxe_utils.py', 'ironic/tests/drivers/test_deploy_utils.py', 'ironic/drivers/modules/boot.ipxe', 'ironic/drivers/modules/ipxe_config.template'], 'web_link': 'https://opendev.org/openstack/ironic/commit/d8a0cf58156ac63283bf96a4bda5001376c4bc91', 'message': ""Add iPXE support for Ironic\n\nAs the size of our deploy ramdisk would continue to increase (Ironic\nPython Agent) we need a more reliable way to transfer such data via\nthe network without relying on TFTP. The problem with TFTP is that it's\nunreliable and any transmission error will result consequently in boot\nproblems. This patch adds support for iPXE so that we have the ability\nto transfer data through HTTP which is a reliable protocol.\n\nNew configuration options added to the 'pxe' group:\n\n- ipxe_enabled: Whether iPXE is enabled or not\n- ipxe_boot_script: The path to the main iPXE script file\n- http_url: The HTTP server URL\n- http_root: The HTTP root path\n\nTwo functions from pxe.py were renamed because they are not related only\nto tftp anymore:\n\n- _get_tftp_image_info renamed to _get_image_info\n\n- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's\nwhat this function is about, it fetchs the kernels and ramdisks associated\nwith the image, not the image itself)\n\nImplements: blueprint ipxe-boot\nChange-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979\n""}]",22,99318,d8a0cf58156ac63283bf96a4bda5001376c4bc91,118,13,18,6773,,,0,"Add iPXE support for Ironic

As the size of our deploy ramdisk would continue to increase (Ironic
Python Agent) we need a more reliable way to transfer such data via
the network without relying on TFTP. The problem with TFTP is that it's
unreliable and any transmission error will result consequently in boot
problems. This patch adds support for iPXE so that we have the ability
to transfer data through HTTP which is a reliable protocol.

New configuration options added to the 'pxe' group:

- ipxe_enabled: Whether iPXE is enabled or not
- ipxe_boot_script: The path to the main iPXE script file
- http_url: The HTTP server URL
- http_root: The HTTP root path

Two functions from pxe.py were renamed because they are not related only
to tftp anymore:

- _get_tftp_image_info renamed to _get_image_info

- _cache_tftp_images renamed to _cache_ramdisk_kernel (because that's
what this function is about, it fetchs the kernels and ramdisks associated
with the image, not the image itself)

Implements: blueprint ipxe-boot
Change-Id: I8dc7640a19374a9c4d687877ea6c0ff1ebc13979
",git fetch https://review.opendev.org/openstack/ironic refs/changes/18/99318/18 && git format-patch -1 --stdout FETCH_HEAD,"['etc/ironic/ironic.conf.sample', 'ironic/drivers/modules/pxe.py', 'ironic/tests/drivers/test_pxe.py']",3,00283a434ba48121ba87d429d809ed13ea66465d,bp/ipxe-boot," def test__get_image_info(self, show_mock): image_info = pxe._get_image_info(self.node, self.context) image_info = pxe._get_image_info(self.node, self.context) pxe._cache_ramdisk_kernel(None, self.node, image_info) @mock.patch.object(pxe, 'TFTPImageCache', lambda: None) @mock.patch.object(fileutils, 'ensure_tree') @mock.patch.object(pxe, '_fetch_images') def test__cache_ramdisk_kernel(self, mock_fetch_image, mock_ensure_tree): self.config(ipxe_enabled=False, group='pxe') fake_pxe_info = {'foo': 'bar'} expected_path = os.path.join(CONF.tftp.tftp_root, self.node.uuid) pxe._cache_ramdisk_kernel(self.context, self.node, fake_pxe_info) mock_ensure_tree.assert_called_with(expected_path) mock_fetch_image.assert_called_once_with(self.context, mock.ANY, fake_pxe_info.values()) @mock.patch.object(pxe, 'TFTPImageCache', lambda: None) @mock.patch.object(fileutils, 'ensure_tree') @mock.patch.object(pxe, '_fetch_images') def test__cache_ramdisk_kernel_ipxe(self, mock_fetch_image, mock_ensure_tree): self.config(ipxe_enabled=True, group='pxe') fake_pxe_info = {'foo': 'bar'} expected_path = os.path.join(CONF.pxe.http_root, self.node.uuid) pxe._cache_ramdisk_kernel(self.context, self.node, fake_pxe_info) mock_ensure_tree.assert_called_with(expected_path) mock_fetch_image.assert_called_once_with(self.context, mock.ANY, fake_pxe_info.values()) @mock.patch.object(base_image_service.BaseImageService, '_show') def test_validate_ipxe_good(self, mock_glance): mock_glance.return_value = {'properties': {'kernel_id': 'fake-kernel', 'ramdisk_id': 'fake-initr'}} self.config(ipxe_enabled=True, group='pxe') self.config(http_server='localhost', group='pxe') self.config(http_root='/test/www', group='pxe') with task_manager.acquire(self.context, self.node.uuid, shared=True) as task: task.driver.deploy.validate(task, self.node) @mock.patch.object(base_image_service.BaseImageService, '_show') def test_validate_ipxe_fail(self, mock_glance): mock_glance.return_value = {'properties': {'kernel_id': 'fake-kernel', 'ramdisk_id': 'fake-initr'}} self.config(ipxe_enabled=True, group='pxe') # empty http_root, http_server self.config(http_server='', group='pxe') self.config(http_root='', group='pxe') with task_manager.acquire(self.context, self.node.uuid, shared=True) as task: self.assertRaises(exception.InvalidParameterValue, task.driver.deploy.validate, task, self.node) @mock.patch.object(pxe, '_get_image_info') @mock.patch.object(pxe, '_cache_ramdisk_kernel') mock_build_pxe, mock_cache_r_k, mock_img_info): mock_img_info.return_value = None mock_cache_r_k.return_value = None mock_img_info.assert_called_once_with(task.node, self.context) mock_cache_r_k.assert_called_once_with(self.context, task.node, None) @mock.patch.object(pxe, '_get_image_info') def clean_up_config(self, get_image_info_mock, master=None): get_image_info_mock.return_value = image_info get_image_info_mock.called_once_with(task.node)"," def test__get_tftp_image_info(self, show_mock): image_info = pxe._get_tftp_image_info(self.node, self.context) image_info = pxe._get_tftp_image_info(self.node, self.context) pxe._cache_tftp_images(None, self.node, image_info) @mock.patch.object(pxe, '_get_tftp_image_info') @mock.patch.object(pxe, '_cache_tftp_images') mock_build_pxe, mock_cache_tftp_images, mock_tftp_img_info): mock_tftp_img_info.return_value = None mock_cache_tftp_images.return_value = None mock_tftp_img_info.assert_called_once_with(task.node, self.context) mock_cache_tftp_images.assert_called_once_with(self.context, task.node, None) @mock.patch.object(pxe, '_get_tftp_image_info') def clean_up_config(self, get_tftp_image_info_mock, master=None): get_tftp_image_info_mock.return_value = image_info get_tftp_image_info_mock.called_once_with(task.node)",135,33
openstack%2Fopenstack-manuals~master~Ib4aab29234654946afe42dfe31a96fe3f4a55cdc,openstack/openstack-manuals,master,Ib4aab29234654946afe42dfe31a96fe3f4a55cdc,Creation of book structure for Networking Guide,MERGED,2014-08-08 12:23:59.000000000,2014-08-08 13:47:18.000000000,2014-08-08 13:47:17.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-08-08 12:23:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/de302df76949946cc6df8f5f6a6e47e496cdff12', 'message': 'Creation of book structure for Networking Guide\n\nChange-Id: Ib4aab29234654946afe42dfe31a96fe3f4a55cdc\n'}, {'number': 2, 'created': '2014-08-08 12:37:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6a73463ab77088a431e534c6ccf473068b6b8404', 'message': 'Creation of book structure for Networking Guide\n\nChange-Id: Ib4aab29234654946afe42dfe31a96fe3f4a55cdc\n'}, {'number': 3, 'created': '2014-08-08 12:46:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a42da0750e4291ce9df94de0fad594ac1e2e723e', 'message': 'Creation of book structure for Networking Guide\n\nChange-Id: Ib4aab29234654946afe42dfe31a96fe3f4a55cdc\n'}, {'number': 4, 'created': '2014-08-08 12:49:13.000000000', 'files': ['doc/networking-guide/ch_advanced.xml', 'doc/networking-guide/ch_plugins.xml', 'doc/networking-guide/roadmap.rst', 'doc/networking-guide/ch_debugging.xml', 'doc/networking-guide/ch_scalability-HA.xml', 'doc/networking-guide/bk-networking.xml', 'doc/networking-guide/ch_intro.xml', 'doc/local-files.html', 'doc/pom.xml', 'doc/networking-guide/ch_deployment.xml', 'doc/networking-guide/pom.xml', 'doc/networking-guide/ch_networking-data-model.xml', 'doc/networking-guide/ch_networking-architecture.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/347724780ac0c8fbf7e8437620b576c8038e676e', 'message': 'Creation of book structure for Networking Guide\n\nChange-Id: Ib4aab29234654946afe42dfe31a96fe3f4a55cdc\n'}]",4,112843,347724780ac0c8fbf7e8437620b576c8038e676e,18,3,4,9162,,,0,"Creation of book structure for Networking Guide

Change-Id: Ib4aab29234654946afe42dfe31a96fe3f4a55cdc
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/43/112843/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/networking-guide/ch_advanced.xml', 'doc/networking-guide/bk-networking.xml', 'doc/networking-guide/ch_plugins.xml', 'doc/networking-guide/ch_intro.xml', 'doc/networking-guide/roadmap.rst', 'doc/networking-guide/ch_debugging.xml', 'doc/networking-guide/ch_scalability-HA.xml', 'doc/networking-guide/ch_deployment.xml', 'doc/networking-guide/pom.xml', 'doc/networking-guide/ch_networking-data-model.xml', 'doc/networking-guide/ch_networking-architecture.xml']",11,de302df76949946cc6df8f5f6a6e47e496cdff12,createnetworkguide/loquacity,"<?xml version=""1.0"" encoding=""UTF-8""?> <chapter xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0"" xml:id=""ch_networking-architecture""> <title>Networking architecture</title> <para> Bacon ipsum dolor sit amet biltong meatloaf andouille, turducken bresaola pork belly beef ribs ham hock capicola tail prosciutto landjaeger meatball pork loin. Swine turkey jowl, porchetta doner boudin meatloaf. Shoulder capicola prosciutto, shank landjaeger short ribs sirloin turducken pork belly boudin frankfurter chuck. Salami shankle bresaola cow filet mignon ham hock shank. </para> </chapter> ",,305,0
openstack%2Fnova~master~Ic8fe13174fda5c75ce95fc0b64391ae081b36c6d,openstack/nova,master,Ic8fe13174fda5c75ce95fc0b64391ae081b36c6d,Add debug log for pci passthrough filter,MERGED,2014-07-03 10:12:33.000000000,2014-08-08 13:39:05.000000000,2014-07-31 11:03:42.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 7166}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-03 10:12:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d5281897ee34f7995ec55d812a1e29991d900ab4', 'message': ""Add debug log for pci passthrough filter\n\nSometimes operator need information why the host doesn't pass\nthe check of scheduler, this patch adds information for pci\npassthrough filter if it falied to pass check.\n\nChange-Id: Ic8fe13174fda5c75ce95fc0b64391ae081b36c6d\nPartial-Bug: #1301830\n""}, {'number': 2, 'created': '2014-07-07 02:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/12e25d305ab65c958148f43c3f0f2ccf9a93ebbe', 'message': ""Add debug log for pci passthrough filter\n\nSometimes operator need information why the host doesn't pass\nthe check of scheduler, this patch adds information for pci\npassthrough filter if it falied to pass check.\n\nChange-Id: Ic8fe13174fda5c75ce95fc0b64391ae081b36c6d\nPartial-Bug: #1301830\n""}, {'number': 3, 'created': '2014-07-25 05:26:13.000000000', 'files': ['nova/scheduler/filters/pci_passthrough_filter.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f71d2fc966cb44b8d74b4432179622d6c9e1f284', 'message': ""Add debug log for pci passthrough filter\n\nSometimes operator need information why the host doesn't pass\nthe check of scheduler, this patch adds information for pci\npassthrough filter if it falied to pass check.\n\nChange-Id: Ic8fe13174fda5c75ce95fc0b64391ae081b36c6d\nPartial-Bug: #1301830\n""}]",5,104504,f71d2fc966cb44b8d74b4432179622d6c9e1f284,80,14,3,6062,,,0,"Add debug log for pci passthrough filter

Sometimes operator need information why the host doesn't pass
the check of scheduler, this patch adds information for pci
passthrough filter if it falied to pass check.

Change-Id: Ic8fe13174fda5c75ce95fc0b64391ae081b36c6d
Partial-Bug: #1301830
",git fetch https://review.opendev.org/openstack/nova refs/changes/04/104504/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/filters/pci_passthrough_filter.py'],1,d5281897ee34f7995ec55d812a1e29991d900ab4,bug/1301830-3,"from nova.openstack.common import log as loggingLOG = logging.getLogger(__name__) if host_state.pci_stats.support_requests( filter_properties.get('pci_requests')): LOG.debug(""%(host_state)s requires pci request support "" ""can not be satisfied"", {'host_state': host_state}) return False return True", return host_state.pci_stats.support_requests( filter_properties.get('pci_requests')),10,2
openstack%2Fec2-api~master~Ifd8ad2e15d2c066c74c98bd62a99e27269638d78,openstack/ec2-api,master,Ifd8ad2e15d2c066c74c98bd62a99e27269638d78,Adding addresses,MERGED,2014-08-08 13:12:14.000000000,2014-08-08 13:26:11.000000000,2014-08-08 13:26:11.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-08-08 13:12:14.000000000', 'files': ['ec2api/api/cloud.py', 'ec2api/tests/test_address.py', 'ec2api/api/address.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/f0a2dd7613bea2c4590b06f6778aea5f01132a47', 'message': 'Adding addresses\n\nChange-Id: Ifd8ad2e15d2c066c74c98bd62a99e27269638d78\n'}]",0,112855,f0a2dd7613bea2c4590b06f6778aea5f01132a47,7,4,1,9312,,,0,"Adding addresses

Change-Id: Ifd8ad2e15d2c066c74c98bd62a99e27269638d78
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/55/112855/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/cloud.py', 'ec2api/tests/test_address.py', 'ec2api/api/address.py']",3,f0a2dd7613bea2c4590b06f6778aea5f01132a47,,"# Copyright 2014 Cloudscaling Group, Inc # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from neutronclient.common import exceptions as neutron_exception from oslo.config import cfg from ec2api.api import clients from ec2api.api import ec2client from ec2api.api import ec2utils from ec2api.api import utils from ec2api.db import api as db_api from ec2api import exception from ec2api.openstack.common.gettextutils import _ CONF = cfg.CONF CONF.import_opt('external_network', 'ec2api.api.internet_gateway') # TODO(ft): generate unique association id def allocate_address(context, domain=None): if domain and domain != 'vpc': msg = _(""Invalid value '%(domain)s' for domain."") % {'domain': domain} raise exception.InvalidParameterValue(msg) if not domain: ec2 = ec2client.ec2client(context) ec2_address = ec2.allocate_address() return _format_address(context, ec2_address) neutron = clients.neutron(context) # TODO(ft): check no public network exists search_opts = {'router:external': True, 'name': CONF.external_network} os_networks = neutron.list_networks(**search_opts)['networks'] os_public_network = os_networks[0] with utils.OnCrashCleaner() as cleaner: os_floating_ip = {'floating_network_id': os_public_network['id']} # TODO(ft): handle error to process floating ip overlimit os_floating_ip = neutron.create_floatingip( {'floatingip': os_floating_ip}) os_floating_ip = os_floating_ip['floatingip'] cleaner.addCleanup(neutron.delete_floatingip, os_floating_ip['id']) address = {'os_id': os_floating_ip['id'], 'public_ip': os_floating_ip['floating_ip_address']} address = db_api.add_item(context, 'eipalloc', address) return _format_address(context, address=address) def associate_address(context, public_ip=None, instance_id=None, allocation_id=None, network_interface_id=None, private_ip_address=None, allow_reassociation=False): if not public_ip and not allocation_id: msg = _('Either public IP or allocation id must be specified') raise exception.MissingParameter(msg) if public_ip and allocation_id: msg = _('You may specify public IP or allocation id, ' 'but not both in the same call') raise exception.InvalidParameterCombination(msg) if not instance_id and not network_interface_id: msg = _('Either instance ID or network interface id must be specified') raise exception.MissingParameter(msg) instance_network_interfaces = [] if instance_id: api_instance_id = ec2utils.ec2_id_to_id(instance_id) # TODO(ft): check instance exists # TODO(ft): implement search in DB layer for eni in db_api.get_items(context, 'eni'): if instance_id and eni.get('instance_id') == api_instance_id: instance_network_interfaces.append(eni) neutron = clients.neutron(context) if public_ip: if instance_network_interfaces: msg = _('You must specify an allocation id when mapping ' 'an address to a VPC instance') raise exception.InvalidParameterCombination(msg) # TODO(ft): implement search in DB layer address = next((addr for addr in db_api.get_items(context, 'eipalloc') if addr['public_ip'] == public_ip), None) if address and _is_address_valid(context, neutron, address): msg = _(""The address '%(public_ip)s' does not belong to you."") raise exception.AuthFailure(msg % {'public_ip': public_ip}) ec2 = ec2client.ec2client(context) # NOTE(ft): in fact only the first two parameters are used to # associate an address in EC2 Classic mode. Other parameters are # sent to validate them for EC2 Classic mode and raise an error. return ec2.associate_address( public_ip=public_ip, instance_id=instance_id, network_interface_id=network_interface_id, private_ip_address=private_ip_address, allow_reassociation=allow_reassociation) if instance_id: if not instance_network_interfaces: msg = _('You must specify an IP address when mapping ' 'to a non-VPC instance') raise exception.InvalidParameterCombination(msg) if len(instance_network_interfaces) > 1: raise exception.InvalidInstanceId(instance_id=instance_id) network_interface = instance_network_interfaces[0] else: network_interface = ec2utils.get_db_item(context, 'eni', network_interface_id) if not private_ip_address: private_ip_address = network_interface['private_ip_address'] address = ec2utils.get_db_item(context, 'eipalloc', allocation_id) if not _is_address_valid(context, neutron, address): raise exception.InvalidAllocationIDNotFound(eipalloc_id=allocation_id) if address.get('network_interface_id') == network_interface['id']: # NOTE(ft): idempotent call pass elif address.get('network_interface_id') and not allow_reassociation: msg = _('resource %(eipalloc_id)s is already associated with ' 'associate-id %(eipassoc_id)s') msg = msg % {'eipalloc_id': allocation_id, 'eipassoc_id': ec2utils.get_ec2_id( address['id'], 'eipassoc')} raise exception.ResourceAlreadyAssociated(msg) else: with utils.OnCrashCleaner() as cleaner: _associate_address_item(context, address, network_interface['id'], private_ip_address) cleaner.addCleanup(_disassociate_address_item, context, address) os_floating_ip = {'port_id': network_interface['os_id'], 'fixed_ip_address': private_ip_address} neutron.update_floatingip(address['os_id'], {'floatingip': os_floating_ip}) return {'return': True, 'associationId': ec2utils.get_ec2_id(address['id'], 'eipassoc')} def disassociate_address(context, public_ip=None, association_id=None): if not public_ip and not association_id: msg = _('Either public IP or association id must be specified') raise exception.MissingParameter(msg) if public_ip and association_id: msg = _('You may specify public IP or association id, ' 'but not both in the same call') raise exception.InvalidParameterCombination(msg) neutron = clients.neutron(context) if public_ip: # TODO(ft): implement search in DB layer address = next((addr for addr in db_api.get_items(context, 'eipalloc') if addr['public_ip'] == public_ip), None) if address and _is_address_valid(context, neutron, address): msg = _('You must specify an association id when unmapping ' 'an address from a VPC instance') raise exception.InvalidParameterValue(msg) ec2 = ec2client.ec2client(context) return ec2.disassociate_address(public_ip=public_ip) address = db_api.get_item_by_id(context, 'eipalloc', ec2utils.ec2_id_to_id(association_id)) if address is None or not _is_address_valid(context, neutron, address): raise exception.InvalidAssociationIDNotFound( assoc_id=association_id) if 'network_interface_id' in address: with utils.OnCrashCleaner() as cleaner: network_interface_id = address['network_interface_id'] private_ip_address = address['private_ip_address'] _disassociate_address_item(context, address) cleaner.addCleanup(_associate_address_item, context, address, network_interface_id, private_ip_address) neutron.update_floatingip(address['os_id'], {'floatingip': {'port_id': None}}) return True def release_address(context, public_ip=None, allocation_id=None): if not public_ip and not allocation_id: msg = _('Either public IP or allocation id must be specified') raise exception.MissingParameter(msg) if public_ip and allocation_id: msg = _('You may specify public IP or allocation id, ' 'but not both in the same call') raise exception.InvalidParameterCombination(msg) neutron = clients.neutron(context) if public_ip: # TODO(ft): implement search in DB layer address = next((addr for addr in db_api.get_items(context, 'eipalloc') if addr['public_ip'] == public_ip), None) if address and _is_address_valid(context, neutron, address): msg = _('You must specify an allocation id when releasing a VPC ' 'elastic IP address') raise exception.InvalidParameterValue(msg) ec2 = ec2client.ec2client(context) return ec2.release_address(public_ip=public_ip) address = ec2utils.get_db_item(context, 'eipalloc', allocation_id) if not _is_address_valid(context, neutron, address): raise exception.InvalidAllocationIDNotFound(eipalloc_id=allocation_id) if 'network_interface_id' in address: raise exception.InvalidIPAddressInUse(ip_address=address['public_ip']) with utils.OnCrashCleaner() as cleaner: db_api.delete_item(context, address['id']) cleaner.addCleanup(db_api.restore_item, context, 'eipalloc', address) try: neutron.delete_floatingip(address['os_id']) except neutron_exception.NotFound: # TODO(ft): catch FloatingIPNotFound pass return True def describe_addresses(context, public_ip=None, allocation_id=None, filter=None): # TODO(ft):implement filters ec2 = ec2client.ec2client(context) ec2_addresses = ec2.describe_addresses(public_ip=public_ip, allocation_id=allocation_id, filter=filter) neutron = clients.neutron(context) os_floating_ips = neutron.list_floatingips()['floatingips'] os_floating_ips = dict((fip['floating_ip_address'], fip) for fip in os_floating_ips) addresses = ec2utils.get_db_items(context, 'eipalloc', allocation_id) addresses = dict((eip['os_id'], eip) for eip in addresses) for ec2_address in ec2_addresses['addressesSet']: os_floating_ip = os_floating_ips.get(ec2_address['publicIp']) address = (addresses.get(os_floating_ip['id']) if os_floating_ip else None) _format_address(context, ec2_address, address) return ec2_addresses def _format_address(context, ec2_address=None, address=None): if not address: ec2_address['domain'] = 'standard' else: if not ec2_address: ec2_address = {'publicIp': address['public_ip']} ec2_address.update({ 'domain': 'vpc', 'allocationId': ec2utils.get_ec2_id(address['id'], 'eipalloc')}) if 'network_interface_id' in address: ec2_address.update({ 'associationId': ec2_address['allocationId']. replace('eipalloc', 'eipassoc'), 'networkInterfaceId': ec2utils.get_ec2_id( address['network_interface_id'], 'eni'), 'privateIpAddress': address['private_ip_address'], 'networkInterfaceOwnerId': context.project_id}) return ec2_address def _is_address_valid(context, neutron, address): try: neutron.show_floatingip(address['os_id']) except neutron_exception.NotFound: return False else: return True def _associate_address_item(context, address, network_interface_id, private_ip_address): address['network_interface_id'] = network_interface_id address['private_ip_address'] = private_ip_address db_api.update_item(context, address) def _disassociate_address_item(context, address): address.pop('network_interface_id') address.pop('private_ip_address') db_api.update_item(context, address) ",,964,0
openstack%2Fcloudkitty~master~I6f496c1cd04a2707bbb84a358c32b9e2923bf42c,openstack/cloudkitty,master,I6f496c1cd04a2707bbb84a358c32b9e2923bf42c,Added module state management DB,MERGED,2014-08-08 13:10:53.000000000,2014-08-08 13:23:39.000000000,2014-08-08 13:23:39.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-08 13:10:53.000000000', 'files': ['cloudkitty/db/sqlalchemy/alembic/__init__.py', 'cloudkitty/db/sqlalchemy/alembic/versions/464e951dc3b8_initial_migration.py', 'cloudkitty/db/sqlalchemy/alembic/script.py.mako', 'cloudkitty/db/sqlalchemy/api.py', 'cloudkitty/db/sqlalchemy/alembic/env.py', 'cloudkitty/config.py', 'cloudkitty/db/sqlalchemy/migration.py', 'cloudkitty/db/sqlalchemy/models.py', 'cloudkitty/db/api.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/cff10a4e87b7132c1b6c5c67187c81164fea8381', 'message': 'Added module state management DB\n\nChange-Id: I6f496c1cd04a2707bbb84a358c32b9e2923bf42c\n'}]",0,112854,cff10a4e87b7132c1b6c5c67187c81164fea8381,7,2,1,7042,,,0,"Added module state management DB

Change-Id: I6f496c1cd04a2707bbb84a358c32b9e2923bf42c
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/54/112854/1 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/db/sqlalchemy/alembic/__init__.py', 'cloudkitty/db/sqlalchemy/alembic/versions/464e951dc3b8_initial_migration.py', 'cloudkitty/db/sqlalchemy/alembic/script.py.mako', 'cloudkitty/db/sqlalchemy/api.py', 'cloudkitty/db/sqlalchemy/alembic/env.py', 'cloudkitty/config.py', 'cloudkitty/db/sqlalchemy/migration.py', 'cloudkitty/db/sqlalchemy/models.py', 'cloudkitty/db/api.py']",9,cff10a4e87b7132c1b6c5c67187c81164fea8381,feature/billing/db_modules_enabled," @six.add_metaclass(abc.ABCMeta) class ModuleEnableState(object): """"""Base class for module state management."""""" @abc.abstractmethod def get_state(self, name): """"""Retrieve the module state. :param name: Name of the module :return bool: State of the module """""" @abc.abstractmethod def set_state(self, name, state): """"""Retrieve the module state. :param name: Name of the module :param value: State of the module """"""",,222,0
openstack%2Fcloudkitty~master~If5923734315efcecc64127edb4abd3d6005c30ed,openstack/cloudkitty,master,If5923734315efcecc64127edb4abd3d6005c30ed,Added alembic support for database migrations,MERGED,2014-08-08 12:35:02.000000000,2014-08-08 13:15:43.000000000,2014-08-08 13:15:42.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-08 12:35:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/b8cf534d67f17d30a3bf68c1e7656fd089bf760e', 'message': 'Added alembic support for database migrations\n\nChange-Id: If5923734315efcecc64127edb4abd3d6005c30ed\n'}, {'number': 2, 'created': '2014-08-08 13:02:21.000000000', 'files': ['cloudkitty/common/db/alembic/env.py', 'cloudkitty/common/__init__.py', 'cloudkitty/common/db/alembic/migration.py', 'cloudkitty/common/db/alembic/__init__.py', 'cloudkitty/common/db/alembic/alembic.ini', 'cloudkitty/common/db/__init__.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/3d16526bc7ff597cf6675bf364f4e4a572421bc6', 'message': 'Added alembic support for database migrations\n\nChange-Id: If5923734315efcecc64127edb4abd3d6005c30ed\n'}]",0,112848,3d16526bc7ff597cf6675bf364f4e4a572421bc6,11,2,2,7042,,,0,"Added alembic support for database migrations

Change-Id: If5923734315efcecc64127edb4abd3d6005c30ed
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/48/112848/1 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/common/db/alembic/env.py', 'cloudkitty/common/__init__.py', 'cloudkitty/common/db/alembic/migration.py', 'cloudkitty/common/db/alembic/__init__.py', 'cloudkitty/common/db/alembic/alembic.ini', 'cloudkitty/common/db/__init__.py']",6,b8cf534d67f17d30a3bf68c1e7656fd089bf760e,feature/alembic,,,172,0
openstack%2Fec2-api~master~I8098ffe231a8ce87944a3f9d30713e66ef2f830c,openstack/ec2-api,master,I8098ffe231a8ce87944a3f9d30713e66ef2f830c,Adding dhcp options,MERGED,2014-08-08 12:33:44.000000000,2014-08-08 13:02:06.000000000,2014-08-08 13:02:06.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-08-08 12:33:44.000000000', 'files': ['ec2api/api/cloud.py', 'ec2api/api/dhcp_options.py', 'ec2api/tests/test_dhcp_options.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/cd47acd47fffcff139540c0e84d2423215c8074b', 'message': 'Adding dhcp options\n\nChange-Id: I8098ffe231a8ce87944a3f9d30713e66ef2f830c\n'}]",0,112847,cd47acd47fffcff139540c0e84d2423215c8074b,7,4,1,9312,,,0,"Adding dhcp options

Change-Id: I8098ffe231a8ce87944a3f9d30713e66ef2f830c
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/47/112847/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/cloud.py', 'ec2api/api/dhcp_options.py', 'ec2api/tests/test_dhcp_options.py']",3,cd47acd47fffcff139540c0e84d2423215c8074b,,"# Copyright 2014 Cloudscaling Group, Inc # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock from ec2api.tests import base from ec2api.tests import fakes from ec2api.tests import matchers from ec2api.tests import tools class DhcpOptionsTestCase(base.ApiTestCase): def test_create_dhcp_options(self): def gen_opt(count, value): return 'DhcpConfiguration.' + str(count) + '.' + value def gen_ec2_param_dhcp_options(dhcp_options): dhcp_configuration = dhcp_options['dhcpConfigurationSet'] result_param = {} opt_count = 0 for opt in dhcp_configuration: opt_count += 1 result_param[gen_opt(opt_count, 'Key')] = opt['key'] value_count = 0 for value in opt['valueSet']: value_count += 1 result_param[gen_opt(opt_count, 'Value.' + str(value_count))] = ( str(value['value'])) return result_param def check(ec2_fake, db_fake): self.db_api.add_item.return_value = db_fake resp = self.execute( 'CreateDhcpOptions', gen_ec2_param_dhcp_options(ec2_fake)) self.assertEqual(200, resp['status']) self.assertThat(ec2_fake, matchers.DictMatches( resp['dhcpOptions'])) self.db_api.add_item.called_once_with( mock.ANY, 'dhcp_options', tools.purge_dict(db_fake, ('id',))) self.db_api.reset_mock() check(fakes.EC2_DHCP_OPTIONS_1, fakes.DB_DHCP_OPTIONS_1) check(fakes.EC2_DHCP_OPTIONS_2, fakes.DB_DHCP_OPTIONS_2) def test_create_dhcp_options_invalid_parameters(self): resp = self.execute('CreateDhcpOptions', {'DhcpConfiguration.1.Key': 'InvalidParameter', 'DhcpConfiguration.1.Value.1': 'Value'}) self.assertEqual(400, resp['status']) self.assertEqual('InvalidParameterValue', resp['Error']['Code']) def test_delete_dhcp_options(self): self.db_api.get_item_by_id.return_value = fakes.DB_DHCP_OPTIONS_1 self.db_api.get_items.return_value = [] resp = self.execute('DeleteDhcpOptions', {'dhcpOptionsId': fakes.ID_EC2_DHCP_OPTIONS_1}) self.assertEqual(200, resp['status']) self.assertEqual(True, resp['return']) self.db_api.get_item_by_id.assert_has_call( mock.ANY, fakes.ID_DB_DHCP_OPTIONS_1) self.db_api.get_items.assert_has_call( mock.ANY, 'vpc') self.db_api.delete_item.assert_called_once_with( mock.ANY, fakes.ID_DB_DHCP_OPTIONS_1) def test_delete_dhcp_options_with_dependencies(self): self.db_api.get_item_by_id.return_value = fakes.DB_DHCP_OPTIONS_1 self.db_api.get_items.return_value = [tools.update_dict( fakes.DB_VPC_1, {'dhcp_options_id': fakes.ID_DB_DHCP_OPTIONS_1})] resp = self.execute('DeleteDhcpOptions', {'dhcpOptionsId': fakes.ID_EC2_DHCP_OPTIONS_1}) self.assertEqual(400, resp['status']) self.assertEqual('DependencyViolation', resp['Error']['Code']) def test_describe_dhcp_options(self): self.db_api.get_items.return_value = ( [fakes.DB_DHCP_OPTIONS_1, fakes.DB_DHCP_OPTIONS_2]) resp = self.execute('DescribeDhcpOptions', {}) self.assertEqual(200, resp['status']) self.assertThat(resp['dhcpOptionsSet'], matchers.DictListMatches([fakes.EC2_DHCP_OPTIONS_1, fakes.EC2_DHCP_OPTIONS_2])) def test_associate_dhcp_options(self): self.db_api.get_item_by_id.side_effect = ( fakes.get_db_api_get_item_by_id( {fakes.ID_DB_VPC_1: fakes.DB_VPC_1, fakes.ID_DB_DHCP_OPTIONS_1: fakes.DB_DHCP_OPTIONS_1})) self.db_api.get_items.return_value = [fakes.DB_NETWORK_INTERFACE_1] self.neutron.list_ports.return_value = ( {'ports': [fakes.OS_PORT_1, fakes.OS_PORT_2]}) def check(ec2_dhcp_options_id, db_dhcp_options_id, os_dhcp_options): resp = self.execute('AssociateDhcpOptions', {'dhcpOptionsId': ec2_dhcp_options_id, 'vpcId': fakes.ID_EC2_VPC_1}) self.assertEqual(200, resp['status']) self.assertEqual(True, resp['return']) self.db_api.update_item.assert_has_call( mock.ANY, tools.update_dict( fakes.DB_VPC_1, {'dhcp_options_id': db_dhcp_options_id})) self.neutron.update_port.assert_has_call( mock.ANY, fakes.ID_OS_PORT_1, {'port': os_dhcp_options}) check(fakes.ID_EC2_DHCP_OPTIONS_1, fakes.ID_DB_DHCP_OPTIONS_1, fakes.OS_DHCP_OPTIONS_1) check('default', None, {'extra_dhcp_opts': []}) def test_associate_dhcp_options_rollback(self): vpc = tools.update_dict( fakes.DB_VPC_1, {'dhcp_options_id': fakes.ID_DB_DHCP_OPTIONS_1}) self.db_api.get_item_by_id.side_effect = ( fakes.get_db_api_get_item_by_id( {fakes.ID_DB_VPC_1: vpc, fakes.ID_DB_DHCP_OPTIONS_1: fakes.DB_DHCP_OPTIONS_1, fakes.ID_DB_DHCP_OPTIONS_2: fakes.DB_DHCP_OPTIONS_2})) self.db_api.get_items.return_value = [fakes.DB_NETWORK_INTERFACE_1, fakes.DB_NETWORK_INTERFACE_2] self.neutron.list_ports.return_value = ( {'ports': [fakes.OS_PORT_1, fakes.OS_PORT_2]}) def update_port_func(port_id, _port_data): if port_id == fakes.ID_OS_PORT_2: raise Exception() self.neutron.update_port.side_effect = update_port_func self.execute('AssociateDhcpOptions', {'dhcpOptionsId': fakes.ID_EC2_DHCP_OPTIONS_2, 'vpcId': fakes.ID_EC2_VPC_1}) self.neutron.update_port.assert_any_call( fakes.ID_OS_PORT_1, {'port': fakes.OS_DHCP_OPTIONS_1}) self.db_api.update_item.assert_any_call( mock.ANY, vpc) ",,389,0
openstack%2Ftempest~master~Ib49b6d5937da6eedc3028a1f831552cf02d9f69e,openstack/tempest,master,Ib49b6d5937da6eedc3028a1f831552cf02d9f69e,Move baremetal API tests to an /admin subdir,MERGED,2014-06-18 18:38:42.000000000,2014-08-08 12:51:30.000000000,2014-08-08 12:51:29.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 1921}, {'_account_id': 2889}, {'_account_id': 3099}, {'_account_id': 5196}, {'_account_id': 5371}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 7227}, {'_account_id': 7293}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-18 18:38:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5be21f718b7fbcd87cc5a683c9cf3df4dbc0366c', 'message': 'Move baremetal API tests to an /admin subdir\n\nTo avoid confusion, move all baremetal API tests to api/baremetal/admin and\nadd a README.rst explaining that the API provided by Ironic is meant an\nadmin and service level API.\n\nChange-Id: Ib49b6d5937da6eedc3028a1f831552cf02d9f69e\n'}, {'number': 2, 'created': '2014-06-18 20:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/19158390edc133d7a09c8ebe4df69de790cd1a33', 'message': 'Move baremetal API tests to an /admin subdir\n\nTo avoid confusion, move all baremetal API tests to api/baremetal/admin and\nadd a README.rst explaining that the API provided by Ironic is meant an\nadmin and service level API.\n\nChange-Id: Ib49b6d5937da6eedc3028a1f831552cf02d9f69e\n'}, {'number': 3, 'created': '2014-07-11 20:55:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/858b0b672618eb3aad925560b56e67c1dbede61c', 'message': 'Move baremetal API tests to an /admin subdir\n\nTo avoid confusion, move all baremetal API tests to api/baremetal/admin and\nadd a README.rst explaining that the API provided by Ironic is meant to be used\nas an admin and service level API.\n\nChange-Id: Ib49b6d5937da6eedc3028a1f831552cf02d9f69e\n'}, {'number': 4, 'created': '2014-07-18 18:54:46.000000000', 'files': ['tempest/api/baremetal/admin/__init__.py', 'tempest/api/baremetal/admin/base.py', 'tempest/api/baremetal/admin/test_chassis.py', 'tempest/api/baremetal/admin/test_nodes.py', 'tempest/api/baremetal/admin/test_ports_negative.py', 'tempest/api/baremetal/admin/test_nodestates.py', 'tempest/api/baremetal/admin/test_api_discovery.py', 'tempest/api/baremetal/README.rst', 'tempest/api/baremetal/admin/test_drivers.py', 'tempest/api/baremetal/admin/test_ports.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/2a86f1c6d7c09cc668e188b95474a0cbfbd60a12', 'message': 'Move baremetal API tests to an /admin subdir\n\nTo avoid confusion, move all baremetal API tests to api/baremetal/admin and\nadd a README.rst explaining that the API provided by Ironic is meant to be used\nas an admin and service level API.\n\nChange-Id: Ib49b6d5937da6eedc3028a1f831552cf02d9f69e\n'}]",3,100989,2a86f1c6d7c09cc668e188b95474a0cbfbd60a12,48,14,4,1420,,,0,"Move baremetal API tests to an /admin subdir

To avoid confusion, move all baremetal API tests to api/baremetal/admin and
add a README.rst explaining that the API provided by Ironic is meant to be used
as an admin and service level API.

Change-Id: Ib49b6d5937da6eedc3028a1f831552cf02d9f69e
",git fetch https://review.opendev.org/openstack/tempest refs/changes/89/100989/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/baremetal/admin/__init__.py', 'tempest/api/baremetal/admin/base.py', 'tempest/api/baremetal/admin/test_chassis.py', 'tempest/api/baremetal/admin/test_nodes.py', 'tempest/api/baremetal/admin/test_ports_negative.py', 'tempest/api/baremetal/admin/test_nodestates.py', 'tempest/api/baremetal/admin/test_api_discovery.py', 'tempest/api/baremetal/README.rst', 'tempest/api/baremetal/admin/test_drivers.py', 'tempest/api/baremetal/admin/test_ports.py']",10,5be21f718b7fbcd87cc5a683c9cf3df4dbc0366c,100989,from tempest.api.baremetal.admin import base,from tempest.api.baremetal import base,33,7
openstack%2Fcloudkitty~master~I2b4ffee1aeb00b2e9d45ba7fe36b170a9a0814a4,openstack/cloudkitty,master,I2b4ffee1aeb00b2e9d45ba7fe36b170a9a0814a4,Fixed missing config generator.rc file,MERGED,2014-08-08 12:40:06.000000000,2014-08-08 12:49:37.000000000,2014-08-08 12:49:37.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-08 12:40:06.000000000', 'files': ['etc/cloudkitty/cloudkitty.conf.sample', 'tools/config/oslo.config.generator.rc'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/9ad2c2059639824709d7d2acce0b7ff6375274ab', 'message': 'Fixed missing config generator.rc file\n\nChange-Id: I2b4ffee1aeb00b2e9d45ba7fe36b170a9a0814a4\n'}]",0,112849,9ad2c2059639824709d7d2acce0b7ff6375274ab,7,2,1,7042,,,0,"Fixed missing config generator.rc file

Change-Id: I2b4ffee1aeb00b2e9d45ba7fe36b170a9a0814a4
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/49/112849/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cloudkitty/cloudkitty.conf.sample', 'tools/config/oslo.config.generator.rc']",2,9ad2c2059639824709d7d2acce0b7ff6375274ab,fix/config/missing_rc,"CLOUDKITTY_CONFIG_GENERATOR_EXTRA_LIBRARIES=""oslo.messaging oslo.db"" ",,313,0
openstack%2Fmurano-dashboard~master~Ib81de721b9c5329157e157075b461a832fc3d3cc,openstack/murano-dashboard,master,Ib81de721b9c5329157e157075b461a832fc3d3cc,Add ability to override dashboard name,MERGED,2014-08-01 20:30:18.000000000,2014-08-08 12:47:15.000000000,2014-08-08 12:47:15.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 9048}]","[{'number': 1, 'created': '2014-08-01 20:30:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/4d1253fc1d90bdb711c70fe6d29e03aabfa82511', 'message': 'Add ability to override dashboard name\n\nAllow confiration settings to be able to\noverride the Murano dashboard name to something\nmore customizable\n\nChange-Id: Ib81de721b9c5329157e157075b461a832fc3d3cc\nImplements: blueprint add-ability-to-override-dashboard-name\n'}, {'number': 2, 'created': '2014-08-07 21:44:13.000000000', 'files': ['muranodashboard/local/local_settings.py.example', 'muranodashboard/dashboard.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/b046b875808eb2b4d04fe9907a1122e3df8a197b', 'message': 'Add ability to override dashboard name\n\nAllow confiration settings to be able to\noverride the Murano dashboard name to something\nmore customizable\n\nChange-Id: Ib81de721b9c5329157e157075b461a832fc3d3cc\nImplements: blueprint add-ability-to-override-dashboard-name\n'}]",0,111383,b046b875808eb2b4d04fe9907a1122e3df8a197b,21,6,2,11098,,,0,"Add ability to override dashboard name

Allow confiration settings to be able to
override the Murano dashboard name to something
more customizable

Change-Id: Ib81de721b9c5329157e157075b461a832fc3d3cc
Implements: blueprint add-ability-to-override-dashboard-name
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/83/111383/2 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/local/local_settings.py.example', 'muranodashboard/dashboard.py']",2,4d1253fc1d90bdb711c70fe6d29e03aabfa82511,bp/add-ability-to-override-dashboard-name,"from django.conf import settings name = _(getattr(settings, 'MURANO_DASHBOARD_NAME', ""Murano""))"," name = _(""Murano"")",6,1
openstack%2Fnova~master~Ibe64e7fd90cd337546765ab17eff92ce8b463b96,openstack/nova,master,Ibe64e7fd90cd337546765ab17eff92ce8b463b96,Making nova.compute.api to return Aggregate Objects,ABANDONED,2014-07-31 11:01:49.000000000,2014-08-08 12:45:37.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8430}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12299}]","[{'number': 1, 'created': '2014-07-31 11:01:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63838814cbd35ccd23234e40a885eb2f4513bdf8', 'message': ""Making nova.compute.api to return Aggregate Objects\n\nnova.compute.api should return Objects and they should be\nconverted into the REST API expected result in the API extensions\n\nThis is just a rebase of Santiago's change:\nhttps://review.openstack.org/#/c/80663\n\nChange-Id: Ibe64e7fd90cd337546765ab17eff92ce8b463b96\nCloses-Bug: #1292644\n""}, {'number': 2, 'created': '2014-08-05 06:45:57.000000000', 'files': ['nova/api/openstack/compute/contrib/aggregates.py', 'nova/api/openstack/compute/plugins/v3/aggregates.py', 'nova/tests/api/openstack/compute/contrib/test_aggregates.py', 'nova/tests/integrated/test_api_samples.py', 'nova/compute/api.py', 'nova/tests/api/openstack/compute/plugins/v3/test_aggregates.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5017f6e89cac0cd0e95da2c9de22418f9a9eafa4', 'message': ""Making nova.compute.api to return Aggregate Objects\n\nnova.compute.api should return Objects and they should be\nconverted into the REST API expected result in the API extensions\n\nThis is just a rebase of Santiago's change:\nhttps://review.openstack.org/#/c/80663\n\nChange-Id: Ibe64e7fd90cd337546765ab17eff92ce8b463b96\nCloses-Bug: #1292644\n""}]",0,110901,5017f6e89cac0cd0e95da2c9de22418f9a9eafa4,20,6,2,12299,,,0,"Making nova.compute.api to return Aggregate Objects

nova.compute.api should return Objects and they should be
converted into the REST API expected result in the API extensions

This is just a rebase of Santiago's change:
https://review.openstack.org/#/c/80663

Change-Id: Ibe64e7fd90cd337546765ab17eff92ce8b463b96
Closes-Bug: #1292644
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/110901/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/contrib/aggregates.py', 'nova/api/openstack/compute/plugins/v3/aggregates.py', 'nova/tests/api/openstack/compute/contrib/test_aggregates.py', 'nova/tests/integrated/test_api_samples.py', 'nova/compute/api.py', 'nova/tests/api/openstack/compute/plugins/v3/test_aggregates.py']",6,63838814cbd35ccd23234e40a885eb2f4513bdf8,bug/1292644,"FORMATTED_AGGREGATE = {""name"": ""aggregate1"", ""id"": ""1"", ""availability_zone"": ""nova1""} self.assertEqual(FORMATTED_AGGREGATE, result[""aggregate""]) self.assertEqual(FORMATTED_AGGREGATE, result[""aggregate""]) ""availability_zone"": None, ""metadata"": {}, ""hosts"": []} formatted_aggregate = {""name"": ""aggregate1"", ""id"": ""1"", self.assertEqual(formatted_aggregate, result[""aggregate""])"," self.assertEqual(AGGREGATE, result[""aggregate""]) self.assertEqual(AGGREGATE, result[""aggregate""]) self.assertEqual(aggregate, result[""aggregate""])",69,37
openstack%2Fnova~master~I0f6b533a81168c3dd2815ab9d3476b738316125a,openstack/nova,master,I0f6b533a81168c3dd2815ab9d3476b738316125a,Making nova.compute.api to return Aggregate Objects,ABANDONED,2014-03-14 19:05:41.000000000,2014-08-08 12:45:30.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10247}, {'_account_id': 10385}, {'_account_id': 12299}]","[{'number': 1, 'created': '2014-03-14 19:05:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/92d958cfc003e49b990670fc68ae012c8302dec7', 'message': 'Make get_aggregate_list to return a List object\n\nnova.compute.api returns a List object which is formatted\nto the REST API expected result in the aggregates API extension\n\nCloses-Bug: #1292644\n\nChange-Id: I0f6b533a81168c3dd2815ab9d3476b738316125a\n'}, {'number': 2, 'created': '2014-03-17 20:20:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/48a74a9310e2c76fc90cc3707909090aa300b706', 'message': 'Make get_aggregate_list to return a List object\n\nnova.compute.api returns a List object which is formatted\nto the REST API expected result in the aggregates API extension\n\nCloses-Bug: #1292644\n\nChange-Id: I0f6b533a81168c3dd2815ab9d3476b738316125a\n'}, {'number': 3, 'created': '2014-05-13 17:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2a0b085edc37f0d69e40669fbac9b5d0f25d6b3', 'message': 'Making nova.compute.api to return Aggregate Objects\n\nnova.compute.api should return Objects and they should be\nconverted into the REST API expected result in the API extensions\n\nCloses-Bug: #1292644\n\nChange-Id: I0f6b533a81168c3dd2815ab9d3476b738316125a\n'}, {'number': 4, 'created': '2014-05-21 14:00:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f42af25256c1b910095a839c8e9b04f1bb01f30', 'message': 'Making nova.compute.api to return Aggregate Objects\n\nnova.compute.api should return Objects and they should be\nconverted into the REST API expected result in the API extensions\n\nCloses-Bug: #1292644\n\nChange-Id: I0f6b533a81168c3dd2815ab9d3476b738316125a\n'}, {'number': 5, 'created': '2014-05-26 16:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7e5988ee6b003dd0e00e0ee6d912578b20104b58', 'message': 'Making nova.compute.api to return Aggregate Objects\n\nnova.compute.api should return Objects and they should be\nconverted into the REST API expected result in the API extensions\n\nCloses-Bug: #1292644\n\nChange-Id: I0f6b533a81168c3dd2815ab9d3476b738316125a\n'}, {'number': 6, 'created': '2014-06-12 12:40:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/92661fbf7be9104f8fd2c5d6a659ac20c564cb99', 'message': 'Making nova.compute.api to return Aggregate Objects\n\nnova.compute.api should return Objects and they should be\nconverted into the REST API expected result in the API extensions\n\nCloses-Bug: #1292644\n\nChange-Id: I0f6b533a81168c3dd2815ab9d3476b738316125a\n'}, {'number': 7, 'created': '2014-06-23 15:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2eb8e068fd13cb8221b69dd5338a6fee48a11526', 'message': 'Making nova.compute.api to return Aggregate Objects\n\nnova.compute.api should return Objects and they should be\nconverted into the REST API expected result in the API extensions\n\nCloses-Bug: #1292644\n\nChange-Id: I0f6b533a81168c3dd2815ab9d3476b738316125a\n'}, {'number': 8, 'created': '2014-06-23 18:04:41.000000000', 'files': ['nova/api/openstack/compute/contrib/aggregates.py', 'nova/api/openstack/compute/plugins/v3/aggregates.py', 'nova/tests/api/openstack/compute/contrib/test_aggregates.py', 'nova/tests/integrated/test_api_samples.py', 'nova/compute/api.py', 'nova/tests/api/openstack/compute/plugins/v3/test_aggregates.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4d183a1f372e4b98de58a1ac061c3c7470f2132d', 'message': 'Making nova.compute.api to return Aggregate Objects\n\nnova.compute.api should return Objects and they should be\nconverted into the REST API expected result in the API extensions\n\nCloses-Bug: #1292644\n\nChange-Id: I0f6b533a81168c3dd2815ab9d3476b738316125a\n'}]",15,80663,4d183a1f372e4b98de58a1ac061c3c7470f2132d,92,15,8,10247,,,0,"Making nova.compute.api to return Aggregate Objects

nova.compute.api should return Objects and they should be
converted into the REST API expected result in the API extensions

Closes-Bug: #1292644

Change-Id: I0f6b533a81168c3dd2815ab9d3476b738316125a
",git fetch https://review.opendev.org/openstack/nova refs/changes/63/80663/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/api.py'],1,92d958cfc003e49b990670fc68ae012c8302dec7,bug/1292644, return aggregate_obj.AggregateList.get_all(context), aggregates = aggregate_obj.AggregateList.get_all(context) return [self._reformat_aggregate_info(agg) for agg in aggregates],1,2
openstack%2Fcloudkitty~master~I89bef295bfec965c06ce7df75fc6fb5cf87f6f57,openstack/cloudkitty,master,I89bef295bfec965c06ce7df75fc6fb5cf87f6f57,Transitioned from file state to DB state,MERGED,2014-08-08 12:30:31.000000000,2014-08-08 12:42:04.000000000,2014-08-08 12:42:04.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-08 12:30:31.000000000', 'files': ['cloudkitty/state.py', 'cloudkitty/db/__init__.py', 'cloudkitty/writer/__init__.py', 'cloudkitty/orchestrator.py', 'cloudkitty/db/sqlalchemy/api.py', 'cloudkitty/db/sqlalchemy/models.py', 'cloudkitty/db/api.py', 'cloudkitty/db/sqlalchemy/__init__.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/6903c5c2fd420784e257c420be6aeec9e1360a88', 'message': 'Transitioned from file state to DB state\n\nManaging states are now made with a DB.\nFixes on the file state manager.\n\nChange-Id: I89bef295bfec965c06ce7df75fc6fb5cf87f6f57\n'}]",0,112846,6903c5c2fd420784e257c420be6aeec9e1360a88,7,2,1,7042,,,0,"Transitioned from file state to DB state

Managing states are now made with a DB.
Fixes on the file state manager.

Change-Id: I89bef295bfec965c06ce7df75fc6fb5cf87f6f57
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/46/112846/1 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/state.py', 'cloudkitty/db/__init__.py', 'cloudkitty/writer/__init__.py', 'cloudkitty/db/sqlalchemy/api.py', 'cloudkitty/orchestrator.py', 'cloudkitty/db/sqlalchemy/models.py', 'cloudkitty/db/api.py', 'cloudkitty/db/sqlalchemy/__init__.py']",8,6903c5c2fd420784e257c420be6aeec9e1360a88,add/DBState,,,302,12
openstack%2Fheat-templates~master~I8488ef3f94b3b55365d36e74a7753a2c25ca78ae,openstack/heat-templates,master,I8488ef3f94b3b55365d36e74a7753a2c25ca78ae,Fix user data format specification.,ABANDONED,2014-08-08 12:25:37.000000000,2014-08-08 12:29:52.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-08-08 12:25:37.000000000', 'files': ['hot/autoscaling.yaml'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/a698f5d377f6edc58e584064bac6c644fb5b3e92', 'message': ""Fix user data format specification.\n\nWhen user_data_format is set to RAW, the script in it won't get\nexecuted.  This patch removes the specification, leaving it to its\ndefault value HEAT_CFNTOOLS.\n\nChange-Id: I8488ef3f94b3b55365d36e74a7753a2c25ca78ae\n""}]",0,112844,a698f5d377f6edc58e584064bac6c644fb5b3e92,3,1,1,8246,,,0,"Fix user data format specification.

When user_data_format is set to RAW, the script in it won't get
executed.  This patch removes the specification, leaving it to its
default value HEAT_CFNTOOLS.

Change-Id: I8488ef3f94b3b55365d36e74a7753a2c25ca78ae
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/44/112844/1 && git format-patch -1 --stdout FETCH_HEAD,['hot/autoscaling.yaml'],1,a698f5d377f6edc58e584064bac6c644fb5b3e92,,, user_data_format: RAW,0,1
openstack%2Fcloudkitty~master~I586b0e604951b158ef1f6f0adbc31a61489f0047,openstack/cloudkitty,master,I586b0e604951b158ef1f6f0adbc31a61489f0047,Added i18n support,MERGED,2014-08-08 12:18:14.000000000,2014-08-08 12:28:58.000000000,2014-08-08 12:28:58.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-08 12:18:14.000000000', 'files': ['cloudkitty/i18n.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/5765daf6c22ec61b958620c0cd811c8cda9c0cd8', 'message': 'Added i18n support\n\nChange-Id: I586b0e604951b158ef1f6f0adbc31a61489f0047\n'}]",0,112841,5765daf6c22ec61b958620c0cd811c8cda9c0cd8,7,2,1,7042,,,0,"Added i18n support

Change-Id: I586b0e604951b158ef1f6f0adbc31a61489f0047
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/41/112841/1 && git format-patch -1 --stdout FETCH_HEAD,['cloudkitty/i18n.py'],1,5765daf6c22ec61b958620c0cd811c8cda9c0cd8,add/i18n,"# -*- coding: utf-8 -*- # Copyright 2014 Objectif Libre # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # @author: Stphane Albert # from oslo import i18n # noqa _translators = i18n.TranslatorFactory(domain='cloudkitty') i18n.enable_lazy() _ = _translators.primary _LI = _translators.log_info _LW = _translators.log_warning _LE = _translators.log_error _LC = _translators.log_critical ",,27,0
openstack%2Fcloudkitty~master~I8d7609ef8f227722a5a897e045d780d8440ac4fa,openstack/cloudkitty,master,I8d7609ef8f227722a5a897e045d780d8440ac4fa,Transitioned from importutils to stevedore,MERGED,2014-08-08 12:05:47.000000000,2014-08-08 12:15:04.000000000,2014-08-08 12:15:04.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-08 12:05:47.000000000', 'files': ['etc/cloudkitty/cloudkitty.conf.sample', 'cloudkitty/billing/hash.py', 'cloudkitty/billing/__init__.py', 'cloudkitty/extension_manager.py', 'cloudkitty/orchestrator.py', 'cloudkitty/billing/noop.py', 'cloudkitty/config.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/2b575ced771f5437247c377110f4996a7b2b5d95', 'message': 'Transitioned from importutils to stevedore\n\nBilling modules now use stevedore.\nCollection modules now use stevedore.\nWriter modules now use stevedore.\nBilling modules now reports if they are enabled or not.\n\nChange-Id: I8d7609ef8f227722a5a897e045d780d8440ac4fa\n'}]",0,112839,2b575ced771f5437247c377110f4996a7b2b5d95,7,2,1,7042,,,0,"Transitioned from importutils to stevedore

Billing modules now use stevedore.
Collection modules now use stevedore.
Writer modules now use stevedore.
Billing modules now reports if they are enabled or not.

Change-Id: I8d7609ef8f227722a5a897e045d780d8440ac4fa
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/39/112839/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cloudkitty/cloudkitty.conf.sample', 'cloudkitty/billing/hash.py', 'cloudkitty/billing/__init__.py', 'cloudkitty/billing/noop.py', 'cloudkitty/extension_manager.py', 'cloudkitty/orchestrator.py', 'cloudkitty/config.py', 'setup.cfg']",8,2b575ced771f5437247c377110f4996a7b2b5d95,improv/stevedore,cloudkitty.collector.backends = ceilometer = cloudkitty.collector.ceilometer:CeilometerCollector cloudkitty.billing.processors = noop = cloudkitty.billing.noop:Noop hashmap = cloudkitty.billing.hash:BasicHashMap cloudkitty.output.writers = osrf = cloudkitty.writer.osrf:OSRFBackend ,,122,47
openstack%2Fironic~master~Iabd62baba09e2f8ea94ed3aab417b6a63ea14ec4,openstack/ironic,master,Iabd62baba09e2f8ea94ed3aab417b6a63ea14ec4,Add create() and destroy() to Chassis object,MERGED,2014-08-06 12:50:42.000000000,2014-08-08 12:11:23.000000000,2014-08-08 12:11:22.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6623}, {'_account_id': 10239}, {'_account_id': 10342}]","[{'number': 1, 'created': '2014-08-06 12:50:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ca80a737d5808e04ad77a060dad474e952a47de5', 'message': 'Add create() and destroy() to Chassis object\n\nWhat it says. Also make the code and tests use them vs direct calls\nto dbapi.\n\nPartial-Bug: 1314732\nChange-Id: Iabd62baba09e2f8ea94ed3aab417b6a63ea14ec4\n'}, {'number': 2, 'created': '2014-08-08 09:12:05.000000000', 'files': ['ironic/api/controllers/v1/chassis.py', 'ironic/tests/objects/utils.py', 'ironic/db/sqlalchemy/api.py', 'ironic/objects/chassis.py', 'ironic/tests/api/v1/test_chassis.py', 'ironic/tests/api/v1/test_nodes.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/459919faa3b76c7763ce0d83de90f4931b3b91d5', 'message': 'Add create() and destroy() to Chassis object\n\nWhat it says. Also make the code and tests use them vs direct calls\nto dbapi.\n\nPartial-Bug: 1314732\nChange-Id: Iabd62baba09e2f8ea94ed3aab417b6a63ea14ec4\n'}]",0,112290,459919faa3b76c7763ce0d83de90f4931b3b91d5,21,5,2,6773,,,0,"Add create() and destroy() to Chassis object

What it says. Also make the code and tests use them vs direct calls
to dbapi.

Partial-Bug: 1314732
Change-Id: Iabd62baba09e2f8ea94ed3aab417b6a63ea14ec4
",git fetch https://review.opendev.org/openstack/ironic refs/changes/90/112290/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/api/controllers/v1/chassis.py', 'ironic/tests/objects/utils.py', 'ironic/db/sqlalchemy/api.py', 'ironic/objects/chassis.py', 'ironic/tests/api/v1/test_chassis.py', 'ironic/tests/api/v1/test_nodes.py']",6,ca80a737d5808e04ad77a060dad474e952a47de5,objects-cleanup, self.chassis = obj_utils.create_test_chassis(self.context) self.chassis = obj_utils.create_test_chassis(self.context) self.chassis = obj_utils.create_test_chassis(self.context) self.chassis = obj_utils.create_test_chassis(self.context) self.chassis = obj_utils.create_test_chassis(self.context), cdict = dbutils.get_test_chassis() self.chassis = self.dbapi.create_chassis(cdict) cdict = dbutils.get_test_chassis() self.chassis = self.dbapi.create_chassis(cdict) cdict = dbutils.get_test_chassis() self.chassis = self.dbapi.create_chassis(cdict) cdict = dbutils.get_test_chassis() self.chassis = self.dbapi.create_chassis(cdict) cdict = dbutils.get_test_chassis() self.chassis = self.dbapi.create_chassis(cdict),144,111
openstack%2Fqa-specs~master~I635647cb0c9c5a1f5a86db4d698edbf7501c871a,openstack/qa-specs,master,I635647cb0c9c5a1f5a86db4d698edbf7501c871a,Add qa spec for bp:add-cinder-v2-qos-tests,ABANDONED,2014-07-23 07:17:10.000000000,2014-08-08 12:03:01.000000000,,"[{'_account_id': 3}, {'_account_id': 8556}, {'_account_id': 11105}]","[{'number': 1, 'created': '2014-07-23 07:17:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/3dcd895cd1429129e254a8f1b94123c306e9c7a9', 'message': 'Add qa spec for bp:add-cinder-qos-tests\n\nThis patch adds the qa spec file for the\ndd-cinder-qos-tests blueprint\nPartially implements blueprint add-cinder-qos-tests\n\nChange-Id: I635647cb0c9c5a1f5a86db4d698edbf7501c871a\n'}, {'number': 2, 'created': '2014-07-23 10:37:39.000000000', 'files': ['specs/add-cinder-v2-qos-tests.rst'], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/2e81a6534f49680aa1a69648155fcfa3a71437f2', 'message': 'Add qa spec for bp:add-cinder-v2-qos-tests\n\nThis patch adds the qa spec file for the\ndd-cinder-v2-qos-tests blueprint\nPartially implements blueprint add-cinder-v2-qos-tests\n\nChange-Id: I635647cb0c9c5a1f5a86db4d698edbf7501c871a\n'}]",0,108907,2e81a6534f49680aa1a69648155fcfa3a71437f2,10,3,2,11105,,,0,"Add qa spec for bp:add-cinder-v2-qos-tests

This patch adds the qa spec file for the
dd-cinder-v2-qos-tests blueprint
Partially implements blueprint add-cinder-v2-qos-tests

Change-Id: I635647cb0c9c5a1f5a86db4d698edbf7501c871a
",git fetch https://review.opendev.org/openstack/qa-specs refs/changes/07/108907/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/add-cinder-qos-tests.rst'],1,3dcd895cd1429129e254a8f1b94123c306e9c7a9,bp/add-cinder-v2-qos-tests,:: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. ============================== Implement Cinder Qos API tests ============================== https://blueprints.launchpad.net/tempest/+spec/add-cinder-qos-tests Add missing Cinder qos tests Problem description =================== Currently Cinder QoS tests are not present in Tempest. Proposed change =============== This blueprint proposes to add Cinder QoS tests in Tempest Implementation ============== Assignee(s) ----------- Primary assignee: Swapnil Kulkarni <coolsvap@redhat.com> Other contributors: * Chandan Kumar <chkumar@redhat.com> Milestones ---------- Target Milestone for completion: Juno-3 Work Items ---------- - Add Cinder QoS tests Tasks will be managed using etherpad : (https://etherpad.openstack.org/p/add-cinder-qos-tests) ,,56,0
openstack%2Fnova~master~I8929dff44fc4091803cd409c879a2ffa69a34d6f,openstack/nova,master,I8929dff44fc4091803cd409c879a2ffa69a34d6f,Check for nested object version errors,ABANDONED,2014-03-06 13:51:23.000000000,2014-08-08 11:58:32.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1865}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 7461}, {'_account_id': 8688}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}]","[{'number': 1, 'created': '2014-03-06 13:51:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6dc68894ce15164cdda9a9dc3a122692933c43dd', 'message': ""Check for nested object version errors\n\nWhen a NovaObject primitive is deseialized it is backported to an earlier\nversion if the version in the primitive is not known. In the case where\nthe top level object version is known, but it contains another object with\nan unknown version nested within one of its fields, the deserializer will\nincorrectly attempt to backport the top level object to a version number\nderived from the nested object.\n\nThis fix adds a check to see if the IncompatibleObjectVersion exception\nraised in deserializing the object refers to the top level object. If it\ndoesn't, the check raises a new NestedObjectVersionError exception to\nindicate the error and more accurately describe the cause.\n\nChange-Id: I8929dff44fc4091803cd409c879a2ffa69a34d6f\nCloses-Bug: #1275675\n""}, {'number': 2, 'created': '2014-03-06 14:04:20.000000000', 'files': ['nova/objects/base.py', 'nova/exception.py', 'nova/tests/objects/test_objects.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9d2cb76d4866e9a29cb6c12d98b7de4290b5cc05', 'message': ""Check for nested object version errors\n\nWhen a NovaObject primitive is deseialized it is backported to an\nearlier version if the version in the primitive is not known. In the\ncase where the top level object version is known, but it contains\nanother object with an unknown version nested within one of its\nfields, the deserializer will incorrectly attempt to backport the\ntop level object to a version number derived from the nested object.\n\nThis fix adds a check to see if the IncompatibleObjectVersion\nexception raised in deserializing the object refers to the top level\nobject. If it doesn't, the check raises a new\nNestedObjectVersionError exception to indicate the error and more\naccurately describe the cause.\n\nChange-Id: I8929dff44fc4091803cd409c879a2ffa69a34d6f\nCloses-Bug: #1275675\n""}]",8,78605,9d2cb76d4866e9a29cb6c12d98b7de4290b5cc05,30,10,2,7461,,,0,"Check for nested object version errors

When a NovaObject primitive is deseialized it is backported to an
earlier version if the version in the primitive is not known. In the
case where the top level object version is known, but it contains
another object with an unknown version nested within one of its
fields, the deserializer will incorrectly attempt to backport the
top level object to a version number derived from the nested object.

This fix adds a check to see if the IncompatibleObjectVersion
exception raised in deserializing the object refers to the top level
object. If it doesn't, the check raises a new
NestedObjectVersionError exception to indicate the error and more
accurately describe the cause.

Change-Id: I8929dff44fc4091803cd409c879a2ffa69a34d6f
Closes-Bug: #1275675
",git fetch https://review.opendev.org/openstack/nova refs/changes/05/78605/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/base.py', 'nova/exception.py', 'nova/tests/objects/test_objects.py']",3,6dc68894ce15164cdda9a9dc3a122692933c43dd,bug/1275675,"class ContainerObj(base.NovaObject): VERSION = '5.5' fields = { 'nested': fields.ObjectField('MyObj'), } def test_deserialize_nested_object(self): ser = base.NovaObjectSerializer() ser._conductor = mock.Mock() ser._conductor.object_backport.return_value = 'backported' A = ContainerObj() B = MyObj() A.nested = B B.VERSION = '1.25' primitive = A.obj_to_primitive() error = None try: ser.deserialize_entity(self.context, primitive) except exception.NestedObjectVersionError as error: pass self.assertIsInstance(error, exception.NestedObjectVersionError) self.assertEqual(B.obj_name(), error.kwargs['nobjname']) self.assertEqual(B.VERSION, error.kwargs['nobjver']) self.assertEqual(A.obj_name(), error.kwargs['objname']) self.assertEqual(A.VERSION, error.kwargs['objver'])",,50,0
openstack%2Ffuel-main~master~I7631145380f1443117c15519dada5232d9b23217,openstack/fuel-main,master,I7631145380f1443117c15519dada5232d9b23217,Refactor network verification method,MERGED,2014-08-05 15:40:38.000000000,2014-08-08 11:55:32.000000000,2014-08-05 19:42:53.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-08-05 15:40:38.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/tests/tests_strength/test_master_node_failover.py', 'fuelweb_test/tests/test_simple.py', 'fuelweb_test/tests/test_environment_action.py', 'fuelweb_test/tests/test_upgrade.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/124ea87f1ac1c06e27613fe3b31fd5fc6b39e82d', 'message': 'Refactor network verification method\n\n- Add default timeout to verify_network method\n- Change run_network_verify to verify_netwrok in tests\n\nChange-Id: I7631145380f1443117c15519dada5232d9b23217\nCloses-Bug: #1352217\n'}]",1,112048,124ea87f1ac1c06e27613fe3b31fd5fc6b39e82d,11,6,1,10136,,,0,"Refactor network verification method

- Add default timeout to verify_network method
- Change run_network_verify to verify_netwrok in tests

Change-Id: I7631145380f1443117c15519dada5232d9b23217
Closes-Bug: #1352217
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/48/112048/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/tests/tests_strength/test_master_node_failover.py', 'fuelweb_test/tests/test_simple.py', 'fuelweb_test/tests/test_environment_action.py', 'fuelweb_test/tests/test_upgrade.py']",5,124ea87f1ac1c06e27613fe3b31fd5fc6b39e82d,refactorNetworkVerify, self.fuel_web.verify_network(cluster_id)," task = self.fuel_web.run_network_verify(cluster_id) self.fuel_web.assert_task_success(task, 60 * 2, interval=10)",10,18
openstack%2Fcloudkitty~master~Ief393d39c2beb13f4ee7cf675633b92387c36b22,openstack/cloudkitty,master,Ief393d39c2beb13f4ee7cf675633b92387c36b22,Moved base billing code,MERGED,2014-08-08 11:39:33.000000000,2014-08-08 11:54:14.000000000,2014-08-08 11:54:14.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-08 11:39:33.000000000', 'files': ['cloudkitty/billing/hash.py', 'cloudkitty/billing/__init__.py', 'cloudkitty/billing/noop.py', 'cloudkitty/billing/base.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/4c440984d60df1e70c9e73bdbee6acea4e397852', 'message': 'Moved base billing code\n\nBase class is now abstract using abc.\n\nChange-Id: Ief393d39c2beb13f4ee7cf675633b92387c36b22\n'}]",0,112830,4c440984d60df1e70c9e73bdbee6acea4e397852,7,2,1,7042,,,0,"Moved base billing code

Base class is now abstract using abc.

Change-Id: Ief393d39c2beb13f4ee7cf675633b92387c36b22
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/30/112830/1 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/billing/hash.py', 'cloudkitty/billing/__init__.py', 'cloudkitty/billing/noop.py', 'cloudkitty/billing/base.py']",4,4c440984d60df1e70c9e73bdbee6acea4e397852,move/billing/base,,"# -*- coding: utf-8 -*- # Copyright 2014 Objectif Libre # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # @author: Stphane Albert # class BaseBillingProcessor(object): def __init__(self): raise NotImplementedError() def process(self, data): raise NotImplementedError() ",40,29
openstack%2Ftripleo-image-elements~master~Ie14fd68a49d7312d3817c25a305eca7a2aa9c9cf,openstack/tripleo-image-elements,master,Ie14fd68a49d7312d3817c25a305eca7a2aa9c9cf,Fix pacemaker cluster configuration,MERGED,2014-07-08 08:52:41.000000000,2014-08-08 11:51:45.000000000,2014-08-08 11:51:45.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 7471}, {'_account_id': 7582}, {'_account_id': 7585}, {'_account_id': 8399}, {'_account_id': 8449}]","[{'number': 1, 'created': '2014-07-08 08:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ea23b9a10d4ca20b9c96b1c892d8b08d79cbab0b', 'message': 'Fix pacemaker cluster configuration\n\n* replaces crm with crm_attribute, crm is a separate tool which is not\n  available for redhat distros. crm_attribute should be available in all\n  supported distros.\n* cluster configuration is done only once on bootstrap host\n\nChange-Id: Ie14fd68a49d7312d3817c25a305eca7a2aa9c9cf\n'}, {'number': 2, 'created': '2014-07-09 11:00:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/713dcd9de301e1cd3b69496ed6cc979daebbd413', 'message': 'Fix pacemaker cluster configuration\n\n* replaces crm with crm_attribute, crm is a separate tool which is not\n  available for redhat distros. crm_attribute should be available in all\n  supported distros.\n* cluster configuration is done only once on bootstrap host\n* adds sleep to let pacemaker start up properly\n\nChange-Id: Ie14fd68a49d7312d3817c25a305eca7a2aa9c9cf\n'}, {'number': 3, 'created': '2014-08-07 12:06:08.000000000', 'files': ['elements/pacemaker/element-deps', 'elements/pacemaker/os-refresh-config/post-configure.d/15-pacemaker', 'elements/pacemaker/os-refresh-config/post-configure.d/16-base-opts-pacemaker'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/4ded514788a296cd338ea9b2c2a5b772e770f840', 'message': 'Fix pacemaker cluster configuration\n\n* replaces crm with crm_attribute, crm is a separate tool which is not\n  available for redhat distros. crm_attribute should be available in all\n  supported distros.\n* cluster configuration is done only once on bootstrap host\n* adds sleep to let pacemaker start up properly\n\nChange-Id: Ie14fd68a49d7312d3817c25a305eca7a2aa9c9cf\n'}]",5,105396,4ded514788a296cd338ea9b2c2a5b772e770f840,57,9,3,7582,,,0,"Fix pacemaker cluster configuration

* replaces crm with crm_attribute, crm is a separate tool which is not
  available for redhat distros. crm_attribute should be available in all
  supported distros.
* cluster configuration is done only once on bootstrap host
* adds sleep to let pacemaker start up properly

Change-Id: Ie14fd68a49d7312d3817c25a305eca7a2aa9c9cf
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/96/105396/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/pacemaker/element-deps', 'elements/pacemaker/os-refresh-config/post-configure.d/16-base-opts-pacemaker']",2,ea23b9a10d4ca20b9c96b1c892d8b08d79cbab0b,pcmk2,"if os-is-bootstrap-host; then QUORUM_POLICY=$(os-apply-config --key pacemaker.quorum_policy --type raw --key-default ignore) RECHECK_INTERVAL=$(os-apply-config --key pacemaker.recheck_interval --type raw --key-default 5) STONITH_ENABLED=$(os-apply-config --key pacemaker.stonith_enabled --type raw --key-default false) crm_attribute -t crm_config -n stonith-enabled -v $STONITH_ENABLED crm_attribute -t crm_config -n no-quorum-policy -v $QUORUM_POLICY crm_attribute -t crm_config -n cluster-recheck-interval -v ""${RECHECK_INTERVAL}min"" fi","QUORUM_POLICY=$(os-apply-config --key pacemaker.quorum_policy --type raw --key-default ignore) RECHECK_INTERVAL=$(os-apply-config --key pacemaker.recheck_interval --type raw --key-default 5) STONITH_ENABLED=$(os-apply-config --key pacemaker.stonith_enabled --type raw --key-default false) crm configure property no-quorum-policy=$QUORUM_POLICY \ cluster-recheck-interval=$RECHECK_INTERVAL""min"" \ stonith-enabled=$STONITH_ENABLED",9,6
openstack%2Foperations-guide~master~If55d31c63c0aafb943c5d1efa3dfdd92ed3af2a2,openstack/operations-guide,master,If55d31c63c0aafb943c5d1efa3dfdd92ed3af2a2,Imported Translations from Transifex,MERGED,2014-08-06 06:01:07.000000000,2014-08-08 11:50:53.000000000,2014-08-08 11:50:53.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-06 06:01:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/b29f560061945b27bb2f0dbb2eaf373251de290c', 'message': 'Imported Translations from Transifex\n\nChange-Id: If55d31c63c0aafb943c5d1efa3dfdd92ed3af2a2\n'}, {'number': 2, 'created': '2014-08-07 06:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/8d846004320a3378cdda869cd378892faeee7c2c', 'message': 'Imported Translations from Transifex\n\nChange-Id: If55d31c63c0aafb943c5d1efa3dfdd92ed3af2a2\n'}, {'number': 3, 'created': '2014-08-08 06:01:03.000000000', 'files': ['doc/openstack-ops/locale/openstack-ops.pot'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/63ab54d7dfdb6a8a39e89475af3e18fc88f2f8d6', 'message': 'Imported Translations from Transifex\n\nChange-Id: If55d31c63c0aafb943c5d1efa3dfdd92ed3af2a2\n'}]",0,112203,63ab54d7dfdb6a8a39e89475af3e18fc88f2f8d6,15,3,3,11131,,,0,"Imported Translations from Transifex

Change-Id: If55d31c63c0aafb943c5d1efa3dfdd92ed3af2a2
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/03/112203/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/locale/openstack-ops.pot'],1,b29f560061945b27bb2f0dbb2eaf373251de290c,transifex/translations,"""POT-Creation-Date: 2014-08-06 06:01+0000\n""#: ./doc/openstack-ops/ch_ops_upgrades.xml:331(title) ./doc/openstack-ops/ch_ops_upgrades.xml:716(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1095(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1533(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:340(title) ./doc/openstack-ops/ch_ops_upgrades.xml:725(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1104(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1542(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:350(title) ./doc/openstack-ops/ch_ops_upgrades.xml:735(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1112(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1550(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:352(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1551(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:361(para) ./doc/openstack-ops/ch_ops_upgrades.xml:745(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1121(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1560(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:365(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1124(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1563(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:372(title) ./doc/openstack-ops/ch_ops_upgrades.xml:756(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1137(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1576(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1096(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1534(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1138(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1577(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1149(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1592(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1152(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1595(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1160(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1603(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1187(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1629(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1188(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1630(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1213(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1645(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1214(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1646(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1222(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1654(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1223(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1655(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1225(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1657(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1228(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1266(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1660(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1698(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1229(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1661(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1232(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1307(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1418(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1664(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1735(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1852(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1240(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1672(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1243(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1327(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1755(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1260(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1293(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1430(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1692(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1721(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1864(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1262(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1694(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1267(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1699(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1270(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1702(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1281(replaceable) ./doc/openstack-ops/ch_ops_upgrades.xml:1407(replaceable) ./doc/openstack-ops/ch_ops_upgrades.xml:1411(replaceable) ./doc/openstack-ops/ch_ops_upgrades.xml:1710(replaceable) ./doc/openstack-ops/ch_ops_upgrades.xml:1841(replaceable) ./doc/openstack-ops/ch_ops_upgrades.xml:1845(replaceable)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1283(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1711(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1292(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1720(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1295(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1723(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1300(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1728(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1302(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1730(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1324(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1752(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1325(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1753(para) msgid ""Before upgrading the Networking database, you must convert the character set for each table to UTF-8."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml:1364(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1792(para) msgid ""Your environment might use a different database name. Also, it might contain different or additional tables that you must also convert to UTF-8 by using similar commands."" msgstr """" #: ./doc/openstack-ops/ch_ops_upgrades.xml:1369(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1799(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1375(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1809(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1377(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1811(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1380(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1814(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1391(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1825(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1395(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1829(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1409(replaceable) ./doc/openstack-ops/ch_ops_upgrades.xml:1843(replaceable)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1410(replaceable) ./doc/openstack-ops/ch_ops_upgrades.xml:1844(replaceable)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1413(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1847(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1417(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1851(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1429(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1863(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1432(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1435(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1869(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1439(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1873(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1443(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1877(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1447(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1881(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1448(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1882(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1450(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1477(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1503(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1884(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1915(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1945(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1456(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1483(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1891(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1922(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1461(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1488(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1896(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1927(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1465(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1492(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1903(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1934(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1467(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1494(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1905(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1936(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1474(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1912(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1475(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1913(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1496(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1938(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1500(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1942(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1501(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1943(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1509(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1950(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1515(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1518(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1543(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1566(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1583(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1586(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1596(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1600(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1611(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1612(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1623(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1634(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1673(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1675(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1688(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1705(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1725(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1797(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1889(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1920(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1805(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1900(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1931(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1866(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1955(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1957(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1963(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1967(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1971(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1980(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1985(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1987(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1999(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2008(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2013(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2017(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2021(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2025(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2037(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2042(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2045(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2049(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2056(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2063(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2075(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2078(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2085(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2133(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2140(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2171(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2223(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2230(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2239(para)","""POT-Creation-Date: 2014-08-05 06:01+0000\n""#: ./doc/openstack-ops/ch_ops_upgrades.xml:331(title) ./doc/openstack-ops/ch_ops_upgrades.xml:716(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1095(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1489(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:340(title) ./doc/openstack-ops/ch_ops_upgrades.xml:725(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1104(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1498(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:350(title) ./doc/openstack-ops/ch_ops_upgrades.xml:735(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1112(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1506(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:352(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1507(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:361(para) ./doc/openstack-ops/ch_ops_upgrades.xml:745(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1121(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1516(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:365(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1124(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1519(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:372(title) ./doc/openstack-ops/ch_ops_upgrades.xml:756(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1137(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1532(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1096(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1490(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1138(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1533(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1149(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1548(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1152(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1551(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1160(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1559(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1187(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1585(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1188(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1586(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1213(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1601(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1214(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1602(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1222(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1610(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1223(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1611(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1225(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1613(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1228(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1266(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1616(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1654(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1229(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1617(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1232(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1307(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1374(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1620(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1691(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1764(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1240(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1628(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1243(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1260(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1293(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1386(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1648(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1677(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1776(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1262(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1650(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1267(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1655(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1270(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1658(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1281(replaceable) ./doc/openstack-ops/ch_ops_upgrades.xml:1363(replaceable) ./doc/openstack-ops/ch_ops_upgrades.xml:1367(replaceable) ./doc/openstack-ops/ch_ops_upgrades.xml:1666(replaceable) ./doc/openstack-ops/ch_ops_upgrades.xml:1753(replaceable) ./doc/openstack-ops/ch_ops_upgrades.xml:1757(replaceable)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1283(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1667(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1292(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1676(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1295(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1679(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1300(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1684(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1302(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1686(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1324(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1708(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1325(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1711(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1331(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1721(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1333(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1723(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1336(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1726(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1347(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1737(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1351(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1741(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1365(replaceable) ./doc/openstack-ops/ch_ops_upgrades.xml:1755(replaceable)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1366(replaceable) ./doc/openstack-ops/ch_ops_upgrades.xml:1756(replaceable)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1369(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1759(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1373(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1763(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1385(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1775(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1388(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1391(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1781(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1395(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1785(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1399(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1789(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1403(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1793(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1404(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1794(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1406(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1433(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1459(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1796(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1827(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1857(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1412(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1439(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1803(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1834(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1417(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1444(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1808(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1839(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1421(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1448(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1815(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1846(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1423(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1450(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1817(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1848(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1430(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1824(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1431(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1825(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1452(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1850(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1456(title) ./doc/openstack-ops/ch_ops_upgrades.xml:1854(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1457(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1855(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1465(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1862(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1471(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1474(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1499(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1522(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1539(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1542(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1552(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1556(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1567(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1568(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1579(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1590(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1629(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1631(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1644(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1661(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1681(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1709(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1801(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1832(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1717(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1812(para) ./doc/openstack-ops/ch_ops_upgrades.xml:1843(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1778(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1867(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1869(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1875(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1879(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1883(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1892(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1897(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1899(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1911(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1920(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1925(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1929(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1933(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1937(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1949(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1954(title)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1957(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1961(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1968(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1975(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1987(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1990(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:1997(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2045(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2052(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2083(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2135(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2142(para)#: ./doc/openstack-ops/ch_ops_upgrades.xml:2151(para)",121,113
openstack%2Ffuel-main~master~I3c95490fdd425b409292ce9550d3817d22c2caca,openstack/fuel-main,master,I3c95490fdd425b409292ce9550d3817d22c2caca,Change sleep method to wait in 'setup_environment',MERGED,2014-07-24 12:54:41.000000000,2014-08-08 11:46:25.000000000,2014-07-29 13:51:17.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8965}, {'_account_id': 8971}, {'_account_id': 10068}, {'_account_id': 10136}]","[{'number': 1, 'created': '2014-07-24 12:54:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/01bb3aa74b10736ceda05bafdfe722bb532a1720', 'message': ""Change sleep method to wait in 'setup_environment'\n\nImproves the environment setup by decreasing the time taken to boot the node up of an image and ensuring that it in fact is running.\n\nChange-Id: I3c95490fdd425b409292ce9550d3817d22c2caca\nCloses-Bug: #1319071\n""}, {'number': 2, 'created': '2014-07-24 13:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1b627492b59fc46455d5fcababd15b8ec894b433', 'message': ""Change sleep method to wait in 'setup_environment'\n\nImproves the environment setup by decreasing the time taken to boot the node up of an image and ensuring that it in fact is running.\n\nChange-Id: I3c95490fdd425b409292ce9550d3817d22c2caca\nCloses-Bug: #1319071\n""}, {'number': 3, 'created': '2014-07-24 13:13:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c723eae040ba55cd273a1750226d0b64e2309bab', 'message': ""Change sleep method to wait in 'setup_environment'\n\nImproves the environment setup by decreasing the time taken to boot the node up of an image and ensuring that it in fact is running.\n\nDepends on: https://review.openstack.org/#/c/109282/\n\nChange-Id: I3c95490fdd425b409292ce9550d3817d22c2caca\nCloses-Bug: #1319071\n""}, {'number': 4, 'created': '2014-07-25 12:15:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7d12c7afbbb549f4529d8ef1986927d61fc011fe', 'message': ""Change sleep method to wait in 'setup_environment'\n\nImproves the environment setup by decreasing the\ntime taken to boot the node up of an image and ensuringi\nthat it in fact is running.\n\nChanged simple sleep timeout to check VM activity.\n\nChange-Id: I3c95490fdd425b409292ce9550d3817d22c2caca\nCloses-Bug: #1319071\n""}, {'number': 5, 'created': '2014-07-25 12:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4666ce595998a4a907e0025025dc6c2fd8d6334c', 'message': ""Change sleep method to wait in 'setup_environment'\n\nChanged simple sleep timeout to wait.\n\nChange-Id: I3c95490fdd425b409292ce9550d3817d22c2caca\nCloses-Bug: #1319071\n""}, {'number': 6, 'created': '2014-07-25 14:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ec3b81a8bb2e3ded2f60ec76b25d320acbdeb181', 'message': ""Change sleep method to wait in 'setup_environment'\n\nChanged simple sleep timeout to wait.\n\nChange-Id: I3c95490fdd425b409292ce9550d3817d22c2caca\nCloses-Bug: #1319071\n""}, {'number': 7, 'created': '2014-07-28 12:04:30.000000000', 'files': ['fuelweb_test/models/environment.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d821b6db1d82094021a084f7c04bf5a81dcbb75c', 'message': ""Change sleep method to wait in 'setup_environment'\n\nChanged simple sleep timeout to wait.\n\nChange-Id: I3c95490fdd425b409292ce9550d3817d22c2caca\nCloses-Bug: #1319071\n""}]",5,109277,d821b6db1d82094021a084f7c04bf5a81dcbb75c,51,7,7,12129,,,0,"Change sleep method to wait in 'setup_environment'

Changed simple sleep timeout to wait.

Change-Id: I3c95490fdd425b409292ce9550d3817d22c2caca
Closes-Bug: #1319071
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/77/109277/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/environment.py'],1,01bb3aa74b10736ceda05bafdfe722bb532a1720,setup-master-node-timeout-to-wait," time_waited = self.wait_node_active(admin) logger.info('Waited for admin node to start up for %s' % round(time_waited, 2)) #Now that we are sure the VM is started wait for a second for it to boot up of an image time.sleep(1) def wait_node_active(self, node): logger.info(""Waiting for admin node to start up"") return wait(node.active, timeout=60) ", time.sleep(float(settings.ADMIN_NODE_SETUP_TIMEOUT)),8,1
openstack%2Fsahara~stable%2Ficehouse~I4028ff177766c0d6e46d1308b774250375039b10,openstack/sahara,stable/icehouse,I4028ff177766c0d6e46d1308b774250375039b10,Fix closing HTTP session in Ambari plugin,MERGED,2014-08-06 14:49:13.000000000,2014-08-08 11:45:23.000000000,2014-08-08 11:45:23.000000000,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 7710}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-08-06 14:49:13.000000000', 'files': ['sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py', 'sahara/utils/ssh_remote.py', 'sahara/utils/remote.py', 'sahara/plugins/hdp/ambariplugin.py', 'sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/0611cd578ecd52de207fe378b68d6b3856d317cc', 'message': 'Fix closing HTTP session in Ambari plugin\n\nChange-Id: I4028ff177766c0d6e46d1308b774250375039b10\nCloses-bug: #1350388\n(cherry picked from commit 85fecd81ffe79cba8171308954819cfdb902e9fd)\n'}]",0,112321,0611cd578ecd52de207fe378b68d6b3856d317cc,16,6,1,7710,,,0,"Fix closing HTTP session in Ambari plugin

Change-Id: I4028ff177766c0d6e46d1308b774250375039b10
Closes-bug: #1350388
(cherry picked from commit 85fecd81ffe79cba8171308954819cfdb902e9fd)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/21/112321/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py', 'sahara/utils/ssh_remote.py', 'sahara/utils/remote.py', 'sahara/plugins/hdp/ambariplugin.py', 'sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py']",5,0611cd578ecd52de207fe378b68d6b3856d317cc,ambari-st,"from sahara import exceptions as exc try: ambari_info.host.remote().close_http_session(ambari_info.port) except exc.NotFoundException: LOG.info(""HTTP session is not cached"")", ambari_info.host.remote().close_http_sessions(),30,12
openstack%2Ffuel-main~master~I743ef9bcf5c1f874bb9e6fbe73a059e3b0ca6240,openstack/fuel-main,master,I743ef9bcf5c1f874bb9e6fbe73a059e3b0ca6240,Add check_run method to deploy_ha case,MERGED,2014-08-07 11:25:12.000000000,2014-08-08 11:45:03.000000000,2014-08-08 11:23:02.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-08-07 11:25:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a360066e7d1a9848f521a6cf19f64cf95989186c', 'message': 'Add check_run method to deploy_ha case\n\nAdd check_run method to deploy_ha case\nto save time on run in case if\ndeploy_ha snapshot already exists.\n\nChange-Id: I743ef9bcf5c1f874bb9e6fbe73a059e3b0ca6240\nCloses-Bug: #1353843\n'}, {'number': 2, 'created': '2014-08-07 12:29:21.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_failover.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c20e0bbd98d040798f14bbc6c0cefc3464e2faad', 'message': 'Add check_run method to deploy_ha case\n\nAdd check_run method to deploy_ha case\nto save time on run in case if\ndeploy_ha snapshot already exists.\n\nChange-Id: I743ef9bcf5c1f874bb9e6fbe73a059e3b0ca6240\nCloses-Bug: #1353843\n'}]",0,112557,c20e0bbd98d040798f14bbc6c0cefc3464e2faad,17,4,2,12129,,,0,"Add check_run method to deploy_ha case

Add check_run method to deploy_ha case
to save time on run in case if
deploy_ha snapshot already exists.

Change-Id: I743ef9bcf5c1f874bb9e6fbe73a059e3b0ca6240
Closes-Bug: #1353843
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/57/112557/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/tests_strength/test_failover.py'],1,a360066e7d1a9848f521a6cf19f64cf95989186c,check_run_ha_fix," self.check_run(""deploy_ha"")",,1,0
openstack%2Ffuel-main~master~Ifd9da3c4563052f0894c60aa0bbbc0d78dea43d4,openstack/fuel-main,master,Ifd9da3c4563052f0894c60aa0bbbc0d78dea43d4,Add --switch-to-version parameter for upgrade.sh script,MERGED,2014-08-07 14:57:29.000000000,2014-08-08 11:43:26.000000000,2014-08-08 11:43:25.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 10391}]","[{'number': 1, 'created': '2014-08-07 14:57:29.000000000', 'files': ['upgrade/upgrade_template.sh'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f202f6a67adce5da9a80f792e87b3c3e82421255', 'message': 'Add --switch-to-version parameter for upgrade.sh script\n\nNow user or developer can switch to\nspecific version of fuel containers.\n\nChange-Id: Ifd9da3c4563052f0894c60aa0bbbc0d78dea43d4\nCloses-bug: #1354038\n'}]",0,112602,f202f6a67adce5da9a80f792e87b3c3e82421255,11,5,1,8749,,,0,"Add --switch-to-version parameter for upgrade.sh script

Now user or developer can switch to
specific version of fuel containers.

Change-Id: Ifd9da3c4563052f0894c60aa0bbbc0d78dea43d4
Closes-bug: #1354038
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/02/112602/1 && git format-patch -1 --stdout FETCH_HEAD,['upgrade/upgrade_template.sh'],1,f202f6a67adce5da9a80f792e87b3c3e82421255,bug/1354038,"function switch_to_version { version=$1 version_path=/etc/fuel/$version/version.yaml if [ ! -f $version_path ]; then error ""Version ${version} not found"" fi # Replace symlink to current version ln -sf $version_path /etc/fuel/version.yaml # Replace symlink to supervisor scripts ln -nsf /etc/supervisord.d/$version /etc/supervisord.d/current # Stop all supervisor services supervisorctl stop all & # And at the same time stop all docker containers docker stop -t=4 $(docker ps -q) # Restart supervisor service supervisord restart exit } function show_version {} function upgrade { (flock -n 9 || error ""Upgrade is already running. Lock file: ${LOCK_FILE}"" run_upgrade ""$@"" ) 9> $LOCK_FILE } case ""$1"" in --switch-to-version) case ""$2"" in """") error '--switch-to-version requires parameter' ;; *) switch_to_version $2 ; exit ;; esac ;; --version) show_version ; exit ;; *) upgrade ""$@"" ; exit ;; esac","if [ ""$1"" == ""--version"" ]; thenfi (flock -n 9 || error ""Upgrade is already running. Lock file: ${LOCK_FILE}"" run_upgrade ""$@"" ) 9> $LOCK_FILE",42,5
openstack%2Fpuppet-glance~stable%2Fhavana~Idc47b6bda3ea38e582501278f82c9c6841b8cdf0,openstack/puppet-glance,stable/havana,Idc47b6bda3ea38e582501278f82c9c6841b8cdf0,Introduce glance:config to manage custom options,MERGED,2014-06-02 15:59:03.000000000,2014-08-08 11:37:24.000000000,2014-08-08 11:37:24.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 6994}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-06-02 15:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/a7a0755370f07042a5f010ce7ae48f355361ecf9', 'message': 'Introduce glance:config to manage custom options\n\nThis glance::config is aim to use glance_config resources\nto manage custom configurations in glance config files.\n\nThis will make end user easy to add their own custom options\nin Hiera data.\n\nFully implements blueprint glance-custom-config\n\n(cherry-picked from 11f5e87a0fe9f9adefcc2b814c4d26950f7dd760)\nChange-Id: Idc47b6bda3ea38e582501278f82c9c6841b8cdf0\n'}, {'number': 2, 'created': '2014-08-06 19:46:26.000000000', 'files': ['manifests/config.pp'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/5d7ec93d00fad01bc12f65d6b69d5ad57ae08583', 'message': 'Introduce glance:config to manage custom options\n\nThis glance::config is aim to use glance_config resources\nto manage custom configurations in glance config files.\n\nThis will make end user easy to add their own custom options\nin Hiera data.\n\nFully implements blueprint glance-custom-config\n\n(cherry-picked from 11f5e87a0fe9f9adefcc2b814c4d26950f7dd760)\nChange-Id: Idc47b6bda3ea38e582501278f82c9c6841b8cdf0\n'}]",0,97276,5d7ec93d00fad01bc12f65d6b69d5ad57ae08583,16,4,2,4128,,,0,"Introduce glance:config to manage custom options

This glance::config is aim to use glance_config resources
to manage custom configurations in glance config files.

This will make end user easy to add their own custom options
in Hiera data.

Fully implements blueprint glance-custom-config

(cherry-picked from 11f5e87a0fe9f9adefcc2b814c4d26950f7dd760)
Change-Id: Idc47b6bda3ea38e582501278f82c9c6841b8cdf0
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/76/97276/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/config.pp'],1,a7a0755370f07042a5f010ce7ae48f355361ecf9,bp/glance-custom-config,"# == Class: glance::config # # This class is used to manage arbitrary glance configurations. # # === Parameters # # [*xxx_config*] # (optional) Allow configuration of arbitrary glance configurations. # The value is an hash of glance_config resources. Example: # { 'DEFAULT/foo' => { value => 'fooValue'}, # 'DEFAULT/bar' => { value => 'barValue'} # } # In yaml format, Example: # glance_config: # DEFAULT/foo: # value: fooValue # DEFAULT/bar: # value: barValue # # [**api_config**] # (optional) Allow configuration of glance-api.conf configurations. # # [**api_paste_ini_config**] # (optional) Allow configuration of glance-api-paste.ini configurations. # # [**registry_config**] # (optional) Allow configuration of glance-registry.conf configurations. # # [**registry_paste_ini_config**] # (optional) Allow configuration of glance-registry-paste.ini configurations. # # [**cache_config**] # (optional) Allow configuration of glance-cache.conf configurations. # # NOTE: The configuration MUST NOT be already handled by this module # or Puppet catalog compilation will fail with duplicate resources. # class glance::config ( $api_config = {}, $api_paste_ini_config = {}, $registry_config = {}, $registry_paste_ini_config = {}, $cache_config = {}, ) { validate_hash($api_config) validate_hash($api_paste_ini_config) validate_hash($registry_config) validate_hash($registry_paste_ini_config) validate_hash($cache_config) create_resources('glance_api_config', $api_config) create_resources('glance_api_paste_ini', $api_paste_ini_config) create_resources('glance_registry_config', $registry_config) create_resources('glance_registry_paste_ini', $registry_paste_ini_config) create_resources('glance_cache_config', $cache_config) } ",,56,0
openstack%2Frally~master~I520b08202910ad476447fa09ca0a5993fc1bffc5,openstack/rally,master,I520b08202910ad476447fa09ca0a5993fc1bffc5,Amended sphinx documents,MERGED,2014-07-30 17:57:43.000000000,2014-08-08 11:34:56.000000000,2014-08-08 11:34:55.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 9545}, {'_account_id': 9601}, {'_account_id': 11105}]","[{'number': 1, 'created': '2014-07-30 17:57:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/cfa558e781e0f089636c944a507172429a03ec44', 'message': 'Sphinx documentation addition\n\n  Added overview paragraph from Rally wiki page.\n  Amended index page with some common info.\n  Pictures added.\n\nChange-Id: I520b08202910ad476447fa09ca0a5993fc1bffc5\n'}, {'number': 2, 'created': '2014-07-31 17:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/152b1139eafd53954123e8242fee7c4b701e5745', 'message': 'Amended sphinx documents\n\nChange-Id: I520b08202910ad476447fa09ca0a5993fc1bffc5\n'}, {'number': 3, 'created': '2014-08-04 09:26:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8758c1b90e5435bab364106ade331f4575f6df5a', 'message': 'Amended sphinx documents\n\nChange-Id: I520b08202910ad476447fa09ca0a5993fc1bffc5\n'}, {'number': 4, 'created': '2014-08-04 19:05:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f43bdceb1aa63084a0f63280cb5950466a3f4a79', 'message': 'Amended sphinx documents\n\nChange-Id: I520b08202910ad476447fa09ca0a5993fc1bffc5\n'}, {'number': 5, 'created': '2014-08-06 12:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/cbebe9b8fb8c5efed4f703843f49b5852461097a', 'message': 'Amended sphinx documents\n\nChange-Id: I520b08202910ad476447fa09ca0a5993fc1bffc5\n'}, {'number': 6, 'created': '2014-08-07 15:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/84a9863a11d7f485ebf9b282d6b565e5313798e0', 'message': 'Amended sphinx documents\n\n  Updated from https://wiki.openstack.org/wiki/Rally\n\nChange-Id: I520b08202910ad476447fa09ca0a5993fc1bffc5\n'}, {'number': 7, 'created': '2014-08-07 15:35:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bd6b6a86013327bde5cd14cd93b28e441c9ed67f', 'message': 'Amended sphinx documents\n\n  Updated from https://wiki.openstack.org/wiki/Rally\n\nChange-Id: I520b08202910ad476447fa09ca0a5993fc1bffc5\n'}, {'number': 8, 'created': '2014-08-07 17:10:02.000000000', 'files': ['doc/source/images/Rally-UseCases.png', 'doc/source/images/Rally-Actions.png', 'doc/source/deploy_engines.rst', 'doc/source/overview.rst', 'doc/source/deploy.rst', 'doc/source/improve_rally.rst', 'doc/source/usage.rst', 'doc/source/images/Rally_VM_list.png', 'doc/source/images/Amqp_rpc_single_reply_queue.png', 'doc/source/rally_gatejob.rst', 'doc/source/server_providers.rst', 'doc/source/installation.rst', 'doc/source/images/Rally_QA.png', 'doc/source/index.rst', 'doc/source/concepts.rst', 'doc/source/images/Rally_snapshot_vm.png', 'doc/source/images/Rally_Architecture.png'], 'web_link': 'https://opendev.org/openstack/rally/commit/c4269ec970bfe7a6f49e6e2ea778bc145219e6d9', 'message': 'Amended sphinx documents\n\n  Updated from https://wiki.openstack.org/wiki/Rally\n\nChange-Id: I520b08202910ad476447fa09ca0a5993fc1bffc5\n'}]",16,110738,c4269ec970bfe7a6f49e6e2ea778bc145219e6d9,46,8,8,9601,,,0,"Amended sphinx documents

  Updated from https://wiki.openstack.org/wiki/Rally

Change-Id: I520b08202910ad476447fa09ca0a5993fc1bffc5
",git fetch https://review.opendev.org/openstack/rally refs/changes/38/110738/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/images/Rally_QA.png', 'doc/source/images/Rally-UseCases.png', 'doc/source/index.rst', 'doc/source/images/Rally-Actions.png', 'doc/source/overview.rst', 'doc/source/images/Rally_VM_list.png', 'doc/source/images/Amqp_rpc_single_reply_queue.png', 'doc/source/images/Rally_snapshot_vm.png', 'doc/source/images/Rally_Architecture.png']",9,cfa558e781e0f089636c944a507172429a03ec44,fix_doc_sidemenu,,,168,5
openstack%2Fnova~master~I9a6de0f993222c1921a0fc4d13ec14d875af2ed1,openstack/nova,master,I9a6de0f993222c1921a0fc4d13ec14d875af2ed1,Move check_image_exists out of try in _inject_data,MERGED,2014-07-30 14:29:30.000000000,2014-08-08 11:32:39.000000000,2014-08-08 01:54:46.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 7641}, {'_account_id': 8412}, {'_account_id': 8787}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-07-30 14:29:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ae6d35f135347da0857f5ecedadaec9299b73a0f', 'message': 'Remove check_image_exists out of try\n\nChange-Id: I9a6de0f993222c1921a0fc4d13ec14d875af2ed1\n'}, {'number': 2, 'created': '2014-07-31 02:12:48.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1d24e2cb63f6656f4300f9ad6182c5af7990fe73', 'message': 'Move check_image_exists out of try in _inject_data\n\nMove check_image_exists out of try in _inject_data and some typo fixes\n\nChange-Id: I9a6de0f993222c1921a0fc4d13ec14d875af2ed1\n'}]",3,110663,1d24e2cb63f6656f4300f9ad6182c5af7990fe73,39,14,2,12175,,,0,"Move check_image_exists out of try in _inject_data

Move check_image_exists out of try in _inject_data and some typo fixes

Change-Id: I9a6de0f993222c1921a0fc4d13ec14d875af2ed1
",git fetch https://review.opendev.org/openstack/nova refs/changes/63/110663/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,ae6d35f135347da0857f5ecedadaec9299b73a0f,inject," """"""Injects data in a disk image suffix -- a string used as an image name suffix if not injection_image.check_image_exists(): LOG.warn(_LW('Image %s not found on disk storage. ' 'Continue without injecting data'), injection_image.path, instance=instance) return try: disk.inject_data(injection_image.path, key, net, metadata, admin_pass, files, partition=target_partition, use_cow=CONF.use_cow_images, mandatory=('files',))"," """"""Injects data in an disk image suffix -- a string used as a image name suffix try: if injection_image.check_image_exists(): disk.inject_data(injection_image.path, key, net, metadata, admin_pass, files, partition=target_partition, use_cow=CONF.use_cow_images, mandatory=('files',)) else: LOG.warn(_LW('Image %s not found on disk storage. ' 'Continue without injecting data'), injection_image.path, instance=instance)",12,12
openstack%2Fhorizon~master~I1b0415bcd5d9b5b0e3f1328f0289c4ca381e02cd,openstack/horizon,master,I1b0415bcd5d9b5b0e3f1328f0289c4ca381e02cd,Cleans up the translation,MERGED,2014-08-06 18:18:15.000000000,2014-08-08 11:30:46.000000000,2014-08-08 11:30:45.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 4978}, {'_account_id': 6610}, {'_account_id': 6914}, {'_account_id': 9622}]","[{'number': 1, 'created': '2014-08-06 18:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3bef1fa3db9f4ca00c90ba0aca63295c72f27fd9', 'message': 'Cleans up the translation\n\nReplaces translation.ungettext_lazy with\nungettext_lazy by importing ungettext_lazy from django.utils.translation\nReplaces translation.ugettext_lazy with _\nby importing ugettext_lazy as _ from django.utils.translation\n\nCloses-Bug: 1351478\n\nChange-Id: I1b0415bcd5d9b5b0e3f1328f0289c4ca381e02cd\n'}, {'number': 2, 'created': '2014-08-06 19:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c7bc34d29d5ec4fe7b8dd8e8d50d0c4a4a82a883', 'message': 'Cleans up the translation\n\nReplaces translation.ungettext_lazy with\nungettext_lazy by importing ungettext_lazy from django.utils.translation\nReplaces translation.ugettext_lazy with _\nby importing ugettext_lazy as _ from django.utils.translation\nChange is done\n\nCloses-Bug: 1351478\n\nChange-Id: I1b0415bcd5d9b5b0e3f1328f0289c4ca381e02cd\n'}, {'number': 3, 'created': '2014-08-07 14:01:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5434487a3787bc19c79f77786a7566f253cc110f', 'message': 'Cleans up the translation\n\nReplaces translation.ungettext_lazy with\nungettext_lazy by importing ungettext_lazy from django.utils.translation\nReplaces translation.ugettext_lazy with _\nby importing ugettext_lazy as _ from django.utils.translation\n\nCloses-Bug: 1351478\n\nChange-Id: I1b0415bcd5d9b5b0e3f1328f0289c4ca381e02cd\n'}, {'number': 4, 'created': '2014-08-08 09:36:28.000000000', 'files': ['horizon/templatetags/sizeformat.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/dd2e1997c974c3b94ca84e75df92e9baa4ccbba7', 'message': 'Cleans up the translation\n\nReplaces translation.ungettext_lazy with\nungettext_lazy by importing ungettext_lazy from django.utils.translation\nReplaces translation.ugettext_lazy with _\nby importing ugettext_lazy as _ from django.utils.translation\n\nCloses-Bug: 1351478\n\nChange-Id: I1b0415bcd5d9b5b0e3f1328f0289c4ca381e02cd\n'}]",1,112373,dd2e1997c974c3b94ca84e75df92e9baa4ccbba7,23,7,4,12485,,,0,"Cleans up the translation

Replaces translation.ungettext_lazy with
ungettext_lazy by importing ungettext_lazy from django.utils.translation
Replaces translation.ugettext_lazy with _
by importing ugettext_lazy as _ from django.utils.translation

Closes-Bug: 1351478

Change-Id: I1b0415bcd5d9b5b0e3f1328f0289c4ca381e02cd
",git fetch https://review.opendev.org/openstack/horizon refs/changes/73/112373/4 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templatetags/sizeformat.py'],1,3bef1fa3db9f4ca00c90ba0aca63295c72f27fd9,bug/1351478,"from django.utils.translation import ugettext_lazy as _ from django.utils.translation import ungettext_lazy return ungettext_lazy(""%(size)d Byte"", return ungettext_lazy(""%(size)d Byte"", return _(""%s KB"") % \ return _(""%s MB"") % \ return _(""%s GB"") % \ return _(""%s TB"") % \ return _(""%s PB"") % \","from django.utils import translation return translation.ungettext_lazy(""%(size)d Byte"", return translation.ungettext_lazy(""%(size)d Byte"", return translation.ugettext_lazy(""%s KB"") % \ return translation.ugettext_lazy(""%s MB"") % \ return translation.ugettext_lazy(""%s GB"") % \ return translation.ugettext_lazy(""%s TB"") % \ return translation.ugettext_lazy(""%s PB"") % \",9,8
openstack%2Fdevstack~master~Ie0f92c3ba5df4848a0ff101ef52139c3a16a9dec,openstack/devstack,master,Ie0f92c3ba5df4848a0ff101ef52139c3a16a9dec,remove saucy support,MERGED,2014-07-31 18:18:01.000000000,2014-08-08 11:19:09.000000000,2014-08-07 23:38:01.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 6735}, {'_account_id': 6854}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-31 18:18:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/0a3db9d37ca422730a3e7f346974d40d7d1df3c7', 'message': 'remove saucy support\n\nubuntu 13.10 is no longer supported by ubuntu. We should remove it.\n\nChange-Id: Ie0f92c3ba5df4848a0ff101ef52139c3a16a9dec\n'}, {'number': 2, 'created': '2014-08-05 21:38:05.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/ab5b5dedf854119bcb07623198c8f02d81b398b3', 'message': 'remove saucy support\n\nubuntu 13.10 is no longer supported by ubuntu. We should remove it.\n\nChange-Id: Ie0f92c3ba5df4848a0ff101ef52139c3a16a9dec\n'}]",0,111026,ab5b5dedf854119bcb07623198c8f02d81b398b3,39,7,2,2750,,,0,"remove saucy support

ubuntu 13.10 is no longer supported by ubuntu. We should remove it.

Change-Id: Ie0f92c3ba5df4848a0ff101ef52139c3a16a9dec
",git fetch https://review.opendev.org/openstack/devstack refs/changes/26/111026/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/get_uec_image.sh', 'stack.sh']",2,0a3db9d37ca422730a3e7f346974d40d7d1df3c7,cleanups,if [[ ! ${DISTRO} =~ (precise|trusty|7.0|wheezy|sid|testing|jessie|f19|f20|rhel6|rhel7) ]]; then,if [[ ! ${DISTRO} =~ (precise|saucy|trusty|7.0|wheezy|sid|testing|jessie|f19|f20|rhel6|rhel7) ]]; then,2,4
openstack%2Fcloudkitty~master~I6113b50c8f641a043ea149984293b617cbc8adb1,openstack/cloudkitty,master,I6113b50c8f641a043ea149984293b617cbc8adb1,Moved base backend code,MERGED,2014-08-08 11:04:34.000000000,2014-08-08 11:16:53.000000000,2014-08-08 11:16:53.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-08 11:04:34.000000000', 'files': ['cloudkitty/backend/__init__.py', 'cloudkitty/backend/base.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/a1b6b41f78d1697fe60da680baaf1a786e3efa47', 'message': 'Moved base backend code\n\nBase class is now abstract using abc.\n\nChange-Id: I6113b50c8f641a043ea149984293b617cbc8adb1\n'}]",0,112826,a1b6b41f78d1697fe60da680baaf1a786e3efa47,7,2,1,7042,,,0,"Moved base backend code

Base class is now abstract using abc.

Change-Id: I6113b50c8f641a043ea149984293b617cbc8adb1
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/26/112826/1 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/backend/__init__.py', 'cloudkitty/backend/base.py']",2,a1b6b41f78d1697fe60da680baaf1a786e3efa47,move/backend,,"# -*- coding: utf-8 -*- # Copyright 2014 Objectif Libre # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # @author: Stphane Albert # class BaseIOBackend(object): def __init__(self, path): self.open(path) def open(self, path): raise NotImplementedError def tell(self): raise NotImplementedError def seek(self, offset, from_what=0): # 0 beg, 1 cur, 2 end raise NotImplementedError def flush(self): raise NotImplementedError def write(self, data): raise NotImplementedError def read(self): raise NotImplementedError def close(self): raise NotImplementedError ",71,44
openstack%2Fcinder~master~I41046beb66f2a6138659ec3e4d1d3f37b37859b8,openstack/cinder,master,I41046beb66f2a6138659ec3e4d1d3f37b37859b8,Fixing LeftHand live migration error,MERGED,2014-08-07 21:14:07.000000000,2014-08-08 11:11:57.000000000,2014-08-08 11:11:56.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 7198}, {'_account_id': 9751}, {'_account_id': 11811}, {'_account_id': 12033}]","[{'number': 1, 'created': '2014-08-07 21:14:07.000000000', 'files': ['cinder/tests/test_hplefthand.py', 'cinder/volume/drivers/san/hp/hp_lefthand_rest_proxy.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b5791432e5126f47b55e958f1686d3dd474b97f6', 'message': ""Fixing LeftHand live migration error\n\nFixed a bug in the LeftHand driver that was causing an error to occur during\nlive migration of an instance that is attached to a volume. The solution was\nto make sure server access is only requested for a volume if the iSCSI\nsession doesn't already have access enabled on the LeftHand backend.\n\nChange-Id: I41046beb66f2a6138659ec3e4d1d3f37b37859b8\nCloses-Bug: 1311350\n""}]",0,112692,b5791432e5126f47b55e958f1686d3dd474b97f6,11,6,1,11903,,,0,"Fixing LeftHand live migration error

Fixed a bug in the LeftHand driver that was causing an error to occur during
live migration of an instance that is attached to a volume. The solution was
to make sure server access is only requested for a volume if the iSCSI
session doesn't already have access enabled on the LeftHand backend.

Change-Id: I41046beb66f2a6138659ec3e4d1d3f37b37859b8
Closes-Bug: 1311350
",git fetch https://review.opendev.org/openstack/cinder refs/changes/92/112692/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_hplefthand.py', 'cinder/volume/drivers/san/hp/hp_lefthand_rest_proxy.py']",2,b5791432e5126f47b55e958f1686d3dd474b97f6,bug/1311350," 1.0.5 - Fixed bug #1311350, Live-migration of an instance when attached to a volume was causing an error. VERSION = ""1.0.5"" access_already_enabled = False if volume_info['iscsiSessions'] is not None: # Extract the server id for each session to check if the # new server already has access permissions enabled. for session in volume_info['iscsiSessions']: server_id = int(session['server']['uri'].split('/')[3]) if server_id == server_info['id']: access_already_enabled = True break if not access_already_enabled: self.client.addServerAccess( volume_info['id'], server_info['id'])"," VERSION = ""1.0.4"" self.client.addServerAccess(volume_info['id'], server_info['id'])",65,4
openstack%2Ftripleo-incubator~master~Ic7059e2e37a443d871e563c4e6d6ca1515bf7c63,openstack/tripleo-incubator,master,Ic7059e2e37a443d871e563c4e6d6ca1515bf7c63,overcloud: cinder-tgt cinder-lio via EXTRA_ARGS,MERGED,2014-07-11 18:40:53.000000000,2014-08-08 11:03:55.000000000,2014-08-08 11:03:54.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 7582}, {'_account_id': 9369}]","[{'number': 1, 'created': '2014-07-11 18:40:53.000000000', 'files': ['scripts/devtest_variables.sh', 'scripts/devtest_overcloud.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/87ec9bee42ede105966618e43687e24443729b71', 'message': 'overcloud: cinder-tgt cinder-lio via EXTRA_ARGS\n\nUpdates devtest_overcloud.sh so that we set the configured\ncinder-lio and/or cinder-tgt elements via the\nOVERCLOUD_CONTROL_DIB_EXTRA_ARGS variable.\n\nAlso, updates the default and docs in devtest_variables.sh.\n\nThis change makes it possible to easily use cinder-lio as\na default. This is the prefered default on Fedora and RHEL 7\nsystems.\n\nChange-Id: Ic7059e2e37a443d871e563c4e6d6ca1515bf7c63\n'}]",0,106464,87ec9bee42ede105966618e43687e24443729b71,37,6,1,360,,,0,"overcloud: cinder-tgt cinder-lio via EXTRA_ARGS

Updates devtest_overcloud.sh so that we set the configured
cinder-lio and/or cinder-tgt elements via the
OVERCLOUD_CONTROL_DIB_EXTRA_ARGS variable.

Also, updates the default and docs in devtest_variables.sh.

This change makes it possible to easily use cinder-lio as
a default. This is the prefered default on Fedora and RHEL 7
systems.

Change-Id: Ic7059e2e37a443d871e563c4e6d6ca1515bf7c63
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/64/106464/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/devtest_variables.sh', 'scripts/devtest_overcloud.sh']",2,87ec9bee42ede105966618e43687e24443729b71,cinder_lio,OVERCLOUD_CONTROL_DIB_EXTRA_ARGS=${OVERCLOUD_CONTROL_DIB_EXTRA_ARGS:-'rabbitmq-server cinder-tgt'} baremetal boot-stack cinder-api cinder-volume ceilometer-collector \,OVERCLOUD_CONTROL_DIB_EXTRA_ARGS=${OVERCLOUD_CONTROL_DIB_EXTRA_ARGS:-'rabbitmq-server'} baremetal boot-stack cinder-api cinder-volume cinder-tgt ceilometer-collector \,6,4
openstack%2Ftripleo-image-elements~master~Iac1274cc52014f25887d696261b32146afc926dd,openstack/tripleo-image-elements,master,Iac1274cc52014f25887d696261b32146afc926dd,Add local_bind flag to my.cf,MERGED,2014-07-09 20:37:51.000000000,2014-08-08 10:55:04.000000000,2014-08-08 10:55:03.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 1872}, {'_account_id': 6796}, {'_account_id': 7471}, {'_account_id': 7582}, {'_account_id': 8399}, {'_account_id': 9369}, {'_account_id': 10035}, {'_account_id': 11655}, {'_account_id': 12385}]","[{'number': 1, 'created': '2014-07-09 20:37:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9d71f5790e6a8be6d3bba217170c8998680e7cea', 'message': ""Add local_bind flag to my.cf\n\nThis change enables the MySQL configuration file's network socket\nbind to be changed from 0.0.0.0, to the local-ipv4 address via\nthe heat template.\n\n    mysql:\n      local_bind: true\n\nThe absence of the option will result in the bind returning to\nthe default of 0.0.0.0. This change was implemented this way\nso the changes to the heat template could land later.\n\nChange-Id: Iac1274cc52014f25887d696261b32146afc926dd\n""}, {'number': 2, 'created': '2014-07-14 18:06:02.000000000', 'files': ['elements/mysql-common/os-apply-config/mnt/state/etc/mysql/my.cnf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/53e23a96b057780f1ce6486aacf00a442f96e888', 'message': ""Add local_bind flag to my.cf\n\nThis change enables the MySQL configuration file's network socket\nbind to be changed from 0.0.0.0, to the local-ipv4 address via\nthe heat template.\n\n    mysql:\n      local_bind: true\n\nThe absence of the option will result in the bind returning to\nthe default of 0.0.0.0. This change was implemented this way\nso the changes to the heat template could land later.\n\nChange-Id: Iac1274cc52014f25887d696261b32146afc926dd\n""}]",0,105870,53e23a96b057780f1ce6486aacf00a442f96e888,51,11,2,11655,,,0,"Add local_bind flag to my.cf

This change enables the MySQL configuration file's network socket
bind to be changed from 0.0.0.0, to the local-ipv4 address via
the heat template.

    mysql:
      local_bind: true

The absence of the option will result in the bind returning to
the default of 0.0.0.0. This change was implemented this way
so the changes to the heat template could land later.

Change-Id: Iac1274cc52014f25887d696261b32146afc926dd
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/70/105870/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/mysql-common/os-config-applier/mnt/state/etc/mysql/my.cnf'],1,9d71f5790e6a8be6d3bba217170c8998680e7cea,bp/tripleo-icehouse-ha-production-configuration,{{#mysql.local_bind}} bind-address = {{local-ipv4}} {{/mysql.local_bind}} {{^mysql.local_bind}}{{/mysql.local_bind}},,5,0
openstack%2Fcinder~master~Ie493768445b838d3e9447edb76d9845e972bc7c3,openstack/cinder,master,Ie493768445b838d3e9447edb76d9845e972bc7c3,VMware:Disk type conversion during clone backing,MERGED,2014-07-11 09:27:14.000000000,2014-08-08 10:52:07.000000000,2014-08-08 10:52:06.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 5538}, {'_account_id': 6094}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9171}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12018}, {'_account_id': 12033}, {'_account_id': 12641}]","[{'number': 1, 'created': '2014-07-11 09:27:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/68eea978c50a44533e9b03f74ef980accb676180', 'message': ""VMware:Disk type conversion during clone backing\n\nThis patch adds support for converting virtual disk provisioning\ntype during clone backing operation. Currently volume creation from\npreallocated/sparse image doesn't honour the disk type property in\nthe volume extra spec. The workflow to address this issue requires\ndisk provisioning type conversion during clone.\n\nPartial-Bug: #1287176\nPartial-Bug: #1287185\n\nChange-Id: Ie493768445b838d3e9447edb76d9845e972bc7c3\n""}, {'number': 2, 'created': '2014-07-23 16:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8ccab468de45eaa80dc7c1138dad51fc9e4304fe', 'message': ""VMware:Disk type conversion during clone backing\n\nThis patch adds support for converting virtual disk provisioning\ntype during clone backing operation. Currently volume creation from\npreallocated/sparse image doesn't honour the disk type property in\nthe volume extra spec. The workflow to address this issue requires\ndisk provisioning type conversion during clone.\n\nPartial-Bug: #1287176\nPartial-Bug: #1287185\n\nChange-Id: Ie493768445b838d3e9447edb76d9845e972bc7c3\n""}, {'number': 3, 'created': '2014-07-24 06:52:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c64afacb0bd7348721eefbd1d5e9c0f63255c562', 'message': ""VMware:Disk type conversion during clone backing\n\nThis patch adds support for converting virtual disk provisioning\ntype during clone backing operation. Currently volume creation from\npreallocated/sparse image doesn't honour the disk type property in\nthe volume extra spec. The workflow to address this issue requires\ndisk provisioning type conversion during clone.\n\nPartial-Bug: #1287176\nPartial-Bug: #1287185\n\nChange-Id: Ie493768445b838d3e9447edb76d9845e972bc7c3\n""}, {'number': 4, 'created': '2014-08-01 09:03:24.000000000', 'files': ['cinder/tests/test_vmware_volumeops.py', 'cinder/volume/drivers/vmware/volumeops.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5f24034a45b97ef023df4517e66c7e8191ef2c6d', 'message': ""VMware:Disk type conversion during clone backing\n\nThis patch adds support for converting virtual disk provisioning\ntype during clone backing operation. Currently volume creation from\npreallocated/sparse image doesn't honour the disk type property in\nthe volume extra spec. The workflow to address this issue requires\ndisk provisioning type conversion during clone.\n\nPartial-Bug: #1287176\nPartial-Bug: #1287185\n\nChange-Id: Ie493768445b838d3e9447edb76d9845e972bc7c3\n""}]",0,106317,5f24034a45b97ef023df4517e66c7e8191ef2c6d,69,17,4,9171,,,0,"VMware:Disk type conversion during clone backing

This patch adds support for converting virtual disk provisioning
type during clone backing operation. Currently volume creation from
preallocated/sparse image doesn't honour the disk type property in
the volume extra spec. The workflow to address this issue requires
disk provisioning type conversion during clone.

Partial-Bug: #1287176
Partial-Bug: #1287185

Change-Id: Ie493768445b838d3e9447edb76d9845e972bc7c3
",git fetch https://review.opendev.org/openstack/cinder refs/changes/17/106317/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_vmware_volumeops.py', 'cinder/volume/drivers/vmware/volumeops.py']",2,68eea978c50a44533e9b03f74ef980accb676180,clone_backing," def _create_relocate_spec_disk_locator(self, datastore, disk_type, disk_device): """"""Creates spec for disk type conversion during relocate."""""" cf = self._session.vim.client.factory disk_locator = cf.create(""ns0:VirtualMachineRelocateSpecDiskLocator"") disk_locator.datastore = datastore disk_locator.diskId = disk_device.key disk_locator.diskBackingInfo = self._create_disk_backing(disk_type, None) return disk_locator disk_move_type, disk_type=None, disk_device=None): :param disk_type: Destination disk type :param disk_device: Virtual device corresponding to the disk if disk_type is not None and disk_device is not None: disk_locator = self._create_relocate_spec_disk_locator(datastore, disk_type, disk_device) relocate_spec.disk = [disk_locator] LOG.debug(""Spec for relocating the backing: %s."", relocate_spec) def _get_clone_spec(self, datastore, disk_move_type, snapshot, backing, disk_type): :param backing: Source backing VM :param disk_type: Disk type of clone if disk_type is not None: disk_device = self._get_disk_device(backing) else: disk_device = None disk_move_type, disk_type, disk_device) LOG.debug(""Spec for cloning the backing: %s."", clone_spec) def clone_backing(self, name, backing, snapshot, clone_type, datastore, disk_type=None): :param disk_type: Disk type of the clone ""datastore: %(ds)s with disk type: %(disk_type)s."", 'snap': snapshot, 'ds': datastore, 'disk_type': disk_type}) clone_spec = self._get_clone_spec(datastore, disk_move_type, snapshot, backing, disk_type) def _get_disk_device(self, backing): """"""Get the virtual device corresponding to disk."""""" return device def get_vmdk_path(self, backing): """"""Get the vmdk file name of the backing. The vmdk file path of the backing returned is of the form: ""[datastore1] my_folder/my_vm.vmdk"" :param backing: Reference to the backing :return: VMDK file path of the backing """""" disk_device = self._get_disk_device(backing) backing = disk_device.backing if backing.__class__.__name__ != ""VirtualDiskFlatVer2BackingInfo"": msg = _(""Invalid disk backing: %s."") % backing.__class__.__name__ LOG.error(msg) raise AssertionError(msg) return backing.fileName"," disk_move_type): LOG.debug(""Spec for relocating the backing: %s."" % relocate_spec) def _get_clone_spec(self, datastore, disk_move_type, snapshot): disk_move_type) LOG.debug(""Spec for cloning the backing: %s."" % clone_spec) def clone_backing(self, name, backing, snapshot, clone_type, datastore): ""datastore: %(ds)s"" % 'snap': snapshot, 'ds': datastore}) clone_spec = self._get_clone_spec(datastore, disk_move_type, snapshot) def get_vmdk_path(self, backing): """"""Get the vmdk file name of the backing. The vmdk file path of the backing returned is of the form: ""[datastore1] my_folder/my_vm.vmdk"" :param backing: Reference to the backing :return: VMDK file path of the backing """""" bkng = device.backing if bkng.__class__.__name__ == ""VirtualDiskFlatVer2BackingInfo"": return bkng.fileName",163,40
openstack%2Fcinder~master~Icdb1f26d5c8eaa42408a14c57c7394d96dda078f,openstack/cinder,master,Icdb1f26d5c8eaa42408a14c57c7394d96dda078f,VMware:Support for attaching disk to backing,MERGED,2014-07-10 17:24:16.000000000,2014-08-08 10:51:58.000000000,2014-08-08 10:51:57.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 5538}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9171}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12018}, {'_account_id': 12033}, {'_account_id': 12641}]","[{'number': 1, 'created': '2014-07-10 17:24:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7635ace1a11ddd5470106aff806ec39be98a997a', 'message': ""VMware:Support for attaching disk to backing\n\nThis change adds support for attaching a virtual disk to an existing\nbacking VM. Currently volume creation from preallocated/sparse image doesn't\nhonour the disk type in the volume extra spec and adapter type in the image\nmeta-data. The workflow to address these issues requires the above mentioned\nmethod.\n\nPartial-Bug: #1284284\nPartial-Bug: #1287185\n\nChange-Id: Icdb1f26d5c8eaa42408a14c57c7394d96dda078f\n""}, {'number': 2, 'created': '2014-07-10 17:38:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4f4eba8f6ae7d0b9640e5702906a0cb51dd824c1', 'message': ""VMware:Support for attaching disk to backing\n\nThis change adds support for attaching a virtual disk to an existing\nbacking VM. Currently volume creation from preallocated/sparse image doesn't\nhonour the disk type in the volume extra spec and adapter type in the image\nmeta-data. The workflow to address these issues requires the above mentioned\nmethod. This change also sets the disk size of backing to at least 1MB which\nis the minimum required by VIM APIs.\n\nCloses-Bug: #1340315\nPartial-Bug: #1284284\nPartial-Bug: #1287185\nPartial-Bug: #1287176\n\nChange-Id: Icdb1f26d5c8eaa42408a14c57c7394d96dda078f\n""}, {'number': 3, 'created': '2014-07-23 16:09:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5732e58a7909bc617b578bcf2b63a06ae1e04497', 'message': ""VMware:Support for attaching disk to backing\n\nThis change adds support for attaching a virtual disk to an existing\nbacking VM. Currently volume creation from preallocated/sparse image doesn't\nhonour the disk type in the volume extra spec and adapter type in the image\nmeta-data. The workflow to address these issues requires the above mentioned\nmethod. This change also sets the disk size of backing to at least 1MB which\nis the minimum required by VIM APIs.\n\nCloses-Bug: #1340315\nPartial-Bug: #1284284\nPartial-Bug: #1287185\nPartial-Bug: #1287176\n\nChange-Id: Icdb1f26d5c8eaa42408a14c57c7394d96dda078f\n""}, {'number': 4, 'created': '2014-07-24 06:52:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3391e03016049b139cb94f9b9f1b27d84588ead2', 'message': ""VMware:Support for attaching disk to backing\n\nThis change adds support for attaching a virtual disk to an existing\nbacking VM. Currently volume creation from preallocated/sparse image doesn't\nhonour the disk type in the volume extra spec and adapter type in the image\nmeta-data. The workflow to address these issues requires the above mentioned\nmethod. This change also sets the disk size of backing to at least 1MB which\nis the minimum required by VIM APIs.\n\nCloses-Bug: #1340315\nPartial-Bug: #1284284\nPartial-Bug: #1287185\nPartial-Bug: #1287176\n\nChange-Id: Icdb1f26d5c8eaa42408a14c57c7394d96dda078f\n""}, {'number': 5, 'created': '2014-08-01 09:00:38.000000000', 'files': ['cinder/tests/test_vmware_volumeops.py', 'cinder/volume/drivers/vmware/volumeops.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/15a93312641bb6121d20c7749481104a1ab34bd0', 'message': ""VMware:Support for attaching disk to backing\n\nThis change adds support for attaching a virtual disk to an existing\nbacking VM. Currently volume creation from preallocated/sparse image doesn't\nhonour the disk type in the volume extra spec and adapter type in the image\nmeta-data. The workflow to address these issues requires the above mentioned\nmethod. This change also sets the disk size of backing to at least 1MB which\nis the minimum required by VIM APIs.\n\nCloses-Bug: #1340315\nPartial-Bug: #1284284\nPartial-Bug: #1287185\nPartial-Bug: #1287176\n\nChange-Id: Icdb1f26d5c8eaa42408a14c57c7394d96dda078f\n""}]",0,106113,15a93312641bb6121d20c7749481104a1ab34bd0,67,14,5,9171,,,0,"VMware:Support for attaching disk to backing

This change adds support for attaching a virtual disk to an existing
backing VM. Currently volume creation from preallocated/sparse image doesn't
honour the disk type in the volume extra spec and adapter type in the image
meta-data. The workflow to address these issues requires the above mentioned
method. This change also sets the disk size of backing to at least 1MB which
is the minimum required by VIM APIs.

Closes-Bug: #1340315
Partial-Bug: #1284284
Partial-Bug: #1287185
Partial-Bug: #1287176

Change-Id: Icdb1f26d5c8eaa42408a14c57c7394d96dda078f
",git fetch https://review.opendev.org/openstack/cinder refs/changes/13/106113/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_vmware_volumeops.py', 'cinder/volume/drivers/vmware/volumeops.py']",2,7635ace1a11ddd5470106aff806ec39be98a997a,attach_disk," def _create_controller_config_spec(self, adapter_type): """"""Returns config spec for adding a disk controller."""""" return controller_spec def _create_disk_backing(self, disk_type, vmdk_ds_file_path): """"""Creates file backing for virtual disk."""""" cf = self._session.vim.client.factory disk_device_bkng = cf.create('ns0:VirtualDiskFlatVer2BackingInfo') if disk_type == VirtualDiskType.EAGER_ZEROED_THICK: disk_device_bkng.eagerlyScrub = True elif disk_type == VirtualDiskType.THIN: disk_device_bkng.thinProvisioned = True disk_device_bkng.fileName = vmdk_ds_file_path or '' disk_device_bkng.diskMode = 'persistent' return disk_device_bkng def _create_virtual_disk_config_spec(self, size_kb, disk_type, controller_key, vmdk_ds_file_path): """"""Returns config spec for adding a virtual disk."""""" cf = self._session.vim.client.factory # disk size should be at least 1024KB disk_device.capacityInKB = max(units.Ki, int(size_kb)) if controller_key < 0: disk_device.key = controller_key - 1 else: disk_device.key = -101 disk_device.controllerKey = controller_key disk_device.backing = self._create_disk_backing(disk_type, vmdk_ds_file_path) if vmdk_ds_file_path is None: disk_spec.fileOperation = 'create' return disk_spec def _create_specs_for_disk_add(self, size_kb, disk_type, adapter_type, vmdk_ds_file_path=None): """"""Create controller and disk config specs for adding a new disk. :param size_kb: disk size in KB :param disk_type: disk provisioning type :param adapter_type: disk adapter type :param vmdk_ds_file_path: Optional datastore file path of an existing virtual disk. If specified, file backing is not created for the virtual disk. :return: list containing controller and disk config specs """""" controller_spec = None if adapter_type == 'ide': # For IDE disks, use one of the default IDE controllers (with keys # 200 and 201) created as part of backing VM creation. controller_key = 200 else: controller_spec = self._create_controller_config_spec(adapter_type) controller_key = controller_spec.device.key disk_spec = self._create_virtual_disk_config_spec(size_kb, disk_type, controller_key, vmdk_ds_file_path) specs = [disk_spec] if controller_spec is not None: specs.append(controller_spec) return specs # Set the hardware version to a compatible version supported by # vSphere 5.0. This will ensure that the backing VM can be migrated # without any incompatibility issues in a mixed cluster of ESX hosts # with versions 5.0 or above. def attach_disk_to_backing(self, backing, size_in_kb, disk_type, adapter_type, vmdk_ds_file_path): """"""Attach an existing virtual disk to the backing VM. :param backing: reference to the backing VM :param size_in_kb: disk size in KB :param disk_type: virtual disk type :param adapter_type: disk adapter type :param vmdk_ds_file_path: datastore file path of the virtual disk to be attached """""" cf = self._session.vim.client.factory reconfig_spec = cf.create('ns0:VirtualMachineConfigSpec') specs = self._create_specs_for_disk_add(size_in_kb, disk_type, adapter_type, vmdk_ds_file_path) reconfig_spec.deviceChange = specs LOG.debug(""Reconfiguring backing VM: %(backing)s with spec: %(spec)s."", {'backing': backing, 'spec': reconfig_spec}) reconfig_task = self._session.invoke_api(self._session.vim, ""ReconfigVM_Task"", backing, spec=reconfig_spec) LOG.debug(""Task: %s created for reconfiguring backing VM."", reconfig_task) self._session.wait_for_task(reconfig_task) LOG.debug(""Backing VM: %s reconfigured with new disk."", backing) "," def _create_specs_for_disk_add(self, size_kb, disk_type, adapter_type): """"""Create controller and disk specs for adding a new disk. :param size_kb: disk size in KB :param disk_type: disk provisioning type :param adapter_type: disk adapter type :return: list containing controller and disk specs """""" # for very small disks allocate at least 1KB disk_device.capacityInKB = max(1, int(size_kb)) disk_device.key = -101 disk_device.controllerKey = -100 disk_device_bkng = cf.create('ns0:VirtualDiskFlatVer2BackingInfo') if disk_type == 'eagerZeroedThick': disk_device_bkng.eagerlyScrub = True elif disk_type == 'thin': disk_device_bkng.thinProvisioned = True disk_device_bkng.fileName = '' disk_device_bkng.diskMode = 'persistent' disk_device.backing = disk_device_bkng disk_spec.fileOperation = 'create' return [controller_spec, disk_spec] # set the Hardware version to the lowest version supported by ESXi5.0 # and compatible with vCenter Server 5.0 # This ensures migration of volume created on a later ESX server # works on any ESX server 5.0 and above.",218,39
openstack%2Fsahara~master~Iffa92400638389a0b410b0cfaba695c1d7cf2a1f,openstack/sahara,master,Iffa92400638389a0b410b0cfaba695c1d7cf2a1f,Imported Translations from Transifex,MERGED,2014-08-08 06:10:40.000000000,2014-08-08 10:51:51.000000000,2014-08-08 10:51:49.000000000,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 12038}]","[{'number': 1, 'created': '2014-08-08 06:10:40.000000000', 'files': ['sahara/locale/de/LC_MESSAGES/sahara.po', 'sahara/locale/en_US/LC_MESSAGES/sahara.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/fr/LC_MESSAGES/sahara.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara-log-info.pot', 'sahara/locale/zh_CN/LC_MESSAGES/sahara.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara.po', 'sahara/locale/es/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/es/LC_MESSAGES/sahara.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara.pot', 'sahara/locale/de/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-info.po'], 'web_link': 'https://opendev.org/openstack/sahara/commit/43056deedc1f490e2c96428e62bde9df39efe9c5', 'message': 'Imported Translations from Transifex\n\nChange-Id: Iffa92400638389a0b410b0cfaba695c1d7cf2a1f\n'}]",0,112765,43056deedc1f490e2c96428e62bde9df39efe9c5,14,4,1,11131,,,0,"Imported Translations from Transifex

Change-Id: Iffa92400638389a0b410b0cfaba695c1d7cf2a1f
",git fetch https://review.opendev.org/openstack/sahara refs/changes/65/112765/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/locale/de/LC_MESSAGES/sahara.po', 'sahara/locale/en_US/LC_MESSAGES/sahara.po', 'sahara/locale/en_GB/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/fr/LC_MESSAGES/sahara.po', 'sahara/locale/zh_CN/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara-log-info.pot', 'sahara/locale/zh_CN/LC_MESSAGES/sahara.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/en_AU/LC_MESSAGES/sahara.po', 'sahara/locale/es/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/pt_BR/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/es/LC_MESSAGES/sahara.po', 'sahara/locale/fr/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/sahara.pot', 'sahara/locale/de/LC_MESSAGES/sahara-log-info.po', 'sahara/locale/it/LC_MESSAGES/sahara-log-info.po']",16,43056deedc1f490e2c96428e62bde9df39efe9c5,transifex/translations,"""POT-Creation-Date: 2014-08-08 06:10+0000\n""#: sahara/plugins/hdp/versions/version_1_3_2/versionhandler.py:592 #: sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py:691 msgid ""HTTP session is not cached"" msgstr """" ","""POT-Creation-Date: 2014-08-05 06:10+0000\n""",140,25
openstack%2Fsahara~master~If825af3cb2f57fbab9ff78633d3470d26acaa7ff,openstack/sahara,master,If825af3cb2f57fbab9ff78633d3470d26acaa7ff,Fixed concurrent job execution with external hdfs,MERGED,2014-08-05 20:02:16.000000000,2014-08-08 10:51:42.000000000,2014-08-08 10:51:42.000000000,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-08-05 20:02:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/554c842f5c9e3c34586837ce81b42fa7a0f80ee2', 'message': 'Fixed concurrent job execution with external hdfs\n\nChange-Id: If825af3cb2f57fbab9ff78633d3470d26acaa7ff\nCloses-Bug: #1353072\n'}, {'number': 2, 'created': '2014-08-05 20:32:49.000000000', 'files': ['sahara/service/edp/hdfs_helper.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/c8b728ccd35004a00e8048c9ad8cecb3eb3209d0', 'message': 'Fixed concurrent job execution with external hdfs\n\nChange-Id: If825af3cb2f57fbab9ff78633d3470d26acaa7ff\nCloses-Bug: #1353072\n'}]",0,112126,c8b728ccd35004a00e8048c9ad8cecb3eb3209d0,23,9,2,8411,,,0,"Fixed concurrent job execution with external hdfs

Change-Id: If825af3cb2f57fbab9ff78633d3470d26acaa7ff
Closes-Bug: #1353072
",git fetch https://review.opendev.org/openstack/sahara refs/changes/26/112126/2 && git format-patch -1 --stdout FETCH_HEAD,['sahara/service/edp/hdfs_helper.py'],1,554c842f5c9e3c34586837ce81b42fa7a0f80ee2,bug/1353072," etc_hosts_update = '/tmp/etc-hosts-update.%s' % six.text_type(uuid.uuid4()) tmp_etc_hosts = '/tmp/etc-hosts.%s' % six.text_type(uuid.uuid4()) 'cat %(etc_hosts_update)s /etc/hosts | ' 'sort | uniq > %(tmp_etc_hosts)s && ' 'cat %(tmp_etc_hosts)s > /etc/hosts && ' 'rm -f %(tmp_etc_hosts)s %(etc_hosts_update)s' % {'etc_hosts_update': etc_hosts_update, 'tmp_etc_hosts':tmp_etc_hosts}) r.write_file_to(etc_hosts_update, etc_hosts_information)"," 'cat /tmp/etc-hosts-update /etc/hosts | ' 'sort | uniq > /tmp/etc-hosts && ' 'cat /tmp/etc-hosts > /etc/hosts && ' 'rm -f /tmp/etc-hosts /tmp/etc-hosts-update') r.write_file_to('/tmp/etc-hosts-update', etc_hosts_information)",8,5
openstack%2Fhorizon~master~I9aff36875c26958ab8ef1f99828ed6113216c3c3,openstack/horizon,master,I9aff36875c26958ab8ef1f99828ed6113216c3c3,Fixed TypeError in database launch error handle,MERGED,2014-04-17 19:37:33.000000000,2014-08-08 10:51:34.000000000,2014-08-08 10:51:34.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 6650}, {'_account_id': 6763}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 8871}, {'_account_id': 9317}, {'_account_id': 9576}, {'_account_id': 9659}, {'_account_id': 10295}, {'_account_id': 12071}]","[{'number': 1, 'created': '2014-04-17 19:37:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3562251825275335e16f1c91bc9d47849a4b2f55', 'message': 'Fixed TypeError in database launch error handle\n\nopenstack_dashboard.dashboards.project.databases.workflows.create_instance\nin populate_flavor_choices\n\nTypeError: \'NoneType\' object is not iterable\n\nIf there\'s an exception in\nopenstack_dashboard/dashboards/project/databases/workflows/create_instance.py\nSetInstanceDetailsAction.flavors, the follow-on method will have a\nTypeError.\n\n[code]\n    @memoized.memoized_method\n    def flavors(self, request):\n        try:\n            return api.trove.flavor_list(request)\n        except Exception:\n            LOG.exception(""Exception while obtaining flavors list"")\n            self._flavors = []\n\n    def populate_flavor_choices(self, request, context):\n        flavor_list = [(f.id, ""%s"" % f.name) for f in self.flavors(request)]\n        return sorted(flavor_list)\n[code]\n\nif self.flavors has an error, it will eventually return a None.\n\nThere\'s 2 options here:\nA) return an empty list\nB) redirect to another page\n\nI have to believe that returning an empty list will be more confusing\nthan a redirect, so I\'d like to handle this with exceptions.handle.\n\nChange-Id: I9aff36875c26958ab8ef1f99828ed6113216c3c3\nCloses-Bug: 1306815\n'}, {'number': 2, 'created': '2014-07-04 03:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/469f84788916c5cb8b372bbd35cb53ac653102ed', 'message': 'Fixed TypeError in database launch error handle\n\nopenstack_dashboard.dashboards.project.databases.workflows.create_instance\nin populate_flavor_choices\n\nTypeError: \'NoneType\' object is not iterable\n\nIf there\'s an exception in\nopenstack_dashboard/dashboards/project/databases/workflows/create_instance.py\nSetInstanceDetailsAction.flavors, the follow-on method will have a\nTypeError.\n\n[code]\n    @memoized.memoized_method\n    def flavors(self, request):\n        try:\n            return api.trove.flavor_list(request)\n        except Exception:\n            LOG.exception(""Exception while obtaining flavors list"")\n            self._flavors = []\n\n    def populate_flavor_choices(self, request, context):\n        flavor_list = [(f.id, ""%s"" % f.name) for f in self.flavors(request)]\n        return sorted(flavor_list)\n[code]\n\nif self.flavors has an error, it will eventually return a None.\n\nThere\'s 2 options here:\nA) return an empty list\nB) redirect to another page\n\nI have to believe that returning an empty list will be more confusing\nthan a redirect, so I\'d like to handle this with exceptions.handle.\n\nChange-Id: I9aff36875c26958ab8ef1f99828ed6113216c3c3\nCloses-Bug: 1306815\n'}, {'number': 3, 'created': '2014-07-08 19:29:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8dbde58874964b11ac5138e756778be311de2b48', 'message': 'Fixed TypeError in database launch error handle\n\nopenstack_dashboard.dashboards.project.databases.workflows.create_instance\nin populate_flavor_choices\n\nTypeError: \'NoneType\' object is not iterable\n\nIf there\'s an exception in\nopenstack_dashboard/dashboards/project/databases/workflows/create_instance.py\nSetInstanceDetailsAction.flavors, the follow-on method will have a\nTypeError.\n\n[code]\n    @memoized.memoized_method\n    def flavors(self, request):\n        try:\n            return api.trove.flavor_list(request)\n        except Exception:\n            LOG.exception(""Exception while obtaining flavors list"")\n            self._flavors = []\n\n    def populate_flavor_choices(self, request, context):\n        flavor_list = [(f.id, ""%s"" % f.name) for f in self.flavors(request)]\n        return sorted(flavor_list)\n[code]\n\nif self.flavors has an error, it will eventually return a None.\n\nThere\'s 2 options here:\nA) return an empty list\nB) redirect to another page\n\nI have to believe that returning an empty list will be more confusing\nthan a redirect, so I\'d like to handle this with exceptions.handle.\n\nChange-Id: I9aff36875c26958ab8ef1f99828ed6113216c3c3\nCloses-Bug: 1306815\n'}, {'number': 4, 'created': '2014-07-23 16:52:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/94139b387d87ba70779c8b0676bd8a47a68188fd', 'message': 'Fixed TypeError in database launch error handle\n\nopenstack_dashboard.dashboards.project.databases.workflows.create_instance\nin populate_flavor_choices\n\nTypeError: \'NoneType\' object is not iterable\n\nIf there\'s an exception in\nopenstack_dashboard/dashboards/project/databases/workflows/create_instance.py\nSetInstanceDetailsAction.flavors, the follow-on method will have a\nTypeError.\n\n[code]\n    @memoized.memoized_method\n    def flavors(self, request):\n        try:\n            return api.trove.flavor_list(request)\n        except Exception:\n            LOG.exception(""Exception while obtaining flavors list"")\n            self._flavors = []\n\n    def populate_flavor_choices(self, request, context):\n        flavor_list = [(f.id, ""%s"" % f.name) for f in self.flavors(request)]\n        return sorted(flavor_list)\n[code]\n\nif self.flavors has an error, it will eventually return a None.\n\nThere\'s 2 options here:\nA) return an empty list\nB) redirect to another page\n\nI have to believe that returning an empty list will be more confusing\nthan a redirect, so I\'d like to handle this with exceptions.handle.\n\nChange-Id: I9aff36875c26958ab8ef1f99828ed6113216c3c3\nCloses-Bug: 1306815\n'}, {'number': 5, 'created': '2014-07-31 14:00:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/be3f367cd2631667da96c2a49af14e71b0c05920', 'message': 'Fixed TypeError in database launch error handle\n\nopenstack_dashboard.dashboards.project.databases.workflows.create_instance\nin populate_flavor_choices\n\nTypeError: \'NoneType\' object is not iterable\n\nIf there\'s an exception in\nopenstack_dashboard/dashboards/project/databases/workflows/create_instance.py\nSetInstanceDetailsAction.flavors, the follow-on method will have a\nTypeError.\n\n[code]\n    @memoized.memoized_method\n    def flavors(self, request):\n        try:\n            return api.trove.flavor_list(request)\n        except Exception:\n            LOG.exception(""Exception while obtaining flavors list"")\n            self._flavors = []\n\n    def populate_flavor_choices(self, request, context):\n        flavor_list = [(f.id, ""%s"" % f.name) for f in self.flavors(request)]\n        return sorted(flavor_list)\n[code]\n\nif self.flavors has an error, it will eventually return a None.\n\nThere\'s 2 options here:\nA) return an empty list\nB) redirect to another page\n\nI have to believe that returning an empty list will be more confusing\nthan a redirect, so I\'d like to handle this with exceptions.handle.\n\nChange-Id: I9aff36875c26958ab8ef1f99828ed6113216c3c3\nCloses-Bug: 1306815\n'}, {'number': 6, 'created': '2014-07-31 18:42:17.000000000', 'files': ['openstack_dashboard/dashboards/project/databases/workflows/create_instance.py', 'openstack_dashboard/dashboards/project/databases/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/8e40c6ce915339553ce04fdb1590a8bac873c15a', 'message': 'Fixed TypeError in database launch error handle\n\nopenstack_dashboard.dashboards.project.databases.workflows.create_instance\nin populate_flavor_choices\n\nTypeError: \'NoneType\' object is not iterable\n\nIf there\'s an exception in\nopenstack_dashboard/dashboards/project/databases/workflows/create_instance.py\nSetInstanceDetailsAction.flavors, the follow-on method will have a\nTypeError.\n\n[code]\n    @memoized.memoized_method\n    def flavors(self, request):\n        try:\n            return api.trove.flavor_list(request)\n        except Exception:\n            LOG.exception(""Exception while obtaining flavors list"")\n            self._flavors = []\n\n    def populate_flavor_choices(self, request, context):\n        flavor_list = [(f.id, ""%s"" % f.name) for f in self.flavors(request)]\n        return sorted(flavor_list)\n[code]\n\nif self.flavors has an error, it will eventually return a None.\n\nThere\'s 2 options here:\nA) return an empty list\nB) redirect to another page\n\nI have to believe that returning an empty list will be more confusing\nthan a redirect, so I\'d like to handle this with exceptions.handle.\n\nChange-Id: I9aff36875c26958ab8ef1f99828ed6113216c3c3\nCloses-Bug: 1306815\n'}]",4,88413,8e40c6ce915339553ce04fdb1590a8bac873c15a,60,14,6,9659,,,0,"Fixed TypeError in database launch error handle

openstack_dashboard.dashboards.project.databases.workflows.create_instance
in populate_flavor_choices

TypeError: 'NoneType' object is not iterable

If there's an exception in
openstack_dashboard/dashboards/project/databases/workflows/create_instance.py
SetInstanceDetailsAction.flavors, the follow-on method will have a
TypeError.

[code]
    @memoized.memoized_method
    def flavors(self, request):
        try:
            return api.trove.flavor_list(request)
        except Exception:
            LOG.exception(""Exception while obtaining flavors list"")
            self._flavors = []

    def populate_flavor_choices(self, request, context):
        flavor_list = [(f.id, ""%s"" % f.name) for f in self.flavors(request)]
        return sorted(flavor_list)
[code]

if self.flavors has an error, it will eventually return a None.

There's 2 options here:
A) return an empty list
B) redirect to another page

I have to believe that returning an empty list will be more confusing
than a redirect, so I'd like to handle this with exceptions.handle.

Change-Id: I9aff36875c26958ab8ef1f99828ed6113216c3c3
Closes-Bug: 1306815
",git fetch https://review.opendev.org/openstack/horizon refs/changes/13/88413/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/databases/workflows/create_instance.py'],1,3562251825275335e16f1c91bc9d47849a4b2f55,bug/1306815,"INDEX_URL = ""horizon:project:databases:index"" help_text_template = ""project/databases/_launch_details_help.html"" exceptions.handle(request, _('Unable to obtain flavors.'), redirect=INDEX_URL) return [] success_url = INDEX_URL 'databases': self._get_databases(context),"," help_text_template = (""project/databases/_launch_details_help.html"") self._flavors = [] success_url = ""horizon:project:databases:index"" 'databases': self._get_databases(context)",8,4
openstack%2Fcloudkitty~master~Iffa000cb2ca68d6ce59c983294a9bad1f93fd48b,openstack/cloudkitty,master,Iffa000cb2ca68d6ce59c983294a9bad1f93fd48b,Fixed wrong datetime usage,MERGED,2014-08-08 10:18:33.000000000,2014-08-08 10:47:30.000000000,2014-08-08 10:47:30.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-08 10:18:33.000000000', 'files': ['cloudkitty/collector/ceilometer.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/85429d1b59de74ac6ca516a01546c00c76279d5e', 'message': 'Fixed wrong datetime usage\n\nChange-Id: Iffa000cb2ca68d6ce59c983294a9bad1f93fd48b\n'}]",0,112818,85429d1b59de74ac6ca516a01546c00c76279d5e,7,2,1,7042,,,0,"Fixed wrong datetime usage

Change-Id: Iffa000cb2ca68d6ce59c983294a9bad1f93fd48b
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/18/112818/1 && git format-patch -1 --stdout FETCH_HEAD,['cloudkitty/collector/ceilometer.py'],1,85429d1b59de74ac6ca516a01546c00c76279d5e,fix/collector/ceilometer, start_iso = datetime.datetime.fromtimestamp(start).isoformat() end_iso = datetime.datetime.fromtimestamp(end).isoformat(), start_iso = datetime.fromtimestamp(start).isoformat() end_iso = datetime.fromtimestamp(end).isoformat(),2,2
openstack%2Ftripleo-incubator~master~Ife0491a627080f9f183f573dec23c002911a37e7,openstack/tripleo-incubator,master,Ife0491a627080f9f183f573dec23c002911a37e7,Add missing OVERCLOUD_COMPUTE_DIB_EXTRA_ARGS to write-tripleorc,MERGED,2014-08-07 08:48:35.000000000,2014-08-08 10:39:34.000000000,2014-08-08 10:39:34.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 7471}, {'_account_id': 7582}]","[{'number': 1, 'created': '2014-08-07 08:48:35.000000000', 'files': ['scripts/write-tripleorc'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/e9aa41792d2e92611cbd9d3c7e6adf7dd84c72d4', 'message': 'Add missing OVERCLOUD_COMPUTE_DIB_EXTRA_ARGS to write-tripleorc\n\nChange-Id: Ife0491a627080f9f183f573dec23c002911a37e7\n'}]",0,112518,e9aa41792d2e92611cbd9d3c7e6adf7dd84c72d4,18,5,1,6796,,,0,"Add missing OVERCLOUD_COMPUTE_DIB_EXTRA_ARGS to write-tripleorc

Change-Id: Ife0491a627080f9f183f573dec23c002911a37e7
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/18/112518/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/write-tripleorc'],1,e9aa41792d2e92611cbd9d3c7e6adf7dd84c72d4,,OVERCLOUD_COMPUTE_DIB_EXTRA_ARGS,,1,0
openstack%2Ftripleo-heat-templates~master~I081976f0da94fc0232dfa2c34de03bbb4abf1a85,openstack/tripleo-heat-templates,master,I081976f0da94fc0232dfa2c34de03bbb4abf1a85,Use VIP for keystone host in swift template,MERGED,2014-07-31 12:48:16.000000000,2014-08-08 10:34:12.000000000,2014-08-08 10:34:12.000000000,"[{'_account_id': 3}, {'_account_id': 4330}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 7471}, {'_account_id': 7582}]","[{'number': 1, 'created': '2014-07-31 12:48:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6135884d13ead91de17ffa971bf9366fbb17dfdf', 'message': 'Use VIP for keystone host in swift template\n\nAs a side effect this fixes invalid keystone host generation\nwhen multiple controller nodes are used.\n\nChange-Id: I081976f0da94fc0232dfa2c34de03bbb4abf1a85\n'}, {'number': 2, 'created': '2014-08-06 14:17:40.000000000', 'files': ['swift-storage-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/85b83846b4131663dd37ba89f7991394f9de6086', 'message': 'Use VIP for keystone host in swift template\n\nAs a side effect this fixes invalid keystone host generation\nwhen multiple controller nodes are used.\n\nChange-Id: I081976f0da94fc0232dfa2c34de03bbb4abf1a85\n'}]",0,110950,85b83846b4131663dd37ba89f7991394f9de6086,33,7,2,7582,,,0,"Use VIP for keystone host in swift template

As a side effect this fixes invalid keystone host generation
when multiple controller nodes are used.

Change-Id: I081976f0da94fc0232dfa2c34de03bbb4abf1a85
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/50/110950/1 && git format-patch -1 --stdout FETCH_HEAD,['swift-storage-source.yaml'],1,6135884d13ead91de17ffa971bf9366fbb17dfdf,swift," keystone_host: {'Fn::Select': [ip_address, 'Fn::Select': [0, 'Fn::GetAtt': [ControlVirtualIP, fixed_ips]]]}"," keystone_host: {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [controller0, networks]} ]} ] }",1,1
openstack%2Ftripleo-heat-templates~master~I796b9bdccd1863647a667edbbc96731fc924c55d,openstack/tripleo-heat-templates,master,I796b9bdccd1863647a667edbbc96731fc924c55d,fix incorrect reference to rabbit_username,MERGED,2014-07-29 09:07:45.000000000,2014-08-08 10:33:28.000000000,2014-08-08 10:33:28.000000000,"[{'_account_id': 3}, {'_account_id': 4330}, {'_account_id': 6550}, {'_account_id': 6796}, {'_account_id': 7582}, {'_account_id': 11655}]","[{'number': 1, 'created': '2014-07-29 09:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3f7d01d58a2f7797b3a52b0b18e5a8aafa0420e7', 'message': 'fix incorrect reference to rabbit_user_name\n\nFixes a typo in nova-compute-config.yaml file where rabbit_username\nwas mistakenly written as rabbit_user_name; compute nodes received\nnull as rabbit username as consequence.\n\nChange-Id: I796b9bdccd1863647a667edbbc96731fc924c55d\n'}, {'number': 2, 'created': '2014-08-04 19:15:14.000000000', 'files': ['nova-compute-config.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dc251e33c39b439d79fedd173102073321f286c4', 'message': 'fix incorrect reference to rabbit_username\n\nFixes a typo in nova-compute-config.yaml file where rabbit_username\nwas mistakenly written as rabbit_user_name; compute nodes received\nnull as rabbit username as consequence.\n\nChange-Id: I796b9bdccd1863647a667edbbc96731fc924c55d\n'}]",0,110239,dc251e33c39b439d79fedd173102073321f286c4,39,6,2,6796,,,0,"fix incorrect reference to rabbit_username

Fixes a typo in nova-compute-config.yaml file where rabbit_username
was mistakenly written as rabbit_user_name; compute nodes received
null as rabbit username as consequence.

Change-Id: I796b9bdccd1863647a667edbbc96731fc924c55d
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/39/110239/2 && git format-patch -1 --stdout FETCH_HEAD,['nova-compute-config.yaml'],1,3f7d01d58a2f7797b3a52b0b18e5a8aafa0420e7,rabbit_username, username: {get_input: rabbit_username}, username: {get_input: rabbit_user_name},1,1
openstack%2Fnova~master~I723fa4a8823019391ea83aa189096531032adab1,openstack/nova,master,I723fa4a8823019391ea83aa189096531032adab1,Keep resizing&resized instances when compute init,MERGED,2014-06-23 05:37:15.000000000,2014-08-08 10:32:15.000000000,2014-07-28 04:17:47.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 679}, {'_account_id': 1247}, {'_account_id': 1653}, {'_account_id': 1882}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12287}]","[{'number': 1, 'created': '2014-06-23 05:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3fa9c020d98bfbf9810c14687cec9897757aa042', 'message': ""Keep resizing&resized instances when compute init\n\nDuring compute manager startup init_host is called. One of the\nfunctions there is to delete instance data that doesn't belong\nto this host i.e. _destroy_evacuated_instances.\nBut this function only checks if the local instance belongs to\nthe host or not. It doesn't check the task_state or vm_state.\n\nIn Resize function, user may want to revert or confirm the resize\noperations so the instance on source and dest compute node should\nbe kept. so for RESIZE_MIGRATING, RESIZE_MIGRATED task states and\nRESIZED vm state instances, they should be kept in compute node\nwhen the compute restart. This patch adds check for the task\nstate and vm state before delete the instances.\n\nCloses-Bug: #1330503\n\nChange-Id: I723fa4a8823019391ea83aa189096531032adab1\n""}, {'number': 2, 'created': '2014-06-23 06:44:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b04e3fdd0efdb8df4b5f25ea3e2599b0ac18aab8', 'message': ""Keep resizing&resized instances when compute init\n\nDuring compute manager startup init_host is called. One of the\nfunctions there is to delete instance data that doesn't belong\nto this host i.e. _destroy_evacuated_instances.\nBut this function only checks if the local instance belongs to\nthe host or not. It doesn't check the task_state or vm_state.\n\nIn Resize function, user may want to revert or confirm the resize\noperations so the instance on source and dest compute node should\nbe kept. so for RESIZE_MIGRATING, RESIZE_MIGRATED task states and\nRESIZED vm state instances, they should be kept in compute node\nwhen the compute restart. This patch adds check for the task\nstate and vm state before delete the instances.\n\nCloses-Bug: #1330503\n\nChange-Id: I723fa4a8823019391ea83aa189096531032adab1\n""}, {'number': 3, 'created': '2014-06-25 06:26:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d0521159ca68cd0fdb7cedc17f1a097dd5cad0a1', 'message': ""Keep resizing&resized instances when compute init\n\nDuring compute manager startup init_host is called. One of the\nfunctions there is to delete instance data that doesn't belong\nto this host i.e. _destroy_evacuated_instances.\nBut this function only checks if the local instance belongs to\nthe host or not. It doesn't check the task_state or vm_state.\n\nIn Resize function, user may want to revert or confirm the resize\noperations so the instance on source and dest compute node should\nbe kept. so for RESIZE_MIGRATING, RESIZE_MIGRATED task states and\nRESIZED vm state instances, they should be kept in compute node\nwhen the compute restart. This patch adds check for the task\nstate and vm state before delete the instances.\n\nCloses-Bug: #1330503\n\nChange-Id: I723fa4a8823019391ea83aa189096531032adab1\n""}, {'number': 4, 'created': '2014-06-27 09:11:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e45db7025dcbcf2a50c0444052191e88e4395dc9', 'message': ""Keep resizing&resized instances when compute init\n\nDuring compute manager startup init_host is called. One of the\nfunctions there is to delete instance data that doesn't belong\nto this host i.e. _destroy_evacuated_instances.\nBut this function only checks if the local instance belongs to\nthe host or not. It doesn't check the task_state or vm_state.\n\nIn Resize function, user may want to revert or confirm the resize\noperations so the instance on source and dest compute node should\nbe kept. so for RESIZE_MIGRATING, RESIZE_MIGRATED task states and\nRESIZED vm state instances, they should be kept in compute node\nwhen the compute restart. This patch adds check for the task\nstate and vm state before delete the instances.\n\nCloses-Bug: #1330503\n\nChange-Id: I723fa4a8823019391ea83aa189096531032adab1\n""}, {'number': 5, 'created': '2014-07-25 01:43:47.000000000', 'files': ['nova/tests/compute/test_compute_mgr.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/dd6fb1246ff2789bd78b772b45e1fcac21eda67a', 'message': ""Keep resizing&resized instances when compute init\n\nDuring compute manager startup init_host is called. One of the\nfunctions there is to delete instance data that doesn't belong\nto this host i.e. _destroy_evacuated_instances.\nBut this function only checks if the local instance belongs to\nthe host or not. It doesn't check the task_state or vm_state.\n\nIn Resize function, user may want to revert or confirm the resize\noperations so the instance on source and dest compute node should\nbe kept. so for RESIZE_MIGRATING, RESIZE_MIGRATED task states and\nRESIZED vm state instances, they should be kept in compute node\nwhen the compute restart. This patch adds check for the task\nstate and vm state before delete the instances.\n\nCloses-Bug: #1330503\n\nChange-Id: I723fa4a8823019391ea83aa189096531032adab1\n""}]",8,101803,dd6fb1246ff2789bd78b772b45e1fcac21eda67a,101,14,5,6062,,,0,"Keep resizing&resized instances when compute init

During compute manager startup init_host is called. One of the
functions there is to delete instance data that doesn't belong
to this host i.e. _destroy_evacuated_instances.
But this function only checks if the local instance belongs to
the host or not. It doesn't check the task_state or vm_state.

In Resize function, user may want to revert or confirm the resize
operations so the instance on source and dest compute node should
be kept. so for RESIZE_MIGRATING, RESIZE_MIGRATED task states and
RESIZED vm state instances, they should be kept in compute node
when the compute restart. This patch adds check for the task
state and vm state before delete the instances.

Closes-Bug: #1330503

Change-Id: I723fa4a8823019391ea83aa189096531032adab1
",git fetch https://review.opendev.org/openstack/nova refs/changes/03/101803/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_mgr.py', 'nova/compute/manager.py']",2,3fa9c020d98bfbf9810c14687cec9897757aa042,bug/1330503," the MIGRATING, RESZIE_MIGRTAING, RESIZE_MIGRATED, RESIZE_FINISH task state or RESIZED vm state. if (instance.task_state in [task_states.MIGRATING, task_states.RESIZE_MIGRATING, task_states.RESIZE_MIGRATED, task_states.RESIZE_FINISH] or instance.vm_state in [vm_states.RESIZED]): 'host (%(our_host)s) but its task state is ' '(%(task_state)s) and vm state is ' '(%(vm_state)s)', 'task_state': instance.task_state, 'vm_state': instance.vm_state},"," the MIGRATING state. if instance.task_state in [task_states.MIGRATING]: 'host (%(our_host)s) but its state is ' '(%(task_state)s)', 'task_state': instance.task_state},",34,7
openstack%2Fglance~master~If348be7fd24fd05146b0c86bef45b79f600cc0f7,openstack/glance,master,If348be7fd24fd05146b0c86bef45b79f600cc0f7,VMware store: Use the Content-Length if available,MERGED,2014-07-02 23:17:23.000000000,2014-08-08 10:30:45.000000000,2014-08-07 01:17:00.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6549}, {'_account_id': 6981}, {'_account_id': 8443}, {'_account_id': 8759}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-07-02 23:17:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f19a080e47bdff81a2fe152311c4706abf45a575', 'message': 'VMware store: Use the Content-Length if available\n\nChange I579084460e7f61ab4042632d17ec0f045fa6f5af changed the VMware\nstore to use chunked encoding to upload data to the underlying backend.\nWe should do that only if the image size is not provided or zero and not\nall the time.\n\nThis patch addressed the issue by checking the image_size before upload.\n\nChange-Id: If348be7fd24fd05146b0c86bef45b79f600cc0f7\nCloses-Bug: #1336970\n'}, {'number': 2, 'created': '2014-07-03 00:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ee619d04db27b07af031d74117ecddaa117f5b01', 'message': 'VMware store: Use the Content-Length if available\n\nChange I579084460e7f61ab4042632d17ec0f045fa6f5af changed the VMware\nstore to use chunked encoding to upload data to the underlying backend.\nWe should do that only if the image size is not provided or zero and not\nall the time.\n\nThis patch addressed the issue by checking the image_size before upload.\n\nChange-Id: If348be7fd24fd05146b0c86bef45b79f600cc0f7\nCloses-Bug: #1336970\n'}, {'number': 3, 'created': '2014-07-07 21:51:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9304adac9d17102169b21f0ac043feb7a58284c4', 'message': 'VMware store: Use the Content-Length if available\n\nChange I579084460e7f61ab4042632d17ec0f045fa6f5af changed the VMware\nstore to use chunked encoding to upload data to the underlying backend.\nWe should do that only if the image size is not provided or zero and not\nall the time.\n\nThis patch addressed the issue by checking the image_size before upload.\n\nChange-Id: If348be7fd24fd05146b0c86bef45b79f600cc0f7\nCloses-Bug: #1336970\n'}, {'number': 4, 'created': '2014-07-22 04:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/84c0a20734bd4f3d42fd427e13778dbea0db063a', 'message': 'VMware store: Use the Content-Length if available\n\nChange I579084460e7f61ab4042632d17ec0f045fa6f5af changed the VMware\nstore to use chunked encoding to upload data to the underlying backend.\nWe should do that only if the image size is not provided or zero and not\nall the time.\n\nThis patch addressed the issue by checking the image_size before upload.\n\nChange-Id: If348be7fd24fd05146b0c86bef45b79f600cc0f7\nCloses-Bug: #1336970\n'}, {'number': 5, 'created': '2014-07-29 01:58:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2b9715e086fa3cafdc46fed7ccf249cb0fc43850', 'message': 'VMware store: Use the Content-Length if available\n\nChange I579084460e7f61ab4042632d17ec0f045fa6f5af changed the VMware\nstore to use chunked encoding to upload data to the underlying backend.\nWe should do that only if the image size is not provided or zero and not\nall the time.\n\nThis patch addressed the issue by checking the image_size before upload.\n\nChange-Id: If348be7fd24fd05146b0c86bef45b79f600cc0f7\nCloses-Bug: #1336970\n'}, {'number': 6, 'created': '2014-07-30 01:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c7425ee7a29e22abd105dec4ae5632c3b45f431c', 'message': 'VMware store: Use the Content-Length if available\n\nChange I579084460e7f61ab4042632d17ec0f045fa6f5af changed the VMware\nstore to use chunked encoding to upload data to the underlying backend.\nWe should do that only if the image size is not provided or zero and not\nall the time.\n\nThis patch addressed the issue by checking the image_size before upload.\n\nChange-Id: If348be7fd24fd05146b0c86bef45b79f600cc0f7\nCloses-Bug: #1336970\n'}, {'number': 7, 'created': '2014-08-04 18:31:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c9c2e332200517247a48cc6683a4823d683e30ef', 'message': 'VMware store: Use the Content-Length if available\n\nChange I579084460e7f61ab4042632d17ec0f045fa6f5af changed the VMware\nstore to use chunked encoding to upload data to the underlying backend.\nWe should do that only if the image size is not provided or zero and not\nall the time.\n\nThis patch addressed the issue by checking the image_size before upload.\n\nChange-Id: If348be7fd24fd05146b0c86bef45b79f600cc0f7\nCloses-Bug: #1336970\n'}, {'number': 8, 'created': '2014-08-05 21:48:05.000000000', 'files': ['glance/tests/unit/test_vmware_store.py', 'glance/store/vmware_datastore.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/8c161b6a4b0a7617ee224b23ada0a368e97eaae7', 'message': 'VMware store: Use the Content-Length if available\n\nChange I579084460e7f61ab4042632d17ec0f045fa6f5af changed the VMware\nstore to use chunked encoding to upload data to the underlying backend.\nWe should do that only if the image size is not provided or zero and not\nall the time.\n\nThis patch addressed the issue by checking the image_size before upload.\n\nChange-Id: If348be7fd24fd05146b0c86bef45b79f600cc0f7\nCloses-Bug: #1336970\n'}]",11,104374,8c161b6a4b0a7617ee224b23ada0a368e97eaae7,62,10,8,8759,,,0,"VMware store: Use the Content-Length if available

Change I579084460e7f61ab4042632d17ec0f045fa6f5af changed the VMware
store to use chunked encoding to upload data to the underlying backend.
We should do that only if the image size is not provided or zero and not
all the time.

This patch addressed the issue by checking the image_size before upload.

Change-Id: If348be7fd24fd05146b0c86bef45b79f600cc0f7
Closes-Bug: #1336970
",git fetch https://review.opendev.org/openstack/glance refs/changes/74/104374/3 && git format-patch -1 --stdout FETCH_HEAD,['glance/store/vmware_datastore.py'],1,f19a080e47bdff81a2fe152311c4706abf45a575,bug/1336970," def __init__(self, data, checksum): self._size = 0 def read(self, size=None): result = self.data.read(size) self._size += len(result) self.checksum.update(result) return result @property def size(self): return self._size class _ChunkedReader(_Reader): def __init__(self, data, checksum, blocksize=8192): super(_ChunkedReader, self).__init__(data, checksum) if image_size > 0: headers = {'Connection': 'Keep-Alive', 'Content-Length': image_size} image_file = _Reader(image_file, checksum) else: headers = {'Transfer-Encoding': 'chunked'} image_file = _ChunkedReader(image_file, checksum) headers = dict(headers.items() + {'Cookie': cookie}.items())"," def __init__(self, data, checksum, blocksize=8192): self._size = 0 @property def size(self): return self._size image_file = _Reader(image_file, checksum) headers = {'Connection': 'Keep-Alive', 'Cookie': cookie, 'Transfer-Encoding': 'chunked'}",26,10
openstack%2Fcloudkitty~master~Ic552d49328c8d76c2ac7c2667c5904c18b4b8937,openstack/cloudkitty,master,Ic552d49328c8d76c2ac7c2667c5904c18b4b8937,Moved base collector code,MERGED,2014-08-08 10:14:35.000000000,2014-08-08 10:30:24.000000000,2014-08-08 10:30:24.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-08 10:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/aa37fbc9a17c14fdeea6f5fce1c7c8a701e1a13d', 'message': 'Moved base collector code\n\nBase class is now abstract using abc.\n\nChange-Id: Ic552d49328c8d76c2ac7c2667c5904c18b4b8937\n'}, {'number': 2, 'created': '2014-08-08 10:15:24.000000000', 'files': ['cloudkitty/collector/base.py', 'cloudkitty/collector/__init__.py', 'cloudkitty/collector/ceilometer.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/eaecea8f34bc6a9cc1f4fa08036d3d19399a36a3', 'message': 'Moved base collector code\n\nBase class is now abstract using abc.\n\nChange-Id: Ic552d49328c8d76c2ac7c2667c5904c18b4b8937\n'}]",0,112817,eaecea8f34bc6a9cc1f4fa08036d3d19399a36a3,9,2,2,7042,,,0,"Moved base collector code

Base class is now abstract using abc.

Change-Id: Ic552d49328c8d76c2ac7c2667c5904c18b4b8937
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/17/112817/1 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/collector/base.py', 'cloudkitty/collector/__init__.py', 'cloudkitty/collector/ceilometer.py']",3,aa37fbc9a17c14fdeea6f5fce1c7c8a701e1a13d,rewriter/collector,from cloudkitty import collector class CeilometerCollector(collector.BaseCollector):,from cloudkitty.collector import base class CeilometerCollector(base.BaseCollector):,66,66
openstack%2Ftripleo-image-elements~master~I3ff37ec18b9191ca8e861519bed142cbdbd5faa2,openstack/tripleo-image-elements,master,I3ff37ec18b9191ca8e861519bed142cbdbd5faa2,Prefer rabbit.host over rabbit.nodes,MERGED,2014-07-22 11:27:45.000000000,2014-08-08 10:09:28.000000000,2014-08-08 10:09:28.000000000,"[{'_account_id': 3}, {'_account_id': 215}, {'_account_id': 360}, {'_account_id': 6796}, {'_account_id': 7582}, {'_account_id': 8041}, {'_account_id': 8532}, {'_account_id': 10035}, {'_account_id': 11655}]","[{'number': 1, 'created': '2014-07-22 11:27:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/1f5229707b9f094c4e5bfa9d82308feecff9764a', 'message': 'Prefer rabit.host over rabbit.nodes\n\nDue to bug #856764 we need to route access to rabbit via haproxy.\n\nThe following changes are introduced:\n  - services use rabbit.host if defined, instead of rabbit.nodes\n  - haproxy element supports arbitrary listener options\n  - rabbitmq listens on local loopback and ipv4 instead of 0.0.0.0\n\nDepends on change I49b622a604542f456bd9a37da8dae3353218e640\nRelated to blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I3ff37ec18b9191ca8e861519bed142cbdbd5faa2\nRelated-Bug: 856764\n'}, {'number': 2, 'created': '2014-07-22 14:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/84c5a543985219b9859a9077adde44e7493abe00', 'message': 'Prefer rabbit.host over rabbit.nodes\n\nDue to bug #856764 we need to route access to rabbit via haproxy.\n\nThe following changes are introduced:\n  - services use rabbit.host if defined, instead of rabbit.nodes\n  - haproxy element supports arbitrary listener options\n  - rabbitmq listens on local loopback and ipv4 instead of 0.0.0.0\n\nDepends on change I49b622a604542f456bd9a37da8dae3353218e640\nRelated to blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I3ff37ec18b9191ca8e861519bed142cbdbd5faa2\nRelated-Bug: 856764\n'}, {'number': 3, 'created': '2014-07-22 17:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/642f05851c54d429a99b17594fa7a6813e845306', 'message': 'Prefer rabbit.host over rabbit.nodes\n\nDue to bug #856764 we need to route access to rabbit via haproxy.\n\nThe following changes are introduced:\n  - services use rabbit.host if defined, instead of rabbit.nodes\n  - haproxy element supports arbitrary listener options\n  - rabbitmq listens on local loopback and ipv4 instead of 0.0.0.0\n\nDepends on change I49b622a604542f456bd9a37da8dae3353218e640\nRelated to blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I3ff37ec18b9191ca8e861519bed142cbdbd5faa2\nRelated-Bug: 856764\n'}, {'number': 4, 'created': '2014-07-23 19:58:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/23707a10ac38e809ceed894894aada0d17ccbed7', 'message': 'Prefer rabbit.host over rabbit.nodes\n\nDue to bug #856764 we need to route access to rabbit via haproxy.\n\nThe following changes are introduced:\n  - services use rabbit.host if defined, instead of rabbit.nodes\n  - haproxy element supports arbitrary listener options\n  - rabbitmq listens on local loopback and ipv4 instead of 0.0.0.0\n\nDepends on change I49b622a604542f456bd9a37da8dae3353218e640\nRelated to blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I3ff37ec18b9191ca8e861519bed142cbdbd5faa2\nRelated-Bug: 856764\n'}, {'number': 5, 'created': '2014-07-30 13:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a13c5c10347a56c1935c197deb5000b69b22e841', 'message': ""Prefer rabbit.host over rabbit.nodes\n\nDue to bug #856764 we need to route access to rabbit via haproxy.\n\nThe following changes are introduced:\n  - services use rabbit.host if defined, instead of rabbit.nodes\n  - haproxy element supports arbitrary listener options\n  - rabbitmq listens on local loopback and ipv4 instead of 0.0.0.0\n  - haproxy.cfg is restructured to make better use of 'defaults'\n\nDepends on change I49b622a604542f456bd9a37da8dae3353218e640\nRelated to blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I3ff37ec18b9191ca8e861519bed142cbdbd5faa2\nRelated-Bug: 856764\n""}, {'number': 6, 'created': '2014-07-30 14:11:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/6cbcf1fc8b9639ff6c682a2ae176ad4d1a348a5b', 'message': ""Prefer rabbit.host over rabbit.nodes\n\nDue to bug #856764 we need to route access to rabbit via haproxy.\n\nThe following changes are introduced:\n  - services use rabbit.host if defined, instead of rabbit.nodes\n  - haproxy element supports arbitrary listener options\n  - rabbitmq listens on local loopback and ipv4 instead of 0.0.0.0\n  - haproxy.cfg is restructured to make better use of 'defaults'\n\nDepends on change I49b622a604542f456bd9a37da8dae3353218e640\nRelated to blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I3ff37ec18b9191ca8e861519bed142cbdbd5faa2\nRelated-Bug: 856764\n""}, {'number': 7, 'created': '2014-07-31 22:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/cce5d82a6d5f152a591338ec07e546f8a189a107', 'message': ""Prefer rabbit.host over rabbit.nodes\n\nDue to bug #856764 we need to route access to rabbit via haproxy.\n\nThe following changes are introduced:\n  - services use rabbit.host if defined, instead of rabbit.nodes\n  - haproxy element supports arbitrary listener options\n  - rabbitmq listens on local loopback and ipv4 instead of 0.0.0.0\n  - haproxy.cfg is restructured to make better use of 'defaults'\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\n\nChange-Id: I3ff37ec18b9191ca8e861519bed142cbdbd5faa2\nRelated-Bug: 856764\n""}, {'number': 8, 'created': '2014-08-01 17:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e491e404ebe5afc5294b77c4e34bd81423d3c76d', 'message': 'Prefer rabbit.host over rabbit.nodes\n\nDue to bug #856764 we want to route access to rabbit via haproxy, this change make\nthe services use rabbit.host if defined, instead of rabbit.nodes and rabbitmq listen\non local loopback and local-ipv4 instead of 0.0.0.0\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\nChange-Id: I3ff37ec18b9191ca8e861519bed142cbdbd5faa2\nRelated-Bug: 856764\n'}, {'number': 9, 'created': '2014-08-01 17:23:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/b884eaf6bf54ba55491ad8a8f44e96ba99755eda', 'message': 'Prefer rabbit.host over rabbit.nodes\n\nDue to bug #856764 we want to route access to rabbit via\nhaproxy, this change make the services use rabbit.host if\ndefined, instead of rabbit.nodes and rabbitmq listen\non local loopback and local-ipv4 instead of 0.0.0.0\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\nChange-Id: I3ff37ec18b9191ca8e861519bed142cbdbd5faa2\nRelated-Bug: 856764\n'}, {'number': 10, 'created': '2014-08-04 09:42:39.000000000', 'files': ['elements/ceilometer/os-apply-config/etc/ceilometer/ceilometer.conf', 'elements/cinder/os-apply-config/etc/cinder/cinder.conf', 'elements/neutron/os-apply-config/etc/neutron/neutron.conf', 'elements/glance/os-apply-config/etc/glance/glance-api.conf', 'elements/heat/os-apply-config/etc/heat/heat.conf', 'elements/ironic/os-apply-config/etc/ironic/ironic.conf', 'elements/trove-api/os-apply-config/etc/trove/trove.conf', 'elements/rabbitmq-server/os-apply-config/etc/rabbitmq/rabbitmq.config', 'elements/nova/os-apply-config/etc/nova/nova.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/23612348a5d66527f7b1221d93148ff476f9588d', 'message': 'Prefer rabbit.host over rabbit.nodes\n\nDue to bug #856764 we want to route access to rabbit via\nhaproxy, this change makes the services use rabbit.host if\ndefined, instead of rabbit.nodes and rabbitmq listen\non local loopback and local-ipv4 instead of 0.0.0.0\n\nRelated to blueprint tripleo-icehouse-ha-production-configuration\nChange-Id: I3ff37ec18b9191ca8e861519bed142cbdbd5faa2\nRelated-Bug: 856764\n'}]",9,108650,23612348a5d66527f7b1221d93148ff476f9588d,101,9,10,6796,,,0,"Prefer rabbit.host over rabbit.nodes

Due to bug #856764 we want to route access to rabbit via
haproxy, this change makes the services use rabbit.host if
defined, instead of rabbit.nodes and rabbitmq listen
on local loopback and local-ipv4 instead of 0.0.0.0

Related to blueprint tripleo-icehouse-ha-production-configuration
Change-Id: I3ff37ec18b9191ca8e861519bed142cbdbd5faa2
Related-Bug: 856764
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/50/108650/10 && git format-patch -1 --stdout FETCH_HEAD,"['elements/ceilometer/os-apply-config/etc/ceilometer/ceilometer.conf', 'elements/cinder/os-apply-config/etc/cinder/cinder.conf', 'elements/neutron/os-apply-config/etc/neutron/neutron.conf', 'elements/glance/os-apply-config/etc/glance/glance-api.conf', 'elements/heat/os-apply-config/etc/heat/heat.conf', 'elements/ironic/os-apply-config/etc/ironic/ironic.conf', 'elements/rabbitmq-server/os-apply-config/etc/rabbitmq/rabbitmq.config', 'elements/haproxy/os-apply-config/etc/haproxy/haproxy.cfg', 'elements/nova/os-apply-config/etc/nova/nova.conf']",9,1f5229707b9f094c4e5bfa9d82308feecff9764a,bug/856764,{{#host}} rabbit_host={{.}} {{/host}} {{^host}}{{/host}},{{#rabbit.nodes}}{{/rabbit.nodes}} {{^rabbit.nodes}} rabbit_host={{host}} {{/rabbit.nodes}},41,37
openstack%2Fopenstack-manuals~master~I38a4a20cf9830fa07c769c34eb1ffd7578948317,openstack/openstack-manuals,master,I38a4a20cf9830fa07c769c34eb1ffd7578948317,Arch Design: Small edits,MERGED,2014-08-07 18:29:28.000000000,2014-08-08 10:08:13.000000000,2014-08-08 10:08:12.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 3153}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-07 18:29:28.000000000', 'files': ['doc/arch-design/ch_specialized.xml', 'doc/arch-design/ch_network_focus.xml', 'doc/arch-design/specialized/section_software_defined_networking_specialized.xml', 'doc/arch-design/ch_compute_focus.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/32e98f50453f92cacb5733f5b02aee30640200d7', 'message': 'Arch Design: Small edits\n\nFix capitalization and markup.\n\nChange-Id: I38a4a20cf9830fa07c769c34eb1ffd7578948317\n'}]",0,112648,32e98f50453f92cacb5733f5b02aee30640200d7,10,4,1,6547,,,0,"Arch Design: Small edits

Fix capitalization and markup.

Change-Id: I38a4a20cf9830fa07c769c34eb1ffd7578948317
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/48/112648/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/arch-design/ch_specialized.xml', 'doc/arch-design/ch_network_focus.xml', 'doc/arch-design/specialized/section_software_defined_networking_specialized.xml', 'doc/arch-design/ch_compute_focus.xml']",4,32e98f50453f92cacb5733f5b02aee30640200d7,edits-arch-intros, <para>Signal processing for network function virtualization (NFV)</para> in the form of overlays or virtual local area networks (VLANs). A, <para>Signal processing for Network Function Virtualization (NFV)</para> in the form of overlays or virtual Local Area Networks (VLANs). A,87,38
openstack%2Fcloudkitty~master~I884ceec4be5803a3e29df745fc88e21ff4a040e8,openstack/cloudkitty,master,I884ceec4be5803a3e29df745fc88e21ff4a040e8,Fixed state recovery in osrf writer,MERGED,2014-08-08 09:48:44.000000000,2014-08-08 09:59:17.000000000,2014-08-08 09:59:17.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-08 09:48:44.000000000', 'files': ['cloudkitty/writer/osrf.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/f039e930d4fe9dfce6d2a6f4f5b26674b501bd78', 'message': 'Fixed state recovery in osrf writer\n\nChange-Id: I884ceec4be5803a3e29df745fc88e21ff4a040e8\n'}]",0,112813,f039e930d4fe9dfce6d2a6f4f5b26674b501bd78,7,2,1,7042,,,0,"Fixed state recovery in osrf writer

Change-Id: I884ceec4be5803a3e29df745fc88e21ff4a040e8
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/13/112813/1 && git format-patch -1 --stdout FETCH_HEAD,['cloudkitty/writer/osrf.py'],1,f039e930d4fe9dfce6d2a6f4f5b26674b501bd78,fix/writer/osrf," self._report.seek(0, 2) if self._report.tell(): self._recover_state() else: self._report.seek(0) hay = '' if last_comma > -1:", self._recover_state() if last_comma > 0:,7,2
openstack%2Fcloudkitty~master~I9c7ced18afe4c37fda427296c1054202a66b9141,openstack/cloudkitty,master,I9c7ced18afe4c37fda427296c1054202a66b9141,Moved base writer code,MERGED,2014-08-08 09:36:07.000000000,2014-08-08 09:47:52.000000000,2014-08-08 09:47:52.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-08 09:36:07.000000000', 'files': ['cloudkitty/writer/osrf.py', 'cloudkitty/writer/__init__.py', 'cloudkitty/writer/base.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/f6a299147fc51f926dd09725df8b6db962422018', 'message': 'Moved base writer code\n\nBase class is now abstract using abc.\n\nChange-Id: I9c7ced18afe4c37fda427296c1054202a66b9141\n'}]",0,112810,f6a299147fc51f926dd09725df8b6db962422018,7,2,1,7042,,,0,"Moved base writer code

Base class is now abstract using abc.

Change-Id: I9c7ced18afe4c37fda427296c1054202a66b9141
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/10/112810/1 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/writer/osrf.py', 'cloudkitty/writer/__init__.py', 'cloudkitty/writer/base.py']",3,f6a299147fc51f926dd09725df8b6db962422018,rewrite/writer,,"# -*- coding: utf-8 -*- # Copyright 2014 Objectif Libre # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # @author: Stphane Albert # import datetime from cloudkitty import state class BaseReportWriter(object): """"""Base report writer."""""" report_type = None def __init__(self, write_orchestrator, user_id, backend, state_backend): self._write_orchestrator = write_orchestrator self._write_backend = backend self._uid = user_id self._sm = state.StateManager(state_backend, None, self._uid, self.report_type) self._report = None self.period = 3600 # State vars self.checked_first_line = False self.usage_start = None self.usage_start_dt = None self.usage_end = None self.usage_end_dt = None # Current total self.total = 0 # Current usage period lines self._usage_data = {} def _gen_filename(self): raise NotImplementedError() def _open(self): filename = self._gen_filename() self._report = self._write_backend(filename, 'wb+') self._report.seek(0, 2) def _get_report_size(self): return self._report.tell() def _recover_state(self): raise NotImplementedError() def _update_state_manager(self): self._sm.set_state(self.usage_end) metadata = {'total': self.total} self._sm.set_metadata(metadata) def _get_state_manager_timeframe(self): timeframe = self._sm.get_state() self.usage_start = timeframe self.usage_start_dt = datetime.datetime.fromtimestamp(timeframe) end_frame = timeframe + self._period self.usage_end = datetime.datetime.fromtimestamp(end_frame) metadata = self._sm.get_metadata() self.total = metadata.get('total', 0) def get_timeframe(self, timeframe): return self._write_orchestrator.get_timeframe(timeframe) def _write_header(self): raise NotImplementedError() def _write(self): raise NotImplementedError() def _pre_commit(self): if self._report is None: self._open() if not self.checked_first_line: if self._get_report_size() == 0: self._write_header() else: self._recover_state() self.checked_first_line = True def _commit(self): self._pre_commit() self._write() self._update_state_manager() self._post_commit() def _post_commit(self): self._usage_data = {} def _update(self, data): for service in data: if service in self._usage_data: self._usage_data[service].extend(data[service]) else: self._usage_data[service] = data[service] # Update totals for entry in data[service]: self.total += entry['billing']['price'] def append(self, data, start, end): # FIXME we should use the real time values if self.usage_end is not None and start >= self.usage_end: self._commit() self.usage_start = None if self.usage_start is None: self.usage_start = start self.usage_end = start + self.period self.usage_start_dt = datetime.fromtimestamp(self.usage_start) self.usage_end_dt = datetime.fromtimestamp(self.usage_end) self._update(data) def commit(self): self._commit() def _close_file(self): raise NotImplementedError() def close(self): self._close_file() ",163,142
openstack%2Fhorizon~master~I7d3b7bbd94c50f5e70a7e70bdb6d4a86475e1a6e,openstack/horizon,master,I7d3b7bbd94c50f5e70a7e70bdb6d4a86475e1a6e,Ability to create data sources from job launch,MERGED,2014-07-25 18:21:17.000000000,2014-08-08 09:37:54.000000000,2014-08-08 09:37:53.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6914}, {'_account_id': 7132}, {'_account_id': 8090}, {'_account_id': 9576}, {'_account_id': 9659}]","[{'number': 1, 'created': '2014-07-25 18:21:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e5abb258477d1713df264eb201510cce94bede43', 'message': 'Ability to create data sources from job launch\n\nAdding the ability to generate data sources from\nwithin the job launch modal.\n* Change to DynamicChoiceField for input and output\n* Changed workflow for data source to properly set\n  workflow.object\n\nChange-Id: I7d3b7bbd94c50f5e70a7e70bdb6d4a86475e1a6e\nCloses-Bug: #1346931\n'}, {'number': 2, 'created': '2014-08-07 14:44:00.000000000', 'files': ['openstack_dashboard/dashboards/project/data_processing/jobs/workflows/launch.py', 'openstack_dashboard/dashboards/project/data_processing/data_sources/workflows/create.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/56334472d609f586d6d6729e62ee1f5b710b5896', 'message': 'Ability to create data sources from job launch\n\nAdding the ability to generate data sources from\nwithin the job launch modal.\n* Change to DynamicChoiceField for input and output\n* Changed workflow for data source to properly set\n  workflow.object\n\nChange-Id: I7d3b7bbd94c50f5e70a7e70bdb6d4a86475e1a6e\nCloses-Bug: #1346931\n'}]",0,109671,56334472d609f586d6d6729e62ee1f5b710b5896,19,7,2,8090,,,0,"Ability to create data sources from job launch

Adding the ability to generate data sources from
within the job launch modal.
* Change to DynamicChoiceField for input and output
* Changed workflow for data source to properly set
  workflow.object

Change-Id: I7d3b7bbd94c50f5e70a7e70bdb6d4a86475e1a6e
Closes-Bug: #1346931
",git fetch https://review.opendev.org/openstack/horizon refs/changes/71/109671/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/data_processing/jobs/workflows/launch.py', 'openstack_dashboard/dashboards/project/data_processing/data_sources/workflows/create.py']",2,e5abb258477d1713df264eb201510cce94bede43,bug/1346931, self.object = saharaclient.data_source_create(, saharaclient.data_source_create(,8,5
openstack%2Ffuel-library~master~I1f317ebbd170b7e48d9bf2afa382a5abae10278a,openstack/fuel-library,master,I1f317ebbd170b7e48d9bf2afa382a5abae10278a,Accept iptables ports for libvirt live migration,ABANDONED,2014-08-08 08:42:45.000000000,2014-08-08 09:37:01.000000000,,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 11827}]","[{'number': 1, 'created': '2014-08-08 08:42:45.000000000', 'files': ['deployment/puppet/openstack/manifests/firewall.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a0e69332808ef387158cac6511bb537e2468659d', 'message': 'Accept iptables ports for libvirt live migration\n\nChange-Id: I1f317ebbd170b7e48d9bf2afa382a5abae10278a\nCloses-Bug: 1352222\n'}]",0,112797,a0e69332808ef387158cac6511bb537e2468659d,9,9,1,6926,,,0,"Accept iptables ports for libvirt live migration

Change-Id: I1f317ebbd170b7e48d9bf2afa382a5abae10278a
Closes-Bug: 1352222
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/97/112797/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack/manifests/firewall.pp'],1,a0e69332808ef387158cac6511bb537e2468659d,bug/1352222," firewall {'120 libvirt migration': port => '49152-49215', proto => 'tcp', action => 'accept', } ",,6,0
openstack%2Fsahara~master~I1303f4b3c3bd2a8b4a883d86ba4f91aba92496e0,openstack/sahara,master,I1303f4b3c3bd2a8b4a883d86ba4f91aba92496e0,Move middleware package to api package,MERGED,2014-07-16 09:36:18.000000000,2014-08-08 09:23:04.000000000,2014-08-08 09:23:03.000000000,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8411}, {'_account_id': 8871}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-07-16 09:36:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/e528b28663e5e3fe2f625383240c67296f47c198', 'message': 'Move middleware package to api package\n\nAll middlewares could be used only for api stuff, so, moving them to the\napi package.\n\nChange-Id: I1303f4b3c3bd2a8b4a883d86ba4f91aba92496e0\n'}, {'number': 2, 'created': '2014-07-31 13:19:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/058f05259fa7e03e951281f05e1cb30d7a752fb1', 'message': 'Move middleware package to api package\n\nAll middlewares could be used only for api stuff, so, moving them to the\napi package.\n\nChange-Id: I1303f4b3c3bd2a8b4a883d86ba4f91aba92496e0\n'}, {'number': 3, 'created': '2014-07-31 15:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/e22d0d46b50c89be685b4724f6c893f76d1f7b57', 'message': 'Move middleware package to api package\n\nAll middlewares could be used only for api stuff, so, moving them to the\napi package.\n\nChange-Id: I1303f4b3c3bd2a8b4a883d86ba4f91aba92496e0\n'}, {'number': 4, 'created': '2014-08-05 13:38:38.000000000', 'files': ['sahara/api/middleware/log_exchange.py', 'sahara/api/middleware/auth_valid.py', 'sahara/api/middleware/__init__.py', 'sahara/main.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/92b2e10f726cbf124b21f169497d8f43662bfed6', 'message': 'Move middleware package to api package\n\nAll middlewares could be used only for api stuff, so, moving them to the\napi package.\n\nChange-Id: I1303f4b3c3bd2a8b4a883d86ba4f91aba92496e0\n'}]",0,107276,92b2e10f726cbf124b21f169497d8f43662bfed6,35,9,4,6786,,,0,"Move middleware package to api package

All middlewares could be used only for api stuff, so, moving them to the
api package.

Change-Id: I1303f4b3c3bd2a8b4a883d86ba4f91aba92496e0
",git fetch https://review.opendev.org/openstack/sahara refs/changes/76/107276/4 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/api/middleware/log_exchange.py', 'sahara/api/middleware/auth_valid.py', 'sahara/api/middleware/__init__.py']",3,e528b28663e5e3fe2f625383240c67296f47c198,authcleanup,,,0,0
openstack%2Ftripleo-heat-templates~master~I5769dc1dc501d48c965f8e4e36238cfcaac64a17,openstack/tripleo-heat-templates,master,I5769dc1dc501d48c965f8e4e36238cfcaac64a17,Move config options under neutron.ovs,MERGED,2014-07-23 19:31:36.000000000,2014-08-08 09:22:24.000000000,2014-08-08 08:12:49.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 4330}, {'_account_id': 7144}, {'_account_id': 7582}, {'_account_id': 8449}]","[{'number': 1, 'created': '2014-07-23 19:31:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/819d5d8c050caec02400b6b47bf6b802bf5f24c4', 'message': 'Move config options under neutron.ovs\n\nThese config options are supposed to be under neutron.ovs (see template\nfor neutron openvswitch agent). They were mistakenly moved to be just\nunder neutron when the migration to SoftwareConfig was done.\n\nChange-Id: I5769dc1dc501d48c965f8e4e36238cfcaac64a17\n'}, {'number': 2, 'created': '2014-08-05 18:40:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/30e85b300e78559175c792bd32d9bd272ed5d907', 'message': 'Move config options under neutron.ovs\n\nThese config options are supposed to be under neutron.ovs (see template\nfor neutron openvswitch agent). They were mistakenly moved to be just\nunder neutron when the migration to SoftwareConfig was done.\n\nChange-Id: I5769dc1dc501d48c965f8e4e36238cfcaac64a17\n'}, {'number': 3, 'created': '2014-08-05 21:25:10.000000000', 'files': ['swift-storage-source.yaml', 'swift-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/47568e1c163bfe856b1502445008cd1395c77f0e', 'message': 'Move config options under neutron.ovs\n\nThese config options are supposed to be under neutron.ovs (see template\nfor neutron openvswitch agent). They were mistakenly moved to be just\nunder neutron when the migration to SoftwareConfig was done.\n\nChange-Id: I5769dc1dc501d48c965f8e4e36238cfcaac64a17\n'}]",0,109090,47568e1c163bfe856b1502445008cd1395c77f0e,38,6,3,7144,,,0,"Move config options under neutron.ovs

These config options are supposed to be under neutron.ovs (see template
for neutron openvswitch agent). They were mistakenly moved to be just
under neutron when the migration to SoftwareConfig was done.

Change-Id: I5769dc1dc501d48c965f8e4e36238cfcaac64a17
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/90/109090/1 && git format-patch -1 --stdout FETCH_HEAD,['swift-source.yaml'],1,819d5d8c050caec02400b6b47bf6b802bf5f24c4,swift-fixes, enable_tunnelling: {Ref: NeutronEnableTunnelling} tenant_network_type: {Ref: NeutronNetworkType}, enable_tunnelling: {Ref: NeutronEnableTunnelling} tenant_network_type: {Ref: NeutronNetworkType},2,2
openstack%2Fcloudkitty~master~I85aace10b26d17a50f197dddddc42ca719286384,openstack/cloudkitty,master,I85aace10b26d17a50f197dddddc42ca719286384,Fixed wrong path for cloudkitty config sample,MERGED,2014-08-08 09:10:31.000000000,2014-08-08 09:22:07.000000000,2014-08-08 09:22:07.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-08 09:10:31.000000000', 'files': ['etc/cloudkitty/cloudkitty.conf.sample'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/d6948ed13afbbfacd9d2662d672068b5093e39e4', 'message': 'Fixed wrong path for cloudkitty config sample\n\nChange-Id: I85aace10b26d17a50f197dddddc42ca719286384\n'}]",0,112803,d6948ed13afbbfacd9d2662d672068b5093e39e4,7,2,1,7042,,,0,"Fixed wrong path for cloudkitty config sample

Change-Id: I85aace10b26d17a50f197dddddc42ca719286384
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/03/112803/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/cloudkitty/cloudkitty.conf.sample'],1,d6948ed13afbbfacd9d2662d672068b5093e39e4,fix/sample,,,0,0
openstack-attic%2Fopenstack-security-notes~master~Ib6158b24fbb4b1bbff328df664091f51a8013b95,openstack-attic/openstack-security-notes,master,Ib6158b24fbb4b1bbff328df664091f51a8013b95,Nova networking IPtables rules not reinstated with soft reboot,MERGED,2014-07-21 11:46:31.000000000,2014-08-08 09:13:49.000000000,2014-08-08 09:13:49.000000000,"[{'_account_id': 3}, {'_account_id': 2807}, {'_account_id': 7063}, {'_account_id': 9098}, {'_account_id': 11029}, {'_account_id': 11315}, {'_account_id': 11397}, {'_account_id': 11716}]","[{'number': 1, 'created': '2014-07-21 11:46:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/openstack-security-notes/commit/5f593b835334d7062a5a8acf1cd9753224853e87', 'message': 'Nova networking IPtables rules not reinstated with soft reboot\n\nChange-Id: Ib6158b24fbb4b1bbff328df664091f51a8013b95\nCloses-Bug: 1316822\n'}, {'number': 2, 'created': '2014-07-22 16:00:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/openstack-security-notes/commit/810f22bc06009ec78c14ed25f87f3b70107631af', 'message': 'Nova networking IPtables rules not reinstated with soft reboot\n\nChange-Id: Ib6158b24fbb4b1bbff328df664091f51a8013b95\nCloses-Bug: 1316822\n'}, {'number': 3, 'created': '2014-07-24 10:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/openstack-security-notes/commit/012619444f01fe9cf983d8a63d288e0ecf2f22a1', 'message': 'Nova networking IPtables rules not reinstated with soft reboot\n\nChange-Id: Ib6158b24fbb4b1bbff328df664091f51a8013b95\nCloses-Bug: 1316822\n'}, {'number': 4, 'created': '2014-07-24 17:48:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/openstack-security-notes/commit/590992a73e9b8cd372119366a31dbc44cabb644c', 'message': 'Nova networking IPtables rules not reinstated with soft reboot\n\nChange-Id: Ib6158b24fbb4b1bbff328df664091f51a8013b95\nCloses-Bug: 1316822\n'}, {'number': 5, 'created': '2014-07-25 10:27:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/openstack-security-notes/commit/0e55b1383481108fd73374bd94180c4467d2d044', 'message': 'Nova networking IPtables rules not reinstated with soft reboot\n\nChange-Id: Ib6158b24fbb4b1bbff328df664091f51a8013b95\nCloses-Bug: 1316822\n'}, {'number': 6, 'created': '2014-07-25 10:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/openstack-security-notes/commit/c95b0acc129899f6867fc1063ce988702c7aaefa', 'message': 'Nova networking IPtables rules not reinstated with soft reboot\n\nChange-Id: Ib6158b24fbb4b1bbff328df664091f51a8013b95\nCloses-Bug: 1316822\n'}, {'number': 7, 'created': '2014-07-25 21:35:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/openstack-security-notes/commit/c73e0dd8258c548ceac95d075a581c2f332f5596', 'message': 'Nova networking IPtables rules not reinstated with soft reboot\n\nChange-Id: Ib6158b24fbb4b1bbff328df664091f51a8013b95\nCloses-Bug: 1316822\n'}, {'number': 8, 'created': '2014-08-01 15:25:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/openstack-security-notes/commit/5f0599cb860d220de6ab8421d0f61afa653be96f', 'message': 'Nova networking IPtables rules not reinstated with soft reboot\n\nChange-Id: Ib6158b24fbb4b1bbff328df664091f51a8013b95\nCloses-Bug: 1316822\n'}, {'number': 9, 'created': '2014-08-01 22:31:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/openstack-security-notes/commit/98faa2717a952677329a1250d53ecbe68aadad7b', 'message': 'Nova networking IPtables rules not reinstated with soft reboot\n\nChange-Id: Ib6158b24fbb4b1bbff328df664091f51a8013b95\nCloses-Bug: 1316822\n'}, {'number': 10, 'created': '2014-08-07 18:00:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/openstack-security-notes/commit/48029199f1059fc75c6b72b78edd1e088c13d915', 'message': 'Nova networking IPtables rules not reinstated with soft reboot\n\nChange-Id: Ib6158b24fbb4b1bbff328df664091f51a8013b95\nCloses-Bug: 1316822\n'}, {'number': 11, 'created': '2014-08-07 18:01:24.000000000', 'files': ['notes/OSSN-0022'], 'web_link': 'https://opendev.org/openstack-attic/openstack-security-notes/commit/39c8043bdfbcf428810284cd3c37f948d613e62e', 'message': 'Nova networking IPtables rules not reinstated with soft reboot\n\nChange-Id: Ib6158b24fbb4b1bbff328df664091f51a8013b95\nCloses-Bug: 1316822\n'}]",36,108349,39c8043bdfbcf428810284cd3c37f948d613e62e,72,8,11,11397,,,0,"Nova networking IPtables rules not reinstated with soft reboot

Change-Id: Ib6158b24fbb4b1bbff328df664091f51a8013b95
Closes-Bug: 1316822
",git fetch https://review.opendev.org/openstack-attic/openstack-security-notes refs/changes/49/108349/8 && git format-patch -1 --stdout FETCH_HEAD,['notes/OSSN-0022'],1,5f593b835334d7062a5a8acf1cd9753224853e87,bug/1316822,"Soft reboot of instance does not ensure Nova Networking iptables rules are present --- ### Summary ### In deployments using Nova Networking, a soft reboot of an instance will bring it up without enforcing iptables rules. If the associated iptables rules have previously been deleted, for example by restarting the compute service, then the instance will be brought up with no iptables rules. Deployments using Neutron are not impacted. ### Affected Services / Software ### Nova, Havana, Grizzly ### Discussion ### In Nova deployments using Nova Networking, iptables is used to configure and control network traffic in and out of Nova instances. If an instance is rebooted using the soft reboot method (nova reboot <instance_id>) the IP tables rules are not re-instated when the instance boots, therefore if the rules have previously been deleted, the instance will be brought up with no iptables rules in place. Depending on the deployment architecture, this could breach security assumptions and leave an instance vulnerable to network based attacks. This situation is most likely to arise in cases where the Nova compute service has been terminated or restarted, which removes all iptables rules. ### Recommended Actions ### Do not to use the soft reboot method to start instances from the stopped state. ### Contacts / References ### This OSSN : https://wiki.openstack.org/wiki/OSSN/OSSN-0022 Original LaunchPad Bug : https://bugs.launchpad.net/ossn/+bug/1316822 OpenStack Security ML : openstack-security@lists.openstack.org OpenStack Security Group : https://launchpad.net/~openstack-ossg ",,36,0
openstack%2Fhorizon~master~I6710fa550a95659cbf5dbf8c6cf29691cfa161fe,openstack/horizon,master,I6710fa550a95659cbf5dbf8c6cf29691cfa161fe,Fix instance flavor popover table,MERGED,2014-08-08 01:12:36.000000000,2014-08-08 09:02:07.000000000,2014-08-08 09:02:06.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 8648}]","[{'number': 1, 'created': '2014-08-08 01:12:36.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/templates/instances/_instance_flavor.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/1461d2e9302b15fa55d35aa9c3395f6e31561ca8', 'message': 'Fix instance flavor popover table\n\nThe instance flavor popover table is not rendered.\n\nChange-Id: I6710fa550a95659cbf5dbf8c6cf29691cfa161fe\nCloses-bug: 1354230\n'}]",0,112743,1461d2e9302b15fa55d35aa9c3395f6e31561ca8,8,4,1,4428,,,0,"Fix instance flavor popover table

The instance flavor popover table is not rendered.

Change-Id: I6710fa550a95659cbf5dbf8c6cf29691cfa161fe
Closes-bug: 1354230
",git fetch https://review.opendev.org/openstack/horizon refs/changes/43/112743/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/instances/templates/instances/_instance_flavor.html'],1,1461d2e9302b15fa55d35aa9c3395f6e31561ca8,bug/1354230," { $(""#flavor_details_{{ id }}"").popover({html:true});","{ $(""#flavor_details_{{ id }}"").popover();",1,1
openstack%2Ffuel-main~stable%2F5.0~Idc990e1e2d537f2379231513cb1825d2ef6d172d,openstack/fuel-main,stable/5.0,Idc990e1e2d537f2379231513cb1825d2ef6d172d,Change ceph restart tests to use existing snapshots,MERGED,2014-08-07 14:12:59.000000000,2014-08-08 08:59:32.000000000,2014-08-08 08:59:31.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-08-07 14:12:59.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_restart.py', 'fuelweb_test/tests/test_ceph.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/19688897199e60a721474862ada47f48a024339b', 'message': 'Change ceph restart tests to use existing snapshots\n\nChange-Id: Idc990e1e2d537f2379231513cb1825d2ef6d172d\nCloses-Bug: #1353543\n(cherry picked from commit 97478eb1612655eedcffd25090e7270cfa91cffe)\n'}]",0,112585,19688897199e60a721474862ada47f48a024339b,9,5,1,10136,,,0,"Change ceph restart tests to use existing snapshots

Change-Id: Idc990e1e2d537f2379231513cb1825d2ef6d172d
Closes-Bug: #1353543
(cherry picked from commit 97478eb1612655eedcffd25090e7270cfa91cffe)
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/85/112585/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/tests_strength/test_restart.py', 'fuelweb_test/tests/test_ceph.py']",2,19688897199e60a721474862ada47f48a024339b,,"@test(groups=[""thread_3"", ""ceph""]) self.env.make_snapshot(""ceph_multinode_with_cinder"", is_make=True) self.env.make_snapshot(""ceph_ha"", is_make=True)","@test(groups=[""thread_1"", ""ceph""]) self.env.make_snapshot(""ceph_multinode_with_cinder"") self.env.make_snapshot(""ceph_ha"")",13,55
openstack%2Fpuppet-horizon~master~I2f94a36a63f64678581e240244f70a6d4cad1ee5,openstack/puppet-horizon,master,I2f94a36a63f64678581e240244f70a6d4cad1ee5,Allow array in cache_server_ip,MERGED,2014-07-29 01:11:35.000000000,2014-08-08 08:48:16.000000000,2014-08-08 08:48:16.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6994}]","[{'number': 1, 'created': '2014-07-29 01:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/48adf55d0e84f29f6ac0b7bdd9bcc593fa94afee', 'message': 'Allow array in cache_server_ip\n\nIf we use multiple memcached servers, we can specify an array of IP addresses\nto use rather than just one.  This also allows a string, for one memcached\nserver and for backwards compatibility.\n\nChange-Id: I2f94a36a63f64678581e240244f70a6d4cad1ee5\n'}, {'number': 2, 'created': '2014-08-07 09:20:07.000000000', 'files': ['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/83cbc3345cb48edbcc92bcbc91e9400383e05bd4', 'message': 'Allow array in cache_server_ip\n\nIf we use multiple memcached servers, we can specify an array of IP addresses\nto use rather than just one.  This also allows a string, for one memcached\nserver and for backwards compatibility.\n\nChange-Id: I2f94a36a63f64678581e240244f70a6d4cad1ee5\n'}]",0,110175,83cbc3345cb48edbcc92bcbc91e9400383e05bd4,12,3,2,10086,,,0,"Allow array in cache_server_ip

If we use multiple memcached servers, we can specify an array of IP addresses
to use rather than just one.  This also allows a string, for one memcached
server and for backwards compatibility.

Change-Id: I2f94a36a63f64678581e240244f70a6d4cad1ee5
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/75/110175/2 && git format-patch -1 --stdout FETCH_HEAD,"['templates/local_settings.py.erb', 'manifests/init.pp']",2,48adf55d0e84f29f6ac0b7bdd9bcc593fa94afee,new/cache_array,"# (optional) Memcached IP address. Can be a string, or an array. # Defaults to '127.0.0.1'.",# (optional) Memcached IP address. Defaults to '127.0.0.1'.,12,1
openstack%2Ffuel-ostf~master~Ib524dbfdce5a514a14806128b8883a8e5ef1386e,openstack/fuel-ostf,master,Ib524dbfdce5a514a14806128b8883a8e5ef1386e,Improve network error message in HealthCheck to a more informative,MERGED,2014-08-07 11:33:08.000000000,2014-08-08 08:47:27.000000000,2014-08-08 08:47:27.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8954}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-08-07 11:33:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/41a7800d09475ee188a517e9ed7c7a1016a83161', 'message': 'Improve network error message in HealthCheck to a more informative\n\nChange-Id: Ib524dbfdce5a514a14806128b8883a8e5ef1386e\nCloses-Bug: #1353408\n'}, {'number': 2, 'created': '2014-08-08 08:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/5dcd0e67610967dc3246dd162c6e0fd7cf77e286', 'message': 'Improve network error message in HealthCheck to a more informative\n\nChange-Id: Ib524dbfdce5a514a14806128b8883a8e5ef1386e\nCloses-Bug: #1353408\n'}, {'number': 3, 'created': '2014-08-08 08:15:39.000000000', 'files': ['fuel_health/nmanager.py', 'fuel_health/tests/smoke/test_nova_image_actions.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/2ced71b30141f0f87f6d8b5b0ac0e29d543d04d1', 'message': 'Improve network error message in HealthCheck to a more informative\n\nChange-Id: Ib524dbfdce5a514a14806128b8883a8e5ef1386e\nCloses-Bug: #1353408\n'}]",1,112560,2ced71b30141f0f87f6d8b5b0ac0e29d543d04d1,21,8,3,11082,,,0,"Improve network error message in HealthCheck to a more informative

Change-Id: Ib524dbfdce5a514a14806128b8883a8e5ef1386e
Closes-Bug: #1353408
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/60/112560/2 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_health/nmanager.py', 'fuel_health/tests/smoke/test_nova_image_actions.py']",2,41a7800d09475ee188a517e9ed7c7a1016a83161,bug/1353408," self.fail(""Default private network 'net04' isn't present."" ""Please verify it is properly created."")", self.fail('Private network was not created by default'),8,4
openstack%2Fpuppet-nova~stable%2Fhavana~I65bade1443395ce99e69c4704d3e1d85e851b9bb,openstack/puppet-nova,stable/havana,I65bade1443395ce99e69c4704d3e1d85e851b9bb,Normalize Gemfile & pin tests to rspec < 2.99,MERGED,2014-08-06 19:37:11.000000000,2014-08-08 08:43:41.000000000,2014-08-08 08:43:41.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 10540}]","[{'number': 1, 'created': '2014-08-06 19:37:11.000000000', 'files': ['Gemfile'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/a9b47b07c076fccc35d847bcb39a7f4321c77de1', 'message': 'Normalize Gemfile & pin tests to rspec < 2.99\n\nPin to rspec < 2.99 until rspec-puppet officially supports rspec 3.x.\nThis is to avoid warnings due to deprecated matchers in the\nrspec-puppet gem.\n\nThis change is also intended to normalize the Gemfile for all stackforge\npuppet modules.  This should facilitate pinning gem versions when\nreleasing new stable branches, since the same diff can be used for all\nrepos.\n\nConflicts:\n  Gemfile\n\nChange-Id: I65bade1443395ce99e69c4704d3e1d85e851b9bb\nPartial-Bug: #1326034\n(cherry picked from commit d691bf7e65bb34ef8eb10d1c636f0d6d221aa9dd)\n'}]",0,112393,a9b47b07c076fccc35d847bcb39a7f4321c77de1,10,4,1,7156,,,0,"Normalize Gemfile & pin tests to rspec < 2.99

Pin to rspec < 2.99 until rspec-puppet officially supports rspec 3.x.
This is to avoid warnings due to deprecated matchers in the
rspec-puppet gem.

This change is also intended to normalize the Gemfile for all stackforge
puppet modules.  This should facilitate pinning gem versions when
releasing new stable branches, since the same diff can be used for all
repos.

Conflicts:
  Gemfile

Change-Id: I65bade1443395ce99e69c4704d3e1d85e851b9bb
Partial-Bug: #1326034
(cherry picked from commit d691bf7e65bb34ef8eb10d1c636f0d6d221aa9dd)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/93/112393/1 && git format-patch -1 --stdout FETCH_HEAD,['Gemfile'],1,a9b47b07c076fccc35d847bcb39a7f4321c77de1,bug/1290634," gem 'rake', '10.1.1' gem 'rspec', '< 2.99' gem 'json' gem 'webmock'"," gem 'rake', '~> 10.1.1'",4,1
openstack%2Fpuppet-glance~stable%2Fhavana~I08dfd8e6a07d60e2421045a0f9d729cc9c26899c,openstack/puppet-glance,stable/havana,I08dfd8e6a07d60e2421045a0f9d729cc9c26899c,Normalize Gemfile & pin tests to rspec < 2.99,MERGED,2014-08-06 19:46:26.000000000,2014-08-08 08:38:25.000000000,2014-08-08 08:38:25.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 10540}]","[{'number': 1, 'created': '2014-08-06 19:46:26.000000000', 'files': ['Gemfile'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/c8cd5e40f545eb7f3844cc85ca9952ab57a1f8bf', 'message': 'Normalize Gemfile & pin tests to rspec < 2.99\n\nPin to rspec < 2.99 until rspec-puppet officially supports rspec 3.x.\nThis is to avoid warnings due to deprecated matchers in the\nrspec-puppet gem.\n\nThis change is also intended to normalize the Gemfile for all stackforge\npuppet modules.  This should facilitate pinning gem versions when\nreleasing new stable branches, since the same diff can be used for all\nrepos.\n\nConflicts:\n  Gemfile\n\nChange-Id: I08dfd8e6a07d60e2421045a0f9d729cc9c26899c\nPartial-Bug: #1326034\n(cherry picked from commit 6e38374e16276619161f7bddd185155493c5d908)\n'}]",0,112397,c8cd5e40f545eb7f3844cc85ca9952ab57a1f8bf,10,4,1,7156,,,0,"Normalize Gemfile & pin tests to rspec < 2.99

Pin to rspec < 2.99 until rspec-puppet officially supports rspec 3.x.
This is to avoid warnings due to deprecated matchers in the
rspec-puppet gem.

This change is also intended to normalize the Gemfile for all stackforge
puppet modules.  This should facilitate pinning gem versions when
releasing new stable branches, since the same diff can be used for all
repos.

Conflicts:
  Gemfile

Change-Id: I08dfd8e6a07d60e2421045a0f9d729cc9c26899c
Partial-Bug: #1326034
(cherry picked from commit 6e38374e16276619161f7bddd185155493c5d908)
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/97/112397/1 && git format-patch -1 --stdout FETCH_HEAD,['Gemfile'],1,c8cd5e40f545eb7f3844cc85ca9952ab57a1f8bf,bp/glance-custom-config," gem 'rake', '10.1.1' gem 'rspec', '< 2.99' gem 'json' gem 'webmock'"," gem 'rake', '~> 10.1.1'",4,1
openstack%2Fpuppet-neutron~stable%2Fhavana~Id8595fc2fd8b4e4bec4ba60d85696983fb632a18,openstack/puppet-neutron,stable/havana,Id8595fc2fd8b4e4bec4ba60d85696983fb632a18,Normalize Gemfile & pin tests to rspec < 2.99,MERGED,2014-08-06 19:51:27.000000000,2014-08-08 08:38:02.000000000,2014-08-08 08:38:02.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 10540}]","[{'number': 1, 'created': '2014-08-06 19:51:27.000000000', 'files': ['Gemfile'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/16682d963580397fa526be4ba296f9e1a62c08eb', 'message': 'Normalize Gemfile & pin tests to rspec < 2.99\n\nPin to rspec < 2.99 until rspec-puppet officially supports rspec 3.x.\nThis is to avoid warnings due to deprecated matchers in the\nrspec-puppet gem.\n\nThis change is also intended to normalize the Gemfile for all stackforge\npuppet modules.  This should facilitate pinning gem versions when\nreleasing new stable branches, since the same diff can be used for all\nrepos.\n\nConflicts:\n  Gemfile\n\nChange-Id: Id8595fc2fd8b4e4bec4ba60d85696983fb632a18\nPartial-Bug: #1326034\n(cherry picked from commit 33798065544f3e23508c12d8a3bda1db09980ba3)\n'}]",0,112400,16682d963580397fa526be4ba296f9e1a62c08eb,10,4,1,7156,,,0,"Normalize Gemfile & pin tests to rspec < 2.99

Pin to rspec < 2.99 until rspec-puppet officially supports rspec 3.x.
This is to avoid warnings due to deprecated matchers in the
rspec-puppet gem.

This change is also intended to normalize the Gemfile for all stackforge
puppet modules.  This should facilitate pinning gem versions when
releasing new stable branches, since the same diff can be used for all
repos.

Conflicts:
  Gemfile

Change-Id: Id8595fc2fd8b4e4bec4ba60d85696983fb632a18
Partial-Bug: #1326034
(cherry picked from commit 33798065544f3e23508c12d8a3bda1db09980ba3)
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/00/112400/1 && git format-patch -1 --stdout FETCH_HEAD,['Gemfile'],1,16682d963580397fa526be4ba296f9e1a62c08eb,bug/1326034," gem 'rake', '10.1.1' gem 'rspec', '< 2.99' gem 'json' gem 'webmock'"," gem 'rspec', '~> 2.14.0' gem 'mocha', '~> 0.10.5' gem 'rspec-puppet', '~> 1.0.1' gem 'rake', '~> 10.1.1'",4,4
openstack%2Fopenstack-manuals~master~I6fe0ff4ad10b938935057a7a9c4c2fbcdd73c335,openstack/openstack-manuals,master,I6fe0ff4ad10b938935057a7a9c4c2fbcdd73c335,Fix typos in VMware glance commands,MERGED,2014-08-07 16:37:16.000000000,2014-08-08 08:37:22.000000000,2014-08-08 08:37:22.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 3153}, {'_account_id': 6547}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-08-07 16:37:16.000000000', 'files': ['doc/config-reference/compute/section_hypervisor_vmware.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/61b2490b33fa9aadc09eba2351f7f1cc483c3317', 'message': 'Fix typos in VMware glance commands\n\nSome parameters should use hyphens instead of underscores, otherwise the commands would fail.\n\nChange-Id: I6fe0ff4ad10b938935057a7a9c4c2fbcdd73c335\nCloses-Bug: #1352430\n'}]",0,112619,61b2490b33fa9aadc09eba2351f7f1cc483c3317,11,5,1,12827,,,0,"Fix typos in VMware glance commands

Some parameters should use hyphens instead of underscores, otherwise the commands would fail.

Change-Id: I6fe0ff4ad10b938935057a7a9c4c2fbcdd73c335
Closes-Bug: #1352430
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/19/112619/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/compute/section_hypervisor_vmware.xml'],1,61b2490b33fa9aadc09eba2351f7f1cc483c3317,bug/1352430," <screen><prompt>$</prompt> <userinput>glance image-create --name=""ubuntu-sparse"" --disk-format=vmdk \ --container-format=bare \ <screen><prompt>$</prompt> <userinput>glance image-create --name=""ubuntu-thick-scsi"" --disk-format=vmdk \ --container-format=bare \ <screen><prompt>$</prompt> <userinput>glance image-create --name=""ubuntu-thick-scsi"" --disk-format=vmdk \ --container-format=bare \"," <screen><prompt>$</prompt> <userinput>glance image-create --name=""ubuntu-sparse"" --disk_format=vmdk \ --container_format=bare \ <screen><prompt>$</prompt> <userinput>glance image-create --name=""ubuntu-thick-scsi"" --disk_format=vmdk \ --container_format=bare \ <screen><prompt>$</prompt> <userinput>glance image-create --name=""ubuntu-thick-scsi"" --disk_format=vmdk \ --container_format=bare \",6,6
openstack%2Fpuppet-ceilometer~stable%2Fhavana~Ia1286824cebca09e20bf6d11a3435982b93442b9,openstack/puppet-ceilometer,stable/havana,Ia1286824cebca09e20bf6d11a3435982b93442b9,Normalize Gemfile & pin tests to rspec < 2.99,MERGED,2014-08-06 19:52:55.000000000,2014-08-08 08:36:27.000000000,2014-08-08 08:36:27.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 10540}]","[{'number': 1, 'created': '2014-08-06 19:52:55.000000000', 'files': ['Gemfile'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/a7d368dc4d2e85103fc058149d45140431b53743', 'message': 'Normalize Gemfile & pin tests to rspec < 2.99\n\nPin to rspec < 2.99 until rspec-puppet officially supports rspec 3.x.\nThis is to avoid warnings due to deprecated matchers in the\nrspec-puppet gem.\n\nThis change is also intended to normalize the Gemfile for all stackforge\npuppet modules.  This should facilitate pinning gem versions when\nreleasing new stable branches, since the same diff can be used for all\nrepos.\n\nChange-Id: Ia1286824cebca09e20bf6d11a3435982b93442b9\nPartial-Bug: #1326034\n(cherry picked from commit bea7794633943e454fe3e99ee119298c3d0000ff)\n'}]",0,112401,a7d368dc4d2e85103fc058149d45140431b53743,10,4,1,7156,,,0,"Normalize Gemfile & pin tests to rspec < 2.99

Pin to rspec < 2.99 until rspec-puppet officially supports rspec 3.x.
This is to avoid warnings due to deprecated matchers in the
rspec-puppet gem.

This change is also intended to normalize the Gemfile for all stackforge
puppet modules.  This should facilitate pinning gem versions when
releasing new stable branches, since the same diff can be used for all
repos.

Change-Id: Ia1286824cebca09e20bf6d11a3435982b93442b9
Partial-Bug: #1326034
(cherry picked from commit bea7794633943e454fe3e99ee119298c3d0000ff)
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/01/112401/1 && git format-patch -1 --stdout FETCH_HEAD,['Gemfile'],1,a7d368dc4d2e85103fc058149d45140431b53743,bug/1326034," gem 'rspec', '< 2.99' gem 'json' gem 'webmock'",,3,0
openstack%2Fpuppet-ceilometer~master~If64f1ea641c5d99c0adf2104a308c2d5442c3324,openstack/puppet-ceilometer,master,If64f1ea641c5d99c0adf2104a308c2d5442c3324,Fix ceilometer agent notification package error,MERGED,2014-08-07 07:12:54.000000000,2014-08-08 08:32:09.000000000,2014-08-08 08:32:09.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7156}, {'_account_id': 8482}]","[{'number': 1, 'created': '2014-08-07 07:12:54.000000000', 'files': ['spec/classes/ceilometer_agent_notification_spec.rb', 'manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/3c38c6522de80d53a8b0b7d0621f222c12928295', 'message': 'Fix ceilometer agent notification package error\n\nceilometer-notification package name should be\nopenstack-ceilometer-notification in RHEL.\nSee more info in related bug tracker record.\n\nChange-Id: If64f1ea641c5d99c0adf2104a308c2d5442c3324\nCloses-Bug: #1353844\n'}]",0,112496,3c38c6522de80d53a8b0b7d0621f222c12928295,11,4,1,1607,,,0,"Fix ceilometer agent notification package error

ceilometer-notification package name should be
openstack-ceilometer-notification in RHEL.
See more info in related bug tracker record.

Change-Id: If64f1ea641c5d99c0adf2104a308c2d5442c3324
Closes-Bug: #1353844
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/96/112496/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/ceilometer_agent_notification_spec.rb', 'manifests/params.pp']",2,3c38c6522de80d53a8b0b7d0621f222c12928295,bug/1353844, $agent_notification_package_name = 'openstack-ceilometer-notification', $agent_notification_package_name = 'openstack-ceilometer-collector' # notification agent is included in collector package:,6,7
openstack%2Ftempest~master~Ib492e291f5c64a18256cefbda11f81ff33f03861,openstack/tempest,master,Ib492e291f5c64a18256cefbda11f81ff33f03861,Fix typo in comment,MERGED,2014-08-07 10:44:09.000000000,2014-08-08 08:31:20.000000000,2014-08-08 08:31:19.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 6167}, {'_account_id': 7872}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-07 10:44:09.000000000', 'files': ['tempest/api_schema/response/compute/v2/flavors.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/ba63906823995c374875d4b4fc2a1b2c2c89bcb6', 'message': 'Fix typo in comment\n\nFixes a typo in flavor response validation.\n\nChange-Id: Ib492e291f5c64a18256cefbda11f81ff33f03861\n'}]",0,112548,ba63906823995c374875d4b4fc2a1b2c2c89bcb6,16,6,1,7872,,,0,"Fix typo in comment

Fixes a typo in flavor response validation.

Change-Id: Ib492e291f5c64a18256cefbda11f81ff33f03861
",git fetch https://review.opendev.org/openstack/tempest refs/changes/48/112548/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api_schema/response/compute/v2/flavors.py'],1,ba63906823995c374875d4b4fc2a1b2c2c89bcb6,,"# 'swap' attributes comes as integer value but if it is empty it comes as """".# 'swap' attributes comes as integer value but if it is empty it comes as """".","# 'swap' attributes comes as integre value but if it is empty it comes as """".# 'swap' attributes comes as integre value but if it is empty it comes as """".",2,2
openstack%2Fheat~master~I80f325c9be9c171c2dc8d5526570bf64f0f87c78,openstack/heat,master,I80f325c9be9c171c2dc8d5526570bf64f0f87c78,Refactor service readiness notification,MERGED,2014-05-06 19:54:45.000000000,2014-08-08 08:17:58.000000000,2014-08-08 08:17:57.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 7385}, {'_account_id': 8161}, {'_account_id': 8289}]","[{'number': 1, 'created': '2014-05-06 19:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/db4d0c9b6bacf485e11ae4c3d9242d8bd7803fb3', 'message': 'Refactor service readiness notification\n\nBuild upon cceda95a35f18f5f7b52daaf0662a4cd3768b3ac\napply Oslo systemd module\n - it was imported in aef33d2d716c064f1f571c334fd36b1ea5928d5c\ndrop heat.common.systemd\ndrop onready configuration parameter\n - systemd notification is no-op when not running inside systemd\n\nOslo commit 53e1214c092f09e3851b1a1b55289a93a72b09ec\nImplements: blueprint systemd-integration\n\nChange-Id: I80f325c9be9c171c2dc8d5526570bf64f0f87c78\n'}, {'number': 2, 'created': '2014-05-07 10:32:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/97c8709529a203dd219d19bd7c74981af4e395b7', 'message': 'Refactor service readiness notification\n\nBuild upon cceda95a35f18f5f7b52daaf0662a4cd3768b3ac\napply Oslo systemd module\n - it was imported in aef33d2d716c064f1f571c334fd36b1ea5928d5c\ndrop heat.common.systemd\ndrop onready configuration parameter\n - systemd notification is no-op when not running inside systemd\n\nOslo commit 53e1214c092f09e3851b1a1b55289a93a72b09ec\nImplements: blueprint systemd-integration\n\nChange-Id: I80f325c9be9c171c2dc8d5526570bf64f0f87c78\n'}, {'number': 3, 'created': '2014-06-26 16:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/13c5b6f15a75fd0019725799a99ca4dc8629b897', 'message': 'Refactor service readiness notification\n\nBuild upon cceda95a35f18f5f7b52daaf0662a4cd3768b3ac\napply Oslo systemd module\n - it was imported in aef33d2d716c064f1f571c334fd36b1ea5928d5c\ndrop heat.common.systemd\ndrop onready configuration parameter\n - systemd notification is no-op when not running inside systemd\n\nOslo commit 53e1214c092f09e3851b1a1b55289a93a72b09ec\nImplements: blueprint systemd-integration\n\nChange-Id: I80f325c9be9c171c2dc8d5526570bf64f0f87c78\n'}, {'number': 4, 'created': '2014-07-16 09:03:53.000000000', 'files': ['etc/heat/heat.conf.sample', 'bin/heat-api-cloudwatch', 'heat/common/systemd.py', 'heat/common/notify.py', 'bin/heat-api-cfn', 'bin/heat-api', 'bin/heat-engine', 'heat/common/config.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/46d6b9306c26f36bc2d490afd9fcab30aa4725f5', 'message': 'Refactor service readiness notification\n\nBuild upon cceda95a35f18f5f7b52daaf0662a4cd3768b3ac apply Oslo systemd\nmodule. It was imported in aef33d2d716c064f1f571c334fd36b1ea5928d5c. It\nalso drops heat.common.systemd and deprecates onready configuration\nparameter.\n\nOslo commit 53e1214c092f09e3851b1a1b55289a93a72b09ec\n\nChange-Id: I80f325c9be9c171c2dc8d5526570bf64f0f87c78\n'}]",3,92456,46d6b9306c26f36bc2d490afd9fcab30aa4725f5,30,7,4,1955,,,0,"Refactor service readiness notification

Build upon cceda95a35f18f5f7b52daaf0662a4cd3768b3ac apply Oslo systemd
module. It was imported in aef33d2d716c064f1f571c334fd36b1ea5928d5c. It
also drops heat.common.systemd and deprecates onready configuration
parameter.

Oslo commit 53e1214c092f09e3851b1a1b55289a93a72b09ec

Change-Id: I80f325c9be9c171c2dc8d5526570bf64f0f87c78
",git fetch https://review.opendev.org/openstack/heat refs/changes/56/92456/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/heat/heat.conf.sample', 'bin/heat-api-cloudwatch', 'heat/common/systemd.py', 'heat/common/notify.py', 'bin/heat-api-cfn', 'bin/heat-api', 'bin/heat-engine', 'heat/common/config.py']",8,db4d0c9b6bacf485e11ae4c3d9242d8bd7803fb3,bp/systemd-integration, ' for stack locking.'))]," ' for stack locking.')), cfg.StrOpt('onready', help=_('onready allows you to send a notification when the' ' heat processes are ready to serve. This is either a' ' module with the notify() method or a shell command. ' ' To enable notifications with systemd, one may use' ' the \'systemd-notify --ready\' shell command or' ' the \'heat.common.systemd\' notification module.'))]",9,107
openstack%2Fhorizon~master~I7c621e77a9f39424eeee8c022abea28bf116de1b,openstack/horizon,master,I7c621e77a9f39424eeee8c022abea28bf116de1b,Imported Translations from Transifex,MERGED,2014-08-08 06:03:08.000000000,2014-08-08 08:14:22.000000000,2014-08-08 08:14:22.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-08-08 06:03:08.000000000', 'files': ['openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'horizon/locale/ko_KR/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a8161dd620d33112253e8d75d98319e6149adbf5', 'message': 'Imported Translations from Transifex\n\nChange-Id: I7c621e77a9f39424eeee8c022abea28bf116de1b\n'}]",0,112760,a8161dd620d33112253e8d75d98319e6149adbf5,8,3,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I7c621e77a9f39424eeee8c022abea28bf116de1b
",git fetch https://review.opendev.org/openstack/horizon refs/changes/60/112760/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'horizon/locale/ko_KR/LC_MESSAGES/django.po']",4,a8161dd620d33112253e8d75d98319e6149adbf5,transifex/translations,"""POT-Creation-Date: 2014-08-07 05:09-0500\n"" ""PO-Revision-Date: 2014-08-07 06:30+0000\n"" ""Last-Translator: Sungjin Kang <potopro@gmail.com>\n""msgstr "" \""%(name)s\"" %(resource)s   ."" #: exceptions.py:285#: exceptions.py:288#: tables/actions.py:747#: tables/actions.py:748#: tables/actions.py:780#: tables/actions.py:781","""POT-Creation-Date: 2014-08-03 00:01-0500\n"" ""PO-Revision-Date: 2014-08-02 15:19+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgstr """" #: exceptions.py:284#: exceptions.py:287#: tables/actions.py:721#: tables/actions.py:722#: tables/actions.py:740#: tables/actions.py:741",344,344
openstack%2Fhorizon~master~I45994dec77d1eb2ca36036eccf8ff8ef0911eea8,openstack/horizon,master,I45994dec77d1eb2ca36036eccf8ff8ef0911eea8,Grouping of DataTable rows,ABANDONED,2014-04-28 20:01:23.000000000,2014-08-08 07:44:57.000000000,,"[{'_account_id': 3}, {'_account_id': 8648}]","[{'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': ['horizon/tables/base.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e40bbb8fe3d02b131b739c12ff109789ad62f913', 'message': 'Grouping of DataTable rows\n\nWork in progress\n\nChange-Id: I45994dec77d1eb2ca36036eccf8ff8ef0911eea8\nimplements: blueprint datatable-row-groups\n'}]",0,66356,e40bbb8fe3d02b131b739c12ff109789ad62f913,9,2,1,8648,,,0,"Grouping of DataTable rows

Work in progress

Change-Id: I45994dec77d1eb2ca36036eccf8ff8ef0911eea8
implements: blueprint datatable-row-groups
",git fetch https://review.opendev.org/openstack/horizon refs/changes/56/66356/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/tables/base.py'],1,e40bbb8fe3d02b131b739c12ff109789ad62f913,bp/datatable-row-groups,"class GroupingTitleRow(html.HTMLElement): """"""A row that separates different row groupings."""""" def render(self): return mark_safe('</tbody><tbody>') .. attribute:: grouping_column The name of the column to be used for grouping rows of the table. Defaults to ``None``, which means that no grouping will occur. self.grouping_column = getattr(options, 'grouping_column', None) nothing = object() last_grouping_value = nothing if self._meta.grouping_column: grouping_value = datum[self._meta.grouping_column] if (last_grouping_value is not nothing and grouping_value != last_grouping_value): rows.append(GroupingTitleRow(grouping_value)) last_grouping_value = grouping_value",,21,0
openstack%2Fhorizon~master~I294cfa39cb4aa9f6dd0a4fa2c4bb83e183902a22,openstack/horizon,master,I294cfa39cb4aa9f6dd0a4fa2c4bb83e183902a22,Downgrade the jquery.tablesorter and upgrade qunit,ABANDONED,2014-07-10 10:06:25.000000000,2014-08-08 07:42:33.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-07-10 10:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/00baff9ec1d8e60d883a0b1251f969f29dba4a59', 'message': 'Downgrade the jquery.tablesorter and qunit libraries\n\nThis patch downgrades the jquery.tablesorter from version\n2.14.5 to version 2.0.5b and qunit from version 1.14.1\n(unreleased) to 1.14.0 to match the versions available in\nDebian stable.\n\nChange-Id: I294cfa39cb4aa9f6dd0a4fa2c4bb83e183902a22\n'}, {'number': 2, 'created': '2014-07-10 10:13:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4fdc8972eabc532db5add9005840d5d60c612613', 'message': 'Downgrade the jquery.tablesorter and upgrade qunit\n\nThis patch changes the jquery.tablesorter from version\n2.14.5 to version 2.0.5b and qunit from version 1.9.0pre\n(unreleased) to 1.14.0 to match the versions available in\nDebian stable.\n\nChange-Id: I294cfa39cb4aa9f6dd0a4fa2c4bb83e183902a22\n'}, {'number': 3, 'created': '2014-07-28 06:13:14.000000000', 'files': ['horizon/static/horizon/lib/jquery/jquery.tablesorter.js', 'horizon/static/horizon/lib/qunit/qunit.css', 'horizon/static/horizon/lib/qunit/qunit.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/cc473f55ab73e029e590fa056920c3c8f6bc9fa9', 'message': 'Downgrade the jquery.tablesorter and upgrade qunit\n\nThis patch changes the jquery.tablesorter from version\n2.14.5 to version 2.0.5b and qunit from version 1.9.0pre\n(unreleased) to 1.14.0 to match the versions available in\nDebian stable.\n\nChange-Id: I294cfa39cb4aa9f6dd0a4fa2c4bb83e183902a22\n'}]",0,106004,cc473f55ab73e029e590fa056920c3c8f6bc9fa9,9,1,3,8648,,,0,"Downgrade the jquery.tablesorter and upgrade qunit

This patch changes the jquery.tablesorter from version
2.14.5 to version 2.0.5b and qunit from version 1.9.0pre
(unreleased) to 1.14.0 to match the versions available in
Debian stable.

Change-Id: I294cfa39cb4aa9f6dd0a4fa2c4bb83e183902a22
",git fetch https://review.opendev.org/openstack/horizon refs/changes/04/106004/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/horizon/lib/jquery/jquery.tablesorter.js', 'horizon/static/horizon/lib/qunit/qunit.css', 'horizon/static/horizon/lib/qunit/qunit.js']",3,00baff9ec1d8e60d883a0b1251f969f29dba4a59,js-lib-downgrade,"/*! * QUnit 1.14.0 * http://qunitjs.com/ * * Copyright 2013 jQuery Foundation and other contributors * Released under the MIT license * http://jquery.org/license * * Date: 2014-01-31T16:40Z assert, // Keep a local reference to Date (GH-283) Date = window.Date, setTimeout = window.setTimeout, clearTimeout = window.clearTimeout, defined = { document: typeof window.document !== ""undefined"", setTimeout: typeof window.setTimeout !== ""undefined"", sessionStorage: (function() { var x = ""qunit-test-string""; try { sessionStorage.setItem( x, x ); sessionStorage.removeItem( x ); return true; } catch( e ) { return false; } }()) }, /** * Provides a normalized error string, correcting an issue * with IE 7 (and prior) where Error.prototype.toString is * not properly implemented * * Based on http://es5.github.com/#x15.11.4.4 * * @param {String|Error} error * @return {String} error message */ errorString = function( error ) { var name, message, errorString = error.toString(); if ( errorString.substring( 0, 7 ) === ""[object"" ) { name = error.name ? error.name.toString() : ""Error""; message = error.message ? error.message.toString() : """"; if ( name && message ) { return name + "": "" + message; } else if ( name ) { return name; } else if ( message ) { return message; } else { return ""Error""; } } else { return errorString; } }, /** * Makes a clone of an object using only Array or Object as base, * and copies over the own enumerable properties. * * @param {Object} obj * @return {Object} New object with only the own properties (recursively). */ objectValues = function( obj ) { // Grunt 0.3.x uses an older version of jshint that still has jshint/jshint#392. /*jshint newcap: false */ var key, val, vals = QUnit.is( ""array"", obj ) ? [] : {}; for ( key in obj ) { if ( hasOwn.call( obj, key ) ) { val = obj[key]; vals[key] = val === Object(val) ? objectValues(val) : val; } } return vals; }; // Root QUnit object. // `QUnit` initialized at top of scope QUnit = { // call on start of module test to prepend name to all tests module: function( name, testEnvironment ) { config.currentModule = name; config.currentModuleTestEnvironment = testEnvironment; config.modules[name] = true; }, asyncTest: function( testName, expected, callback ) { if ( arguments.length === 2 ) { callback = expected; expected = null; } QUnit.test( testName, expected, callback, true ); }, test: function( testName, expected, callback, async ) { var test, nameHtml = ""<span class='test-name'>"" + escapeText( testName ) + ""</span>""; if ( arguments.length === 2 ) { callback = expected; expected = null; } if ( config.currentModule ) { nameHtml = ""<span class='module-name'>"" + escapeText( config.currentModule ) + ""</span>: "" + nameHtml; } test = new Test({ nameHtml: nameHtml, testName: testName, expected: expected, async: async, callback: callback, module: config.currentModule, moduleTestEnvironment: config.currentModuleTestEnvironment, stack: sourceFromStacktrace( 2 ) }); if ( !validTest( test ) ) { return; } test.queue(); }, // Specify the number of expected assertions to guarantee that failed test (no assertions are run at all) don't slip through. expect: function( asserts ) { if (arguments.length === 1) { config.current.expected = asserts; } else { return config.current.expected; } }, start: function( count ) { // QUnit hasn't been initialized yet. // Note: RequireJS (et al) may delay onLoad if ( config.semaphore === undefined ) { QUnit.begin(function() { // This is triggered at the top of QUnit.load, push start() to the event loop, to allow QUnit.load to finish first setTimeout(function() { QUnit.start( count ); }); }); return; } config.semaphore -= count || 1; // don't start until equal number of stop-calls if ( config.semaphore > 0 ) { return; } // ignore if start is called more often then stop if ( config.semaphore < 0 ) { config.semaphore = 0; QUnit.pushFailure( ""Called start() while already started (QUnit.config.semaphore was 0 already)"", null, sourceFromStacktrace(2) ); return; } // A slight delay, to avoid any current callbacks if ( defined.setTimeout ) { setTimeout(function() { if ( config.semaphore > 0 ) { return; } if ( config.timeout ) { clearTimeout( config.timeout ); } config.blocking = false; process( true ); }, 13); } else { config.blocking = false; process( true ); } }, stop: function( count ) { config.semaphore += count || 1; config.blocking = true; if ( config.testTimeout && defined.setTimeout ) { clearTimeout( config.timeout ); config.timeout = setTimeout(function() { QUnit.ok( false, ""Test timed out"" ); config.semaphore = 1; QUnit.start(); }, config.testTimeout ); } } }; // We use the prototype to distinguish between properties that should // be exposed as globals (and in exports) and those that shouldn't (function() { function F() {} F.prototype = QUnit; QUnit = new F(); // Make F QUnit's constructor so that we can add to the prototype later QUnit.constructor = F; }()); /** * Config object: Maintain internal state * Later exposed as QUnit.config * `config` initialized at top of scope */ config = { // The queue of tests to run queue: [], // block until document ready blocking: true, // when enabled, show only failing tests // gets persisted through sessionStorage and can be changed in UI via checkbox hidepassed: false, // by default, run previously failed tests first // very useful in combination with ""Hide passed tests"" checked reorder: true, // by default, modify document.title when suite is done altertitle: true, // by default, scroll to top of the page when suite is done scrolltop: true, // when enabled, all tests must call expect() requireExpects: false, // add checkboxes that are persisted in the query-string // when enabled, the id is set to `true` as a `QUnit.config` property urlConfig: [ { id: ""noglobals"", label: ""Check for Globals"", tooltip: ""Enabling this will test if any test introduces new properties on the `window` object. Stored as query-strings."" }, { id: ""notrycatch"", label: ""No try-catch"", tooltip: ""Enabling this will run tests outside of a try-catch block. Makes debugging exceptions in IE reasonable. Stored as query-strings."" } ], // Set of all modules. modules: {}, // logging callback queues begin: [], done: [], log: [], testStart: [], testDone: [], moduleStart: [], moduleDone: [] }; // Initialize more QUnit.config and QUnit.urlParams (function() { var i, current, location = window.location || { search: """", protocol: ""file:"" }, params = location.search.slice( 1 ).split( ""&"" ), length = params.length, urlParams = {}; if ( params[ 0 ] ) { for ( i = 0; i < length; i++ ) { current = params[ i ].split( ""="" ); current[ 0 ] = decodeURIComponent( current[ 0 ] ); // allow just a key to turn on a flag, e.g., test.html?noglobals current[ 1 ] = current[ 1 ] ? decodeURIComponent( current[ 1 ] ) : true; if ( urlParams[ current[ 0 ] ] ) { urlParams[ current[ 0 ] ] = [].concat( urlParams[ current[ 0 ] ], current[ 1 ] ); } else { urlParams[ current[ 0 ] ] = current[ 1 ]; } } } QUnit.urlParams = urlParams; // String search anywhere in moduleName+testName config.filter = urlParams.filter; // Exact match of the module name config.module = urlParams.module; config.testNumber = []; if ( urlParams.testNumber ) { // Ensure that urlParams.testNumber is an array urlParams.testNumber = [].concat( urlParams.testNumber ); for ( i = 0; i < urlParams.testNumber.length; i++ ) { current = urlParams.testNumber[ i ]; config.testNumber.push( parseInt( current, 10 ) ); } } // Figure out if we're running the tests from a server or not QUnit.isLocal = location.protocol === ""file:""; }()); extend( QUnit, { config: config, // Initialize the configuration options init: function() { extend( config, { stats: { all: 0, bad: 0 }, moduleStats: { all: 0, bad: 0 }, started: +new Date(), updateRate: 1000, blocking: false, autostart: true, autorun: false, filter: """", queue: [], semaphore: 1 }); var tests, banner, result, qunit = id( ""qunit"" ); if ( qunit ) { qunit.innerHTML = ""<h1 id='qunit-header'>"" + escapeText( document.title ) + ""</h1>"" + ""<h2 id='qunit-banner'></h2>"" + ""<div id='qunit-testrunner-toolbar'></div>"" + ""<h2 id='qunit-userAgent'></h2>"" + ""<ol id='qunit-tests'></ol>""; } tests = id( ""qunit-tests"" ); banner = id( ""qunit-banner"" ); result = id( ""qunit-testresult"" ); if ( tests ) { tests.innerHTML = """"; } if ( banner ) { banner.className = """"; } if ( result ) { result.parentNode.removeChild( result ); } if ( tests ) { result = document.createElement( ""p"" ); result.id = ""qunit-testresult""; result.className = ""result""; tests.parentNode.insertBefore( result, tests ); result.innerHTML = ""Running...<br/>&nbsp;""; } }, // Resets the test setup. Useful for tests that modify the DOM. /* DEPRECATED: Use multiple tests instead of resetting inside a test. Use testStart or testDone for custom cleanup. This method will throw an error in 2.0, and will be removed in 2.1 */ reset: function() { var fixture = id( ""qunit-fixture"" ); if ( fixture ) { fixture.innerHTML = config.fixture; } }, // Safe object type checking is: function( type, obj ) { return QUnit.objectType( obj ) === type; }, objectType: function( obj ) { if ( typeof obj === ""undefined"" ) { return ""undefined""; } // Consider: typeof null === object if ( obj === null ) { return ""null""; } var match = toString.call( obj ).match(/^\[object\s(.*)\]$/), type = match && match[1] || """"; switch ( type ) { case ""Number"": if ( isNaN(obj) ) { return ""nan""; } return ""number""; case ""String"": case ""Boolean"": case ""Array"": case ""Date"": case ""RegExp"": case ""Function"": return type.toLowerCase(); } if ( typeof obj === ""object"" ) { return ""object""; } return undefined; }, push: function( result, actual, expected, message ) { if ( !config.current ) { throw new Error( ""assertion outside test context, was "" + sourceFromStacktrace() ); } var output, source, details = { module: config.current.module, name: config.current.testName, result: result, message: message, actual: actual, expected: expected }; message = escapeText( message ) || ( result ? ""okay"" : ""failed"" ); message = ""<span class='test-message'>"" + message + ""</span>""; output = message; if ( !result ) { expected = escapeText( QUnit.jsDump.parse(expected) ); actual = escapeText( QUnit.jsDump.parse(actual) ); output += ""<table><tr class='test-expected'><th>Expected: </th><td><pre>"" + expected + ""</pre></td></tr>""; if ( actual !== expected ) { output += ""<tr class='test-actual'><th>Result: </th><td><pre>"" + actual + ""</pre></td></tr>""; output += ""<tr class='test-diff'><th>Diff: </th><td><pre>"" + QUnit.diff( expected, actual ) + ""</pre></td></tr>""; } source = sourceFromStacktrace(); if ( source ) { details.source = source; output += ""<tr class='test-source'><th>Source: </th><td><pre>"" + escapeText( source ) + ""</pre></td></tr>""; } output += ""</table>""; } runLoggingCallbacks( ""log"", QUnit, details ); config.current.assertions.push({ result: !!result, message: output }); }, pushFailure: function( message, source, actual ) { if ( !config.current ) { throw new Error( ""pushFailure() assertion outside test context, was "" + sourceFromStacktrace(2) ); } var output, details = { module: config.current.module, name: config.current.testName, result: false, message: message }; message = escapeText( message ) || ""error""; message = ""<span class='test-message'>"" + message + ""</span>""; output = message; output += ""<table>""; if ( actual ) { output += ""<tr class='test-actual'><th>Result: </th><td><pre>"" + escapeText( actual ) + ""</pre></td></tr>""; } if ( source ) { details.source = source; output += ""<tr class='test-source'><th>Source: </th><td><pre>"" + escapeText( source ) + ""</pre></td></tr>""; } output += ""</table>""; runLoggingCallbacks( ""log"", QUnit, details ); config.current.assertions.push({ result: false, message: output }); }, url: function( params ) { params = extend( extend( {}, QUnit.urlParams ), params ); var key, querystring = ""?""; for ( key in params ) { if ( hasOwn.call( params, key ) ) { querystring += encodeURIComponent( key ) + ""="" + encodeURIComponent( params[ key ] ) + ""&""; } } return window.location.protocol + ""//"" + window.location.host + window.location.pathname + querystring.slice( 0, -1 ); }, extend: extend, id: id, addEvent: addEvent, addClass: addClass, hasClass: hasClass, removeClass: removeClass // load, equiv, jsDump, diff: Attached later }); /** * @deprecated: Created for backwards compatibility with test runner that set the hook function * into QUnit.{hook}, instead of invoking it and passing the hook function. * QUnit.constructor is set to the empty F() above so that we can add to it's prototype here. * Doing this allows us to tell if the following methods have been overwritten on the actual * QUnit object. */ extend( QUnit.constructor.prototype, { // Logging callbacks; all receive a single argument with the listed properties // run test/logs.html for any related changes begin: registerLoggingCallback( ""begin"" ), // done: { failed, passed, total, runtime } done: registerLoggingCallback( ""done"" ), // log: { result, actual, expected, message } log: registerLoggingCallback( ""log"" ), // testStart: { name } testStart: registerLoggingCallback( ""testStart"" ), // testDone: { name, failed, passed, total, runtime } testDone: registerLoggingCallback( ""testDone"" ), // moduleStart: { name } moduleStart: registerLoggingCallback( ""moduleStart"" ), // moduleDone: { name, failed, passed, total } moduleDone: registerLoggingCallback( ""moduleDone"" ) }); if ( !defined.document || document.readyState === ""complete"" ) { config.autorun = true; } QUnit.load = function() { runLoggingCallbacks( ""begin"", QUnit, {} ); // Initialize the config, saving the execution queue var banner, filter, i, j, label, len, main, ol, toolbar, val, selection, urlConfigContainer, moduleFilter, userAgent, numModules = 0, moduleNames = [], moduleFilterHtml = """", urlConfigHtml = """", oldconfig = extend( {}, config ); QUnit.init(); extend(config, oldconfig); config.blocking = false; len = config.urlConfig.length; for ( i = 0; i < len; i++ ) { val = config.urlConfig[i]; if ( typeof val === ""string"" ) { val = { id: val, label: val }; } config[ val.id ] = QUnit.urlParams[ val.id ]; if ( !val.value || typeof val.value === ""string"" ) { urlConfigHtml += ""<input id='qunit-urlconfig-"" + escapeText( val.id ) + ""' name='"" + escapeText( val.id ) + ""' type='checkbox'"" + ( val.value ? "" value='"" + escapeText( val.value ) + ""'"" : """" ) + ( config[ val.id ] ? "" checked='checked'"" : """" ) + "" title='"" + escapeText( val.tooltip ) + ""'><label for='qunit-urlconfig-"" + escapeText( val.id ) + ""' title='"" + escapeText( val.tooltip ) + ""'>"" + val.label + ""</label>""; } else { urlConfigHtml += ""<label for='qunit-urlconfig-"" + escapeText( val.id ) + ""' title='"" + escapeText( val.tooltip ) + ""'>"" + val.label + "": </label><select id='qunit-urlconfig-"" + escapeText( val.id ) + ""' name='"" + escapeText( val.id ) + ""' title='"" + escapeText( val.tooltip ) + ""'><option></option>""; selection = false; if ( QUnit.is( ""array"", val.value ) ) { for ( j = 0; j < val.value.length; j++ ) { urlConfigHtml += ""<option value='"" + escapeText( val.value[j] ) + ""'"" + ( config[ val.id ] === val.value[j] ? (selection = true) && "" selected='selected'"" : """" ) + "">"" + escapeText( val.value[j] ) + ""</option>""; } } else { for ( j in val.value ) { if ( hasOwn.call( val.value, j ) ) { urlConfigHtml += ""<option value='"" + escapeText( j ) + ""'"" + ( config[ val.id ] === j ? (selection = true) && "" selected='selected'"" : """" ) + "">"" + escapeText( val.value[j] ) + ""</option>""; } } } if ( config[ val.id ] && !selection ) { urlConfigHtml += ""<option value='"" + escapeText( config[ val.id ] ) + ""' selected='selected' disabled='disabled'>"" + escapeText( config[ val.id ] ) + ""</option>""; } urlConfigHtml += ""</select>""; } } for ( i in config.modules ) { if ( config.modules.hasOwnProperty( i ) ) { moduleNames.push(i); } } numModules = moduleNames.length; moduleNames.sort( function( a, b ) { return a.localeCompare( b ); }); moduleFilterHtml += ""<label for='qunit-modulefilter'>Module: </label><select id='qunit-modulefilter' name='modulefilter'><option value='' "" + ( config.module === undefined ? ""selected='selected'"" : """" ) + "">< All Modules ></option>""; for ( i = 0; i < numModules; i++) { moduleFilterHtml += ""<option value='"" + escapeText( encodeURIComponent(moduleNames[i]) ) + ""' "" + ( config.module === moduleNames[i] ? ""selected='selected'"" : """" ) + "">"" + escapeText(moduleNames[i]) + ""</option>""; } moduleFilterHtml += ""</select>""; // `userAgent` initialized at top of scope userAgent = id( ""qunit-userAgent"" ); if ( userAgent ) { userAgent.innerHTML = navigator.userAgent; } // `banner` initialized at top of scope banner = id( ""qunit-header"" ); if ( banner ) { banner.innerHTML = ""<a href='"" + QUnit.url({ filter: undefined, module: undefined, testNumber: undefined }) + ""'>"" + banner.innerHTML + ""</a> ""; } // `toolbar` initialized at top of scope toolbar = id( ""qunit-testrunner-toolbar"" ); if ( toolbar ) { // `filter` initialized at top of scope filter = document.createElement( ""input"" ); filter.type = ""checkbox""; filter.id = ""qunit-filter-pass""; addEvent( filter, ""click"", function() { var tmp, ol = id( ""qunit-tests"" ); if ( filter.checked ) { ol.className = ol.className + "" hidepass""; } else { tmp = "" "" + ol.className.replace( /[\n\t\r]/g, "" "" ) + "" ""; ol.className = tmp.replace( / hidepass /, "" "" ); } if ( defined.sessionStorage ) { if (filter.checked) { sessionStorage.setItem( ""qunit-filter-passed-tests"", ""true"" ); } else { sessionStorage.removeItem( ""qunit-filter-passed-tests"" ); } } }); if ( config.hidepassed || defined.sessionStorage && sessionStorage.getItem( ""qunit-filter-passed-tests"" ) ) { filter.checked = true; // `ol` initialized at top of scope ol = id( ""qunit-tests"" ); ol.className = ol.className + "" hidepass""; } toolbar.appendChild( filter ); // `label` initialized at top of scope label = document.createElement( ""label"" ); label.setAttribute( ""for"", ""qunit-filter-pass"" ); label.setAttribute( ""title"", ""Only show tests and assertions that fail. Stored in sessionStorage."" ); label.innerHTML = ""Hide passed tests""; toolbar.appendChild( label ); urlConfigContainer = document.createElement(""span""); urlConfigContainer.innerHTML = urlConfigHtml; // For oldIE support: // * Add handlers to the individual elements instead of the container // * Use ""click"" instead of ""change"" for checkboxes // * Fallback from event.target to event.srcElement addEvents( urlConfigContainer.getElementsByTagName(""input""), ""click"", function( event ) { var params = {}, target = event.target || event.srcElement; params[ target.name ] = target.checked ? target.defaultValue || true : undefined; window.location = QUnit.url( params ); }); addEvents( urlConfigContainer.getElementsByTagName(""select""), ""change"", function( event ) { var params = {}, target = event.target || event.srcElement; params[ target.name ] = target.options[ target.selectedIndex ].value || undefined; window.location = QUnit.url( params ); }); toolbar.appendChild( urlConfigContainer ); if (numModules > 1) { moduleFilter = document.createElement( ""span"" ); moduleFilter.setAttribute( ""id"", ""qunit-modulefilter-container"" ); moduleFilter.innerHTML = moduleFilterHtml; addEvent( moduleFilter.lastChild, ""change"", function() { var selectBox = moduleFilter.getElementsByTagName(""select"")[0], selectedModule = decodeURIComponent(selectBox.options[selectBox.selectedIndex].value); window.location = QUnit.url({ module: ( selectedModule === """" ) ? undefined : selectedModule, // Remove any existing filters filter: undefined, testNumber: undefined }); }); toolbar.appendChild(moduleFilter); } } // `main` initialized at top of scope main = id( ""qunit-fixture"" ); if ( main ) { config.fixture = main.innerHTML; } if ( config.autostart ) { QUnit.start(); } }; if ( defined.document ) { addEvent( window, ""load"", QUnit.load ); } // `onErrorFnPrev` initialized at top of scope // Preserve other handlers onErrorFnPrev = window.onerror; // Cover uncaught exceptions // Returning true will suppress the default browser handler, // returning false will let it run. window.onerror = function ( error, filePath, linerNr ) { var ret = false; if ( onErrorFnPrev ) { ret = onErrorFnPrev( error, filePath, linerNr ); } // Treat return value as window.onerror itself does, // Only do our handling if not suppressed. if ( ret !== true ) { if ( QUnit.config.current ) { if ( QUnit.config.current.ignoreGlobalErrors ) { return true; } QUnit.pushFailure( error, filePath + "":"" + linerNr ); } else { QUnit.test( ""global failure"", extend( function() { QUnit.pushFailure( error, filePath + "":"" + linerNr ); }, { validTest: validTest } ) ); } return false; } return ret; }; function done() { config.autorun = true; // Log the last module results if ( config.previousModule ) { runLoggingCallbacks( ""moduleDone"", QUnit, { name: config.previousModule, failed: config.moduleStats.bad, passed: config.moduleStats.all - config.moduleStats.bad, total: config.moduleStats.all }); } delete config.previousModule; var i, key, banner = id( ""qunit-banner"" ), tests = id( ""qunit-tests"" ), runtime = +new Date() - config.started, passed = config.stats.all - config.stats.bad, html = [ ""Tests completed in "", runtime, "" milliseconds.<br/>"", ""<span class='passed'>"", passed, ""</span> assertions of <span class='total'>"", config.stats.all, ""</span> passed, <span class='failed'>"", config.stats.bad, ""</span> failed."" ].join( """" ); if ( banner ) { banner.className = ( config.stats.bad ? ""qunit-fail"" : ""qunit-pass"" ); } if ( tests ) { id( ""qunit-testresult"" ).innerHTML = html; } if ( config.altertitle && defined.document && document.title ) { // show  for good,  for bad suite result in title // use escape sequences in case file gets loaded with non-utf-8-charset document.title = [ ( config.stats.bad ? ""\u2716"" : ""\u2714"" ), document.title.replace( /^[\u2714\u2716] /i, """" ) ].join( "" "" ); } // clear own sessionStorage items if all tests passed if ( config.reorder && defined.sessionStorage && config.stats.bad === 0 ) { // `key` & `i` initialized at top of scope for ( i = 0; i < sessionStorage.length; i++ ) { key = sessionStorage.key( i++ ); if ( key.indexOf( ""qunit-test-"" ) === 0 ) { sessionStorage.removeItem( key ); } } } // scroll back to top to show results if ( config.scrolltop && window.scrollTo ) { window.scrollTo(0, 0); } runLoggingCallbacks( ""done"", QUnit, { failed: config.stats.bad, passed: passed, total: config.stats.all, runtime: runtime }); } /** @return Boolean: true if this test should be ran */ function validTest( test ) { var include, filter = config.filter && config.filter.toLowerCase(), module = config.module && config.module.toLowerCase(), fullName = ( test.module + "": "" + test.testName ).toLowerCase(); // Internally-generated tests are always valid if ( test.callback && test.callback.validTest === validTest ) { delete test.callback.validTest; return true; } if ( config.testNumber.length > 0 ) { if ( inArray( test.testNumber, config.testNumber ) < 0 ) { } if ( module && ( !test.module || test.module.toLowerCase() !== module ) ) { return false; } if ( !filter ) { return true; } include = filter.charAt( 0 ) !== ""!""; if ( !include ) { filter = filter.slice( 1 ); } // If the filter matches, we need to honour include if ( fullName.indexOf( filter ) !== -1 ) { return include; } // Otherwise, do the opposite return !include; } // so far supports only Firefox, Chrome and Opera (buggy), Safari (for real exceptions) // Later Safari and IE10 are supposed to support error.stack as well // See also https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Error/Stack function extractStacktrace( e, offset ) { offset = offset === undefined ? 3 : offset; var stack, include, i; if ( e.stacktrace ) { // Opera return e.stacktrace.split( ""\n"" )[ offset + 3 ]; } else if ( e.stack ) { // Firefox, Chrome stack = e.stack.split( ""\n"" ); if (/^error$/i.test( stack[0] ) ) { stack.shift(); } if ( fileName ) { include = []; for ( i = offset; i < stack.length; i++ ) { if ( stack[ i ].indexOf( fileName ) !== -1 ) { break; } include.push( stack[ i ] ); } if ( include.length ) { return include.join( ""\n"" ); } } return stack[ offset ]; } else if ( e.sourceURL ) { // Safari, PhantomJS // hopefully one day Safari provides actual stacktraces // exclude useless self-reference for generated Error objects if ( /qunit.js$/.test( e.sourceURL ) ) { return; } // for actual exceptions, this is useful return e.sourceURL + "":"" + e.line; } } function sourceFromStacktrace( offset ) { try { throw new Error(); } catch ( e ) { return extractStacktrace( e, offset ); } } /** * Escape text for attribute or text content. */ function escapeText( s ) { if ( !s ) { return """"; } s = s + """"; // Both single quotes and double quotes (for attributes) return s.replace( /['""<>&]/g, function( s ) { switch( s ) { case ""'"": return ""&#039;""; case ""\"""": return ""&quot;""; case ""<"": return ""&lt;""; case "">"": return ""&gt;""; case ""&"": return ""&amp;""; } }); } function synchronize( callback, last ) { config.queue.push( callback ); if ( config.autorun && !config.blocking ) { process( last ); } } function process( last ) { function next() { process( last ); } var start = new Date().getTime(); config.depth = config.depth ? config.depth + 1 : 1; while ( config.queue.length && !config.blocking ) { if ( !defined.setTimeout || config.updateRate <= 0 || ( ( new Date().getTime() - start ) < config.updateRate ) ) { config.queue.shift()(); } else { setTimeout( next, 13 ); break; } } config.depth--; if ( last && !config.blocking && !config.queue.length && config.depth === 0 ) { done(); } } function saveGlobal() { config.pollution = []; if ( config.noglobals ) { for ( var key in window ) { if ( hasOwn.call( window, key ) ) { // in Opera sometimes DOM element ids show up here, ignore them if ( /^qunit-test-output/.test( key ) ) { continue; } config.pollution.push( key ); } } } } function checkPollution() { var newGlobals, deletedGlobals, old = config.pollution; saveGlobal(); newGlobals = diff( config.pollution, old ); if ( newGlobals.length > 0 ) { QUnit.pushFailure( ""Introduced global variable(s): "" + newGlobals.join("", "") ); } deletedGlobals = diff( old, config.pollution ); if ( deletedGlobals.length > 0 ) { QUnit.pushFailure( ""Deleted global variable(s): "" + deletedGlobals.join("", "") ); } } // returns a new Array with the elements that are in a but not in b function diff( a, b ) { var i, j, result = a.slice(); for ( i = 0; i < result.length; i++ ) { for ( j = 0; j < b.length; j++ ) { if ( result[i] === b[j] ) { result.splice( i, 1 ); i--; break; } } } return result; } function extend( a, b ) { for ( var prop in b ) { if ( hasOwn.call( b, prop ) ) { // Avoid ""Member not found"" error in IE8 caused by messing with window.constructor if ( !( prop === ""constructor"" && a === window ) ) { if ( b[ prop ] === undefined ) { delete a[ prop ]; } else { a[ prop ] = b[ prop ]; } } } } return a; } /** * @param {HTMLElement} elem * @param {string} type * @param {Function} fn */ function addEvent( elem, type, fn ) { if ( elem.addEventListener ) { // Standards-based browsers elem.addEventListener( type, fn, false ); } else if ( elem.attachEvent ) { // support: IE <9 elem.attachEvent( ""on"" + type, fn ); } else { // Caller must ensure support for event listeners is present throw new Error( ""addEvent() was called in a context without event listener support"" ); } } /** * @param {Array|NodeList} elems * @param {string} type * @param {Function} fn */ function addEvents( elems, type, fn ) { var i = elems.length; while ( i-- ) { addEvent( elems[i], type, fn ); } } function hasClass( elem, name ) { return ("" "" + elem.className + "" "").indexOf("" "" + name + "" "") > -1; } function addClass( elem, name ) { if ( !hasClass( elem, name ) ) { elem.className += (elem.className ? "" "" : """") + name; } } function removeClass( elem, name ) { var set = "" "" + elem.className + "" ""; // Class name may appear multiple times while ( set.indexOf("" "" + name + "" "") > -1 ) { set = set.replace("" "" + name + "" "" , "" ""); } // If possible, trim it for prettiness, but not necessarily elem.className = typeof set.trim === ""function"" ? set.trim() : set.replace(/^\s+|\s+$/g, """"); } function id( name ) { return defined.document && document.getElementById && document.getElementById( name ); } function registerLoggingCallback( key ) { return function( callback ) { config[key].push( callback ); }; } // Supports deprecated method of completely overwriting logging callbacks function runLoggingCallbacks( key, scope, args ) { var i, callbacks; if ( QUnit.hasOwnProperty( key ) ) { QUnit[ key ].call(scope, args ); } else { callbacks = config[ key ]; for ( i = 0; i < callbacks.length; i++ ) { callbacks[ i ].call( scope, args ); } } } // from jquery.js function inArray( elem, array ) { if ( array.indexOf ) { return array.indexOf( elem ); } for ( var i = 0, length = array.length; i < length; i++ ) { if ( array[ i ] === elem ) { return i; } } return -1; } tests = id( ""qunit-tests"" ); b.innerHTML = this.nameHtml; if ( // Emit moduleStart when we're switching from one module to another this.module !== config.previousModule || // They could be equal (both undefined) but if the previousModule property doesn't // yet exist it means this is the first test in a suite that isn't wrapped in a // module, in which case we'll just emit a moduleStart event for 'undefined'. // Without this, reporters can get testStart before moduleStart which is a problem. !hasOwn.call( config, ""previousModule"" ) ) { if ( hasOwn.call( config, ""previousModule"" ) ) { this.started = +new Date(); /*jshint camelcase:false */ /** * Expose the current test environment. * * @deprecated since 1.12.0: Use QUnit.config.current.testEnvironment instead. */ /*jshint camelcase:true */ this.testEnvironment.setup.call( this.testEnvironment, QUnit.assert ); this.testEnvironment.setup.call( this.testEnvironment, QUnit.assert ); } catch( e ) { QUnit.pushFailure( ""Setup failed on "" + this.testName + "": "" + ( e.message || e ), extractStacktrace( e, 1 ) ); running.innerHTML = ""Running: <br/>"" + this.nameHtml; this.callbackStarted = +new Date(); this.callbackRuntime = +new Date() - this.callbackStarted; this.callbackRuntime = +new Date() - this.callbackStarted; } catch( e ) { this.callbackRuntime = +new Date() - this.callbackStarted; QUnit.pushFailure( ""Died on test #"" + (this.assertions.length + 1) + "" "" + this.stack + "": "" + ( e.message || e ), extractStacktrace( e, 0 ) ); if ( typeof this.callbackRuntime === ""undefined"" ) { this.callbackRuntime = +new Date() - this.callbackStarted; } this.testEnvironment.teardown.call( this.testEnvironment, QUnit.assert ); this.testEnvironment.teardown.call( this.testEnvironment, QUnit.assert ); } catch( e ) { QUnit.pushFailure( ""Teardown failed on "" + this.testName + "": "" + ( e.message || e ), extractStacktrace( e, 1 ) ); if ( config.requireExpects && this.expected === null ) { } else if ( this.expected !== null && this.expected !== this.assertions.length ) { } else if ( this.expected === null && !this.assertions.length ) { var i, assertion, a, b, time, li, ol, this.runtime = +new Date() - this.started; ol.className = ""qunit-assert-list""; addClass( ol, ""qunit-collapsed"" ); b.innerHTML = this.nameHtml + "" <b class='counts'>(<b class='failed'>"" + bad + ""</b>, <b class='passed'>"" + good + ""</b>, "" + this.assertions.length + "")</b>""; var next = b.parentNode.lastChild, collapsed = hasClass( next, ""qunit-collapsed"" ); ( collapsed ? removeClass : addClass )( next, ""qunit-collapsed"" ); if ( target.nodeName.toLowerCase() === ""span"" || target.nodeName.toLowerCase() === ""b"" ) { // `time` initialized at top of scope time = document.createElement( ""span"" ); time.className = ""runtime""; time.innerHTML = this.runtime + "" ms""; li.appendChild( a ); li.appendChild( time ); total: this.assertions.length, runtime: this.runtime, // DEPRECATED: this property will be removed in 2.0.0, use runtime instead duration: this.runtime// `assert` initialized at top of scope // Assert helpers // All of these must either call QUnit.push() or manually do:assert = QUnit.assert = { * @name ok * @function msg = msg || ( result ? ""okay"" : ""failed"" ); module: config.current.module, name: config.current.testName, msg = ""<span class='test-message'>"" + escapeText( msg ) + ""</span>""; msg += ""<table><tr class='test-source'><th>Source: </th><td><pre>"" + escapeText( source ) + ""</pre></td></tr></table>""; * @name equal * @function /*jshint eqeqeq:false */ /** * @name notEqual * @function */ notEqual: function( actual, expected, message ) { /*jshint eqeqeq:false */ /** * @name propEqual * @function */ propEqual: function( actual, expected, message ) { actual = objectValues(actual); expected = objectValues(expected); QUnit.push( QUnit.equiv(actual, expected), actual, expected, message ); }, /** * @name notPropEqual * @function */ notPropEqual: function( actual, expected, message ) { actual = objectValues(actual); expected = objectValues(expected); QUnit.push( !QUnit.equiv(actual, expected), actual, expected, message ); }, /** * @name deepEqual * @function */ /** * @name notDeepEqual * @function */ /** * @name strictEqual * @function */ /** * @name notStrictEqual * @function */ ""throws"": function( block, expected, message ) { expectedOutput = expected, // 'expected' is optional if ( !message && typeof expected === ""string"" ) { expectedOutput = null; // expected is an Error object } else if ( expected instanceof Error ) { ok = actual instanceof Error && actual.name === expected.name && actual.message === expected.message; ok = expected.test( errorString( actual ) ); // expected is a string } else if ( QUnit.objectType( expected ) === ""string"" ) { ok = expected === errorString( actual ); expectedOutput = null; QUnit.push( ok, actual, expectedOutput, message ); } else { QUnit.pushFailure( message, null, ""No exception was thrown."" ); }/** * @deprecated since 1.8.0 * Kept assertion helpers in root for backwards compatibility. */ extend( QUnit.constructor.prototype, assert ); /** * @deprecated since 1.9.0 * Kept to avoid TypeErrors for undefined methods.QUnit.constructor.prototype.raises = function() { QUnit.push( false, false, false, ""QUnit.raises has been deprecated since 2012 (fad3c1ea), use QUnit.throws instead"" ); }; /** * @deprecated since 1.0.0, replaced with error pushes since 1.3.0 * Kept to avoid TypeErrors for undefined methods. */ QUnit.constructor.prototype.equals = function() {QUnit.constructor.prototype.same = function() { parentsB = [], /*jshint camelcase:false */ /*jshint eqeqeq:false */ if ( b instanceof a.constructor || a instanceof b.constructor ) { // to catch short annotation VS 'new' annotation of a // and its modifiers a.multiline === b.multiline && a.sticky === b.sticky; var i, j, len, loop, aCircular, bCircular; parentsB.push( b ); aCircular = parents[j] === a[i]; bCircular = parentsB[j] === b[i]; if ( aCircular || bCircular ) { if ( a[i] === b[i] || aCircular && bCircular ) { loop = true; } else { parents.pop(); parentsB.pop(); return false; } parentsB.pop(); parentsB.pop(); /*jshint forin:false */ var i, j, loop, aCircular, bCircular, parentsB.push( b ); // be strict: don't ensure hasOwnProperty and go deep for ( i in a ) { aCircular = parents[j] === a[i]; bCircular = parentsB[j] === b[i]; if ( aCircular || bCircular ) { if ( a[i] === b[i] || aCircular && bCircular ) { loop = true; } else { eq = false; break; } } } aProperties.push(i); if ( !loop && !innerEquiv(a[i], b[i]) ) { parentsB.pop(); callers.pop(); // unstack, we are done }( args[0], args[1] ) && innerEquiv.apply( this, args.splice(1, args.length - 1 )) ); return ""\"""" + str.toString().replace( /""/g, ""\\\"""" ) + ""\""""; // type is used mostly internally, you can fix a (custom)type in advance parse: function( obj, type, stack ) { if ( inStack !== -1 ) { if ( type === ""function"" ) { return ( type === ""string"" ) ? parser : this.parsers.error; } else if ( obj.constructor === Error.prototype.constructor ) { type = ""error""; // extra can be a number, shortcut for increasing-calling-decreasing indent: function( extra ) { return new Array( this.depth + ( extra || 0 ) ).join(chr); this.depth += a || 1; this.depth -= a || 1; depth: 1, error: function(error) { return ""Error(\"""" + error.message + ""\"")""; }, // functions never have name in IE name = ""name"" in fn ? fn.name : (reName.exec(fn) || [])[1]; /*jshint forin:false */ keys = []; for ( key in map ) { keys.push( key ); var len, i, val, ret = open + tag, attrs = node.attributes; if ( attrs ) { for ( i = 0, len = attrs.length; i < len; i++ ) { val = attrs[i].nodeValue; // IE6 includes all attributes in .attributes, even ones not explicitly set. // Those have values like undefined, null, 0, false, """" or ""inherit"". if ( val && val !== ""inherit"" ) { ret += "" "" + attrs[i].nodeName + ""="" + QUnit.jsDump.parse( val, ""attribute"" ); } } } ret += close; // Show content of TextNode or CDATASection if ( node.nodeType === 3 || node.nodeType === 4 ) { ret += node.nodeValue; } return ret + open + ""/"" + tag + close; // function calls it internally, it's the arguments part of the function functionArgs: function( fn ) { // 97 is 'a' args[l] = String.fromCharCode(97+l); // object calls it internally, the key part of an item in a map key: quote, // function calls it internally, it's the content of the function functionCode: ""[code]"", // node calls it internally, it's an html attribute value attribute: quote, regexp: literal, // if true, entities are escaped ( <, >, \t, space and \n ) HTML: false, // indentation unit indentChar: "" "", // if true, items in a collection, are separated by a \n, else just a space. multiline: true /*jshint eqeqeq:false, eqnull:true */ if ( !hasOwn.call( ns, n[i] ) ) { if ( !hasOwn.call( os, o[i] ) ) { if ( hasOwn.call( ns, i ) ) { if ( ns[i].rows.length === 1 && hasOwn.call( os, i ) && os[i].rows.length === 1 ) { n[ ns[i].rows[0] ] = { text: n[ ns[i].rows[0] ], row: os[i].rows[0] }; o[ os[i].rows[0] ] = { text: o[ os[i].rows[0] ], row: ns[i].rows[0] }; }// For browser, export only select globals if ( typeof window !== ""undefined"" ) { extend( window, QUnit.constructor.prototype ); window.QUnit = QUnit; } // For CommonJS environments, export everything if ( typeof module !== ""undefined"" && module.exports ) { module.exports = QUnit; } // Get a reference to the global object, like window in browsers }( (function() { return this; })() ));","/** * QUnit v1.9.0pre - A JavaScript Unit Testing Framework * * http://docs.jquery.com/QUnit * * Copyright (c) 2012 John Resig, Jrn Zaefferer * Dual licensed under the MIT (MIT-LICENSE.txt) * or GPL (GPL-LICENSE.txt) licenses. * Pulled Live from Git Sat Jun 23 20:50:01 UTC 2012 * Last Commit: 1c0af4e943400de73bc36310d3db42a5217da215 defined = { setTimeout: typeof window.setTimeout !== ""undefined"", sessionStorage: (function() { var x = ""qunit-test-string""; try { sessionStorage.setItem( x, x ); sessionStorage.removeItem( x ); return true; } catch( e ) { }()) }; tests = id( ""qunit-tests"" ); b.innerHTML = this.name; if ( this.module !== config.previousModule ) { if ( config.previousModule ) { } else if ( config.autorun ) { runLoggingCallbacks( ""moduleStart"", QUnit, { name: this.module }); // allow utility functions to access the current test environment // TODO why?? this.testEnvironment.setup.call( this.testEnvironment ); this.testEnvironment.setup.call( this.testEnvironment ); } catch( e ) { QUnit.pushFailure( ""Setup failed on "" + this.testName + "": "" + e.message, extractStacktrace( e, 1 ) ); running.innerHTML = ""Running: <br/>"" + this.name; } catch( e ) { QUnit.pushFailure( ""Died on test #"" + (this.assertions.length + 1) + "" "" + this.stack + "": "" + e.message, extractStacktrace( e, 0 ) ); this.testEnvironment.teardown.call( this.testEnvironment ); this.testEnvironment.teardown.call( this.testEnvironment ); } catch( e ) { QUnit.pushFailure( ""Teardown failed on "" + this.testName + "": "" + e.message, extractStacktrace( e, 1 ) ); if ( config.requireExpects && this.expected == null ) { } else if ( this.expected != null && this.expected != this.assertions.length ) { } else if ( this.expected == null && !this.assertions.length ) { var assertion, a, b, i, li, ol, ol.style.display = ""none""; b.innerHTML = this.name + "" <b class='counts'>(<b class='failed'>"" + bad + ""</b>, <b class='passed'>"" + good + ""</b>, "" + this.assertions.length + "")</b>""; var next = b.nextSibling.nextSibling, display = next.style.display; next.style.display = display === ""none"" ? ""block"" : ""none""; if ( target.nodeName.toLowerCase() == ""span"" || target.nodeName.toLowerCase() == ""b"" ) { li.appendChild ( a ); total: this.assertions.length// Root QUnit object. // `QUnit` initialized at top of scope QUnit = { // call on start of module test to prepend name to all tests module: function( name, testEnvironment ) { config.currentModule = name; config.currentModuleTestEnvironment = testEnvironment; }, asyncTest: function( testName, expected, callback ) { if ( arguments.length === 2 ) { callback = expected; expected = null; } QUnit.test( testName, expected, callback, true ); }, test: function( testName, expected, callback, async ) { var test, name = ""<span class='test-name'>"" + escapeInnerText( testName ) + ""</span>""; if ( arguments.length === 2 ) { callback = expected; expected = null; } if ( config.currentModule ) { name = ""<span class='module-name'>"" + config.currentModule + ""</span>: "" + name; } test = new Test({ name: name, testName: testName, expected: expected, async: async, callback: callback, module: config.currentModule, moduleTestEnvironment: config.currentModuleTestEnvironment, stack: sourceFromStacktrace( 2 ) }); if ( !validTest( test ) ) { return; } test.queue(); }, // Specify the number of expected assertions to guarantee that failed test (no assertions are run at all) don't slip through. expect: function( asserts ) { config.current.expected = asserts; }, start: function( count ) { config.semaphore -= count || 1; // don't start until equal number of stop-calls if ( config.semaphore > 0 ) { return; } // ignore if start is called more often then stop if ( config.semaphore < 0 ) { config.semaphore = 0; } // A slight delay, to avoid any current callbacks if ( defined.setTimeout ) { window.setTimeout(function() { if ( config.semaphore > 0 ) { return; } if ( config.timeout ) { clearTimeout( config.timeout ); } config.blocking = false; process( true ); }, 13); } else { config.blocking = false; process( true ); } }, stop: function( count ) { config.semaphore += count || 1; config.blocking = true; if ( config.testTimeout && defined.setTimeout ) { clearTimeout( config.timeout ); config.timeout = window.setTimeout(function() { QUnit.ok( false, ""Test timed out"" ); config.semaphore = 1; QUnit.start(); }, config.testTimeout ); } } }; // Asssert helpers // All of these must call either QUnit.push() or manually do:QUnit.assert = { msg = escapeInnerText( msg || (result ? ""okay"" : ""failed"" ) ); msg = ""<span class='test-message'>"" + msg + ""</span>""; msg += ""<table><tr class='test-source'><th>Source: </th><td><pre>"" + escapeInnerText( source ) + ""</pre></td></tr></table>""; notEqual: function( actual, expected, message ) { raises: function( block, expected, message ) { if ( typeof expected === ""string"" ) { ok = expected.test( actual ); } QUnit.push( ok, actual, null, message );// @deprecated: Kept assertion helpers in root for backwards compatibility extend( QUnit, QUnit.assert ); /** * @deprecated: Kept for backwards compatibility * next step: remove entirelyQUnit.equals = function() {QUnit.same = function() {// We want access to the constructor's prototype (function() { function F() {} F.prototype = QUnit; QUnit = new F(); // Make F QUnit's constructor so that we can add to the prototype later QUnit.constructor = F; }()); /** * Config object: Maintain internal state * Later exposed as QUnit.config * `config` initialized at top of scope */ config = { // The queue of tests to run queue: [], // block until document ready blocking: true, // when enabled, show only failing tests // gets persisted through sessionStorage and can be changed in UI via checkbox hidepassed: false, // by default, run previously failed tests first // very useful in combination with ""Hide passed tests"" checked reorder: true, // by default, modify document.title when suite is done altertitle: true, // when enabled, all tests must call expect() requireExpects: false, urlConfig: [ ""noglobals"", ""notrycatch"" ], // logging callback queues begin: [], done: [], log: [], testStart: [], testDone: [], moduleStart: [], moduleDone: [] }; // Initialize more QUnit.config and QUnit.urlParams (function() { var i, location = window.location || { search: """", protocol: ""file:"" }, params = location.search.slice( 1 ).split( ""&"" ), length = params.length, urlParams = {}, current; if ( params[ 0 ] ) { for ( i = 0; i < length; i++ ) { current = params[ i ].split( ""="" ); current[ 0 ] = decodeURIComponent( current[ 0 ] ); // allow just a key to turn on a flag, e.g., test.html?noglobals current[ 1 ] = current[ 1 ] ? decodeURIComponent( current[ 1 ] ) : true; urlParams[ current[ 0 ] ] = current[ 1 ]; } } QUnit.urlParams = urlParams; // String search anywhere in moduleName+testName config.filter = urlParams.filter; // Exact match of the module name config.module = urlParams.module; config.testNumber = parseInt( urlParams.testNumber, 10 ) || null; // Figure out if we're running the tests from a server or not QUnit.isLocal = location.protocol === ""file:""; }()); // Export global variables, unless an 'exports' object exists, // in that case we assume we're in CommonJS (dealt with on the bottom of the script) if ( typeof exports === ""undefined"" ) { extend( window, QUnit ); // Expose QUnit object window.QUnit = QUnit; } // Extend QUnit object, // these after set here because they should not be exposed as global functions extend( QUnit, { config: config, // Initialize the configuration options init: function() { extend( config, { stats: { all: 0, bad: 0 }, moduleStats: { all: 0, bad: 0 }, started: +new Date(), updateRate: 1000, blocking: false, autostart: true, autorun: false, filter: """", queue: [], semaphore: 0 }); var tests, banner, result, qunit = id( ""qunit"" ); if ( qunit ) { qunit.innerHTML = ""<h1 id='qunit-header'>"" + escapeInnerText( document.title ) + ""</h1>"" + ""<h2 id='qunit-banner'></h2>"" + ""<div id='qunit-testrunner-toolbar'></div>"" + ""<h2 id='qunit-userAgent'></h2>"" + ""<ol id='qunit-tests'></ol>""; } tests = id( ""qunit-tests"" ); banner = id( ""qunit-banner"" ); result = id( ""qunit-testresult"" ); if ( tests ) { tests.innerHTML = """"; } if ( banner ) { banner.className = """"; } if ( result ) { result.parentNode.removeChild( result ); } if ( tests ) { result = document.createElement( ""p"" ); result.id = ""qunit-testresult""; result.className = ""result""; tests.parentNode.insertBefore( result, tests ); result.innerHTML = ""Running...<br/>&nbsp;""; } }, // Resets the test setup. Useful for tests that modify the DOM. // If jQuery is available, uses jQuery's html(), otherwise just innerHTML. reset: function() { var fixture; if ( window.jQuery ) { jQuery( ""#qunit-fixture"" ).html( config.fixture ); } else { fixture = id( ""qunit-fixture"" ); if ( fixture ) { fixture.innerHTML = config.fixture; } } }, // Trigger an event on an element. // @example triggerEvent( document.body, ""click"" ); triggerEvent: function( elem, type, event ) { if ( document.createEvent ) { event = document.createEvent( ""MouseEvents"" ); event.initMouseEvent(type, true, true, elem.ownerDocument.defaultView, 0, 0, 0, 0, 0, false, false, false, false, 0, null); elem.dispatchEvent( event ); } else if ( elem.fireEvent ) { elem.fireEvent( ""on"" + type ); } }, // Safe object type checking is: function( type, obj ) { return QUnit.objectType( obj ) == type; }, objectType: function( obj ) { if ( typeof obj === ""undefined"" ) { return ""undefined""; // consider: typeof null === object } if ( obj === null ) { return ""null""; } var type = toString.call( obj ).match(/^\[object\s(.*)\]$/)[1] || """"; switch ( type ) { case ""Number"": if ( isNaN(obj) ) { return ""nan""; } return ""number""; case ""String"": case ""Boolean"": case ""Array"": case ""Date"": case ""RegExp"": case ""Function"": return type.toLowerCase(); } if ( typeof obj === ""object"" ) { return ""object""; } return undefined; }, push: function( result, actual, expected, message ) { if ( !config.current ) { throw new Error( ""assertion outside test context, was "" + sourceFromStacktrace() ); } var output, source, details = { result: result, message: message, actual: actual, expected: expected }; message = escapeInnerText( message ) || ( result ? ""okay"" : ""failed"" ); message = ""<span class='test-message'>"" + message + ""</span>""; output = message; if ( !result ) { expected = escapeInnerText( QUnit.jsDump.parse(expected) ); actual = escapeInnerText( QUnit.jsDump.parse(actual) ); output += ""<table><tr class='test-expected'><th>Expected: </th><td><pre>"" + expected + ""</pre></td></tr>""; if ( actual != expected ) { output += ""<tr class='test-actual'><th>Result: </th><td><pre>"" + actual + ""</pre></td></tr>""; output += ""<tr class='test-diff'><th>Diff: </th><td><pre>"" + QUnit.diff( expected, actual ) + ""</pre></td></tr>""; } source = sourceFromStacktrace(); if ( source ) { details.source = source; output += ""<tr class='test-source'><th>Source: </th><td><pre>"" + escapeInnerText( source ) + ""</pre></td></tr>""; } output += ""</table>""; } runLoggingCallbacks( ""log"", QUnit, details ); config.current.assertions.push({ result: !!result, message: output }); }, pushFailure: function( message, source ) { if ( !config.current ) { throw new Error( ""pushFailure() assertion outside test context, was "" + sourceFromStacktrace(2) ); } var output, details = { result: false, message: message }; message = escapeInnerText(message ) || ""error""; message = ""<span class='test-message'>"" + message + ""</span>""; output = message; if ( source ) { details.source = source; output += ""<table><tr class='test-source'><th>Source: </th><td><pre>"" + escapeInnerText( source ) + ""</pre></td></tr></table>""; } runLoggingCallbacks( ""log"", QUnit, details ); config.current.assertions.push({ result: false, message: output }); }, url: function( params ) { params = extend( extend( {}, QUnit.urlParams ), params ); var key, querystring = ""?""; for ( key in params ) { if ( !hasOwn.call( params, key ) ) { continue; } querystring += encodeURIComponent( key ) + ""="" + encodeURIComponent( params[ key ] ) + ""&""; } return window.location.pathname + querystring.slice( 0, -1 ); }, extend: extend, id: id, addEvent: addEvent // load, equiv, jsDump, diff: Attached later }); /** * @deprecated: Created for backwards compatibility with test runner that set the hook function * into QUnit.{hook}, instead of invoking it and passing the hook function. * QUnit.constructor is set to the empty F() above so that we can add to it's prototype here. * Doing this allows us to tell if the following methods have been overwritten on the actual * QUnit object. */ extend( QUnit.constructor.prototype, { // Logging callbacks; all receive a single argument with the listed properties // run test/logs.html for any related changes begin: registerLoggingCallback( ""begin"" ), // done: { failed, passed, total, runtime } done: registerLoggingCallback( ""done"" ), // log: { result, actual, expected, message } log: registerLoggingCallback( ""log"" ), // testStart: { name } testStart: registerLoggingCallback( ""testStart"" ), // testDone: { name, failed, passed, total } testDone: registerLoggingCallback( ""testDone"" ), // moduleStart: { name } moduleStart: registerLoggingCallback( ""moduleStart"" ), // moduleDone: { name, failed, passed, total } moduleDone: registerLoggingCallback( ""moduleDone"" ) }); if ( typeof document === ""undefined"" || document.readyState === ""complete"" ) { config.autorun = true; } QUnit.load = function() { runLoggingCallbacks( ""begin"", QUnit, {} ); // Initialize the config, saving the execution queue var banner, filter, i, label, len, main, ol, toolbar, userAgent, val, urlConfigHtml = """", oldconfig = extend( {}, config ); QUnit.init(); extend(config, oldconfig); config.blocking = false; len = config.urlConfig.length; for ( i = 0; i < len; i++ ) { val = config.urlConfig[i]; config[val] = QUnit.urlParams[val]; urlConfigHtml += ""<label><input name='"" + val + ""' type='checkbox'"" + ( config[val] ? "" checked='checked'"" : """" ) + "">"" + val + ""</label>""; } // `userAgent` initialized at top of scope userAgent = id( ""qunit-userAgent"" ); if ( userAgent ) { userAgent.innerHTML = navigator.userAgent; } // `banner` initialized at top of scope banner = id( ""qunit-header"" ); if ( banner ) { banner.innerHTML = ""<a href='"" + QUnit.url({ filter: undefined }) + ""'>"" + banner.innerHTML + ""</a> "" + urlConfigHtml; addEvent( banner, ""change"", function( event ) { var params = {}; params[ event.target.name ] = event.target.checked ? true : undefined; window.location = QUnit.url( params ); }); } // `toolbar` initialized at top of scope toolbar = id( ""qunit-testrunner-toolbar"" ); if ( toolbar ) { // `filter` initialized at top of scope filter = document.createElement( ""input"" ); filter.type = ""checkbox""; filter.id = ""qunit-filter-pass""; addEvent( filter, ""click"", function() { var tmp, ol = document.getElementById( ""qunit-tests"" ); if ( filter.checked ) { ol.className = ol.className + "" hidepass""; } else { tmp = "" "" + ol.className.replace( /[\n\t\r]/g, "" "" ) + "" ""; ol.className = tmp.replace( / hidepass /, "" "" ); } if ( defined.sessionStorage ) { if (filter.checked) { sessionStorage.setItem( ""qunit-filter-passed-tests"", ""true"" ); } else { sessionStorage.removeItem( ""qunit-filter-passed-tests"" ); } } }); if ( config.hidepassed || defined.sessionStorage && sessionStorage.getItem( ""qunit-filter-passed-tests"" ) ) { filter.checked = true; // `ol` initialized at top of scope ol = document.getElementById( ""qunit-tests"" ); ol.className = ol.className + "" hidepass""; } toolbar.appendChild( filter ); // `label` initialized at top of scope label = document.createElement( ""label"" ); label.setAttribute( ""for"", ""qunit-filter-pass"" ); label.innerHTML = ""Hide passed tests""; toolbar.appendChild( label ); } // `main` initialized at top of scope main = id( ""qunit-fixture"" ); if ( main ) { config.fixture = main.innerHTML; } if ( config.autostart ) { QUnit.start(); } }; addEvent( window, ""load"", QUnit.load ); // `onErrorFnPrev` initialized at top of scope // Preserve other handlers onErrorFnPrev = window.onerror; // Cover uncaught exceptions // Returning true will suppress the default browser handler, // returning false will let it run. window.onerror = function ( error, filePath, linerNr ) { var ret = false; if ( onErrorFnPrev ) { ret = onErrorFnPrev( error, filePath, linerNr ); } // Treat return value as window.onerror itself does, // Only do our handling if not suppressed. if ( ret !== true ) { if ( QUnit.config.current ) { if ( QUnit.config.current.ignoreGlobalErrors ) { return true; } QUnit.pushFailure( error, filePath + "":"" + linerNr ); } else { QUnit.test( ""global failure"", function() { QUnit.pushFailure( error, filePath + "":"" + linerNr ); }); } return false; } return ret; }; function done() { config.autorun = true; // Log the last module results if ( config.currentModule ) { runLoggingCallbacks( ""moduleDone"", QUnit, { name: config.currentModule, failed: config.moduleStats.bad, passed: config.moduleStats.all - config.moduleStats.bad, total: config.moduleStats.all }); } var i, key, banner = id( ""qunit-banner"" ), tests = id( ""qunit-tests"" ), runtime = +new Date() - config.started, passed = config.stats.all - config.stats.bad, html = [ ""Tests completed in "", runtime, "" milliseconds.<br/>"", ""<span class='passed'>"", passed, ""</span> tests of <span class='total'>"", config.stats.all, ""</span> passed, <span class='failed'>"", config.stats.bad, ""</span> failed."" ].join( """" ); if ( banner ) { banner.className = ( config.stats.bad ? ""qunit-fail"" : ""qunit-pass"" ); } if ( tests ) { id( ""qunit-testresult"" ).innerHTML = html; } if ( config.altertitle && typeof document !== ""undefined"" && document.title ) { // show  for good,  for bad suite result in title // use escape sequences in case file gets loaded with non-utf-8-charset document.title = [ ( config.stats.bad ? ""\u2716"" : ""\u2714"" ), document.title.replace( /^[\u2714\u2716] /i, """" ) ].join( "" "" ); } // clear own sessionStorage items if all tests passed if ( config.reorder && defined.sessionStorage && config.stats.bad === 0 ) { // `key` & `i` initialized at top of scope for ( i = 0; i < sessionStorage.length; i++ ) { key = sessionStorage.key( i++ ); if ( key.indexOf( ""qunit-test-"" ) === 0 ) { sessionStorage.removeItem( key ); } } } runLoggingCallbacks( ""done"", QUnit, { failed: config.stats.bad, passed: passed, total: config.stats.all, runtime: runtime }); } /** @return Boolean: true if this test should be ran */ function validTest( test ) { var include, filter = config.filter && config.filter.toLowerCase(), module = config.module, fullName = (test.module + "": "" + test.testName).toLowerCase(); if ( config.testNumber ) { return test.testNumber === config.testNumber; } if ( module && test.module !== module ) { return false; } if ( !filter ) { return true; } include = filter.charAt( 0 ) !== ""!""; if ( !include ) { filter = filter.slice( 1 ); } // If the filter matches, we need to honour include if ( fullName.indexOf( filter ) !== -1 ) { return include; } // Otherwise, do the opposite return !include; } // so far supports only Firefox, Chrome and Opera (buggy), Safari (for real exceptions) // Later Safari and IE10 are supposed to support error.stack as well // See also https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Error/Stack function extractStacktrace( e, offset ) { offset = offset === undefined ? 3 : offset; var stack, include, i, regex; if ( e.stacktrace ) { // Opera return e.stacktrace.split( ""\n"" )[ offset + 3 ]; } else if ( e.stack ) { // Firefox, Chrome stack = e.stack.split( ""\n"" ); if (/^error$/i.test( stack[0] ) ) { stack.shift(); } if ( fileName ) { include = []; for ( i = offset; i < stack.length; i++ ) { if ( stack[ i ].indexOf( fileName ) != -1 ) { break; } include.push( stack[ i ] ); } if ( include.length ) { return include.join( ""\n"" ); } } return stack[ offset ]; } else if ( e.sourceURL ) { // Safari, PhantomJS // hopefully one day Safari provides actual stacktraces // exclude useless self-reference for generated Error objects if ( /qunit.js$/.test( e.sourceURL ) ) { return; } // for actual exceptions, this is useful return e.sourceURL + "":"" + e.line; } } function sourceFromStacktrace( offset ) { try { throw new Error(); } catch ( e ) { return extractStacktrace( e, offset ); } } function escapeInnerText( s ) { if ( !s ) { return """"; } s = s + """"; return s.replace( /[\&<>]/g, function( s ) { switch( s ) { case ""&"": return ""&amp;""; case ""<"": return ""&lt;""; case "">"": return ""&gt;""; default: return s; } }); } function synchronize( callback, last ) { config.queue.push( callback ); if ( config.autorun && !config.blocking ) { process( last ); } } function process( last ) { function next() { process( last ); } var start = new Date().getTime(); config.depth = config.depth ? config.depth + 1 : 1; while ( config.queue.length && !config.blocking ) { if ( !defined.setTimeout || config.updateRate <= 0 || ( ( new Date().getTime() - start ) < config.updateRate ) ) { config.queue.shift()(); } else { window.setTimeout( next, 13 ); break; } } config.depth--; if ( last && !config.blocking && !config.queue.length && config.depth === 0 ) { done(); } } function saveGlobal() { config.pollution = []; if ( config.noglobals ) { for ( var key in window ) { // in Opera sometimes DOM element ids show up here, ignore them if ( !hasOwn.call( window, key ) || /^qunit-test-output/.test( key ) ) { continue; } config.pollution.push( key ); } } } function checkPollution( name ) { var newGlobals, deletedGlobals, old = config.pollution; saveGlobal(); newGlobals = diff( config.pollution, old ); if ( newGlobals.length > 0 ) { QUnit.pushFailure( ""Introduced global variable(s): "" + newGlobals.join("", "") ); } deletedGlobals = diff( old, config.pollution ); if ( deletedGlobals.length > 0 ) { QUnit.pushFailure( ""Deleted global variable(s): "" + deletedGlobals.join("", "") ); } } // returns a new Array with the elements that are in a but not in b function diff( a, b ) { var i, j, result = a.slice(); for ( i = 0; i < result.length; i++ ) { for ( j = 0; j < b.length; j++ ) { if ( result[i] === b[j] ) { result.splice( i, 1 ); i--; break; } } } return result; } function extend( a, b ) { for ( var prop in b ) { if ( b[ prop ] === undefined ) { delete a[ prop ]; // Avoid ""Member not found"" error in IE8 caused by setting window.constructor } else if ( prop !== ""constructor"" || a !== window ) { a[ prop ] = b[ prop ]; } } return a; } function addEvent( elem, type, fn ) { if ( elem.addEventListener ) { elem.addEventListener( type, fn, false ); } else if ( elem.attachEvent ) { elem.attachEvent( ""on"" + type, fn ); } else { fn(); } } function id( name ) { return !!( typeof document !== ""undefined"" && document && document.getElementById ) && document.getElementById( name ); } function registerLoggingCallback( key ) { return function( callback ) { config[key].push( callback ); }; } // Supports deprecated method of completely overwriting logging callbacks function runLoggingCallbacks( key, scope, args ) { //debugger; var i, callbacks; if ( QUnit.hasOwnProperty( key ) ) { QUnit[ key ].call(scope, args ); } else { callbacks = config[ key ]; for ( i = 0; i < callbacks.length; i++ ) { callbacks[ i ].call( scope, args ); } } } if ( b instanceof a.constructor || a instanceof b.constructor ) { // to catch short annotaion VS 'new' annotation of a // and its modifers a.multiline === b.multiline; var i, j, len, loop; if ( parents[j] === a[i] ) { loop = true;// dont rewalk array var i, j, loop, for ( i in a ) { // be strict: don't ensures hasOwnProperty // and go deep if ( parents[j] === a[i] ) { // don't go down the same path twice loop = true; } } aProperties.push(i); // collect a's properties if (!loop && !innerEquiv( a[i], b[i] ) ) { callers.pop(); // unstack, we are done }( args[0], args[1] ) && arguments.callee.apply( this, args.splice(1, args.length - 1 )) ); return '""' + str.toString().replace( /""/g, '\\""' ) + '""'; parse: function( obj, type, stack ) { //type is used mostly internally, you can fix a (custom)type in advance if ( inStack != -1 ) { //else if ( type == ""function"" ) { // else return ( type == ""string"" ) ? parser : this.parsers.error; indent: function( extra ) {// extra can be a number, shortcut for increasing-calling-decreasing return new Array( this._depth_ + (extra||0) ).join(chr); this._depth_ += a || 1; this._depth_ -= a || 1; _depth_: 1, error: ""[ERROR]"", //when no parser is found, shouldn""t happen name = ""name"" in fn ? fn.name : (reName.exec(fn) || [])[1];//functions never have name in IE if ( Object.keys ) { keys = Object.keys( map ); } else { keys = []; for ( key in map ) { keys.push( key ); } var a, val, ret = open + tag; for ( a in QUnit.jsDump.DOMAttrs ) { val = node[ QUnit.jsDump.DOMAttrs[a] ]; if ( val ) { ret += "" "" + a + ""="" + QUnit.jsDump.parse( val, ""attribute"" ); } } return ret + close + open + ""/"" + tag + close; functionArgs: function( fn ) {//function calls it internally, it's the arguments part of the function args[l] = String.fromCharCode(97+l);//97 is 'a' key: quote, //object calls it internally, the key part of an item in a map functionCode: ""[code]"", //function calls it internally, it's the content of the function attribute: quote, //node calls it internally, it's an html attribute value regexp: literal, //regex DOMAttrs: { //attributes to dump from nodes, name=>realName id: ""id"", name: ""name"", ""class"": ""className"" }, HTML: false,//if true, entities are escaped ( <, >, \t, space and \n ) indentChar: "" "",//indentation unit multiline: true //if true, items in a collection, are separated by a \n, else just a space.// from Sizzle.js function getText( elems ) { var i, elem, ret = """"; for ( i = 0; elems[i]; i++ ) { elem = elems[i]; // Get the text from text nodes and CDATA nodes if ( elem.nodeType === 3 || elem.nodeType === 4 ) { ret += elem.nodeValue; // Traverse everything else, except comment nodes } else if ( elem.nodeType !== 8 ) { ret += getText( elem.childNodes ); } } return ret; } // from jquery.js function inArray( elem, array ) { if ( array.indexOf ) { return array.indexOf( elem ); } for ( var i = 0, length = array.length; i < length; i++ ) { if ( array[ i ] === elem ) { return i; } } return -1; } if ( ns[ n[i] ] == null ) { if ( os[ o[i] ] == null ) { if ( !hasOwn.call( ns, i ) ) { continue; } if ( ns[i].rows.length == 1 && typeof os[i] != ""undefined"" && os[i].rows.length == 1 ) { n[ ns[i].rows[0] ] = { text: n[ ns[i].rows[0] ], row: os[i].rows[0] }; o[ os[i].rows[0] ] = { text: o[ os[i].rows[0] ], row: ns[i].rows[0] };// for CommonJS environments, export everything if ( typeof exports !== ""undefined"" ) { extend(exports, QUnit); } // get at whatever the global object is, like window in browsers }( (function() {return this;}.call()) ));",2547,2685
openstack%2Fnova~master~I9a5d4f647611aa00bed44afdeda5763f8fa9c35b,openstack/nova,master,I9a5d4f647611aa00bed44afdeda5763f8fa9c35b,Make compute api use util.check_string_length,MERGED,2014-03-19 07:49:05.000000000,2014-08-08 07:32:47.000000000,2014-08-08 07:32:44.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 6062}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-03-19 07:49:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bcf4d2767c38644dc32c2a25ea2ae6fc96560f72', 'message': 'Make compute api use util.check_string_length\n\nMake some string variables check in compute use util.check_string_length\ninstead of checking by itself\n\nChange-Id: I9a5d4f647611aa00bed44afdeda5763f8fa9c35b\n'}, {'number': 2, 'created': '2014-03-19 08:00:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f2bd26dd78daa07d5f766946252aa4de9ed5ab8', 'message': 'Make compute api use util.check_string_length\n\nMake some string variables check in compute use util.check_string_length\ninstead of checking by itself\n\nChange-Id: I9a5d4f647611aa00bed44afdeda5763f8fa9c35b\n'}, {'number': 3, 'created': '2014-03-20 03:14:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5655da8dee974d92b927d8035c5f396e8fc6eb84', 'message': 'Make compute api use util.check_string_length\n\nMake some string variables check in compute use util.check_string_length\ninstead of checking by itself\n\nChange-Id: I9a5d4f647611aa00bed44afdeda5763f8fa9c35b\n'}, {'number': 4, 'created': '2014-06-04 13:00:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ef3ae49204649e66aa4c3755a06f9e2b63968519', 'message': 'Make compute api use util.check_string_length\n\nMake some string variables check in compute use util.check_string_length\ninstead of checking by itself\n\nChange-Id: I9a5d4f647611aa00bed44afdeda5763f8fa9c35b\n'}, {'number': 5, 'created': '2014-06-05 01:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84679e84d8489fb8c38122b0c368abc7fbd7267d', 'message': 'Make compute api use util.check_string_length\n\nMake some string variables check in compute use util.check_string_length\ninstead of checking by itself\n\nChange-Id: I9a5d4f647611aa00bed44afdeda5763f8fa9c35b\n'}, {'number': 6, 'created': '2014-07-14 01:23:51.000000000', 'files': ['nova/tests/compute/test_keypairs.py', 'nova/utils.py', 'nova/tests/api/openstack/compute/contrib/test_keypairs.py', 'nova/compute/api.py', 'nova/tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8e0e61c971d82137ff870908ce360c9991a001d8', 'message': 'Make compute api use util.check_string_length\n\nMake some string variables check in compute use util.check_string_length\ninstead of checking by itself\n\nChange-Id: I9a5d4f647611aa00bed44afdeda5763f8fa9c35b\n'}]",7,81468,8e0e61c971d82137ff870908ce360c9991a001d8,90,11,6,6062,,,0,"Make compute api use util.check_string_length

Make some string variables check in compute use util.check_string_length
instead of checking by itself

Change-Id: I9a5d4f647611aa00bed44afdeda5763f8fa9c35b
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/81468/6 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/api.py'],1,bcf4d2767c38644dc32c2a25ea2ae6fc96560f72,refactory-compute-use-utils," try: utils.check_string_length(v, v) utils.check_string_length(k, k, min_length=1) except exception.InvalidInput as e: raise exception.InvalidMetadata(reason=e.format_message()) #For backward compatible, we need to raise HTTPRequestEntityTooLarge #so we need to keep InvalidMetadataSize exception here try: utils.check_string_length(key_name, key_name, min_length=1, max_length=255) except exception.InvalidInput: utils.check_string_length(val, val, min_length=1, max_length=255)"," if not isinstance(k, six.string_types): msg = _(""Metadata property key '%s' is not a string."") % k raise exception.InvalidMetadata(reason=msg) if not isinstance(v, six.string_types): msg = (_(""Metadata property value '%(v)s' for key '%(k)s' is "" ""not a string."") % {'v': v, 'k': k}) raise exception.InvalidMetadata(reason=msg) if len(k) == 0: msg = _(""Metadata property key blank"") raise exception.InvalidMetadata(reason=msg) if not 0 < len(key_name) < 256: if not val: msg = _(""Security group %s cannot be empty."") % property self.raise_invalid_property(msg) if len(val) > 255: msg = _(""Security group %s should not be greater "" ""than 255 characters."") % property self.raise_invalid_property(msg)",16,18
openstack%2Fheat~master~I9134dfc625e12df1ebcacda8373f81737fd59c2c,openstack/heat,master,I9134dfc625e12df1ebcacda8373f81737fd59c2c,Fix monkey-patching occurence in a test,MERGED,2014-07-12 22:11:27.000000000,2014-08-08 07:23:29.000000000,2014-08-08 07:23:28.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 7404}, {'_account_id': 8871}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-07-12 22:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0d8a104e64dbe197ec51412d4f1e35b5ba29ca90', 'message': 'Fix monkey-patching occurence in a test\n\nA test of Resource class was using a direct monkey-patching of a\ngeneric resource class without cleanup. This has not resulted in an error\nso far, but surely might in the future.\n\nThis patch uses proper mock for patching instead.\n\nChange-Id: I9134dfc625e12df1ebcacda8373f81737fd59c2c\n'}, {'number': 2, 'created': '2014-07-13 15:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/55eab6c0a5d963544ce274b9190cb2dbc3d3eae2', 'message': 'Fix monkey-patching occurence in a test\n\nA test of Resource class was using a direct monkey-patching of a\ngeneric resource class without cleanup. This has not resulted in an error\nso far, but surely might in the future.\n\nThis patch uses proper mock for patching instead.\n\nChange-Id: I9134dfc625e12df1ebcacda8373f81737fd59c2c\n'}, {'number': 3, 'created': '2014-07-14 08:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5ac39ada1e2fd5d80f6d603b73ee73debe02a885', 'message': 'Fix monkey-patching occurence in a test\n\nA test of Resource class was using a direct monkey-patching of a\ngeneric resource class without cleanup. This has not resulted in an error\nso far, but surely might in the future.\n\nThis patch uses proper mock for patching instead.\n\nChange-Id: I9134dfc625e12df1ebcacda8373f81737fd59c2c\n'}, {'number': 4, 'created': '2014-07-17 12:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e9e317bce80b638d1117579c74606392a9e28416', 'message': 'Fix monkey-patching occurence in a test\n\nA test of Resource class was using a direct monkey-patching of a\ngeneric resource class without cleanup. This has not resulted in an error\nso far, but surely might in the future.\n\nThis patch uses proper mock for patching instead.\n\nChange-Id: I9134dfc625e12df1ebcacda8373f81737fd59c2c\n'}, {'number': 5, 'created': '2014-08-07 08:44:08.000000000', 'files': ['heat/tests/test_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/b44284fb5b0da7ff57ca04f93ae116f061a64ba4', 'message': 'Fix monkey-patching occurence in a test\n\nA test of Resource class was using a direct monkey-patching of a\ngeneric resource class without cleanup. This has not resulted in an error\nso far, but surely might in the future.\n\nThis patch uses proper mock for patching instead.\n\nChange-Id: I9134dfc625e12df1ebcacda8373f81737fd59c2c\n'}]",0,106586,b44284fb5b0da7ff57ca04f93ae116f061a64ba4,55,8,5,9542,,,0,"Fix monkey-patching occurence in a test

A test of Resource class was using a direct monkey-patching of a
generic resource class without cleanup. This has not resulted in an error
so far, but surely might in the future.

This patch uses proper mock for patching instead.

Change-Id: I9134dfc625e12df1ebcacda8373f81737fd59c2c
",git fetch https://review.opendev.org/openstack/heat refs/changes/86/106586/4 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_resource.py'],1,0d8a104e64dbe197ec51412d4f1e35b5ba29ca90,improve-mock-patching," schema = {'Foo': {'Type': 'String', 'Default': '567'}} self.patchobject(generic_rsrc.ResourceWithProps, 'properties_schema', new=schema)"," generic_rsrc.ResourceWithProps.properties_schema = \ {'Foo': {'Type': 'String', 'Default': '567'}}",3,2
openstack%2Fheat~master~I779cab63249d5eb1962e9ec388cd31f3df4a4189,openstack/heat,master,I779cab63249d5eb1962e9ec388cd31f3df4a4189,Improve mocking in HeatTestCase,MERGED,2014-07-12 22:11:27.000000000,2014-08-08 07:23:21.000000000,2014-08-08 07:23:21.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7404}, {'_account_id': 8871}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-07-12 22:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e8a92898927ef665239af236e2daf2f6354922a9', 'message': 'Improve mocking in HeatTestCase\n\nAs the mock lib is going to be used more actively, there is a need\nto improve our boilerplate code in respect to mock.\n\nChanges in this patch include:\n* `patchobject` method now uses `mock.patch.object` directly,\n  without two layers of abstraction\n  (those might be a crust from earlier mock days, but current mock\n  does all that just fine by itself);\n* `patchobject` now accepts kwargs and passes them to `mock.patch.object`;\n* added `patch` method that uses mock.patch (similar to `patchobject`)\n  - NOTE: this shadows `testtools.TestCase.patch` method that uses\n    simple monkey-patching in favor of mock-based patching,\n    relevant comment added in the code;\n* test code changed accordingly where needed.\n\nChange-Id: I779cab63249d5eb1962e9ec388cd31f3df4a4189\n'}, {'number': 2, 'created': '2014-07-13 15:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/73e20ec111c3671a8f567317c92833f9dcde42ad', 'message': 'Improve mocking in HeatTestCase\n\nAs the mock lib is going to be used more actively, there is a need\nto improve our boilerplate code in respect to mock.\n\nChanges in this patch include:\n* `patchobject` method now uses `mock.patch.object` directly,\n  without two layers of abstraction\n  (those might be a crust from earlier mock days, but current mock\n  does all that just fine by itself);\n* `patchobject` now accepts kwargs and passes them to `mock.patch.object`;\n* added `patch` method that uses mock.patch (similar to `patchobject`)\n  - NOTE: this shadows `testtools.TestCase.patch` method that uses\n    simple monkey-patching in favor of mock-based patching,\n    relevant comment added in the code;\n* test code changed accordingly where needed.\n\nChange-Id: I779cab63249d5eb1962e9ec388cd31f3df4a4189\n'}, {'number': 3, 'created': '2014-07-14 08:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/86d75126611b47b16bceeff322bfacb8dee808fc', 'message': 'Improve mocking in HeatTestCase\n\nAs the mock lib is going to be used more actively, there is a need\nto improve our boilerplate code in respect to mock.\n\nChanges in this patch include:\n* `patchobject` now accepts kwargs and passes them to `mock.patch.object`;\n* added `patch` method that uses mock.patch (similar to `patchobject`)\n  - NOTE: this shadows `testtools.TestCase.patch` method that uses\n    simple monkey-patching in favor of mock-based patching,\n    relevant comment added in the code;\n* test code changed accordingly where needed.\n\nChange-Id: I779cab63249d5eb1962e9ec388cd31f3df4a4189\n'}, {'number': 4, 'created': '2014-07-17 12:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3db08cad59eda4ac94fa0307b7b046089d71bc8c', 'message': 'Improve mocking in HeatTestCase\n\nAs the mock lib is going to be used more actively, there is a need\nto improve our boilerplate code in respect to mock.\n\nChanges in this patch include:\n* `patchobject` now accepts kwargs and passes them to `mock.patch.object`;\n* added `patch` method that uses mock.patch (similar to `patchobject`)\n  - NOTE: this shadows `testtools.TestCase.patch` method that uses\n    simple monkey-patching in favor of mock-based patching,\n    relevant comment added in the code;\n* test code changed accordingly where needed.\n\nChange-Id: I779cab63249d5eb1962e9ec388cd31f3df4a4189\n'}, {'number': 5, 'created': '2014-08-07 08:44:08.000000000', 'files': ['heat/tests/test_metadata_refresh.py', 'heat/tests/common.py', 'heat/tests/test_engine_service.py', 'heat/tests/test_validate.py', 'heat/tests/test_heat_autoscaling_group.py', 'contrib/rackspace/rackspace/tests/test_auto_scale.py', 'heat/tests/test_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/3d65dba1638d5a292840f70166324f5d7c1db537', 'message': 'Improve mocking in HeatTestCase\n\nAs the mock lib is going to be used more actively, there is a need\nto improve our boilerplate code in respect to mock.\n\nChanges in this patch include:\n* `patchobject` now accepts kwargs and passes them to `mock.patch.object`;\n* added `patch` method that uses mock.patch (similar to `patchobject`)\n  - NOTE: this shadows `testtools.TestCase.patch` method that uses\n    simple monkey-patching in favor of mock-based patching,\n    relevant comment added in the code;\n* test code changed accordingly where needed.\n\nChange-Id: I779cab63249d5eb1962e9ec388cd31f3df4a4189\n'}]",2,106585,3d65dba1638d5a292840f70166324f5d7c1db537,43,7,5,9542,,,0,"Improve mocking in HeatTestCase

As the mock lib is going to be used more actively, there is a need
to improve our boilerplate code in respect to mock.

Changes in this patch include:
* `patchobject` now accepts kwargs and passes them to `mock.patch.object`;
* added `patch` method that uses mock.patch (similar to `patchobject`)
  - NOTE: this shadows `testtools.TestCase.patch` method that uses
    simple monkey-patching in favor of mock-based patching,
    relevant comment added in the code;
* test code changed accordingly where needed.

Change-Id: I779cab63249d5eb1962e9ec388cd31f3df4a4189
",git fetch https://review.opendev.org/openstack/heat refs/changes/85/106585/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_metadata_refresh.py', 'heat/tests/common.py', 'heat/tests/test_engine_service.py', 'heat/tests/test_validate.py', 'heat/tests/test_heat_autoscaling_group.py', 'contrib/rackspace/rackspace/tests/test_auto_scale.py', 'heat/tests/test_resource.py']",7,e8a92898927ef665239af236e2daf2f6354922a9,improve-mock-patching, self.patch('heat.engine.resource.warnings') self.patch('heat.engine.resource.warnings') self.patch('heat.engine.resource.warnings'), self.mock_warnings = mock.patch('heat.engine.resource.warnings') self.mock_warnings.start() self.addCleanup(self.mock_warnings.stop) self.mock_warnings = mock.patch('heat.engine.resource.warnings') self.mock_warnings.start() self.addCleanup(self.mock_warnings.stop) self.mock_warnings = mock.patch('heat.engine.resource.warnings') self.mock_warnings.start() self.addCleanup(self.mock_warnings.stop),37,52
openstack%2Fsahara-image-elements~master~I851bc426db64df953bc0d429fc0ad466c5a62908,openstack/sahara-image-elements,master,I851bc426db64df953bc0d429fc0ad466c5a62908,Disable Hive element for vanilla 2.x plugins,MERGED,2014-08-06 11:44:05.000000000,2014-08-08 07:22:02.000000000,2014-08-08 07:22:02.000000000,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-08-06 11:44:05.000000000', 'files': ['diskimage-create/diskimage-create.sh'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/30b11bf95098ec362dd6ac97d574bda4a801da6f', 'message': ""Disable Hive element for vanilla 2.x plugins\n\nVanilla 2.x plugin don't support Hive in Sahara\n\nChange-Id: I851bc426db64df953bc0d429fc0ad466c5a62908\n""}]",0,112270,30b11bf95098ec362dd6ac97d574bda4a801da6f,16,8,1,7710,,,0,"Disable Hive element for vanilla 2.x plugins

Vanilla 2.x plugin don't support Hive in Sahara

Change-Id: I851bc426db64df953bc0d429fc0ad466c5a62908
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/70/112270/1 && git format-patch -1 --stdout FETCH_HEAD,['diskimage-create/diskimage-create.sh'],1,30b11bf95098ec362dd6ac97d574bda4a801da6f,," ubuntu_elements_sequence=""base vm ubuntu hadoop oozie mysql"" fedora_elements_sequence=""base vm fedora hadoop oozie mysql disable-firewall"" centos_elements_sequence=""vm rhel hadoop oozie mysql redhat-lsb disable-firewall"" elements_sequence=""$ubuntu_elements_sequence swift_hadoop hive"" elements_sequence=""$fedora_elements_sequence swift_hadoop hive"" elements_sequence=""$centos_elements_sequence swift_hadoop hive"""," ubuntu_elements_sequence=""base vm ubuntu hadoop oozie mysql hive"" fedora_elements_sequence=""base vm fedora hadoop oozie mysql hive disable-firewall"" centos_elements_sequence=""vm rhel hadoop oozie mysql hive redhat-lsb disable-firewall"" elements_sequence=""$ubuntu_elements_sequence swift_hadoop"" elements_sequence=""$fedora_elements_sequence swift_hadoop"" elements_sequence=""$centos_elements_sequence swift_hadoop""",6,6
openstack%2Fneutron~master~I88f6574f921596426e1a31c9ff2251aa6f4674b8,openstack/neutron,master,I88f6574f921596426e1a31c9ff2251aa6f4674b8,l3_db: refactor L3_NAT_DB_mixin,MERGED,2014-07-22 15:14:31.000000000,2014-08-08 07:16:21.000000000,2014-08-08 07:16:20.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 333}, {'_account_id': 841}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 8213}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12614}]","[{'number': 1, 'created': '2014-07-22 15:14:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2be2c32cb08255fdae2b3d5d2222cf665e302fe6', 'message': 'l3_db: refactor L3_NAT_DB_mixin\n\nThis patch refactors L3_NAT_DB_mixin to split out\ndb operation and rpc notification.\n\nRelated to blueprint cisco-routing-service-vm\nRelated to blueprint l3-plugin-brocade-vyatta-vrouter\n\nChange-Id: I88f6574f921596426e1a31c9ff2251aa6f4674b8\n'}, {'number': 2, 'created': '2014-07-23 09:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bac5bc4733a77b0fdfdad917e8fce2faf731c382', 'message': 'l3_db: refactor L3_NAT_DB_mixin\n\nThis patch refactors L3_NAT_DB_mixin to split out\ndb operation and rpc notification.\n\nRelated to blueprint cisco-routing-service-vm\nRelated to blueprint l3-plugin-brocade-vyatta-vrouter\n\nChange-Id: I88f6574f921596426e1a31c9ff2251aa6f4674b8\n'}, {'number': 3, 'created': '2014-07-28 04:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bcf3ec50e8eecb5137dd443c4be9d5a0896ea62b', 'message': 'l3_db: refactor L3_NAT_DB_mixin\n\nThis patch refactors L3_NAT_DB_mixin to split out db operation and\nrpc notification.\n\nl3 plugin for routervm will implement the method for REST resource\noperation as something linke\n    def op_resource():\n        additional operation\n        with session\n            additional db operation\n            db operation of super class => super().db_op_resoruce\n            additional db operation\n        additional operation\n        l3 rpc notification\n\nHowever, The current L3_NAT_DB_mixin intermixes db operations with l3 rpc.\nSo it is difficult to reuse the db operation code without l3 rpc.\nThis patch splits db operation from l3 rpc notification so that\ndb operation logic can be reused easily. Thus the l3 plugin for routervm\nwill be simplified with this patch.\n\nRelated to blueprint cisco-routing-service-vm\nRelated to blueprint l3-plugin-brocade-vyatta-vrouter\n\nChange-Id: I88f6574f921596426e1a31c9ff2251aa6f4674b8\n'}, {'number': 4, 'created': '2014-07-30 02:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3e962a9db81509c2679a4f13633ae3eab7fea2c6', 'message': 'l3_db: refactor L3_NAT_DB_mixin\n\nThis patch refactors L3_NAT_DB_mixin to split out db operation and\nrpc notification.\n\nl3 plugin for routervm will implement the method for REST resource\noperation as something like\n    def op_resource():\n        additional operation\n        with session\n            additional db operation\n            db operation of super class => super().db_op_resoruce\n            additional db operation\n        additional operation\n        l3 rpc notification\n\nHowever, The current L3_NAT_DB_mixin intermixes db operations with l3 rpc.\nSo it is difficult to reuse the db operation code without l3 rpc.\nThis patch splits db operation from l3 rpc notification so that\ndb operation logic can be reused easily. Thus the l3 plugin for routervm\nwill be simplified with this patch.\n\nRelated to blueprint cisco-routing-service-vm\nRelated to blueprint l3-plugin-brocade-vyatta-vrouter\n\nChange-Id: I88f6574f921596426e1a31c9ff2251aa6f4674b8\n'}, {'number': 5, 'created': '2014-07-30 06:18:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2d954639d9217be6145c410f8fe8177a8be78ffa', 'message': 'l3_db: refactor L3_NAT_DB_mixin\n\nThis patch refactors L3_NAT_DB_mixin to split out db operation and\nrpc notification.\n\nl3 plugin for routervm will implement the method for REST resource\noperation as something like\n    def op_resource():\n        additional operation\n        with session\n            additional db operation\n            db operation of super class => super().db_op_resoruce\n            additional db operation\n        additional operation\n        l3 rpc notification\n\nHowever, The current L3_NAT_DB_mixin intermixes db operations with l3 rpc.\nSo it is difficult to reuse the db operation code without l3 rpc.\nThis patch splits db operation from l3 rpc notification so that\ndb operation logic can be reused easily. Thus the l3 plugin for routervm\nwill be simplified with this patch.\n\nRelated to blueprint cisco-routing-service-vm\nRelated to blueprint l3-plugin-brocade-vyatta-vrouter\n\nChange-Id: I88f6574f921596426e1a31c9ff2251aa6f4674b8\n'}, {'number': 6, 'created': '2014-08-04 06:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/71ae07ce37a166cc21612139804762c025273ea5', 'message': 'l3_db: refactor L3_NAT_DB_mixin\n\nThis patch refactors L3_NAT_DB_mixin to split out db operation and\nrpc notification.\n\nl3 plugin for routervm will implement the method for REST resource\noperation as something like\n    def op_resource():\n        additional operation\n        with session\n            additional db operation\n            db operation of super class => super().db_op_resoruce\n            additional db operation\n        additional operation\n        l3 rpc notification\n\nHowever, The current L3_NAT_DB_mixin intermixes db operations with l3 rpc.\nSo it is difficult to reuse the db operation code without l3 rpc.\nThis patch splits db operation from l3 rpc notification so that\ndb operation logic can be reused easily. Thus the l3 plugin for routervm\nwill be simplified with this patch.\n\nRelated to blueprint cisco-routing-service-vm\nRelated to blueprint l3-plugin-brocade-vyatta-vrouter\n\nChange-Id: I88f6574f921596426e1a31c9ff2251aa6f4674b8\n'}, {'number': 7, 'created': '2014-08-04 07:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/928567f653bf52329b1d81dde435b2419c67ecba', 'message': 'l3_db: refactor L3_NAT_DB_mixin\n\nThis patch refactors L3_NAT_DB_mixin to split out db operation and\nrpc notification.\n\nl3 plugin for routervm will implement the method for REST resource\noperation as something like\n    def op_resource():\n        additional operation\n        with session\n            additional db operation\n            db operation of super class => super().db_op_resoruce\n            additional db operation\n        additional operation\n        l3 rpc notification\n\nHowever, The current L3_NAT_DB_mixin intermixes db operations with l3 rpc.\nSo it is difficult to reuse the db operation code without l3 rpc.\nThis patch splits db operation from l3 rpc notification so that\ndb operation logic can be reused easily. Thus the l3 plugin for routervm\nwill be simplified with this patch.\n\nRelated to blueprint cisco-routing-service-vm\nRelated to blueprint l3-plugin-brocade-vyatta-vrouter\n\nChange-Id: I88f6574f921596426e1a31c9ff2251aa6f4674b8\n'}, {'number': 8, 'created': '2014-08-04 08:34:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/45ec41f6e1b7db4ab6586a7582f8a486ca008964', 'message': 'l3_db: refactor L3_NAT_DB_mixin\n\nThis patch refactors L3_NAT_DB_mixin to split out db operation and\nrpc notification.\n\nl3 plugin for routervm will implement the method for REST resource\noperation as something like\n    def op_resource():\n        additional operation\n        with session\n            additional db operation\n            db operation of super class => super().db_op_resoruce\n            additional db operation\n        additional operation\n        l3 rpc notification\n\nHowever, The current L3_NAT_DB_mixin intermixes db operations with l3 rpc.\nSo it is difficult to reuse the db operation code without l3 rpc.\nThis patch splits db operation from l3 rpc notification so that\ndb operation logic can be reused easily. Thus the l3 plugin for routervm\nwill be simplified with this patch.\n\nRelated to blueprint cisco-routing-service-vm\nRelated to blueprint l3-plugin-brocade-vyatta-vrouter\n\nChange-Id: I88f6574f921596426e1a31c9ff2251aa6f4674b8\n'}, {'number': 9, 'created': '2014-08-05 03:21:18.000000000', 'files': ['neutron/db/extraroute_db.py', 'neutron/db/l3_gwmode_db.py', 'neutron/db/l3_dvr_db.py', 'neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/748f0d53a150ffc46871bc2cd7ab7012105e64de', 'message': 'l3_db: refactor L3_NAT_DB_mixin\n\nThis patch refactors L3_NAT_DB_mixin to split out db operation and\nrpc notification.\n\nl3 plugin for routervm will implement the method for REST resource\noperation as something like\n    def op_resource():\n        additional operation\n        with session\n            additional db operation\n            db operation of super class => super().db_op_resoruce\n            additional db operation\n        additional operation\n        l3 rpc notification\n\nHowever, The current L3_NAT_DB_mixin intermixes db operations with l3 rpc.\nSo it is difficult to reuse the db operation code without l3 rpc.\nThis patch splits db operation from l3 rpc notification so that\ndb operation logic can be reused easily. Thus the l3 plugin for routervm\nwill be simplified with this patch.\n\nRelated to blueprint cisco-routing-service-vm\nRelated to blueprint l3-plugin-brocade-vyatta-vrouter\n\nChange-Id: I88f6574f921596426e1a31c9ff2251aa6f4674b8\n'}]",15,108728,748f0d53a150ffc46871bc2cd7ab7012105e64de,198,32,9,333,,,0,"l3_db: refactor L3_NAT_DB_mixin

This patch refactors L3_NAT_DB_mixin to split out db operation and
rpc notification.

l3 plugin for routervm will implement the method for REST resource
operation as something like
    def op_resource():
        additional operation
        with session
            additional db operation
            db operation of super class => super().db_op_resoruce
            additional db operation
        additional operation
        l3 rpc notification

However, The current L3_NAT_DB_mixin intermixes db operations with l3 rpc.
So it is difficult to reuse the db operation code without l3 rpc.
This patch splits db operation from l3 rpc notification so that
db operation logic can be reused easily. Thus the l3 plugin for routervm
will be simplified with this patch.

Related to blueprint cisco-routing-service-vm
Related to blueprint l3-plugin-brocade-vyatta-vrouter

Change-Id: I88f6574f921596426e1a31c9ff2251aa6f4674b8
",git fetch https://review.opendev.org/openstack/neutron refs/changes/28/108728/8 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/l3_db.py'],1,2be2c32cb08255fdae2b3d5d2222cf665e302fe6,bp/cisco-routing-service-vm,"class L3NatDbMixin(l3.RouterPluginBase): @staticmethod def _make_router_interface_info( router_id, tenant_id, port_id, subnet_id): return { return self._make_router_interface_info( router_id, port['tenant_id'], port['id'], port['fixed_ips'][0]['subnet_id']) return self._make_router_interface_info(router_id, port['tenant_id'], port['id'], subnet['id']) def _update_floatingip(self, context, id, floatingip): return router_ids, self._make_floatingip_dict(floatingip_db) def update_floatingip(self, context, id, floatingip): _router_ids, floatingip_dict = self._update_floatingip( context, id, floatingip) return floatingip_dict def _delete_floatingip(self, context, id): return router_id def delete_floatingip(self, context, id): self._delete_floatingip(context, id) def disassociate_floatingips(self, context, port_id): class L3RpcNotifierMixin(object): """"""Mixin class to add rpc notifier attribute to db_base_plugin_v2."""""" @property def l3_rpc_notifier(self): if not hasattr(self, '_l3_rpc_notifier'): self._l3_rpc_notifier = l3_rpc_agent_api.L3AgentNotifyAPI() return self._l3_rpc_notifier @l3_rpc_notifier.setter def l3_rpc_notifier(self, value): self._l3_rpc_notifier = value def notify_router_updated(self, context, router_id, operation=None, data=None): if router_id: self.l3_rpc_notifier.routers_updated( context, [router_id], operation, data) def notify_routers_updated(self, context, router_ids, operation=None, data=None): if router_ids: self.l3_rpc_notifier.routers_updated( context, router_ids, operation, data) def notify_router_deleted(self, context, router_id): self.l3_rpc_notifier.router_deleted(context, router_id) class L3_NAT_db_mixin(L3NatDbMixin, L3RpcNotifierMixin): """"""Mixin class to add rpc notifier methods to db_base_plugin_v2."""""" def notify_super_routers_updated(self, context, router_ids, operation=None, data=None): super(L3_NAT_db_mixin, self).notify_routers_updated( context, router_ids, operation, data) def update_router(self, context, id, router): router_dict = super(L3_NAT_db_mixin, self).update_router(context, id, router) self.notify_router_updated(context, router_dict['id']) return router_dict def delete_router(self, context, id): super(L3_NAT_db_mixin, self).delete_router(context, id) self.notify_router_deleted(context, id) def notify_router_interface_action( self, context, router_interface_info, action): l3_method = '%s_router_interface' % action self.notify_super_routers_updated( context, [router_interface_info['id']], l3_method) mapping = {'add': 'create', 'remove': 'delete'} notifier = n_rpc.get_notifier('network') router_event = 'router.interface.%s' % mapping[action] notifier.info(context, router_event, {'router_interface': router_interface_info}) def add_router_interface(self, context, router_id, interface_info): router_interface_info = super( L3_NAT_db_mixin, self).add_router_interface( context, router_id, interface_info) return self.notify_router_interface_action( context, router_interface_info, 'add') def remove_router_interface(self, context, router_id, interface_info): router_interface_info = super( L3_NAT_db_mixin, self).remove_router_interface( context, router_id, interface_info) return self.notify_router_interface_action( context, router_interface_info, 'remove') def create_floatingip( self, context, floatingip, initial_status=l3_constants.FLOATINGIP_STATUS_ACTIVE): floatingip_dict = super(L3_NAT_db_mixin, self).create_floatingip( context, floatingip, initial_status) router_id = floatingip_dict['router_id'] self.notify_router_updated(context, router_id, 'create_floatingip') return floatingip_dict def update_floatingip(self, context, id, floatingip): router_ids, floatingip_dict = self._update_floatingip( context, id, floatingip) self.notify_super_routers_updated( context, router_ids, 'update_floatingip') return floatingip_dict def delete_floatingip(self, context, id): router_id = self._delete_floatingip(context, id) self.notify_router_updated(context, router_id, 'delete_floatingip') def disassociate_floatingips(self, context, port_id, do_notify=True): """"""Disassociate all floating IPs linked to specific port. @param port_id: ID of the port to disassociate floating IPs. @param do_notify: whether we should notify routers right away. @return: set of router-ids that require notification updates if do_notify is False, otherwise None. """""" router_ids = super(L3_NAT_db_mixin, self).disassociate_floatingips( context, port_id) if do_notify: self.notify_routers_updated(context, router_ids) # since caller assumes that we handled notifications on its # behalf, return nothing return return router_ids def notify_routers_updated(self, context, router_ids): self.notify_super_routers_updated(context, list(router_ids), 'disassociate_floatingips')","class L3_NAT_db_mixin(l3.RouterPluginBase): def l3_rpc_notifier(self): if not hasattr(self, '_l3_rpc_notifier'): self._l3_rpc_notifier = l3_rpc_agent_api.L3AgentNotifyAPI() return self._l3_rpc_notifier @l3_rpc_notifier.setter def l3_rpc_notifier(self, value): self._l3_rpc_notifier = value @property self.l3_rpc_notifier.routers_updated(context, [router_db['id']]) self.l3_rpc_notifier.router_deleted(context, id) def notify_router_interface_action( self, context, router_id, tenant_id, port_id, subnet_id, action): l3_method = '%s_router_interface' % action self.l3_rpc_notifier.routers_updated(context, [router_id], l3_method) mapping = {'add': 'create', 'remove': 'delete'} info = { notifier = n_rpc.get_notifier('network') router_event = 'router.interface.%s' % mapping[action] notifier.info(context, router_event, {'router_interface': info}) return info return self.notify_router_interface_action( context, router_id, port['tenant_id'], port['id'], port['fixed_ips'][0]['subnet_id'], 'add') return self.notify_router_interface_action( context, router_id, port['tenant_id'], port['id'], subnet['id'], 'remove') def update_floatingip(self, context, id, floatingip): if router_ids: self.l3_rpc_notifier.routers_updated( context, router_ids, 'update_floatingip') return self._make_floatingip_dict(floatingip_db) def delete_floatingip(self, context, id): if router_id: self.l3_rpc_notifier.routers_updated( context, [router_id], 'delete_floatingip') def disassociate_floatingips(self, context, port_id, do_notify=True): if do_notify: self.notify_routers_updated(context, router_ids) # since caller assumes that we handled notifications on its # behalf, return nothing return def notify_routers_updated(self, context, router_ids): if router_ids: self.l3_rpc_notifier.routers_updated( context, list(router_ids), 'disassociate_floatingips') ",139,54
openstack%2Fkeystone~master~I878a71c4b99bb8e9e080be852cb139909030dfd9,openstack/keystone,master,I878a71c4b99bb8e9e080be852cb139909030dfd9,Update CADF auditing example to show non-payload information,MERGED,2014-08-04 06:53:28.000000000,2014-08-08 07:12:05.000000000,2014-08-08 07:12:04.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 9751}, {'_account_id': 11045}]","[{'number': 1, 'created': '2014-08-04 06:53:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c15d0d69b3cb6ffdecd54941c1290d4dce655cbe', 'message': 'Update CADF auditing example to show non-payload information\n\nCurrently, the documentation only shows the payload of a CADF\nauthentication event. We should show the other non-payload info\nso as to be consistent with the other notification examples.\n\nChange-Id: I878a71c4b99bb8e9e080be852cb139909030dfd9\n'}, {'number': 2, 'created': '2014-08-07 21:19:34.000000000', 'files': ['doc/source/event_notifications.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/1cb512a7c397d49f9910fd248644f32146bc1fdd', 'message': 'Update CADF auditing example to show non-payload information\n\nCurrently, the documentation only shows the payload of a CADF\nauthentication event. We should show the other non-payload info\nso as to be consistent with the other notification examples.\n\nChange-Id: I878a71c4b99bb8e9e080be852cb139909030dfd9\n'}]",6,111657,1cb512a7c397d49f9910fd248644f32146bc1fdd,18,15,2,6482,,,0,"Update CADF auditing example to show non-payload information

Currently, the documentation only shows the payload of a CADF
authentication event. We should show the other non-payload info
so as to be consistent with the other notification examples.

Change-Id: I878a71c4b99bb8e9e080be852cb139909030dfd9
",git fetch https://review.opendev.org/openstack/keystone refs/changes/57/111657/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/event_notifications.rst'],1,c15d0d69b3cb6ffdecd54941c1290d4dce655cbe,hn2," ""event_type"": ""identity.authenticate"", ""message_id"": ""1371a590-d5fd-448f-b3bb-a14dead6f4cb"", ""payload"": { ""typeURI"": ""http: //schemas.dmtf.org/cloud/audit/1.0/event"", ""initiator"": { ""typeURI"": ""service/security/account/user"", ""host"": { ""agent"": ""curl/7.22.0(x86_64-pc-linux-gnu)"", ""address"": ""127.0.0.1"" }, ""id"": ""openstack: 5ee22124-6f41-4d23-a9f7-862c13a53a66"", ""name"": ""joeuser"" ""target"": { ""typeURI"": ""service/security/account/user"", ""id"": ""openstack: 1c2fc591-facb-4479-a327-520dade1ea15"" }, ""observer"": { ""typeURI"": ""service/security"", ""id"": ""openstack: 3d4a50a9-2b59-438b-bf19-c231f9c7625a"" }, ""eventType"": ""activity"", ""eventTime"": ""2014-02-14T01: 20: 47.932842+0000"", ""action"": ""authenticate"", ""outcome"": ""failure"", ""id"": ""openstack: f5352d7b-bee6-4c22-8213-450e7b646e9f"" ""priority"": ""INFO"", ""publisher_id"": ""identity.host1234"", ""timestamp"": ""2013-08-29 19:03:45.960280"""," ""typeURI"": ""http: //schemas.dmtf.org/cloud/audit/1.0/event"", ""initiator"": { ""typeURI"": ""service/security/account/user"", ""host"": { ""agent"": ""curl/7.22.0(x86_64-pc-linux-gnu)"", ""address"": ""127.0.0.1"" ""id"": ""openstack: 5ee22124-6f41-4d23-a9f7-862c13a53a66"", ""name"": ""joeuser"" ""target"": { ""typeURI"": ""service/security/account/user"", ""id"": ""openstack: 1c2fc591-facb-4479-a327-520dade1ea15"" }, ""observer"": { ""typeURI"": ""service/security"", ""id"": ""openstack: 3d4a50a9-2b59-438b-bf19-c231f9c7625a"" }, ""eventType"": ""activity"", ""eventTime"": ""2014-02-14T01: 20: 47.932842+0000"", ""action"": ""authenticate"", ""outcome"": ""failure"", ""id"": ""openstack: f5352d7b-bee6-4c22-8213-450e7b646e9f""",28,21
openstack%2Fneutron~master~Ic6dd28e3caf8b9e3322bf2df99e67adb138cb234,openstack/neutron,master,Ic6dd28e3caf8b9e3322bf2df99e67adb138cb234,test_l3_plugin: L3AgentDbInteTestCase L3AgentDbSepTestCase fails,MERGED,2014-07-30 09:15:46.000000000,2014-08-08 07:09:25.000000000,2014-08-08 06:30:00.000000000,"[{'_account_id': 3}, {'_account_id': 333}, {'_account_id': 704}, {'_account_id': 841}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6788}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 12444}]","[{'number': 1, 'created': '2014-07-30 09:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1f64454bf6e79f4eea6430eb1ca703e55caf4642', 'message': ""test_l3_plugin: L3AgentDbInteTestCase L3AgentDbSepTestCase fails\n\nL3AgentDbInteTestCase and L3AgentDbSepTestCase fails when they are run\nindependently without other test case. something like\ntox -e py27 neutron.tests.unit.test_l3_plugin\nIt's because necessary oslo.config options aren't properly initialized\nwhen instantiating service plugin.\nInitialize config before instantiating plugin.\n\nChange-Id: Ic6dd28e3caf8b9e3322bf2df99e67adb138cb234\nCloses-Bug: #1350252\n""}, {'number': 2, 'created': '2014-07-30 10:39:21.000000000', 'files': ['neutron/tests/unit/test_l3_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/748d4fdaf62667f39ce65e5053792b54dd684698', 'message': ""test_l3_plugin: L3AgentDbInteTestCase L3AgentDbSepTestCase fails\n\nL3AgentDbInteTestCase and L3AgentDbSepTestCase fails when they are run\nindependently without other test case. something like\ntox -e py27 neutron.tests.unit.test_l3_plugin\nIt's because necessary oslo.config options aren't properly initialized\nwhen instantiating service plugin.\nInitialize config before instantiating plugin.\n\nChange-Id: Ic6dd28e3caf8b9e3322bf2df99e67adb138cb234\nCloses-Bug: #1350252\n""}]",2,110577,748d4fdaf62667f39ce65e5053792b54dd684698,61,25,2,333,,,0,"test_l3_plugin: L3AgentDbInteTestCase L3AgentDbSepTestCase fails

L3AgentDbInteTestCase and L3AgentDbSepTestCase fails when they are run
independently without other test case. something like
tox -e py27 neutron.tests.unit.test_l3_plugin
It's because necessary oslo.config options aren't properly initialized
when instantiating service plugin.
Initialize config before instantiating plugin.

Change-Id: Ic6dd28e3caf8b9e3322bf2df99e67adb138cb234
Closes-Bug: #1350252
",git fetch https://review.opendev.org/openstack/neutron refs/changes/77/110577/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/test_l3_plugin.py'],1,1f64454bf6e79f4eea6430eb1ca703e55caf4642,bug/1350252, self.config_parse() self.config_parse(),,2,0
openstack%2Fapi-site~master~I7dd3c37aff948ef8f15252104bb2b6ca590305a6,openstack/api-site,master,I7dd3c37aff948ef8f15252104bb2b6ca590305a6,Imported Translations from Transifex,MERGED,2014-08-08 06:06:41.000000000,2014-08-08 07:08:34.000000000,2014-08-08 07:08:34.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-08 06:06:41.000000000', 'files': ['api-ref/locale/fr.po'], 'web_link': 'https://opendev.org/openstack/api-site/commit/d94bd8445a5084e6e91aadf457688f3291880205', 'message': 'Imported Translations from Transifex\n\nChange-Id: I7dd3c37aff948ef8f15252104bb2b6ca590305a6\n'}]",0,112762,d94bd8445a5084e6e91aadf457688f3291880205,7,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I7dd3c37aff948ef8f15252104bb2b6ca590305a6
",git fetch https://review.opendev.org/openstack/api-site refs/changes/62/112762/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/locale/fr.po'],1,d94bd8445a5084e6e91aadf457688f3291880205,transifex/translations,"""POT-Creation-Date: 2014-08-07 06:40+0000\n"" ""PO-Revision-Date: 2014-08-07 08:50+0000\n"" ""Last-Translator: Franois Bureau <francois.bureau@cloudwatt.com>\n""msgstr ""DEFERRED""msgstr ""PENDING_CREATE""msgstr ""PENDING_DELETE""msgstr ""ACTIVE""msgstr ""INACTIVE""msgstr ""ERROR""","""POT-Creation-Date: 2014-08-06 21:53+0000\n"" ""PO-Revision-Date: 2014-08-06 22:13+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"",9,9
openstack%2Fopenstack-manuals~master~I979455d8325e3f63fde80fd5e7d1eeb593fc35f2,openstack/openstack-manuals,master,I979455d8325e3f63fde80fd5e7d1eeb593fc35f2,Imported Translations from Transifex,MERGED,2014-08-08 06:10:08.000000000,2014-08-08 07:00:50.000000000,2014-08-08 07:00:50.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-08 06:10:08.000000000', 'files': ['doc/user-guide/locale/fr.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6ed46b067d7a2db1769294f85e03c8228198596f', 'message': 'Imported Translations from Transifex\n\nChange-Id: I979455d8325e3f63fde80fd5e7d1eeb593fc35f2\n'}]",0,112763,6ed46b067d7a2db1769294f85e03c8228198596f,7,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I979455d8325e3f63fde80fd5e7d1eeb593fc35f2
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/63/112763/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/user-guide/locale/fr.po'],1,6ed46b067d7a2db1769294f85e03c8228198596f,transifex/translations,"""POT-Creation-Date: 2014-08-07 23:43+0000\n"" ""PO-Revision-Date: 2014-08-07 20:10+0000\n""msgstr ""Dissocier une adresse IP flottante d'une instance d'un projet.""msgstr ""Utiliser la commande <placeholder-1/> pour grer les adresses IP flottantes.""msgstr ""Pour lister toutes les adresses IP flottantes qui sont alloues au projet courant excuter :""msgstr ""Associer des adresses IP flottantes""msgstr ""Vous pouvez assigner une adresse flottante  un projet et  une instance.""msgstr ""D-associer les adresse IP flottantes""msgstr ""Librer une adresse IP flottante d'une instance, comme suit :""msgstr ""Librer une adresse IP flottante d'un projet courant, comme suit :""","""POT-Creation-Date: 2014-07-31 21:35+0000\n"" ""PO-Revision-Date: 2014-07-31 10:11+0000\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"",10,10
openstack%2Fironic~master~If5939e3dcc3686046e0fc7989114d25270f034e8,openstack/ironic,master,If5939e3dcc3686046e0fc7989114d25270f034e8,backport reviewer comments on nova.virt.ironic.patcher,MERGED,2014-08-07 21:10:24.000000000,2014-08-08 06:53:57.000000000,2014-08-08 06:53:57.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 10239}, {'_account_id': 10342}]","[{'number': 1, 'created': '2014-08-07 21:10:24.000000000', 'files': ['ironic/nova/virt/ironic/patcher.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/435c20bd01c895587e6eb059d66e1eb2aff414b4', 'message': ""backport reviewer comments on nova.virt.ironic.patcher\n\nBackport comments on the Nova driver review in\nhttps://review.openstack.org/#/c/111423/\nto Ironic's tree.\n\nChange-Id: If5939e3dcc3686046e0fc7989114d25270f034e8\n""}]",0,112691,435c20bd01c895587e6eb059d66e1eb2aff414b4,10,4,1,2889,,,0,"backport reviewer comments on nova.virt.ironic.patcher

Backport comments on the Nova driver review in
https://review.openstack.org/#/c/111423/
to Ironic's tree.

Change-Id: If5939e3dcc3686046e0fc7989114d25270f034e8
",git fetch https://review.opendev.org/openstack/ironic refs/changes/91/112691/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/nova/virt/ironic/patcher.py'],1,435c20bd01c895587e6eb059d66e1eb2aff414b4,port-fixes-from-111423, :param node: a node object returned from ironicclient 'value': str(instance.root_gb)}) if instance.ephemeral_gb: 'value': str(instance.ephemeral_gb)}), :param node: a dict containing an Ironic node 'value': str(instance['root_gb'])}) if instance.get('ephemeral_gb'): 'value': str(instance['ephemeral_gb'])}),4,4
openstack%2Ftripleo-image-elements~master~I80dcce56d00fc6f1240a5fcccd425cc2b4db29d5,openstack/tripleo-image-elements,master,I80dcce56d00fc6f1240a5fcccd425cc2b4db29d5,Fix argparse issue for RHEL 6.5.,MERGED,2014-07-10 04:58:52.000000000,2014-08-08 06:51:12.000000000,2014-07-16 19:20:43.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6928}, {'_account_id': 8399}, {'_account_id': 9712}, {'_account_id': 10375}]","[{'number': 1, 'created': '2014-07-10 04:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/c56474eb9d63082c2a51a451b479b855aba9f1b0', 'message': 'Fix argparse issue for RHEL 6.5.\n\nSince RHEL 6.5 uses Python 2.6, which lacks argparse,\nthey need to be installed to ensure that os-apply-config\nand os-refresh-config work properly.\n\nChange-Id: I80dcce56d00fc6f1240a5fcccd425cc2b4db29d5\n'}, {'number': 2, 'created': '2014-07-15 14:07:21.000000000', 'files': ['elements/os-apply-config/install.d/os-apply-config-source-install/10-os-apply-config', 'elements/os-refresh-config/install.d/os-refresh-config-source-install/10-os-refresh-config'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/d088fde2ea59423d153f32d65be684be62727232', 'message': 'Fix argparse issue for RHEL 6.5.\n\nSince RHEL 6.5 uses Python 2.6, which lacks argparse,\nthey need to be installed to ensure that os-apply-config\nand os-refresh-config work properly.\n\nChange-Id: I80dcce56d00fc6f1240a5fcccd425cc2b4db29d5\n'}]",0,105966,d088fde2ea59423d153f32d65be684be62727232,25,6,2,10375,,,0,"Fix argparse issue for RHEL 6.5.

Since RHEL 6.5 uses Python 2.6, which lacks argparse,
they need to be installed to ensure that os-apply-config
and os-refresh-config work properly.

Change-Id: I80dcce56d00fc6f1240a5fcccd425cc2b4db29d5
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/66/105966/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/os-apply-config/install.d/os-apply-config-source-install/10-os-config-applier', 'elements/os-refresh-config/install.d/os-refresh-config-source-install/10-os-refresh-config']",2,c56474eb9d63082c2a51a451b479b855aba9f1b0,redhat_6.5_fix, /opt/stack/venvs/os-refresh-config/bin/pip install -U 'argparse',,2,0
openstack%2Fnova~master~Id8ef7ee2c0d85f8b784b8d1d46c7120331f1e01a,openstack/nova,master,Id8ef7ee2c0d85f8b784b8d1d46c7120331f1e01a,Return 404 when floating IP pool not found,MERGED,2014-08-07 10:04:47.000000000,2014-08-08 06:38:31.000000000,2014-08-07 13:53:11.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1923}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 5754}, {'_account_id': 6524}, {'_account_id': 8157}, {'_account_id': 8655}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-07 10:04:47.000000000', 'files': ['nova/tests/api/openstack/compute/contrib/test_floating_ips.py', 'nova/api/openstack/compute/contrib/floating_ips.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5de983be86fc05224d04fe48e12540b6914ce73f', 'message': 'Return 404 when floating IP pool not found\n\nThe FloatingIPPoolNotFound exception is raised only by the\nNeutron integration API. When that happens, the exception\nhandling code should ensure a 404 response code is returned\nin order to guarantee consistency with nova-network.\n\nChange-Id: Id8ef7ee2c0d85f8b784b8d1d46c7120331f1e01a\nCloses-Bug: 1353936\n'}]",0,112541,5de983be86fc05224d04fe48e12540b6914ce73f,18,13,1,261,,,0,"Return 404 when floating IP pool not found

The FloatingIPPoolNotFound exception is raised only by the
Neutron integration API. When that happens, the exception
handling code should ensure a 404 response code is returned
in order to guarantee consistency with nova-network.

Change-Id: Id8ef7ee2c0d85f8b784b8d1d46c7120331f1e01a
Closes-Bug: 1353936
",git fetch https://review.opendev.org/openstack/nova refs/changes/41/112541/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/compute/contrib/test_floating_ips.py', 'nova/api/openstack/compute/contrib/floating_ips.py']",2,5de983be86fc05224d04fe48e12540b6914ce73f,bug/1353936, raise webob.exc.HTTPNotFound(explanation=e.format_message()), raise webob.exc.HTTPBadRequest(explanation=e.format_message()),2,2
openstack%2Fnova~master~I358d9c0485c5dcf81498871faa9150e3bf167c6b,openstack/nova,master,I358d9c0485c5dcf81498871faa9150e3bf167c6b,Import Ironic scheduler filters and host manager,MERGED,2014-06-27 15:01:20.000000000,2014-08-08 06:24:31.000000000,2014-08-03 07:47:09.000000000,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 2271}, {'_account_id': 2889}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 8125}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-27 15:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6a1474cf7c99d423f98d5e30f134bca63914f7e0', 'message': 'Import Ironic scheduler filters and host manager\n\nThis is an import of the Ironic scheduler changes as of\ncommit 70b28fb5c124de16ef33ad28cb1bdbbebb39818e\n\nimplements bp: add-ironic-driver\n\nChange-Id: I358d9c0485c5dcf81498871faa9150e3bf167c6b\n'}, {'number': 2, 'created': '2014-06-27 19:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c4b4da750f1c986e5d6390ddb1bd5308e8da0fae', 'message': 'Import Ironic scheduler filters and host manager\n\nThis is an import of the Ironic scheduler changes as of\ncommit 70b28fb5c124de16ef33ad28cb1bdbbebb39818e\n\nimplements bp: add-ironic-driver\n\nChange-Id: I358d9c0485c5dcf81498871faa9150e3bf167c6b\n'}, {'number': 3, 'created': '2014-07-02 20:53:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/adfe2cbc34e336aa94c205bf80b5a996ddb8cabc', 'message': 'Import Ironic scheduler filters and host manager\n\nThis is an import of the Ironic scheduler changes as of\ncommit 70b28fb5c124de16ef33ad28cb1bdbbebb39818e\n\nimplements bp: add-ironic-driver\n\nChange-Id: I358d9c0485c5dcf81498871faa9150e3bf167c6b\n'}, {'number': 4, 'created': '2014-07-02 21:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0269ba4485f3be43281b66b4a6b5c74de0ff09a6', 'message': 'Import Ironic scheduler filters and host manager\n\nThis is an import of the Ironic scheduler changes as of\ncommit da967d77894be6f23d81fb5cc948f9d13898ba84\n\nimplements bp: add-ironic-driver\n\nChange-Id: I358d9c0485c5dcf81498871faa9150e3bf167c6b\n'}, {'number': 5, 'created': '2014-07-22 23:42:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/055a704bb667d090448073956d7abee32a800817', 'message': 'Import Ironic scheduler filters and host manager\n\nThis is an import of the Ironic scheduler changes as of\ncommit da967d77894be6f23d81fb5cc948f9d13898ba84\n\nimplements bp: add-ironic-driver\n\nCo-Authored-By: Michael Davies <michael@the-davies.net>\nCo-Authored-By: Adam Gandelman <adamg@ubuntu.com>\nCo-Authored-By: Hans Lindgren <hanlind@kth.se>\nCo-Authored-By: Rohan Kanade <openstack@rohankanade.com>\nCo-Authored-By: Chris Krelle <nobodycam@gmail.com>\nCo-Authored-By: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nCo-Authored-By: Derek Higgins <derekh@redhat.com>\nCo-Authored-By: Kurt Taylor <krtaylor@us.ibm.com>\nCo-Authored-By: Chris Behrens <cbehrens@codestud.com>\nCo-Authored-By: Mikyung Kang <mkkang@isi.edu>\n\nChange-Id: I358d9c0485c5dcf81498871faa9150e3bf167c6b\n'}, {'number': 6, 'created': '2014-07-23 01:19:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b356053d8e629dc58508bd0045afde47433b9318', 'message': 'Import Ironic scheduler filters and host manager\n\nThis is an import of the Ironic scheduler changes as of\ncommit da967d77894be6f23d81fb5cc948f9d13898ba84\n\nimplements bp: add-ironic-driver\n\nCo-Authored-By: Michael Davies <michael@the-davies.net>\nCo-Authored-By: Adam Gandelman <adamg@ubuntu.com>\nCo-Authored-By: Hans Lindgren <hanlind@kth.se>\nCo-Authored-By: Rohan Kanade <openstack@rohankanade.com>\nCo-Authored-By: Chris Krelle <nobodycam@gmail.com>\nCo-Authored-By: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nCo-Authored-By: Derek Higgins <derekh@redhat.com>\nCo-Authored-By: Kurt Taylor <krtaylor@us.ibm.com>\nCo-Authored-By: Chris Behrens <cbehrens@codestud.com>\nCo-Authored-By: Mikyung Kang <mkkang@isi.edu>\n\nChange-Id: I358d9c0485c5dcf81498871faa9150e3bf167c6b\n'}, {'number': 7, 'created': '2014-07-23 02:31:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4fddb271ae3405677983e18182134794dfe57ff0', 'message': 'Import Ironic scheduler filters and host manager\n\nThis is an import of the Ironic scheduler changes as of\ncommit da967d77894be6f23d81fb5cc948f9d13898ba84\n\nimplements bp: add-ironic-driver\n\nCo-Authored-By: Michael Davies <michael@the-davies.net>\nCo-Authored-By: Adam Gandelman <adamg@ubuntu.com>\nCo-Authored-By: Hans Lindgren <hanlind@kth.se>\nCo-Authored-By: Rohan Kanade <openstack@rohankanade.com>\nCo-Authored-By: Chris Krelle <nobodycam@gmail.com>\nCo-Authored-By: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nCo-Authored-By: Derek Higgins <derekh@redhat.com>\nCo-Authored-By: Kurt Taylor <krtaylor@us.ibm.com>\nCo-Authored-By: Chris Behrens <cbehrens@codestud.com>\nCo-Authored-By: Mikyung Kang <mkkang@isi.edu>\n\nChange-Id: I358d9c0485c5dcf81498871faa9150e3bf167c6b\n'}, {'number': 8, 'created': '2014-07-23 03:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9962f4111cd6f3d8ca72661d51d32b503d2b6175', 'message': 'Import Ironic scheduler filters and host manager\n\nThis is an import of the Ironic scheduler changes as of\ncommit da967d77894be6f23d81fb5cc948f9d13898ba84\n\nimplements bp: add-ironic-driver\n\nCo-Authored-By: Michael Davies <michael@the-davies.net>\nCo-Authored-By: Adam Gandelman <adamg@ubuntu.com>\nCo-Authored-By: Hans Lindgren <hanlind@kth.se>\nCo-Authored-By: Rohan Kanade <openstack@rohankanade.com>\nCo-Authored-By: Chris Krelle <nobodycam@gmail.com>\nCo-Authored-By: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nCo-Authored-By: Derek Higgins <derekh@redhat.com>\nCo-Authored-By: Kurt Taylor <krtaylor@us.ibm.com>\nCo-Authored-By: Chris Behrens <cbehrens@codestud.com>\nCo-Authored-By: Mikyung Kang <mkkang@isi.edu>\n\nChange-Id: I358d9c0485c5dcf81498871faa9150e3bf167c6b\n'}, {'number': 9, 'created': '2014-07-23 04:34:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/06990dbd21a40f2f61ca7f5a176bbdfdd9a2a9da', 'message': 'Import Ironic scheduler filters and host manager\n\nThis is an import of the Ironic scheduler changes as of\ncommit da967d77894be6f23d81fb5cc948f9d13898ba84\n\nimplements bp: add-ironic-driver\n\nCo-Authored-By: Michael Davies <michael@the-davies.net>\nCo-Authored-By: Adam Gandelman <adamg@ubuntu.com>\nCo-Authored-By: Hans Lindgren <hanlind@kth.se>\nCo-Authored-By: Rohan Kanade <openstack@rohankanade.com>\nCo-Authored-By: Chris Krelle <nobodycam@gmail.com>\nCo-Authored-By: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nCo-Authored-By: Derek Higgins <derekh@redhat.com>\nCo-Authored-By: Kurt Taylor <krtaylor@us.ibm.com>\nCo-Authored-By: Chris Behrens <cbehrens@codestud.com>\nCo-Authored-By: Mikyung Kang <mkkang@isi.edu>\n\nChange-Id: I358d9c0485c5dcf81498871faa9150e3bf167c6b\n'}, {'number': 10, 'created': '2014-07-23 18:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/450f60645bb6170d5aef350f1daf7cc280aaa5f9', 'message': 'Import Ironic scheduler filters and host manager\n\nThis is an import of the Ironic scheduler changes as of\ncommit da967d77894be6f23d81fb5cc948f9d13898ba84\n\nimplements bp: add-ironic-driver\n\nCo-authored-by: Adam Gandelman <adamg@ubuntu.com>\nCo-authored-by: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nCo-authored-by: Chris Behrens <cbehrens@codestud.com>\nCo-authored-by: Chris Krelle <nobodycam@gmail.com>\nCo-authored-by: Devananda van der Veen <devananda.vdv@gmail.com>\nCo-authored-by: Fengqian Gao <fengqian.gao@intel.com>\nCo-authored-by: Hans Lindgren <hanlind@kth.se>\nCo-authored-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nCo-authored-by: Michael Davies <michael@the-davies.net>\nCo-authored-by: Rohan Kanade <openstack@rohankanade.com>\nCo-authored-by: Zhongyue Luo <zhongyue.nah@intel.com>\n\n\nChange-Id: I358d9c0485c5dcf81498871faa9150e3bf167c6b\n'}, {'number': 11, 'created': '2014-07-24 05:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c132d855291240e170917aa8571d44227b41143', 'message': 'Import Ironic scheduler filters and host manager\n\nThis is an import of the Ironic scheduler changes as of\ncommit da967d77894be6f23d81fb5cc948f9d13898ba84\n\nimplements bp: add-ironic-driver\n\nChange-Id: I358d9c0485c5dcf81498871faa9150e3bf167c6b\n'}, {'number': 12, 'created': '2014-07-24 06:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/37f43fea2e7b98233c9a52d33f2ee8d999174488', 'message': 'Import Ironic scheduler filters and host manager\n\nThis is an import of the Ironic scheduler changes as of\ncommit da967d77894be6f23d81fb5cc948f9d13898ba84\n\nimplements bp: add-ironic-driver\n\nChange-Id: I358d9c0485c5dcf81498871faa9150e3bf167c6b\n'}, {'number': 13, 'created': '2014-07-24 22:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aa2c55d4c60b0d9433b502081439920e6659fbdd', 'message': 'Import Ironic scheduler filters and host manager\n\nThis is an import of the Ironic scheduler changes as of\ncommit da967d77894be6f23d81fb5cc948f9d13898ba84\n\nimplements bp: add-ironic-driver\n\nCo-authored-by: Adam Gandelman <adamg@ubuntu.com>\nCo-authored-by: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nCo-authored-by: Chris Behrens <cbehrens@codestud.com>\nCo-authored-by: Chris Krelle <nobodycam@gmail.com>\nCo-authored-by: Devananda van der Veen <devananda.vdv@gmail.com>\nCo-authored-by: Fengqian Gao <fengqian.gao@intel.com>\nCo-authored-by: Hans Lindgren <hanlind@kth.se>\nCo-authored-by: Jenkins <jenkins@review.openstack.org>\nCo-authored-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nCo-authored-by: Michael Davies <michael@the-davies.net>\nCo-authored-by: Rohan Kanade <openstack@rohankanade.com>\nCo-authored-by: Zhongyue Luo <zhongyue.nah@intel.com>\n\nChange-Id: I358d9c0485c5dcf81498871faa9150e3bf167c6b\n'}, {'number': 14, 'created': '2014-07-28 23:26:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8996837adbbceb3793ad3307400df3d6e9236fc', 'message': 'Import Ironic scheduler filters and host manager\n\nThis is an import of the Ironic scheduler changes as of\ncommit da967d77894be6f23d81fb5cc948f9d13898ba84\n\nimplements bp: add-ironic-driver\n\nCo-authored-by: Adam Gandelman <adamg@ubuntu.com>\nCo-authored-by: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nCo-authored-by: Chris Behrens <cbehrens@codestud.com>\nCo-authored-by: Chris Krelle <nobodycam@gmail.com>\nCo-authored-by: Devananda van der Veen <devananda.vdv@gmail.com>\nCo-authored-by: Fengqian Gao <fengqian.gao@intel.com>\nCo-authored-by: Hans Lindgren <hanlind@kth.se>\nCo-authored-by: Jenkins <jenkins@review.openstack.org>\nCo-authored-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nCo-authored-by: Michael Davies <michael@the-davies.net>\nCo-authored-by: Rohan Kanade <openstack@rohankanade.com>\nCo-authored-by: Zhongyue Luo <zhongyue.nah@intel.com>\n\nChange-Id: I358d9c0485c5dcf81498871faa9150e3bf167c6b\n'}, {'number': 15, 'created': '2014-08-01 09:49:48.000000000', 'files': ['nova/tests/scheduler/ironic_fakes.py', 'nova/scheduler/filters/exact_ram_filter.py', 'nova/scheduler/baremetal_host_manager.py', 'nova/scheduler/filters/exact_core_filter.py', 'nova/scheduler/ironic_host_manager.py', 'nova/scheduler/base_baremetal_host_manager.py', 'nova/tests/scheduler/test_ironic_host_manager.py', 'nova/scheduler/filters/exact_disk_filter.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/53c1794b59d8ae050241bbfe5a9a6bea63b87b4c', 'message': 'Import Ironic scheduler filters and host manager\n\nThis is an import of the Ironic scheduler changes as of\ncommit da967d77894be6f23d81fb5cc948f9d13898ba84\n\nimplements bp: add-ironic-driver\n\nCo-authored-by: Adam Gandelman <adamg@ubuntu.com>\nCo-authored-by: ChangBo Guo(gcb) <eric.guo@easystack.cn>\nCo-authored-by: Chris Behrens <cbehrens@codestud.com>\nCo-authored-by: Chris Krelle <nobodycam@gmail.com>\nCo-authored-by: Devananda van der Veen <devananda.vdv@gmail.com>\nCo-authored-by: Fengqian Gao <fengqian.gao@intel.com>\nCo-authored-by: Hans Lindgren <hanlind@kth.se>\nCo-authored-by: Jenkins <jenkins@review.openstack.org>\nCo-authored-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nCo-authored-by: Michael Davies <michael@the-davies.net>\nCo-authored-by: Rohan Kanade <openstack@rohankanade.com>\nCo-authored-by: Zhongyue Luo <zhongyue.nah@intel.com>\n\nChange-Id: I358d9c0485c5dcf81498871faa9150e3bf167c6b\n'}]",24,103165,53c1794b59d8ae050241bbfe5a9a6bea63b87b4c,125,14,15,2889,,,0,"Import Ironic scheduler filters and host manager

This is an import of the Ironic scheduler changes as of
commit da967d77894be6f23d81fb5cc948f9d13898ba84

implements bp: add-ironic-driver

Co-authored-by: Adam Gandelman <adamg@ubuntu.com>
Co-authored-by: ChangBo Guo(gcb) <eric.guo@easystack.cn>
Co-authored-by: Chris Behrens <cbehrens@codestud.com>
Co-authored-by: Chris Krelle <nobodycam@gmail.com>
Co-authored-by: Devananda van der Veen <devananda.vdv@gmail.com>
Co-authored-by: Fengqian Gao <fengqian.gao@intel.com>
Co-authored-by: Hans Lindgren <hanlind@kth.se>
Co-authored-by: Jenkins <jenkins@review.openstack.org>
Co-authored-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
Co-authored-by: Michael Davies <michael@the-davies.net>
Co-authored-by: Rohan Kanade <openstack@rohankanade.com>
Co-authored-by: Zhongyue Luo <zhongyue.nah@intel.com>

Change-Id: I358d9c0485c5dcf81498871faa9150e3bf167c6b
",git fetch https://review.opendev.org/openstack/nova refs/changes/65/103165/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/scheduler/ironic_fakes.py', 'nova/scheduler/filters/exact_core_filter.py', 'nova/scheduler/filters/exact_ram_filter.py', 'nova/scheduler/ironic_host_manager.py', 'nova/tests/scheduler/test_ironic_host_manager.py', 'nova/scheduler/filters/exact_disk_filter.py']",6,6a1474cf7c99d423f98d5e30f134bca63914f7e0,ironic-driver,"# Copyright (c) 2014 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from nova.openstack.common import log as logging from nova.scheduler import filters LOG = logging.getLogger(__name__) class ExactDiskFilter(filters.BaseHostFilter): """"""Exact Disk Filter."""""" def host_passes(self, host_state, filter_properties): """"""Filter based on disk usage."""""" instance_type = filter_properties.get('instance_type') requested_disk = (1024 * (instance_type['root_gb'] + instance_type['ephemeral_gb']) + instance_type['swap']) if requested_disk != host_state.free_disk_mb: LOG.debug(""%(host_state)s does not have %(requested_disk)s MB "" ""usable disk, it only has %(usable_disk_mb)s MB usable "" ""disk."", {'host_state': host_state, 'requested_disk': requested_disk, 'usable_disk_mb': host_state.free_disk_mb}) return False return True ",,724,0
openstack%2Fneutron~master~I00a3f178a3b48f5c209ddf52b93cb9bfcb364934,openstack/neutron,master,I00a3f178a3b48f5c209ddf52b93cb9bfcb364934,remove unneed config option slave_connection,ABANDONED,2014-08-07 23:44:21.000000000,2014-08-08 06:15:30.000000000,,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9751}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}]","[{'number': 1, 'created': '2014-08-07 23:44:21.000000000', 'files': ['etc/neutron.conf'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d02f7ebe28e4ccaed51124ff3a39baeba14b1f4f', 'message': ""remove unneed config option slave_connection\n\nIn trying to chance down an issue I noticed we don't actually use\nslave_connection anywhere in the code so we could remove this.\n\nChange-Id: I00a3f178a3b48f5c209ddf52b93cb9bfcb364934\n""}]",0,112729,d02f7ebe28e4ccaed51124ff3a39baeba14b1f4f,20,15,1,4395,,,0,"remove unneed config option slave_connection

In trying to chance down an issue I noticed we don't actually use
slave_connection anywhere in the code so we could remove this.

Change-Id: I00a3f178a3b48f5c209ddf52b93cb9bfcb364934
",git fetch https://review.opendev.org/openstack/neutron refs/changes/29/112729/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/neutron.conf'],1,d02f7ebe28e4ccaed51124ff3a39baeba14b1f4f,,,# The SQLAlchemy connection string used to connect to the slave database # slave_connection = ,0,3
openstack%2Fneutron~master~I1a703b327e6c569dfaa8263a222e4bc797e5dbfd,openstack/neutron,master,I1a703b327e6c569dfaa8263a222e4bc797e5dbfd,Improve external gateway update handling,MERGED,2014-07-25 23:28:41.000000000,2014-08-08 05:48:34.000000000,2014-08-08 05:48:33.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6695}, {'_account_id': 6854}, {'_account_id': 6876}, {'_account_id': 7448}, {'_account_id': 8873}, {'_account_id': 9077}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10971}]","[{'number': 1, 'created': '2014-07-25 23:28:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a5c5e7281e6db9cdeec57e9b7d842c8d38581cea', 'message': ""Instead of Ports, compare port ids when checking external gateway changed\n\nOnce gateway is set, external_gateway_added() was getting called every time\n a router update was received. The check for change in external\ngateway compared previously cached copy of gateway port (ri.ex_gw_port) with\n the one passed in through update router (ri.router['gw_port']).\nThe cached copy was already being modified by code so the two values would\nalways appear to be different.\nMaking the change to compare the 'id' field only instead.\n\nChange-Id: I1a703b327e6c569dfaa8263a222e4bc797e5dbfd\nCloses-Bug: 1348737\n""}, {'number': 2, 'created': '2014-07-26 01:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5144ea4fe7f8aadaec72ffa499413c9478745a76', 'message': ""Compare port ids for external gateway changed\n\nOnce gateway is set, external_gateway_added() was getting called every time\n a router update was received. The check for change in external\ngateway compared previously cached copy of gateway port (ri.ex_gw_port) with\n the one passed in through update router (ri.router['gw_port']).\nThe cached copy was already being modified by code so the two values would\nalways appear to be different.\nMaking the change to compare the 'id' field only instead.\n\nChange-Id: I1a703b327e6c569dfaa8263a222e4bc797e5dbfd\nCloses-Bug: 1348737\n""}, {'number': 3, 'created': '2014-08-01 20:01:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/242934bec4736e4db31963822631b0ab79c45efb', 'message': ""Improve external gateway update handling\n\nOnce gateway is set, external_gateway_added() was getting called every time\n a router update was received. The check for change in external\ngateway compared previously cached copy of gateway port (ri.ex_gw_port) with\n the one passed in through update router (ri.router['gw_port']).\nThe cached copy was already being modified by code so the two values would\nalways appear to be different.\nMaking the change to compare correctly and remove actions not required\nfor gateway update.\n\nChange-Id: I1a703b327e6c569dfaa8263a222e4bc797e5dbfd\nCloses-Bug: 1348737\n""}, {'number': 4, 'created': '2014-08-01 21:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4bf3bf0c587a8e496dd0524db4bf947cdafdf693', 'message': ""Improve external gateway update handling\n\nOnce gateway is set, external_gateway_added() was getting called every time\n a router update was received. The check for change in external\ngateway compared previously cached copy of gateway port (ri.ex_gw_port) with\n the one passed in through update router (ri.router['gw_port']).\nThe cached copy was already being modified by code so the two values would\nalways appear to be different.\nMaking the change to compare correctly and remove actions not required\nfor gateway update.\n\nChange-Id: I1a703b327e6c569dfaa8263a222e4bc797e5dbfd\nCloses-Bug: 1348737\n""}, {'number': 5, 'created': '2014-08-04 19:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/48fec2d6bfd1abc62d3697d43a63f6f00e5d88a1', 'message': ""Improve external gateway update handling\n\nOnce gateway is set, external_gateway_added() was getting called every time\n a router update was received. The check for change in external\ngateway compared previously cached copy of gateway port (ri.ex_gw_port) with\n the one passed in through update router (ri.router['gw_port']).\nThe cached copy was already being modified by code so the two values would\nalways appear to be different.\nMaking the change to compare correctly and remove actions not required\nfor gateway update.\n\nChange-Id: I1a703b327e6c569dfaa8263a222e4bc797e5dbfd\nCloses-Bug: 1348737\n""}, {'number': 6, 'created': '2014-08-06 19:41:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3d48df1a789409db59296c177b4ecaab87096d32', 'message': ""Improve external gateway update handling\n\nOnce gateway is set, external_gateway_added() was getting called every time\n a router update was received. The check for change in external\ngateway compared previously cached copy of gateway port (ri.ex_gw_port) with\n the one passed in through update router (ri.router['gw_port']).\nThe cached copy was already being modified by code so the two values would\nalways appear to be different.\nMaking the change to compare correctly and remove actions not required\nfor gateway update.\n\nChange-Id: I1a703b327e6c569dfaa8263a222e4bc797e5dbfd\nCloses-Bug: 1348737\n""}, {'number': 7, 'created': '2014-08-07 17:07:42.000000000', 'files': ['neutron/agent/l3_agent.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/596908f8a8aecff06b079147b957c7da3dc7a51b', 'message': ""Improve external gateway update handling\n\nOnce gateway is set, external_gateway_added() was getting called every time\n a router update was received. The check for change in external\ngateway compared previously cached copy of gateway port (ri.ex_gw_port) with\n the one passed in through update router (ri.router['gw_port']).\nThe cached copy was already being modified by code so the two values would\nalways appear to be different.\nMaking the change to compare correctly and remove actions not required\nfor gateway update.\n\nChange-Id: I1a703b327e6c569dfaa8263a222e4bc797e5dbfd\nCloses-Bug: 1348737\n""}]",18,109776,596908f8a8aecff06b079147b957c7da3dc7a51b,149,27,7,9077,,,0,"Improve external gateway update handling

Once gateway is set, external_gateway_added() was getting called every time
 a router update was received. The check for change in external
gateway compared previously cached copy of gateway port (ri.ex_gw_port) with
 the one passed in through update router (ri.router['gw_port']).
The cached copy was already being modified by code so the two values would
always appear to be different.
Making the change to compare correctly and remove actions not required
for gateway update.

Change-Id: I1a703b327e6c569dfaa8263a222e4bc797e5dbfd
Closes-Bug: 1348737
",git fetch https://review.opendev.org/openstack/neutron refs/changes/76/109776/5 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3_agent.py'],1,a5c5e7281e6db9cdeec57e9b7d842c8d38581cea,bug/1348737, # gateway port has been added or changed if (ex_gw_port and (not ri.ex_gw_port or ex_gw_port['id'] != ri.ex_gw_port['id'])):, if ex_gw_port and ex_gw_port != ri.ex_gw_port:,3,1
openstack%2Fpython-keystoneclient~master~I30930f16425f1825373184371f3cba995833bc22,openstack/python-keystoneclient,master,I30930f16425f1825373184371f3cba995833bc22,Mark the keystoneclient s3_token middleware deprecated,MERGED,2014-08-04 22:04:33.000000000,2014-08-08 05:23:58.000000000,2014-08-08 05:23:57.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 7191}]","[{'number': 1, 'created': '2014-08-04 22:04:33.000000000', 'files': ['keystoneclient/middleware/s3_token.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/492bd3594796f28c85bddc2dc95174c6a4a015ad', 'message': 'Mark the keystoneclient s3_token middleware deprecated\n\nThe s3_token middleware in python-keystoneclient is deprecated in\nfavor of keystonemiddleware.s3_token.\n\nChange-Id: I30930f16425f1825373184371f3cba995833bc22\n'}]",0,111847,492bd3594796f28c85bddc2dc95174c6a4a015ad,11,3,1,2903,,,0,"Mark the keystoneclient s3_token middleware deprecated

The s3_token middleware in python-keystoneclient is deprecated in
favor of keystonemiddleware.s3_token.

Change-Id: I30930f16425f1825373184371f3cba995833bc22
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/47/111847/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/middleware/s3_token.py'],1,492bd3594796f28c85bddc2dc95174c6a4a015ad,, self.logger.warning( 'This middleware module is deprecated as of v0.11.0 in favor of ' 'keystonemiddleware.s3_token - please update your WSGI pipeline ' 'to reference the new middleware package.'),,4,0
openstack%2Fcookbook-openstack-block-storage~master~I102d27e693dc1fd1493e8cca078273994739bfaa,openstack/cookbook-openstack-block-storage,master,I102d27e693dc1fd1493e8cca078273994739bfaa,"Change gpfs driver path from cinder.volume.drivers.gpfs.GPFSDriver to cinder.volume.drivers.ibm.gpfs.GPFSDriver.This Driver is defined in https://github.com/openstack/cinder/blob/master/cinder/volume/drivers/ibm/gpfs.py In order to keep compatibility with older path,I just add new GPFSDriver path for it.Also add new testcase for new path. Change-Id: I102d27e693dc1fd1493e8cca078273994739bfaa",ABANDONED,2014-08-04 10:43:49.000000000,2014-08-08 05:21:48.000000000,,"[{'_account_id': 3}, {'_account_id': 7128}, {'_account_id': 8410}, {'_account_id': 8666}]","[{'number': 1, 'created': '2014-08-04 10:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/6e80dc0ac2acaf5be34c1c913268a4b7a3ab71c4', 'message': 'Change gpfs driver path from cinder.volume.drivers.gpfs.GPFSDriver to\ncinder.volume.drivers.ibm.gpfs.GPFSDriver.This Driver is defined in https://github.com/openstack/cinder/blob/master/cinder/volume/drivers/ibm/gpfs.py\nIn order to keep compatibility with older path,I just add new GPFSDriver path for it.\n\nChange-Id: I102d27e693dc1fd1493e8cca078273994739bfaa\n'}, {'number': 2, 'created': '2014-08-05 03:32:29.000000000', 'files': ['recipes/volume.rb', 'spec/volume-redhat_spec.rb', 'spec/cinder_common_spec.rb', 'templates/default/cinder.conf.erb', 'CHANGELOG.md', 'README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/d7bcf7a708b8c6b9f7d1b7570a16838b84e3d079', 'message': 'Change gpfs driver path from cinder.volume.drivers.gpfs.GPFSDriver to\ncinder.volume.drivers.ibm.gpfs.GPFSDriver.This Driver is defined in https://github.com/openstack/cinder/blob/master/cinder/volume/drivers/ibm/gpfs.py\nIn order to keep compatibility with older path,I just add new GPFSDriver path for it.Also add new testcase for new path.\nChange-Id: I102d27e693dc1fd1493e8cca078273994739bfaa\n'}]",3,111683,d7bcf7a708b8c6b9f7d1b7570a16838b84e3d079,14,4,2,8666,,,0,"Change gpfs driver path from cinder.volume.drivers.gpfs.GPFSDriver to
cinder.volume.drivers.ibm.gpfs.GPFSDriver.This Driver is defined in https://github.com/openstack/cinder/blob/master/cinder/volume/drivers/ibm/gpfs.py
In order to keep compatibility with older path,I just add new GPFSDriver path for it.Also add new testcase for new path.
Change-Id: I102d27e693dc1fd1493e8cca078273994739bfaa
",git fetch https://review.opendev.org/openstack/cookbook-openstack-block-storage refs/changes/83/111683/1 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/volume.rb', 'spec/volume-redhat_spec.rb', 'spec/cinder_common_spec.rb', 'templates/default/cinder.conf.erb', 'CHANGELOG.md', 'README.md']",6,6e80dc0ac2acaf5be34c1c913268a4b7a3ab71c4,bug/1347447, - **cinder.volume.drivers.ibm.gpfs.GPFSDriver** - IBM General Parallel File System driver, - **cinder.volume.drivers.gpfs.GPFSDriver** - IBM General Parallel File System driver,58,6
openstack%2Fcinder~master~Iaa82eb7c1e1bdbb4d4a638c185d50bc15e32e975,openstack/cinder,master,Iaa82eb7c1e1bdbb4d4a638c185d50bc15e32e975,Add log output of x-openstack-request-id from nova,ABANDONED,2014-06-16 02:21:51.000000000,2014-08-08 05:15:04.000000000,,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 7198}, {'_account_id': 7219}, {'_account_id': 7634}, {'_account_id': 8871}, {'_account_id': 9533}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-16 02:21:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6a00e261b8f2723478904c47b19f1f05d731f9e1', 'message': ""Add log output of x-openstack-request-id from nova\n\nThis patch enables cinder to output\n'x-openstack-request-id'/'x-compute-request-id'\nof nova's responses to the log.\n\nChange-Id: Iaa82eb7c1e1bdbb4d4a638c185d50bc15e32e975\nCloses-bug: #1324376\n""}, {'number': 2, 'created': '2014-06-17 11:08:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8b68d167b2cde23351ad42b8a0b9b0cb3d27b158', 'message': ""Add log output of x-openstack-request-id from nova\n\nThis patch enables cinder to output\n'x-openstack-request-id'/'x-compute-request-id'\nof nova's responses to the log.\n\nDocImpact: There is a new configuration option\n'nova_log_debug' in cinder.compute.nova\n\nChange-Id: Iaa82eb7c1e1bdbb4d4a638c185d50bc15e32e975\nCloses-bug: #1324376\n""}, {'number': 3, 'created': '2014-06-17 11:25:46.000000000', 'files': ['etc/cinder/cinder.conf.sample', 'cinder/compute/nova.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/55319da41a186436e8f5ee603ab07cdf4a5a6e6d', 'message': ""Add log output of x-openstack-request-id from nova\n\nThis patch enables cinder to output\n'x-openstack-request-id'/'x-compute-request-id'\nof nova's responses to the log.\nAnd it also enables cinder to output\nrequest headers, request parameters,\nother response headers and a response body to\nthe log when cinder calls nova.\n\nDocImpact: There is a new configuration option\n'nova_log_debug' in cinder.compute.nova\n\nChange-Id: Iaa82eb7c1e1bdbb4d4a638c185d50bc15e32e975\nCloses-bug: #1324376\n""}]",0,100126,55319da41a186436e8f5ee603ab07cdf4a5a6e6d,29,9,3,7634,,,0,"Add log output of x-openstack-request-id from nova

This patch enables cinder to output
'x-openstack-request-id'/'x-compute-request-id'
of nova's responses to the log.
And it also enables cinder to output
request headers, request parameters,
other response headers and a response body to
the log when cinder calls nova.

DocImpact: There is a new configuration option
'nova_log_debug' in cinder.compute.nova

Change-Id: Iaa82eb7c1e1bdbb4d4a638c185d50bc15e32e975
Closes-bug: #1324376
",git fetch https://review.opendev.org/openstack/cinder refs/changes/26/100126/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cinder/cinder.conf.sample', 'cinder/compute/nova.py']",2,6a00e261b8f2723478904c47b19f1f05d731f9e1,bug/1324376," cfg.BoolOpt('nova_http_log_debug', default=False, help='Allow novaclient\'s debug log output.'), http_log_debug=CONF.nova_http_log_debug,",,7,0
openstack%2Fcinder~master~Ib7edaefa5eceb8e8c01ec0ce0dcdada7eaa9dd08,openstack/cinder,master,Ib7edaefa5eceb8e8c01ec0ce0dcdada7eaa9dd08,EMC VNX Direct Driver Update for Juno,MERGED,2014-07-03 02:00:34.000000000,2014-08-08 05:10:56.000000000,2014-08-07 08:51:51.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 5997}, {'_account_id': 6094}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 8716}, {'_account_id': 9533}, {'_account_id': 9751}, {'_account_id': 9924}, {'_account_id': 10621}, {'_account_id': 10628}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}]","[{'number': 1, 'created': '2014-07-03 02:00:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d87fd96d466924438d4ab02c5aced986308ad9aa', 'message': 'EMC VNX Direct Driver Update for Juno\n\nVNX Direct Driver has been contributed to Icehouse release.\nThis patch refactors driver and adds the following new features\n\n* Array-based Backend Support\n* FC Basic Support\n* Target Port Selection for MPIO\n* Initiator Auto Registration\n* Storage Group Auto Deletion\n* Multiple Authentication Type Support\n* Storage-Assisted Volume Migration\n* SP Toggle for HA\n* Security File Support\n* Advance LUN Features\n    # Compression Support\n    # Deduplication Support\n    # FAST VP Support\n    # FAST Cache Support\n* Storage-assisted Retype\n* External Volume Management\n* Read-only Volume\n* FC Auto Zoning\n\nCertificate Test Results\n    https://bugs.launchpad.net/cinder/+bug/1336640\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: Ib7edaefa5eceb8e8c01ec0ce0dcdada7eaa9dd08\nImplements: blueprint emc-vnx-direct-driver-juno-update\n'}, {'number': 2, 'created': '2014-07-03 11:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/88ce9e9be4989767c9c7533ee0c3e25b3705e389', 'message': 'EMC VNX Direct Driver Update for Juno\n\nVNX Direct Driver has been contributed to Icehouse release.\nThis patch refactors driver and adds the following new features\n\n* Array-based Backend Support\n* FC Basic Support\n* Target Port Selection for MPIO\n* Initiator Auto Registration\n* Storage Group Auto Deletion\n* Multiple Authentication Type Support\n* Storage-Assisted Volume Migration\n* SP Toggle for HA\n* Security File Support\n* Advance LUN Features\n    # Compression Support\n    # Deduplication Support\n    # FAST VP Support\n    # FAST Cache Support\n* Storage-assisted Retype\n* External Volume Management\n* Read-only Volume\n* FC Auto Zoning\n\nCertificate Test Results\n    https://bugs.launchpad.net/cinder/+bug/1336640\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: Ib7edaefa5eceb8e8c01ec0ce0dcdada7eaa9dd08\nImplements: blueprint emc-vnx-direct-driver-juno-update\n'}, {'number': 3, 'created': '2014-07-17 14:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/645dd028a7313168f47c61c60a6257c9a1d419d9', 'message': 'EMC VNX Direct Driver Update for Juno\n\nVNX Direct Driver has been contributed to Icehouse release.\nThis patch refactors driver and adds the following new features\n\n* Array-based Backend Support\n* FC Basic Support\n* Target Port Selection for MPIO\n* Initiator Auto Registration\n* Storage Group Auto Deletion\n* Multiple Authentication Type Support\n* Storage-Assisted Volume Migration\n* SP Toggle for HA\n* Security File Support\n* Advance LUN Features\n    # Compression Support\n    # Deduplication Support\n    # FAST VP Support\n    # FAST Cache Support\n* Storage-assisted Retype\n* External Volume Management\n* Read-only Volume\n* FC Auto Zoning\n\nCertificate Test Results\n    https://bugs.launchpad.net/cinder/+bug/1336640\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: Ib7edaefa5eceb8e8c01ec0ce0dcdada7eaa9dd08\nImplements: blueprint emc-vnx-direct-driver-juno-update\n'}, {'number': 4, 'created': '2014-07-21 12:41:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/22a6c8f6bfd4cc43382a15b27ebf04e172f37a0f', 'message': 'EMC VNX Direct Driver Update for Juno\n\nVNX Direct Driver has been contributed to Icehouse release.\nThis patch refactors driver and adds the following new features\n\n* Array-based Backend Support\n* FC Basic Support\n* Target Port Selection for MPIO\n* Initiator Auto Registration\n* Storage Group Auto Deletion\n* Multiple Authentication Type Support\n* Storage-Assisted Volume Migration\n* SP Toggle for HA\n* Security File Support\n* Advance LUN Features\n    # Compression Support\n    # Deduplication Support\n    # FAST VP Support\n    # FAST Cache Support\n* Storage-assisted Retype\n* External Volume Management\n* Read-only Volume\n* FC Auto Zoning\n\nCertificate Test Results\n    https://bugs.launchpad.net/cinder/+bug/1336640\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: Ib7edaefa5eceb8e8c01ec0ce0dcdada7eaa9dd08\nImplements: blueprint emc-vnx-direct-driver-juno-update\n'}, {'number': 5, 'created': '2014-07-22 04:55:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/26fe7f62761baa823bd1d743aca058f3db0c4ce5', 'message': 'EMC VNX Direct Driver Update for Juno\n\nVNX Direct Driver has been contributed to Icehouse release.\nThis patch refactors driver and adds the following new features\n\n* Array-based Backend Support\n* FC Basic Support\n* Target Port Selection for MPIO\n* Initiator Auto Registration\n* Storage Group Auto Deletion\n* Multiple Authentication Type Support\n* Storage-Assisted Volume Migration\n* SP Toggle for HA\n* Security File Support\n* Advance LUN Features\n    # Compression Support\n    # Deduplication Support\n    # FAST VP Support\n    # FAST Cache Support\n* Storage-assisted Retype\n* External Volume Management\n* Read-only Volume\n* FC Auto Zoning\n\nCertificate Test Results\n    https://bugs.launchpad.net/cinder/+bug/1336640\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: Ib7edaefa5eceb8e8c01ec0ce0dcdada7eaa9dd08\nImplements: blueprint emc-vnx-direct-driver-juno-update\n'}, {'number': 6, 'created': '2014-07-22 11:53:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d009b698324604033a4ed4790ccd3bb98311d3b4', 'message': 'EMC VNX Direct Driver Update for Juno\n\nVNX Direct Driver has been contributed to Icehouse release.\nThis patch refactors driver and adds the following new features\n\n* Array-based Backend Support\n* FC Basic Support\n* Target Port Selection for MPIO\n* Initiator Auto Registration\n* Storage Group Auto Deletion\n* Multiple Authentication Type Support\n* Storage-Assisted Volume Migration\n* SP Toggle for HA\n* Security File Support\n* Advance LUN Features\n    # Compression Support\n    # Deduplication Support\n    # FAST VP Support\n    # FAST Cache Support\n* Storage-assisted Retype\n* External Volume Management\n* Read-only Volume\n* FC Auto Zoning\n\nCertificate Test Results\n    https://bugs.launchpad.net/cinder/+bug/1336640\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: Ib7edaefa5eceb8e8c01ec0ce0dcdada7eaa9dd08\nImplements: blueprint emc-vnx-direct-driver-juno-update\n'}, {'number': 7, 'created': '2014-07-24 02:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f60837e85157479faf99823436ed45c84adeb486', 'message': 'EMC VNX Direct Driver Update for Juno\n\nVNX Direct Driver has been contributed to Icehouse release.\nThis patch refactors driver and adds the following new features\n\n* Array-based Backend Support\n* FC Basic Support\n* Target Port Selection for MPIO\n* Initiator Auto Registration\n* Storage Group Auto Deletion\n* Multiple Authentication Type Support\n* Storage-Assisted Volume Migration\n* SP Toggle for HA\n* Security File Support\n* Advance LUN Features\n    # Compression Support\n    # Deduplication Support\n    # FAST VP Support\n    # FAST Cache Support\n* Storage-assisted Retype\n* External Volume Management\n* Read-only Volume\n* FC Auto Zoning\n\nCertificate Test Results\n    https://bugs.launchpad.net/cinder/+bug/1336640\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: Ib7edaefa5eceb8e8c01ec0ce0dcdada7eaa9dd08\nImplements: blueprint emc-vnx-direct-driver-juno-update\n'}, {'number': 8, 'created': '2014-07-24 03:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/68b561968ed96f16da68c83ebc48b63716b7422f', 'message': 'EMC VNX Direct Driver Update for Juno\n\nVNX Direct Driver has been contributed to Icehouse release.\nThis patch refactors driver and adds the following new features\n\n* Array-based Backend Support\n* FC Basic Support\n* Target Port Selection for MPIO\n* Initiator Auto Registration\n* Storage Group Auto Deletion\n* Multiple Authentication Type Support\n* Storage-Assisted Volume Migration\n* SP Toggle for HA\n* Security File Support\n* Advance LUN Features\n    # Compression Support\n    # Deduplication Support\n    # FAST VP Support\n    # FAST Cache Support\n* Storage-assisted Retype\n* External Volume Management\n* Read-only Volume\n* FC Auto Zoning\n\nCertificate Test Results\n    https://bugs.launchpad.net/cinder/+bug/1336640\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: Ib7edaefa5eceb8e8c01ec0ce0dcdada7eaa9dd08\nImplements: blueprint emc-vnx-direct-driver-juno-update\n'}, {'number': 9, 'created': '2014-07-24 04:57:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a96c13d9faf7cd1e419f3b581aff7c1adce0afa3', 'message': 'EMC VNX Direct Driver Update for Juno\n\nVNX Direct Driver has been contributed to Icehouse release.\nThis patch refactors driver and adds the following new features\n\n* Array-based Backend Support\n* FC Basic Support\n* Target Port Selection for MPIO\n* Initiator Auto Registration\n* Storage Group Auto Deletion\n* Multiple Authentication Type Support\n* Storage-Assisted Volume Migration\n* SP Toggle for HA\n* Security File Support\n* Advance LUN Features\n    # Compression Support\n    # Deduplication Support\n    # FAST VP Support\n    # FAST Cache Support\n* Storage-assisted Retype\n* External Volume Management\n* Read-only Volume\n* FC Auto Zoning\n\nCertificate Test Results\n    https://bugs.launchpad.net/cinder/+bug/1336640\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: Ib7edaefa5eceb8e8c01ec0ce0dcdada7eaa9dd08\nImplements: blueprint emc-vnx-direct-driver-juno-update\n'}, {'number': 10, 'created': '2014-07-24 12:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/199ea32b0a0c1282c5b5278bd6a89e67b1e03fed', 'message': 'EMC VNX Direct Driver Update for Juno\n\nVNX Direct Driver has been contributed to Icehouse release.\nThis patch refactors driver and adds the following new features\n\n* Array-based Backend Support\n* FC Basic Support\n* Target Port Selection for MPIO\n* Initiator Auto Registration\n* Storage Group Auto Deletion\n* Multiple Authentication Type Support\n* Storage-Assisted Volume Migration\n* SP Toggle for HA\n* Security File Support\n* Advance LUN Features\n    # Compression Support\n    # Deduplication Support\n    # FAST VP Support\n    # FAST Cache Support\n* Storage-assisted Retype\n* External Volume Management\n* Read-only Volume\n* FC Auto Zoning\n\nCertificate Test Results\n    https://bugs.launchpad.net/cinder/+bug/1336640\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: Ib7edaefa5eceb8e8c01ec0ce0dcdada7eaa9dd08\nImplements: blueprint emc-vnx-direct-driver-juno-update\n'}, {'number': 11, 'created': '2014-07-25 08:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e3af74874d116a324217ee697eb28cf2a4b08b90', 'message': 'EMC VNX Direct Driver Update for Juno\n\nVNX Direct Driver has been contributed to Icehouse release.\nThis patch refactors driver and adds the following new features\n\n* Array-based Backend Support\n* FC Basic Support\n* Target Port Selection for MPIO\n* Initiator Auto Registration\n* Storage Group Auto Deletion\n* Multiple Authentication Type Support\n* Storage-Assisted Volume Migration\n* SP Toggle for HA\n* Security File Support\n* Advance LUN Features\n    # Compression Support\n    # Deduplication Support\n    # FAST VP Support\n    # FAST Cache Support\n* Storage-assisted Retype\n* External Volume Management\n* Read-only Volume\n* FC Auto Zoning\n\nCertificate Test Results\n    https://bugs.launchpad.net/cinder/+bug/1336640\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: Ib7edaefa5eceb8e8c01ec0ce0dcdada7eaa9dd08\nImplements: blueprint emc-vnx-direct-driver-juno-update\n'}, {'number': 12, 'created': '2014-07-28 05:14:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8720a31828ce23cee216e6ed6dcc7b665b48422f', 'message': 'EMC VNX Direct Driver Update for Juno\n\nVNX Direct Driver has been contributed to Icehouse release.\nThis patch refactors driver and adds the following new features\n\n* Array-based Backend Support\n* FC Basic Support\n* Target Port Selection for MPIO\n* Initiator Auto Registration\n* Storage Group Auto Deletion\n* Multiple Authentication Type Support\n* Storage-Assisted Volume Migration\n* SP Toggle for HA\n* Security File Support\n* Advance LUN Features\n    # Compression Support\n    # Deduplication Support\n    # FAST VP Support\n    # FAST Cache Support\n* Storage-assisted Retype\n* External Volume Management\n* Read-only Volume\n* FC Auto Zoning\n\nCertificate Test Results\n    https://bugs.launchpad.net/cinder/+bug/1336640\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: Ib7edaefa5eceb8e8c01ec0ce0dcdada7eaa9dd08\nImplements: blueprint emc-vnx-direct-driver-juno-update\n'}, {'number': 13, 'created': '2014-07-30 06:11:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/900394f973a1e3eeb0fbb983afc43595f6c67b32', 'message': 'EMC VNX Direct Driver Update for Juno\n\nVNX Direct Driver has been contributed to Icehouse release.\nThis patch refactors driver and adds the following new features\n\n* Array-based Backend Support\n* FC Basic Support\n* Target Port Selection for MPIO\n* Initiator Auto Registration\n* Storage Group Auto Deletion\n* Multiple Authentication Type Support\n* Storage-Assisted Volume Migration\n* SP Toggle for HA\n* Security File Support\n* Advance LUN Features\n    # Compression Support\n    # Deduplication Support\n    # FAST VP Support\n    # FAST Cache Support\n* Storage-assisted Retype\n* External Volume Management\n* Read-only Volume\n* FC Auto Zoning\n\nCertificate Test Results\n    https://bugs.launchpad.net/cinder/+bug/1336640\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: Ib7edaefa5eceb8e8c01ec0ce0dcdada7eaa9dd08\nImplements: blueprint emc-vnx-direct-driver-juno-update\n'}, {'number': 14, 'created': '2014-07-30 06:36:29.000000000', 'files': ['etc/cinder/cinder.conf.sample', 'cinder/tests/test_emc_vnxdirect.py', 'cinder/exception.py', 'cinder/volume/drivers/emc/emc_cli_iscsi.py', 'cinder/volume/drivers/emc/emc_cli_fc.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b9d0ac21d87a294b2e23d880c359c56ebee9940b', 'message': 'EMC VNX Direct Driver Update for Juno\n\nVNX Direct Driver has been contributed to Icehouse release.\nThis patch refactors driver and adds the following new features\n\n* Array-based Backend Support\n* FC Basic Support\n* Target Port Selection for MPIO\n* Initiator Auto Registration\n* Storage Group Auto Deletion\n* Multiple Authentication Type Support\n* Storage-Assisted Volume Migration\n* SP Toggle for HA\n* Security File Support\n* Advance LUN Features\n    # Compression Support\n    # Deduplication Support\n    # FAST VP Support\n    # FAST Cache Support\n* Storage-assisted Retype\n* External Volume Management\n* Read-only Volume\n* FC Auto Zoning\n\nCertificate Test Results\n    https://bugs.launchpad.net/cinder/+bug/1336640\n\nCCLA SCHEDULE B SUBMISSION\n\nChange-Id: Ib7edaefa5eceb8e8c01ec0ce0dcdada7eaa9dd08\nImplements: blueprint emc-vnx-direct-driver-juno-update\n'}]",208,104413,b9d0ac21d87a294b2e23d880c359c56ebee9940b,178,16,14,9924,,,0,"EMC VNX Direct Driver Update for Juno

VNX Direct Driver has been contributed to Icehouse release.
This patch refactors driver and adds the following new features

* Array-based Backend Support
* FC Basic Support
* Target Port Selection for MPIO
* Initiator Auto Registration
* Storage Group Auto Deletion
* Multiple Authentication Type Support
* Storage-Assisted Volume Migration
* SP Toggle for HA
* Security File Support
* Advance LUN Features
    # Compression Support
    # Deduplication Support
    # FAST VP Support
    # FAST Cache Support
* Storage-assisted Retype
* External Volume Management
* Read-only Volume
* FC Auto Zoning

Certificate Test Results
    https://bugs.launchpad.net/cinder/+bug/1336640

CCLA SCHEDULE B SUBMISSION

Change-Id: Ib7edaefa5eceb8e8c01ec0ce0dcdada7eaa9dd08
Implements: blueprint emc-vnx-direct-driver-juno-update
",git fetch https://review.opendev.org/openstack/cinder refs/changes/13/104413/3 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cinder/cinder.conf.sample', 'cinder/tests/test_emc_vnxdirect.py', 'cinder/volume/drivers/emc/emc_cli_iscsi.py', 'cinder/volume/drivers/emc/emc_cli_fc.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py']",5,d87fd96d466924438d4ab02c5aced986308ad9aa,bp/emc-vnx-direct-driver-juno-update,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at# http://www.apache.org/licenses/LICENSE-2.0# Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License.VNX CLIimport re import sysimport random try: import json except ImportError: import simplejson as json try: from cinder.openstack.common.gettextutils import _LE from cinder.openstack.common.gettextutils import _LI from cinder.openstack.common.gettextutils import _LW except ImportError: _LE = _ _LI = _ _LW = _ from cinder.openstack.common import lockutilsfrom cinder.openstack.common import timeutilsVERSION = '03.01.00'LOG = logging.getLogger(__name__) INTERVAL_1_SEC = 1 INTERVAL_5_SEC = 5 INTERVAL_10_SEC = 10 INTERVAL_30_SEC = 30 INTERVAL_60_SEC = 60 NO_POLL = True cfg.StrOpt('storage_vnx_authentication_type', default='global', help='VNX authentication scope type'), cfg.StrOpt('storage_vnx_security_file_dir', default=None, help='Directory path that contains the VNX security file.' ' Make sure the security file is generated first'), help='Storage pool name'), cfg.StrOpt('san_secondary_ip', default=None, help='VNX secondary SP IP Address'), default=sys.maxint, help='Default Time Out For CLI operations. ' 'By default it will never timeout'), default=255, help='Default max number of LUNs in a storage group.' ' By default, the value is 255'), cfg.BoolOpt('destroy_empty_storage_group', default=False, help='To destroy storage group ' 'when the last LUN is removed from it. ' 'By default, the value is False'), cfg.StrOpt('iscsi_initiators', default='', help='Mapping between hostname and ' 'its iSCSI initiator IP addresses'), cfg.BoolOpt('initiator_auto_registration', default=False, help='Automatically register initiators'), ]def log_enter_exit(func): def inner(self, *args, **kwargs): LOG.debug(""Entering %(cls)s.%(method)s"" % {'cls': self.__class__.__name__, 'method': func.__name__}) start = timeutils.utcnow() ret = func(self, *args, **kwargs) end = timeutils.utcnow() LOG.debug(""Exiting %(cls)s.%(method)s. "" ""Spent %(duration)s sec. "" ""Return %(return)s"" % {'cls': self.__class__.__name__, 'duration': timeutils.delta_seconds(start, end), 'method': func.__name__, 'return': ret}) return ret return inner class EMCVnxCLICmdError(exception.VolumeBackendAPIException): def __init__(self, cmd, rc, out, log_as_error=True, **kwargs): self.cmd = cmd self.rc = rc self.out = out msg = _(""EMCVnxCLICmdError : %(cmd)s "" ""(Return Code: %(rc)s) "" ""(Output: %(out)s) "") % \ {'cmd': cmd, 'rc': rc, 'out': out.split('\n')} kwargs[""data""] = msg super(EMCVnxCLICmdError, self).__init__(**kwargs) if log_as_error: LOG.error(msg) else: LOG.warn(msg) class PropertyDescriptor(object): def __init__(self, option, label, key, converter=None): self.option = option self.label = label self.key = key self.converter = converter class CommandLineHelper(object): LUN_STATE = PropertyDescriptor( '-state', 'Current State:\s*(.*)\s*', 'state') LUN_STATUS = PropertyDescriptor( '-status', 'Status:\s*(.*)\s*', 'status') LUN_OPERATION = PropertyDescriptor( '-opDetails', 'Current Operation:\s*(.*)\s*', 'operation') LUN_CAPACITY = PropertyDescriptor( '-userCap', 'User Capacity \(GBs\):\s*(.*)\s*', 'total_capacity_gb', float) LUN_OWNER = PropertyDescriptor( '-owner', 'Current Owner:\s*SP\s*(.*)\s*', 'owner') LUN_ATTACHEDSNAP = PropertyDescriptor( '-attachedSnapshot', 'Attached Snapshot:\s*(.*)\s*', 'attached_snapshot') LUN_NAME = PropertyDescriptor( '-name', 'Name:\s*(.*)\s*', 'lun_name') LUN_ID = PropertyDescriptor( '-id', 'LOGICAL UNIT NUMBER\s*(\d+)\s*', 'lun_id', int) LUN_POOL = PropertyDescriptor( '-poolName', 'Pool Name:\s*(.*)\s*', 'pool') LUN_ALL = [LUN_STATE, LUN_STATUS, LUN_OPERATION, LUN_CAPACITY, LUN_OWNER, LUN_ATTACHEDSNAP] LUN_WITH_POOL = [LUN_STATE, LUN_CAPACITY, LUN_OWNER, LUN_ATTACHEDSNAP, LUN_POOL] POOL_TOTAL_CAPACITY = PropertyDescriptor( '-userCap', 'User Capacity \(GBs\):\s*(.*)\s*', 'total_capacity_gb', float) POOL_FREE_CAPACITY = PropertyDescriptor( '-availableCap', 'Available Capacity *\(GBs\) *:\s*(.*)\s*', 'free_capacity_gb', float) POOL_NAME = PropertyDescriptor( '-name', 'Pool Name:\s*(.*)\s*', 'pool_name') POOL_ALL = [POOL_TOTAL_CAPACITY, POOL_FREE_CAPACITY] def __init__(self, configuration): configuration.append_config_values(san.san_opts) self.timeout = configuration.default_timeout * 60 self.max_luns = configuration.max_luns_per_storage_group errormessage = [] # Checking for existence of naviseccli tool navisecclipath = configuration.naviseccli_path if not os.path.exists(navisecclipath): errormessage.append(_('naviseccli_path: Could not find ' 'NAVISECCLI tool %(path)s.') % {'path': navisecclipath}) self.command = (navisecclipath, '-address') self.active_storage_ip = configuration.san_ip self.primary_storage_ip = self.active_storage_ip self.secondary_storage_ip = configuration.san_secondary_ip if self.secondary_storage_ip == self.primary_storage_ip: LOG.warn(_LW(""san_secondary_ip is configured as "" ""the same value as san_ip."")) self.secondary_storage_ip = None if not configuration.san_ip: errormessage.append(_('san_ip: Mandatory field configuration. ' 'san_ip is not set.')) self.credentials = () storage_username = configuration.san_login storage_password = configuration.san_password storage_auth_type = configuration.storage_vnx_authentication_type storage_vnx_security_file = configuration.storage_vnx_security_file_dir if storage_auth_type is None: storage_auth_type = 'global' elif storage_auth_type.lower() not in ('ldap', 'local', 'global'): errormessage.append(_('storage_vnx_authentication_type: ' 'Invalid VNX authentication type %s\n') % storage_auth_type) # if there is security file path provided, use this security file if storage_vnx_security_file: self.credentials = ('-secfilepath', storage_vnx_security_file) LOG.info(_LI(""Security file under location configured by "" ""storage_vnx_security_file_dir is using for "" ""authentication"")) # if there is a username/password provided, use those in the cmd line elif storage_username is not None and len(storage_username) > 0 and\ storage_password is not None and len(storage_password) > 0: self.credentials = ('-user', storage_username, '-password', storage_password, '-scope', storage_auth_type) LOG.info(_LI(""Plain text credentials are using for "" ""authentication"")) else: LOG.info(_LI(""Neither storage_vnx_security_file_dir nor plain "" ""text credentials are specified. Security file under "" ""home directory will be used for authentication "" ""if present"")) self.iscsi_initiator_map = None if configuration.iscsi_initiators: self.iscsi_initiator_map = \ json.loads(configuration.iscsi_initiators) LOG.info(_LI(""iscsi_initiators: %s""), self.iscsi_initiator_map) if len(errormessage) != 0: errormessage = ""\n"".join(errormessage) LOG.error(errormessage) raise exception.VolumeBackendAPIException(data=errormessage) # extra spec constants self.pool_spec = 'storagetype:pool' self.tiering_spec = 'storagetype:tiering' self.provisioning_spec = 'storagetype:provisioning' self.provisioning_values = { 'thin': ['-type', 'Thin'], 'thick': ['-type', 'NonThin'], 'compressed': ['-type', 'Thin'], 'deduplicated': ['-type', 'Thin', '-deduplication', 'on']} self.tiering_values = { 'starthighthenauto': [ '-initialTier', 'highestAvailable', '-tieringPolicy', 'autoTier'], 'auto': [ '-initialTier', 'optimizePool', '-tieringPolicy', 'autoTier'], 'highestavailable': [ '-initialTier', 'highestAvailable', '-tieringPolicy', 'highestAvailable'], 'lowestavailable': [ '-initialTier', 'lowestAvailable', '-tieringPolicy', 'lowestAvailable'], 'nomovement': [ '-initialTier', 'optimizePool', '-tieringPolicy', 'noMovement']} @log_enter_exit def create_lun_with_advance_feature(self, pool, name, size, provisioning, tiering): command_create_lun = ['lun', '-create', '-capacity', size, '-sq', 'gb', '-poolName', pool, '-name', name] # provisioning if provisioning: command_create_lun.extend(self.provisioning_values[provisioning]) # tiering if tiering: command_create_lun.extend(self.tiering_values[tiering]) # create lun data = self.create_lun_by_cmd(command_create_lun, name) # handle compression try: if provisioning == 'compressed': self.enable_or_disable_compression_on_lun( name, 'on') except Exception as ex: self.delete_lun(name) LOG.error(_LE(""Failed to enable compression on lun. %s"") % ex) raise return data @log_enter_exit def create_lun_by_cmd(self, cmd, name): out, rc = self.command_execute(*cmd) if rc != 0: # Ignore the error that due to retry if rc == 4 and out.find('(0x712d8d04)') >= 0: LOG.warn(_LW('LUN already exists, LUN name %(name)s. ' 'Message: %(msg)s') % {'name': name, 'msg': out}) else: raise EMCVnxCLICmdError(cmd, rc, out) def lun_is_ready(): data = self.get_lun_by_name(name) return data[self.LUN_STATE.key] == 'Ready' and \ data[self.LUN_STATUS.key] == 'OK(0x0)' and \ data[self.LUN_OPERATION.key] == 'None' self._wait_for_a_condition(lun_is_ready) lun = self.get_lun_by_name(name) return lun @log_enter_exit def delete_lun(self, name): command_delete_lun = ['lun', '-destroy', '-name', name, '-forceDetach', '-o'] # executing cli command to delete volume out, rc = self.command_execute(*command_delete_lun) if rc != 0: # Ignore the error that due to retry if rc == 9 and out.find(""not exist"") >= 0: LOG.warn(_LW(""LUN is already deleted, LUN name %(name)s. "" ""Message: %(msg)s"") % {'name': name, 'msg': out}) else: raise EMCVnxCLICmdError(command_delete_lun, rc, out) def _wait_for_a_condition(self, testmethod, timeout=None, interval=INTERVAL_5_SEC): start_time = time.time() if timeout is None: timeout = self.timeout def _inner(): try: testValue = testmethod() except Exception as ex: testValue = False LOG.debug('CommandLineHelper.' '_wait_for_condition: %(method_name)s ' 'execution failed for %(exception)s' % {'method_name': testmethod.__name__, 'exception': ex}) if testValue: raise loopingcall.LoopingCallDone() if int(time.time()) - start_time > timeout: msg = (_('CommandLineHelper._wait_for_condition: %s ' 'timeout') % testmethod.__name__) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) timer = loopingcall.FixedIntervalLoopingCall(_inner) timer.start(interval=interval).wait() @log_enter_exit def expand_lun(self, name, new_size): command_expand_lun = ('lun', '-expand', '-name', name, '-capacity', new_size, '-sq', 'gb', '-o', '-ignoreThresholds') out, rc = self.command_execute(*command_expand_lun) if rc != 0: # Ignore the error that due to retry if rc == 4 and out.find(""(0x712d8e04)"") >= 0: LOG.warn(_LW(""LUN %(name)s is already expanded. "" ""Message: %(msg)s"") % {'name': name, 'msg': out}) else: raise EMCVnxCLICmdError(command_expand_lun, rc, out) @log_enter_exit def expand_lun_and_wait(self, name, new_size): self.expand_lun(name, new_size) def lun_is_extented(): data = self.get_lun_by_name(name) return new_size == data[self.LUN_CAPACITY.key] self._wait_for_a_condition(lun_is_extented) @log_enter_exit def lun_rename(self, lun_id, new_name): """"""This function used to rename a lun to match the expected name for the volume. """""" command_lun_rename = ('lun', '-modify', '-l', lun_id, '-newName', new_name, '-o') out, rc = self.command_execute(*command_lun_rename) if rc != 0: raise EMCVnxCLICmdError(command_lun_rename, rc, out) @log_enter_exit def modify_lun_tiering(self, name, tiering): """"""This function used to modify a lun's tiering policy."""""" command_modify_lun = ['lun', '-modify', '-name', name, '-o'] if tiering: command_modify_lun.extend(self.tiering_values[tiering]) out, rc = self.command_execute(*command_modify_lun) if rc != 0: raise EMCVnxCLICmdError(command_modify_lun, rc, out) @log_enter_exit def create_snapshot(self, volume_name, name): data = self.get_lun_by_name(volume_name) if data[self.LUN_ID.key] is not None: command_create_snapshot = ('snap', '-create', '-res', data[self.LUN_ID.key], '-name', name, '-allowReadWrite', 'yes', '-allowAutoDelete', 'no') out, rc = self.command_execute(*command_create_snapshot) if rc != 0: # Ignore the error that due to retry if rc == 5 and \ out.find(""(0x716d8005)"") >= 0: LOG.warn(_LW('Snapshot %(name)s already exists. ' 'Message: %(msg)s') % {'name': name, 'msg': out}) else: raise EMCVnxCLICmdError(command_create_snapshot, rc, out) else: msg = _('Failed to get LUN ID for volume %s') % volume_name raise exception.VolumeBackendAPIException(data=msg) @log_enter_exit def delete_snapshot(self, name): def delete_snapshot_success(): command_delete_snapshot = ('snap', '-destroy', '-id', name, '-o') out, rc = self.command_execute(*command_delete_snapshot) if rc != 0: # Ignore the error that due to retry if rc == 5 and out.find(""not exist"") >= 0: LOG.warn(_LW(""Snapshot %(name)s may deleted already. "" ""Message: %(msg)s"") % {'name': name, 'msg': out}) return True # The snapshot cannot be destroyed because it is # attached to a snapshot mount point. Wait elif rc == 3 and out.find(""(0x716d8003)"") >= 0: LOG.warn(_LW(""Snapshot %(name)s is in use, retry. "" ""Message: %(msg)s"") % {'name': name, 'msg': out}) return False else: raise EMCVnxCLICmdError(command_delete_snapshot, rc, out) else: LOG.info(_LI('Snapshot %s is deleted successfully.') % name) return True self._wait_for_a_condition(delete_snapshot_success, interval=INTERVAL_30_SEC, timeout=INTERVAL_30_SEC * 3) @log_enter_exit def create_mount_point(self, primary_lun_name, name): command_create_mount_point = ('lun', '-create', '-type', 'snap', '-primaryLunName', primary_lun_name, '-name', name) out, rc = self.command_execute(*command_create_mount_point) if rc != 0: # Ignore the error that due to retry if rc == 4 and out.find(""(0x712d8d04)"") >= 0: LOG.warn(_LW(""Mount points %(name)s already exists. "" ""Message: %(msg)s"") % {'name': name, 'msg': out}) else: raise EMCVnxCLICmdError(command_create_mount_point, rc, out) return rc @log_enter_exit def attach_mount_point(self, name, snapshot_name): command_attach_mount_point = ('lun', '-attach', '-name', name, '-snapName', snapshot_name) out, rc = self.command_execute(*command_attach_mount_point) if rc != 0: # Ignore the error that due to retry if rc == 85 and out.find('(0x716d8055)') >= 0: LOG.warn(_LW(""Snapshot %(snapname)s is attached to snapshot "" ""mount point %(mpname)s already. "" ""Message: %(msg)s"") % {'snapname': snapshot_name, 'mpname': name, 'msg': out}) else: raise EMCVnxCLICmdError(command_attach_mount_point, rc, out) return rc @log_enter_exit def check_smp_not_attached(self, smp_name): """"""Ensure a snap mount point with snap become a LUN."""""" def _wait_for_sync_status(): lun_list = ('lun', '-list', '-name', smp_name, '-attachedSnapshot') out, rc = self.command_execute(*lun_list) if rc == 0: vol_details = out.split('\n') snap_name = vol_details[2].split(':')[1].strip() if (snap_name == 'N/A'): return True return False self._wait_for_a_condition(_wait_for_sync_status) @log_enter_exit def migrate_lun(self, src_id, dst_id, log_failure_as_error=True): command_migrate_lun = ('migrate', '-start', '-source', src_id, '-dest', dst_id, '-rate', 'high', '-o') # SP HA is not supported by LUN migration out, rc = self.command_execute(*command_migrate_lun, retry_disable=True) if 0 != rc: raise EMCVnxCLICmdError(command_migrate_lun, rc, out, log_failure_as_error) return rc @log_enter_exit def migrate_lun_with_verification(self, src_id, dst_id=None, dst_name=None): try: self.migrate_lun(src_id, dst_id, log_failure_as_error=False) except EMCVnxCLICmdError as ex: migration_succeed = False if self._is_sp_unavailable_error(ex.out): LOG.warn(_LW(""Migration command may timed out. "" ""Verify migration "" ""status continuously. Message: %(msg)s"") % {'msg': ex.out}) command_migrate_list = ('migrate', '-list', '-source', src_id) rc = self.command_execute(*command_migrate_list)[1] if rc == 0: migration_succeed = True if not migration_succeed: LOG.warn(_LW(""Start migration failed. Message: %s"") % ex.out) LOG.debug(""Delete temp LUN after migration "" ""start failed. LUN: %s"" % dst_name) if(dst_name is not None): self.delete_lun(dst_name) return 1 # Set the proper interval to verify the migration status def migration_is_ready(): mig_ready = False command_migrate_list = ('migrate', '-list', '-source', src_id) out, rc = self.command_execute(*command_migrate_list) LOG.debug(""Migration output: %s"" % out) if rc == 0: # parse the percentage out = re.split(r'\n', out) log = ""Migration in process %s %%."" % out[7].split("": "")[1] LOG.debug(log) else: if re.search(r'The specified source LUN ' 'is not currently migrating', out): LOG.debug(""Migration of LUN %s is finished."" % src_id) mig_ready = True else: reason = _(""Querying migrating status error."") LOG.error(reason) raise exception.VolumeBackendAPIException( data=""%(reason)s : %(output)s"" % {'reason': reason, 'output': out}) return mig_ready self._wait_for_a_condition(migration_is_ready, interval=INTERVAL_30_SEC) return 0 @log_enter_exit def get_storage_group(self, name): # ALU/HLU as key/value map lun_map = {} data = {'storage_group_name': name, 'storage_group_uid': None, 'lunmap': lun_map} command_get_storage_group = ('storagegroup', '-list', '-gname', name) out, rc = self.command_execute(*command_get_storage_group) if rc != 0: raise EMCVnxCLICmdError(command_get_storage_group, rc, out) re_stroage_group_id = 'Storage Group UID:\s*(.*)\s*' m = re.search(re_stroage_group_id, out) if m is not None: data['storage_group_uid'] = m.group(1) re_HLU_ALU_pair = 'HLU\/ALU Pairs:\s*HLU Number' \ '\s*ALU Number\s*[-\s]*(?P<lun_details>(\d+\s*)+)' m = re.search(re_HLU_ALU_pair, out) if m is not None: lun_details = m.group('lun_details').strip() values = re.split('\s*', lun_details) while (len(values) >= 2): key = values.pop() value = values.pop() lun_map[int(key)] = int(value) return data @log_enter_exit def create_storage_group(self, name): command_create_storage_group = ('storagegroup', '-create', '-gname', name) out, rc = self.command_execute(*command_create_storage_group) if rc != 0: # Ignore the error that due to retry if rc == 66 and out.find(""name already in use"") >= 0: LOG.warn(_LW('Storage group %(name)s already exists. ' 'Message: %(msg)s') % {'name': name, 'msg': out}) else: raise EMCVnxCLICmdError(command_create_storage_group, rc, out) @log_enter_exit def delete_storage_group(self, name): command_delete_storage_group = ('storagegroup', '-destroy', '-gname', name, '-o') out, rc = self.command_execute(*command_delete_storage_group) if rc != 0: # Ignore the error that due to retry if rc == 83 and out.find(""group name or UID does not "" ""match any storage groups"") >= 0: LOG.warn(_LW(""Storage group %(name)s doesn't exist, "" ""may has already been deleted. "" ""Message: %(msg)s"") % {'name': name, 'msg': out}) else: raise EMCVnxCLICmdError(command_delete_storage_group, rc, out) @log_enter_exit def connect_host_to_storage_group(self, hostname, sg_name): command_host_connect = ('storagegroup', '-connecthost', '-host', hostname, '-gname', sg_name, '-o') out, rc = self.command_execute(*command_host_connect) if rc != 0: raise EMCVnxCLICmdError(command_host_connect, rc, out) @log_enter_exit def disconnect_host_from_storage_group(self, hostname, sg_name): command_host_disconnect = ('storagegroup', '-disconnecthost', '-host', hostname, '-gname', sg_name, '-o') out, rc = self.command_execute(*command_host_disconnect) if rc != 0: # Ignore the error that due to retry if rc == 116 and \ re.search(""host is not.*connected to.*storage group"", out) is not None: LOG.warn(_LW(""Host %(host)s has already disconnected from "" ""storage group %(sgname)s. Message: %(msg)s"") % {'host': hostname, 'sgname': sg_name, 'msg': out}) else: raise EMCVnxCLICmdError(command_host_disconnect, rc, out) @log_enter_exit def add_hlu_to_storage_group(self, hlu, alu, sg_name): LOG.debug('Entering CommandLineHelper.add_hlu_to_storage_group.') command_add_hlu = ('storagegroup', '-addhlu', '-hlu', hlu, '-alu', alu, '-gname', sg_name) out, rc = self.command_execute(*command_add_hlu) if rc != 0: # Ignore the error that due to retry if rc == 66 and \ re.search(""LUN.*already.*added to.*Storage Group"", out) is not None: LOG.warn(_LW(""LUN %(lun)s has already added to "" ""Storage Group %(sgname)s. "" ""Message: %(msg)s"") % {'lun': alu, 'sgname': sg_name, 'msg': out}) else: raise EMCVnxCLICmdError(command_add_hlu, rc, out) @log_enter_exit def remove_hlu_from_storagegroup(self, hlu, sg_name): command_remove_hlu = ('storagegroup', '-removehlu', '-hlu', hlu, '-gname', sg_name, '-o') out, rc = self.command_execute(*command_remove_hlu) if rc != 0: # Ignore the error that due to retry if rc == 66 and\ out.find(""No such Host LUN in this Storage Group"") >= 0: LOG.warn(_LW(""HLU %(hlu)s has already removed from "" ""%(sgname)s. Message: %(msg)s"") % {'hlu': hlu, 'sgname': sg_name, 'msg': out}) else: raise EMCVnxCLICmdError(command_remove_hlu, rc, out) @log_enter_exit def get_iscsi_protocol_endpoints(self, device_sp): command_get_port = ('connection', '-getport', '-sp', device_sp) out, rc = self.command_execute(*command_get_port) if rc != 0: raise EMCVnxCLICmdError(command_get_port, rc, out) re_port_wwn = 'Port WWN:\s*(.*)\s*' initiator_address = re.findall(re_port_wwn, out) return initiator_address @log_enter_exit def get_pool_name_of_lun(self, lun_name): data = self.get_lun_properties( ('-name', lun_name), self.LUN_WITH_POOL) return data.get('pool', '') @log_enter_exit def get_lun_by_name(self, name, properties=LUN_ALL): data = self.get_lun_properties(('-name', name), properties) return data @log_enter_exit def get_lun_by_id(self, lunid, properties=LUN_ALL): data = self.get_lun_properties(('-l', lunid), properties) return data @log_enter_exit def get_pool(self, name): data = self.get_pool_properties(('-name', name)) return data @log_enter_exit def get_pool_properties(self, filter_option, properties=POOL_ALL): module_list = ('storagepool', '-list') data = self._get_lun_or_pool_properties( module_list, filter_option, base_properties=[self.POOL_NAME], adv_properties=properties) return data @log_enter_exit def get_lun_properties(self, filter_option, properties=LUN_ALL): module_list = ('lun', '-list') data = self._get_lun_or_pool_properties( module_list, filter_option, base_properties=[self.LUN_NAME, self.LUN_ID], adv_properties=properties) return data def _get_lun_or_pool_properties(self, module_list, filter_option, base_properties=[], adv_properties=[]): # to do instance check command_get_lun = module_list + filter_option for prop in adv_properties: command_get_lun += (prop.option, ) out, rc = self.command_execute(*command_get_lun) if rc != 0: raise EMCVnxCLICmdError(command_get_lun, rc, out) data = {} for baseprop in base_properties: data[baseprop.key] = self._get_property_value(out, baseprop) for prop in adv_properties: data[prop.key] = self._get_property_value(out, prop) LOG.debug('Return LUN or Pool properties. Data: %s' % data) return data def _get_property_value(self, out, propertyDescriptor): label = propertyDescriptor.label m = re.search(label, out) if m: if (propertyDescriptor.converter is not None): try: return propertyDescriptor.converter(m.group(1)) except ValueError: LOG.error(_LE(""Invalid value for %(key)s, "" ""value is %(value)s"") % {'key': propertyDescriptor.key, 'value': m.group(1)}) return None else: return m.group(1) else: LOG.debug('%s value is not found in the output' % propertyDescriptor.label) return None @log_enter_exit def check_lun_has_snap(self, lun_id): cmd = ('snap', '-list', '-res', lun_id) rc = self.command_execute(*cmd)[1] if rc == 0: LOG.debug(""Find snapshots for %s."" % lun_id) return True else: return False # Return a pool list @log_enter_exit def get_pool_list(self, no_poll=False): temp_cache = [] cmd = ('-np', 'storagepool', '-list', '-availableCap', '-state') \ if no_poll \ else ('storagepool', '-list', '-availableCap', '-state') out, rc = self.command_execute(*cmd) if rc != 0: raise EMCVnxCLICmdError(cmd, rc, out) try: for pool in out.split('\n\n'): if len(pool.strip()) == 0: continue obj = {} obj['name'] = self._get_property_value(pool, self.POOL_NAME) obj['free_space'] = self._get_property_value( pool, self.POOL_FREE_CAPACITY) temp_cache.append(obj) except Exception as ex: LOG.error(_LE(""Error happens during storage pool querying, %s"") % ex) # NOTE: Do not want to continue raise the exception # as the pools may temporarly unavailable pass return temp_cache @log_enter_exit def get_array_serial(self, no_poll=False): """"""return array Serial No for pool backend."""""" data = {'array_serial': 'unknown'} command_get_array_serial = ('-np', 'getagent', '-serial') \ if no_poll else ('getagent', '-serial') # Set the property timeout to get array serial out, rc = self.command_execute(*command_get_array_serial) if 0 == rc: m = re.search(r'Serial No:\s+(\w+)', out) if m: data['array_serial'] = m.group(1) else: LOG.warn(_LW(""No array serial number returned, "" ""set as unknown"")) else: raise EMCVnxCLICmdError(command_get_array_serial, rc, out) return data @log_enter_exit def get_status_up_ports(self, storage_group_name): """"""Function to get ports whose status are up."""""" cmd_get_hba = ('storagegroup', '-list', '-gname', storage_group_name) out, rc = self.command_execute(*cmd_get_hba) wwns = [] if 0 == rc: _re_hba_sp_pair = re.compile('((\w\w:){15}(\w\w)\s*' + '(SP\s[A-B]){1}\s*(\d*)\s*\n)') _all_hba_sp_pairs = re.findall(_re_hba_sp_pair, out) sps = [each[3] for each in _all_hba_sp_pairs] portid = [each[4] for each in _all_hba_sp_pairs] cmd_get_port = ('port', '-list', '-sp') out, rc = self.command_execute(*cmd_get_port) if 0 != rc: raise EMCVnxCLICmdError(cmd_get_port, rc, out) for i, sp in enumerate(sps): wwn = self.get_port_wwn(sp, portid[i], out) if (wwn is not None) and (wwn not in wwns): LOG.debug('Add wwn:%(wwn)s for sg:%(sg)s.' % {'wwn': wwn, 'sg': storage_group_name}) wwns.append(wwn) else: raise EMCVnxCLICmdError(cmd_get_hba, rc, out) return wwns @log_enter_exit def get_login_ports(self, storage_group_name, connector_wwpns): cmd_list_hba = ('port', '-list', '-gname', storage_group_name) out, rc = self.command_execute(*cmd_list_hba) ports = [] wwns = [] connector_hba_list = [] if 0 == rc and out.find('Information about each HBA:') != -1: hba_list = out.split('Information about each SPPORT:')[0].split( 'Information about each HBA:')[1:] allports = out.split('Information about each SPPORT:')[1] hba_uid_pat = re.compile('HBA\sUID:\s*((\w\w:){15}(\w\w))') for each in hba_list: obj_search = re.search(hba_uid_pat, each) if obj_search and obj_search.group(1). \ replace(':', '')[16:].lower() in connector_wwpns: connector_hba_list.append(each) port_pat = re.compile('SP Name:\s*(SP\s\w)\n\s*' + 'SP Port ID:\s*(\w*)\n\s*' + 'HBA Devicename:.*\n\s*' + 'Trusted:.*\n\s*' + 'Logged In:\s*YES\n') for each in connector_hba_list: ports.extend(re.findall(port_pat, each)) ports = list(set(ports)) for each in ports: wwn = self.get_port_wwn(each[0], each[1], allports) if wwn: wwns.append(wwn) else: raise EMCVnxCLICmdError(cmd_list_hba, rc, out) return wwns @log_enter_exit def get_port_wwn(self, sp, port_id, allports=None): wwn = None if allports is None: cmd_get_port = ('port', '-list', '-sp') out, rc = self.command_execute(*cmd_get_port) if 0 != rc: raise EMCVnxCLICmdError(cmd_get_port, rc, out) else: allports = out _re_port_wwn = re.compile('SP Name:\s*' + sp + '\nSP Port ID:\s*' + port_id + '\nSP UID:\s*((\w\w:){15}(\w\w))' + '\nLink Status: Up' + '\nPort Status: Online') _obj_search = re.search(_re_port_wwn, allports) if _obj_search is not None: wwn = _obj_search.group(1).replace(':', '')[16:] return wwn @log_enter_exit def get_fc_targets(self): fc_getport = ('port', '-list', '-sp') out, rc = self.command_execute(*fc_getport) if rc != 0: raise EMCVnxCLICmdError(fc_getport, rc, out) fc_target_dict = {'A': [], 'B': []} _fcport_pat = (r'SP Name: SP\s(\w)\s*' r'SP Port ID:\s*(\w*)\n' r'SP UID:\s*((\w\w:){15}(\w\w))\s*' r'Link Status: Up\n' r'Port Status: Online\n') for m in re.finditer(_fcport_pat, out): sp = m.groups()[0] sp_port_id = m.groups()[1] fc_target_dict[sp].append({'SP': sp, 'Port ID': sp_port_id}) return fc_target_dict @log_enter_exit def get_iscsi_targets(self): cmd_getport = ('connection', '-getport', '-address', '-vlanid') out, rc = self.command_execute(*cmd_getport) if rc != 0: raise EMCVnxCLICmdError(cmd_getport, rc, out) iscsi_target_dict = {'A': [], 'B': []} iscsi_spport_pat = r'(A|B)\s*' + \ r'Port ID:\s+(\d+)\s*' + \ r'Port WWN:\s+(iqn\S+)' iscsi_vport_pat = r'Virtual Port ID:\s+(\d+)\s*' + \ r'VLAN ID:\s*\S*\s*' + \ r'IP Address:\s+(\S+)' for spport_content in re.split(r'^SP:\s+|\nSP:\s*', out): m_spport = re.match(iscsi_spport_pat, spport_content, flags=re.IGNORECASE) if not m_spport: continue sp = m_spport.group(1) port_id = int(m_spport.group(2)) iqn = m_spport.group(3) for m_vport in re.finditer(iscsi_vport_pat, spport_content): vport_id = int(m_vport.group(1)) ip_addr = m_vport.group(2) if ip_addr.find('N/A') != -1: LOG.debug(""Skip port without IP Address: %s"", m_spport.group(0) + m_vport.group(0)) continue iscsi_target_dict[sp].append({'SP': sp, 'Port ID': port_id, 'Port WWN': iqn, 'Virtual Port ID': vport_id, 'IP Address': ip_addr}) return iscsi_target_dict @log_enter_exit def get_registered_spport_set(self, initiator_iqn, sgname): sg_list = ('storagegroup', '-list', '-gname', sgname) out, rc = self.command_execute(*sg_list) spport_set = set() if rc == 0: for m_spport in re.finditer(r'\n\s+%s\s+SP\s(A|B)\s+(\d+)' % initiator_iqn, out, flags=re.IGNORECASE): spport_set.add((m_spport.group(1), int(m_spport.group(2)))) LOG.debug('See path %(path)s in %(sg)s' % ({'path': m_spport.group(0), 'sg': sgname})) else: raise EMCVnxCLICmdError(sg_list, rc, out) return spport_set @log_enter_exit def ping_node(self, target_portal, initiator_ip): connection_pingnode = ('connection', '-pingnode', '-sp', target_portal['SP'], '-portid', target_portal['Port ID'], '-vportid', target_portal['Virtual Port ID'], '-address', initiator_ip) out, rc = self.command_execute(*connection_pingnode) if rc == 0: ping_ok = re.compile(r'Reply from %s' % initiator_ip) if re.match(ping_ok, out) is not None: LOG.debug(""See available iSCSI target: %s"", connection_pingnode) return True LOG.warn(_LW(""See unavailable iSCSI target: %s""), connection_pingnode) return False @log_enter_exit def find_avaialable_iscsi_target_one(self, hostname, preferred_sp, registered_spport_set): if self.iscsi_initiator_map and hostname in self.iscsi_initiator_map: iscsi_initiator_ips = list(self.iscsi_initiator_map[hostname]) random.shuffle(iscsi_initiator_ips) else: iscsi_initiator_ips = None # Check the targets on the owner first if preferred_sp == 'A': target_sps = ('A', 'B') else: target_sps = ('B', 'A') for target_sp in target_sps: iscsi_targets = self.get_iscsi_targets() target_portals = list(iscsi_targets[target_sp]) random.shuffle(target_portals) for target_portal in target_portals: spport = (target_portal['SP'], target_portal['Port ID']) if spport not in registered_spport_set: LOG.debug(""Skip SP Port %(port)s since "" ""no path from %(host)s is through it"" % {'port': spport, 'host': hostname}) continue if iscsi_initiator_ips is not None: for initiator_ip in iscsi_initiator_ips: if self.ping_node(target_portal, initiator_ip): return target_portal else: LOG.debug(""No iSCSI IP addresses of %(hostname)s is known"" ""Return a random iSCSI target portal %(portal)s"" % {'hostname': hostname, 'portal': target_portal}) return target_portal return None def _is_sp_unavailable_error(self, out): error_pattern = '(^Error.*Message.*End of data stream.*)|'\ '(.*Message.*connection refused.*)|'\ '(^Error.*Message.*Service Unavailable.*)' pattern = re.compile(error_pattern) return pattern.match(out) @log_enter_exit def command_execute(self, *command, **kwargv): # NOTE: retry_disable need to be removed from kwargv # before it pass to utils.execute, otherwise exception will thrown retry_disable = kwargv.pop('retry_disable', False) if self._is_sp_alive(self.active_storage_ip): out, rc = self._command_execute_on_active_ip(*command, **kwargv) if not retry_disable and self._is_sp_unavailable_error(out): # When active sp is unavailble, swith to another sp # and set it to active if self._toggle_sp(): LOG.debug('EMC: Command Exception: %(rc) %(result)s. ' 'Retry on another SP' % {'rc': rc, 'result': out}) out, rc = self._command_execute_on_active_ip(*command, **kwargv) elif self._toggle_sp() and not retry_disable: # If active ip is not accessible, toggled to another sp out, rc = self._command_execute_on_active_ip(*command, **kwargv) else: # Active IP is inaccessible, and cannot toggle to another SP, # return Error out, rc = ""Server Unavailable"", 255 LOG.debug('EMC: Command: %(command)s' % {'command': self.command + command}) LOG.debug('EMC: Command Result: %(result)s' % {'result': out.replace('\n', '\\n')}) return out, rc def _command_execute_on_active_ip(self, *command, **kwargv): if ""check_exit_code"" not in kwargv: kwargv[""check_exit_code""] = True rc = 0 out = """" try: active_ip = (self.active_storage_ip,) out, err = utils.execute( *(self.command + active_ip + self.credentials + command), **kwargv) except processutils.ProcessExecutionError as pe: rc = pe.exit_code out = pe.stdout out = out.replace('\n', '\\n') return out, rc def _is_sp_alive(self, ipaddr): ping_cmd = ('ping', '-c', 1, ipaddr) try: out, err = utils.execute(*ping_cmd, check_exit_code=True) except processutils.ProcessExecutionError as pe: out = pe.stdout rc = pe.exit_code if rc != 0: LOG.debug('%s is unavaialbe' % ipaddr) return False LOG.debug('Ping SP %(spip)s Command Result: %(result)s' % {'spip': self.active_storage_ip, 'result': out}) return True def _toggle_sp(self): """"""This function toggles the storage IP Address between primary IP and secondary IP, if no SP IP address has exchanged, return False, otherwise True will be returned. """""" if self.secondary_storage_ip is None: return False old_ip = self.active_storage_ip self.active_storage_ip = self.secondary_storage_ip if\ self.active_storage_ip == self.primary_storage_ip else\ self.primary_storage_ip LOG.info(_LI('Toggle storage_vnx_ip_adress from %(old)s to ' '%(new)s') % {'old': old_ip, 'new': self.primary_storage_ip}) return True @log_enter_exit def get_enablers_on_array(self, no_poll=False): """"""The function would get all the enabler installed on array. """""" enablers = [] cmd_list = ('-np', 'ndu', '-list') \ if no_poll else ('ndu', '-list') out, rc = self.command_execute(*cmd_list) if rc != 0: raise EMCVnxCLICmdError(cmd_list, rc, out) else: enabler_pat = r'Name of the software package:\s*(\S+)\s*' for m in re.finditer(enabler_pat, out): enablers.append(m.groups()[0]) LOG.debug('Enablers on array %s' % enablers) return enablers @log_enter_exit def enable_or_disable_compression_on_lun(self, volumename, compression): """"""The function will enable or disable the compression on lun """""" lun_data = self.get_lun_by_name(volumename) command_compression_cmd = ('compression', '-' + compression, '-l', lun_data['lun_id'], '-ignoreThresholds', '-o') out, rc = self.command_execute(*command_compression_cmd) if 0 != rc: raise EMCVnxCLICmdError(command_compression_cmd, rc, out) return rc, out class EMCVnxCliBase(object): 'volume_backend_name': None, 'compression_support': 'False', 'fast_support': 'False', 'deduplication_support': 'False', 'thinprovisioning_support': 'False'} enablers = [] self.timeout = self.configuration.default_timeout * 60 self.max_luns_per_sg = self.configuration.max_luns_per_storage_group self.destroy_empty_sg = self.configuration.destroy_empty_storage_group self.itor_auto_reg = self.configuration.initiator_auto_registration # if zoning_mode is fabric, use lookup service to build itor_tgt_map self.zonemanager_lookup_service = None if self.configuration.safe_get('zoning_mode') == 'fabric': from cinder.zonemanager.fc_san_lookup_service \ import FCSanLookupService self.zonemanager_lookup_service = \ FCSanLookupService(configuration=configuration) self.max_retries = 5 if self.destroy_empty_sg: LOG.warn(_LW(""destroy_empty_storage_group: True. "" ""Empty storage group will be deleted "" ""after volume is detached"")) if not self.itor_auto_reg: LOG.info(_LI(""initiator_auto_registration: False. "" ""Initiator auto registration is not enabled. "" ""Please register initiator manually"")) self.hlu_set = set(xrange(1, self.max_luns_per_sg + 1)) self._client = CommandLineHelper(self.configuration) self.array_serial = None def get_target_storagepool(self, volume, source_volume_name=None): raise NotImplementedError def dumps_provider_location(self, pl_dict): return '|'.join([k + '^' + pl_dict[k] for k in pl_dict]) def get_array_serial(self): if not self.array_serial: self.array_serial = self._client.get_array_serial() return self.array_serial['array_serial'] @log_enter_exit self._volume_creation_check(volume) specs = self.get_volumetype_extraspecs(volume) pool = self.get_target_storagepool(volume) provisioning, tiering = self.get_extra_spec_value(specs) if not provisioning: provisioning = 'thick' LOG.info(_LI('Create Volume: %(volume)s Size: %(size)s ' 'pool: %(pool)s ' 'provisioning: %(provisioning)s ' 'tiering: %(tiering)s') % {'volume': volumename, 'size': volumesize, 'pool': pool, 'provisioning': provisioning, 'tiering': tiering}) data = self._client.create_lun_with_advance_feature( pool, volumename, volumesize, provisioning, tiering) pl_dict = {'system': self.get_array_serial(), 'type': 'lun', 'id': str(data['lun_id'])} model_update = {'provider_location': self.dumps_provider_location(pl_dict)} volume['provider_location'] = model_update['provider_location'] return model_update def _volume_creation_check(self, volume): """"""This function will perform the check on the extra spec before the volume can be created. The check is a common check between the array baced and pool baced backend. """""" LOG.debug('Entering EMCVnxCliBase._volume_creation_check.') specs = self.get_volumetype_extraspecs(volume) provisioning, tiering = self.get_extra_spec_value(specs) # step 1: check extra spec value if provisioning: self.check_extra_spec_value( provisioning, self._client.provisioning_values.keys()) if tiering: self.check_extra_spec_value( tiering, self._client.tiering_values.keys()) # step 2: check extra spec combination self.check_extra_spec_combination(specs) def check_extra_spec_value(self, extra_spec, valid_values): """"""check whether an extra spec's value is valid."""""" if not extra_spec or not valid_values: LOG.error(_LE('The given extra_spec or valid_values is None.')) elif extra_spec not in valid_values: msg = _(""The extra_spec: %s is invalid."") % extra_spec return def get_extra_spec_value(self, extra_specs): """"""get EMC extra spec values."""""" provisioning = 'thick' tiering = None if self._client.provisioning_spec in extra_specs: provisioning = extra_specs[self._client.provisioning_spec].lower() if self._client.tiering_spec in extra_specs: tiering = extra_specs[self._client.tiering_spec].lower() return provisioning, tiering def check_extra_spec_combination(self, extra_specs): """"""check whether extra spec combination is valid."""""" provisioning, tiering = self.get_extra_spec_value(extra_specs) enablers = self.enablers # check provisioning and tiering # deduplicated and tiering can not be both enabled if provisioning == 'deduplicated' and tiering is not None: msg = _(""deduplicated and auto tiering can't be both enabled."") LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) elif provisioning == 'compressed' and '-Compression' not in enablers: msg = _(""Compression Enabler is not installed. "" ""Can not create compressed volume."") LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) elif provisioning == 'deduplicated' and \ '-Deduplication' not in enablers: msg = _(""Deduplication Enabler is not installed."" "" Can not create deduplicated volume"") LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) elif provisioning in ['thin', 'deduplicated', 'compressed'] and \ '-ThinProvisioning' not in enablers: msg = _(""ThinProvisioning Enabler is not installed."" "" Can not create thin volume"") LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) elif tiering is not None and '-FAST' not in enablers: msg = _(""FAST VP Enabler is not installed. "" ""Can't set tiering policy for the volume"") LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) return @log_enter_exit self._client.delete_lun(volume['name']) @log_enter_exit self._client.expand_lun_and_wait(volume['name'], new_size) def _get_original_status(self, volume): if (volume['instance_uuid'] is None and volume['attached_host'] is None): return 'available' else: return 'in-use' def _is_valid_for_storage_assisted_migration( self, volume, host, new_type=None): """"""Check the src and dest volume to decide the mogration type."""""" false_ret = (False, None) if 'location_info' not in host['capabilities']: LOG.warn(_LW(""Failed to getting target_pool_name/"" ""target_array_serial. 'location_info' "" ""is not in host['capabilities'] "")) return false_ret # mandatory info should be ok info = host['capabilities']['location_info'] LOG.debug(""Host for migration is %s"" % info) try: info_detail = info.split('|') target_pool_name = info_detail[0] target_array_serial = info_detail[1] except AttributeError: LOG.warn(_LW(""Error on parsing target_pool_name/"" ""target_array_serial."")) return false_ret if len(target_pool_name) == 0: # if retype, try to get the pool of the volume # when it's array-based if new_type: if 'storagetype:pool' in new_type['extra_specs']\ and new_type['extra_specs']['storagetype:pool']\ is not None: target_pool_name = \ new_type['extra_specs']['storagetype:pool'] else: target_pool_name = self._client.get_pool_name_of_lun( volume['name']) if len(target_pool_name) == 0: LOG.debug(""Skip storage-assisted migration because "" ""it doesn't support array backend ."") return false_ret # source and destination should be on same array array_serial = self._client.get_array_serial() if target_array_serial != array_serial['array_serial']: LOG.debug('Skip storage-assisted migration because ' 'target and source backend are not managing' 'a same array.') return false_ret # same protocol should be used if volume is in-use if host['capabilities']['storage_protocol'] != self.protocol \ and self._get_original_status(volume) == 'in-use': LOG.debug('Skip storage-assisted migration because ' 'in-use volume can not be ' 'migrate between diff protocol') return false_ret return (True, target_pool_name) @log_enter_exit def migrate_volume(self, ctxt, volume, host, new_type=None): """"""leverage the VNX on-array migration functionality, \ here is entry in source Backend. """""" false_ret = (False, None) is_valid, target_pool_name = \ self._is_valid_for_storage_assisted_migration( volume, host, new_type) if not is_valid: return false_ret return self._migrate_volume(volume, target_pool_name, new_type) def _migrate_volume(self, volume, target_pool_name, new_type=None): LOG.debug(""Starting real storage-assisted migration..."") # first create a new volume with same name and size of source volume volume_name = volume['name'] new_volume_name = ""%(src)s-%(ts)s"" % {'src': volume_name, 'ts': int(time.time())} src_id = self.get_lun_id(volume) provisioning = 'thick' tiering = None if new_type: provisioning, tiering = self.get_extra_spec_value( new_type['extra_specs']) else: provisioning, tiering = self.get_extra_spec_value( self.get_volumetype_extraspecs(volume)) self._client.create_lun_with_advance_feature( target_pool_name, new_volume_name, volume['size'], provisioning, tiering) dst_id = self.get_lun_id_by_name(new_volume_name) rc = self._client.migrate_lun_with_verification( src_id, dst_id, new_volume_name) moved = False if rc == 0: moved = True return moved, {} @log_enter_exit def retype(self, ctxt, volume, new_type, diff, host): new_specs = new_type['extra_specs'] new_provisioning, new_tiering = self.get_extra_spec_value( new_specs) # validate new_type if new_provisioning: self.check_extra_spec_value( new_provisioning, self._client.provisioning_values.keys()) if new_tiering: self.check_extra_spec_value( new_tiering, self._client.tiering_values.keys()) self.check_extra_spec_combination(new_specs) # check what changes are needed migration, tiering_change = self.determine_changes_when_retype( volume, new_type, host) # reject if volume has snapshot when migration is needed if migration and self._client.check_lun_has_snap( self.get_lun_id(volume)): LOG.debug('Driver is not able to do retype because the volume ' 'has snapshot which is forbidden to migrate') return False if migration: # check whether the migration is valid is_valid, target_pool_name = \ self._is_valid_for_storage_assisted_migration( volume, host, new_type) if is_valid: if self._migrate_volume( volume, target_pool_name, new_type)[0]: return True else: LOG.warn(_LW('Storage-assisted migration failed during ' 'retype')) return False else: # migration is invalid LOG.debug('Driver is not able to do retype due to ' 'storage-assisted migration is not valid ' 'in this stuation.') return False elif not migration and tiering_change: # modify lun to change tiering policy self._client.modify_lun_tiering(volume['name'], new_tiering) return True else: return True def determine_changes_when_retype(self, volume, new_type, host): migration = False tiering_change = False old_specs = self.get_volumetype_extraspecs(volume) old_provisioning, old_tiering = self.get_extra_spec_value( old_specs) old_pool = self.get_specific_extra_spec( old_specs, self._client.pool_spec) new_specs = new_type['extra_specs'] new_provisioning, new_tiering = self.get_extra_spec_value( new_specs) new_pool = self.get_specific_extra_spec( new_specs, self._client.pool_spec) if volume['host'] != host['host'] or \ old_provisioning != new_provisioning: migration = True elif new_pool and new_pool != old_pool: migration = True if new_tiering != old_tiering: tiering_change = True return migration, tiering_change def get_specific_extra_spec(self, specs, key): return specs.get(key, None) def determine_all_enablers_exist(self, enablers): """"""Determine all wanted enablers whether exist."""""" wanted = ['-ThinProvisioning', '-Deduplication', '-FAST', '-Compression'] for each in wanted: if each not in enablers: return False return True @log_enter_exit def update_volume_stats(self): """"""Update the common status share with pool and array backend. """""" if not self.determine_all_enablers_exist(self.enablers): self.enablers = self._client.get_enablers_on_array(NO_POLL) if '-Compression' in self.enablers: self.stats['compression_support'] = 'True' else: self.stats['compression_support'] = 'False' if '-FAST' in self.enablers: self.stats['fast_support'] = 'True' else: self.stats['fast_support'] = 'False' if '-Deduplication' in self.enablers: self.stats['deduplication_support'] = 'True' else: self.stats['deduplication_support'] = 'False' if '-ThinProvisioning' in self.enablers: self.stats['thinprovisioning_support'] = 'True' else: self.stats['thinprovisioning_support'] = 'False' if '-FASTCache' in self.enablers: self.stats['fast_cache_enabled'] = 'True' else: self.stats['fast_cache_enabled'] = 'False' @log_enter_exit data = self._client.get_lun_by_name(volumename) device_id = data['lun_id'] LOG.debug('Exiting EMCVnxCliBase.create_export: Volume: %(volume)s ' 'Device ID: %(device_id)s' @log_enter_exit LOG.info(_LI('Create snapshot: %(snapshot)s: volume: %(volume)s') self._client.create_snapshot(volumename, snapshotname) @log_enter_exit LOG.info(_LI('Delete Snapshot: %(snapshot)s') % {'snapshot': snapshotname}) self._client.delete_snapshot(snapshotname) @log_enter_exit snapshot_name = snapshot['name'] volume_name = volume['name'] volume_size = snapshot['volume_size'] self._client.create_mount_point(source_volume_name, volume_name) self._client.attach_mount_point(volume_name, snapshot_name) dest_volume_name = volume_name + '_dest' LOG.debug('Creating Temporary Volume: %s ' % dest_volume_name) pool_name = self.get_target_storagepool(volume, source_volume_name) try: self._volume_creation_check(volume) specs = self.get_volumetype_extraspecs(volume) provisioning, tiering = self.get_extra_spec_value(specs) self._client.create_lun_with_advance_feature( pool_name, dest_volume_name, volume_size, provisioning, tiering) except exception.VolumeBackendAPIException as ex: msg = (_LE('Command to create the temporary Volume %s failed') % dest_volume_name) raise ex source_vol_lun_id = self.get_lun_id(volume) temp_vol_lun_id = self.get_lun_id_by_name(dest_volume_name) LOG.debug('Migrating Mount Point Volume: %s ' % volume_name) self._client.migrate_lun_with_verification(source_vol_lun_id, temp_vol_lun_id, dest_volume_name) self._client.check_smp_not_attached(volume_name) data = self._client.get_lun_by_name(volume_name) pl_dict = {'system': self.get_array_serial(), 'type': 'lun', 'id': str(data['lun_id'])} model_update = {'provider_location': self.dumps_provider_location(pl_dict)} volume['provider_location'] = model_update['provider_location'] return model_update @log_enter_exit volume_size = src_vref['size'] snapshot_name = 'tmp-snap-%s' % volume['id'] 'name': snapshot_name, 'volume_size': volume_size, } # Create volume model_update = self.create_volume_from_snapshot(volume, snapshot) # Delete temp Snapshot self.delete_snapshot(snapshot) return model_update def get_lun_id_by_name(self, volume_name): data = self._client.get_lun_by_name(volume_name) return data['lun_id'] def get_lun_id(self, volume): lun_id = None try: if volume.get('provider_location') is not None: lun_id = int( volume['provider_location'].split('|')[2].split('^')[1]) if not lun_id: LOG.debug('Lun id is not stored in provider location, ' 'query it') lun_id = self._client.get_lun_by_name(volume['name'])['lun_id'] except Exception as ex: LOG.debug('Exception when getting lun id: %s.' % (ex)) lun_id = self._client.get_lun_by_name(volume['name'])['lun_id'] LOG.debug('Get lun_id: %s.' % (lun_id)) return lun_id def get_lun_map(self, storage_group): data = self._client.get_storage_group(storage_group) return data['lunmap'] def get_storage_group_uid(self, name): data = self._client.get_storage_group(name) return data['storage_group_uid'] def assure_storage_group(self, storage_group): try: self._client.create_storage_group(storage_group) except EMCVnxCLICmdError as ex: if ex.out.find(""Storage Group name already in use"") == -1: raise ex def assure_host_in_storage_group(self, hostname, storage_group): try: self._client.connect_host_to_storage_group(hostname, storage_group) except EMCVnxCLICmdError as ex: if ex.rc == 83: # SG was not created or was destroyed by another concurrent # operation before connected. # Create SG and try to connect again LOG.warn(_LW('Storage Group %s is not found. Create it.'), storage_group) self.assure_storage_group(storage_group) self._client.connect_host_to_storage_group( hostname, storage_group) else: raise ex data = self._client.get_storage_group(storage_group) lun_map = data['lunmap'] data = self._client.get_lun_by_name(volume['name']) allocated_lun_id = data['lun_id'] owner_sp = data['owner'] for lun in lun_map.iterkeys(): if lun == int(allocated_lun_id): host_lun_id = lun_map[lun] LOG.debug('Host Lun Id : %s' % (host_lun_id)) break LOG.debug('Owner SP : %s' % (owner_sp)) def filter_available_hlu_set(self, used_hlus): used_hlu_set = set(used_hlus) return self.hlu_set - used_hlu_set def _extract_iscsi_uids(self, connector): if 'initiator' not in connector: if self.protocol == 'iSCSI': msg = _('Host %s has no iSCSI initiator') % connector['host'] LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) else: return () return [connector['initiator']] def _extract_fc_uids(self, connector): if 'wwnns' not in connector or 'wwpns' not in connector: if self.protocol == 'FC': msg = _('Host %s has no FC initiators') % connector['host'] LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) else: return () wwnns = connector['wwnns'] wwpns = connector['wwpns'] wwns = [(node + port).upper() for node, port in zip(wwnns, wwpns)] return map(lambda wwn: re.sub(r'\S\S', lambda m: m.group(0) + ':', wwn, len(wwn) / 2 - 1), wwns) def _exec_command_setpath(self, initiator_uid, sp, port_id, ip, host, vport_id=None): gname = host if vport_id is not None: cmd_iscsi_setpath = ('storagegroup', '-gname', gname, '-setpath', '-hbauid', initiator_uid, '-sp', sp, '-spport', port_id, '-spvport', vport_id, '-ip', ip, '-host', host, '-o') out, rc = self._client.command_execute(*cmd_iscsi_setpath) if rc != 0: raise EMCVnxCLICmdError(cmd_iscsi_setpath, rc, out) else: cmd_fc_setpath = ('storagegroup', '-gname', gname, '-setpath', '-hbauid', initiator_uid, '-sp', sp, '-spport', port_id, '-ip', ip, '-host', host, '-o') out, rc = self._client.command_execute(*cmd_fc_setpath) if rc != 0: raise EMCVnxCLICmdError(cmd_fc_setpath, rc, out) def _register_iscsi_initiator(self, ip, host, initiator_uids): for initiator_uid in initiator_uids: iscsi_targets = self._client.get_iscsi_targets() LOG.info(_LI('Get ISCSI targets %(tg)s to register ' 'initiator %(in)s') % ({'tg': iscsi_targets, 'in': initiator_uid})) target_portals_SPA = list(iscsi_targets['A']) target_portals_SPB = list(iscsi_targets['B']) for pa in target_portals_SPA: sp = 'A' port_id = pa['Port ID'] vport_id = pa['Virtual Port ID'] self._exec_command_setpath(initiator_uid, sp, port_id, ip, host, vport_id) for pb in target_portals_SPB: sp = 'B' port_id = pb['Port ID'] vport_id = pb['Virtual Port ID'] self._exec_command_setpath(initiator_uid, sp, port_id, ip, host, vport_id) def _register_fc_initiator(self, ip, host, initiator_uids): for initiator_uid in initiator_uids: fc_targets = self._client.get_fc_targets() LOG.info(_LI('Get FC targets %(tg)s to register initiator %(in)s') % ({'tg': fc_targets, 'in': initiator_uid})) target_portals_SPA = list(fc_targets['A']) target_portals_SPB = list(fc_targets['B']) for pa in target_portals_SPA: sp = 'A' port_id = pa['Port ID'] self._exec_command_setpath(initiator_uid, sp, port_id, ip, host) for pb in target_portals_SPB: sp = 'B' port_id = pb['Port ID'] self._exec_command_setpath(initiator_uid, sp, port_id, ip, host) def _filter_unregistered_initiators(self, initiator_uids=[]): unregistered_initiators = [] if not initiator_uids: return unregistered_initiators command_get_storage_group = ('storagegroup', '-list') out, rc = self._client.command_execute(*command_get_storage_group) if rc != 0: raise EMCVnxCLICmdError(command_get_storage_group, rc, out) for initiator_uid in initiator_uids: m = re.search(initiator_uid, out) if m is None: unregistered_initiators.append(initiator_uid) return unregistered_initiators def auto_register_initiator(self, connector): """"""Automatically register available initiators."""""" initiator_uids = [] ip = connector['ip'] host = connector['host'] if self.protocol == 'iSCSI': initiator_uids = self._extract_iscsi_uids(connector) itors_toReg = self._filter_unregistered_initiators(initiator_uids) LOG.debug('iSCSI Initiators %(in)s of %(ins)s need registration' % ({'in': itors_toReg, 'ins': initiator_uids})) if not itors_toReg: LOG.debug('Initiators %s are already registered' % initiator_uids) return self._register_iscsi_initiator(ip, host, itors_toReg) elif self.protocol == 'FC': initiator_uids = self._extract_fc_uids(connector) itors_toReg = self._filter_unregistered_initiators(initiator_uids) LOG.debug('FC Initiators %(in)s of %(ins)s need registration' % ({'in': itors_toReg, 'ins': initiator_uids})) if not itors_toReg: LOG.debug('Initiators %s are already registered' % initiator_uids) return self._register_fc_initiator(ip, host, itors_toReg) def assure_host_access(self, volumename, connector): auto_registration_done = False try: self.get_storage_group_uid(hostname) except EMCVnxCLICmdError as ex: if ex.rc != 83: raise ex # Storage Group has not existed yet self.assure_storage_group(hostname) if self.itor_auto_reg: self.auto_register_initiator(connector) auto_registration_done = True else: self._client.connect_host_to_storage_group(hostname, hostname) if self.itor_auto_reg and not auto_registration_done: self.auto_register_initiator(connector) auto_registration_done = True lun_id = self.get_lun_id_by_name(volumename) lun_map = self.get_lun_map(hostname) if lun_id in lun_map: return lun_map[lun_id] used_hlus = lun_map.values() if len(used_hlus) >= self.max_luns_per_sg: msg = _('Reach limitation set by configuration ' 'option max_luns_per_storage_group. ' 'Operation to add %(vol)s into ' 'Storage Group %(sg)s is rejected') % \ {'vol': volumename, 'sg': hostname} LOG.error(msg) raise exception.CinderException(msg) candidate_hlus = self.filter_available_hlu_set(used_hlus) candidate_hlus = list(candidate_hlus) random.shuffle(candidate_hlus) for i, hlu in enumerate(candidate_hlus): if i >= self.max_retries: break try: self._client.add_hlu_to_storage_group( hlu, lun_id, hostname) return hlu except EMCVnxCLICmdError as ex: # Retry continue msg = _(""Failed to add %(vol)s into %(sg)s "" ""after %(retries)s tries"") % \ {'vol': volumename, 'sg': hostname, 'retries': min(self.max_retries, len(candidate_hlus))} LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) def vnx_get_iscsi_properties(self, volume, connector): storage_group = connector['host'] device_info = self.find_device_details(volume, storage_group) owner_sp = device_info['ownersp'] registered_spports = self._client.get_registered_spport_set( connector['initiator'], storage_group) target = self._client.find_avaialable_iscsi_target_one( storage_group, owner_sp, registered_spports) properties = {'target_discovered': True, 'target_iqn': 'unknown', 'target_portal': 'unknown', 'target_lun': 'unknown', 'volume_id': volume['id']} if target: properties = {'target_discovered': True, 'target_iqn': target['Port WWN'], 'target_portal': ""%s:3260"" % target['IP Address'], 'target_lun': device_info['hostlunid']} LOG.debug(""iSCSI Properties: %s"", properties) auth = volume['provider_auth'] if auth: (auth_method, auth_username, auth_secret) = auth.split() properties['auth_method'] = auth_method properties['auth_username'] = auth_username properties['auth_password'] = auth_secret else: LOG.error(_LE('Failed to find an available iSCSI targets for %s'), storage_group) return properties def vnx_get_fc_properties(self, connector, device_number): ports = self.get_login_ports(connector) return {'target_lun': device_number, 'target_discovered': True, 'target_wwn': ports} @log_enter_exit def initialize_connection(self, volume, connector): volume_metadata = {} for metadata in volume['volume_admin_metadata']: volume_metadata[metadata['key']] = metadata['value'] access_mode = volume_metadata.get('attached_mode') if access_mode is None: access_mode = ('ro' if volume_metadata.get('readonly') == 'True' else 'rw') LOG.debug('Volume %(vol)s Access mode is: %(access)s.' % {'vol': volume['name'], 'access': access_mode}) """"""Initializes the connection and returns connection info."""""" @lockutils.synchronized('emc-connection-' + connector['host'], ""emc-connection-"", True) def do_initialize_connection(): device_number = self.assure_host_access( volume['name'], connector) return device_number if self.protocol == 'iSCSI': do_initialize_connection() iscsi_properties = self.vnx_get_iscsi_properties(volume, connector) iscsi_properties['access_mode'] = access_mode data = {'driver_volume_type': 'iscsi', 'data': iscsi_properties} elif self.protocol == 'FC': device_number = do_initialize_connection() fc_properties = self.vnx_get_fc_properties(connector, device_number) fc_properties['volume_id'] = volume['id'] fc_properties['access_mode'] = access_mode data = {'driver_volume_type': 'fibre_channel', 'data': fc_properties} return data @log_enter_exit LOG.debug(""Entering EMCVnxCliBase.terminate_connection."") @lockutils.synchronized('emc-connection-' + connector['host'], ""emc-connection-"", True) def do_terminate_connection(): hostname = connector['host'] volume_name = volume['name'] try: lun_map = self.get_lun_map(hostname) except EMCVnxCLICmdError as ex: if ex.rc == 83: LOG.warn(_LW(""Storage Group %s is not found. "" ""terminate_connection() is unnecessary. ""), hostname) return True try: lun_id = self.get_lun_id(volume) except EMCVnxCLICmdError as ex: if ex.rc == 9: LOG.warn(_LW(""Volume %s has probably been removed in VNX""), volume_name) if lun_id in lun_map: self._client.remove_hlu_from_storagegroup( lun_map[lun_id], hostname) else: LOG.warn(_LW(""Volume %(vol)s was not in Storatge Group %(sg)s"") % {'vol': volume_name, 'sg': hostname}) if self.destroy_empty_sg or self.zonemanager_lookup_service: try: lun_map = self.get_lun_map(hostname) if not lun_map: LOG.debug(""Storage Group %s was empty"", hostname) if self.destroy_empty_sg: LOG.info(_LI(""Storage Group %s was empty, "" ""detroy it""), hostname) self._client.disconnect_host_from_storage_group( hostname, hostname) self._client.delete_storage_group(hostname) return True else: LOG.debug(""Storage Group %s not empty"", hostname) return False except Exception: LOG.warn(_LW(""Failed to destroy Storage Group %s""), hostname) else: return False return do_terminate_connection() @log_enter_exit def adjust_fc_conn_info(self, conn_info, connector, remove_zone=None): target_wwns, itor_tgt_map = self.get_initiator_target_map( connector['wwpns'], self.get_status_up_ports(connector)) if target_wwns: conn_info['data']['target_wwn'] = target_wwns conn_info['data']['initiator_target_map'] = itor_tgt_map if remove_zone is not None: conn_info['data']['remove_zone'] = remove_zone return conn_info @log_enter_exit def manage_existing_get_size(self, volume, ref): """"""Return size of volume to be managed by manage_existing. """""" # Check that the reference is valid if 'id' not in ref: reason = _('Reference must contain lun_id element.') raise exception.ManageExistingInvalidReference( existing_ref=ref, reason=reason) # Check for existence of the lun data = self._client.get_lun_by_id(ref['id']) if data is None: reason = _('Find no lun with the specified lun_id.') raise exception.ManageExistingInvalidReference(existing_ref=ref, reason=reason) return data['total_capacity_gb'] @log_enter_exit def manage_existing(self, volume, ref): raise NotImplementedError def find_iscsi_protocol_endpoints(self, device_sp): return self._client.get_iscsi_protocol_endpoints(device_sp) def get_login_ports(self, connector): return self._client.get_login_ports(connector['host'], connector['wwpns']) def get_status_up_ports(self, connector): return self._client.get_status_up_ports(connector['host']) def get_initiator_target_map(self, fc_initiators, fc_targets): target_wwns = [] itor_tgt_map = {} if self.zonemanager_lookup_service: mapping = \ self.zonemanager_lookup_service. \ get_device_mapping_from_network(fc_initiators, fc_targets) for each in mapping: map_d = mapping[each] target_wwns.extend(map_d['target_port_wwn_list']) for initiator in map_d['initiator_port_wwn_list']: itor_tgt_map[initiator] = map_d['target_port_wwn_list'] return list(set(target_wwns)), itor_tgt_map def get_volumetype_extraspecs(self, volume): class EMCVnxCliPool(EMCVnxCliBase): def __init__(self, prtcl, configuration): super(EMCVnxCliPool, self).__init__(prtcl, configuration=configuration) self.storage_pool = configuration.storage_vnx_pool_name.strip() self._client.get_pool(self.storage_pool) def get_target_storagepool(self, volume=None, source_volume_name=None): pool_spec_id = ""storagetype:pool"" if volume is not None: specs = self.get_volumetype_extraspecs(volume) if specs and pool_spec_id in specs: expect_pool = specs[pool_spec_id].strip() if expect_pool != self.storage_pool: msg = _(""Storage pool %s is not supported"" "" by this Cinder Volume"") % expect_pool LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) return self.storage_pool def is_pool_fastcache_enabled(self, storage_pool, no_poll=False): command_check_fastcache = None if no_poll: command_check_fastcache = ('-np', 'storagepool', '-list', '-name', storage_pool, '-fastcache') else: command_check_fastcache = ('storagepool', '-list', '-name', storage_pool, '-fastcache') out, rc = self._client.command_execute(*command_check_fastcache) if 0 != rc: raise EMCVnxCLICmdError(command_check_fastcache, rc, out) else: re_fastcache = 'FAST Cache:\s*(.*)\s*' m = re.search(re_fastcache, out) if m is not None: result = True if 'Enabled' == m.group(1) else False else: LOG.error(_LE(""Error parsing output for FastCache Command."")) return result @log_enter_exit def update_volume_stats(self): """"""Retrieve stats info."""""" self.stats = super(EMCVnxCliPool, self).update_volume_stats() data = self._client.get_pool(self.get_target_storagepool()) self.stats['total_capacity_gb'] = data['total_capacity_gb'] self.stats['free_capacity_gb'] = data['free_capacity_gb'] array_serial = self._client.get_array_serial(NO_POLL) self.stats['location_info'] = ('%(pool_name)s|%(array_serial)s' % {'pool_name': self.storage_pool, 'array_serial': array_serial['array_serial']}) # check if this pool's fast_cache is really enabled if self.stats['fast_cache_enabled'] == 'True' and \ not self.is_pool_fastcache_enabled(self.storage_pool, NO_POLL): self.stats['fast_cache_enabled'] = 'False' return self.stats @log_enter_exit def manage_existing(self, volume, ref): """"""Manage an existing lun in the array. The lun should be in a manageable pool backend, otherwise error would return. Rename the backend storage object so that it matches the, volume['name'] which is how drivers traditionally map between a cinder volume and the associated backend storage object. existing_ref:{ 'id':lun_id } """""" data = self._client.get_lun_by_id( ref['id'], self._client.LUN_WITH_POOL) if self.storage_pool != data['pool']: reason = _('The input lun is not in a manageable pool backend ' 'by cinder') raise exception.ManageExistingInvalidReference(existing_ref=ref, reason=reason) self._client.lun_rename(ref['id'], volume['name']) class EMCVnxCliArray(EMCVnxCliBase): def __init__(self, prtcl, configuration): super(EMCVnxCliArray, self).__init__(prtcl, configuration=configuration) self._update_pool_cache() def _update_pool_cache(self): LOG.debug(""Updating Pool Cache"") self.pool_cache = self._client.get_pool_list(NO_POLL) def get_target_storagepool(self, volume, source_volume_name=None): """"""Find the storage pool for given volume."""""" pool_spec_id = ""storagetype:pool"" specs = self.get_volumetype_extraspecs(volume) if specs and pool_spec_id in specs: return specs[pool_spec_id] elif source_volume_name: data = self._client.get_lun_by_name(source_volume_name, [self._client.LUN_POOL]) if data is None: msg = _(""Failed to find storage pool for source volume %s"") \ % source_volume_name LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) return data[self._client.LUN_POOL.key] else: if len(self.pool_cache) > 0: pools = sorted(self.pool_cache, key=lambda po: po['free_space'], reverse=True) return pools[0]['name'] msg = _(""Failed to find storage pool to create volume %s"")\ % volume['name'] LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) @log_enter_exit def update_volume_stats(self): """"""Retrieve stats info."""""" self.stats = super(EMCVnxCliArray, self).update_volume_stats() self._update_pool_cache() self.stats['total_capacity_gb'] = 'unknown' self.stats['free_capacity_gb'] = 'unknown' array_serial = self._client.get_array_serial(NO_POLL) self.stats['location_info'] = ('%(pool_name)s|%(array_serial)s' % {'pool_name': '', 'array_serial': array_serial['array_serial']}) self.stats['fast_cache_enabled'] = 'unknown' return self.stats @log_enter_exit def manage_existing(self, volume, ref): """"""Rename the backend storage object so that it matches the, volume['name'] which is how drivers traditionally map between a cinder volume and the associated backend storage object. existing_ref:{ 'id':lun_id } """""" LOG.debug(""Entering EMCVnxCliArray.manage_existing."") self._client.lun_rename(ref['id'], volume['name']) def getEMCVnxCli(prtcl, configuration=None): configuration.append_config_values(loc_opts) pool_name = configuration.safe_get(""storage_vnx_pool_name"") if pool_name is None or len(pool_name.strip()) == 0: return EMCVnxCliArray(prtcl, configuration=configuration) else: return EMCVnxCliPool(prtcl, configuration=configuration)","# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at# http://www.apache.org/licenses/LICENSE-2.0# Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License.VNX CLI on iSCSI.LOG = logging.getLogger(__name__)VERSION = '02.00.00' help='ISCSI pool name'), default=20, help='Default Time Out For CLI operations in minutes'), default=256, help='Default max number of LUNs in a storage group'), ]class EMCVnxCli(object): 'volume_backend_name': None} self.configuration.append_config_values(loc_opts) self.configuration.append_config_values(san.san_opts) self.storage_ip = self.configuration.san_ip self.storage_username = self.configuration.san_login self.storage_password = self.configuration.san_password self.pool_name = self.configuration.storage_vnx_pool_name if not self.pool_name: msg = (_('Pool name is not specified.')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) self.timeout = self.configuration.default_timeout self.max_luns = self.configuration.max_luns_per_storage_group self.hlu_set = set(xrange(1, self.max_luns + 1)) self.navisecclipath = self.configuration.naviseccli_path self.cli_prefix = (self.navisecclipath, '-address', self.storage_ip) self.cli_credentials = () self.wait_interval = 3 # if there is a username/password provided, use those in the cmd line if self.storage_username is not None and \ self.storage_password is not None: self.cli_credentials += ('-user', self.storage_username, '-password', self.storage_password, '-scope', '0') # Checking for existence of naviseccli tool if not os.path.exists(self.navisecclipath): msg = (_('Could not find NAVISECCLI tool.')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) # Testing the naviseccli setup query_list = (""storagepool"", ""-list"", ""-name"", self.pool_name, ""-state"") out, rc = self._cli_execute(*query_list) if rc != 0: LOG.error(_(""Failed to find pool %s""), self.pool_name) raise exception.VolumeBackendAPIException(data=out) def _cli_execute(self, *cmd, **kwargv): if ""check_exit_code"" not in kwargv: kwargv[""check_exit_code""] = True rc = 0 try: out, _err = utils.execute(*(self.cli_prefix + self.cli_credentials + cmd), **kwargv) except processutils.ProcessExecutionError as pe: rc = pe.exit_code out = pe.stdout + pe.stderr return out, rc LOG.debug('Entering create_volume.') LOG.info(_('Create Volume: %(volume)s Size: %(size)s') % {'volume': volumename, 'size': volumesize}) thinness = self._get_provisioning_by_volume(volume) # executing CLI command to create volume LOG.debug('Create Volume: %(volumename)s' % {'volumename': volumename}) lun_create = ('lun', '-create', '-type', thinness, '-capacity', volumesize, '-sq', 'gb', '-poolName', self.pool_name, '-name', volumename) out, rc = self._cli_execute(*lun_create) LOG.debug('Create Volume: %(volumename)s Return code: %(rc)s' % {'volumename': volumename, 'rc': rc}) if rc == 4: LOG.warn(_('Volume %s already exists'), volumename) elif rc != 0: msg = (_('Failed to create %(volumename)s: %(out)s') % {'volumename': volumename, 'out': out}) # wait for up to a minute to verify that the LUN has progressed # to Ready state def _wait_for_lun_ready(volumename, start_time): # executing cli command to check volume command_to_verify = ('lun', '-list', '-name', volumename) out, rc = self._cli_execute(*command_to_verify) if rc == 0 and out.find(""Ready"") > -1: raise loopingcall.LoopingCallDone() if int(time.time()) - start_time > self.timeout * 60: msg = (_('LUN %s failed to become Ready'), volumename) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) timer = loopingcall.FixedIntervalLoopingCall( _wait_for_lun_ready, volumename, int(time.time())) timer.start(interval=self.wait_interval).wait() LOG.debug('Entering delete_volume.') volumename = volume['name'] # defining CLI command lun_destroy = ('lun', '-destroy', '-name', volumename, '-forceDetach', '-o') # executing CLI command to delete volume out, rc = self._cli_execute(*lun_destroy) LOG.debug('Delete Volume: %(volumename)s Output: %(out)s' % {'volumename': volumename, 'out': out}) if rc not in (0, 9): msg = (_('Failed to destroy %s'), volumename) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('Entering extend_volume.') volumename = volume['name'] # defining CLI command lun_expand = ('lun', '-expand', '-name', volumename, '-capacity', new_size, '-sq', 'gb', '-o', '-ignoreThresholds') # executing CLI command to extend volume out, rc = self._cli_execute(*lun_expand) LOG.debug('Extend Volume: %(volumename)s Output: %(out)s' % {'volumename': volumename, 'out': out}) if rc == 97: msg = (_('The LUN cannot be expanded or shrunk because ' 'it has snapshots. Command to extend the specified ' 'volume failed.')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) if rc != 0: msg = (_('Failed to expand %s'), volumename) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) def update_volume_status(self): """"""Retrieve status info."""""" LOG.debug(""Updating volume status"") poolname = self.pool_name pool_list = ('storagepool', '-list', '-name', poolname, '-userCap', '-availableCap') out, rc = self._cli_execute(*pool_list) if rc == 0: pool_details = out.split('\n') self.stats['total_capacity_gb'] = float( pool_details[3].split(':')[1].strip()) self.stats['free_capacity_gb'] = float( pool_details[5].split(':')[1].strip()) else: msg = (_('Failed to list %s'), poolname) LOG.error(msg) device_id = self._find_lun_id(volumename) LOG.debug('create_export: Volume: %(volume)s Device ID: ' '%(device_id)s' def _find_lun_id(self, volumename): """"""Returns the LUN of a volume."""""" lun_list = ('lun', '-list', '-name', volumename) out, rc = self._cli_execute(*lun_list) if rc == 0: vol_details = out.split('\n') lun = vol_details[0].split(' ')[3] else: msg = (_('Failed to list %s'), volumename) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) return lun LOG.debug('Entering create_snapshot.') LOG.info(_('Create snapshot: %(snapshot)s: volume: %(volume)s') volume_lun = self._find_lun_id(volumename) # defining CLI command snap_create = ('snap', '-create', '-res', volume_lun, '-name', snapshotname, '-allowReadWrite', 'yes') # executing CLI command to create snapshot out, rc = self._cli_execute(*snap_create) LOG.debug('Create Snapshot: %(snapshotname)s Unity: %(out)s' % {'snapshotname': snapshotname, 'out': out}) if rc != 0: msg = (_('Failed to create snap %s'), snapshotname) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) LOG.debug('Entering delete_snapshot.') volumename = snapshot['volume_name'] LOG.info(_('Delete Snapshot: %(snapshot)s: volume: %(volume)s') % {'snapshot': snapshotname, 'volume': volumename}) def _wait_for_snap_delete(snapshot, start_time): # defining CLI command snapshotname = snapshot['name'] volumename = snapshot['volume_name'] snap_destroy = ('snap', '-destroy', '-id', snapshotname, '-o') # executing CLI command out, rc = self._cli_execute(*snap_destroy) LOG.debug('Delete Snapshot: Volume: %(volumename)s Snapshot: ' '%(snapshotname)s Output: %(out)s' % {'volumename': volumename, 'snapshotname': snapshotname, 'out': out}) if rc not in [0, 9, 5]: if rc == 13: if int(time.time()) - start_time < \ self.timeout * 60: LOG.info(_('Snapshot %s is in use'), snapshotname) else: msg = (_('Failed to destroy %s ' ' because snapshot is in use.'), snapshotname) LOG.error(msg) raise exception.SnapshotIsBusy(data=msg) else: msg = (_('Failed to destroy %s'), snapshotname) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) else: raise loopingcall.LoopingCallDone() timer = loopingcall.FixedIntervalLoopingCall( _wait_for_snap_delete, snapshot, int(time.time())) timer.start(interval=self.wait_interval).wait() LOG.debug('Entering create_volume_from_snapshot.') snapshotname = snapshot['name'] volumename = volume['name'] volumesize = snapshot['volume_size'] destvolumename = volumename + 'dest' # Create a mount point, migrate data from source (snapshot) to # destination volume. The destination volume is the only new volume # to be created here. LOG.info(_('Creating Destination Volume : %s ') % (destvolumename)) poolname = self.pool_name thinness = self._get_provisioning_by_volume(volume) # defining CLI command lun_create = ('lun', '-create', '-type', thinness, '-capacity', volumesize, '-sq', 'gb', '-poolName', poolname, '-name', destvolumename) # executing CLI command out, rc = self._cli_execute(*lun_create) LOG.debug('Create temporary Volume: %(volumename)s ' 'Output : %(out)s' % {'volumename': destvolumename, 'out': out}) if rc != 0: msg = (_('Command to create the destination volume failed')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) smp_create = ('lun', '-create', '-type', 'Snap', '-primaryLunName', source_volume_name, '-name', volumename) # executing CLI command out, rc = self._cli_execute(*smp_create) LOG.debug('Create mount point : Volume: %(volumename)s ' 'Source Volume: %(sourcevolumename)s Output: %(out)s' % {'volumename': volumename, 'sourcevolumename': source_volume_name, 'out': out}) if rc != 0: msg = (_('Failed to create SMP %s'), volumename) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) lun_attach = ('lun', '-attach', '-name', volumename, '-snapName', snapshotname) # executing CLI command out, rc = self._cli_execute(*lun_attach) LOG.debug('Attaching mount point Volume: %(volumename)s ' 'with Snapshot: %(snapshotname)s Output: %(out)s' % {'volumename': volumename, 'snapshotname': snapshotname, 'out': out}) if rc != 0: msg = (_('Failed to attach snapshotname %s'), snapshotname) raise exception.VolumeBackendAPIException(data=msg) source_vol_lun = self._find_lun_id(volumename) dest_vol_lun = self._find_lun_id(destvolumename) LOG.info(_('Migrating Mount Point Volume: %s ') % (volumename)) # defining CLI command migrate_start = ('migrate', '-start', '-source', source_vol_lun, '-dest', dest_vol_lun, '-rate', 'ASAP', '-o') # executing CLI command out, rc = self._cli_execute(*migrate_start) LOG.debug('Migrate Mount Point Volume: %(volumename)s ' 'Output : %(out)s' % {'volumename': volumename, 'out': out}) if rc != 0: msg = (_('Failed to start migrating SMP %s'), volumename) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) def _wait_for_sync_status(volumename, start_time): lun_list = ('lun', '-list', '-name', volumename, '-attachedSnapshot') out, rc = self._cli_execute(*lun_list) if rc == 0: vol_details = out.split('\n') snapshotname = vol_details[2].split(':')[1].strip() if (snapshotname == 'N/A'): raise loopingcall.LoopingCallDone() else: LOG.info(_('Waiting for the update on Sync status of %s'), volumename) if int(time.time()) - start_time >= self.timeout * 60: msg = (_('Failed to really migrate %s'), volumename) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) timer = loopingcall.FixedIntervalLoopingCall( _wait_for_sync_status, volumename, int(time.time())) timer.start(interval=self.wait_interval).wait() volumesize = src_vref['size'] snapshotname = source_volume_name + '-temp-snapshot' 'name': snapshotname, 'volume_size': volumesize, } try: # Create volume self.create_volume_from_snapshot(volume, snapshot) except Exception: msg = (_('Failed to create cloned volume %s'), volume['name']) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) finally: # Delete temp Snapshot self.delete_snapshot(snapshot) def get_storage_group(self, hostname): """"""Returns the storage group for the host node."""""" storage_groupname = hostname sg_list = ('storagegroup', '-list', '-gname', storage_groupname) out, rc = self._cli_execute(*sg_list) if rc != 0: LOG.debug('creating new storage group %s', storage_groupname) sg_create = ('storagegroup', '-create', '-gname', storage_groupname) out, rc = self._cli_execute(*sg_create) LOG.debug('Create new storage group : %(storage_groupname)s, ' 'Output: %(out)s' % {'storage_groupname': storage_groupname, 'out': out}) if rc != 0: msg = (_('Failed to create SG %s'), storage_groupname) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) # connecting the new storagegroup to the host connect_host = ('storagegroup', '-connecthost', '-host', hostname, '-gname', storage_groupname, '-o') out, rc = self._cli_execute(*connect_host) LOG.debug('Connect storage group : %(storage_groupname)s ,' 'To Host : %(hostname)s, Output : %(out)s' % {'storage_groupname': storage_groupname, 'hostname': hostname, 'out': out}) if rc != 0: msg = (_('Failed to connect %s'), hostname) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) allocated_lun_id = self._find_lun_id(volume[""name""]) owner_sp = """" lun_map = {} sg_list = ('storagegroup', '-list', '-gname', storage_group) out, rc = self._cli_execute(*sg_list) if out.find('HLU/ALU Pairs') == -1: LOG.info(_('NO LUNs in the storagegroup : %s ') % (storage_group)) else: sg_details = out.split('HLU/ALU Pairs:')[1] sg_lun_details = sg_details.split('Shareable')[0] lun_details = sg_lun_details.split('\n') for data in lun_details: if data not in ['', ' HLU Number ALU Number', ' ---------- ----------']: data = data.strip() items = data.split(' ') lun_map[int(items[len(items) - 1])] = int(items[0]) for lun in lun_map.iterkeys(): if lun == int(allocated_lun_id): host_lun_id = lun_map[lun] LOG.debug('Host Lun Id : %s' % (host_lun_id)) break # finding the owner SP for the LUN lun_list = ('lun', '-list', '-l', allocated_lun_id, '-owner') out, rc = self._cli_execute(*lun_list) if rc == 0: output = out.split('\n') owner_sp = output[2].split('Current Owner: SP ')[1] LOG.debug('Owner SP : %s' % (owner_sp)) def _get_host_lun_id(self, host_lun_id_list): # Returns the host lun id for the LUN to be added # in the storage group. used_hlu_set = set(host_lun_id_list) for hlu in self.hlu_set - used_hlu_set: return hlu return None def _add_lun_to_storagegroup(self, volume, storage_group): storage_groupname = storage_group volumename = volume['name'] allocated_lun_id = self._find_lun_id(volumename) count = 0 while(count < 5): device_info = self.find_device_details(volume, storage_group) device_number = device_info['hostlunid'] if device_number < 0: lun_map = device_info['lunmap'] if lun_map: host_lun_id_list = lun_map.values() if len(host_lun_id_list) >= self.max_luns: msg = (_('The storage group has reached the ' 'maximum capacity of LUNs. ' 'Command to add LUN for volume - %s ' 'in storagegroup failed') % (volumename)) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) host_lun_id = self._get_host_lun_id(host_lun_id_list) if host_lun_id is None: msg = (_('Unable to get new host lun id. Please ' 'check if the storage group can accommodate ' 'new LUN. ' 'Command to add LUN for volume - %s ' 'in storagegroup failed') % (volumename)) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) else: host_lun_id = 1 addhlu = ('storagegroup', '-addhlu', '-o', '-gname', storage_groupname, '-hlu', host_lun_id, '-alu', allocated_lun_id) out, rc = self._cli_execute(*addhlu) LOG.debug('Add ALU %(alu)s to SG %(sg)s as %(hlu)s. ' 'Output: %(out)s' % {'alu': allocated_lun_id, 'sg': storage_groupname, 'hlu': host_lun_id, 'out': out}) if rc == 0: return host_lun_id if rc == 66: LOG.warn(_('Requested Host LUN Number already in use')) count += 1 else: LOG.warn(_('LUN was already added in the storage group')) return device_number if count == 5: msg = (_('Failed to add %s into SG') % (volumename)) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) def _remove_lun_from_storagegroup(self, device_number, storage_group): storage_groupname = storage_group removehlu = ('storagegroup', '-removehlu', '-gname', storage_groupname, '-hlu', device_number, '-o') out, rc = self._cli_execute(*removehlu) LOG.debug('Remove %(hlu)s from SG %(sg)s. Output: %(out)s' % {'hlu': device_number, 'sg': storage_groupname, 'out': out}) if rc != 0: msg = (_('Failed to remove %(hlu)s from %(sg)s') % {'hlu': device_number, 'sg': storage_groupname}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) def initialize_connection(self, volume, connector): """"""Initializes the connection and returns connection info."""""" storage_group = self.get_storage_group(hostname) device_number = self._add_lun_to_storagegroup(volume, storage_group) return device_number hostname = connector['host'] storage_group = self.get_storage_group(hostname) device_info = self.find_device_details(volume, storage_group) device_number = device_info['hostlunid'] if device_number < 0: LOG.error(_('Could not locate the attached volume.')) else: self._remove_lun_from_storagegroup(device_number, storage_group) def _find_iscsi_protocol_endpoints(self, device_sp): initiator_address = [] connection_getport = ('connection', '-getport', '-sp', device_sp) out, _rc = self._cli_execute(*connection_getport) output = out.split('SP: ') for port in output: port_info = port.split('\n') if port_info[0] == device_sp: port_wwn = port_info[2].split('Port WWN:')[1].strip() initiator_address.append(port_wwn) LOG.debug('WWNs found for SP %(devicesp)s ' 'are: %(initiator_address)s' % {'devicesp': device_sp, 'initiator_address': initiator_address}) return initiator_address def _get_volumetype_extraspecs(self, volume): def _get_provisioning_by_volume(self, volume): # By default, the user can not create thin LUN without thin # provisioning enabler. thinness = 'NonThin' spec_id = 'storagetype:provisioning' specs = self._get_volumetype_extraspecs(volume) if specs and spec_id in specs: provisioning = specs[spec_id].lower() if 'thin' == provisioning: thinness = 'Thin' elif 'thick' != provisioning: LOG.warning(_('Invalid value of extra spec ' '\'storagetype:provisioning\': %(provisioning)s') % {'provisioning': specs[spec_id]}) else: LOG.info(_('No extra spec \'storagetype:provisioning\' exist')) return thinness",4910,1149
openstack%2Fnova~master~I4e27580964558d8f68da108fbca5eaf9565c99fd,openstack/nova,master,I4e27580964558d8f68da108fbca5eaf9565c99fd,Modify filters to get aggregate metadata from request_spec,ABANDONED,2014-06-19 12:38:35.000000000,2014-08-08 04:53:29.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 5170}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-19 12:38:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/be232200342e118a269c193fdf9e35e52de30578', 'message': 'Modify filters to get aggregate metadata from request_spec\n\nModify some scheduler filters to look into HostState\nand get the aggregate metadata from request_spec.\n\nCo-Authored-By: Sylvain Bauza <sbauza@redhat.com>\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I4e27580964558d8f68da108fbca5eaf9565c99fd\n'}, {'number': 2, 'created': '2014-07-01 10:50:28.000000000', 'files': ['nova/tests/scheduler/test_filters_utils.py', 'nova/scheduler/filters/availability_zone_filter.py', 'nova/scheduler/filters/utils.py', 'nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/core_filter.py', 'nova/scheduler/filters/ram_filter.py', 'nova/scheduler/filters/type_filter.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/58648e39d1507b9ea7ad1772bc08fb9e8626abb3', 'message': 'Modify filters to get aggregate metadata from request_spec\n\nModify some scheduler filters to look into HostState\nand get the aggregate metadata from request_spec.\n\nCo-Authored-By: Sylvain Bauza <sbauza@redhat.com>\nImplements: blueprint isolate-scheduler-db\n\nChange-Id: I4e27580964558d8f68da108fbca5eaf9565c99fd\n'}]",0,101196,58648e39d1507b9ea7ad1772bc08fb9e8626abb3,19,8,2,7641,,,0,"Modify filters to get aggregate metadata from request_spec

Modify some scheduler filters to look into HostState
and get the aggregate metadata from request_spec.

Co-Authored-By: Sylvain Bauza <sbauza@redhat.com>
Implements: blueprint isolate-scheduler-db

Change-Id: I4e27580964558d8f68da108fbca5eaf9565c99fd
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/101196/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/scheduler/test_filters_utils.py', 'nova/scheduler/filters/availability_zone_filter.py', 'nova/scheduler/filters/utils.py', 'nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/core_filter.py', 'nova/scheduler/filters/ram_filter.py', 'nova/scheduler/filters/type_filter.py']",7,be232200342e118a269c193fdf9e35e52de30578,bp/isolate-scheduler-db," metadata = utils.get_aggregates_from_request_spec( host_state, filter_properties) aggregate_vals = metadata.get('instance_type')"," # TODO(uni): DB query in filter is a performance hit, especially for # system with lots of hosts. Will need a general solution here to fix # all filters with aggregate DB call things. aggregate_vals = utils.aggregate_values_from_db( filter_properties['context'], host_state.host, 'instance_type') ",44,94
openstack%2Fmanila~master~I03d0d09aeef016e48b4507c067774f5e45e73be0,openstack/manila,master,I03d0d09aeef016e48b4507c067774f5e45e73be0,Remove unused imports,MERGED,2014-08-06 14:43:50.000000000,2014-08-08 04:35:43.000000000,2014-08-08 04:35:42.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-08-06 14:43:50.000000000', 'files': ['manila/share/driver.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/80c510e76efd3f1e981c5f4c9290c51dce5d22eb', 'message': 'Remove unused imports\n\nRemove unused imports from module manila.share.drivers.\n\nChange-Id: I03d0d09aeef016e48b4507c067774f5e45e73be0\n'}]",0,112319,80c510e76efd3f1e981c5f4c9290c51dce5d22eb,10,4,1,12631,,,0,"Remove unused imports

Remove unused imports from module manila.share.drivers.

Change-Id: I03d0d09aeef016e48b4507c067774f5e45e73be0
",git fetch https://review.opendev.org/openstack/manila refs/changes/19/112319/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/share/driver.py'],1,80c510e76efd3f1e981c5f4c9290c51dce5d22eb,,,import ConfigParser import os import refrom manila.share.configuration import Configuration,0,4
openstack%2Ftempest~master~Ia09e84d7acfcd7291b3c9b58bc163603d6a0fb34,openstack/tempest,master,Ia09e84d7acfcd7291b3c9b58bc163603d6a0fb34,Add interface_attach compute feature flag,MERGED,2014-07-23 13:46:25.000000000,2014-08-08 04:30:51.000000000,2014-08-08 04:30:50.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2750}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-23 13:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ef143f7f3e016711ac69c64272153396a094e5cd', 'message': 'Add interface_attach compute feature flag\n\nDynamic attachment of network interfaces is not currently a supported feature\nin the baremetal case.  This adds feature flag to skip related API tests.\n\nChange-Id: Ia09e84d7acfcd7291b3c9b58bc163603d6a0fb34\n'}, {'number': 2, 'created': '2014-07-23 13:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d8be626d3b62a0a3f57a15d56bb352b6a60cc6ff', 'message': 'Add interface_attach compute feature flag\n\nDynamic attachment of network interfaces is not currently a supported feature\nin the baremetal case.  This adds feature flag to skip related API tests.\n\nChange-Id: Ia09e84d7acfcd7291b3c9b58bc163603d6a0fb34\n'}, {'number': 3, 'created': '2014-07-29 16:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e2dfb3b715beaed3c7420f92c25d25283a8973b8', 'message': 'Add interface_attach compute feature flag\n\nDynamic attachment of network interfaces is not currently a supported feature\nin the baremetal case.  This adds feature flag to skip related API tests.\n\nChange-Id: Ia09e84d7acfcd7291b3c9b58bc163603d6a0fb34\n'}, {'number': 4, 'created': '2014-08-04 17:45:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/72d6a85941b0d8a7f770a641cd87a294b78974d3', 'message': 'Add interface_attach compute feature flag\n\nDynamic attachment of network interfaces is not currently a supported feature\nin the baremetal case.  This adds feature flag to skip related API tests.\n\nChange-Id: Ia09e84d7acfcd7291b3c9b58bc163603d6a0fb34\n'}, {'number': 5, 'created': '2014-08-06 23:40:10.000000000', 'files': ['tempest/api/compute/servers/test_attach_interfaces.py', 'tempest/api/compute/v3/servers/test_attach_interfaces.py', 'tempest/scenario/test_network_basic_ops.py', 'etc/tempest.conf.sample', 'tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7186f7a668328184ba6ec8e84446e87d816bf771', 'message': 'Add interface_attach compute feature flag\n\nDynamic attachment of network interfaces is not currently a supported feature\nin the baremetal case.  This adds feature flag to skip related API tests.\n\nChange-Id: Ia09e84d7acfcd7291b3c9b58bc163603d6a0fb34\n'}]",1,108995,7186f7a668328184ba6ec8e84446e87d816bf771,50,9,5,1420,,,0,"Add interface_attach compute feature flag

Dynamic attachment of network interfaces is not currently a supported feature
in the baremetal case.  This adds feature flag to skip related API tests.

Change-Id: Ia09e84d7acfcd7291b3c9b58bc163603d6a0fb34
",git fetch https://review.opendev.org/openstack/tempest refs/changes/95/108995/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/servers/test_attach_interfaces.py', 'tempest/scenario/test_network_basic_ops.py', 'etc/tempest.conf.sample', 'tempest/config.py']",4,ef143f7f3e016711ac69c64272153396a094e5cd,ironic_tempest," 'mode?'), cfg.BoolOpt('interface_attach', default=True, help='Does the test environment support dynamic network ' 'interface attachment?')", 'mode?'),14,2
openstack%2Foslo.messaging~master~Iee5f6a952d9b12c6c8a4a79ef656fc7f94170776,openstack/oslo.messaging,master,Iee5f6a952d9b12c6c8a4a79ef656fc7f94170776,Enable check for E226,MERGED,2014-07-21 06:10:04.000000000,2014-08-08 04:29:20.000000000,2014-08-08 04:29:19.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1994}, {'_account_id': 7763}]","[{'number': 1, 'created': '2014-07-21 06:10:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/90048cbbb04f0cad7c69a2ec0ed1fe425d9c00d4', 'message': 'Enable check for E226\n\n* E226 missing whitespace around arithmetic operator\n\nChange-Id: Iee5f6a952d9b12c6c8a4a79ef656fc7f94170776\n'}, {'number': 2, 'created': '2014-07-21 11:12:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/6ee50e4c552415f99b0cc361c747d5661513e7e6', 'message': 'Enable check for E226\n\n* E226 missing whitespace around arithmetic operator\n\nChange-Id: Iee5f6a952d9b12c6c8a4a79ef656fc7f94170776\n'}, {'number': 3, 'created': '2014-07-23 18:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/15b367b8dd221908c92931efc5024ac5978597b6', 'message': 'Enable check for E226\n\n* E226 missing whitespace around arithmetic operator\n\nChange-Id: Iee5f6a952d9b12c6c8a4a79ef656fc7f94170776\n'}, {'number': 4, 'created': '2014-08-04 12:15:34.000000000', 'files': ['tests/drivers/test_impl_rabbit.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/500f1e5dca632de638b8aa0e747d2ffca242ae40', 'message': 'Enable check for E226\n\n* E226 missing whitespace around arithmetic operator\n\nChange-Id: Iee5f6a952d9b12c6c8a4a79ef656fc7f94170776\n'}]",0,108278,500f1e5dca632de638b8aa0e747d2ffca242ae40,23,4,4,167,,,0,"Enable check for E226

* E226 missing whitespace around arithmetic operator

Change-Id: Iee5f6a952d9b12c6c8a4a79ef656fc7f94170776
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/78/108278/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/drivers/test_impl_rabbit.py', 'tox.ini']",2,90048cbbb04f0cad7c69a2ec0ed1fe425d9c00d4,add_requirement_argparse,"ignore = E241,E265,E714,H237,H402,H405,H904","ignore = E226,E241,E265,E714,H237,H402,H405,H904",2,2
openstack%2Fpython-keystoneclient~master~I769b4e2cd59a4dd167c4dcd8f14641081f867a71,openstack/python-keystoneclient,master,I769b4e2cd59a4dd167c4dcd8f14641081f867a71,Isolate get_discovery function,MERGED,2014-07-17 06:37:26.000000000,2014-08-08 04:05:39.000000000,2014-08-08 04:05:39.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 2903}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 11045}, {'_account_id': 11333}]","[{'number': 1, 'created': '2014-07-17 06:37:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/c37d8518a09a1635acbdbcd3cee7a96ba7258a3f', 'message': 'Isolate get_discovery function\n\nWhen we get to having version independent identity plugins they need to\nbe able to share the discovery cache with the session. This function\nshould therefore be reusable rather than making the cache on the session\npublic.\n\nChange-Id: I769b4e2cd59a4dd167c4dcd8f14641081f867a71\n'}, {'number': 2, 'created': '2014-07-20 01:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/e9880e2f9b3a4b5c7076122394aec1bb60590f29', 'message': 'Isolate get_discovery function\n\nWhen we get to having version independent identity plugins they need to\nbe able to share the discovery cache with the session. This function\nshould therefore be reusable rather than making the cache on the session\npublic.\n\nChange-Id: I769b4e2cd59a4dd167c4dcd8f14641081f867a71\n'}, {'number': 3, 'created': '2014-07-31 00:36:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/5cf78bf54cdb310a2af62ff7fe3f147eeae0eca4', 'message': 'Isolate get_discovery function\n\nWhen we get to having version independent identity plugins they need to\nbe able to share the discovery cache with the session. This function\nshould therefore be reusable rather than making the cache on the session\npublic.\n\nChange-Id: I769b4e2cd59a4dd167c4dcd8f14641081f867a71\n'}, {'number': 4, 'created': '2014-08-04 02:22:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/411931fad14b3ca7395a48b536dbea3ac4871fa0', 'message': 'Isolate get_discovery function\n\nWhen we get to having version independent identity plugins they need to\nbe able to share the discovery cache with the session. This function\nshould therefore be reusable rather than making the cache on the session\npublic.\n\nChange-Id: I769b4e2cd59a4dd167c4dcd8f14641081f867a71\n'}, {'number': 5, 'created': '2014-08-05 19:59:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/b78e89015ccc5597a54d5dc974649ea57f527530', 'message': 'Isolate get_discovery function\n\nWhen we get to having version independent identity plugins they need to\nbe able to share the discovery cache with the session. This function\nshould therefore be reusable rather than making the cache on the session\npublic.\n\nChange-Id: I769b4e2cd59a4dd167c4dcd8f14641081f867a71\n'}, {'number': 6, 'created': '2014-08-05 23:56:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/60e5e565414c544eb9d07dd0bceefc87559dec04', 'message': 'Isolate get_discovery function\n\nWhen we get to having version independent identity plugins they need to\nbe able to share the discovery cache with the session. This function\nshould therefore be reusable rather than making the cache on the session\npublic.\n\nDocImpact: Adds a new get_discovery function to identity plugins. This\nfunction is expected to be used by subclasses doing custom URL discovery\nrather than users.\n\nBlueprint: version-independant-plugins\nChange-Id: I769b4e2cd59a4dd167c4dcd8f14641081f867a71\n'}, {'number': 7, 'created': '2014-08-06 23:32:38.000000000', 'files': ['keystoneclient/auth/identity/base.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/5d2264051d3fdc9043201a38042daea4d1f3b577', 'message': 'Isolate get_discovery function\n\nWhen we get to having version independent identity plugins they need to\nbe able to share the discovery cache with the session. This function\nshould therefore be reusable rather than making the cache on the session\npublic.\n\nDocImpact: Adds a new get_discovery function to identity plugins. This\nfunction is expected to be used by subclasses doing custom URL discovery\nrather than users.\n\nBlueprint: version-independant-plugins\nChange-Id: I769b4e2cd59a4dd167c4dcd8f14641081f867a71\n'}]",8,107569,5d2264051d3fdc9043201a38042daea4d1f3b577,45,7,7,7191,,,0,"Isolate get_discovery function

When we get to having version independent identity plugins they need to
be able to share the discovery cache with the session. This function
should therefore be reusable rather than making the cache on the session
public.

DocImpact: Adds a new get_discovery function to identity plugins. This
function is expected to be used by subclasses doing custom URL discovery
rather than users.

Blueprint: version-independant-plugins
Change-Id: I769b4e2cd59a4dd167c4dcd8f14641081f867a71
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/69/107569/2 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/auth/identity/base.py'],1,c37d8518a09a1635acbdbcd3cee7a96ba7258a3f,isolate-disc," url = service_catalog.url_for(service_type=service_type, endpoint_type=interface, region_name=region_name, service_name=service_name) return url try: return self.get_discovery(session, url).url_for(version) except exceptions.DiscoveryFailure: # NOTE(jamielennox): Again if we can't contact the server we fall # back to just returning the URL from the catalog. This may not be # the best default but we need it for now. return url def get_discovery(self, session, url): """"""Return the discovery object for a URL. Check the session and the plugin cache to see if we have already performed discovery on the URL and if so return it, otherwise create a new discovery object, cache it and return it. :param Session session: A session object to discover with. :param str url: The url to lookup. :raises: DiscoveryFailure if for some reason the lookup fails. :return: A discovery object with the results of looking up that URL. """""" disc = cache.get(url) disc = _discover.Discover(session, url) 'base url.', url) raise exceptions.DiscoveryFailure() else: self._endpoint_cache[url] = disc session_endpoint_cache[url] = disc return disc"," sc_url = service_catalog.url_for(service_type=service_type, endpoint_type=interface, region_name=region_name, service_name=service_name) return sc_url disc = None disc = cache.get(sc_url) disc = _discover.Discover(session, sc_url) 'base url.', sc_url) return sc_url else: self._endpoint_cache[sc_url] = disc session_endpoint_cache[sc_url] = disc return disc.url_for(version)",33,13
openstack%2Fpython-keystoneclient~master~Ib01f6341e087866ca05862c200e6c783fb1a8ff5,openstack/python-keystoneclient,master,Ib01f6341e087866ca05862c200e6c783fb1a8ff5,expose the revoke token for V3,MERGED,2014-06-26 02:51:25.000000000,2014-08-08 03:26:44.000000000,2014-08-08 03:26:43.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 1916}, {'_account_id': 1941}, {'_account_id': 6486}, {'_account_id': 8871}, {'_account_id': 9101}, {'_account_id': 9500}, {'_account_id': 11045}, {'_account_id': 11387}, {'_account_id': 11428}]","[{'number': 1, 'created': '2014-06-26 02:51:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/cc756cfa92e6255a228bed76a2905cb7a4385984', 'message': 'expose the revoke token for V3\n\nImplement the v3 revoke token method for CLI.\n\nChange-Id: Ib01f6341e087866ca05862c200e6c783fb1a8ff5\nCloses-Bug: #1331972\n'}, {'number': 2, 'created': '2014-06-28 08:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/113ce5dbb80b0078e1370a9520bf96e76e48c15d', 'message': 'expose the revoke token for V3\n\nImplement the v3 revoke token method for CLI.\n\nChange-Id: Ib01f6341e087866ca05862c200e6c783fb1a8ff5\nCloses-Bug: #1331972\n'}, {'number': 3, 'created': '2014-07-21 07:26:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/d8f381fff0fb4e7ddb72f3b28ce1507ce9e73a84', 'message': 'expose the revoke token for V3\n\nImplement the v3 revoke token method for CLI.\n\nChange-Id: Ib01f6341e087866ca05862c200e6c783fb1a8ff5\nCloses-Bug: #1331972\n'}, {'number': 4, 'created': '2014-07-23 08:10:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/c0c027524f83bc744fbd8b7ee7c00f592eb638be', 'message': 'expose the revoke token for V3\n\nImplement the v3 revoke token method for CLI.\n\nChange-Id: Ib01f6341e087866ca05862c200e6c783fb1a8ff5\nCloses-Bug: #1331972\n'}, {'number': 5, 'created': '2014-08-05 03:49:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/06af4f6d4e3ff1201c3d2796f12a8972d5e200a6', 'message': 'expose the revoke token for V3\n\nImplement the v3 revoke token method for CLI.\n\nChange-Id: Ib01f6341e087866ca05862c200e6c783fb1a8ff5\nCloses-Bug: #1331972\n'}, {'number': 6, 'created': '2014-08-05 03:59:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/1d20aedf7cec112024cefb0f6f5bdaa4802ef66a', 'message': 'expose the revoke token for V3\n\nImplement the v3 revoke token method for CLI.\n\nChange-Id: Ib01f6341e087866ca05862c200e6c783fb1a8ff5\nCloses-Bug: #1331972\n'}, {'number': 7, 'created': '2014-08-06 01:44:20.000000000', 'files': ['keystoneclient/v3/client.py', 'keystoneclient/tests/v3/test_tokens.py', 'keystoneclient/v3/tokens.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/07d45effefcf9716d6d1a3387c9b921c662338d5', 'message': 'expose the revoke token for V3\n\nImplement the v3 revoke token method for CLI.\n\nChange-Id: Ib01f6341e087866ca05862c200e6c783fb1a8ff5\nCloses-Bug: #1331972\n'}]",17,102701,07d45effefcf9716d6d1a3387c9b921c662338d5,62,12,7,9101,,,0,"expose the revoke token for V3

Implement the v3 revoke token method for CLI.

Change-Id: Ib01f6341e087866ca05862c200e6c783fb1a8ff5
Closes-Bug: #1331972
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/01/102701/6 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/v3/client.py', 'keystoneclient/tests/v3/test_tokens.py', 'keystoneclient/v3/tokens.py']",3,cc756cfa92e6255a228bed76a2905cb7a4385984,bug/1331972,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from keystoneclient import access from keystoneclient import base class TokenManager(object): """"""Manager class for manipulating Identity tokens."""""" def __init__(self, client): self._client = client def revoke_token(self, token): if isinstance(token, access.AccessInfo): revoke_token_url = '/auth/tokens/%s' % token.auth_token else: revoke_token_url = '/auth/tokens/%s' % base.getid(token) return self._client.delete(revoke_token_url) ",,72,0
openstack-attic%2Fidentity-api~master~Ibf2fd038f58479dea507ed06bda4cf443c3f6a64,openstack-attic/identity-api,master,Ibf2fd038f58479dea507ed06bda4cf443c3f6a64,add name filter on list services,MERGED,2014-08-04 20:27:39.000000000,2014-08-08 03:09:19.000000000,2014-08-08 03:09:19.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-08-04 20:27:39.000000000', 'files': ['v3/src/markdown/identity-api-v3.md'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/914df791754f4ce3d239bd295a7a2086dc642c6d', 'message': 'add name filter on list services\n\nChange-Id: Ibf2fd038f58479dea507ed06bda4cf443c3f6a64\nRelated-Bug: 1350273\n'}]",0,111818,914df791754f4ce3d239bd295a7a2086dc642c6d,13,13,1,4,,,0,"add name filter on list services

Change-Id: Ibf2fd038f58479dea507ed06bda4cf443c3f6a64
Related-Bug: 1350273
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/18/111818/1 && git format-patch -1 --stdout FETCH_HEAD,['v3/src/markdown/identity-api-v3.md'],1,914df791754f4ce3d239bd295a7a2086dc642c6d,bug/1350273,- `name` (string) *New in version 3.3*,,1,0
openstack%2Fnova~master~If5f91de020ed8a40fa04fc001c7c4c92681f4ad1,openstack/nova,master,If5f91de020ed8a40fa04fc001c7c4c92681f4ad1,API: Enable support for tenant option in nova absolute-limits,MERGED,2014-07-01 03:31:12.000000000,2014-08-08 02:53:40.000000000,2014-08-07 05:58:23.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 8247}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10294}, {'_account_id': 10385}, {'_account_id': 10618}]","[{'number': 1, 'created': '2014-07-01 03:31:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6e684b1a9381091decf2e993adc9796835d51e0a', 'message': 'API: Enable support for tenant option in nova absolute-limits\n\nWhen querying for the absolute limits of a specific tenant,\nthe tenant option is ignored. There are no attempts to extract\nthe tenant from the request. Instead, nova uses context.project_id\nas the project_id in QUOTAS.get_project_quotas. The following\npatch extracts the tenant_id from the request (if any) and passes\nthat to QUOTAS.get_project_quotas to obtain the proper quota.\n\nChange-Id: If5f91de020ed8a40fa04fc001c7c4c92681f4ad1\nCloses-Bug: #1334278\n'}, {'number': 2, 'created': '2014-07-01 15:25:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/33405cfa5932bf4600c53042c376fff2b1f2bedc', 'message': 'API: Enable support for tenant option in nova absolute-limits\n\nWhen querying for the absolute limits of a specific tenant,\nthe tenant option is ignored. There are no attempts to extract\nthe tenant from the request. Instead, nova uses context.project_id\nas the project_id in QUOTAS.get_project_quotas. The following\npatch extracts the tenant_id from the request (if any) and passes\nthat to QUOTAS.get_project_quotas to obtain the proper quota.\n\nChange-Id: If5f91de020ed8a40fa04fc001c7c4c92681f4ad1\nCloses-Bug: #1334278\n'}, {'number': 3, 'created': '2014-07-15 01:38:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9921ff7781789ed6cba44fb702967b96a1c28742', 'message': 'API: Enable support for tenant option in nova absolute-limits\n\nWhen querying for the absolute limits of a specific tenant,\nthe tenant option is ignored. There are no attempts to extract\nthe tenant from the request. Instead, nova uses context.project_id\nas the project_id in QUOTAS.get_project_quotas. The following\npatch extracts the tenant_id from the request (if any) and passes\nthat to QUOTAS.get_project_quotas to obtain the proper quota.\n\nDocImpact: tenant_id parameter supported when querying limits\nChange-Id: If5f91de020ed8a40fa04fc001c7c4c92681f4ad1\nCloses-Bug: #1334278\n'}, {'number': 4, 'created': '2014-07-15 03:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d0d251007abd51b41f70204b8560fd5244ab06e2', 'message': 'API: Enable support for tenant option in nova absolute-limits\n\nWhen querying for the absolute limits of a specific tenant,\nthe tenant option is ignored. There are no attempts to extract\nthe tenant from the request. Instead, nova uses context.project_id\nas the project_id in QUOTAS.get_project_quotas. The following\npatch extracts the tenant_id from the request (if any) and passes\nthat to QUOTAS.get_project_quotas to obtain the proper quota.\n\nChange-Id: If5f91de020ed8a40fa04fc001c7c4c92681f4ad1\nCloses-Bug: #1334278\n'}, {'number': 5, 'created': '2014-07-15 03:45:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eff829c669bd095d5d59c8f037d16715b2fd1e4a', 'message': 'API: Enable support for tenant option in nova absolute-limits\n\nWhen querying for the absolute limits of a specific tenant,\nthe tenant option is ignored. There are no attempts to extract\nthe tenant from the request. Instead, nova uses context.project_id\nas the project_id in QUOTAS.get_project_quotas. The following\npatch extracts the tenant_id from the request (if any) and passes\nthat to QUOTAS.get_project_quotas to obtain the proper quota.\n\nChange-Id: If5f91de020ed8a40fa04fc001c7c4c92681f4ad1\nCloses-Bug: #1334278\n'}, {'number': 6, 'created': '2014-07-24 20:35:14.000000000', 'files': ['nova/api/openstack/compute/limits.py', 'nova/tests/api/openstack/compute/test_limits.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2e6b2404155156ca336dadeacc8874645ca07bfc', 'message': 'API: Enable support for tenant option in nova absolute-limits\n\nWhen querying for the absolute limits of a specific tenant,\nthe tenant option is ignored. There are no attempts to extract\nthe tenant from the request. Instead, nova uses context.project_id\nas the project_id in QUOTAS.get_project_quotas. The following\npatch extracts the tenant_id from the request (if any) and passes\nthat to QUOTAS.get_project_quotas to obtain the proper quota.\n\nChange-Id: If5f91de020ed8a40fa04fc001c7c4c92681f4ad1\nCloses-Bug: #1334278\n'}]",13,103709,2e6b2404155156ca336dadeacc8874645ca07bfc,94,16,6,8247,,,0,"API: Enable support for tenant option in nova absolute-limits

When querying for the absolute limits of a specific tenant,
the tenant option is ignored. There are no attempts to extract
the tenant from the request. Instead, nova uses context.project_id
as the project_id in QUOTAS.get_project_quotas. The following
patch extracts the tenant_id from the request (if any) and passes
that to QUOTAS.get_project_quotas to obtain the proper quota.

Change-Id: If5f91de020ed8a40fa04fc001c7c4c92681f4ad1
Closes-Bug: #1334278
",git fetch https://review.opendev.org/openstack/nova refs/changes/09/103709/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/limits.py', 'nova/tests/api/openstack/compute/test_limits.py']",2,6e684b1a9381091decf2e993adc9796835d51e0a,bug/1334278,"import mockimport urllib self._test_index_json() def test_index_json_by_tenant(self): self._test_index_json('faketenant') def _test_index_json(self, query_tenant_id=None): context = nova.context.RequestContext('testuser', 'testproject') request.environ[""nova.context""] = context if query_tenant_id: request.environ[""QUERY_STRING""] = \ urllib.urlencode({'tenant_id': query_tenant_id}) else: query_tenant_id = context.project_id def _get_project_quotas(context, project_id, usages=True): return dict((k, dict(limit=v)) for k, v in self.absolute_limits.items()) with mock.patch('nova.quota.QUOTAS.get_project_quotas') as \ get_project_quotas: get_project_quotas.side_effect = _get_project_quotas response = request.get_response(self.controller) body = jsonutils.loads(response.body) self.assertEqual(expected, body) get_project_quotas.assert_called_once_with(context, query_tenant_id, usages=False)"," response = request.get_response(self.controller) body = jsonutils.loads(response.body) self.assertEqual(expected, body)",36,4
openstack%2Foslo-incubator~master~I0ae141ed9b68f847dccbf7beb43551a978a344ae,openstack/oslo-incubator,master,I0ae141ed9b68f847dccbf7beb43551a978a344ae,Fix E126 pep8 errors,MERGED,2014-07-31 10:14:51.000000000,2014-08-08 02:46:37.000000000,2014-08-08 02:46:37.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 1994}, {'_account_id': 6601}, {'_account_id': 8041}, {'_account_id': 9796}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-07-31 10:14:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/426576afee6c0f87c9616dccaf817efec541c040', 'message': 'Fix E126 pep8 errors\n\nThat allows other projects using the incubator to stop ignoring them\ntoo.\n\nChange-Id: I0ae141ed9b68f847dccbf7beb43551a978a344ae\n'}, {'number': 2, 'created': '2014-08-01 09:39:17.000000000', 'files': ['openstack/common/lockutils.py', 'openstack/common/log.py', 'openstack/common/apiclient/client.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/ac995bec524967d6e13c488343a318c3c8ae8694', 'message': 'Fix E126 pep8 errors\n\nChange-Id: I0ae141ed9b68f847dccbf7beb43551a978a344ae\n'}]",1,110892,ac995bec524967d6e13c488343a318c3c8ae8694,21,7,2,1669,,,0,"Fix E126 pep8 errors

Change-Id: I0ae141ed9b68f847dccbf7beb43551a978a344ae
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/92/110892/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/lockutils.py', 'openstack/common/log.py', 'openstack/common/apiclient/client.py', 'tox.ini']",4,426576afee6c0f87c9616dccaf817efec541c040,jd/fix-E126,"ignore = E123,H405,H904","ignore = E123,E126,H405,H904",8,11
openstack%2Fnova~master~I2cd65f26097f154f1a4f794916c74cd1730ae142,openstack/nova,master,I2cd65f26097f154f1a4f794916c74cd1730ae142,Correct InvalidAggregateAction reason for Xen,MERGED,2014-08-06 05:24:14.000000000,2014-08-08 01:55:08.000000000,2014-08-08 01:55:05.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 9545}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-06 05:24:14.000000000', 'files': ['nova/tests/virt/xenapi/test_xenapi.py', 'nova/virt/xenapi/pool.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a4e3ea4fdaeb4f850f3deb2b7098da19d015d7b9', 'message': ""Correct InvalidAggregateAction reason for Xen\n\nCurrently the xenapi will report InvalidAggregateAction\nwhen add aggreate under some conditions. But the reason\ndidn't use the pre-defined reason list.\n\nChange-Id: I2cd65f26097f154f1a4f794916c74cd1730ae142\n""}]",1,112193,a4e3ea4fdaeb4f850f3deb2b7098da19d015d7b9,19,9,1,6062,,,0,"Correct InvalidAggregateAction reason for Xen

Currently the xenapi will report InvalidAggregateAction
when add aggreate under some conditions. But the reason
didn't use the pre-defined reason list.

Change-Id: I2cd65f26097f154f1a4f794916c74cd1730ae142
",git fetch https://review.opendev.org/openstack/nova refs/changes/93/112193/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/xenapi/test_xenapi.py', 'nova/virt/xenapi/pool.py']",2,a4e3ea4fdaeb4f850f3deb2b7098da19d015d7b9,update_xen_pool_invalid_agg_reason, reason=invalid[aggregate['metadata'][pool_states.KEY]]), reason=aggregate['metadata'][pool_states.KEY]),13,10
openstack%2Fcookbook-openstack-block-storage~master~I4da5c1b979b2485d743cfd4a5ba6df3604c8cd92,openstack/cookbook-openstack-block-storage,master,I4da5c1b979b2485d743cfd4a5ba6df3604c8cd92,Change gpfs driver path from cinder.volume.drivers.gpfs.GPFSDriver to cinder.volume.drivers.ibm.gpfs.GPFSDriver.This Driver is defined in https://github.com/openstack/cinder/blob/master/cinder/volume/drivers/ibm/gpfs.py,ABANDONED,2014-08-01 06:38:58.000000000,2014-08-08 01:50:47.000000000,,"[{'_account_id': 3}, {'_account_id': 8410}]","[{'number': 1, 'created': '2014-08-01 06:38:58.000000000', 'files': ['recipes/volume.rb', 'spec/volume-redhat_spec.rb', 'spec/cinder_common_spec.rb', 'templates/default/cinder.conf.erb', 'CHANGELOG.md', 'README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/f4f5cea92018fb066966b47e2811a31204d5f966', 'message': 'Change gpfs driver path from cinder.volume.drivers.gpfs.GPFSDriver to\ncinder.volume.drivers.ibm.gpfs.GPFSDriver.This Driver is defined in https://github.com/openstack/cinder/blob/master/cinder/volume/drivers/ibm/gpfs.py\n\nChange-Id: I4da5c1b979b2485d743cfd4a5ba6df3604c8cd92\n'}]",2,111178,f4f5cea92018fb066966b47e2811a31204d5f966,5,2,1,8666,,,0,"Change gpfs driver path from cinder.volume.drivers.gpfs.GPFSDriver to
cinder.volume.drivers.ibm.gpfs.GPFSDriver.This Driver is defined in https://github.com/openstack/cinder/blob/master/cinder/volume/drivers/ibm/gpfs.py

Change-Id: I4da5c1b979b2485d743cfd4a5ba6df3604c8cd92
",git fetch https://review.opendev.org/openstack/cookbook-openstack-block-storage refs/changes/78/111178/1 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/volume.rb', 'spec/volume-redhat_spec.rb', 'spec/cinder_common_spec.rb', 'templates/default/cinder.conf.erb', 'CHANGELOG.md', 'README.md']",6,f4f5cea92018fb066966b47e2811a31204d5f966,bug/1347447, - **cinder.volume.drivers.ibm.gpfs.GPFSDriver** - IBM General Parallel File System driver, - **cinder.volume.drivers.gpfs.GPFSDriver** - IBM General Parallel File System driver,9,7
openstack%2Fnova~master~I879916021c3b61f19dd69ff11838dbbac19f72d1,openstack/nova,master,I879916021c3b61f19dd69ff11838dbbac19f72d1,Method to filter non-root block device mappings,MERGED,2014-06-13 17:46:40.000000000,2014-08-08 01:48:18.000000000,2014-07-27 17:00:10.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 642}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 7746}, {'_account_id': 8430}, {'_account_id': 8802}, {'_account_id': 9008}, {'_account_id': 9275}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10618}]","[{'number': 1, 'created': '2014-06-13 17:46:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7fcc637f79f350470e07575b730c043916e1c329', 'message': ""Method to filter only non root block device mappings\n\nAdding a method to filter only the non-root block device mappings.\nThe method will have an optional variable to keep root device in\nthe reported mappings.\nThe method will be needed to handle LXC volumes, as it's root FS\nshould be handled differently.\n\nChange-Id: I879916021c3b61f19dd69ff11838dbbac19f72d1\nRelated-Bug: #1269990\n""}, {'number': 2, 'created': '2014-07-02 01:10:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ac73a60eda447e5e0186695610df4961a270f806', 'message': ""Method to filter only non root block device mappings\n\nAdding a method to filter only the non-root block device mappings.\nThe method will have an optional variable to keep root device in\nthe reported mappings.\nThe method will be needed to handle LXC volumes, as it's root FS\nshould be handled differently.\n\nChange-Id: I879916021c3b61f19dd69ff11838dbbac19f72d1\nRelated-Bug: #1269990\n""}, {'number': 3, 'created': '2014-07-08 13:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6fe92801feb528574fcd04e078fc48f5d42bbdf7', 'message': ""Method to filter only non root block device mappings\n\nAdding a method to filter only the non-root block device mappings.\nThe method will have an optional variable to keep root device in\nthe reported mappings.\nThe method will be needed to handle LXC volumes, as it's root FS\nshould be handled differently.\n\nChange-Id: I879916021c3b61f19dd69ff11838dbbac19f72d1\nRelated-Bug: #1269990\n""}, {'number': 4, 'created': '2014-07-10 13:42:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7d797aceb66dbb6183cd5b1ab772a3223a3d9157', 'message': ""Method to filter non-root block device mappings\n\nAdding a generator that would provide a non-root block device\nmappings, when it's optional variable exclude_root_mapping is\nset to true. Otherwise, all mappings will be returned.\n\nThe method will be used to handle LXC volumes, as it's root FS\nshould be handled differently.\n\nChange-Id: I879916021c3b61f19dd69ff11838dbbac19f72d1\nRelated-Bug: #1269990\n""}, {'number': 5, 'created': '2014-07-18 20:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b0a0a5c679a38a1b556b2ec3d4581b8d23ffcdc', 'message': ""Method to filter non-root block device mappings\n\nAdding a generator that would provide a non-root block device\nmappings, when it's optional variable exclude_root_mapping is\nset to true. Otherwise, all mappings will be returned.\n\nThe method will be used to handle LXC volumes, as it's root FS\nshould be handled differently.\n\nChange-Id: I879916021c3b61f19dd69ff11838dbbac19f72d1\nRelated-Bug: #1269990\n""}, {'number': 6, 'created': '2014-07-23 12:34:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0828bc46b130586cc8626b74de579aabbd3fadb9', 'message': ""Method to filter non-root block device mappings\n\nAdding a generator that would provide a non-root block device\nmappings, when it's optional variable exclude_root_mapping is\nset to true. Otherwise, all mappings will be returned.\n\nThe method will be used to handle LXC volumes, as it's root FS\nshould be handled differently.\n\nChange-Id: I879916021c3b61f19dd69ff11838dbbac19f72d1\nRelated-Bug: #1269990\n""}, {'number': 7, 'created': '2014-07-24 20:03:29.000000000', 'files': ['nova/tests/test_block_device.py', 'nova/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/099aad2c3f8887fb9c7c1e81cf4239a104227f48', 'message': ""Method to filter non-root block device mappings\n\nAdding a generator that would provide a non-root block device\nmappings, when it's optional variable exclude_root_mapping is\nset to true. Otherwise, all mappings will be returned.\n\nThe method will be used to handle LXC volumes, as it's root FS\nshould be handled differently.\n\nChange-Id: I879916021c3b61f19dd69ff11838dbbac19f72d1\nRelated-Bug: #1269990\n""}]",12,99973,099aad2c3f8887fb9c7c1e81cf4239a104227f48,79,15,7,8802,,,0,"Method to filter non-root block device mappings

Adding a generator that would provide a non-root block device
mappings, when it's optional variable exclude_root_mapping is
set to true. Otherwise, all mappings will be returned.

The method will be used to handle LXC volumes, as it's root FS
should be handled differently.

Change-Id: I879916021c3b61f19dd69ff11838dbbac19f72d1
Related-Bug: #1269990
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/99973/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/test_block_device.py', 'nova/block_device.py']",2,7fcc637f79f350470e07575b730c043916e1c329,bp/libvirt-start-lxc-from-block-devices,"def filter_root_bdm(bdms, remove_root_mapping=False): return (bdm for bdm in bdms if bdm.get('boot_index', -1) != 0 or not remove_root_mapping) ",,16,0
openstack%2Fcookbook-openstack-block-storage~master~I6a301834fbcf3063375a89187b1a9b724df20f0f,openstack/cookbook-openstack-block-storage,master,I6a301834fbcf3063375a89187b1a9b724df20f0f,Change gpfs dirver path,ABANDONED,2014-07-30 05:25:27.000000000,2014-08-08 01:47:39.000000000,,"[{'_account_id': 3}, {'_account_id': 7128}, {'_account_id': 8410}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-07-30 05:25:27.000000000', 'files': ['recipes/volume.rb', 'spec/volume-redhat_spec.rb', 'spec/cinder_common_spec.rb', 'templates/default/cinder.conf.erb', 'README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/7bf41007b71dfedfe64b837f031e90cd8f02761b', 'message': 'Change gpfs dirver path\n\n change pgfs driver path from cinder.volume.drivers.gpfs.GPFSDriver to\n cinder.volume.drivers.ibm.gpfs.GPFSDriver\n\nChange-Id: I6a301834fbcf3063375a89187b1a9b724df20f0f\nImplements:\nCloses-Bug: 1347447\n'}]",1,110540,7bf41007b71dfedfe64b837f031e90cd8f02761b,9,4,1,8666,,,0,"Change gpfs dirver path

 change pgfs driver path from cinder.volume.drivers.gpfs.GPFSDriver to
 cinder.volume.drivers.ibm.gpfs.GPFSDriver

Change-Id: I6a301834fbcf3063375a89187b1a9b724df20f0f
Implements:
Closes-Bug: 1347447
",git fetch https://review.opendev.org/openstack/cookbook-openstack-block-storage refs/changes/40/110540/1 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/volume.rb', 'spec/volume-redhat_spec.rb', 'spec/cinder_common_spec.rb', 'templates/default/cinder.conf.erb', 'README.md']",5,7bf41007b71dfedfe64b837f031e90cd8f02761b,bug/1347447, - **cinder.volume.drivers.ibm.gpfs.GPFSDriver** - IBM General Parallel File System driver, - **cinder.volume.drivers.gpfs.GPFSDriver** - IBM General Parallel File System driver,7,7
openstack%2Fpuppet-ceilometer~stable%2Ficehouse~I00a5e651184788acdd30de1908e2bf38566f78e1,openstack/puppet-ceilometer,stable/icehouse,I00a5e651184788acdd30de1908e2bf38566f78e1,Add ability to disable ceilometer-collector without db,MERGED,2014-08-06 16:57:03.000000000,2014-08-08 01:45:02.000000000,2014-08-08 01:45:02.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6994}, {'_account_id': 7155}]","[{'number': 1, 'created': '2014-08-06 16:57:03.000000000', 'files': ['spec/classes/ceilometer_collector_spec.rb', 'manifests/collector.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/43ad68554622888d593c9b08c54f09dd962fc5c9', 'message': 'Add ability to disable ceilometer-collector without db\n\nYou are no longer required to include ceilometer::db when\ndisabling ceilometer-collector using the enabled parameter.\n\nThe relationships with any database resources are now only enforced\nwhen the service is enabled.\n\nCloses-bug: #1352958\nChange-Id: I00a5e651184788acdd30de1908e2bf38566f78e1\n(cherry picked from commit 8c9f4fcd53e4ef0fb7694de6dce6e001c7e8cf7d)\n'}]",0,112356,43ad68554622888d593c9b08c54f09dd962fc5c9,9,4,1,7156,,,0,"Add ability to disable ceilometer-collector without db

You are no longer required to include ceilometer::db when
disabling ceilometer-collector using the enabled parameter.

The relationships with any database resources are now only enforced
when the service is enabled.

Closes-bug: #1352958
Change-Id: I00a5e651184788acdd30de1908e2bf38566f78e1
(cherry picked from commit 8c9f4fcd53e4ef0fb7694de6dce6e001c7e8cf7d)
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/56/112356/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/ceilometer_collector_spec.rb', 'manifests/collector.pp']",2,43ad68554622888d593c9b08c54f09dd962fc5c9,, Class['ceilometer::db'] -> Service['ceilometer-collector'] Exec['ceilometer-dbsync'] ~> Service['ceilometer-collector'] hasrestart => true," hasrestart => true, require => Class['ceilometer::db'], subscribe => Exec['ceilometer-dbsync']",34,16
openstack%2Ftempest~master~I27c03bbba3b559f9ef587cea5b4192f89b02dcf1,openstack/tempest,master,I27c03bbba3b559f9ef587cea5b4192f89b02dcf1,Move response validation schema's in sub folder,MERGED,2014-08-04 07:47:07.000000000,2014-08-08 01:31:10.000000000,2014-08-07 08:57:48.000000000,"[{'_account_id': 3}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 7872}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-04 07:47:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d4f3ccd13c858efdc84a0b410f52deb7e2f59c16', 'message': ""Move response validation schema's in sub folder\n\nIn order to move all negative test schema's to tempest/api_schema it's\nneeded to separate between response checking and request checking.\n\nChange-Id: I27c03bbba3b559f9ef587cea5b4192f89b02dcf1\nPartially-implements: bp api-schema-unification\n""}, {'number': 2, 'created': '2014-08-07 06:18:30.000000000', 'files': ['tempest/services/compute/v3/json/quotas_client.py', 'tempest/services/compute/json/servers_client.py', 'tempest/services/compute/json/tenant_usages_client.py', 'tempest/api_schema/response/compute/hypervisors.py', 'tempest/api_schema/response/compute/v2/flavors.py', 'tempest/services/compute/json/limits_client.py', 'tempest/services/compute/v3/json/migration_client.py', 'tempest/api_schema/response/compute/v2/volumes.py', 'tempest/api_schema/response/compute/hosts.py', 'tempest/services/compute/json/images_client.py', 'tempest/api_schema/response/compute/v3/__init__.py', 'tempest/api_schema/response/compute/v2/servers.py', 'tempest/services/compute/json/hypervisor_client.py', 'tempest/api_schema/response/compute/interfaces.py', 'tempest/api_schema/response/compute/v2/quota_classes.py', 'tempest/services/compute/v3/json/hypervisor_client.py', 'tempest/api_schema/response/compute/v2/hosts.py', 'tempest/api_schema/response/compute/parameter_types.py', 'tempest/api_schema/response/compute/keypairs.py', 'tempest/api_schema/response/compute/services.py', 'tempest/api_schema/response/compute/v3/servers.py', 'tempest/api_schema/response/compute/v2/agents.py', 'tempest/services/compute/v3/json/availability_zone_client.py', 'tempest/services/compute/json/certificates_client.py', 'tempest/services/queuing/json/queuing_client.py', 'tempest/api_schema/response/compute/v3/agents.py', 'tempest/services/compute/json/hosts_client.py', 'tempest/services/compute/json/migrations_client.py', 'tempest/services/compute/v3/json/certificates_client.py', 'tempest/api_schema/response/compute/v3/availability_zone.py', 'tempest/api_schema/response/compute/v2/fixed_ips.py', 'tempest/api_schema/response/compute/certificates.py', 'tempest/services/compute/json/flavors_client.py', 'tempest/api_schema/response/compute/v2/limits.py', 'tempest/api_schema/response/compute/v2/tenant_usages.py', 'tempest/services/compute/json/services_client.py', 'tempest/api_schema/response/queuing/v1/__init__.py', 'tempest/api_schema/response/compute/v2/availability_zone.py', 'tempest/api_schema/response/compute/v2/instance_usage_audit_logs.py', 'tempest/api_schema/response/compute/v2/extensions.py', 'tempest/services/compute/json/aggregates_client.py', 'tempest/api_schema/response/queuing/__init__.py', 'tempest/services/compute/json/volumes_extensions_client.py', 'tempest/services/compute/json/quotas_client.py', 'tempest/services/compute/v3/json/agents_client.py', 'tempest/api_schema/response/compute/quotas.py', 'tempest/api_schema/response/compute/v2/floating_ips.py', 'tempest/services/compute/v3/json/interfaces_client.py', 'tempest/services/compute/v3/json/services_client.py', 'tempest/api_schema/response/__init__.py', 'tempest/api_schema/response/compute/servers.py', 'tempest/api_schema/response/compute/v3/hosts.py', 'tempest/api_schema/response/compute/v2/interfaces.py', 'tempest/services/compute/v3/json/keypairs_client.py', 'tempest/api_schema/response/compute/v3/hypervisors.py', 'tempest/services/compute/v3/json/hosts_client.py', 'tempest/api_schema/response/compute/__init__.py', 'tempest/services/compute/json/extensions_client.py', 'tempest/services/compute/v3/json/flavors_client.py', 'tempest/services/compute/v3/json/version_client.py', 'tempest/api_schema/response/compute/v2/security_groups.py', 'tempest/api_schema/response/compute/v2/keypairs.py', 'tempest/services/compute/json/floating_ips_client.py', 'tempest/services/compute/json/instance_usage_audit_log_client.py', 'tempest/api_schema/response/compute/flavors_access.py', 'tempest/api_schema/response/compute/v3/certificates.py', 'tempest/api_schema/response/compute/flavors_extra_specs.py', 'tempest/api_schema/response/compute/v2/aggregates.py', 'tempest/services/compute/v3/json/extensions_client.py', 'tempest/api_schema/response/compute/v2/quotas.py', 'tempest/services/compute/json/agents_client.py', 'tempest/services/compute/v3/json/servers_client.py', 'tempest/services/compute/json/availability_zone_client.py', 'tempest/services/compute/json/fixed_ips_client.py', 'tempest/services/compute/json/keypairs_client.py', 'tempest/api_schema/response/compute/v3/keypairs.py', 'tempest/api_schema/response/queuing/v1/queues.py', 'tempest/api_schema/response/compute/flavors.py', 'tempest/api_schema/response/compute/v3/extensions.py', 'tempest/api_schema/response/compute/aggregates.py', 'tempest/api_schema/response/compute/v3/interfaces.py', 'tempest/services/compute/json/interfaces_client.py', 'tempest/api_schema/response/compute/availability_zone.py', 'tempest/api_schema/response/compute/version.py', 'tempest/services/compute/v3/json/aggregates_client.py', 'tempest/api_schema/response/compute/migrations.py', 'tempest/api_schema/response/compute/v2/certificates.py', 'tempest/api_schema/response/compute/v3/aggregates.py', 'tempest/api_schema/response/compute/v2/__init__.py', 'tempest/api_schema/response/compute/agents.py', 'tempest/services/compute/json/security_groups_client.py', 'tempest/api_schema/response/compute/v2/hypervisors.py', 'tempest/api_schema/response/compute/v2/images.py', 'tempest/api_schema/response/compute/v3/quotas.py', 'tempest/api_schema/response/compute/v3/flavors.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/6fbd74fcb5667dc63dbfbf9aca8decc585f8ddd7', 'message': ""Move response validation schema's in sub folder\n\nIn order to move all negative test schema's to tempest/api_schema it's\nneeded to separate between response checking and request checking.\n\nChange-Id: I27c03bbba3b559f9ef587cea5b4192f89b02dcf1\nPartially-implements: bp api-schema-unification\n""}]",0,111664,6fbd74fcb5667dc63dbfbf9aca8decc585f8ddd7,23,7,2,7872,,,0,"Move response validation schema's in sub folder

In order to move all negative test schema's to tempest/api_schema it's
needed to separate between response checking and request checking.

Change-Id: I27c03bbba3b559f9ef587cea5b4192f89b02dcf1
Partially-implements: bp api-schema-unification
",git fetch https://review.opendev.org/openstack/tempest refs/changes/64/111664/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/compute/v3/json/quotas_client.py', 'tempest/services/compute/json/servers_client.py', 'tempest/services/compute/json/tenant_usages_client.py', 'tempest/api_schema/response/compute/hypervisors.py', 'tempest/api_schema/response/compute/v2/flavors.py', 'tempest/services/compute/json/limits_client.py', 'tempest/services/compute/v3/json/migration_client.py', 'tempest/api_schema/response/compute/v2/volumes.py', 'tempest/api_schema/response/compute/hosts.py', 'tempest/services/compute/json/images_client.py', 'tempest/api_schema/response/compute/v3/__init__.py', 'tempest/api_schema/response/compute/v2/servers.py', 'tempest/services/compute/json/hypervisor_client.py', 'tempest/api_schema/response/compute/interfaces.py', 'tempest/api_schema/response/compute/v2/quota_classes.py', 'tempest/services/compute/v3/json/hypervisor_client.py', 'tempest/api_schema/response/compute/v2/hosts.py', 'tempest/api_schema/response/compute/parameter_types.py', 'tempest/api_schema/response/compute/keypairs.py', 'tempest/api_schema/response/compute/services.py', 'tempest/api_schema/response/compute/v3/servers.py', 'tempest/api_schema/response/compute/v2/agents.py', 'tempest/services/compute/v3/json/availability_zone_client.py', 'tempest/services/compute/json/certificates_client.py', 'tempest/services/queuing/json/queuing_client.py', 'tempest/api_schema/response/compute/v3/agents.py', 'tempest/services/compute/json/hosts_client.py', 'tempest/services/compute/json/migrations_client.py', 'tempest/services/compute/v3/json/certificates_client.py', 'tempest/api_schema/response/compute/v3/availability_zone.py', 'tempest/api_schema/response/compute/v2/fixed_ips.py', 'tempest/api_schema/response/compute/certificates.py', 'tempest/services/compute/json/flavors_client.py', 'tempest/api_schema/response/compute/v2/limits.py', 'tempest/api_schema/response/compute/v2/tenant_usages.py', 'tempest/services/compute/json/services_client.py', 'tempest/api_schema/response/queuing/v1/__init__.py', 'tempest/api_schema/response/compute/v2/availability_zone.py', 'tempest/api_schema/response/compute/v2/instance_usage_audit_logs.py', 'tempest/api_schema/response/compute/v2/extensions.py', 'tempest/services/compute/json/aggregates_client.py', 'tempest/api_schema/response/queuing/__init__.py', 'tempest/services/compute/json/volumes_extensions_client.py', 'tempest/services/compute/json/quotas_client.py', 'tempest/services/compute/v3/json/agents_client.py', 'tempest/api_schema/response/compute/quotas.py', 'tempest/api_schema/response/compute/v2/floating_ips.py', 'tempest/services/compute/v3/json/interfaces_client.py', 'tempest/services/compute/v3/json/services_client.py', 'tempest/api_schema/response/__init__.py', 'tempest/api_schema/response/compute/servers.py', 'tempest/api_schema/response/compute/v3/hosts.py', 'tempest/api_schema/response/compute/v2/interfaces.py', 'tempest/services/compute/v3/json/keypairs_client.py', 'tempest/api_schema/response/compute/v3/hypervisors.py', 'tempest/services/compute/v3/json/hosts_client.py', 'tempest/api_schema/response/compute/__init__.py', 'tempest/services/compute/json/extensions_client.py', 'tempest/services/compute/v3/json/flavors_client.py', 'tempest/services/compute/v3/json/version_client.py', 'tempest/api_schema/response/compute/v2/security_groups.py', 'tempest/api_schema/response/compute/v2/keypairs.py', 'tempest/services/compute/json/floating_ips_client.py', 'tempest/services/compute/json/instance_usage_audit_log_client.py', 'tempest/api_schema/response/compute/flavors_access.py', 'tempest/api_schema/response/compute/v3/certificates.py', 'tempest/api_schema/response/compute/flavors_extra_specs.py', 'tempest/api_schema/response/compute/v2/aggregates.py', 'tempest/services/compute/v3/json/extensions_client.py', 'tempest/api_schema/response/compute/v2/quotas.py', 'tempest/services/compute/json/agents_client.py', 'tempest/services/compute/v3/json/servers_client.py', 'tempest/services/compute/json/availability_zone_client.py', 'tempest/services/compute/json/fixed_ips_client.py', 'tempest/services/compute/json/keypairs_client.py', 'tempest/api_schema/response/compute/v3/keypairs.py', 'tempest/api_schema/response/queuing/v1/queues.py', 'tempest/api_schema/response/compute/flavors.py', 'tempest/api_schema/response/compute/v3/extensions.py', 'tempest/api_schema/response/compute/aggregates.py', 'tempest/api_schema/response/compute/v3/interfaces.py', 'tempest/services/compute/json/interfaces_client.py', 'tempest/api_schema/response/compute/availability_zone.py', 'tempest/api_schema/response/compute/version.py', 'tempest/services/compute/v3/json/aggregates_client.py', 'tempest/api_schema/response/compute/migrations.py', 'tempest/api_schema/response/compute/v2/certificates.py', 'tempest/api_schema/response/compute/v3/aggregates.py', 'tempest/api_schema/response/compute/v2/__init__.py', 'tempest/api_schema/response/compute/agents.py', 'tempest/services/compute/json/security_groups_client.py', 'tempest/api_schema/response/compute/v2/hypervisors.py', 'tempest/api_schema/response/compute/v2/images.py', 'tempest/api_schema/response/compute/v3/quotas.py', 'tempest/api_schema/response/compute/v3/flavors.py']",95,d4f3ccd13c858efdc84a0b410f52deb7e2f59c16,bp/api-schema-unification,from tempest.api_schema.response.compute import flavors from tempest.api_schema.response.compute import flavors_extra_specs,from tempest.api_schema.compute import flavors from tempest.api_schema.compute import flavors_extra_specs,94,93
openstack%2Fcinder~master~Ic62bfb80d88fbd4d76f2de0f27f24f7b0c50bb3f,openstack/cinder,master,Ic62bfb80d88fbd4d76f2de0f27f24f7b0c50bb3f,Enable check for E251,ABANDONED,2014-07-30 18:42:58.000000000,2014-08-08 01:28:58.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1207}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9533}, {'_account_id': 11811}, {'_account_id': 12018}, {'_account_id': 12033}]","[{'number': 1, 'created': '2014-07-30 18:42:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/74bdee4879dec7b766d4ce212e9ce4da9e46ba73', 'message': 'Enable check for E251\n\n* E251 unexpected spaces around keyword / parameter equals\n\nChange-Id: Ic62bfb80d88fbd4d76f2de0f27f24f7b0c50bb3f\n'}, {'number': 2, 'created': '2014-07-31 06:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/60e211d09ef2f1df25b896c4748dc4ec2f408ca1', 'message': 'Enable check for E251\n\n* E251 unexpected spaces around keyword / parameter equals\n\nChange-Id: Ic62bfb80d88fbd4d76f2de0f27f24f7b0c50bb3f\n'}, {'number': 3, 'created': '2014-07-31 07:59:41.000000000', 'files': ['cinder/volume/drivers/rbd.py', 'cinder/brick/initiator/connector.py', 'cinder/tests/test_netapp_nfs.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/volume/iscsi.py', 'cinder/tests/test_ibmnas.py', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/test_volume.py', 'cinder/scheduler/host_manager.py', 'cinder/tests/test_vmware_vmdk.py', 'tox.ini', 'cinder/utils.py', 'cinder/volume/drivers/huawei/huawei_t.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/1a8879097827b0c4bfc646a2d7d559b169cfa193', 'message': 'Enable check for E251\n\n* E251 unexpected spaces around keyword / parameter equals\n\nChange-Id: Ic62bfb80d88fbd4d76f2de0f27f24f7b0c50bb3f\n'}]",0,110751,1a8879097827b0c4bfc646a2d7d559b169cfa193,32,11,3,167,,,0,"Enable check for E251

* E251 unexpected spaces around keyword / parameter equals

Change-Id: Ic62bfb80d88fbd4d76f2de0f27f24f7b0c50bb3f
",git fetch https://review.opendev.org/openstack/cinder refs/changes/51/110751/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/rbd.py', 'cinder/brick/initiator/connector.py', 'cinder/tests/test_netapp_nfs.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/volume/iscsi.py', 'cinder/tests/test_ibmnas.py', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/test_volume.py', 'cinder/scheduler/host_manager.py', 'cinder/tests/test_vmware_vmdk.py', 'tox.ini', 'cinder/utils.py', 'cinder/volume/drivers/huawei/huawei_t.py']",13,74bdee4879dec7b766d4ce212e9ce4da9e46ba73,enable_e251, self.common = ssh_common.TseriesCommon( configuration=self.configuration ) self.common = ssh_common.TseriesCommon( configuration=self.configuration ), self.common = ssh_common.TseriesCommon(configuration= self.configuration) self.common = ssh_common.TseriesCommon(configuration= self.configuration),118,97
openstack%2Fcinder~master~I76413c886f6903df2adcf4a4ceb8990486a2ff2f,openstack/cinder,master,I76413c886f6903df2adcf4a4ceb8990486a2ff2f,General cleanup of unused objects,MERGED,2014-08-07 19:15:07.000000000,2014-08-08 01:08:19.000000000,2014-08-08 01:08:18.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 6282}, {'_account_id': 7198}, {'_account_id': 9751}, {'_account_id': 11811}, {'_account_id': 12033}]","[{'number': 1, 'created': '2014-08-07 19:15:07.000000000', 'files': ['cinder/tests/api/v1/test_volume_metadata.py', 'cinder/tests/api/v2/test_volume_metadata.py', 'cinder/tests/image/fake.py', 'cinder/tests/api/v1/test_snapshot_metadata.py', 'cinder/tests/api/v2/test_snapshot_metadata.py', 'cinder/tests/api/contrib/test_extended_snapshot_attributes.py', 'cinder/tests/brick/test_brick_linuxscsi.py', 'cinder/tests/api/fakes.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5c1d0a6246cbd3f05f6c41e7cfc7046fa3431726', 'message': 'General cleanup of unused objects\n\n* Remove unused function fake_get_remote_image_service\n* Remove unused local function fake_execute2\n* stub_out_key_pair_funcs() does nothing, remove it.\n* Removed usage of enumerate()\n\nCloses-Bug: #1286714\nCloses-Bug: #1286712\nCloses-Bug: #1286742\nCloses-Bug: #1286809\nChange-Id: I76413c886f6903df2adcf4a4ceb8990486a2ff2f\n'}]",0,112661,5c1d0a6246cbd3f05f6c41e7cfc7046fa3431726,12,8,1,170,,,0,"General cleanup of unused objects

* Remove unused function fake_get_remote_image_service
* Remove unused local function fake_execute2
* stub_out_key_pair_funcs() does nothing, remove it.
* Removed usage of enumerate()

Closes-Bug: #1286714
Closes-Bug: #1286712
Closes-Bug: #1286742
Closes-Bug: #1286809
Change-Id: I76413c886f6903df2adcf4a4ceb8990486a2ff2f
",git fetch https://review.opendev.org/openstack/cinder refs/changes/61/112661/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/api/v1/test_volume_metadata.py', 'cinder/tests/api/v2/test_volume_metadata.py', 'cinder/tests/image/fake.py', 'cinder/tests/api/v1/test_snapshot_metadata.py', 'cinder/tests/api/v2/test_snapshot_metadata.py', 'cinder/tests/api/contrib/test_extended_snapshot_attributes.py', 'cinder/tests/brick/test_brick_linuxscsi.py', 'cinder/tests/api/fakes.py']",8,5c1d0a6246cbd3f05f6c41e7cfc7046fa3431726,bug/1286714,,"from cinder import exception as excdef stub_out_key_pair_funcs(stubs, have_key_pair=True): def key_pair(context, user_id): return [dict(name='key', public_key='public_key')] def one_key_pair(context, user_id, name): if name == 'key': return dict(name='key', public_key='public_key') else: raise exc.KeypairNotFound(user_id=user_id, name=name) def no_key_pair(context, user_id): return [] ",1,31
openstack%2Fhorizon~master~Ib857ad4cc8bef1b26353ad88743dab43b32b50e3,openstack/horizon,master,Ib857ad4cc8bef1b26353ad88743dab43b32b50e3,Add missing inline edit save and cancel icon,MERGED,2014-07-30 01:52:32.000000000,2014-08-08 00:58:53.000000000,2014-08-08 00:58:52.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5623}, {'_account_id': 6914}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 9659}, {'_account_id': 11592}, {'_account_id': 11881}]","[{'number': 1, 'created': '2014-07-30 01:52:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/678d646fb9c27fe62e2ff3750ef2409de35da2e3', 'message': 'Add missing inline edit save and cancel icon\n\nChange-Id: Ib857ad4cc8bef1b26353ad88743dab43b32b50e3\nCloses-Bug: #1349605\n'}, {'number': 2, 'created': '2014-07-30 02:13:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/51f440fa33e6dc1d626018dde0fb717e151e8004', 'message': 'Add missing inline edit save and cancel icon\n\nChange-Id: Ib857ad4cc8bef1b26353ad88743dab43b32b50e3\nCloses-Bug: #1349605'}, {'number': 3, 'created': '2014-07-30 16:36:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/81ffe77aeb34b5225b4f01b6828746733fd9f036', 'message': 'Add missing inline edit save and cancel icon\n\nDid some clean up and added the missing icons.\n\nChange-Id: Ib857ad4cc8bef1b26353ad88743dab43b32b50e3\nCloses-Bug: #1349605\n'}, {'number': 4, 'created': '2014-07-30 17:04:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b28be230e824de8be8db7789c2aa43da60d7d9f1', 'message': 'Add missing inline edit save and cancel icon\n\nDid some clean up and added the missing icons.\n\nChange-Id: Ib857ad4cc8bef1b26353ad88743dab43b32b50e3\nCloses-Bug: #1349605'}, {'number': 5, 'created': '2014-08-05 17:30:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f80150b9455558a4f3468d653d5569159a26afff', 'message': 'Add missing inline edit save and cancel icon\n\nDid some clean up and added the missing icons.\n\nChange-Id: Ib857ad4cc8bef1b26353ad88743dab43b32b50e3\nCloses-Bug: #1349605'}, {'number': 6, 'created': '2014-08-05 18:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6297c3a6c7bdbb076ca2a45b6cd61732c34a8c98', 'message': 'Add missing inline edit save and cancel icon\n\nDid some clean up and added the missing icons.\n\nChange-Id: Ib857ad4cc8bef1b26353ad88743dab43b32b50e3\nCloses-Bug: #1349605'}, {'number': 7, 'created': '2014-08-05 18:14:14.000000000', 'files': ['horizon/templates/horizon/common/_data_table_cell.html', 'openstack_dashboard/static/dashboard/scss/horizon.scss'], 'web_link': 'https://opendev.org/openstack/horizon/commit/fd6406c627a5ab9c0ccca0765184a45fbfbccb09', 'message': 'Add missing inline edit save and cancel icon\n\nDid some clean up and added the missing icons.\n\nChange-Id: Ib857ad4cc8bef1b26353ad88743dab43b32b50e3\nCloses-Bug: #1349605'}]",3,110523,fd6406c627a5ab9c0ccca0765184a45fbfbccb09,37,9,7,9576,,,0,"Add missing inline edit save and cancel icon

Did some clean up and added the missing icons.

Change-Id: Ib857ad4cc8bef1b26353ad88743dab43b32b50e3
Closes-Bug: #1349605",git fetch https://review.opendev.org/openstack/horizon refs/changes/23/110523/5 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templates/horizon/common/_data_table_cell.html'],1,678d646fb9c27fe62e2ff3750ef2409de35da2e3,bug/1349605," <span class=""glyphicon glyphicon-ok""></span> <button class=""inline-edit-cancel btn btn-default secondary cancel""> <span class=""glyphicon glyphicon-remove""></span> </button>"," <button class=""inline-edit-cancel btn btn-default secondary cancel""></button>",4,1
openstack%2Fpython-keystoneclient~master~I638c4eeab7d01ec2f26a0d9d532f0006f4f75e72,openstack/python-keystoneclient,master,I638c4eeab7d01ec2f26a0d9d532f0006f4f75e72,Remove intersphinx mappings,MERGED,2014-08-07 05:50:49.000000000,2014-08-08 00:55:58.000000000,2014-08-08 00:55:58.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-08-07 05:50:49.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/bb5380822127525fa7b8bec9041b69b33a553fef', 'message': ""Remove intersphinx mappings\n\nNone of our documentation references any external sphinx documents so we\ndon't need the intersphinx mappings.\n\nThis started as a rename from the old glance.openstack.org site to the\nnewer docs.openstack.org/developer/glance however they may as well be\nremoved if not used.\n\nCloses-Bug: #1353817\nChange-Id: I638c4eeab7d01ec2f26a0d9d532f0006f4f75e72\n""}]",0,112479,bb5380822127525fa7b8bec9041b69b33a553fef,11,5,1,7191,,,0,"Remove intersphinx mappings

None of our documentation references any external sphinx documents so we
don't need the intersphinx mappings.

This started as a rename from the old glance.openstack.org site to the
newer docs.openstack.org/developer/glance however they may as well be
removed if not used.

Closes-Bug: #1353817
Change-Id: I638c4eeab7d01ec2f26a0d9d532f0006f4f75e72
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/79/112479/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,bb5380822127525fa7b8bec9041b69b33a553fef,doc-site,"#intersphinx_mapping = {'python': ('http://docs.python.org/', None)}","intersphinx_mapping = {'python': ('http://docs.python.org/', None), 'nova': ('http://nova.openstack.org', None), 'swift': ('http://swift.openstack.org', None), 'glance': ('http://glance.openstack.org', None)}",1,4
openstack%2Fnova~master~I3d9feed761af3729611d082584e6c264d8839578,openstack/nova,master,I3d9feed761af3729611d082584e6c264d8839578,Handle invalid regexp(s) better,ABANDONED,2014-07-04 16:17:28.000000000,2014-08-08 00:49:32.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1030}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 7746}, {'_account_id': 8247}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10618}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-07-04 16:17:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/013b266a8dfaebe7fd7d9ae6a2464dea9a866033', 'message': 'Handle invalid regexp(s) better\n\nCatch the OperationalError and return back a much better message\nthat can help the user diagnose what went wrong. Added a test\ncase as well\n\nChange-Id: I3d9feed761af3729611d082584e6c264d8839578\nCloses-Bug: #1337265\n'}, {'number': 2, 'created': '2014-07-04 17:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/00cdfb198bc1bfb24869651d8336ea98e4a0d592', 'message': 'Handle invalid regexp(s) better\n\nCatch the OperationalError and return back a much better message\nthat can help the user diagnose what went wrong. Added a test\ncase as well\n\nChange-Id: I3d9feed761af3729611d082584e6c264d8839578\nCloses-Bug: #1337265\n'}, {'number': 3, 'created': '2014-07-04 21:14:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e43a40e98c59f95e1ca4410c04539d1f54a3435', 'message': 'Handle invalid regexp(s) better\n\nCatch the OperationalError and return back a much better message\nthat can help the user diagnose what went wrong. Added a test\ncase as well\n\nChange-Id: I3d9feed761af3729611d082584e6c264d8839578\nCloses-Bug: #1337265\n'}, {'number': 4, 'created': '2014-07-07 13:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0789b688a38fbc186cfbfd404a9f4d93ae3bfa3d', 'message': 'Handle invalid regexp(s) better\n\nCatch the OperationalError and return back a much better message\nthat can help the user diagnose what went wrong.\n\nChange-Id: I3d9feed761af3729611d082584e6c264d8839578\nCloses-Bug: #1337265\n'}, {'number': 5, 'created': '2014-07-15 01:12:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf3ea739e9e821b522b80854f2995cd3b2d2c9af', 'message': 'Handle invalid regexp(s) better\n\nCatch the OperationalError and return back a much better message\nthat can help the user diagnose what went wrong.\n\nChange-Id: I3d9feed761af3729611d082584e6c264d8839578\nCloses-Bug: #1337265\n'}, {'number': 6, 'created': '2014-07-15 11:29:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b2abdeacaaf29c0b5256c9f040b8269d22cff7b6', 'message': 'Handle invalid regexp(s) better\n\nCatch the OperationalError and return back a much better message\nthat can help the user diagnose what went wrong.\n\nChange-Id: I3d9feed761af3729611d082584e6c264d8839578\nCloses-Bug: #1337265\n'}, {'number': 7, 'created': '2014-07-17 01:00:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7ba69c86d71ea21b70b93c009d8477730a04b34a', 'message': 'Handle invalid regexp(s) better\n\nCatch the OperationalError and return back a much better message\nthat can help the user diagnose what went wrong.\n\nChange-Id: I3d9feed761af3729611d082584e6c264d8839578\nCloses-Bug: #1337265\n'}, {'number': 8, 'created': '2014-07-17 10:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a192b55793092b72c776058b3d2e54dcfa32b00b', 'message': 'Handle invalid regexp(s) better\n\nCatch the OperationalError and return back a much better message\nthat can help the user diagnose what went wrong.\n\nChange-Id: I3d9feed761af3729611d082584e6c264d8839578\nCloses-Bug: #1337265\n'}, {'number': 9, 'created': '2014-07-18 11:55:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9e5bd9a7152c26243d3b3a825074f0b1aa87f140', 'message': 'Handle invalid regexp(s) better\n\nCatch the OperationalError and return back a much better message\nthat can help the user diagnose what went wrong.\n\nChange-Id: I3d9feed761af3729611d082584e6c264d8839578\nCloses-Bug: #1337265\n'}, {'number': 10, 'created': '2014-07-18 21:43:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e681313a6cdc366190f418bea22ea03e7167575', 'message': 'Handle invalid regexp(s) better\n\nCatch the OperationalError and return back a much better message\nthat can help the user diagnose what went wrong.\n\nChange-Id: I3d9feed761af3729611d082584e6c264d8839578\nCloses-Bug: #1337265\n'}, {'number': 11, 'created': '2014-07-19 01:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/51b8403d64dde1ceb4d3e76eba316b94b62a0c1e', 'message': 'Handle invalid regexp(s) better\n\nCatch the OperationalError and return back a much better message\nthat can help the user diagnose what went wrong.\n\nChange-Id: I3d9feed761af3729611d082584e6c264d8839578\nCloses-Bug: #1337265\n'}, {'number': 12, 'created': '2014-07-23 14:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/315972476d18ee93e502c0e4788268b40cc1d264', 'message': 'Handle invalid regexp(s) better\n\nCatch the OperationalError and return back a much better message\nthat can help the user diagnose what went wrong.\n\nChange-Id: I3d9feed761af3729611d082584e6c264d8839578\nCloses-Bug: #1337265\n'}, {'number': 13, 'created': '2014-07-29 22:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1b6a5189e03a6915963e33262092aea7de6913b4', 'message': 'Bug Fix - Handle invalid regexp(s) better\n\nCatch the OperationalError and return back a much better message\nthat can help the user diagnose what went wrong.\n\nChange-Id: I3d9feed761af3729611d082584e6c264d8839578\nCloses-Bug: #1337265\n'}, {'number': 14, 'created': '2014-07-29 22:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e0a22e4696f10fb733c3f73c58f13f2d1584e542', 'message': 'Bug Fix - Handle invalid regexp(s) better\n\nCatch the OperationalError and return back a much better message\nthat can help the user diagnose what went wrong.\n\nChange-Id: I3d9feed761af3729611d082584e6c264d8839578\nCloses-Bug: #1337265\n'}, {'number': 15, 'created': '2014-08-01 01:43:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/77a6db3e01b635997d108200f76a0c5ec1ff9024', 'message': 'Bug Fix - Handle invalid regexp(s) better\n\nCatch the OperationalError and return back a much better message\nthat can help the user diagnose what went wrong.\n\nChange-Id: I3d9feed761af3729611d082584e6c264d8839578\nCloses-Bug: #1337265\n'}, {'number': 16, 'created': '2014-08-06 01:21:16.000000000', 'files': ['nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2a9db0ac7eb37b25b05151805a705d22a66c7baf', 'message': 'Handle invalid regexp(s) better\n\nCatch the OperationalError and return back a much better message\nthat can help the user diagnose what went wrong.\n\nChange-Id: I3d9feed761af3729611d082584e6c264d8839578\nCloses-Bug: #1337265\n'}]",7,104931,2a9db0ac7eb37b25b05151805a705d22a66c7baf,177,14,16,5638,,,0,"Handle invalid regexp(s) better

Catch the OperationalError and return back a much better message
that can help the user diagnose what went wrong.

Change-Id: I3d9feed761af3729611d082584e6c264d8839578
Closes-Bug: #1337265
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/104931/13 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",2,013b266a8dfaebe7fd7d9ae6a2464dea9a866033,bug/1337265,"from sqlalchemy.exc import OperationalError try: return _instances_fill_metadata(context, query_prefix.all(), manual_joins) except OperationalError as oe: raise exception.InvalidParameterValue(err=oe.args[0])"," return _instances_fill_metadata(context, query_prefix.all(), manual_joins)",14,1
openstack%2Fpycadf~master~I53893d618cd60c0456368088497542db7e4a6eac,openstack/pycadf,master,I53893d618cd60c0456368088497542db7e4a6eac,Debug env for tox,MERGED,2014-07-28 04:32:32.000000000,2014-08-08 00:37:47.000000000,2014-08-08 00:37:47.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 6537}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-07-28 04:32:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/93c2a82300b0c5fc1a5df47f2a123355dfb12bcc', 'message': ""Debug env for tox\n\nRunning a test with pdb was difficult because tox captures\noutput and causes pdb prompt to quit.\n\nTips for how to run with debug are provided here:\n https://wiki.openstack.org/wiki/Testr#Debugging_.28pdb.29_Tests\n\nThis change puts these commands into a debug env in tox.ini so\nyou can do a command like\n\ntox -e debug pycadf.tests.test_cadf_spec\n\nand when it hits your breakpoint you'll get the debug prompt.\n\nChange-Id: I53893d618cd60c0456368088497542db7e4a6eac\nCo-Authored-By: Brant Knudson <bknudson@us.ibm.com>\n""}, {'number': 2, 'created': '2014-07-28 04:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/d54f7e17b391b7075131b742b4c2016a6a5950d4', 'message': ""Debug env for tox\n\nRunning a test with pdb was difficult because tox captures\noutput and causes pdb prompt to quit.\n\nTips for how to run with debug are provided here:\n https://wiki.openstack.org/wiki/Testr#Debugging_.28pdb.29_Tests\n\nThis change puts these commands into a debug env in tox.ini so\nyou can do a command like\n\ntox -e debug pycadf.tests.test_cadf_spec\n\nand when it hits your breakpoint you'll get the debug prompt.\n\nChange-Id: I53893d618cd60c0456368088497542db7e4a6eac\nCo-Authored-By: Brant Knudson <bknudson@us.ibm.com>\n""}, {'number': 3, 'created': '2014-07-28 05:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/bd2e547d3f23f3f650429f6fd5ecb2bb05e1a3a6', 'message': ""Debug env for tox\n\nRunning a test with pdb was difficult because tox captures\noutput and causes pdb prompt to quit.\n\nTips for how to run with debug are provided here:\n https://wiki.openstack.org/wiki/Testr#Debugging_.28pdb.29_Tests\n\nThis change puts these commands into a debug env in tox.ini so\nyou can do a command like\n\ntox -e debug pycadf.tests.test_cadf_spec\n\nand when it hits your breakpoint you'll get the debug prompt.\n\nChange-Id: I53893d618cd60c0456368088497542db7e4a6eac\nCo-Authored-By: Brant Knudson <bknudson@us.ibm.com>\n""}, {'number': 4, 'created': '2014-07-28 18:59:23.000000000', 'files': ['doc/source/index.rst', 'tools/debug_helper.sh', 'tox.ini', 'doc/source/debugging.rst'], 'web_link': 'https://opendev.org/openstack/pycadf/commit/02c6e369060da29192768076eb932067b9b5c3ef', 'message': ""Debug env for tox\n\nRunning a test with pdb was difficult because tox captures\noutput and causes pdb prompt to quit.\n\nTips for how to run with debug are provided here:\n https://wiki.openstack.org/wiki/Testr#Debugging_.28pdb.29_Tests\n\nThis change puts these commands into a debug env in tox.ini so\nyou can do a command like\n\ntox -e debug pycadf.tests.test_cadf_spec\n\nand when it hits your breakpoint you'll get the debug prompt.\n\nChange-Id: I53893d618cd60c0456368088497542db7e4a6eac\nCo-Authored-By: Brant Knudson <bknudson@us.ibm.com>\n""}]",3,109903,02c6e369060da29192768076eb932067b9b5c3ef,26,7,4,6460,,,0,"Debug env for tox

Running a test with pdb was difficult because tox captures
output and causes pdb prompt to quit.

Tips for how to run with debug are provided here:
 https://wiki.openstack.org/wiki/Testr#Debugging_.28pdb.29_Tests

This change puts these commands into a debug env in tox.ini so
you can do a command like

tox -e debug pycadf.tests.test_cadf_spec

and when it hits your breakpoint you'll get the debug prompt.

Change-Id: I53893d618cd60c0456368088497542db7e4a6eac
Co-Authored-By: Brant Knudson <bknudson@us.ibm.com>
",git fetch https://review.opendev.org/openstack/pycadf refs/changes/03/109903/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/debug_helper.sh', 'tox.ini', 'doc/source/debugging.rst']",3,93c2a82300b0c5fc1a5df47f2a123355dfb12bcc,add_debug,".. Copyright 2014 IBM Corp. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. .. _debugging: =================== Debugging with PDB =================== Using PDB breakpoints with tox and testr normally doesn't work since the tests just fail with a BdbQuit exception rather than stopping at the breakpoint. To run with PDB breakpoints during testing, use the ``debug`` tox environment rather than ``py27``. Here's an example, passing the name of a test since you'll normally only want to run the test that hits your breakpoint:: $ tox -e debug pycadf.tests.test_cadf_spec For reference, the ``debug`` tox environment implements the instructions here: https://wiki.openstack.org/wiki/Testr#Debugging_.28pdb.29_Tests The pyCADF library provides a tox environment that enables pdb based debugging of test cases. ",,57,0
openstack%2Fhorizon~master~Ida8c545ceec7c31999f2497d540a0dc5a653d286,openstack/horizon,master,Ida8c545ceec7c31999f2497d540a0dc5a653d286,Replace force_unicode with force_text,MERGED,2014-07-17 13:55:34.000000000,2014-08-08 00:18:39.000000000,2014-08-08 00:18:38.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2424}, {'_account_id': 2455}, {'_account_id': 4978}, {'_account_id': 8871}, {'_account_id': 9317}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 10295}]","[{'number': 1, 'created': '2014-07-17 13:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b53163b3250db7fde045b1584afdbdbc8bb0ebe0', 'message': ""Replace force_unicode with force_text\n\nDjango changed the name to force_unicode and it's only available in\npython2 as an alias of force_text. The new name is available since\nDjango 1.4.2\n\nChange-Id: Ida8c545ceec7c31999f2497d540a0dc5a653d286\n""}, {'number': 2, 'created': '2014-07-20 17:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9a3616a7cb2ee7d36be5d17d1aad85bcf268e6e7', 'message': ""Replace force_unicode with force_text\n\nDjango changed the name to force_unicode and it's only available in\npython2 as an alias of force_text. The new name is available since\nDjango 1.4.2\n\nCloses-Bug: #1345642\nChange-Id: Ida8c545ceec7c31999f2497d540a0dc5a653d286\n""}, {'number': 3, 'created': '2014-08-03 18:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/20a63af5d0ee7638a9400a4c50a69ea3693a5206', 'message': ""Replace force_unicode with force_text\n\nDjango changed the name to force_unicode and it's only available in\npython2 as an alias of force_text. The new name is available since\nDjango 1.4.2\n\nCloses-Bug: #1345642\nChange-Id: Ida8c545ceec7c31999f2497d540a0dc5a653d286\n""}, {'number': 4, 'created': '2014-08-03 19:49:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9dfb3879a5ce5791d93384377bd1e236b8803bf6', 'message': ""Replace force_unicode with force_text\n\nDjango changed the name to force_unicode and it's only available in\npython2 as an alias of force_text. The new name is available since\nDjango 1.4.2\n\nCloses-Bug: #1345642\nChange-Id: Ida8c545ceec7c31999f2497d540a0dc5a653d286\n""}, {'number': 5, 'created': '2014-08-06 12:34:56.000000000', 'files': ['horizon/test/tests/exceptions.py', 'openstack_dashboard/dashboards/project/containers/forms.py', 'horizon/test/tests/base.py', 'horizon/workflows/base.py', 'openstack_dashboard/dashboards/project/data_processing/job_binaries/forms.py', 'horizon/messages.py', 'horizon/templatetags/horizon.py', 'horizon/test/tests/messages.py', 'horizon/forms/fields.py', 'openstack_dashboard/dashboards/settings/user/forms.py', 'horizon/exceptions.py', 'horizon/test/helpers.py', 'horizon/utils/functions.py', 'tox.ini', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/horizon/commit/af49cf1f156e68dcd8d34a3de59c40ee5bd12b66', 'message': ""Replace force_unicode with force_text\n\nDjango changed the name to force_unicode and it's only available in\npython2 as an alias of force_text. The new name is available since\nDjango 1.4.2\n\nCloses-Bug: #1345642\nChange-Id: Ida8c545ceec7c31999f2497d540a0dc5a653d286\n""}]",0,107708,af49cf1f156e68dcd8d34a3de59c40ee5bd12b66,49,10,5,2424,,,0,"Replace force_unicode with force_text

Django changed the name to force_unicode and it's only available in
python2 as an alias of force_text. The new name is available since
Django 1.4.2

Closes-Bug: #1345642
Change-Id: Ida8c545ceec7c31999f2497d540a0dc5a653d286
",git fetch https://review.opendev.org/openstack/horizon refs/changes/08/107708/4 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/forms/fields.py', 'horizon/test/tests/exceptions.py', 'horizon/exceptions.py', 'horizon/test/tests/base.py', 'horizon/test/helpers.py', 'horizon/utils/functions.py', 'horizon/workflows/base.py', 'horizon/messages.py', 'horizon/templatetags/horizon.py', 'horizon/test/tests/messages.py']",10,b53163b3250db7fde045b1584afdbdbc8bb0ebe0,bug/1345642,"from django.utils.encoding import force_text expected = [""error"", force_text(string), """"] expected = [""error"", force_text(string), "" safe""]","from django.utils.encoding import force_unicode expected = [""error"", force_unicode(string), """"] expected = [""error"", force_unicode(string), "" safe""]",28,28
openstack%2Fironic-specs~master~I686ef4f7a5835635b75ce6d8e3ff4fd13c9a031d,openstack/ironic-specs,master,I686ef4f7a5835635b75ce6d8e3ff4fd13c9a031d,Support for different boot loaders and locations,ABANDONED,2014-05-22 16:26:40.000000000,2014-08-08 00:13:53.000000000,,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 10239}, {'_account_id': 10342}]","[{'number': 1, 'created': '2014-05-22 16:26:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/b31ac54d4af7247c1bf98083bedd5d6ba0068679', 'message': 'Add spec for improving the handling of bootloaders\n\nChange-Id: I686ef4f7a5835635b75ce6d8e3ff4fd13c9a031d\n'}, {'number': 2, 'created': '2014-05-24 02:39:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/e88f870e349d63a2497326af9ae51cbf1f7c0ede', 'message': 'Add spec for improving the handling of bootloaders\n\nChange-Id: I686ef4f7a5835635b75ce6d8e3ff4fd13c9a031d\n'}, {'number': 3, 'created': '2014-05-26 20:48:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/34053f73326fffc8a7d99a51e4228e3ee2631304', 'message': ""Support for different boot loaders and locations\n\nThis proposal aims to improve Ironic's support for determining the boot\nconditions of the hosts it has provisioned.\n\n\nChange-Id: I686ef4f7a5835635b75ce6d8e3ff4fd13c9a031d\n""}, {'number': 4, 'created': '2014-06-17 00:15:22.000000000', 'files': ['specs/juno/better-bootloader-options.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/0e55f3a4138acb1d7153a92c4779dd2ec692a97d', 'message': ""Support for different boot loaders and locations\n\nThis proposal aims to improve Ironic's support for determining the boot\nconditions of the hosts it has provisioned.\n\nChange-Id: I686ef4f7a5835635b75ce6d8e3ff4fd13c9a031d\n""}]",1,94925,0e55f3a4138acb1d7153a92c4779dd2ec692a97d,14,4,4,2889,,,0,"Support for different boot loaders and locations

This proposal aims to improve Ironic's support for determining the boot
conditions of the hosts it has provisioned.

Change-Id: I686ef4f7a5835635b75ce6d8e3ff4fd13c9a031d
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/25/94925/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/better-bootloader-options.rst'],1,b31ac54d4af7247c1bf98083bedd5d6ba0068679,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================ Support for different boot loaders and locations ================================================ Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/ironic/+spec/better-bootloader-options.rst This proposal aims to improve Ironic's support for determining the boot conditions of the hosts it has provisioned. Problem description =================== The following independent conditions should be supported, and should be automatically determined based on the flavor, image, and hardware properties. An operator should also be able to override these on a per-node basis, where necessary. * MBR vs GPT: hardware which can only read MBR-based partitions should be supported, while still allowing GUID Partition Tables on newer hardware. * Default Power State: in some cases, the operator may wish to enforce a default-power-state policy such that certain hardware remains powered off in the event of a rack or datacenter power event, while other hardware powers on automatically. * Boot from PXE vs HDD: in some cases, the operator may wish that some nodes boot from their local disk while other nodes always boot from the network. Proposed change =============== TBD Alternatives ------------ What other ways could we do this thing? Has someone else done this thing in another project? In another language? Why aren't we using those? This doesn't have to be a full literature review, but it should demonstrate that thought has been put into why the proposed solution is an appropriate one. Data model impact ----------------- Changes which require modifications to the data model often have a wider impact on the system. The community often has strong opinions on how the data model should be evolved, from both a functional and performance perspective. It is therefore important to capture and gain agreement as early as possible on any proposed changes to the data model. Questions which need to be addressed by this section include: * What new data objects and/or database schema changes is this going to require? * What database migrations will accompany this change? * How will the initial set of new data objects be generated, for example if you need to take into account existing instances, or modify other existing data, describe how that will work. REST API impact --------------- Each API method which is either added or changed should have the following * Specification for the method * A description of what the method does suitable for use in user documentation * Method type (POST/PUT/GET/DELETE/PATCH) * Normal http response code(s) * Expected error http response code(s) * A description for each possible error code should be included describing semantic errors which can cause it such as inconsistent parameters supplied to the method, or when an instance is not in an appropriate state for the request to succeed. Errors caused by syntactic problems covered by the JSON schema defintion do not need to be included. * URL for the resource * Parameters which can be passed via the url, including data types * JSON schema definition for the body data if allowed * JSON schema definition for the response data if any * Example use case including typical API samples for both data supplied by the caller and the response * Discuss any policy changes, and discuss what things a deployer needs to think about when defining their policy. Note that the schema should be defined as restrictively as possible. Parameters which are required should be marked as such and only under exceptional circumstances should additional parameters which are not defined in the schema be permitted. Use of free-form JSON dicts should only be permitted where necessary to allow divergence in the drivers. In such case, the drivers must expose the expected content of the JSON dict and an ability to validate it. Reuse of existing predefined parameter types is highly encouraged. Driver API impact ----------------- Changes which affects the driver API have a direct effect on all drivers, and often have a wider impact on the system. There are several things to consider in this section. * Is it a change to a ""core"" or ""common"" API? * Can all drivers support it initially, or is it specific to a particular vendor's hardware? * How will it be tested in the gate and in third-party CI systems? * If adding a new interface, explain the intended scope of the proposed interface, what functionality it enables, why it is needed, and whether it is supported by current drivers. * If adding or changing a method on an existing interface, the impact on existing drivers should be explored. * Will the new interface or method need to be invoked when the hash ring rebalances, for example to rebuild local state on a new conductor service? Nova driver impact ------------------ Chances are, if this change affects the REST or Driver APIs, it will also affect the Nova driver in some way. Questions which need to be addressed in this section include: * What is the impact on Nova? * If this change is enabling new functionality exposed via Nova, this section should cite the relevant components within other Nova drivers that alraedy implement this. * Ironic and Nova services must be upgradable independently. If the change is affecting existing functionality of the nova.virt.ironic driver, how will an upgrade be performe? How will it be tested? Security impact --------------- Describe any potential security impact on the system. Some of the items to consider include: * Does this change touch sensitive data such as tokens, keys, or credentials? * Does this change affect the accessibility of hardware managed by Ironic? * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? * Does this change involve cryptography or hashing? * Does this change require the use of sudo or any elevated privileges? * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. For more detailed guidance, please see the OpenStack Security Guidelines as a reference (https://wiki.openstack.org/wiki/Security/Guidelines). These guidelines are a work in progress and are designed to help you identify security best practices. For further information, feel free to reach out to the OpenStack Security Group at openstack-security@lists.openstack.org. Other end user impact --------------------- Aside from the API, are there other ways a user will interact with this feature? * Does this change have an impact on python-ironicclient? What does the user interface there look like? * Will this require changes in the Horizon panel? Scalability impact ------------------ Describe any potential scalability impact on the system, for example any increase in network, RPC, or database traffic, or whether the feature requires synchronization across multiple services. Examples of things to consider here include: * Additional network calls to internal or external services. * Additional disk or network traffic that will be required by the feature. * Any change in the number of physical nodes which can be managed by each conductor service. Performance Impact ------------------ Describe any potential performance impact on the system, for example how often will new code be called, and is there a major change to the calling pattern of existing code. Examples of things to consider here include: * A periodic task might look like a small addition, but all periodic tasks run in a single thread so a periodic task that takes a long time to run will have an effect on the timing of other periodic tasks. * A small change in a utility function or a commonly used decorator can have a large impacts on performance. * Calls which result in a database queries (whether direct or via conductor) can have a profound impact on performance when called in critical sections of the code. * Will the change include any TaskManager locking, and if so what considerations are there on holding the lock? * How will the new code be affected if the hash ring rebalances while it is running? Other deployer impact --------------------- Discuss things that will affect how you deploy and configure OpenStack that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example a flag that other hypervisor drivers might want to implement as well)? Are the default values ones which will work well in real deployments? * Is this a change that takes immediate effect after its merged, or is it something that has to be explicitly enabled? * If this change is a new binary, how would it be deployed? * Please state anything that those doing continuous deployment, or those upgrading from the previous release, need to be aware of. Also describe any plans to deprecate configuration values or features. For example, if we change the directory name that instances are stored in, how do we handle instance directories created before the change landed? Do we move them? Do we have a special case in the code? Do we assume that the operator will recreate all the instances in their cloud? Developer impact ---------------- Discuss things that will affect other developers working on OpenStack, such as: * If the blueprint proposes a change to the driver API, discussion of how other drivers would implement the feature is required. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: <launchpad-id or None> Other contributors: <launchpad-id or None> Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ * Include specific references to specs and/or blueprints in ironic, or in other projects, that this one either depends on or is related to. * If this requires functionality of another project that is not currently used by Ironic, document that fact. * Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? * Does this feature target specific hardware? If so, is it a common standard (eg IPMI) or a vendor-specific implementation (eg iLO)? Testing ======= Please discuss how the change will be tested. We especially want to know what tempest tests will be added. It is assumed that unit test coverage will be added so that doesn't need to be mentioned explicitly, but discussion of why you think unit tests are sufficient and we don't need to add more tempest tests would need to be included. Is this untestable in gate given current limitations (specific hardware / software configurations available)? If so, are there mitigation plans (3rd party testing, gate enhancements, etc)? Documentation Impact ==================== What is the impact on the docs team of this change? Some changes might require donating resources to the docs team to have the documentation updated. Don't repeat details discussed above, but please reference them here. References ========== Please add any useful references here. You are not required to have any reference. Moreover, this specification should still make sense when your references are unavailable. Examples of what you could include are: * Links to mailing list or IRC discussions * Links to notes from a summit session * Links to relevant research, if appropriate * Related specifications as appropriate (e.g. if it's an EC2 thing, link the EC2 docs) * Anything else you feel it is worthwhile to refer to ",,357,0
openstack%2Fpython-novaclient~master~I666a5c7e6747f0c5c2dc96336774fd0fcd3f5907,openstack/python-novaclient,master,I666a5c7e6747f0c5c2dc96336774fd0fcd3f5907,Convert to requests-mock,MERGED,2014-08-06 02:09:57.000000000,2014-08-08 00:09:55.000000000,2014-08-08 00:09:55.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 7191}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-08-06 02:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/75f039e7d3ce094591e7c0c744123f4f89ee3a0b', 'message': ""Convert to requests-mock\n\nWe've had some trouble with httpretty in the past and so are moving to\nrequests-mock. There should be no functionality change in this patch,\nsimply a transition to a newer library.\n\nChange-Id: I666a5c7e6747f0c5c2dc96336774fd0fcd3f5907\n""}, {'number': 2, 'created': '2014-08-06 04:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/9d0eedfb23d0299eeadc59eb697c17fca5249929', 'message': ""Convert to requests-mock\n\nWe've had some trouble with httpretty in the past and so are moving to\nrequests-mock. There should be no functionality change in this patch,\nsimply a transition to a newer library.\n\nChange-Id: I666a5c7e6747f0c5c2dc96336774fd0fcd3f5907\n""}, {'number': 3, 'created': '2014-08-06 22:46:55.000000000', 'files': ['novaclient/tests/fixture_data/security_groups.py', 'novaclient/tests/fixture_data/servers.py', 'test-requirements.txt', 'novaclient/tests/fixture_data/floatingips.py', 'novaclient/tests/fixture_data/networks.py', 'novaclient/tests/fixture_data/quotas.py', 'novaclient/tests/fixture_data/hosts.py', 'novaclient/tests/fixture_data/server_groups.py', 'novaclient/tests/fixture_data/aggregates.py', 'novaclient/tests/fixture_data/hypervisors.py', 'novaclient/tests/utils.py', 'novaclient/tests/v1_1/test_agents.py', 'novaclient/tests/fixture_data/keypairs.py', 'novaclient/tests/fixture_data/client.py', 'novaclient/tests/fixture_data/images.py', 'novaclient/tests/fixture_data/certs.py', 'novaclient/tests/fixture_data/fixedips.py', 'novaclient/tests/fixture_data/agents.py', 'novaclient/tests/fixture_data/security_group_rules.py', 'novaclient/tests/fixture_data/cloudpipe.py', 'novaclient/tests/fixture_data/limits.py', 'novaclient/tests/fixture_data/fping.py', 'novaclient/tests/fixture_data/base.py', 'novaclient/tests/fixture_data/availability_zones.py', 'novaclient/tests/v1_1/test_servers.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/caf9f799efeff2163cf0adc236986bfa4addfe9d', 'message': ""Convert to requests-mock\n\nWe've had some trouble with httpretty in the past and so are moving to\nrequests-mock. There should be no functionality change in this patch,\nsimply a transition to a newer library.\n\nExamples: \n - Python 2/3 inconsistencies\n - Breaking compatibility between releases\n - Incorrect package dependency specifications\n - Problems with distro packaging around tests \n - *can* introduce a maintained state between tests.\n\nChange-Id: I666a5c7e6747f0c5c2dc96336774fd0fcd3f5907\n""}]",2,112179,caf9f799efeff2163cf0adc236986bfa4addfe9d,23,5,3,7191,,,0,"Convert to requests-mock

We've had some trouble with httpretty in the past and so are moving to
requests-mock. There should be no functionality change in this patch,
simply a transition to a newer library.

Examples: 
 - Python 2/3 inconsistencies
 - Breaking compatibility between releases
 - Incorrect package dependency specifications
 - Problems with distro packaging around tests 
 - *can* introduce a maintained state between tests.

Change-Id: I666a5c7e6747f0c5c2dc96336774fd0fcd3f5907
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/79/112179/1 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/tests/fixture_data/security_groups.py', 'novaclient/tests/fixture_data/servers.py', 'test-requirements.txt', 'novaclient/tests/fixture_data/floatingips.py', 'novaclient/tests/fixture_data/networks.py', 'novaclient/tests/fixture_data/quotas.py', 'novaclient/tests/fixture_data/hosts.py', 'novaclient/tests/fixture_data/server_groups.py', 'novaclient/tests/fixture_data/aggregates.py', 'novaclient/tests/fixture_data/hypervisors.py', 'novaclient/tests/utils.py', 'novaclient/tests/v1_1/test_agents.py', 'novaclient/tests/fixture_data/keypairs.py', 'novaclient/tests/fixture_data/client.py', 'novaclient/tests/fixture_data/images.py', 'novaclient/tests/fixture_data/certs.py', 'novaclient/tests/fixture_data/fixedips.py', 'novaclient/tests/fixture_data/agents.py', 'novaclient/tests/fixture_data/security_group_rules.py', 'novaclient/tests/fixture_data/cloudpipe.py', 'novaclient/tests/fixture_data/limits.py', 'novaclient/tests/fixture_data/fping.py', 'novaclient/tests/fixture_data/base.py', 'novaclient/tests/fixture_data/availability_zones.py', 'novaclient/tests/v1_1/test_servers.py']",25,75f039e7d3ce094591e7c0c744123f4f89ee3a0b,tests,from novaclient.openstack.common import jsonutils self.useFixture(floatingips.FloatingFixture(self.requests)) body = jsonutils.loads(self.requests.last_request.body) body = jsonutils.loads(self.requests.last_request.body) body = jsonutils.loads(self.requests.last_request.body) body = jsonutils.loads(self.requests.last_request.body.decode('utf-8')),import httpretty self.useFixture(floatingips.FloatingFixture()) body = httpretty.last_request().parsed_body body = httpretty.last_request().parsed_body body = httpretty.last_request().parsed_body body = httpretty.last_request().parsed_body,477,518
openstack%2Fbarbican~master~If0761f2c58860b7e8155fd8ae3fac9e4aef3259d,openstack/barbican,master,If0761f2c58860b7e8155fd8ae3fac9e4aef3259d,"Add ""Connection"" HTTP header to response",ABANDONED,2014-08-07 00:47:20.000000000,2014-08-08 00:07:21.000000000,,"[{'_account_id': 3}, {'_account_id': 7262}, {'_account_id': 7687}, {'_account_id': 7973}, {'_account_id': 9234}, {'_account_id': 10273}, {'_account_id': 11970}]","[{'number': 1, 'created': '2014-08-07 00:47:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/82a246df0126ae624e52206a45ac0ea30b11df2e', 'message': 'Add ""Connection"" HTTP header to response\n\nFixes an issue with connection handling that will cause tempest failures\nModeled after the fix by Dmitriy Ukhlov in CR 92448\n\nChange-Id: If0761f2c58860b7e8155fd8ae3fac9e4aef3259d\n'}, {'number': 2, 'created': '2014-08-07 01:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/23b27635af247c0c9ca560ab132085db0bc81179', 'message': 'Add ""Connection"" HTTP header to response\n\nFixes an issue with connection handling that will cause tempest failures\nModeled after the fix by Dmitriy Ukhlov in CR 92448\n\nChange-Id: If0761f2c58860b7e8155fd8ae3fac9e4aef3259d\n'}, {'number': 3, 'created': '2014-08-07 14:13:35.000000000', 'files': ['etc/barbican/barbican-api-paste.ini', 'contrib/devstack/lib/barbican', 'barbican/api/middleware/connection_handler.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/2f7d6f83d54e070e71d728c917dcb911073e8647', 'message': 'Add ""Connection"" HTTP header to response\n\nFixes an issue with connection handling that will cause tempest failures\nModeled after the fix by Dmitriy Ukhlov in CR 92448\n\nChange-Id: If0761f2c58860b7e8155fd8ae3fac9e4aef3259d\n'}]",7,112444,2f7d6f83d54e070e71d728c917dcb911073e8647,24,7,3,10273,,,0,"Add ""Connection"" HTTP header to response

Fixes an issue with connection handling that will cause tempest failures
Modeled after the fix by Dmitriy Ukhlov in CR 92448

Change-Id: If0761f2c58860b7e8155fd8ae3fac9e4aef3259d
",git fetch https://review.opendev.org/openstack/barbican refs/changes/44/112444/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/barbican/barbican-api-paste.ini', 'contrib/devstack/lib/barbican', 'barbican/api/middleware/connection_handler.py']",3,82a246df0126ae624e52206a45ac0ea30b11df2e,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2014 OpenStack LLC. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from barbican.api import middleware as mw from barbican.common import utils LOG = utils.getLogger(__name__) HTTP_CONNECTION = ""Connection"" class ConnectionHandlerMiddleware(mw.Middleware): def __init__(self, app): super(ConnectionHandlerMiddleware, self).__init__(app) def process_request(self, req): response = req.get_response(self.application) connection = req.headers.get(HTTP_CONNECTION, None) if connection: response.headers[HTTP_CONNECTION] = connection return response ",,42,3
openstack%2Fhorizon~master~I34b730ac0f943cb8e341b163c271065246b9b45f,openstack/horizon,master,I34b730ac0f943cb8e341b163c271065246b9b45f,membership widget styling,MERGED,2014-08-04 09:12:31.000000000,2014-08-08 00:01:31.000000000,2014-08-08 00:01:30.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 4428}, {'_account_id': 5623}, {'_account_id': 6914}, {'_account_id': 7665}, {'_account_id': 8648}, {'_account_id': 9576}, {'_account_id': 9622}]","[{'number': 1, 'created': '2014-08-04 09:12:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/195339c1d62257f9a6738cdc0b884672bcf48afa', 'message': 'membership widget styling\n\nNeeds to update membership widget style after Bootstrap upgrading.\n\nChange-Id: I34b730ac0f943cb8e341b163c271065246b9b45f\nCloses-bug: 1347067\n'}, {'number': 2, 'created': '2014-08-05 01:49:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a858d9ca341a1516e4b02c461f4c6db1a642545c', 'message': 'membership widget styling\n\nNeeds to update membership widget style after Bootstrap upgrading.\n\nChange-Id: I34b730ac0f943cb8e341b163c271065246b9b45f\nCloses-bug: 1347067\n'}, {'number': 3, 'created': '2014-08-06 00:02:38.000000000', 'files': ['horizon/templates/horizon/common/_workflow_step_update_members.html', 'openstack_dashboard/static/dashboard/scss/horizon.scss'], 'web_link': 'https://opendev.org/openstack/horizon/commit/6cd893a8512927e6c04ca2a3bc6d8b26059dc155', 'message': 'membership widget styling\n\nNeeds to update membership widget style after Bootstrap upgrading.\n\nChange-Id: I34b730ac0f943cb8e341b163c271065246b9b45f\nCloses-bug: 1347067\n'}]",4,111674,6cd893a8512927e6c04ca2a3bc6d8b26059dc155,30,10,3,4428,,,0,"membership widget styling

Needs to update membership widget style after Bootstrap upgrading.

Change-Id: I34b730ac0f943cb8e341b163c271065246b9b45f
Closes-bug: 1347067
",git fetch https://review.opendev.org/openstack/horizon refs/changes/74/111674/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/dashboard/scss/horizon.scss'],1,195339c1d62257f9a6738cdc0b884672bcf48afa,bug/1347067, margin-left: 5px; width: 650px; background: url(/static/dashboard/img/search.png) no-repeat 95px 2px; background: url(/static/dashboard/img/search.png) no-repeat 95px 5px $gray-lighter; margin-left: -40px;, margin-left: 15px; background: url(/static/dashboard/img/search.png) no-repeat 105px 5px; background: url(/static/dashboard/img/search.png) no-repeat 105px 5px $gray-lighter;,5,3
openstack%2Ftripleo-image-elements~master~I604adab055fe9c1b0d7bee9cc30ac79afb2d2315,openstack/tripleo-image-elements,master,I604adab055fe9c1b0d7bee9cc30ac79afb2d2315,Try to start neutron-server first,MERGED,2014-08-07 20:10:34.000000000,2014-08-07 23:54:22.000000000,2014-08-07 23:54:22.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4190}, {'_account_id': 4571}, {'_account_id': 6928}, {'_account_id': 7144}]","[{'number': 1, 'created': '2014-08-07 20:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/3eed1504042420e1e9a5c8eae26b7cc6810c20ba', 'message': ""Ensure neutron-server starts first\n\nHaving neutron-l3-agent start before neutron-server appears to be\na problem because neutron-l3-agent dies if it doesn't get a\nresponse to an rpc it sends at startup.  This change moves the\nrestart of neutron-server ahead of the other neutron services so\nthat can't happen.\n\nChange-Id: I604adab055fe9c1b0d7bee9cc30ac79afb2d2315\nCloses-Bug: 1353953\n""}, {'number': 2, 'created': '2014-08-07 22:00:59.000000000', 'files': ['elements/neutron-server/os-refresh-config/post-configure.d/79-neutron-server'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/8322ffdc8a35d7875b78a9e265e8ca70c1ee936e', 'message': 'Try to start neutron-server first\n\nneutron-l3-agent fails to start if neutron-server does not respond\nto an rpc message within one minute.  Because of the order our\nneutron scripts run in, this often happens.  To work around\nthe problem, this change moves the neutron-server script from\nthe 80 level to 79 so it will be started before the other neutron\nservices.\n\nUltimately this needs to be solved in neutron-l3-agent, but right\nnow this is blocking our CI so we need to address it immediately.\n\nChange-Id: I604adab055fe9c1b0d7bee9cc30ac79afb2d2315\nPartial-Bug: 1353953\n'}]",0,112674,8322ffdc8a35d7875b78a9e265e8ca70c1ee936e,19,6,2,6928,,,0,"Try to start neutron-server first

neutron-l3-agent fails to start if neutron-server does not respond
to an rpc message within one minute.  Because of the order our
neutron scripts run in, this often happens.  To work around
the problem, this change moves the neutron-server script from
the 80 level to 79 so it will be started before the other neutron
services.

Ultimately this needs to be solved in neutron-l3-agent, but right
now this is blocking our CI so we need to address it immediately.

Change-Id: I604adab055fe9c1b0d7bee9cc30ac79afb2d2315
Partial-Bug: 1353953
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/74/112674/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/neutron-server/os-refresh-config/post-configure.d/79-neutron-server'],1,3eed1504042420e1e9a5c8eae26b7cc6810c20ba,bug/1353953,,,0,0
openstack%2Fpython-glanceclient~master~I863ba08d312363dc1ce4fc7822fb21ef53df1a4f,openstack/python-glanceclient,master,I863ba08d312363dc1ce4fc7822fb21ef53df1a4f,Add support for Keystone v3,MERGED,2014-03-21 15:26:30.000000000,2014-08-07 23:49:54.000000000,2014-08-07 23:49:53.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 970}, {'_account_id': 1916}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6549}, {'_account_id': 7052}, {'_account_id': 7817}, {'_account_id': 8871}, {'_account_id': 11045}, {'_account_id': 11333}]","[{'number': 1, 'created': '2014-03-21 15:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/f42e024d658148a477f4adc82b0300dda9965d29', 'message': 'Add support for Keystone v3\n\nThis allows glanceclient to auth via Keystone v3, this includes\nthe addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 2, 'created': '2014-03-31 09:42:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/8f48d9137808abd44e73b0e5d676a86f699d612c', 'message': 'Add support for Keystone v3\n\nThis allows glanceclient to auth via Keystone v3, this includes\nthe addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 3, 'created': '2014-03-31 12:15:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/274f5c49212c54f517b2b9947ae9e0034cc38bf2', 'message': 'Add support for Keystone v3\n\nThis allows glanceclient to auth via Keystone v3, this includes\nthe addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 4, 'created': '2014-03-31 12:15:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/174f51a26b7c3754f63579050af719528d0e3cd1', 'message': 'Add support for Keystone v3\n\nThis allows glanceclient to auth via Keystone v3, this includes\nthe addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 5, 'created': '2014-05-23 02:31:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/350a173d8e0681a25786ac057e1070cf7bf12b9c', 'message': 'Add support for Keystone v3\n\nThis allows glanceclient to auth via Keystone v3, this includes\nthe addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 6, 'created': '2014-06-13 07:07:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/9df946580ec3e0e729d74d9a1398254f750a124d', 'message': 'Add support for Keystone v3\n\nThis allows glanceclient to auth via Keystone v3, this includes\nthe addition of several new CLI arguments.\n\nA number of CLI parameters are marked as deprecated and are\ntracked via bp/python-glanceclient/+spec/cli-parameter-deprecation\n\nDO NOT MERGE\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 7, 'created': '2014-06-23 18:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/7478c7da3cfe80c23f6e4244bf98fc6074364a9c', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 8, 'created': '2014-06-24 00:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/873658d5c228936c39b8c7a0c8931d07f0f7638a', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 9, 'created': '2014-06-24 04:41:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/cd5da9b7582e06b840e4e4b731f3eeb12dfa541e', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 10, 'created': '2014-06-24 04:45:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/72fbbc8f86a923ac49674ee1d509932d21797173', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 11, 'created': '2014-06-24 05:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/ee7f18167e040f38e7d6061ea86bc0ad11cc8fbb', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 12, 'created': '2014-06-24 08:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/e87a7684b90ff9a997dc1970e6758e6c397370d5', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 13, 'created': '2014-06-24 15:03:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/379e8ba2e7347f6287355062a9dc96c0493ab518', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 14, 'created': '2014-06-25 16:30:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/dfa5ca180e3d8f764f69b035c69c1fa1139c033d', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 15, 'created': '2014-06-25 19:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/9db4f996c7d0d9b7dfe3133a0eccac9135f361a6', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 16, 'created': '2014-06-25 22:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/7ed9c3fbd9b50cf30cd4424a90032aaefbbefd31', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 17, 'created': '2014-06-26 17:41:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/0ceedb88324c2b436c7e134db1ea28db69b698b9', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 18, 'created': '2014-06-26 17:43:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/1a1fa0eb18813d09bd9ab1f766aedb41a70645f5', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 19, 'created': '2014-06-27 00:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/545dce683b1d15a2fbcbdb3664eaeada8335cc4a', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 20, 'created': '2014-06-27 05:30:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/e64b48db65bb5a3e1919ff3c25d0c6391c48e329', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 21, 'created': '2014-06-27 12:10:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/b46cfbb42b6bde1bc0b1434133bf6912eabbd4af', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 22, 'created': '2014-06-27 23:26:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/8ed648978aeb6c4000d65f8e3dfd09d462b1174d', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 23, 'created': '2014-06-28 02:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/1a33ee8d5903a49547d6b173e6dcbd88a5004dd3', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 24, 'created': '2014-06-30 17:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/531061405eb9c8517ba7240a67fa76e6275ac388', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 25, 'created': '2014-06-30 20:59:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/0d889700792a92cea1ebb1d9fb295397b8d24fd2', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 26, 'created': '2014-07-02 19:36:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/b015f119afea700500af835810b4525fe7dee102', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 27, 'created': '2014-07-03 06:36:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/3404cb46df6109d3f8882b41d34749c31ff12e78', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 28, 'created': '2014-07-09 00:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/ee0d4d986d9ac3a34259d70998765486761c52c5', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 29, 'created': '2014-07-10 23:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/6e0f704ac6d4028f01a0d7a7872edffbccd1ec75', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}, {'number': 30, 'created': '2014-08-05 18:05:29.000000000', 'files': ['glanceclient/shell.py', 'tests/test_shell.py', 'tests/keystone_client_fixtures.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/f15dc6b82f1972e8995ad695bd8b3b52bf5c3897', 'message': 'Add support for Keystone v3\n\nThis enables glanceclient to authenticate using Keystone v3\nAPI and includes the addition of several new CLI arguments.\n\nDocImpact\n\nChange-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f\n'}]",31,82126,f15dc6b82f1972e8995ad695bd8b3b52bf5c3897,152,12,30,7817,,,0,"Add support for Keystone v3

This enables glanceclient to authenticate using Keystone v3
API and includes the addition of several new CLI arguments.

DocImpact

Change-Id: I863ba08d312363dc1ce4fc7822fb21ef53df1a4f
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/26/82126/17 && git format-patch -1 --stdout FETCH_HEAD,['glanceclient/shell.py'],1,f42e024d658148a477f4adc82b0300dda9965d29,KeystoneV3Support,"from keystoneclient.v2_0 import client as ksclient_v2 from keystoneclient.v3 import client as ksclient_v3 parser.add_argument('--os-user-id', default=utils.env('OS_USER_ID'), help='Defaults to env[OS_USER_ID].') parser.add_argument('--os_user_id', help=argparse.SUPPRESS) parser.add_argument('--os-user-domain-id', default=utils.env('OS_USER_DOMAIN_ID'), help='Defaults to env[OS_USER_DOMAIN_ID].') parser.add_argument('--os_user_domain_id', help=argparse.SUPPRESS) parser.add_argument('--os-user-domain-name', default=utils.env('OS_USER_DOMAIN_NAME'), help='Defaults to env[OS_USER_DOMAIN_NAME].') parser.add_argument('--os_user_domain_name', help=argparse.SUPPRESS) parser.add_argument('--os-project-id', default=utils.env('OS_PROJECT_ID'), help='Another way to specify tenant ID. ' 'This option is mutually exclusive with ' ' --os-tenant-id. ' 'Defaults to env[OS_PROJECT_ID].') parser.add_argument('--os_project_id', help=argparse.SUPPRESS) parser.add_argument('--os-project-name', default=utils.env('OS_PROJECT_NAME'), help='Another way to specify tenant name. ' 'This option is mutually exclusive with ' ' --os-tenant-name. ' 'Defaults to env[OS_PROJECT_NAME].') parser.add_argument('--os_project_name', help=argparse.SUPPRESS) parser.add_argument('--os-project-domain-id', default=utils.env('OS_PROJECT_DOMAIN_ID'), help='Defaults to env[OS_PROJECT_DOMAIN_ID].') parser.add_argument('--os_project_domain_id', help=argparse.SUPPRESS) parser.add_argument('--os-project-domain-name', default=utils.env('OS_PROJECT_DOMAIN_NAME'), help='Defaults to env[OS_PROJECT_DOMAIN_NAME].') parser.add_argument('--os_project_domain_name', help=argparse.SUPPRESS) """"""Get an endpoint and auth token from Keystone."""""" auth_url = kwargs.pop('auth_url', None) username = kwargs.pop('username', None) user_id = kwargs.pop('user_id', None) user_domain_id = kwargs.pop('user_domain_id', None) user_domain_name = kwargs.pop('user_domain_name', None) password = kwargs.pop('password', None) project_name = kwargs.pop('tenant_name', None) if not project_name: project_name = kwargs.pop('project_name', None) project_id = kwargs.pop('tenant_id', None) if not project_id: project_id = kwargs.pop('project_id', None) project_domain_name = kwargs.pop('project_domain_name', None) project_domain_id = kwargs.pop('project_domain_id', None) if not auth_url: raise exc.CommandError(""You must provide an auth url via "" ""either --os-auth-url or "" ""via env[OS_AUTH_URL]."") auth_url = auth_url.rstrip('/') if auth_url.endswith('/v3'): return self._get_v3_ksclient(auth_url, username, user_id, user_domain_name, user_domain_id, password, project_name, project_id, project_domain_name, project_domain_id, **kwargs) else: # assume v2.0 return self._get_v2_ksclient(auth_url, username, password, project_name, project_id, **kwargs) def _get_v3_ksclient(self, auth_url, username, user_id, user_domain_name, user_domain_id, password, project_name, project_id, project_domain_name, project_domain_id, **kwargs): user_info = user_id or username and (user_domain_id or user_domain_name) project_info = project_id or project_name and (project_domain_id or project_domain_name) if not user_info: raise exc.CommandError(""You must provide either a user id or "" ""username with user domain name/id via "" ""--os-user-id, --os-username, "" ""--os-user-domain-name, "" ""--os-user-domain-id, env[OS_USER_ID], "" ""env[OS_USERNAME], "" ""env[OS_USER_DOMAIN_NAME] or "" ""env[OS_USER_DOMAIN_ID]."") if not password: raise exc.CommandError(""You must provide a password via "" ""either --os-password or "" ""env[OS_PASSWORD]."") if not project_info: raise exc.CommandError(""You must provide either a project id "" ""or project name with project domain "" ""name/id via --os-project-id, "" ""--os-project-name, "" ""--os-project-domain-name, "" ""--os-project-domain-id, "" ""env[OS_PROJECT_ID], env[OS_PROJECT_NAME], "" ""env[OS_PROJECT_DOMAIN_NAME] or "" ""env[OS_PROJECT_DOMAIN_ID]."") return ksclient_v3.Client(auth_url=auth_url, username=username, user_id=user_id, user_domain_id=user_domain_id, user_domain_name=user_domain_name, password=password, project_id=project_id, project_name=project_name, project_domain_id=project_domain_id, project_domain_name=project_domain_name, **kwargs) def _get_v2_ksclient(self, auth_url, username, password, project_name, project_id, **kwargs): project_info = project_name or project_id if not username: raise exc.CommandError(""You must provide a username via "" ""either --os-username or "" ""env[OS_USERNAME]"") if not password: raise exc.CommandError(""You must provide a password via "" ""either --os-password or "" ""env[OS_PASSWORD]"") if not project_info: raise exc.CommandError(""You must provide either a project "" ""name or id via --os-project-name, "" ""--os-project-id, env[OS_PROJECT_NAME] "" ""or env[OS_PROJECT_ID]."") return ksclient_v2.Client(auth_url=auth_url, username=username, password=password, tenant_id=project_id, tenant_name=project_name, **kwargs) kwargs = { 'username': args.os_username, 'user_id': args.os_user_id, 'user_domain_id': args.os_user_domain_id, 'user_domain_name': args.os_user_domain_name, 'password': args.os_password, 'tenant_name': args.os_tenant_name, 'tenant_id': args.os_tenant_id, 'project_name': args.os_project_name, 'project_id': args.os_project_id, 'project_domain_name': args.os_project_domain_name, 'project_domain_id': args.os_project_domain_id, 'insecure': args.insecure, 'cacert': args.os_cacert,","from keystoneclient.v2_0 import client as ksclient """"""Get an endpoint and auth token from Keystone. :param username: name of user :param password: user's password :param tenant_id: unique identifier of tenant :param tenant_name: name of tenant :param auth_url: endpoint to authenticate against """""" return ksclient.Client(username=kwargs.get('username'), password=kwargs.get('password'), tenant_id=kwargs.get('tenant_id'), tenant_name=kwargs.get('tenant_name'), auth_url=kwargs.get('auth_url'), cacert=kwargs.get('cacert'), insecure=kwargs.get('insecure')) if not args.os_username: raise exc.CommandError(""You must provide a username via"" "" either --os-username or "" ""env[OS_USERNAME]"") if not args.os_password: raise exc.CommandError(""You must provide a password via"" "" either --os-password or "" ""env[OS_PASSWORD]"") if not (args.os_tenant_id or args.os_tenant_name): raise exc.CommandError(""You must provide a tenant_id via"" "" either --os-tenant-id or "" ""via env[OS_TENANT_ID]"") if not args.os_auth_url: raise exc.CommandError(""You must provide an auth url via"" "" either --os-auth-url or "" ""via env[OS_AUTH_URL]"") kwargs = { 'username': args.os_username, 'password': args.os_password, 'tenant_id': args.os_tenant_id, 'tenant_name': args.os_tenant_name, 'cacert': args.os_cacert, 'insecure': args.insecure,",178,40
openstack%2Fopenstack-manuals~master~I6e9b9c0d43f59111891e0ea4817b88487619a2af,openstack/openstack-manuals,master,I6e9b9c0d43f59111891e0ea4817b88487619a2af,Adds a landing page for the Architecture Design Guide,MERGED,2014-08-05 16:36:14.000000000,2014-08-07 23:42:45.000000000,2014-08-07 23:42:44.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 7472}, {'_account_id': 7751}, {'_account_id': 8128}, {'_account_id': 10348}]","[{'number': 1, 'created': '2014-08-05 16:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6b6b291e1786a2d1e6efeae11d14ba34d155129b', 'message': 'Adds a landing page for the Architecture Design Guide\n\nChange-Id: I6e9b9c0d43f59111891e0ea4817b88487619a2af\n'}, {'number': 2, 'created': '2014-08-06 02:57:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/36f099ea628bdb8b223916553e845b32de87a64a', 'message': 'Adds a landing page for the Architecture Design Guide\n\nChange-Id: I6e9b9c0d43f59111891e0ea4817b88487619a2af\n'}, {'number': 3, 'created': '2014-08-06 19:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6436f64be8373c1ce695df9cd98026c743d42bce', 'message': 'Adds a landing page for the Architecture Design Guide\n\n- Removes /arc in preference to /arch\n- Adds redirect to .htaccess\n- Adds direct links to Ops Guide rather than /ops landing for consistency\n\nChange-Id: I6e9b9c0d43f59111891e0ea4817b88487619a2af\n'}, {'number': 4, 'created': '2014-08-07 12:41:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3ea3400c2c32024db312f8ecd2eb72f6fbb4f1dc', 'message': 'Adds a landing page for the Architecture Design Guide\n\n- Removes /arc in preference to /arch\n- Adds redirect to .htaccess\n- Adds direct links to Ops Guide rather than /ops landing for consistency\n\nChange-Id: I6e9b9c0d43f59111891e0ea4817b88487619a2af\n'}, {'number': 5, 'created': '2014-08-07 18:51:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7a15e4732573a070fa6989fa8da6fd8dd13a4996', 'message': 'Adds a landing page for the Architecture Design Guide\n\n- Removes /arc in preference to /arch\n- Adds redirect to .htaccess\n- Adds direct links to Ops Guide rather than /ops landing for consistency\n\nChange-Id: I6e9b9c0d43f59111891e0ea4817b88487619a2af\n'}, {'number': 6, 'created': '2014-08-07 18:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/812885164dead739de710d1074b7884481e38876', 'message': 'Adds a landing page for the Architecture Design Guide\n\n- Removes /arc in preference to /arch\n- Adds redirect to .htaccess\n- Adds direct links to Ops Guide rather than /ops landing for consistency\n\nChange-Id: I6e9b9c0d43f59111891e0ea4817b88487619a2af\n'}, {'number': 7, 'created': '2014-08-07 19:52:27.000000000', 'files': ['www/.htaccess', 'www/arch/OpenStackArchitectureDesignGuide.epub', 'www/icehouse/index.html', 'www/arch/index.html', 'www/common/images/arch-guide-cover.png', 'www/havana/index.html', 'www/common/images/openstack-arch-guide-team.png', 'www/index.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/60a82622c50b8d25381995ede0c4ca94108633d4', 'message': 'Adds a landing page for the Architecture Design Guide\n\n- Removes /arc in preference to /arch\n- Adds redirect to .htaccess\n- Adds direct links to Ops Guide rather than /ops landing for consistency\n\nChange-Id: I6e9b9c0d43f59111891e0ea4817b88487619a2af\n'}]",8,112070,60a82622c50b8d25381995ede0c4ca94108633d4,48,8,7,964,,,0,"Adds a landing page for the Architecture Design Guide

- Removes /arc in preference to /arch
- Adds redirect to .htaccess
- Adds direct links to Ops Guide rather than /ops landing for consistency

Change-Id: I6e9b9c0d43f59111891e0ea4817b88487619a2af
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/70/112070/3 && git format-patch -1 --stdout FETCH_HEAD,"['www/arc/index.html', 'www/common/images/arch-guide-cover.png', 'www/common/images/openstack-arch-guide-team.png']",3,6b6b291e1786a2d1e6efeae11d14ba34d155129b,arch-guide-landing,,,280,0
openstack%2Fglance~master~Ie1ed1b7f06b8a0aeede70c3d4dd061c857e448da,openstack/glance,master,Ie1ed1b7f06b8a0aeede70c3d4dd061c857e448da,Quota column name 'key' in downgrade script,MERGED,2014-08-01 18:19:42.000000000,2014-08-07 23:34:53.000000000,2014-08-07 23:34:52.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 6549}, {'_account_id': 8759}]","[{'number': 1, 'created': '2014-08-01 18:19:42.000000000', 'files': ['glance/db/sqlalchemy/migrate_repo/versions/006_mysql_downgrade.sql'], 'web_link': 'https://opendev.org/openstack/glance/commit/579e0c18751216177c94d02f6488907165ce17ec', 'message': ""Quota column name 'key' in downgrade script\n\n006_mysql_downgrade didn't correctly quote 'key' column of\n'image_properties' table when creating index, the index wasn't created\nas needed, and then operator could not run any upgrade script\nsuccessfully since 006_mysql_upgrade script could not to handle this\nunexpected db status.\n\nNote, this issue doesn't impact one-way upgrade migration operation,\nsince bug existed in downgrade script. But once operator do a\nreciprocating migration operation, this issue will rise up as a blocker.\n\nCloses-bug: 1351413\n\nChange-Id: Ie1ed1b7f06b8a0aeede70c3d4dd061c857e448da\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>""}]",1,111358,579e0c18751216177c94d02f6488907165ce17ec,11,4,1,6549,,,0,"Quota column name 'key' in downgrade script

006_mysql_downgrade didn't correctly quote 'key' column of
'image_properties' table when creating index, the index wasn't created
as needed, and then operator could not run any upgrade script
successfully since 006_mysql_upgrade script could not to handle this
unexpected db status.

Note, this issue doesn't impact one-way upgrade migration operation,
since bug existed in downgrade script. But once operator do a
reciprocating migration operation, this issue will rise up as a blocker.

Closes-bug: 1351413

Change-Id: Ie1ed1b7f06b8a0aeede70c3d4dd061c857e448da
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>",git fetch https://review.opendev.org/openstack/glance refs/changes/58/111358/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/db/sqlalchemy/migrate_repo/versions/006_mysql_downgrade.sql'],1,579e0c18751216177c94d02f6488907165ce17ec,,"CREATE UNIQUE INDEX ix_image_properties_image_id_key ON image_properties (image_id, `key`);","CREATE UNIQUE INDEX ix_image_properties_image_id_key ON image_properties (image_id, key);",1,1
openstack%2Fnova~master~Ia96c9668c74374476d4dccdbdb281e99d91b0088,openstack/nova,master,Ia96c9668c74374476d4dccdbdb281e99d91b0088,Catch NeutronClientException when showing a network,MERGED,2014-03-03 02:46:59.000000000,2014-08-07 23:03:48.000000000,2014-08-07 06:53:38.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 6348}, {'_account_id': 6873}, {'_account_id': 7461}, {'_account_id': 7641}, {'_account_id': 8163}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9533}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10612}]","[{'number': 1, 'created': '2014-03-03 02:46:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ab6aa14c870d1d00975252683271c0e3537a7985', 'message': ""Catch NeutronClientException when showing a network\n\nThe NeutronClientException raised by neutronclient isn't caught\nby nova.network.neutronv2.api when using neutronclient to show\na network details. This will cause a 500 error.\nThis patch fixes this bug.\n\nCloses-Bug: #1286969\nChange-Id: Ia96c9668c74374476d4dccdbdb281e99d91b0088\n""}, {'number': 2, 'created': '2014-03-19 09:56:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fbd47ebddffdf7e8e03326c3da55ecc8cd4ff967', 'message': ""Catch NeutronClientException when showing a network\n\nThe NeutronClientException raised by neutronclient isn't caught\nby nova.network.neutronv2.api when using neutronclient to show\na network details. This will cause a 500 error.\nThis patch fixes this bug.\n\nCloses-Bug: #1286969\nChange-Id: Ia96c9668c74374476d4dccdbdb281e99d91b0088\n""}, {'number': 3, 'created': '2014-04-21 00:04:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b4b962576b84590307af10b4439b9606227daac8', 'message': ""Catch NeutronClientException when showing a network\n\nThe NeutronClientException raised by neutronclient isn't caught\nby nova.network.neutronv2.api when using neutronclient to show\na network details. This will cause a 500 error.\nThis patch fixes this bug.\n\nCloses-Bug: #1286969\nChange-Id: Ia96c9668c74374476d4dccdbdb281e99d91b0088\n""}, {'number': 4, 'created': '2014-07-14 07:03:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0322fd0b9a5b98036a3fe1260d6d0f551984832c', 'message': ""Catch NeutronClientException when showing a network\n\nThe NeutronClientException raised by neutronclient isn't caught\nby nova.network.neutronv2.api when using neutronclient to show\na network details. This will cause a 500 error.\nThis patch fixes this bug.\n\nCloses-Bug: #1286969\nChange-Id: Ia96c9668c74374476d4dccdbdb281e99d91b0088\n""}, {'number': 5, 'created': '2014-07-14 08:05:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b3903a55f6d493963f97780482ed66100f52f65', 'message': ""Catch NeutronClientException when showing a network\n\nThe NeutronClientException raised by neutronclient isn't caught\nby nova.network.neutronv2.api when using neutronclient to show\na network details. This will cause a 500 error.\nThis patch fixes this bug.\n\nCloses-Bug: #1286969\nChange-Id: Ia96c9668c74374476d4dccdbdb281e99d91b0088\n""}, {'number': 6, 'created': '2014-07-29 23:49:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f7b5e6fda12b5deac8515733cb0ca67924202a11', 'message': ""Catch NeutronClientException when showing a network\n\nThe NeutronClientException raised by neutronclient isn't caught\nby nova.network.neutronv2.api when using neutronclient to show\na network details. This will cause a 500 error.\nThis patch fixes this bug.\n\nCloses-Bug: #1286969\nChange-Id: Ia96c9668c74374476d4dccdbdb281e99d91b0088\n""}, {'number': 7, 'created': '2014-07-30 01:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d1936047dbb8ddc60e41c71e7d83de849920f9ad', 'message': ""Catch NeutronClientException when showing a network\n\nThe NeutronClientException raised by neutronclient isn't caught\nby nova.network.neutronv2.api when using neutronclient to show\na network details. This will cause a 500 error.\nThis patch fixes this bug.\n\nCloses-Bug: #1286969\nChange-Id: Ia96c9668c74374476d4dccdbdb281e99d91b0088\n""}, {'number': 8, 'created': '2014-08-05 08:47:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a84992f2f46794a22743634c325b8bb2d232207f', 'message': ""Catch NeutronClientException when showing a network\n\nThe NeutronClientException raised by neutronclient isn't caught\nby nova.network.neutronv2.api when using neutronclient to show\na network details. This will cause a 500 error.\nThis patch fixes this bug.\n\nCloses-Bug: #1286969\nChange-Id: Ia96c9668c74374476d4dccdbdb281e99d91b0088\n""}, {'number': 9, 'created': '2014-08-06 05:34:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/881e7880e5afd08bfd909e21908738cb4689a4e8', 'message': ""Catch NeutronClientException when showing a network\n\nThe NeutronClientException raised by neutronclient isn't caught\nby nova.network.neutronv2.api when using neutronclient to show\na network details. This will cause a 500 error.\nThis patch fixes this bug.\n\nCloses-Bug: #1286969\nChange-Id: Ia96c9668c74374476d4dccdbdb281e99d91b0088\n""}, {'number': 10, 'created': '2014-08-06 05:46:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/339f2089d830fde610a25014e3bcb3358a50da1b', 'message': ""Catch NeutronClientException when showing a network\n\nWhen a network id can't be found, neutronclient raise\nNetworkNotFoundClient exception, but this exception is not\nhandled by nova. This will cause a 500 error.\nThis patch fixes this bug.\n\nCloses-Bug: #1286969\nChange-Id: Ia96c9668c74374476d4dccdbdb281e99d91b0088\n""}, {'number': 11, 'created': '2014-08-07 01:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f379f69a5f8799c5c8b1efd5d79e29869c3354d9', 'message': ""Catch NeutronClientException when showing a network\n\nWhen a network id can't be found, neutronclient raise\nNetworkNotFoundClient exception, but this exception is not\nhandled by nova. This will cause a 500 error.\nThis patch fixes this bug.\n\nCloses-Bug: #1286969\nChange-Id: Ia96c9668c74374476d4dccdbdb281e99d91b0088\n""}, {'number': 12, 'created': '2014-08-07 02:45:19.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/dac0ce979ed7871539c8bcf19fcc73a2ab1390a3', 'message': ""Catch NeutronClientException when showing a network\n\nWhen a network id can't be found, neutronclient raise\nNetworkNotFoundClient exception, but this exception is not\nhandled by nova. This will cause a 500 error.\nThis patch fixes this bug.\n\nCloses-Bug: #1286969\nChange-Id: Ia96c9668c74374476d4dccdbdb281e99d91b0088\n""}]",30,77477,dac0ce979ed7871539c8bcf19fcc73a2ab1390a3,189,22,12,6348,,,0,"Catch NeutronClientException when showing a network

When a network id can't be found, neutronclient raise
NetworkNotFoundClient exception, but this exception is not
handled by nova. This will cause a 500 error.
This patch fixes this bug.

Closes-Bug: #1286969
Change-Id: Ia96c9668c74374476d4dccdbdb281e99d91b0088
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/77477/12 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py']",2,ab6aa14c870d1d00975252683271c0e3537a7985,catch_NeutronClientException," try: network = client.show_network(network_uuid).get('network') or {} network['label'] = network['name'] except neutronv2.exceptions.NeutronClientException as e: if e.status_code == 404: raise exception.NetworkNotFound(network_id=network_uuid) else: with excutils.save_and_reraise_exception(): LOG.exception(_(""Failed to access network %s""), network_uuid)", network = client.show_network(network_uuid).get('network') or {} network['label'] = network['name'],23,2
openstack%2Fneutron~master~Ib630e57c186da60eb15f9ffa6b1b0bfa74f48caa,openstack/neutron,master,Ib630e57c186da60eb15f9ffa6b1b0bfa74f48caa,Fix to enable L2pop to serve DVR,MERGED,2014-08-06 07:32:35.000000000,2014-08-07 22:39:51.000000000,2014-08-07 19:05:00.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 2888}, {'_account_id': 5170}, {'_account_id': 6876}, {'_account_id': 7448}, {'_account_id': 9361}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}]","[{'number': 1, 'created': '2014-08-06 07:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/12f1a4d2fe87e4ec89b298feb34447db139198b5', 'message': 'Fix to enable L2pop to serve DVR\n\nThis change fixes the information used by the L2pop\ndriver to populate l2pop rules that enables DVR to\nroute packets across compute servers that have\ntenant VMs that belong to different networks.\nIt also fixes the case where VMs were not able to\nobtain IP Addresses when such VMs are on DVR\nhisted subnets.\n\nChange-Id: Ib630e57c186da60eb15f9ffa6b1b0bfa74f48caa\nCloses-Bug: #1350485, #1352857\n'}, {'number': 2, 'created': '2014-08-06 07:36:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aaa206eb1345e22715360454198e290c5845709f', 'message': 'Fix to enable L2pop to serve DVR\n\nThis change fixes the information used by the L2pop\ndriver to populate l2pop rules that enables DVR to\nroute packets across compute servers that have\ntenant VMs that belong to different networks.\nIt also fixes the case where VMs were not able to\nobtain IP Addresses when such VMs are on DVR\nhisted subnets.\n\nChange-Id: Ib630e57c186da60eb15f9ffa6b1b0bfa74f48caa\nCloses-Bug: #1350485,#1352857\n'}, {'number': 3, 'created': '2014-08-06 07:41:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e345c3890d3efae90f44b5eba20534802008ed40', 'message': 'Fix to enable L2pop to serve DVR\n\nThis change fixes the information used by the L2pop\ndriver to populate l2pop rules that enables DVR to\nroute packets across compute servers that have\ntenant VMs that belong to different networks.\nIt also fixes the case where VMs were not able to\nobtain IP Addresses when such VMs are on DVR\nhisted subnets.\n\nChange-Id: Ib630e57c186da60eb15f9ffa6b1b0bfa74f48caa\nCloses-Bug: #1350485\nCloses-Bug: #1352857\n'}, {'number': 4, 'created': '2014-08-06 07:43:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d94bc24193d8b0bb89297467bbfa7abe2da6b901', 'message': 'Fix to enable L2pop to serve DVR\n\nThis change fixes the information used by the L2pop\ndriver to populate l2pop rules that enables DVR to\nroute packets across compute servers that have\ntenant VMs that belong to different networks.\nIt also fixes the case where VMs were not able to\nobtain IP Addresses when such VMs are on DVR\nhosted subnets.\n\nChange-Id: Ib630e57c186da60eb15f9ffa6b1b0bfa74f48caa\nCloses-Bug: #1350485\nCloses-Bug: #1352857\n'}, {'number': 5, 'created': '2014-08-06 23:06:39.000000000', 'files': ['neutron/plugins/ml2/drivers/l2pop/mech_driver.py', 'neutron/plugins/ml2/driver_context.py', 'neutron/tests/unit/ml2/test_driver_context.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/dc658273e7cfe72e50dad40203db8bb0d9bb2188', 'message': 'Fix to enable L2pop to serve DVR\n\nThis change fixes the information used by the L2pop\ndriver to populate l2pop rules that enables DVR to\nroute packets across compute servers that have\ntenant VMs that belong to different networks.\nIt also fixes the case where VMs were not able to\nobtain IP Addresses when such VMs are on DVR\nhosted subnets.\n\nChange-Id: Ib630e57c186da60eb15f9ffa6b1b0bfa74f48caa\nCloses-Bug: #1350485\nCloses-Bug: #1352857\n'}]",15,112229,dc658273e7cfe72e50dad40203db8bb0d9bb2188,91,22,5,9361,,,0,"Fix to enable L2pop to serve DVR

This change fixes the information used by the L2pop
driver to populate l2pop rules that enables DVR to
route packets across compute servers that have
tenant VMs that belong to different networks.
It also fixes the case where VMs were not able to
obtain IP Addresses when such VMs are on DVR
hosted subnets.

Change-Id: Ib630e57c186da60eb15f9ffa6b1b0bfa74f48caa
Closes-Bug: #1350485
Closes-Bug: #1352857
",git fetch https://review.opendev.org/openstack/neutron refs/changes/29/112229/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/l2pop/mech_driver.py', 'neutron/tests/unit/ml2/drivers/test_dvr_l2population.py', 'neutron/plugins/ml2/driver_context.py']",3,12f1a4d2fe87e4ec89b298feb34447db139198b5,bp/neutron-ovs-dvr, def host(self): agent_host = self._port.get(portbindings.HOST_ID) @property def status(self): if self._port['device_owner'] == constants.DEVICE_OWNER_DVR_INTERFACE: status = self._binding.status else: status = self._port['status'] return status, def bound_host(self): agent_host = self._port['binding:host_id'],1116,5
openstack%2Fnova~master~I2ae4a9d2f5383ff05f47d00550c1c917fedc5db9,openstack/nova,master,I2ae4a9d2f5383ff05f47d00550c1c917fedc5db9,VMware: remove local variable,MERGED,2014-07-22 22:37:00.000000000,2014-08-07 22:27:24.000000000,2014-08-04 11:33:36.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-22 22:37:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32e1037e089287dfdb1e22a0a64f6cd7fac2c5ef', 'message': 'VMware: remove local variable\n\nMake use of the instance.root_gb instead of reading the value\ninto a local variable.\n\nTrivialFix\n\nChange-Id: I2ae4a9d2f5383ff05f47d00550c1c917fedc5db9\n'}, {'number': 2, 'created': '2014-07-24 19:16:07.000000000', 'files': ['nova/virt/vmwareapi/vmops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/aa300fcbfd88f984dce53d853d255270b73b5dbd', 'message': 'VMware: remove local variable\n\nMake use of the instance.root_gb instead of reading the value\ninto a local variable.\n\nTrivialFix\n\nChange-Id: I2ae4a9d2f5383ff05f47d00550c1c917fedc5db9\n'}]",0,108860,aa300fcbfd88f984dce53d853d255270b73b5dbd,28,10,2,1653,,,0,"VMware: remove local variable

Make use of the instance.root_gb instead of reading the value
into a local variable.

TrivialFix

Change-Id: I2ae4a9d2f5383ff05f47d00550c1c917fedc5db9
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/108860/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/vmwareapi/vmops.py'],1,32e1037e089287dfdb1e22a0a64f6cd7fac2c5ef,remove-local-var, root_gb_in_kb = instance.root_gb * units.Mi if instance.root_gb:, root_gb = instance.root_gb root_gb_in_kb = root_gb * units.Mi if root_gb:,2,3
openstack%2Ftripleo-heat-templates~master~Icc97e36a1db198b973041346cf2056f68de661a2,openstack/tripleo-heat-templates,master,Icc97e36a1db198b973041346cf2056f68de661a2,Set basic pacemaker and corosync properties in undercloud,MERGED,2014-07-31 19:36:18.000000000,2014-08-07 22:26:55.000000000,2014-08-07 22:26:55.000000000,"[{'_account_id': 3}, {'_account_id': 4330}, {'_account_id': 6928}, {'_account_id': 7144}]","[{'number': 1, 'created': '2014-07-31 19:36:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/395d2ce16e9576e0796b87d9bec8bb32f27cffd3', 'message': 'Set basic pacemaker and corosync properties in undercloud\n\nBecause services which depend on pacemaker (ceilometer central\nagent and neutron services) are used in undercloud too, we need to\nset basic pacemaker and corosync metadata for undercloud.\n\nRelated to: Ifa83d62c2132bcdcb40d0b7c80ce3adadc0b5587\nRelated to: I63f054a8c80f9f676a77341c89e605b5b472d078\nChange-Id: Icc97e36a1db198b973041346cf2056f68de661a2\n'}, {'number': 2, 'created': '2014-08-06 14:08:22.000000000', 'files': ['undercloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4fd5693c3cd808561e409e8004ce885d27e24366', 'message': 'Set basic pacemaker and corosync properties in undercloud\n\nBecause services which depend on pacemaker (ceilometer central\nagent and neutron services) are used in undercloud too, we need to\nset basic pacemaker and corosync metadata for undercloud.\n\nRelated to: Ifa83d62c2132bcdcb40d0b7c80ce3adadc0b5587\nRelated to: I63f054a8c80f9f676a77341c89e605b5b472d078\nChange-Id: Icc97e36a1db198b973041346cf2056f68de661a2\n'}]",0,111055,4fd5693c3cd808561e409e8004ce885d27e24366,19,4,2,7582,,,0,"Set basic pacemaker and corosync properties in undercloud

Because services which depend on pacemaker (ceilometer central
agent and neutron services) are used in undercloud too, we need to
set basic pacemaker and corosync metadata for undercloud.

Related to: Ifa83d62c2132bcdcb40d0b7c80ce3adadc0b5587
Related to: I63f054a8c80f9f676a77341c89e605b5b472d078
Change-Id: Icc97e36a1db198b973041346cf2056f68de661a2
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/55/111055/1 && git format-patch -1 --stdout FETCH_HEAD,['undercloud-source.yaml'],1,395d2ce16e9576e0796b87d9bec8bb32f27cffd3,pcmk-undercloud," corosync: bindnetaddr: {get_input: controller_host} mcastport: 5577 nodes: Merge::Map: controller0: ip: {""Fn::Select"": [ 0, {""Fn::Select"": [ ""ctlplane"", {""Fn::GetAtt"": [undercloud, networks]} ]} ] } pacemaker: stonith_enabled : false recheck_interval : 5 quorum_policy : ignore",,11,0
openstack%2Fglance~master~I45a19f5eb5304c2b78a9e12cbc0744941a807304,openstack/glance,master,I45a19f5eb5304c2b78a9e12cbc0744941a807304,Integrate OSprofiler and Glance,MERGED,2014-07-09 00:08:40.000000000,2014-08-07 22:24:58.000000000,2014-08-07 22:24:58.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6172}, {'_account_id': 6549}, {'_account_id': 8127}, {'_account_id': 8443}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-07-09 00:08:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/39b2eef20d3f15b93de83d24d1af2fd70bdde807', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to Ceilometer)\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\n""}, {'number': 2, 'created': '2014-07-09 00:26:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/6827e863d2a036b05a484cea26f53322e35843ea', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to Ceilometer)\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\n""}, {'number': 3, 'created': '2014-07-09 01:06:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4ae42dcc018e90b0ae72fc282ed7caedd5da6fc6', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to Ceilometer)\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\n""}, {'number': 4, 'created': '2014-07-09 20:46:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/371cb0b1307764fccdda31a614b31d4ed27879d3', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to Ceilometer)\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\n""}, {'number': 5, 'created': '2014-07-09 20:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7ddbf6fdb47d978d067dd7d46792330a2a933136', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to Ceilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\n""}, {'number': 6, 'created': '2014-07-09 20:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/710be6a3f65cfb241fe1c51a595b76e0b1be76a4', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to Ceilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\n""}, {'number': 7, 'created': '2014-07-09 21:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/53c53171aea060a0efd54f5d10df8161b01f22a1', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to Ceilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\n""}, {'number': 8, 'created': '2014-07-09 22:32:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d6dc30b04bf06c5511f0cec16f2f3180033c63ac', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to Ceilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\n""}, {'number': 9, 'created': '2014-07-10 15:05:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a72c947102611325662a1b34d2febea10ceb29de', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to Ceilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\n""}, {'number': 10, 'created': '2014-07-10 22:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/79967387ea67f1a9d70ecb895346a52fd0d25b2e', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to Ceilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\n*) Glance-registry wasn't setted properly to send notifications.\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\n""}, {'number': 11, 'created': '2014-07-11 23:16:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0465ed5152e1cbf8f80ce1059bae136573af7a91', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to Ceilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\n*) Glance-registry wasn't setted properly to send notifications.\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\n""}, {'number': 12, 'created': '2014-07-11 23:23:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/93fb424e0ab7e0ca76118416ec8e58e1ab36d986', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to Ceilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\n*) Glance-registry wasn't setted properly to send notifications.\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\n""}, {'number': 13, 'created': '2014-07-17 08:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a75894ecc4ad975eb3a35a5e4aac7e95bb297017', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to Ceilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\n*) Glance-registry wasn't setted properly to send notifications.\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\n""}, {'number': 14, 'created': '2014-07-24 07:17:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3257e7487d5917f4826b39daf39b0e1c6ac7f1be', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to\nCeilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\n*) Glance-registry wasn't setted properly to send notifications.\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nDocImpact\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\nCo-author: Zhi Yan Liu <zhiyanl@cn.ibm.com>""}, {'number': 15, 'created': '2014-07-24 07:23:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/cf52382039bebbe4352a490fdc7b15e791bb9893', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to\nCeilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\n*) Glance-registry wasn't setted properly to send notifications.\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nDocImpact\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\nCo-author: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 16, 'created': '2014-07-25 17:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2a02573fa63c8eec8e7661d15a632d3a6113508b', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to\nCeilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\n*) Glance-registry wasn't setted properly to send notifications.\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nDocImpact\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\nCo-author: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 17, 'created': '2014-07-25 19:00:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f4466218a3cb16ef587b3b836b0d15b7249f26b2', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to\nCeilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\n*) Glance-registry wasn't setted properly to send notifications.\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nDocImpact\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\nCo-author: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 18, 'created': '2014-08-04 07:28:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/897cfc0d9e5488a045b397594e0eeb4a6e1f57c6', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to\nCeilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\n*) Glance-registry wasn't setted properly to send notifications.\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nDocImpact\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\nCo-author: Zhi Yan Liu <zhiyanl@cn.ibm.com>#\n""}, {'number': 19, 'created': '2014-08-07 00:47:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/236ffcce766a9ac79d77b1be30730ba4f4f57576', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to\nCeilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\n*) Glance-registry wasn't setted properly to send notifications.\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nDocImpact\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\nCo-author: Zhi Yan Liu <zhiyanl@cn.ibm.com>#\n""}, {'number': 20, 'created': '2014-08-07 04:48:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fb0d11942b744972810b3f7d08a5ac8bfc5fe041', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to\nCeilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\n*) Glance-registry wasn't setted properly to send notifications.\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nDocImpact\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\nCo-author: Zhi Yan Liu <zhiyanl@cn.ibm.com>#\n""}, {'number': 21, 'created': '2014-08-07 04:48:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3609913282fba22b39e26d0f51443d0a2abbe519', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to\nCeilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\n*) Glance-registry wasn't setted properly to send notifications.\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n\n2) Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\n\nDocImpact\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\nCo-author: Zhi Yan Liu <zhiyanl@cn.ibm.com>#\n""}, {'number': 22, 'created': '2014-08-07 13:16:16.000000000', 'files': ['etc/glance-registry-paste.ini', 'glance/db/sqlalchemy/api.py', 'doc/source/configuring.rst', 'etc/glance-api-paste.ini', 'glance/common/client.py', 'glance/cmd/registry.py', 'requirements.txt', 'glance/common/wsgi.py', 'glance/notifier.py', 'etc/glance-api.conf', 'glance/cmd/api.py', 'etc/glance-registry.conf'], 'web_link': 'https://opendev.org/openstack/glance/commit/94b670c199fcc39784edd90b323b0396914ce66a', 'message': ""Integrate OSprofiler and Glance\n\n*) Add osprofiler wsgi middleware\nThis middleware is used for 2 things:\n1) It checks that person who want to trace is trusted and knows\nsecret HMAC key.\n2) It start tracing in case of proper trace headers\nand add first wsgi trace point, with info about HTTP request\n\n*) Add initialization of osprofiler at start of serivce\nSet's olso.messaging notifer instance (to send notifications to\nCeilometer)\n\n*) Add tracing support for sqlalchemy\n\n*) Add profiler CONF group that has to options:\n1) Enable or disable profiler\n2) Enable or disable sqlalchemy tracing\n(the reason why we put this in Conf options, is that usually\ndb requests create a lot of trace info)\n\n*) Glance-registry wasn't setted properly to send notifications.\n\nTo test it you need 2 things:\n1) Enable ceilometer in devstack:\nhttp://paste.openstack.org/show/85724/\n2) Initialize osprofiler and send out API request. You can use\none of follow approaches:\na. Run this script (pls provide proper credentials)\nhttp://paste.openstack.org/show/85722/\nb. Use the function https://review.openstack.org/#/c/111184/\nadded from glanceclient CLI directly.\n\nDocImpact\n\nChange-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304\nCo-author: Zhi Yan Liu <zhiyanl@cn.ibm.com>#\n""}]",11,105635,94b670c199fcc39784edd90b323b0396914ce66a,93,9,22,6172,,,0,"Integrate OSprofiler and Glance

*) Add osprofiler wsgi middleware
This middleware is used for 2 things:
1) It checks that person who want to trace is trusted and knows
secret HMAC key.
2) It start tracing in case of proper trace headers
and add first wsgi trace point, with info about HTTP request

*) Add initialization of osprofiler at start of serivce
Set's olso.messaging notifer instance (to send notifications to
Ceilometer)

*) Add tracing support for sqlalchemy

*) Add profiler CONF group that has to options:
1) Enable or disable profiler
2) Enable or disable sqlalchemy tracing
(the reason why we put this in Conf options, is that usually
db requests create a lot of trace info)

*) Glance-registry wasn't setted properly to send notifications.

To test it you need 2 things:
1) Enable ceilometer in devstack:
http://paste.openstack.org/show/85724/
2) Initialize osprofiler and send out API request. You can use
one of follow approaches:
a. Run this script (pls provide proper credentials)
http://paste.openstack.org/show/85722/
b. Use the function https://review.openstack.org/#/c/111184/
added from glanceclient CLI directly.

DocImpact

Change-Id: I45a19f5eb5304c2b78a9e12cbc0744941a807304
Co-author: Zhi Yan Liu <zhiyanl@cn.ibm.com>#
",git fetch https://review.opendev.org/openstack/glance refs/changes/35/105635/18 && git format-patch -1 --stdout FETCH_HEAD,"['glance/cmd/registry.py', 'glance/notifier.py', 'glance/cmd/api.py', 'etc/glance-api-paste.ini']",4,39b2eef20d3f15b93de83d24d1af2fd70bdde807,profi,pipeline = versionnegotiation unauthenticated-context osprofiler rootapppipeline = versionnegotiation unauthenticated-context osprofiler cache rootapppipeline = versionnegotiation unauthenticated-context osprofiler cache cachemanage rootapppipeline = versionnegotiation authtoken context osprofiler rootapppipeline = versionnegotiation authtoken context osprofiler cache rootapppipeline = versionnegotiation authtoken context osprofiler cache cachemanage rootapppipeline = versionnegotiation context osprofiler rootapppipeline = versionnegotiation context osprofiler cache cachemanage rootapp [filter:osprofiler] paste.filter_factory = osprofiler.web:WsgiMiddleware.factory hmac_key = SECRET_KEY enabled = yes ,pipeline = versionnegotiation unauthenticated-context rootapppipeline = versionnegotiation unauthenticated-context cache rootapppipeline = versionnegotiation unauthenticated-context cache cachemanage rootapppipeline = versionnegotiation authtoken context rootapppipeline = versionnegotiation authtoken context cache rootapppipeline = versionnegotiation authtoken context cache cachemanage rootapppipeline = versionnegotiation context rootapppipeline = versionnegotiation context cache cachemanage rootapp,35,10
openstack%2Fnova~master~I9a7ce74d595531196804615a8947e253b0bd3f1a,openstack/nova,master,I9a7ce74d595531196804615a8947e253b0bd3f1a,Use hypervisor hostname for compute trust level,MERGED,2014-04-21 21:45:50.000000000,2014-08-07 22:19:48.000000000,2014-08-07 22:19:45.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 4393}, {'_account_id': 4573}, {'_account_id': 5170}, {'_account_id': 6735}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-04-21 21:45:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b012f15017a2c50bbce036d07823ae7c0378fcff', 'message': ""Use hypervisor hostname for compute trust level\n\nIn XenAPI, service hostname and compute node hostname is different\nbecause the Nova compute service may run in a separated VM and is\ndifferent with the hostname of the compute node.\n\nThe remote attestation service use the compute node's hostname because\nit's the compute node that will run the servers.\n\nClose-Bug: 1223452\n\nChange-Id: I9a7ce74d595531196804615a8947e253b0bd3f1a\n""}, {'number': 2, 'created': '2014-06-11 23:22:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fa10b9d248bdd6277aac00d4ce74f3dd2289a86f', 'message': ""Use hypervisor hostname for compute trust level\n\nIn XenAPI, service hostname and compute node hostname is different\nbecause the Nova compute service may run in a separated VM and is\ndifferent with the hostname of the compute node.\n\nThe remote attestation service use the compute node's hostname because\nit's the compute node that will run the servers.\n\nClose-Bug: 1223452\n\nChange-Id: I9a7ce74d595531196804615a8947e253b0bd3f1a\n""}, {'number': 3, 'created': '2014-07-22 18:13:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/98337076fe2e542ccfa0b2036e06f1505ab7a47e', 'message': ""Use hypervisor hostname for compute trust level\n\nIn XenAPI, service hostname and compute node hostname is different\nbecause the Nova compute service may run in a separated VM and is\ndifferent with the hostname of the compute node.\n\nThe remote attestation service use the compute node's hostname because\nit's the compute node that will run the servers.\n\nCloses-Bug: #1223452\n\nChange-Id: I9a7ce74d595531196804615a8947e253b0bd3f1a\n""}, {'number': 4, 'created': '2014-07-22 20:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d6f1c68fbfd7bd94c01c668b14c062ff1a3a7b04', 'message': ""Use hypervisor hostname for compute trust level\n\nIn XenAPI, service hostname and compute node hostname is different\nbecause the Nova compute service may run in a separated VM and is\ndifferent with the hostname of the compute node.\n\nThe remote attestation service use the compute node's hostname because\nit's the compute node that will run the servers.\n\nCloses-Bug: #1223452\n\nChange-Id: I9a7ce74d595531196804615a8947e253b0bd3f1a\n""}, {'number': 5, 'created': '2014-07-24 18:05:51.000000000', 'files': ['nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/trusted_filter.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3c88fce604959a68f48d71274e0d93b74da17e34', 'message': ""Use hypervisor hostname for compute trust level\n\nIn XenAPI, service hostname and compute node hostname is different\nbecause the Nova compute service may run in a separated VM and is\ndifferent with the hostname of the compute node.\n\nThe remote attestation service use the compute node's hostname because\nit's the compute node that will run the servers.\n\nCloses-Bug: #1223452\n\nChange-Id: I9a7ce74d595531196804615a8947e253b0bd3f1a\n""}]",3,89427,3c88fce604959a68f48d71274e0d93b74da17e34,80,11,5,4573,,,0,"Use hypervisor hostname for compute trust level

In XenAPI, service hostname and compute node hostname is different
because the Nova compute service may run in a separated VM and is
different with the hostname of the compute node.

The remote attestation service use the compute node's hostname because
it's the compute node that will run the servers.

Closes-Bug: #1223452

Change-Id: I9a7ce74d595531196804615a8947e253b0bd3f1a
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/89427/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/scheduler/test_host_filters.py', 'nova/scheduler/filters/trusted_filter.py']",2,b012f15017a2c50bbce036d07823ae7c0378fcff,trust_host_node, host = compute['hypervisor_hostname'] host = host_state.nodename, host = service['host'] host = host_state.host,34,9
openstack%2Fpython-openstackclient~master~I06f727ffa8d37afe1a1191c36574887fecc7a733,openstack/python-openstackclient,master,I06f727ffa8d37afe1a1191c36574887fecc7a733,test_find_resource fails if run alone,MERGED,2014-08-07 03:22:06.000000000,2014-08-07 22:07:56.000000000,2014-08-07 22:07:56.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-08-07 03:22:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d956f59dfb22b25f19aeb6f85dbdf506ec76376b', 'message': ""it will fail if test test_find_resource singly\n\nCurrently, we set 'NAME_ATTR' attribute for Volume and Snapshot\nclass in volume.client.py. When we test test_find_resource singly,\nthe Volume and Snapshot class do not have 'NAME_ATTR' attribute since\nwe will not import volume.client. Therefor the test will fail if we\ntest test_find_resource singly.\n\nChange-Id: I06f727ffa8d37afe1a1191c36574887fecc7a733\nCloses-Bug: #1353788\n""}, {'number': 2, 'created': '2014-08-07 17:24:29.000000000', 'files': ['openstackclient/tests/volume/test_find_resource.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ddb7e18974964abbe3fc50dab47ab55286a7328c', 'message': ""test_find_resource fails if run alone\n\nCurrently, we set 'NAME_ATTR' attribute for Volume and Snapshot\nclass in volume.client.py. When we test test_find_resource alone,\nthe Volume and Snapshot class do not have 'NAME_ATTR' attribute since\nwe do not import volume.client, which causes the tests to fail.\n\nChange-Id: I06f727ffa8d37afe1a1191c36574887fecc7a733\nCloses-Bug: #1353788\n""}]",0,112458,ddb7e18974964abbe3fc50dab47ab55286a7328c,16,4,2,9101,,,0,"test_find_resource fails if run alone

Currently, we set 'NAME_ATTR' attribute for Volume and Snapshot
class in volume.client.py. When we test test_find_resource alone,
the Volume and Snapshot class do not have 'NAME_ATTR' attribute since
we do not import volume.client, which causes the tests to fail.

Change-Id: I06f727ffa8d37afe1a1191c36574887fecc7a733
Closes-Bug: #1353788
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/58/112458/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/common/utils.py', 'openstackclient/volume/client.py']",2,d956f59dfb22b25f19aeb6f85dbdf506ec76376b,wh,,from cinderclient.v1 import volume_snapshots from cinderclient.v1 import volumes# Monkey patch for v1 cinderclient volumes.Volume.NAME_ATTR = 'display_name' volume_snapshots.Snapshot.NAME_ATTR = 'display_name' ,7,6
openstack%2Fcloudkitty~master~I604a510984bf4f071bb9aef80be3635e12b6739c,openstack/cloudkitty,master,I604a510984bf4f071bb9aef80be3635e12b6739c,Added config tools,MERGED,2014-08-07 17:44:18.000000000,2014-08-07 22:03:20.000000000,2014-08-07 22:03:19.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-07 17:44:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/b4fe90af804d3a1709549b802fd548d8e034736a', 'message': 'Added config tools\n\nChange-Id: I604a510984bf4f071bb9aef80be3635e12b6739c\n'}, {'number': 2, 'created': '2014-08-07 20:16:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/6b53114161e784daf64a2fe36a063adb9c1f232d', 'message': 'Added config tools\n\nChange-Id: I604a510984bf4f071bb9aef80be3635e12b6739c\n'}, {'number': 3, 'created': '2014-08-07 20:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/594bdc47d17d715b54d576bd44686dba3d8a597d', 'message': 'Added config tools\n\nChange-Id: I604a510984bf4f071bb9aef80be3635e12b6739c\n'}, {'number': 4, 'created': '2014-08-07 21:52:33.000000000', 'files': ['cloudkitty/openstack/common/jsonutils.py', 'cloudkitty/openstack/common/local.py', 'etc/cloudkitty.conf.sample', 'tools/config/generate_sample.sh', 'cloudkitty/openstack/common/config/generator.py', 'tools/config/check_uptodate.sh', 'cloudkitty/openstack/common/config/__init__.py', 'openstack-common.conf', 'cloudkitty/openstack/common/log.py', 'cloudkitty/openstack/common/strutils.py', 'tox.ini', 'cloudkitty/openstack/common/gettextutils.py', 'cloudkitty/openstack/common/timeutils.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/1228d9418b67703e52844a324d076b1c496d107c', 'message': 'Added config tools\n\nChange-Id: I604a510984bf4f071bb9aef80be3635e12b6739c\n'}]",0,112638,1228d9418b67703e52844a324d076b1c496d107c,19,2,4,7042,,,0,"Added config tools

Change-Id: I604a510984bf4f071bb9aef80be3635e12b6739c
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/38/112638/4 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cloudkitty.conf.sample', 'tools/config/check_uptodate.sh', 'tools/config/generate_sample.sh', 'openstack-common.conf', 'tools/config/oslo.config.generator.rc', 'tox.ini']",6,b4fe90af804d3a1709549b802fd548d8e034736a,lib/config," {toxinidir}/tools/config/check_uptodate.sh [testenv:docs] commands = python setup.py build_sphinxexclude = .git,.venv,.tox,dist,doc,*egg,build,.ropeproject,./cloudkitty/openstack/common,*/alembic/versions/*","exclude = .git,.venv,.tox,dist,doc,*egg,build,./cloudkitty/openstack/common",179,1
openstack%2Fhorizon~master~Iacfade81de0e3f5c225e17ec3a34ce7712e4ad6d,openstack/horizon,master,Iacfade81de0e3f5c225e17ec3a34ce7712e4ad6d,Redirect to the current page after edited instance,MERGED,2014-08-07 07:42:55.000000000,2014-08-07 22:03:13.000000000,2014-08-07 22:03:12.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4428}, {'_account_id': 8648}, {'_account_id': 9576}]","[{'number': 1, 'created': '2014-08-07 07:42:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1c3e89f834d0777f003ef7a1549abb20b98c8d42', 'message': 'Redirect to the current page after edited instance\n\nWhen the instances is paginated in multiple pages, if we edit an\ninstance not in the first page, after successful editting the instance\nit will redirect to the first page and not to current one.\n\nChange-Id: Iacfade81de0e3f5c225e17ec3a34ce7712e4ad6d\nCloses-bug: 1353870\n'}, {'number': 2, 'created': '2014-08-07 09:23:01.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d5ca48d98511a068c506b820607625f8b137df56', 'message': 'Redirect to the current page after edited instance\n\nWhen the instances is paginated in multiple pages, if we edit an\ninstance not in the first page, after successful editting the instance\nit will redirect to the first page and not to current one.\n\nChange-Id: Iacfade81de0e3f5c225e17ec3a34ce7712e4ad6d\nCloses-bug: 1353870\n'}]",2,112500,d5ca48d98511a068c506b820607625f8b137df56,14,5,2,4428,,,0,"Redirect to the current page after edited instance

When the instances is paginated in multiple pages, if we edit an
instance not in the first page, after successful editting the instance
it will redirect to the first page and not to current one.

Change-Id: Iacfade81de0e3f5c225e17ec3a34ce7712e4ad6d
Closes-bug: 1353870
",git fetch https://review.opendev.org/openstack/horizon refs/changes/00/112500/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/instances/tables.py'],1,1c3e89f834d0777f003ef7a1549abb20b98c8d42,bug/1353870,"from openstack_dashboard.dashboards.project.instances.workflows \ import update_instance next = self.table.get_full_url() params = {""step"": step_slug, update_instance.UpdateInstance.redirect_param_name: next} param = urlencode(params)"," param = urlencode({""step"": step_slug})",6,1
openstack%2Fneutron~master~I021ba6f890dfbabddd53e75c63083f5da0ecfdec,openstack/neutron,master,I021ba6f890dfbabddd53e75c63083f5da0ecfdec,Return 403 instead of 404 on attr policy failures,MERGED,2014-08-05 21:54:26.000000000,2014-08-07 22:01:42.000000000,2014-08-07 22:01:41.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 7987}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-08-05 21:54:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1cc5742622598d4a982256389f47c44465606d5b', 'message': ""Return 403 instead of 404 on some policy failures\n\nReturn a 403 instead of a 404 if a tenant is trying to\nupdate it's own object.\n\nCloses-Bug: #1352907\nChange-Id: I021ba6f890dfbabddd53e75c63083f5da0ecfdec\n""}, {'number': 2, 'created': '2014-08-05 23:25:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/20dbbfc9d4ddf383847d952c7e1f08d8f24461f4', 'message': ""Return 403 instead of 404 on attr policy failures\n\nReturn an HTTP Forbidden code (403) instead of an\nHTTP Not Found code (404) if a tenant is trying to\nupdate it's own object. This is a safe adjustment\nsince the tenant already knows this object exists\nso pretending it doesn't isn't improving secuirty\nas much as it is causing confusion.\n\nCloses-Bug: #1352907\nChange-Id: I021ba6f890dfbabddd53e75c63083f5da0ecfdec\n""}, {'number': 3, 'created': '2014-08-06 05:26:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8f1d62b5eae00c27f121865a79a6c00ccc0fbb45', 'message': ""Return 403 instead of 404 on attr policy failures\n\nReturn an HTTP Forbidden code (403) instead of an\nHTTP Not Found code (404) if a tenant is trying to\nupdate it's own object. This is a safe adjustment\nsince the tenant already knows this object exists\nso pretending it doesn't isn't improving secuirty\nas much as it is causing confusion.\n\nCloses-Bug: #1352907\nChange-Id: I021ba6f890dfbabddd53e75c63083f5da0ecfdec\n""}, {'number': 4, 'created': '2014-08-06 19:51:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dbefb66b5fb34dac73f14c0fb19c547a6d985011', 'message': ""Return 403 instead of 404 on attr policy failures\n\nReturn an HTTP Forbidden code (403) instead of an\nHTTP Not Found code (404) if a tenant is trying to\nupdate it's own object. This is a safe adjustment\nsince the tenant already knows this object exists\nso pretending it doesn't isn't improving secuirty\nas much as it is causing confusion.\n\nCloses-Bug: #1352907\nChange-Id: I021ba6f890dfbabddd53e75c63083f5da0ecfdec\n""}, {'number': 5, 'created': '2014-08-07 01:44:39.000000000', 'files': ['neutron/tests/unit/nec/test_portbindings.py', 'neutron/tests/unit/services/firewall/test_fwaas_plugin.py', 'neutron/api/v2/base.py', 'neutron/tests/unit/_test_extension_portbindings.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/tests/unit/test_extension_pnet.py', 'neutron/tests/unit/test_extension_ext_net.py', 'neutron/tests/unit/test_extension_portsecurity.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cfea218390605e2fe34b225ffa75b8b5c141f0b9', 'message': ""Return 403 instead of 404 on attr policy failures\n\nReturn an HTTP Forbidden code (403) instead of an\nHTTP Not Found code (404) if a tenant is trying to\nupdate it's own object. This is a safe adjustment\nsince the tenant already knows this object exists\nso pretending it doesn't isn't improving secuirty\nas much as it is causing confusion.\n\nCloses-Bug: #1352907\nChange-Id: I021ba6f890dfbabddd53e75c63083f5da0ecfdec\n""}]",4,112150,cfea218390605e2fe34b225ffa75b8b5c141f0b9,89,23,5,7787,,,0,"Return 403 instead of 404 on attr policy failures

Return an HTTP Forbidden code (403) instead of an
HTTP Not Found code (404) if a tenant is trying to
update it's own object. This is a safe adjustment
since the tenant already knows this object exists
so pretending it doesn't isn't improving secuirty
as much as it is causing confusion.

Closes-Bug: #1352907
Change-Id: I021ba6f890dfbabddd53e75c63083f5da0ecfdec
",git fetch https://review.opendev.org/openstack/neutron refs/changes/50/112150/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/api/v2/base.py'],1,1cc5742622598d4a982256389f47c44465606d5b,bug/1352907,"from neutron.openstack.common import excutils with excutils.save_and_reraise_exception() as ctxt: # if a tenant is modifying it's own obj, it's safe to return # a 403, else pretent it doesn't exist. if request.context.tenant_id != orig_obj['tenant_id']: ctxt.reraise = False",,6,0
openstack%2Fneutron~master~Ia2d879cc1251fb9cf9b653a41064e902b30005af,openstack/neutron,master,Ia2d879cc1251fb9cf9b653a41064e902b30005af,Do not assume order of pci slot list,MERGED,2014-08-04 21:26:45.000000000,2014-08-07 22:00:09.000000000,2014-08-07 22:00:08.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 1923}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-08-04 21:26:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7ee8df5aa39309847b1c8d439ac5a1fbd521a9f6', 'message': 'Do not assume order of pci slot list\n\nThis fixes the neutron.tests.unit.sriovnicagent.test_eswitch_manager\n.TestEmbSwitch.test_get_pci_list unit test that breaks with a\nrandomized PYTHONHASHSEED (see the bug report).\n\nThe test assumed that the pci slot list was sorted, so sort\nthe result before comparing.\n\nNote: There are several other unrelated unit tests that also break with a\nrandomized PYTHONHASHSEED, but they are not addressed here. They will be\naddressed in separate patches.\n\nChange-Id: Ia2d879cc1251fb9cf9b653a41064e902b30005af\nPartial-bug: #1348818\n'}, {'number': 2, 'created': '2014-08-05 16:37:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3af8966ed3e609166e271f5f860299cd001f6d2e', 'message': 'Do not assume order of pci slot list\n\nThis fixes the neutron.tests.unit.sriovnicagent.test_eswitch_manager\n.TestEmbSwitch.test_get_pci_list unit test that breaks with a\nrandomized PYTHONHASHSEED (see the bug report).\n\nThe test assumed that the pci slot list was sorted, so sort\nthe result before comparing.\n\nNote: There are several other unrelated unit tests that also break with a\nrandomized PYTHONHASHSEED, but they are not addressed here. They will be\naddressed in separate patches.\n\nChange-Id: Ia2d879cc1251fb9cf9b653a41064e902b30005af\nPartial-bug: #1348818\n'}, {'number': 3, 'created': '2014-08-06 20:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/48a7b6e6935eb220ff663a22aabde5e26746bdf7', 'message': 'Do not assume order of pci slot list\n\nThis fixes the neutron.tests.unit.sriovnicagent.test_eswitch_manager\n.TestEmbSwitch.test_get_pci_list unit test that breaks with a\nrandomized PYTHONHASHSEED (see the bug report).\n\nThe test assumed that the pci slot list was sorted, so sort\nthe result before comparing.\n\nNote: There are several other unrelated unit tests that also break with a\nrandomized PYTHONHASHSEED, but they are not addressed here. They will be\naddressed in separate patches.\n\nChange-Id: Ia2d879cc1251fb9cf9b653a41064e902b30005af\nPartial-bug: #1348818\n'}, {'number': 4, 'created': '2014-08-07 16:41:57.000000000', 'files': ['neutron/tests/unit/sriovnicagent/test_eswitch_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b0f68bb14531b74f54cad6106491ff75b0e8a1d8', 'message': 'Do not assume order of pci slot list\n\nThis fixes the neutron.tests.unit.sriovnicagent.test_eswitch_manager\n.TestEmbSwitch.test_get_pci_list unit test that breaks with a\nrandomized PYTHONHASHSEED (see the bug report).\n\nThe test assumed that the pci slot list was sorted, so sort\nthe result before comparing.\n\nNote: There are several other unrelated unit tests that also break with a\nrandomized PYTHONHASHSEED, but they are not addressed here. They will be\naddressed in separate patches.\n\nChange-Id: Ia2d879cc1251fb9cf9b653a41064e902b30005af\nPartial-bug: #1348818\n'}]",0,111835,b0f68bb14531b74f54cad6106491ff75b0e8a1d8,82,23,4,5892,,,0,"Do not assume order of pci slot list

This fixes the neutron.tests.unit.sriovnicagent.test_eswitch_manager
.TestEmbSwitch.test_get_pci_list unit test that breaks with a
randomized PYTHONHASHSEED (see the bug report).

The test assumed that the pci slot list was sorted, so sort
the result before comparing.

Note: There are several other unrelated unit tests that also break with a
randomized PYTHONHASHSEED, but they are not addressed here. They will be
addressed in separate patches.

Change-Id: Ia2d879cc1251fb9cf9b653a41064e902b30005af
Partial-bug: #1348818
",git fetch https://review.opendev.org/openstack/neutron refs/changes/35/111835/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/sriovnicagent/test_eswitch_manager.py'],1,7ee8df5aa39309847b1c8d439ac5a1fbd521a9f6,bug/1348818," self.assertEqual([tup[0] for tup in self.SCANNED_DEVICES], sorted(result))"," self.assertEqual([tup[0] for tup in self.SCANNED_DEVICES], result)",2,1
openstack%2Fswift~feature%2Fec~Ifc6f59ba6d06e5f62d9e9b5188a9a486f5ab69d1,openstack/swift,feature/ec,Ifc6f59ba6d06e5f62d9e9b5188a9a486f5ab69d1,Merge remote-tracking branch 'gerrit/master' into ec,MERGED,2014-08-07 18:48:46.000000000,2014-08-07 21:48:54.000000000,2014-08-07 21:48:53.000000000,"[{'_account_id': 3}, {'_account_id': 2622}]","[{'number': 1, 'created': '2014-08-07 18:48:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1fa6229472fa57d8b6b34dd8b1405056d88966ad', 'message': ""Merge remote-tracking branch 'gerrit/master' into ec\n\nChange-Id: Ifc6f59ba6d06e5f62d9e9b5188a9a486f5ab69d1\n""}]",0,112653,1fa6229472fa57d8b6b34dd8b1405056d88966ad,10,2,1,2622,,,0,"Merge remote-tracking branch 'gerrit/master' into ec

Change-Id: Ifc6f59ba6d06e5f62d9e9b5188a9a486f5ab69d1
",git fetch https://review.opendev.org/openstack/swift refs/changes/53/112653/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,1fa6229472fa57d8b6b34dd8b1405056d88966ad,ec,,,0,0
openstack%2Fcinder~master~I7b3388dded6eeec972d9949538e1608c3a538734,openstack/cinder,master,I7b3388dded6eeec972d9949538e1608c3a538734,RPC client lazy initialization,MERGED,2014-08-06 11:07:21.000000000,2014-08-07 21:48:46.000000000,2014-08-07 21:48:45.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 8415}, {'_account_id': 11811}, {'_account_id': 12033}, {'_account_id': 12641}]","[{'number': 1, 'created': '2014-08-06 11:07:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0fe00c45b55d272df54b2738ed67c41821c59299', 'message': 'RPC client lazy initialization\n\nAll *Command classes are instantiating for each cinder-manage command\nexecution. RPC client should be initialized for VolumeCommands usage.\nSome custom RPC clients (oslo.messaging backends) coul init RPC\nconnetion after client initialization so it is no need to create RPC\nclient for every cinder-manage command invoke.\n\nChange-Id: I7b3388dded6eeec972d9949538e1608c3a538734\n'}, {'number': 2, 'created': '2014-08-06 19:46:49.000000000', 'files': ['bin/cinder-manage'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d02f79b2043869d98c7ccdcc650206a3b2ed13e6', 'message': 'RPC client lazy initialization\n\nAll *Command classes are instantiating for each cinder-manage command\nexecution. RPC client should be initialized for VolumeCommands usage.\nSome custom RPC clients (oslo.messaging backends) could init RPC\nconnection after client initialization so it is no need to create RPC\nclient for every cinder-manage command invoke.\n\nRelated-Bug: #1348787\nChange-Id: I7b3388dded6eeec972d9949538e1608c3a538734\n'}]",5,112265,d02f79b2043869d98c7ccdcc650206a3b2ed13e6,21,8,2,1736,,,0,"RPC client lazy initialization

All *Command classes are instantiating for each cinder-manage command
execution. RPC client should be initialized for VolumeCommands usage.
Some custom RPC clients (oslo.messaging backends) could init RPC
connection after client initialization so it is no need to create RPC
client for every cinder-manage command invoke.

Related-Bug: #1348787
Change-Id: I7b3388dded6eeec972d9949538e1608c3a538734
",git fetch https://review.opendev.org/openstack/cinder refs/changes/65/112265/2 && git format-patch -1 --stdout FETCH_HEAD,['bin/cinder-manage'],1,0fe00c45b55d272df54b2738ed67c41821c59299,bug/1348787, @property def rpc_client(self): if not rpc.initialized(): rpc.init(CONF) target = messaging.Target(topic=CONF.volume_topic) self.client = rpc.get_client(target) return self.client cctxt = self.rpc_client.prepare(server=host)," def __init__(self, *args, **kwargs): super(VolumeCommands, self).__init__(*args, **kwargs) rpc.init(CONF) target = messaging.Target(topic=CONF.volume_topic) self.client = rpc.get_client(target) cctxt = self.client.prepare(server=host)",9,6
openstack%2Fcloudkitty~master~I2e35bb15e64d095d47314cc234fc2a701130655a,openstack/cloudkitty,master,I2e35bb15e64d095d47314cc234fc2a701130655a,Setup and dist modifications,MERGED,2014-08-07 17:37:19.000000000,2014-08-07 21:33:21.000000000,2014-08-07 21:33:20.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-07 17:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/b89e8a31e8382e1ec57d47052aa2efffce6fb873', 'message': 'Setup and dist modifications\n\nRenamed ckitty-orchestrator to cloudkitty-processor.\nUpdated requirements for future needs.\n\nChange-Id: I2e35bb15e64d095d47314cc234fc2a701130655a\n'}, {'number': 2, 'created': '2014-08-07 21:23:05.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/0dee462ea9aec6c93af63a917035d42d25ce6e0d', 'message': 'Setup and dist modifications\n\nRenamed ckitty-orchestrator to cloudkitty-processor.\nUpdated requirements for future needs.\n\nChange-Id: I2e35bb15e64d095d47314cc234fc2a701130655a\n'}]",0,112636,0dee462ea9aec6c93af63a917035d42d25ce6e0d,13,2,2,7042,,,0,"Setup and dist modifications

Renamed ckitty-orchestrator to cloudkitty-processor.
Updated requirements for future needs.

Change-Id: I2e35bb15e64d095d47314cc234fc2a701130655a
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/36/112636/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.cfg']",3,b89e8a31e8382e1ec57d47052aa2efffce6fb873,setup/dist,description-file = README.rst classifier = Environment :: OpenStack Intended Audience :: Information Technology Intended Audience :: System Administrators License :: OSI Approved :: Apache Software License Operating System :: POSIX :: Linux Programming Language :: Python Programming Language :: Python :: 2 Programming Language :: Python :: 2.7 Programming Language :: Python :: 2.6packages = cloudkitty cloudkitty-processor = cloudkitty.orchestrator:main [global] setup-hooks = pbr.hooks.setup_hook,version = 0.1 [global] setup-hooks = pbr.hooks.setup_hookpackages = cloudkitty ckitty-orchestrator = cloudkitty.orchestrator:main,33,7
openstack%2Ffuel-specs~master~I20c780a846c240f389a4742df764b73c4c47c986,openstack/fuel-specs,master,I20c780a846c240f389a4742df764b73c4c47c986,Loss of .gitignore file,MERGED,2014-06-30 11:46:38.000000000,2014-08-07 21:23:09.000000000,2014-08-07 21:23:09.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 9546}]","[{'number': 1, 'created': '2014-06-30 11:46:38.000000000', 'files': ['requirements.txt', '.gitignore'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/0d70863169cc2ad796788095cc9fe67f2d9baefd', 'message': 'Loss of .gitignore file\n\n* Add the .gitignore file.\n* Update the pbr version of the module matching global requ.\n\nChange-Id: I20c780a846c240f389a4742df764b73c4c47c986\n'}]",0,103529,0d70863169cc2ad796788095cc9fe67f2d9baefd,13,5,1,9536,,,0,"Loss of .gitignore file

* Add the .gitignore file.
* Update the pbr version of the module matching global requ.

Change-Id: I20c780a846c240f389a4742df764b73c4c47c986
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/29/103529/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', '.gitignore']",2,0d70863169cc2ad796788095cc9fe67f2d9baefd,requ_update,*.pyc # vim swap files .*.swp # services' runtime files *.log *.pid .idea/ .DS_Store *.egg-info draft/ ,,17,2
openstack%2Ftripleo-incubator~master~I10336b0c9f510ef87aa17fb5d53a5b5773b07177,openstack/tripleo-incubator,master,I10336b0c9f510ef87aa17fb5d53a5b5773b07177,"Revert ""devtest_overcloud: boot an instance from a volume""",MERGED,2014-08-07 13:48:36.000000000,2014-08-07 21:18:23.000000000,2014-08-07 21:18:23.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7582}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-08-07 13:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/96d542ba81fa3a9cdb28f12c4e8f695694bb441a', 'message': 'Revert ""devtest_overcloud: boot an instance from a volume""\n\nThe change in subject seems to have brought up an issue\nbreaking a good number of CI jobs, see bug 1353447.\n\nUntil the root cause is found (and fixed), reverting this\nseems the only way to get CI back in a decent state.\n\nThis reverts commit bc1da1fe067f237109f97c3894abc4296cc15a65.\n\nChange-Id: I10336b0c9f510ef87aa17fb5d53a5b5773b07177\n'}, {'number': 2, 'created': '2014-08-07 14:01:25.000000000', 'files': ['scripts/devtest_overcloud.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/f66ad982019e56e2c04b149ebadb8ccb7699dbd8', 'message': 'Revert ""devtest_overcloud: boot an instance from a volume""\n\nThe change in subject seems to have brought up an issue\nbreaking a good number of CI jobs, see bug 1353447.\n\nUntil the root cause is found (and fixed), reverting this\nseems the only way to get CI back in a decent state.\n\nThis reverts commit bc1da1fe067f237109f97c3894abc4296cc15a65.\n\nChange-Id: I10336b0c9f510ef87aa17fb5d53a5b5773b07177\nCloses-Bug: 1353447\n'}]",0,112580,f66ad982019e56e2c04b149ebadb8ccb7699dbd8,26,6,2,6796,,,0,"Revert ""devtest_overcloud: boot an instance from a volume""

The change in subject seems to have brought up an issue
breaking a good number of CI jobs, see bug 1353447.

Until the root cause is found (and fixed), reverting this
seems the only way to get CI back in a decent state.

This reverts commit bc1da1fe067f237109f97c3894abc4296cc15a65.

Change-Id: I10336b0c9f510ef87aa17fb5d53a5b5773b07177
Closes-Bug: 1353447
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/80/112580/2 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_overcloud.sh'],1,96d542ba81fa3a9cdb28f12c4e8f695694bb441a,bug/1353447, nova boot --key-name default --flavor m1.tiny --image user demo," IMAGE_ID=$(glance image-show user | awk '/ id / {print $4}') nova boot --key-name default --flavor m1.tiny --block-device source=image,id=$IMAGE_ID,dest=volume,size=2,shutdown=preserve,bootindex=0 demo",1,2
openstack%2Fcookbook-openstack-image~master~I3b2a6b9da99ca061012c8b808c3821072ec63f9b,openstack/cookbook-openstack-image,master,I3b2a6b9da99ca061012c8b808c3821072ec63f9b,Add attribute filesystem_store_metadata_file,MERGED,2014-07-31 02:55:03.000000000,2014-08-07 21:07:01.000000000,2014-08-07 21:07:01.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 2340}, {'_account_id': 7128}, {'_account_id': 9488}, {'_account_id': 9492}, {'_account_id': 10068}, {'_account_id': 11207}, {'_account_id': 12323}]","[{'number': 1, 'created': '2014-07-31 02:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/e03cd2fa70475c7e539e2b050e68937545624da6', 'message': 'Add attribute filesystem_store_metadata_file\n\nAttribute name: filesystem_store_metadata_file\nFile name: /etc/glance/glance-api.conf\nSection: default\n\nDescription: A path to a JSON file that contains\n metadata describing the storage system. When\nshow_multiple_locations is True the information\nin this file will be returned with any location\nthat is contained in this store.\n\nChange-Id: I3b2a6b9da99ca061012c8b808c3821072ec63f9b\nClose-bug: #1348015\n'}, {'number': 2, 'created': '2014-08-01 02:29:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/8ca1c17bd2c8a2bceb12c3a3cd3e77ff847dc2a2', 'message': 'Add attribute filesystem_store_metadata_file\n\nAttribute name: filesystem_store_metadata_file\nFile name: /etc/glance/glance-api.conf\nSection: default\n\nDescription: A path to a JSON file that contains\n metadata describing the storage system. When\nshow_multiple_locations is True the information\nin this file will be returned with any location\nthat is contained in this store.\n\nChange-Id: I3b2a6b9da99ca061012c8b808c3821072ec63f9b\nClose-bug: #1348015\n'}, {'number': 3, 'created': '2014-08-01 07:39:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/eeb4f61d7128b284c69891eb76b70e668c100266', 'message': 'Add attribute filesystem_store_metadata_file\n\nAttribute name: filesystem_store_metadata_file\nFile name: /etc/glance/glance-api.conf\nSection: default\n\nDescription: A path to a JSON file that contains\n metadata describing the storage system. When\nshow_multiple_locations is True the information\nin this file will be returned with any location\nthat is contained in this store.\n\nChange-Id: I3b2a6b9da99ca061012c8b808c3821072ec63f9b\nCloses-bug: #1348015\n'}, {'number': 4, 'created': '2014-08-01 07:44:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/283be87a6377c12b8e07cd6ef1994a057a1a5373', 'message': 'Add attribute filesystem_store_metadata_file\n\nAttribute name: filesystem_store_metadata_file\nFile name: /etc/glance/glance-api.conf\nSection: default\n\nDescription: A path to a JSON file that contains\n metadata describing the storage system. When\nshow_multiple_locations is True the information\nin this file will be returned with any location\nthat is contained in this store.\n\nChange-Id: I3b2a6b9da99ca061012c8b808c3821072ec63f9b\nCloses-bug: #1348015\n'}, {'number': 5, 'created': '2014-08-01 08:02:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/663cee31275d50008f0422ccaf403fa1d210be6e', 'message': 'Add attribute filesystem_store_metadata_file\n\nAttribute name: filesystem_store_metadata_file\nFile name: /etc/glance/glance-api.conf\nSection: default\n\nDescription: A path to a JSON file that contains\n metadata describing the storage system. When\nshow_multiple_locations is True the information\nin this file will be returned with any location\nthat is contained in this store.\n\nChange-Id: I3b2a6b9da99ca061012c8b808c3821072ec63f9b\nCloses-bug: #1348015\n'}, {'number': 6, 'created': '2014-08-02 04:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/98ad7f34592b2cafb06fb90f89907e9e7792ab4c', 'message': 'Add attribute filesystem_store_metadata_file\n\nAttribute name: filesystem_store_metadata_file\nFile name: /etc/glance/glance-api.conf\nSection: default\n\nDescription: A path to a JSON file that contains\n metadata describing the storage system. When\nshow_multiple_locations is True the information\nin this file will be returned with any location\nthat is contained in this store.\n\nChange-Id: I3b2a6b9da99ca061012c8b808c3821072ec63f9b\nCloses-bug: #1348015\n'}, {'number': 7, 'created': '2014-08-06 07:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/4cae50105dbe24308b03b850c0cd17db9e8f55f9', 'message': 'Add attribute filesystem_store_metadata_file\n\nAttribute name: filesystem_store_metadata_file\nFile name: /etc/glance/glance-api.conf\nSection: default\n\nDescription: A path to a JSON file that contains\n metadata describing the storage system. When\nshow_multiple_locations is True the information\nin this file will be returned with any location\nthat is contained in this store.\n\nChange-Id: I3b2a6b9da99ca061012c8b808c3821072ec63f9b\nCloses-bug: #1348015\n'}, {'number': 8, 'created': '2014-08-06 07:18:28.000000000', 'files': ['templates/default/glance-api.conf.erb', 'attributes/default.rb', 'spec/api_spec.rb', 'CHANGELOG.md', 'README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/a9cb36f5f3a57e1f3da2b072cb1eb4d2a75dc790', 'message': 'Add attribute filesystem_store_metadata_file\n\nAttribute name: filesystem_store_metadata_file\nFile name: /etc/glance/glance-api.conf\nSection: default\n\nDescription: A path to a JSON file that contains\n metadata describing the storage system. When\nshow_multiple_locations is True the information\nin this file will be returned with any location\nthat is contained in this store.\n\nChange-Id: I3b2a6b9da99ca061012c8b808c3821072ec63f9b\nCloses-bug: #1348015\n'}]",16,110839,a9cb36f5f3a57e1f3da2b072cb1eb4d2a75dc790,45,9,8,11207,,,0,"Add attribute filesystem_store_metadata_file

Attribute name: filesystem_store_metadata_file
File name: /etc/glance/glance-api.conf
Section: default

Description: A path to a JSON file that contains
 metadata describing the storage system. When
show_multiple_locations is True the information
in this file will be returned with any location
that is contained in this store.

Change-Id: I3b2a6b9da99ca061012c8b808c3821072ec63f9b
Closes-bug: #1348015
",git fetch https://review.opendev.org/openstack/cookbook-openstack-image refs/changes/39/110839/8 && git format-patch -1 --stdout FETCH_HEAD,"['templates/default/glance-api.conf.erb', 'spec/api_spec.rb']",2,e03cd2fa70475c7e539e2b050e68937545624da6,bug/1348015, %w(verbose debug filesystem_store_datadir filesystem_store_metadata_file notification_driver).each do |attr|, %w(verbose debug filesystem_store_datadir notification_driver).each do |attr|,9,1
openstack%2Fbarbican~master~I5f1b196f36d02587cd35aac7cdfa1c152743aaa6,openstack/barbican,master,I5f1b196f36d02587cd35aac7cdfa1c152743aaa6,Adds store_secret_supports to secret_store,MERGED,2014-07-29 17:29:59.000000000,2014-08-07 20:46:07.000000000,2014-08-07 20:46:07.000000000,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 6783}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 8623}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-07-29 17:29:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/345f169d1d8bc77f1fde8d8b8d93d4c13ebeb2c3', 'message': 'Adds store_supports to secret_store\n\nThis adds a new method, store_supports, to the SecretStore interface. Given a\nSecretDTO, this method will allow the plugin manager to check if a plugin\nsupports storing the secret data.\n\nFor example, a plugin that only supports storing secrets if the secret\nattributes are defined and valid will check the attributes are not None, but\nsome plugins may be able to store any secret as a blob whether or not the\nattributes are defined and thus will define this method to always return True.\n\nImplements: blueprint create-secret-store\nChange-Id: I5f1b196f36d02587cd35aac7cdfa1c152743aaa6\n'}, {'number': 2, 'created': '2014-07-29 18:56:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/378b8fb1d30023371bc2c7246e4885ac33be047f', 'message': 'Adds store_supports to secret_store\n\nThis adds a new method, store_supports, to the SecretStore interface. Given a\nSecretDTO, this method will allow the plugin manager to check if a plugin\nsupports storing the secret data.\n\nFor example, a plugin that only supports storing secrets if the secret\nattributes are defined and valid will check the attributes are not None, but\nsome plugins may be able to store any secret as a blob whether or not the\nattributes are defined and thus will define this method to always return True.\n\nImplements: blueprint create-secret-store\nChange-Id: I5f1b196f36d02587cd35aac7cdfa1c152743aaa6\n'}, {'number': 3, 'created': '2014-07-29 18:58:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/151a14bd35a29b5633fd5a701ad725aa42bcf1b9', 'message': 'Adds store_supports to secret_store\n\nThis adds a new method, store_supports, to the SecretStore interface. Given a\nSecretDTO, this method will allow the plugin manager to check if a plugin\nsupports storing the secret data.\n\nFor example, a plugin that only supports storing secrets if the secret\nattributes are defined and valid will check the attributes are not None, but\nsome plugins may be able to store any secret as a blob whether or not the\nattributes are defined and thus will define this method to always return True.\n\nImplements: blueprint create-secret-store\nChange-Id: I5f1b196f36d02587cd35aac7cdfa1c152743aaa6\n'}, {'number': 4, 'created': '2014-07-31 19:27:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/30f3ad43488c45c5c16c43f3719fe608d62678b8', 'message': 'Adds store_supports to secret_store\n\nThis adds a new method, store_supports, to the SecretStore interface. Given a\nSecretDTO, this method will allow the plugin manager to check if a plugin\nsupports storing the secret data.\n\nFor example, a plugin that only supports storing secrets if the secret\nattributes are defined and valid will check the attributes are not None, but\nsome plugins may be able to store any secret as a blob whether or not the\nattributes are defined and thus will define this method to always return True.\n\nImplements: blueprint create-secret-store\n(https://blueprints.launchpad.net/barbican/+spec/create-secret-store)\nChange-Id: I5f1b196f36d02587cd35aac7cdfa1c152743aaa6\n'}, {'number': 5, 'created': '2014-07-31 19:33:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/de7515ea9cdab3f9efdabe8a648079357fc942d8', 'message': 'Adds store_secret_supports to secret_store\n\nThis adds a new method, store_secret_supports, to the SecretStore interface. Given a\nSecretDTO, this method will allow the plugin manager to check if a plugin\nsupports storing the secret data.\n\nFor example, a plugin that only supports storing secrets if the secret\nattributes are defined and valid will check the attributes are not None, but\nsome plugins may be able to store any secret as a blob whether or not the\nattributes are defined and thus will define this method to always return True.\n\nImplements: blueprint create-secret-store\n(https://blueprints.launchpad.net/barbican/+spec/create-secret-store)\nChange-Id: I5f1b196f36d02587cd35aac7cdfa1c152743aaa6\n'}, {'number': 6, 'created': '2014-07-31 20:37:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/f133281fa89952d0d3aa45da967e497385c159ec', 'message': 'Adds store_supports to secret_store\n\nThis adds a new method, store_supports, to the SecretStore interface. Given a\nSecretDTO, this method will allow the plugin manager to check if a plugin\nsupports storing the secret data.\n\nFor example, a plugin that only supports storing secrets if the secret\nattributes are defined and valid will check the attributes are not None, but\nsome plugins may be able to store any secret as a blob whether or not the\nattributes are defined and thus will define this method to always return True.\n\nImplements: blueprint create-secret-store\n(https://blueprints.launchpad.net/barbican/+spec/create-secret-store)\nChange-Id: I5f1b196f36d02587cd35aac7cdfa1c152743aaa6\n'}, {'number': 7, 'created': '2014-08-01 16:43:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/1906cd3103bcbd5f4adaeffa138066cef5d0e4d6', 'message': 'Adds store_supports to secret_store\n\nThis adds a new method, store_supports, to the SecretStore interface. Given a\nSecretDTO, this method will allow the plugin manager to check if a plugin\nsupports storing the secret data.\n\nFor example, a plugin that only supports storing secrets if the secret\nattributes are defined and valid will check the attributes are not None, but\nsome plugins may be able to store any secret as a blob whether or not the\nattributes are defined and thus will define this method to always return True.\n\nImplements: blueprint create-secret-store\n(https://blueprints.launchpad.net/barbican/+spec/create-secret-store)\nChange-Id: I5f1b196f36d02587cd35aac7cdfa1c152743aaa6\n'}, {'number': 8, 'created': '2014-08-01 20:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/9ef7ff8b0fa864b9582c4a7528985408e43f95a4', 'message': 'Adds store_supports to secret_store\n\nThis adds a new method, store_supports, to the SecretStore interface. Given a\nSecretDTO, this method will allow the plugin manager to check if a plugin\nsupports storing the secret data.\n\nFor example, a plugin that only supports storing secrets if the secret\nattributes are defined and valid will check the attributes are not None, but\nsome plugins may be able to store any secret as a blob whether or not the\nattributes are defined and thus will define this method to always return True.\n\nImplements: blueprint create-secret-store\n(https://blueprints.launchpad.net/barbican/+spec/create-secret-store)\nChange-Id: I5f1b196f36d02587cd35aac7cdfa1c152743aaa6\n'}, {'number': 9, 'created': '2014-08-05 17:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/93048a321f4588428479d03bafccc0bb022d5d33', 'message': 'Adds store_secret_supports to secret_store\n\nThis adds a new method, store_secret_supports, to the SecretStore interface.\nGiven a KeySpec, this method will allow the plugin manager to check if a plugin\nsupports storing the secret data.\n\nFor example, a plugin that only supports storing secrets if the secret\nattributes are defined and valid will check the attributes are not None, but\nsome plugins may be able to store any secret as a blob whether or not the\nattributes are defined and thus will define this method to always return True.\n\nImplements: blueprint create-secret-store\n(https://blueprints.launchpad.net/barbican/+spec/create-secret-store)\nChange-Id: I5f1b196f36d02587cd35aac7cdfa1c152743aaa6\n'}, {'number': 10, 'created': '2014-08-05 19:57:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/7128bb96659a230a0cc8f95a35d5ee1a190f1e93', 'message': 'Adds store_secret_supports to secret_store\n\nThis adds a new method, store_secret_supports, to the SecretStore interface.\nGiven a KeySpec, this method will allow the plugin manager to check if a plugin\nsupports storing the secret data.\n\nFor example, a plugin that only supports storing secrets if the secret\nattributes are defined and valid will check the attributes are not None, but\nsome plugins may be able to store any secret as a blob whether or not the\nattributes are defined and thus will define this method to always return True.\n\nImplements: blueprint create-secret-store\n(https://blueprints.launchpad.net/barbican/+spec/create-secret-store)\nChange-Id: I5f1b196f36d02587cd35aac7cdfa1c152743aaa6\n'}, {'number': 11, 'created': '2014-08-05 19:59:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/b1ed871d235bff4a396ecbc4b8533965a4cacc3f', 'message': 'Adds store_secret_supports to secret_store\n\nThis adds a new method, store_secret_supports, to the SecretStore interface.\nGiven a KeySpec, this method will allow the plugin manager to check if a plugin\nsupports storing the secret data.\n\nFor example, a plugin that only supports storing secrets if the secret\nattributes are defined and valid will check the attributes are not None, but\nsome plugins may be able to store any secret as a blob whether or not the\nattributes are defined and thus will define this method to always return True.\n\nImplements: blueprint create-secret-store\n(https://blueprints.launchpad.net/barbican/+spec/create-secret-store)\nChange-Id: I5f1b196f36d02587cd35aac7cdfa1c152743aaa6\n'}, {'number': 12, 'created': '2014-08-07 17:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/1427bca14340a9296367f72562b9ab438f3d9776', 'message': 'Adds store_secret_supports to secret_store\n\nThis adds a new method, store_secret_supports, to the SecretStore interface.\nGiven a KeySpec, this method will allow the plugin manager to check if a plugin\nsupports storing the secret data.\n\nFor example, a plugin that only supports storing secrets if the secret\nattributes are defined and valid will check the attributes are not None, but\nsome plugins may be able to store any secret as a blob whether or not the\nattributes are defined and thus will define this method to always return True.\n\nImplements: blueprint create-secret-store\n(https://blueprints.launchpad.net/barbican/+spec/create-secret-store)\nChange-Id: I5f1b196f36d02587cd35aac7cdfa1c152743aaa6\n'}, {'number': 13, 'created': '2014-08-07 19:20:36.000000000', 'files': ['barbican/plugin/resources.py', 'barbican/tests/plugin/interface/test_secret_store.py', 'barbican/plugin/store_crypto.py', 'barbican/plugin/interface/secret_store.py', 'barbican/plugin/dogtag.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/ef79bc59279a16cdb42d87842136bd8f28c2e064', 'message': 'Adds store_secret_supports to secret_store\n\nThis adds a new method, store_secret_supports, to the SecretStore interface.\nGiven a KeySpec, this method will allow the plugin manager to check if a plugin\nsupports storing the secret data.\n\nFor example, a plugin that only supports storing secrets if the secret\nattributes are defined and valid will check the attributes are not None, but\nsome plugins may be able to store any secret as a blob whether or not the\nattributes are defined and thus will define this method to always return True.\n\nImplements: blueprint create-secret-store\n(https://blueprints.launchpad.net/barbican/+spec/create-secret-store)\nChange-Id: I5f1b196f36d02587cd35aac7cdfa1c152743aaa6\n'}]",31,110386,ef79bc59279a16cdb42d87842136bd8f28c2e064,73,9,13,8623,,,0,"Adds store_secret_supports to secret_store

This adds a new method, store_secret_supports, to the SecretStore interface.
Given a KeySpec, this method will allow the plugin manager to check if a plugin
supports storing the secret data.

For example, a plugin that only supports storing secrets if the secret
attributes are defined and valid will check the attributes are not None, but
some plugins may be able to store any secret as a blob whether or not the
attributes are defined and thus will define this method to always return True.

Implements: blueprint create-secret-store
(https://blueprints.launchpad.net/barbican/+spec/create-secret-store)
Change-Id: I5f1b196f36d02587cd35aac7cdfa1c152743aaa6
",git fetch https://review.opendev.org/openstack/barbican refs/changes/86/110386/13 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/plugin/resources.py', 'barbican/plugin/store_crypto.py', 'barbican/plugin/interface/secret_store.py', 'barbican/plugin/dogtag.py']",4,345f169d1d8bc77f1fde8d8b8d93d4c13ebeb2c3,bp/create-secret-store," def store_supports(self, secret_dto): """"""Key storage supported? Specifies whether the plugin supports key storage of the secret given the attributes included in the SecretDTO """""" # TODO(kaitlin-farr or alee?) Complete implementation return False ",,41,8
openstack%2Fpython-openstackclient~master~Ia104db9d7e580d33097ea33a5690998f817995d1,openstack/python-openstackclient,master,Ia104db9d7e580d33097ea33a5690998f817995d1,Add container create and delete support,MERGED,2014-08-03 06:20:45.000000000,2014-08-07 20:41:57.000000000,2014-08-07 20:41:57.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-08-03 06:20:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b071e89aa3e8177e92009cca9e190597caedaa5b', 'message': 'Add container create and delete support\n\nAdd basic container create and delete support to OSC.\n\nChange-Id: Ia104db9d7e580d33097ea33a5690998f817995d1\nimplements: bp swift-client\n'}, {'number': 2, 'created': '2014-08-03 07:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/7bd82f18f36e318fcaefff4d2c09926df345f7d8', 'message': 'Add container create and delete support\n\nAdd basic container create and delete support to OSC.\n\nChange-Id: Ia104db9d7e580d33097ea33a5690998f817995d1\nimplements: bp swift-client\n'}, {'number': 3, 'created': '2014-08-03 07:52:11.000000000', 'files': ['openstackclient/object/v1/lib/container.py', 'openstackclient/object/v1/container.py', 'openstackclient/common/restapi.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/be83ae763ffbcd3208ba1df9fe8b22cfe3fa6fa2', 'message': 'Add container create and delete support\n\nAdd basic container create and delete support to OSC.\n\nChange-Id: Ia104db9d7e580d33097ea33a5690998f817995d1\nimplements: bp swift-client\n'}]",0,111552,be83ae763ffbcd3208ba1df9fe8b22cfe3fa6fa2,20,4,3,6482,,,0,"Add container create and delete support

Add basic container create and delete support to OSC.

Change-Id: Ia104db9d7e580d33097ea33a5690998f817995d1
implements: bp swift-client
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/52/111552/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/object/v1/container.py', 'openstackclient/object/v1/lib/container.py', 'openstackclient/common/restapi.py', 'setup.cfg']",4,b071e89aa3e8177e92009cca9e190597caedaa5b,bp/swift-client, container_create = openstackclient.object.v1.container:CreateContainer container_delete = openstackclient.object.v1.container:DeleteContainer,,108,4
openstack%2Frally~master~I1008829d866655c331b68aac27eb34fc6a0f71c0,openstack/rally,master,I1008829d866655c331b68aac27eb34fc6a0f71c0,modified rally-neutron.yaml file,ABANDONED,2014-08-07 17:18:38.000000000,2014-08-07 20:38:24.000000000,,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-08-07 17:18:38.000000000', 'files': ['rally-scenarios/rally-neutron.yaml', 'rally-scenarios/rally.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/fa08e17c68487f3f56da9f5977bfa848841b06eb', 'message': 'modified rally-neutron.yaml file\n\nChange-Id: I1008829d866655c331b68aac27eb34fc6a0f71c0\n'}]",2,112632,fa08e17c68487f3f56da9f5977bfa848841b06eb,6,3,1,12722,,,0,"modified rally-neutron.yaml file

Change-Id: I1008829d866655c331b68aac27eb34fc6a0f71c0
",git fetch https://review.opendev.org/openstack/rally refs/changes/32/112632/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally-scenarios/rally-neutron.yaml', 'rally-scenarios/rally.yaml']",2,fa08e17c68487f3f56da9f5977bfa848841b06eb,neutron_yaml_modification," - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" fixed_network: ""private"" use_floatingip: false script: ""/home/jenkins/.rally/extra/instance_dd_test.sh"" interpreter: ""/bin/sh"" username: ""cirros"" runner: type: ""constant"" times: 6 concurrency: 3"," sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 sla: max_failure_percent: 0 VMTasks.boot_runcommand_delete: - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" fixed_network: ""private"" floating_network: ""public"" use_floatingip: true script: ""/home/jenkins/.rally/extra/instance_dd_test.sh"" interpreter: ""/bin/sh"" username: ""cirros"" runner: type: ""constant"" times: 6 concurrency: 3 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0 - args: flavor: name: ""m1.tiny"" image: name: ""cirros-0.3.2-x86_64-uec"" fixed_network: ""private"" use_floatingip: false script: ""/home/jenkins/.rally/extra/instance_dd_test.sh"" interpreter: ""/bin/sh"" username: ""cirros"" runner: type: ""constant"" times: 6 concurrency: 3 context: users: tenants: 1 users_per_tenant: 1 sla: max_failure_percent: 0",160,144
openstack%2Fheat~master~I3723daa9dee00e32a280d221eda5f1b6b8604af4,openstack/heat,master,I3723daa9dee00e32a280d221eda5f1b6b8604af4,Update pyrax version to include base64 fix,ABANDONED,2014-08-06 15:04:25.000000000,2014-08-07 20:37:57.000000000,,"[{'_account_id': 3}, {'_account_id': 7230}]","[{'number': 1, 'created': '2014-08-06 15:04:25.000000000', 'files': ['contrib/rackspace/requirements.txt'], 'web_link': 'https://opendev.org/openstack/heat/commit/183abeedcb34c2a13728015cb7ed3e25e8f39a59', 'message': ""Update pyrax version to include base64 fix\n\nVersion 1.9.0 fixes a bug in the Auto Scale resource where it didn't\nbase64-encode the contents of server personalities the way novaclient\ndoes: https://github.com/rackspace/pyrax/commit/2519017\n\nChange-Id: I3723daa9dee00e32a280d221eda5f1b6b8604af4\n""}]",0,112322,183abeedcb34c2a13728015cb7ed3e25e8f39a59,5,2,1,7253,,,0,"Update pyrax version to include base64 fix

Version 1.9.0 fixes a bug in the Auto Scale resource where it didn't
base64-encode the contents of server personalities the way novaclient
does: https://github.com/rackspace/pyrax/commit/2519017

Change-Id: I3723daa9dee00e32a280d221eda5f1b6b8604af4
",git fetch https://review.opendev.org/openstack/heat refs/changes/22/112322/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/rackspace/requirements.txt'],1,183abeedcb34c2a13728015cb7ed3e25e8f39a59,update-pyrax,pyrax>=1.9.0,pyrax>=1.8.2,1,1
openstack%2Foslo-incubator~master~I110d71209aad50acdffd530c27062ab66d357fa1,openstack/oslo-incubator,master,I110d71209aad50acdffd530c27062ab66d357fa1,Mark oslo.cocnurrency libs as graduating,MERGED,2014-08-07 20:09:02.000000000,2014-08-07 20:34:01.000000000,2014-08-07 20:34:01.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-08-07 20:09:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/b3ed497a2ebf088a39b4a1149c479343ee27e49d', 'message': 'Mark oslo.cocnurrency libs as graduating\n\nChange-Id: I110d71209aad50acdffd530c27062ab66d357fa1\n'}, {'number': 2, 'created': '2014-08-07 20:14:02.000000000', 'files': ['MAINTAINERS'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/8660b74671e0e976099fcdd4b2127d62b8780c46', 'message': 'Mark oslo.cocnurrency libs as graduating\n\nblueprint graduate-oslo-concurrency\nChange-Id: I110d71209aad50acdffd530c27062ab66d357fa1\n'}]",0,112673,8660b74671e0e976099fcdd4b2127d62b8780c46,10,3,2,708,,,0,"Mark oslo.cocnurrency libs as graduating

blueprint graduate-oslo-concurrency
Change-Id: I110d71209aad50acdffd530c27062ab66d357fa1
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/73/112673/1 && git format-patch -1 --stdout FETCH_HEAD,['MAINTAINERS'],1,b3ed497a2ebf088a39b4a1149c479343ee27e49d,bp/graduate-oslo-concurrency,M: Yuriy Taraday <yorik.sar@gmail.com> S: GraduatingM: Yuriy Taraday <yorik.sar@gmail.com> S: Graduating,S: MaintainedS: Maintained,4,2
openstack%2Ftelemetry-specs~master~Ia46ccad5ffda71f399965f318baa4188eaf51be4,openstack/telemetry-specs,master,Ia46ccad5ffda71f399965f318baa4188eaf51be4,Central agent horizontal scaling spec,MERGED,2014-08-05 11:02:28.000000000,2014-08-07 20:32:25.000000000,2014-08-07 20:32:25.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 7052}, {'_account_id': 7336}, {'_account_id': 9562}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-08-05 11:02:28.000000000', 'files': ['specs/juno/central-agent-partitioning.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/c2be32ab84ba35526314090d72fbfa624940de3f', 'message': 'Central agent horizontal scaling spec\n\nChange-Id: Ia46ccad5ffda71f399965f318baa4188eaf51be4\n'}]",3,111978,c2be32ab84ba35526314090d72fbfa624940de3f,24,10,1,8052,,,0,"Central agent horizontal scaling spec

Change-Id: Ia46ccad5ffda71f399965f318baa4188eaf51be4
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/78/111978/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/central-agent-partitioning.rst'],1,c2be32ab84ba35526314090d72fbfa624940de3f,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================================== Horizontal scaling and work-load partitioning of the Central Agent ================================================================== https://blueprints.launchpad.net/ceilometer/+spec/central-agent-partitioning The central agent's job is polling resources for information, transforming that information into samples and passing the samples on to the Collector Agent. This specification proposes an implementation of coordination between multiple Central Agents, which could then dynamically distribute the workload between them, providing scalability and high availability. Problem description =================== Currently, each Central Agent retrieves a set of resources and polls all of them. If we have multiple Central Agents running, they all poll the same set of resources, which prevents us from scaling out horizontally. At the start of each polling interval, each of the pollsters retrieves a list of resources to poll from its Discovery plugin (configured in the pipeline or a default one). This makes the discovery process a great place to implement the coordination and partitioning logic, while the pollsters themselves can remain in blissful ignorance of anything going on. Proposed change =============== The basic idea is to use the *tooz* [1]_ library for group membership and hashing to assign resources to active Central Agents. * Discovery plugins on different Central Agents that discover the same set of resources would join the same group in *tooz*. * For each polling interval, after independently discovering the global set of resources that need to be polled by one or other of the central agents, they would get a list of all group members (Discovery plugins in other Central Agents that have the same set of resources). * They would use hashing to determine the set of resources assigned to the Discovery's Central Agent. **Determining the resources we're responsible for** We have a list of resources and get a list of active agents from *tooz*. We then get our assigned resources as follows:: our_key = sorted(agents).index(our_agent_uuid) our_resources = [] for resource in resources: key = hash(resource) mod len(agents) if key == our_key: our_resources.append(resource) # or more pythonic our_resources = [r for r in resources if hash(r) mod len(agents) == our_key] In essence we hash the resources to <number of Central Agents> of buckets and only poll the resources that fall into our bucket. A good hash function [3]_ ensures that the resources are evenly distributed to the active Central Agents. **Grouping** The pollster's Discovery plugin (be it a Compute Discovery, Hardware Discovery, etc.) provides the scope its resources are a part of. For example, if a Discovery plugin isn't constrained to a subset of resources, as is the case for most Discovery plugins, then it should simply join the global group of unconstrained Discovery plugins. If, on the other hand, the resources that the Discovery plugin can discover are constrained, like in the case of Compute Discovery, then the group name should reflect their scope. An example of this would be 'compute-<hostname>-discovery'. This way only the pollsters that are polling the same host will share their workload between them. **What happens when we start another agent (or stop an existing one)?** *tooz* allows us to register a callback that is called when a member joins or leaves the group. It keeps track of member liveness using a heartbeat mechanism. When a member joins or leaves the group, this is what happens to: * **The agents already running** If they are currently in the middle of polling, they complete their full polling cycle and only then they re-balance their hash buckets. * **The agent we just started** Joins a group first, but then waits for one polling interval to ensure all the other agents have updated their hash buckets as well, then starts polling. * **The agent that is stopped/crashes mid-cycle** The resources that the stopped agent hasn't polled yet will not be polled in this cycle, but they will be polled from the next one on. **Generalizing the implementation for re-use** The need for coordinated assignment of ""things"" (resources, alarms, ...) to agents is not unique to the Central Agent. Currently, the Alarm Evaluator could make use of it as well to have multiple Alarm Evaluators running, each evaluating their share of alarms. This functionality could be captured in a *PartitionCoordinator* class, which agents could use like:: partition_coordinator = PartitionCoordinator(group='alarm') partition_coordinator.start() every evaluation_interval: all_alarms = get_all_alarms() my_alarms = partition_coordinator.get_my_subset(all_alarms) for a in my_alarms: evaluate(a) .. note:: The actual change-over of the alarm partitioning coordination to the proposed approach will be tracked in a separate blueprint. or in the case of the central agent:: partition_coordinator = PartitionCoordinator(group='central_agent') partition_coordinator.start() every polling_interval: all_resources = discover_resources() my_resource = partition_coordinator.get_my_subset(all_resources) for r in my_resources: poll(r) Alternatives ------------ * **Fabio Gianetti's approach** [2]_. Fabio's approach uses source<->agent assignments in the database for figuring out what to poll and a heartbeat in combination with additional agents listening for that heartbeat for failure detection. In contrast, this proposal uses *tooz* for failure detection (via heartbeats as well). Additionally, the resource allocation is more dynamic since the resources are assigned to agents evenly at any point in time. It is also more lightweight since we don't need to keep an explicit resource<->agent mapping in the database, but use hashing instead. * **Locking** Another approach would be to use distributed locking provided by *tooz*. Before a pollster would poll a resource, it'd need to acquire its lock. Pollsters contend for the locks and whoever gets the lock, polls the resource. The downside of this approach is the overhead of distributed locking. Acquiring a distributed lock incurs a cost (time, network traffic). When using distributed locks for resource contention, this cost is incurred per-resource. Whereas in the approach with group membership, the coordination cost is incurred only when a member joins/leaves the group, the frequency of which is negligible compared to the amount of resources. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Pipeline impact --------------- None Other end user impact --------------------- None Performance/Scalability Impacts ------------------------------- Positive Other deployer impact --------------------- If deployers want to use multiple central agents, they will need to deploy one of the tooz backends (ZooKeeper, memcached, possibly just an AMQP broker soon) Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: nejc-saje Other contributors: chdent Ongoing maintainer: ceilometer team Work Items ---------- Future lifecycle ================ Dependencies ============ * tooz * one of the backends for tooz (ZooKeeper, memcached, possibly just oslo.messaging) Testing ======= The implementation should be tested with unit tests. Documentation Impact ==================== Operator's manual should explain the process and properties of running multiple Central Agents. References ========== .. [1] https://github.com/stackforge/tooz .. [2] https://review.openstack.org/#/c/101282/5 .. [3] http://en.wikipedia.org/wiki/Hash_function#Properties ",,263,0
openstack%2Fpython-openstackclient~master~I428dbc26520bb86efad33768ce04f584217ad168,openstack/python-openstackclient,master,I428dbc26520bb86efad33768ce04f584217ad168,user create v2.0 depends on tenantId in response,MERGED,2014-08-04 04:12:53.000000000,2014-08-07 20:26:08.000000000,2014-08-07 20:26:07.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-08-04 04:12:53.000000000', 'files': ['openstackclient/identity/v2_0/user.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e2ebeb7fdcb63576db2b59b9c59f782b2a5e7d75', 'message': ""user create v2.0 depends on tenantId in response\n\nUser create for v2.0 no longer always contains a tenantId in the\nresponse. Add a guard to check for tenantId first before pop'ing it.\n\nChange-Id: I428dbc26520bb86efad33768ce04f584217ad168\nCloses-Bug: #1352119\n""}]",0,111636,e2ebeb7fdcb63576db2b59b9c59f782b2a5e7d75,11,4,1,6482,,,0,"user create v2.0 depends on tenantId in response

User create for v2.0 no longer always contains a tenantId in the
response. Add a guard to check for tenantId first before pop'ing it.

Change-Id: I428dbc26520bb86efad33768ce04f584217ad168
Closes-Bug: #1352119
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/36/111636/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/identity/v2_0/user.py'],1,e2ebeb7fdcb63576db2b59b9c59f782b2a5e7d75,fix_user_create, if 'tenantId' in user._info: user._info.update( {'project_id': user._info.pop('tenantId')} ), user._info.update( {'project_id': user._info.pop('tenantId')} ),4,3
openstack%2Fnova~master~I3e4d233278966c79019235ac8836a825c46c27ea,openstack/nova,master,I3e4d233278966c79019235ac8836a825c46c27ea,Make nova-api use quotas object for reservations,MERGED,2014-07-14 04:15:52.000000000,2014-08-07 20:25:31.000000000,2014-08-07 20:25:29.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1030}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6661}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-14 04:15:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f44ce99b893dffd6be8d368d4807676f5a963c0a', 'message': 'Make nova-api use quotas object for reservations\n\nThis makes nova-api use the quotas object for reservations;\nmore work needs to be done to convert it the rest.\n\nPartial-Bug: #1131395\nChange-Id: I3e4d233278966c79019235ac8836a825c46c27ea\n'}, {'number': 2, 'created': '2014-07-14 04:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d83f30556ffe55a5af03a637315b58c8843c182c', 'message': 'Make nova-api use quotas object for reservations\n\nThis makes nova-api use the quotas object for reservations;\nmore work needs to be done to convert the rest.\n\nPartial-Bug: #1131395\nChange-Id: I3e4d233278966c79019235ac8836a825c46c27ea\n'}, {'number': 3, 'created': '2014-07-14 21:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f8bf1ab6f9e46c57ef1f1219ae688263ef29a23e', 'message': 'Make nova-api use quotas object for reservations\n\nThis makes nova-api use the quotas object for reservations;\nmore work needs to be done to convert the rest.\n\nPartial-Bug: #1131395\nChange-Id: I3e4d233278966c79019235ac8836a825c46c27ea\n'}, {'number': 4, 'created': '2014-08-05 15:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e9a29f41f9b46e023d51b762a56d524551e6e58', 'message': 'Make nova-api use quotas object for reservations\n\nThis makes nova-api use the quotas object for reservations;\nmore work needs to be done to convert the rest.\n\nPartial-Bug: #1131395\nChange-Id: I3e4d233278966c79019235ac8836a825c46c27ea\n'}, {'number': 5, 'created': '2014-08-05 17:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db5fc50c4c104b4866e31b2e2b35dbf2cea16178', 'message': 'Make nova-api use quotas object for reservations\n\nThis makes nova-api use the quotas object for reservations;\nmore work needs to be done to convert the rest.\n\nPartial-Bug: #1131395\nChange-Id: I3e4d233278966c79019235ac8836a825c46c27ea\n'}, {'number': 6, 'created': '2014-08-06 14:28:23.000000000', 'files': ['nova/tests/compute/test_compute_api.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7a1e50772154b0b0907592582b91eb89407dfb8b', 'message': 'Make nova-api use quotas object for reservations\n\nThis makes nova-api use the quotas object for reservations;\nmore work needs to be done to convert the rest.\n\nPartial-Bug: #1131395\nChange-Id: I3e4d233278966c79019235ac8836a825c46c27ea\n'}]",12,106679,7a1e50772154b0b0907592582b91eb89407dfb8b,78,13,6,6661,,,0,"Make nova-api use quotas object for reservations

This makes nova-api use the quotas object for reservations;
more work needs to be done to convert the rest.

Partial-Bug: #1131395
Change-Id: I3e4d233278966c79019235ac8836a825c46c27ea
",git fetch https://review.opendev.org/openstack/nova refs/changes/79/106679/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_api.py', 'nova/compute/api.py']",2,f44ce99b893dffd6be8d368d4807676f5a963c0a,bug/1131395," quotas = quotas_obj.Quotas(context) quotas.reserve(context, instances=max_count, cores=req_cores, ram=req_ram) return max_count, quotas num_instances, quotas = self._check_num_instances_quota( quotas.rollback() quotas.commit() quotas = self._create_reservations(context, instance, original_task_state, project_id, user_id) reservations = quotas.reservations quotas.commit() quotas.commit() quotas.rollback() quotas.commit() quotas.rollback() quotas.rollback() quotas = quotas_obj.Quotas(context) quotas.reserve(context, project_id=project_id, user_id=user_id, instances=-1, cores=-instance_vcpus, ram=-instance_memory_mb) return quotas"," reservations = QUOTAS.reserve(context, instances=max_count, cores=req_cores, ram=req_ram) return max_count, reservations num_instances, quota_reservations = self._check_num_instances_quota( QUOTAS.rollback(context, quota_reservations) QUOTAS.commit(context, quota_reservations) reservations = self._create_reservations(context, instance, original_task_state, project_id, user_id) QUOTAS.commit(context, reservations, project_id=project_id, user_id=user_id) QUOTAS.commit(context, reservations, project_id=project_id, user_id=user_id) QUOTAS.rollback(context, reservations, project_id=project_id, user_id=user_id) QUOTAS.commit(context, reservations, project_id=project_id, user_id=user_id) QUOTAS.rollback(context, reservations, project_id=project_id, user_id=user_id) QUOTAS.rollback(context, reservations, project_id=project_id, user_id=user_id) reservations = QUOTAS.reserve(context, project_id=project_id, user_id=user_id, instances=-1, cores=-instance_vcpus, ram=-instance_memory_mb) return reservations",34,43
openstack%2Fpython-openstackclient~master~I71aab1ee4f467dc963e7afa7fc1c82b4255ea822,openstack/python-openstackclient,master,I71aab1ee4f467dc963e7afa7fc1c82b4255ea822,v3 endpoint set shouldn't always need service option,MERGED,2014-08-01 02:10:03.000000000,2014-08-07 20:25:26.000000000,2014-08-07 20:25:26.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 8736}, {'_account_id': 9101}]","[{'number': 1, 'created': '2014-08-01 02:10:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/89773f395cf231e47e9d0d32190bf2740809ce81', 'message': ""v3 endpoint set shouldn't always need service option\n\nChange-Id: I71aab1ee4f467dc963e7afa7fc1c82b4255ea822\nCloses-Bug: #1351121\n""}, {'number': 2, 'created': '2014-08-04 02:00:21.000000000', 'files': ['openstackclient/identity/v3/endpoint.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a9fb5fa102560d389a8a9f76ed572f1c4fc9944b', 'message': ""v3 endpoint set shouldn't always need service option\n\nChange-Id: I71aab1ee4f467dc963e7afa7fc1c82b4255ea822\nCloses-Bug: #1351121\n""}]",0,111137,a9fb5fa102560d389a8a9f76ed572f1c4fc9944b,18,4,2,9101,,,0,"v3 endpoint set shouldn't always need service option

Change-Id: I71aab1ee4f467dc963e7afa7fc1c82b4255ea822
Closes-Bug: #1351121
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/37/111137/2 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/identity/v3/endpoint.py'],1,89773f395cf231e47e9d0d32190bf2740809ce81,bug/1351121," help='Enable endpoint', help='Disable endpoint', help='Enable endpoint', help='Disable endpoint', service_id = None if parsed_args.service: service = common.find_service(identity_client, parsed_args.service) service_id = service.id service=service_id,"," help='Enable user', help='Disable user', help='Enable user', help='Disable user', service = common.find_service(identity_client, parsed_args.service) service=service.id,",10,6
openstack%2Fcloudkitty~master~I606c386cceb56ad98b77a74c40dd938da1897d34,openstack/cloudkitty,master,I606c386cceb56ad98b77a74c40dd938da1897d34,Added ropeproject to gitignore,MERGED,2014-08-07 17:08:43.000000000,2014-08-07 20:15:28.000000000,2014-08-07 20:15:28.000000000,"[{'_account_id': 3}, {'_account_id': 7042}]","[{'number': 1, 'created': '2014-08-07 17:08:43.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/89c18d52af3ee19a3548f55ff346baec20c547f3', 'message': 'Added ropeproject to gitignore\n\nChange-Id: I606c386cceb56ad98b77a74c40dd938da1897d34\n'}]",0,112624,89c18d52af3ee19a3548f55ff346baec20c547f3,7,2,1,7042,,,0,"Added ropeproject to gitignore

Change-Id: I606c386cceb56ad98b77a74c40dd938da1897d34
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/24/112624/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,89c18d52af3ee19a3548f55ff346baec20c547f3,improv/gitignore,cloudkitty.egg-info # Rope .ropeproject/,cloudkitty.egg-info,4,1
openstack%2Ftempest~master~I730f239190bf1099f173d7781be035a90a911a95,openstack/tempest,master,I730f239190bf1099f173d7781be035a90a911a95,Implement javelin2 destroy images,MERGED,2014-07-25 01:15:01.000000000,2014-08-07 20:06:51.000000000,2014-08-07 07:40:08.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1849}, {'_account_id': 5196}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-25 01:15:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/62f4d7e9b0796c6b598de50dadafb1cda9e9fed7', 'message': 'Implement javelin2 destroy images\n\nimplement destroy_images function in javelin2\n\nChange-Id: I730f239190bf1099f173d7781be035a90a911a95\n'}, {'number': 2, 'created': '2014-07-25 17:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e9fc48ad24de756d166bb45322b21228b23a2c9c', 'message': 'Implement javelin2 destroy images\n\nimplement destroy_images function in javelin2\n\nChange-Id: I730f239190bf1099f173d7781be035a90a911a95\n'}, {'number': 3, 'created': '2014-07-25 18:49:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/15b85967f32dbde40f675e1ac709a6568ebe5435', 'message': 'Implement javelin2 destroy images\n\nimplement destroy_images function in javelin2\n\nChange-Id: I730f239190bf1099f173d7781be035a90a911a95\n'}, {'number': 4, 'created': '2014-08-07 00:46:45.000000000', 'files': ['tempest/cmd/javelin.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/6f0426cef8ea30e59c58a82cf28ed35c42f9f8e5', 'message': 'Implement javelin2 destroy images\n\nimplement destroy_images function in javelin2\n\nChange-Id: I730f239190bf1099f173d7781be035a90a911a95\n'}]",1,109466,6f0426cef8ea30e59c58a82cf28ed35c42f9f8e5,51,8,4,1849,,,0,"Implement javelin2 destroy images

implement destroy_images function in javelin2

Change-Id: I730f239190bf1099f173d7781be035a90a911a95
",git fetch https://review.opendev.org/openstack/tempest refs/changes/66/109466/4 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cmd/javelin.py'],1,62f4d7e9b0796c6b598de50dadafb1cda9e9fed7,javelin,"def _get_image_by_name(client, name): r, body = client.images.image_list() for image in body: if name == image['name']: return image return None if _get_image_by_name(client, image['name']):def destroy_images(images): if not images: return LOG.info(""Destroying images"") for image in images: client = client_for_user(image['owner']) response = _get_image_by_name(client, image['name']) if not response: LOG.info(""Image '%s' does not exists"" % image['name']) continue client.images.delete_image(response['id']) destroy_images(RES['images']) LOG.warn(""Destroy mode incomplete"") "," r, body = client.images.image_list() names = [x['name'] for x in body] if image['name'] in names:def _get_image_by_name(client, name): r, body = client.images.image_list() for image in body: if name == image['name']: return image return None LOG.warn(""Destroy mode incomplete"") # destroy_images",26,13
openstack-attic%2Fcompute-api~master~Id56da05c0409ed432dfdd0f5de799f5ed5e2e47c,openstack-attic/compute-api,master,Id56da05c0409ed432dfdd0f5de799f5ed5e2e47c,Replaces WADL references with links to API Reference,MERGED,2014-08-02 03:21:03.000000000,2014-08-07 20:05:43.000000000,2014-08-07 20:05:43.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}]","[{'number': 1, 'created': '2014-08-02 03:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/45707f1c260027bc6cfa849758b1bc5a9e4dc77e', 'message': ""Replaces WADL references with links to API Reference\n\n- Moves detailed info to the Compute API v2 WADL itself\n- Alleviates the following issues:\n  * Params are not documented in this output due to tooling\n  * When a WADL was broken, this deliverable breaks also\n  * WADL contributions are low\n  * It's difficult to train contributors how to embed WADL references\n\nChange-Id: Id56da05c0409ed432dfdd0f5de799f5ed5e2e47c\n""}, {'number': 2, 'created': '2014-08-02 14:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/655a9bf82df79bd3a2e8656b226cad51999d3e82', 'message': ""Replaces WADL references with links to API Reference\n\n- Moves detailed info to the Compute API v2 WADL itself\n- Alleviates the following issues:\n  * Params are not documented in this output due to tooling\n  * When a WADL was broken, this deliverable breaks also\n  * WADL contributions are low\n  * It's difficult to train contributors how to embed WADL references\n\nChange-Id: Id56da05c0409ed432dfdd0f5de799f5ed5e2e47c\n""}, {'number': 3, 'created': '2014-08-02 19:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/9fc3c53d2079bbc2d7cc1f07120838ac14b51f5a', 'message': ""Replaces WADL references with links to API Reference\n\n- Moves detailed info to the Compute API v2 WADL itself\n- Alleviates the following issues:\n  * Params are not documented in this output due to tooling\n  * When a WADL was broken, this deliverable breaks also\n  * WADL contributions are low\n  * It's difficult to train contributors how to embed WADL references\n\nChange-Id: Id56da05c0409ed432dfdd0f5de799f5ed5e2e47c\n""}, {'number': 4, 'created': '2014-08-02 19:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/d95d0ff26787b6f387d6cfd3e561e472e275e5e2', 'message': ""Replaces WADL references with links to API Reference\n\n- Moves detailed info to the Compute API v2 WADL itself\n- Alleviates the following issues:\n  * Params are not documented in this output due to tooling\n  * When a WADL was broken, this deliverable breaks also\n  * WADL contributions are low\n  * It's difficult to train contributors how to embed WADL references\n\nChange-Id: Id56da05c0409ed432dfdd0f5de799f5ed5e2e47c\n""}, {'number': 5, 'created': '2014-08-05 15:20:34.000000000', 'files': ['v2/samples/images-page2.xml', 'v2/samples/server-post-req-pip2.json', 'v2/samples/versions-atom.xml', 'v2/samples/version-get-resp.xml', 'v2/samples/version-get-resp.json', 'v2/samples/images-page1.xml', 'v2/samples/notfound.xml', 'v2/samples/server-post-req-pip.json', 'v2/samples/images-page3.xml', 'v2/samples/versions-get-resp.xml', 'v2/samples/image-fault.xml', 'v2/samples/server-fault.xml', 'v2/samples/server-simple.json', 'v2/samples/overlimit.xml', 'v2/samples/server-simple.xml', 'v2/samples/server-post-req-pip.xml', 'v2/samples/server-post-req.json', 'v2/bk_compute_api_ref_v2.xml', 'v2/samples/image-simple.xml', 'v2/samples/version-atom.xml', 'v2/samples/versions-get-resp.json', 'v2/samples/server-post-req.xml', 'v2/samples/server-post-req-pip2.xml', 'v2/samples/choices.json', 'v2/pom.xml', 'v2/samples/fault.json', 'v2/samples/image-meta-page1.xml', 'v2/samples/server-post-req-short.xml', 'v2/samples/server-post-req-short.json', 'v2/samples/notfound.json'], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/2ab480d9700b6999a6bf11f22548de066922da1f', 'message': ""Replaces WADL references with links to API Reference\n\n- Moves detailed info to the Compute API v2 WADL itself\n- Alleviates the following issues:\n  * Params are not documented in this output due to tooling\n  * When a WADL was broken, this deliverable breaks also\n  * WADL contributions are low\n  * It's difficult to train contributors how to embed WADL references\n\nChange-Id: Id56da05c0409ed432dfdd0f5de799f5ed5e2e47c\n""}]",3,111436,2ab480d9700b6999a6bf11f22548de066922da1f,26,3,5,964,,,0,"Replaces WADL references with links to API Reference

- Moves detailed info to the Compute API v2 WADL itself
- Alleviates the following issues:
  * Params are not documented in this output due to tooling
  * When a WADL was broken, this deliverable breaks also
  * WADL contributions are low
  * It's difficult to train contributors how to embed WADL references

Change-Id: Id56da05c0409ed432dfdd0f5de799f5ed5e2e47c
",git fetch https://review.opendev.org/openstack-attic/compute-api refs/changes/36/111436/3 && git format-patch -1 --stdout FETCH_HEAD,['v2/bk_compute_api_ref_v2.xml'],1,45707f1c260027bc6cfa849758b1bc5a9e4dc77e,extricate-wadl," <date>2014-08-01</date> <revdescription><para>Removes all WADL references and replaces with links to API Reference.</para></revdescription> </revision> <revision> <para>Fix content length in Image Create response sample.</para> <para>Fixed bad request error code in Server Passwords.</para> current account limits using the /limits URI with <link xlink:href=""http://developer.openstack.org/api-ref-compute-v2.html#compute_limits""> GET /v2/{tenant_id}/limits </link>.</para> xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <para>Get all relevant information about Compute API operations from the complete API Reference at <link xlink:href=""http://developer.openstack.org/api-ref-compute-v2.html"" > http://developer.openstack.org/api-ref-compute-v2.html</link>.</para>"," <para>Fix content length in <xref linkend=""ImageCreateFullResponse"" />.</para> <para>Fixed bad request error code in <xref linkend=""Server_Passwords-d1e2510"" />.</para> current account limits using the /limits URI as follows:</para> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#limits""> <wadl:method href=""#listLimits""/> </wadl:resource> </wadl:resources> <!--<wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#extensions""> <wadl:method href=""#listExtensions""/> <wadl:method href=""#getExtension""/> </wadl:resource> </wadl:resources>--> xmlns:wadl=""http://wadl.dev.java.net/2009/02"" role=""api-reference""> <section xml:id=""compute_servers""> <title>Servers</title> <section xml:id=""List_Servers-d1e2078""> <title>List servers</title> <para xml:id=""id35836359"">You can filter the list of servers by image, flavor, name, and status through the respective query parameters.</para> <para>Servers contain a status attribute that indicates the current server state. You can filter on the server status when you complete a list servers request. The server status is returned in the response body. The server status is one of the following values:</para> <itemizedlist xml:id=""server_status""> <title>Server status values</title> <listitem> <para><code>ACTIVE</code>. The server is active.</para> </listitem> <listitem> <para><code>BUILD</code>. The server has not finished the original build process.</para> </listitem> <listitem> <para><code>DELETED</code>. The server is deleted.</para> </listitem> <listitem> <para><code>ERROR</code>. The server is in error.</para> </listitem> <listitem> <para><code>HARD_REBOOT</code>. The server is hard rebooting. This is equivalent to pulling the power plug on a physical server, plugging it back in, and rebooting it.</para> </listitem> <listitem> <para><code>PASSWORD</code>. The password is being reset on the server.</para> </listitem> <listitem> <para><code>REBOOT</code>. The server is in a soft reboot state. A reboot command was passed to the operating system.</para> </listitem> <listitem> <para><code>REBUILD</code>. The server is currently being rebuilt from an image.</para> </listitem> <listitem> <para><code>RESCUE</code>. The server is in rescue mode.</para> </listitem> <listitem> <para><code>RESIZE</code>. Server is performing the differential copy of data that changed during its initial copy. Server is down for this stage.</para> </listitem> <listitem> <para><code>REVERT_RESIZE</code>. The resize or migration of a server failed for some reason. The destination server is being cleaned up and the original source server is restarting.</para> </listitem> <listitem> <para><code>SHUTOFF</code>. The virtual machine (VM) was powered down by the user, but not through the OpenStack Compute API. For example, the user issued a <code>shutdown -h</code> command from within the server instance. If the OpenStack Compute manager detects that the VM was powered down, it transitions the server instance to the SHUTOFF status. If you use the OpenStack Compute API to restart the instance, the instance might be deleted first, depending on the value in the <parameter>shutdown_terminate</parameter> database field on the Instance model.</para> </listitem> <listitem> <para><code>SUSPENDED</code>. The server is suspended, either by request or necessity. This status appears for only the following hypervisors: XenServer/XCP, KVM, and ESXi. Administrative users may suspend an instance if it is infrequently used or to perform system maintenance. When you suspend an instance, its VM state is stored on disk, all memory is written to disk, and the virtual machine is stopped. Suspending an instance is similar to placing a device in hibernation; memory and vCPUs become available to create other instances.</para> </listitem> <listitem> <para><code>UNKNOWN</code>. The state of the server is unknown. Contact your cloud provider.</para> </listitem> <listitem> <para><code>VERIFY_RESIZE</code>. System is awaiting confirmation that the server is operational after a move or resize.</para> </listitem> </itemizedlist> <para>The compute provisioning algorithm has an anti-affinity property that attempts to spread customer VMs across hosts. Under certain situations, VMs from the same customer might be placed on the same host. <property>hostId</property> represents the host your server runs on and can be used to determine this scenario if it is relevant to your application.</para> <note> <para><property>HostId</property> is unique <emphasis>per account</emphasis> and is not globally unique.</para> </note> <!--<wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""v2/wadl/os-compute-2.wadl#Servers""> <wadl:method href=""#listServers""/> </wadl:resource> </wadl:resources>--> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#Servers""> <wadl:method href=""#listServers""/> </wadl:resource> </wadl:resources> </section> <?hard-pagebreak?> <section xml:id=""CreateServers""> <title>Create server</title> <informaltable frame=""void""> <tbody> <tr> <td>Status Transition:</td> <td> <code>BUILD</code> &ARROW; <code>ACTIVE</code> </td> </tr> <tr> <td/> <td> <code>BUILD</code> &ARROW; <code>ERROR</code> (on error)</td> </tr> </tbody> </informaltable> <para>This operation asynchronously provisions a new server. The progress of this operation depends on several factors including location of the requested image, network i/o, host load, and the selected flavor. The progress of the request can be checked by performing a &GET; on /servers/<parameter>id</parameter>, which will return a progress attribute (0-100% completion). The full URL to the newly created server is returned via the <code>Location</code> header and is available as a <code>self</code> and <code>bookmark</code> link in the server representation (See <xref linkend=""LinksReferences""/>). Note that when creating a server only the server ID, its links, and the admin password are guaranteed to be returned in the request. Additional attributes may be retrieved by performing subsequent &GET;s on the server.</para> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#Servers""> <wadl:method href=""#createServer""/> </wadl:resource> </wadl:resources> <section xml:id=""Server_Passwords-d1e2510""> <title>Server passwords</title> <para>A password may be specified when creating the server via the optional <property>adminPass</property> attribute. The specified password must meet the complexity requirements set by your OpenStack Compute provider. The server may enter an <code>ERROR</code> state if the complexity requirements are not met. In this case, a client may issue a change password action to reset the server password.</para> <para>If a password is not specified, a randomly generated password will be assigned and returned in the response object. This password is guaranteed to meet the security requirements set by the compute provider. For security reasons, the password will not be returned in subsequent &GET; calls.</para> </section> <section xml:id=""Server_Metadata-d1e2529""> <title>Server metadata</title> <para>Custom server metadata can also be supplied at launch time. See <xref linkend=""MetadataSection""/> for details on working with metadata. The maximum size of the metadata key and value is 255 bytes each. The maximum number of key-value pairs that can be supplied per server is determined by the compute provider and may be queried via the maxServerMeta absolute limit.</para> </section> <section xml:id=""Server_Networks-d1e2530""> <title>Server networks</title> <para>Networks which the server connects to can also be supplied at launch time. See <xref linkend=""NetworksSection""/> for details on working with networks. One or more networks can be specified. User can also specify a specific port on the network or the fixed IP address to assign to the server interface.</para> </section> <section xml:id=""Server_Personality-d1e2543""> <title>Server personality</title> <para>You can customize the personality of a server instance by injecting data into its file system. For example, you might want to insert ssh keys, set configuration files, or store data that you want to retrieve from inside the instance. This feature provides a minimal amount of launch-time personalization. If you require significant customization, create a custom image.</para> <para>Follow these guidelines when you inject files:</para> <itemizedlist> <listitem> <para>The maximum size of the file path data is 255 bytes.</para> </listitem> <listitem> <para>Encode the file contents as a Base64 string. The maximum size of the file contents is determined by the compute provider and may vary based on the image that is used to create the server</para> <note> <para>The maximum limit refers to the number of bytes in the decoded data and not the number of characters in the encoded data.</para> </note> </listitem> <listitem> <para>You can inject text files only. You cannot inject binary or zip files into a new build.</para> </listitem> <listitem> <para>The maximum number of file path/content pairs that you can supply is also determined by the compute provider and is defined by the maxPersonality absolute limit.</para> </listitem> <listitem> <para>The absolute limit, maxPersonalitySize, is a byte limit that is guaranteed to apply to all images in the deployment. Providers can set additional per-image personality limits.</para> </listitem> </itemizedlist> <para>The file injection might not occur until after the server is built and booted.</para> <para>During file injection, any existing files that match specified files are renamed to include the bak extension appended with a time stamp. For example, if the file /etc/passwd exists, it is backed up as /etc/passwd.bak.1246036261.5785.</para> <para>After file injection, personality files are accessible by only system administrators. For example, on Linux, all files have root and the root group as the owner and group owner, respectively, and allow user and group read access only ( ).</para> </section> <section xml:id=""Server_Primary_Addresses-d1e2558""> <title>Server access addresses</title> <para>In a hybrid environment, the IP address of a server may not be controlled by the underlying implementation. Instead, the access IP address may be part of the dedicated hardware; for example, a router/NAT device. In this case, the addresses provided by the implementation cannot actually be used to access the server (from outside the local LAN). Here, a separate <firstterm>access address</firstterm> may be assigned at creation time to provide access to the server. This address may not be directly bound to a network interface on the server and may not necessarily appear when a server's addresses are queried. See <xref linkend=""compute_server-addresses""/>. Nonetheless, clients which need to access the server directly are encouraged to do so via an access address. In the example below, an IPv4 address is assigned at creation time.</para> <example> <title>Create server with access IP: XML request</title> <programlisting language=""xml""><xi:include href=""samples/server-post-req-pip.xml"" parse=""text""/></programlisting> </example> <example> <title>Create server with access IP: JSON request</title> <programlisting language=""json""><xi:include href=""samples/server-post-req-pip.json"" parse=""text""/></programlisting> </example> <note> <para>Both IPv4 and IPv6 addresses may be used as access addresses and both addresses may be assigned simultaneously as illustrated below. Access addresses may be updated after a server has been created. See <xref linkend=""compute_servers""/> for more details.</para> </note> <example> <title>Create server with multiple access IPs: XML request</title> <programlisting language=""xml""><xi:include href=""samples/server-post-req-pip2.xml"" parse=""text""/></programlisting> </example> <?hard-pagebreak?> <example> <title>Create server with multiple access IPs: JSON request</title> <programlisting language=""json""><xi:include href=""samples/server-post-req-pip2.json"" parse=""text""/></programlisting> </example> </section> </section> <section xml:id=""Get_Server_Details-d1e2623""> <title>Get server details</title> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#server_id""> <wadl:method href=""#getServer""/> </wadl:resource> </wadl:resources> </section> <?hard-pagebreak?> <section xml:id=""ServerUpdate""> <title>Update server</title> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#server_id""> <wadl:method href=""#updateServer""/> </wadl:resource> </wadl:resources> </section> <?hard-pagebreak?> <section xml:id=""Delete_Server-d1e2883""> <title>Delete server</title> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#server_id""> <wadl:method href=""#deleteServer""/> </wadl:resource> </wadl:resources> </section> </section> <?hard-pagebreak?> <section xml:id=""compute_server-addresses""> <title>Server addresses</title> <para>Lists addresses for a specified server or a specified server and network.</para> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#ips""/> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#network_label"" /> </wadl:resources> </section> <?hard-pagebreak?> <section xml:id=""Server_Actions-d1e3229""> <title>Server actions</title> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#action"" /> </wadl:resources> </section> <?hard-pagebreak?> <section xml:id=""Flavors-d1e4180""> <title>Flavors</title> <para>A flavor is an available hardware configuration for a server. Each flavor has a unique combination of disk space and memory capacity.</para> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#flavor_detail""/> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#flavor_id"" /> </wadl:resources> </section> <?hard-pagebreak?> <section xml:id=""Images-d1e4427""> <title>Images</title> <para>An image is a collection of files you use to create or rebuild a server. Operators provide pre-built OS images by default. You may also create custom images.</para> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#image_detail""/> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#image_id"" /> </wadl:resources> </section> <?hard-pagebreak?> <section xml:id=""MetadataSection""> <title>Metadata</title> <para>The following operations enable access to metadata after a server or image has been created.</para> <wadl:resources xmlns:wadl=""http://wadl.dev.java.net/2009/02""> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#server_metadata""/> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#ServerMetadataKey""/> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#image_metadata""/> <wadl:resource href=""http://git.openstack.org/cgit/openstack/api-site/plain/api-ref/src/wadls/compute-api/src/v2/wadl/os-compute-2.wadl#imageMetadataKey"" /> </wadl:resources> </section> <?hard-pagebreak?> <section xml:id=""NetworksSection""> <title>Networks</title> <para>Using the network API you can create, update, delete and show networks, ports and subnets. A few examples are given below.</para> <table rules=""all"" xml:id=""NetworkMethods-d1e5091""> <caption>Get all networks</caption> <thead> <tr> <td>Method</td> <td>URI</td> <td>Description</td> </tr> </thead> <tbody> <tr> <td>GET</td> <td>/v2.0/networks</td> <td>Returns an array of all networks</td> </tr> <tr> <td>GET</td> <td>/v2.0/networks/{network_id}</td> <td>Return network with given id</td> </tr> <tr> <td>POST</td> <td>/v2.0/networks</td> <td>Creates new network</td> </tr> <tr> <td>DELETE</td> <td>/v2.0/networks/{network_id}</td> <td>Delete network with given id</td> </tr> </tbody> </table> <para>You can specify the following attributes for a network.</para> <table rules=""all"" xml:id=""NetworkAttributes-d1e5090""> <caption>Network attributes</caption> <thead> <tr> <td>Name</td> <td>Type</td> <td>Description</td> </tr> </thead> <tbody> <tr> <td>uuid</td> <td>uuid</td> <td>The uuid of the network.</td> </tr> <tr> <td>fixed_ip</td> <td>IPv4</td> <td>The IP address to assign to the interface.</td> </tr> <tr> <td>port</td> <td>uuid</td> <td>The uuid of the port.</td> </tr> </tbody> </table> <note> <para>The <parameter>fixed_ip</parameter> parameter is used only when network <parameter>uuid</parameter> is specified; also, when <parameter>port</parameter> is specified, network <parameter>uuid</parameter> and <parameter>fixed_ip</parameter> are properties of the port and are ignored. Omit <parameter>fixed_ip</parameter> and (network) <parameter>uuid</parameter> to avoid validation errors.</para> </note> </section>",19,568
openstack%2Fironic-specs~master~I7496e6678d7f923cc0cefacfcb70964fbe5d4119,openstack/ironic-specs,master,I7496e6678d7f923cc0cefacfcb70964fbe5d4119,UEFI support for Ironic deploy drivers,MERGED,2014-06-13 05:57:11.000000000,2014-08-07 20:02:10.000000000,2014-08-07 20:02:10.000000000,"[{'_account_id': 3}, {'_account_id': 114}, {'_account_id': 2889}, {'_account_id': 4190}, {'_account_id': 5805}, {'_account_id': 7902}, {'_account_id': 8029}, {'_account_id': 9315}, {'_account_id': 10068}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 10574}, {'_account_id': 12356}]","[{'number': 1, 'created': '2014-06-13 05:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/62144cbade90158bc61984ef3422707c34e3bc4c', 'message': 'UEFI support for Ironic deploy drivers\n\nThis spec proposes to add support for UEFI based deployment on baremetal.\n\nChange-Id: I7496e6678d7f923cc0cefacfcb70964fbe5d4119\n'}, {'number': 2, 'created': '2014-07-02 11:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/b9ff4a666d293558572676175e24edb2c05ce835', 'message': 'UEFI support for Ironic deploy drivers\n\nThis spec proposes to add support for UEFI based deployment on baremetal.\n\nChange-Id: I7496e6678d7f923cc0cefacfcb70964fbe5d4119\n'}, {'number': 3, 'created': '2014-07-09 20:14:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/7c9e60a80c8811739fd2f178f57e26c1b84f1da7', 'message': 'UEFI support for Ironic deploy drivers\n\nThis spec proposes to add support for UEFI based deployment on baremetal.\n\nChange-Id: I7496e6678d7f923cc0cefacfcb70964fbe5d4119\n'}, {'number': 4, 'created': '2014-07-16 14:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/125ccd6cf6dcbee5c175683a244d5995de8d5d54', 'message': 'UEFI support for Ironic deploy drivers\n\nThis spec proposes to add support for UEFI based deployment on baremetal.\n\nChange-Id: I7496e6678d7f923cc0cefacfcb70964fbe5d4119\n'}, {'number': 5, 'created': '2014-07-17 09:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/213a929e3a9ac654653b989adebb5ce5ffa4fe60', 'message': 'UEFI support for Ironic deploy drivers\n\nThis spec proposes to add support for UEFI based deployment on baremetal.\n\nChange-Id: I7496e6678d7f923cc0cefacfcb70964fbe5d4119\n'}, {'number': 6, 'created': '2014-07-28 04:29:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/8c46adf565bfb4a198483daa61ea53b96b88195a', 'message': 'UEFI support for Ironic deploy drivers\n\nThis spec proposes to add support for UEFI based deployment on baremetal.\n\nChange-Id: I7496e6678d7f923cc0cefacfcb70964fbe5d4119\n'}, {'number': 7, 'created': '2014-07-28 18:23:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/bb6332d7fe141bcd963fd8751996969686594e59', 'message': 'UEFI support for Ironic deploy drivers\n\nThis spec proposes to add support for UEFI based deployments on\nbaremetal nodes.\n\nChange-Id: I7496e6678d7f923cc0cefacfcb70964fbe5d4119\n'}, {'number': 8, 'created': '2014-07-30 06:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/83e5a588e50921d61638b8bd190efaf0bbf7f173', 'message': 'UEFI support for Ironic deploy drivers\n\nThis spec proposes to add support for UEFI based deployments on\nbaremetal nodes.\n\nChange-Id: I7496e6678d7f923cc0cefacfcb70964fbe5d4119\n'}, {'number': 9, 'created': '2014-08-06 20:12:20.000000000', 'files': ['specs/juno/uefi-boot-for-ironic.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/f3e33bcab53427a4a610773067943459995bf4ad', 'message': 'UEFI support for Ironic deploy drivers\n\nThis spec proposes to add support for UEFI based deployment on baremetal.\n\nChange-Id: I7496e6678d7f923cc0cefacfcb70964fbe5d4119\n'}]",90,99850,f3e33bcab53427a4a610773067943459995bf4ad,67,14,9,10574,,,0,"UEFI support for Ironic deploy drivers

This spec proposes to add support for UEFI based deployment on baremetal.

Change-Id: I7496e6678d7f923cc0cefacfcb70964fbe5d4119
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/50/99850/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/uefi-boot-for-ironic.rst'],1,62144cbade90158bc61984ef3422707c34e3bc4c,uefi-boot-for-ironic,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== UEFI support for Ironic deploy drivers ========================================== https://blueprints.launchpad.net/ironic/+spec/uefi-boot-for-ironic This spec proposes to add support for UEFI based deployment on baremetal. Problem description =================== Currently the ironic deploy driver works only with BIOS boot mode. It expects the system to be in bios boot mode. Most of the hardware now supports dual boot mode bios and UEFI and come with factory default to UEFI. So ironic deploy drivers should support the UEFI boot. Proposed change =============== Administrator's tasks for ironic deploy on UEFI based system: PXE/tftp server configuration: * Copy appropriate UEFI bootloader (elilo.efi, syslinux.efi, grub*, etc) to tftp root directory, along with pxelinux.0. We will support only elilo.efi at the moment. We can later add support to other efi bootloader. * Set new Ironic CONF parameter ""uefi_pxe_bootfile_name"". This will indicate the type of efi bootloader and use corresponding config template. * Set new Ironic CONF parameter ""default_boot_type"". The values are current_boot_mode|uefi|bios. This will define the boot mode if no user requested boot mode is specified. This parameter will be applicable only for the nodes which supports both bios and UEFI boot mode. The defualt value is ""current_boot_mode"". Note: User requested boot mode can be passed to ironic node by setting ""requested_boot_mode"" in driver_info field by nova ironic virt driver. Ironic node creation: * Create ironic node with additional node property attributes. ""supported_boot_modes"" - The values are uefi_only|bios_only|uefi_bios. ""current_boot_mode"" - The value are uefi|bios example: ironic node-update <node_id> add properties/supported_boot_mode=uefi_bios ironic node-update <node_id> add properties/current_boot_mode=uefi If the attributes are not present then it can be discovered by the dirver using management/vendorpassthru interface or it could be populated as part of hardware discovery feature or respective deploy driver. Here are some usecases and the flow for UEFI boot mode deploy: 1. User does not specify any boot mode * nova selects any available node for deploy. * Based on ""default_boot_type"" in ironic CONF file, deploy driver will take UEFI or bios boot path. By default it can choose the current boot mode of the baremetal. 2. Boot mode spcified through nova flavor * Admin creates a specific nova flavor for UEFI boot by setting ""boot_type=uefi"" in extra_specs field. * User select this nova flavor for deploy. * nova should select the ironic node which supports the specified boot mode. * nova ironic virt driver sets ""requested_boot_type"" as ""uefi"" in driver_info fields of the ironic node. * Respective deploy driver takes UEFI or bios boot path, based on ""requested_boot_type"" value. 3. Boot mode specified as disk image property * For local boot support, admin generates UEFI specific disk image, which will contain the necessary GPT partitions required for UEFI boot. * Admin add an image property ""boot_type""=uefi to indicate that it require UEFI boot. * User select this disk image for deploy. * nova should select the ironic node which supports the specified boot mode in the image property. * nova ironic virt driver sets ""requested_boot_type"" as ""uefi"" in driver_info fields of the ironic node. * Respective deploy driver takes UEFI or bios boot path, based on ""requested_boot_type"" value. Local boot options support: Since it is still in discussion whether to use a different disk image or same fs image for local boot, implementation of UEFI boot support for local boot should be changed accordingly. Discussion here is who will write the MBR/GPT and set the boot device - Either it is done by ironic driver, while using the same fs image for all the deploys, or is it done while creating the disk image using DiskImageBuilder. If user selects a UEFI based image and selects a flavor which does not contain boot-type, then the boot-type should be treated as UEFI. Note: For usecase ""1. User does not specify any boot mode"", the changes are contained in ironic driver space. Also it is not required to switch between boot mode if ""default_boot_type"" is set to current_boot_mode. For usecases 2. Boot mode specified through nova flavor, 3. Boot mode specified as disk image property and Local boot option support, most of the changes are required in nova ironic driver. Chages for these cases can be address in another blueprint. Changes required in respective Ironic deploy drivers. PXE deploy driver: * In validate() method, If ""requested_boot_mode"" is present, then check whether the boot boot mode is supported by the node. * If ""requested_boot_mode"" is uefi or current boot mode is uefi then detect uefi_pxe_bootfile_name(elilo.efi), PXE driver should create boot config file for corresponding boot loader and place it in the tftp root directory. This implementation should go in deploy.prepare() method in pxe.py. * Update neutron port DHCP extra opts with correct boot file for UEFI boot, set the client system architecture type to EFI and client network interface type to UNDI. These changes should go in _update_neutron() in pxe.py. * If ""requested_boot_mode"" is present and different from current boot mode then call vendorpassthru function or management Infterface to change the boot type. * For local boot, call vendorpassthru function or management Infterface to change the boot order to boot it from local disk. Proposed Ironic iLO deploy driver: * In validate() method, If ""requested_boot_mode"" is present then check whether the boot mode is supported by the node. * In deploy() method, If ""requested_boot_mode"" is present, then check if the current boot mode is not same as ""requested_boot_mode""(UEFI), then change boot mode to UEFI using ProliantUtils library. Need to implement the corresponding API in ProliantUtils library. For UEFI boot mode, the deploy_iso and boot_iso should be created for both bios and uefi boot modes. * For local boot, iLO driver should change the boot order to boot from local disk. Other changes: * We will define a new driver type ""pxe_ilo"", where pxe will use ilo power and ilo vendorpassthru functions for power operations and to change the boot type/boot order respectively, using MixinVendorInterface utility. * Currently IPMI tool does not support changing/querying the boot type. So for ""pxe_ipmitool"" driver, this will be a noop. We might have to implement a dummpy ipmi vendor passthru methods to change boot_type and boot_order. Alternatives ------------ Data model impact ----------------- None. REST API impact --------------- None. Driver API impact ----------------- None. Nova driver impact ------------------ For usecases 2. Boot mode specified through nova flavor, 3. Boot mode specified as disk image property and Local boot option support, most of the changes are required in Nova Ironic Virt driver/scheduler. * Need to define new filters in nova ironic scheduler, based on extra_specs field of nova flavor - boot_type and image property. * Admin has to enable baremetal filter to support UEFI boot. * Nova ironic driver should pass down the required_boot_mode in the driver info field of the respective ironic node. Security impact --------------- None. Other end user impact --------------------- None. Scalability impact ------------------ None. Performance Impact ------------------ None. Other deployer impact --------------------- None. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Faizan Barmawer. Work Items ---------- For usecase ""1. User does not specify any boot mode"", For PXE driver driver/modules/pxe.py: 1. Define new template for elilo.efi pxe config file. 2. Add new ironic CONF parameters uefi_pxe_bootfile_name, default_boot_mode 3. Make changes to PXEDeploy.validate() method. 4. Make changes to PXEDeploy.deploy() method. 5. Make changes to _update_neutron() function in pxe.py. Dependencies ============ For usecases 2. Boot mode specified through nova flavor, 3. Boot mode specified as disk image property and Local boot option support, most of the changes are required in nova ironic driver. Chages for these cases can be address in another blueprint. iLO deploy driver is currently undergoing design spec review. UEFI changes for iLO deploy driver will be made in the iLO deploy driver code. Testing ======= * Unit tests Documentation Impact ==================== Documentation should be modified to instruct admin to setup tftp server for UEFI boot support. References ========== None. ",,283,0
openstack%2Fcookbook-openstack-network~master~I48174db291512cded9b371eaf5699e97af6a0ca0,openstack/cookbook-openstack-network,master,I48174db291512cded9b371eaf5699e97af6a0ca0,Allow rootwrap configuration via attributes,MERGED,2014-07-23 20:37:33.000000000,2014-08-07 19:57:48.000000000,2014-08-07 19:57:48.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 2340}, {'_account_id': 7128}, {'_account_id': 12323}]","[{'number': 1, 'created': '2014-07-23 20:37:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/7ffe59668c5b3f3a0eb3267ee3042700b9b780bc', 'message': 'Allow rootwrap configuration via attributes\n\nChange-Id: I48174db291512cded9b371eaf5699e97af6a0ca0\nPartial-Bug: #1347861\n'}, {'number': 2, 'created': '2014-07-23 21:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/c07837941fc7366381e42615c79ba668993eec6d', 'message': 'Allow rootwrap configuration via attributes\n\nChange-Id: I48174db291512cded9b371eaf5699e97af6a0ca0\nPartial-Bug: #1347861\n'}, {'number': 3, 'created': '2014-07-24 15:36:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/a1e710121a7532e834fea789d870a7f6ce787eab', 'message': 'Allow rootwrap configuration via attributes\n\nChange-Id: I48174db291512cded9b371eaf5699e97af6a0ca0\nPartial-Bug: #1347861\n'}, {'number': 4, 'created': '2014-07-24 16:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/b872c74b0458f829547131e42d48c13154727bc0', 'message': 'Allow rootwrap configuration via attributes\n\nChange-Id: I48174db291512cded9b371eaf5699e97af6a0ca0\nPartial-Bug: #1347861\n'}, {'number': 5, 'created': '2014-07-31 20:08:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/5d75987b033ff8e0ee7c5bf53def05b79ca17ebc', 'message': 'Allow rootwrap configuration via attributes\n\nChange-Id: I48174db291512cded9b371eaf5699e97af6a0ca0\nPartial-Bug: #1347861\n'}, {'number': 6, 'created': '2014-08-01 16:33:03.000000000', 'files': ['templates/default/rootwrap.conf.erb', 'spec/spec_helper.rb', 'attributes/default.rb', 'spec/server_spec.rb', 'CHANGELOG.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/3442ec6376b886c9b21b11920d528db13c268df2', 'message': 'Allow rootwrap configuration via attributes\n\nChange-Id: I48174db291512cded9b371eaf5699e97af6a0ca0\nPartial-Bug: #1347861\n'}]",0,109113,3442ec6376b886c9b21b11920d528db13c268df2,26,5,6,7128,,,0,"Allow rootwrap configuration via attributes

Change-Id: I48174db291512cded9b371eaf5699e97af6a0ca0
Partial-Bug: #1347861
",git fetch https://review.opendev.org/openstack/cookbook-openstack-network refs/changes/13/109113/2 && git format-patch -1 --stdout FETCH_HEAD,"['templates/default/rootwrap.conf.erb', 'attributes/default.rb', 'spec/server_spec.rb', 'CHANGELOG.md']",4,7ffe59668c5b3f3a0eb3267ee3042700b9b780bc,bug-1347861-rootwrap2,* Allow rootwrap.conf attributes,,70,1
openstack%2Fcinder~master~I7972e238e11a02b4aa626333b5bb4827457e7cc0,openstack/cinder,master,I7972e238e11a02b4aa626333b5bb4827457e7cc0,Debug log messages need to be unicode,ABANDONED,2014-07-28 16:55:23.000000000,2014-08-07 19:51:09.000000000,,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 6601}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 12016}, {'_account_id': 12033}]","[{'number': 1, 'created': '2014-07-28 16:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2ddf48bb3f0c3cca7b2fbc9ba979e8b956f4a7d2', 'message': 'Debug log messages need to be unicode\n\nMakes all strings being used with LOG.debug into unicode strings.\n\nNot using unicode causes failures when replacemet text is unicode.\n\nFor example, when replacement text is an exception, if the exception\nmessage is unicode (due to translation) it will fail.  When lazy\ntranslation was enabled for blueprint: i18n-enablement the message\nis replaced with an object that does not support str() and it will\nalways fail.\n\nChange-Id: I7972e238e11a02b4aa626333b5bb4827457e7cc0\nCloses-Bug: 1348244\n'}, {'number': 2, 'created': '2014-07-28 17:02:04.000000000', 'files': ['cinder/scheduler/filter_scheduler.py', 'cinder/volume/manager.py', 'cinder/service.py', 'cinder/backup/api.py', 'cinder/volume/drivers/nimble.py', 'cinder/backup/rpcapi.py', 'cinder/brick/iscsi/iscsi.py', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/backup/fake_swift_client.py', 'cinder/tests/integrated/integrated_helpers.py', 'cinder/volume/drivers/ibm/ibmnas.py', 'cinder/volume/drivers/nfs.py', 'cinder/tests/api/contrib/test_backups.py', 'cinder/brick/remotefs/remotefs.py', 'cinder/api/openstack/__init__.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/api/contrib/volume_image_metadata.py', 'cinder/tests/test_hds_iscsi.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/windows/windows_utils.py', 'cinder/volume/drivers/coraid.py', 'cinder/volume/drivers/zadara.py', 'cinder/volume/drivers/netapp/utils.py', 'cinder/tests/fake_utils.py', 'cinder/volume/drivers/nexenta/iscsi.py', 'cinder/volume/iscsi.py', 'cinder/api/contrib/qos_specs_manage.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_san_lookup_service.py', 'cinder/volume/drivers/emc/emc_smis_iscsi.py', 'cinder/volume/drivers/netapp/eseries/iscsi.py', 'cinder/openstack/common/processutils.py', 'cinder/volume/drivers/hds/hds.py', 'cinder/volume/drivers/san/hp/hp_msa_common.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/volume/drivers/ibm/storwize_svc/__init__.py', 'cinder/volume/drivers/huawei/huawei_utils.py', 'cinder/brick/local_dev/lvm.py', 'cinder/zonemanager/utils.py', 'cinder/volume/drivers/vmware/io_util.py', 'cinder/zonemanager/fc_zone_manager.py', 'cinder/scheduler/host_manager.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py', 'cinder/volume/drivers/vmware/read_write_util.py', 'cinder/api/v2/volumes.py', 'cinder/volume/drivers/hds/hus_backend.py', 'cinder/api/contrib/volume_manage.py', 'cinder/volume/drivers/hds/hnas_backend.py', 'cinder/compute/nova.py', 'cinder/volume/drivers/lvm.py', 'cinder/tests/brick/test_brick_connector.py', 'cinder/api/extensions.py', 'cinder/api/v1/volumes.py', 'cinder/brick/initiator/connector.py', 'cinder/volume/drivers/eqlx.py', 'cinder/hacking/checks.py', 'cinder/volume/drivers/san/hp/hp_lefthand_rest_proxy.py', 'cinder/backup/drivers/swift.py', 'cinder/image/image_utils.py', 'cinder/api/contrib/backups.py', 'cinder/volume/drivers/san/solaris.py', 'cinder/api/contrib/volume_transfer.py', 'cinder/api/openstack/wsgi.py', 'cinder/volume/drivers/huawei/__init__.py', 'cinder/volume/drivers/huawei/huawei_t.py', 'cinder/volume/drivers/huawei/huawei_dorado.py', 'cinder/manager.py', 'cinder/volume/flows/api/create_volume.py', 'cinder/tests/integrated/test_xml.py', 'cinder/volume/drivers/huawei/rest_common.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py', 'cinder/volume/drivers/windows/utilsfactory.py', 'cinder/volume/drivers/vmware/api.py', 'cinder/volume/drivers/sheepdog.py', 'cinder/tests/integrated/test_login.py', 'cinder/tests/test_hacking.py', 'cinder/tests/integrated/api/client.py', 'cinder/volume/drivers/rbd.py', 'cinder/volume/drivers/solidfire.py', 'cinder/zonemanager/fc_san_lookup_service.py', 'cinder/volume/drivers/nexenta/nfs.py', 'cinder/api/contrib/snapshot_actions.py', 'cinder/tests/test_zadara.py', 'cinder/openstack/common/periodic_task.py', 'cinder/backup/driver.py', 'cinder/volume/drivers/huawei/ssh_common.py', 'cinder/tests/test_storwize_svc.py', 'cinder/volume/drivers/emc/emc_smis_common.py', 'cinder/volume/drivers/hds/iscsi.py', 'cinder/volume/flows/common.py', 'cinder/volume/drivers/hds/nfs.py', 'cinder/brick/initiator/linuxscsi.py', 'cinder/backup/drivers/tsm.py', 'cinder/volume/api.py', 'cinder/api/middleware/auth.py', 'cinder/backup/manager.py', 'cinder/volume/drivers/block_device.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_driver.py', 'cinder/volume/drivers/netapp/eseries/client.py', 'cinder/tests/integrated/test_volumes.py', 'cinder/volume/drivers/windows/windows.py', 'cinder/volume/volume_types.py', 'cinder/volume/drivers/emc/emc_cli_iscsi.py', 'cinder/tests/api/contrib/test_volume_transfer.py', 'cinder/tests/zonemanager/test_brcd_fc_zone_driver.py', 'cinder/zonemanager/drivers/fc_zone_driver.py', 'cinder/volume/drivers/san/hp/hp_lefthand_cliq_proxy.py', 'cinder/zonemanager/drivers/brocade/brcd_fabric_opts.py', 'cinder/volume/drivers/netapp/ssc_utils.py', 'cinder/backup/drivers/ceph.py', 'cinder/quota.py', 'cinder/volume/drivers/ibm/storwize_svc/helpers.py', 'cinder/tests/fake_driver.py', 'cinder/volume/drivers/ibm/gpfs.py', 'cinder/volume/drivers/emc/emc_smis_fc.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/volume/drivers/nexenta/jsonrpc.py', 'bin/cinder-volume-usage-audit', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/tests/integrated/test_extensions.py', 'cinder/volume/driver.py', 'cinder/volume/drivers/vmware/vmware_images.py', 'cinder/volume/qos_specs.py', 'cinder/volume/drivers/vmware/volumeops.py', 'cinder/api/contrib/hosts.py', 'cinder/utils.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_client_cli.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8ab6cbd435579caffe73e0c1746f3127b8082f8d', 'message': 'Debug log messages need to be unicode\n\nMakes all strings being used with LOG.debug into unicode strings.\n\nNot using unicode causes failures when replacemet text is unicode.\n\nFor example, when replacement text is an exception, if the exception\nmessage is unicode (due to translation) it will fail.  When lazy\ntranslation was enabled for blueprint: i18n-enablement the message\nis replaced with an object that does not support str() and it will\nalways fail.\n\nThis change includes a hacking check to avoid having to make\na commit like this in the future and tests in test_hacking.py.\n\nChange-Id: I7972e238e11a02b4aa626333b5bb4827457e7cc0\nCloses-Bug: 1348244\n'}]",0,110059,8ab6cbd435579caffe73e0c1746f3127b8082f8d,15,7,2,7198,,,0,"Debug log messages need to be unicode

Makes all strings being used with LOG.debug into unicode strings.

Not using unicode causes failures when replacemet text is unicode.

For example, when replacement text is an exception, if the exception
message is unicode (due to translation) it will fail.  When lazy
translation was enabled for blueprint: i18n-enablement the message
is replaced with an object that does not support str() and it will
always fail.

This change includes a hacking check to avoid having to make
a commit like this in the future and tests in test_hacking.py.

Change-Id: I7972e238e11a02b4aa626333b5bb4827457e7cc0
Closes-Bug: 1348244
",git fetch https://review.opendev.org/openstack/cinder refs/changes/59/110059/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/scheduler/filter_scheduler.py', 'cinder/volume/manager.py', 'cinder/service.py', 'cinder/backup/api.py', 'cinder/volume/drivers/nimble.py', 'cinder/backup/rpcapi.py', 'cinder/brick/iscsi/iscsi.py', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/backup/fake_swift_client.py', 'cinder/tests/integrated/integrated_helpers.py', 'cinder/volume/drivers/ibm/ibmnas.py', 'cinder/volume/drivers/nfs.py', 'cinder/tests/api/contrib/test_backups.py', 'cinder/brick/remotefs/remotefs.py', 'cinder/api/openstack/__init__.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/api/contrib/volume_image_metadata.py', 'cinder/tests/test_hds_iscsi.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/windows/windows_utils.py', 'cinder/volume/drivers/coraid.py', 'cinder/volume/drivers/zadara.py', 'cinder/volume/drivers/netapp/utils.py', 'cinder/tests/fake_utils.py', 'cinder/volume/drivers/nexenta/iscsi.py', 'cinder/volume/iscsi.py', 'cinder/api/contrib/qos_specs_manage.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_san_lookup_service.py', 'cinder/volume/drivers/emc/emc_smis_iscsi.py', 'cinder/volume/drivers/netapp/eseries/iscsi.py', 'cinder/openstack/common/processutils.py', 'cinder/volume/drivers/hds/hds.py', 'cinder/volume/drivers/san/hp/hp_msa_common.py', 'cinder/volume/flows/manager/create_volume.py', 'cinder/volume/drivers/ibm/storwize_svc/__init__.py', 'cinder/volume/drivers/huawei/huawei_utils.py', 'cinder/brick/local_dev/lvm.py', 'cinder/zonemanager/utils.py', 'cinder/volume/drivers/vmware/io_util.py', 'cinder/zonemanager/fc_zone_manager.py', 'cinder/scheduler/host_manager.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py', 'cinder/volume/drivers/vmware/read_write_util.py', 'cinder/api/v2/volumes.py', 'cinder/volume/drivers/hds/hus_backend.py', 'cinder/api/contrib/volume_manage.py', 'cinder/volume/drivers/hds/hnas_backend.py', 'cinder/compute/nova.py', 'cinder/volume/drivers/lvm.py', 'cinder/tests/brick/test_brick_connector.py', 'cinder/api/extensions.py', 'cinder/api/v1/volumes.py', 'cinder/brick/initiator/connector.py', 'cinder/volume/drivers/eqlx.py', 'cinder/hacking/checks.py', 'cinder/volume/drivers/san/hp/hp_lefthand_rest_proxy.py', 'cinder/backup/drivers/swift.py', 'cinder/image/image_utils.py', 'cinder/api/contrib/backups.py', 'cinder/volume/drivers/san/solaris.py', 'cinder/api/contrib/volume_transfer.py', 'cinder/api/openstack/wsgi.py', 'cinder/volume/drivers/huawei/__init__.py', 'cinder/volume/drivers/huawei/huawei_t.py', 'cinder/volume/drivers/huawei/huawei_dorado.py', 'cinder/manager.py', 'cinder/volume/flows/api/create_volume.py', 'cinder/tests/integrated/test_xml.py', 'cinder/volume/drivers/huawei/rest_common.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py', 'cinder/volume/drivers/windows/utilsfactory.py', 'cinder/volume/drivers/vmware/api.py', 'cinder/volume/drivers/sheepdog.py', 'cinder/tests/integrated/test_login.py', 'cinder/tests/test_hacking.py', 'cinder/tests/integrated/api/client.py', 'cinder/volume/drivers/rbd.py', 'cinder/volume/drivers/solidfire.py', 'cinder/zonemanager/fc_san_lookup_service.py', 'cinder/volume/drivers/nexenta/nfs.py', 'cinder/api/contrib/snapshot_actions.py', 'cinder/tests/test_zadara.py', 'cinder/openstack/common/periodic_task.py', 'cinder/backup/driver.py', 'cinder/volume/drivers/huawei/ssh_common.py', 'cinder/tests/test_storwize_svc.py', 'cinder/volume/drivers/emc/emc_smis_common.py', 'cinder/volume/drivers/hds/iscsi.py', 'cinder/volume/flows/common.py', 'cinder/volume/drivers/hds/nfs.py', 'cinder/brick/initiator/linuxscsi.py', 'cinder/backup/drivers/tsm.py', 'cinder/volume/api.py', 'cinder/api/middleware/auth.py', 'cinder/backup/manager.py', 'cinder/volume/drivers/block_device.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_driver.py', 'cinder/volume/drivers/netapp/eseries/client.py', 'cinder/tests/integrated/test_volumes.py', 'cinder/volume/drivers/windows/windows.py', 'cinder/volume/volume_types.py', 'cinder/volume/drivers/emc/emc_cli_iscsi.py', 'cinder/tests/api/contrib/test_volume_transfer.py', 'cinder/tests/zonemanager/test_brcd_fc_zone_driver.py', 'cinder/zonemanager/drivers/fc_zone_driver.py', 'cinder/volume/drivers/san/hp/hp_lefthand_cliq_proxy.py', 'cinder/zonemanager/drivers/brocade/brcd_fabric_opts.py', 'cinder/volume/drivers/netapp/ssc_utils.py', 'cinder/backup/drivers/ceph.py', 'cinder/quota.py', 'cinder/volume/drivers/ibm/storwize_svc/helpers.py', 'cinder/tests/fake_driver.py', 'cinder/volume/drivers/ibm/gpfs.py', 'cinder/volume/drivers/emc/emc_smis_fc.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/volume/drivers/nexenta/jsonrpc.py', 'bin/cinder-volume-usage-audit', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/tests/integrated/test_extensions.py', 'cinder/volume/driver.py', 'cinder/volume/drivers/vmware/vmware_images.py', 'cinder/volume/qos_specs.py', 'cinder/volume/drivers/vmware/volumeops.py', 'cinder/api/contrib/hosts.py', 'cinder/utils.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_zone_client_cli.py']",126,2ddf48bb3f0c3cca7b2fbc9ba979e8b956f4a7d2,bug/1348244," LOG.debug(u""Add Zones - Zones passed: %s"", zones) LOG.debug(u""Active zone set:%s"", active_zone_set) LOG.debug(u""zone list:%s"", zone_list) LOG.debug(u""Deleted Zone before insert : %s"", zone) LOG.debug(u""Forming command for add zone"") LOG.debug(u""Adding zone, cmd to run %s"", cmd) LOG.debug(u""Created zones on the switch"") LOG.debug(u""New zone %s"", cmd) LOG.debug(u""Delete zones: Config cmd to run:%s"", cmd) LOG.debug(u""Executing command via ssh: %s"", cmd_list) LOG.debug(u""Firmware version string:%s"", line) LOG.debug(u""Executing command via ssh: %s"" % command) LOG.debug(u""Exit Status from ssh:%s"", exit_status) LOG.debug(u'Result was %s' % exit_status) LOG.debug(u""Handling error case after "" LOG.debug(u'Running cmd (SSH): %s' % command) LOG.debug(u'Result was %s' % exit_status) LOG.debug(u""_execute_cmd: stderr to return:%s"" % stderr)"," LOG.debug(""Add Zones - Zones passed: %s"", zones) LOG.debug(""Active zone set:%s"", active_zone_set) LOG.debug(""zone list:%s"", zone_list) LOG.debug(""Deleted Zone before insert : %s"", zone) LOG.debug(""Forming command for add zone"") LOG.debug(""Adding zone, cmd to run %s"", cmd) LOG.debug(""Created zones on the switch"") LOG.debug(""New zone %s"", cmd) LOG.debug(""Delete zones: Config cmd to run:%s"", cmd) LOG.debug(""Executing command via ssh: %s"", cmd_list) LOG.debug(""Firmware version string:%s"", line) LOG.debug(""Executing command via ssh: %s"" % command) LOG.debug(""Exit Status from ssh:%s"", exit_status) LOG.debug('Result was %s' % exit_status) LOG.debug(""Handling error case after "" LOG.debug('Running cmd (SSH): %s' % command) LOG.debug('Result was %s' % exit_status) LOG.debug(""_execute_cmd: stderr to return:%s"" % stderr)",955,927
openstack%2Fcookbook-openstack-compute~master~Ibf090253dd52a1b027e9ad2467a1de766bce7243,openstack/cookbook-openstack-compute,master,Ibf090253dd52a1b027e9ad2467a1de766bce7243,Allow rootwrap configuration via attributes,MERGED,2014-07-23 19:15:16.000000000,2014-08-07 19:40:34.000000000,2014-08-07 19:40:34.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 12323}]","[{'number': 1, 'created': '2014-07-23 19:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/95e08454a2aeecac75fca48169657671c6459331', 'message': 'Allow rootwrap configuration via attributes\n\nChange-Id: Ibf090253dd52a1b027e9ad2467a1de766bce7243\nCloses-Bug: #1347861\n'}, {'number': 2, 'created': '2014-07-23 19:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/1ec568790321147b93036a18a3573084407b443b', 'message': 'Allow rootwrap configuration via attributes\n\nChange-Id: Ibf090253dd52a1b027e9ad2467a1de766bce7243\nPartial-Bug: #1347861\n'}, {'number': 3, 'created': '2014-08-01 17:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/affc427f5df6be3530112e15b535a4e5c0367ea0', 'message': 'Allow rootwrap configuration via attributes\n\nChange-Id: Ibf090253dd52a1b027e9ad2467a1de766bce7243\nCloses-Bug: #1347861\n'}, {'number': 4, 'created': '2014-08-01 17:56:54.000000000', 'files': ['templates/default/rootwrap.conf.erb', 'spec/spec_helper.rb', 'attributes/default.rb', 'spec/nova-common_spec.rb', 'CHANGELOG.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/d4c01834ef7cbb0215bd15a963023042a1d8e201', 'message': 'Allow rootwrap configuration via attributes\n\nChange-Id: Ibf090253dd52a1b027e9ad2467a1de766bce7243\nCloses-Bug: #1347861\n'}]",0,109083,d4c01834ef7cbb0215bd15a963023042a1d8e201,18,3,4,7128,,,0,"Allow rootwrap configuration via attributes

Change-Id: Ibf090253dd52a1b027e9ad2467a1de766bce7243
Closes-Bug: #1347861
",git fetch https://review.opendev.org/openstack/cookbook-openstack-compute refs/changes/83/109083/4 && git format-patch -1 --stdout FETCH_HEAD,"['templates/default/rootwrap.conf.erb', 'attributes/default.rb', 'spec/nova-common_spec.rb', 'CHANGELOG.md']",4,95e08454a2aeecac75fca48169657671c6459331,bug-1347861-rootwrap2,* Allow rootwrap.conf attributes,,15,7
openstack%2Fironic~master~I80d2208d41d21821f0da662637418ecd76b5db2b,openstack/ironic,master,I80d2208d41d21821f0da662637418ecd76b5db2b,Move the 'instance_info' fields to GenericDriverFields,MERGED,2014-08-07 16:55:55.000000000,2014-08-07 19:36:21.000000000,2014-08-07 19:36:21.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 10342}, {'_account_id': 10343}]","[{'number': 1, 'created': '2014-08-07 16:55:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4f23fde0e153c5f22656b73d8217ddfc7be8edd9', 'message': ""Move the 'intance_info' fields to the GenericDriverFields\n\nThe instance_info fields should be common across all drivers and not\njust for PXE drivers.\n\nCloses-Bug: #1353631\nChange-Id: I80d2208d41d21821f0da662637418ecd76b5db2b\n""}, {'number': 2, 'created': '2014-08-07 17:40:50.000000000', 'files': ['ironic/nova/virt/ironic/patcher.py', 'ironic/nova/tests/virt/ironic/test_driver.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/1062b79a35763a9f9257d9743f884202525bc8a7', 'message': ""Move the 'instance_info' fields to GenericDriverFields\n\nThe instance_info parameters are common across all drivers and not\njust for PXE drivers.\n\nThis patch corrects an issue in nova/virt/ironic/patcher.py by moving\nthe generation of the instance_info patch to the common base class.\nIt also adds notes stating the intent to remove the PXE-specific\npatching in Kilo.\n\nCloses-Bug: #1353631\nChange-Id: I80d2208d41d21821f0da662637418ecd76b5db2b\n""}]",1,112623,1062b79a35763a9f9257d9743f884202525bc8a7,13,4,2,6773,,,0,"Move the 'instance_info' fields to GenericDriverFields

The instance_info parameters are common across all drivers and not
just for PXE drivers.

This patch corrects an issue in nova/virt/ironic/patcher.py by moving
the generation of the instance_info patch to the common base class.
It also adds notes stating the intent to remove the PXE-specific
patching in Kilo.

Closes-Bug: #1353631
Change-Id: I80d2208d41d21821f0da662637418ecd76b5db2b
",git fetch https://review.opendev.org/openstack/ironic refs/changes/23/112623/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/nova/virt/ironic/patcher.py', 'ironic/nova/tests/virt/ironic/test_driver.py']",2,4f23fde0e153c5f22656b73d8217ddfc7be8edd9,bug/1353631-patcher," image_meta = ironic_utils.get_test_image_meta() flavor = ironic_utils.get_test_flavor() self.driver._add_driver_fields(node, instance, image_meta, flavor) expected_patch = [{'path': '/instance_info/image_source', 'op': 'add', 'value': image_meta['id']}, {'path': '/instance_info/root_gb', 'op': 'add', 'value': str(instance['root_gb'])}, {'path': '/instance_info/swap_mb', 'op': 'add', 'value': str(flavor['swap'])}, {'path': '/instance_uuid', 'op': 'add', image_meta = ironic_utils.get_test_image_meta() flavor = ironic_utils.get_test_flavor() node, instance, image_meta, flavor) mock_flavor.return_value = ironic_utils.get_test_flavor() image_meta = ironic_utils.get_test_image_meta() self.ctx, instance, image_meta, [], None) mock_flavor.return_value = ironic_utils.get_test_flavor() image_meta = ironic_utils.get_test_image_meta() self.ctx, instance, image_meta, [], None) mock_flavor.return_value = ironic_utils.get_test_flavor() image_meta = ironic_utils.get_test_image_meta() self.ctx, instance, image_meta, [], None) mock_flavor.return_value = ironic_utils.get_test_flavor() image_meta = ironic_utils.get_test_image_meta() self.ctx, instance, image_meta, [], None) mock_flavor.return_value = ironic_utils.get_test_flavor() image_meta = ironic_utils.get_test_image_meta() self.driver.spawn, self.ctx, instance, image_meta, [], None, fake_net_info) mock_flavor.return_value = ironic_utils.get_test_flavor(ephemeral_gb=1) image_meta = ironic_utils.get_test_image_meta() self.driver.spawn(self.ctx, instance, image_meta, [], None)"," self.driver._add_driver_fields(node, instance, None, None) expected_patch = [{'path': '/instance_uuid', 'op': 'add', node, instance, None, None) fake_flavor = {'ephemeral_gb': 0} mock_flavor.return_value = fake_flavor self.ctx, instance, None, [], None) fake_flavor = {'ephemeral_gb': 0} mock_flavor.return_value = fake_flavor self.ctx, instance, None, [], None) fake_flavor = {'ephemeral_gb': 0} mock_flavor.return_value = fake_flavor self.ctx, instance, None, [], None) fake_flavor = {'ephemeral_gb': 0} mock_flavor.return_value = fake_flavor self.ctx, instance, None, [], None) fake_flavor = {'ephemeral_gb': 0} mock_flavor.return_value = fake_flavor self.driver.spawn, self.ctx, instance, None, [], None, fake_net_info) fake_flavor = {'ephemeral_gb': 1} mock_flavor.return_value = fake_flavor self.driver.spawn(self.ctx, instance, None, [], None)",86,48
openstack%2Fopenstacksdk~master~Ic1488da60718e7d518c531d2f02b78a8b0c72c8d,openstack/openstacksdk,master,Ic1488da60718e7d518c531d2f02b78a8b0c72c8d,Separate head restrictions from get,MERGED,2014-07-29 20:28:37.000000000,2014-08-07 19:32:41.000000000,2014-08-07 19:32:40.000000000,"[{'_account_id': 3}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-07-29 20:28:37.000000000', 'files': ['openstack/resource.py', 'openstack/tests/test_resource.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/b8ee194105764ecc71a52c7bf9236cad78235119', 'message': 'Separate head restrictions from get\n\nWe need to be able to allow head requests while disallowing get\nrequests. In swift, we want to be able to call head on the account\nfor metadata, but will be listing containers - both of which are calls\non the root URL - from a different class\n\nChange-Id: Ic1488da60718e7d518c531d2f02b78a8b0c72c8d\n'}]",0,110454,b8ee194105764ecc71a52c7bf9236cad78235119,15,2,1,8257,,,0,"Separate head restrictions from get

We need to be able to allow head requests while disallowing get
requests. In swift, we want to be able to call head on the account
for metadata, but will be listing containers - both of which are calls
on the root URL - from a different class

Change-Id: Ic1488da60718e7d518c531d2f02b78a8b0c72c8d
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/54/110454/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/resource.py', 'openstack/tests/test_resource.py']",2,b8ee194105764ecc71a52c7bf9236cad78235119,allow_head, allow_delete = allow_list = allow_head = True, allow_delete = allow_list = True,4,3
openstack%2Fnova~master~Ie0720d5c847871527db7d9477ca6cb05abe7a1a5,openstack/nova,master,Ie0720d5c847871527db7d9477ca6cb05abe7a1a5,Set is_public to False by default for volume backed snapshots,MERGED,2013-11-26 21:41:25.000000000,2014-08-07 19:17:18.000000000,2014-01-17 15:34:35.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2202}, {'_account_id': 5511}, {'_account_id': 5652}, {'_account_id': 7002}, {'_account_id': 7069}, {'_account_id': 7156}, {'_account_id': 8107}, {'_account_id': 8125}, {'_account_id': 8321}, {'_account_id': 8322}, {'_account_id': 9046}]","[{'number': 1, 'created': '2013-11-26 21:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b5e085fa4fe7a2e3775a9f4635054bd23779bbf', 'message': 'Set is_public meta data to False by default for volume backed snapshots\n\nThis update results in the same behavior that is already implemented in\n_create_image where the meta_data for is_public is set to False.\n\nChange-Id: Ie0720d5c847871527db7d9477ca6cb05abe7a1a5\nCloses-Bug: #1255316\n'}, {'number': 2, 'created': '2013-11-26 21:45:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/62401eb59a08b46fea4c7845ed47c2746bd5159b', 'message': 'Set is_public to False by default for volume backed snapshots\n\nThis update results in the same behavior that is already implemented\nin _create_image where the meta_data for is_public is set to False.\n\nChange-Id: Ie0720d5c847871527db7d9477ca6cb05abe7a1a5\nCloses-Bug: #1255316\n'}, {'number': 3, 'created': '2013-11-27 03:31:14.000000000', 'files': ['nova/tests/compute/test_compute_api.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0530e02004578a36039111beddf472fcf3e48df6', 'message': 'Set is_public to False by default for volume backed snapshots\n\nThis update results in the same behavior that is already implemented\nin _create_image where the meta_data for is_public is set to False.\n\nChange-Id: Ie0720d5c847871527db7d9477ca6cb05abe7a1a5\nCloses-Bug: #1255316\n'}]",1,58629,0530e02004578a36039111beddf472fcf3e48df6,19,13,3,2202,,,0,"Set is_public to False by default for volume backed snapshots

This update results in the same behavior that is already implemented
in _create_image where the meta_data for is_public is set to False.

Change-Id: Ie0720d5c847871527db7d9477ca6cb05abe7a1a5
Closes-Bug: #1255316
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/58629/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/api.py'],1,2b5e085fa4fe7a2e3775a9f4635054bd23779bbf,bug/1255316, image_meta['is_public'] = False,,1,0
openstack%2Fopenstack-chef-repo~master~I9f132efefdf5b78ea1a8d1ee66185c89e13713de,openstack/openstack-chef-repo,master,I9f132efefdf5b78ea1a8d1ee66185c89e13713de,Adding roles from cookbook-ceph,MERGED,2014-07-24 18:53:54.000000000,2014-08-07 19:15:25.000000000,2014-08-07 19:15:24.000000000,"[{'_account_id': 3}, {'_account_id': 1032}, {'_account_id': 6526}, {'_account_id': 7128}, {'_account_id': 9488}, {'_account_id': 12323}]","[{'number': 1, 'created': '2014-07-24 18:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef-repo/commit/d87dd861ef7f8c433d7f266c3bbae4faebe55ba8', 'message': 'Adding roles from cookbook-ceph\n\n* Updating infrastructure.yml\n\nChange-Id: I9f132efefdf5b78ea1a8d1ee66185c89e13713de\nPartial-Bug: 1348324\n'}, {'number': 2, 'created': '2014-07-25 22:11:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef-repo/commit/e4604e44321212d3c7c4af281f5975d3610970ea', 'message': 'Adding roles from cookbook-ceph\n\n* Adding cookbook-ceph to Berksfile\n* Updating infrastructure.yml\n* Updated Gemfile.lock\n\nChange-Id: I9f132efefdf5b78ea1a8d1ee66185c89e13713de\nPartial-Bug: 1348324\n'}, {'number': 3, 'created': '2014-08-04 12:35:06.000000000', 'files': ['.gitignore', 'roles/ceph-mon.json', 'roles/ceph-tgt.json', 'infrastructure.yml', 'roles/ceph-mds.json', 'roles/ceph-radosgw.json', 'roles/ceph-osd.json', 'Berksfile'], 'web_link': 'https://opendev.org/openstack/openstack-chef-repo/commit/569f4af706e55802fa23a9fb93b134fe4ad1b216', 'message': 'Adding roles from cookbook-ceph\n\n* Adding cookbook-ceph to Berksfile\n* Updating infrastructure.yml\n* Updated Gemfile.lock\n\nChange-Id: I9f132efefdf5b78ea1a8d1ee66185c89e13713de\nPartial-Bug: 1348324\n'}]",2,109387,569f4af706e55802fa23a9fb93b134fe4ad1b216,28,6,3,1032,,,0,"Adding roles from cookbook-ceph

* Adding cookbook-ceph to Berksfile
* Updating infrastructure.yml
* Updated Gemfile.lock

Change-Id: I9f132efefdf5b78ea1a8d1ee66185c89e13713de
Partial-Bug: 1348324
",git fetch https://review.opendev.org/openstack/openstack-chef-repo refs/changes/87/109387/3 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'roles/ceph-mon.json', 'roles/ceph-tgt.json', 'infrastructure.yml', 'roles/ceph-mds.json', 'roles/ceph-radosgw.json', 'roles/ceph-osd.json']",7,d87dd861ef7f8c433d7f266c3bbae4faebe55ba8,bug/1348324,"{ ""name"": ""ceph-osd"", ""description"": ""Ceph Object Storage Device"", ""run_list"": [ ""recipe[ceph::repo]"", ""recipe[ceph::osd]"" ] } ",,53,16
openstack%2Fneutron~master~I2e6d82ee79814e500604f4951e7d89eab662047a,openstack/neutron,master,I2e6d82ee79814e500604f4951e7d89eab662047a,DeferredBridge to allow add_tunnel_port passthru,MERGED,2014-08-07 11:49:12.000000000,2014-08-07 18:59:40.000000000,2014-08-07 18:45:15.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 9361}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-08-07 11:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/82c6a0b1ad3703163d2a60c97956e35232c30a38', 'message': 'DeferredBridge to allow add_tunnel_port passthru\n\nThe DeferredBridge should allow add_tunnel_port\nmethod as passthrough in addition to add_port\nand delete_port. L2Pop uses add_tunnel_port to\ndynamically establish tunnel endpoints on cloud\nnodes.\n\nChange-Id: I2e6d82ee79814e500604f4951e7d89eab662047a\nCloses-Bug: #1353885\n'}, {'number': 2, 'created': '2014-08-07 15:54:01.000000000', 'files': ['neutron/tests/unit/agent/linux/test_ovs_lib.py', 'neutron/agent/linux/ovs_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/be81901b615b45d6aed4287df8c285a1f0aa72b0', 'message': 'DeferredBridge to allow add_tunnel_port passthru\n\nThe DeferredBridge should allow add_tunnel_port\nmethod as passthrough in addition to add_port\nand delete_port. L2Pop uses add_tunnel_port to\ndynamically establish tunnel endpoints on cloud\nnodes.\n\nCloses-Bug: #1353885\n\nChange-Id: I2e6d82ee79814e500604f4951e7d89eab662047a\n'}]",1,112565,be81901b615b45d6aed4287df8c285a1f0aa72b0,45,20,2,9361,,,0,"DeferredBridge to allow add_tunnel_port passthru

The DeferredBridge should allow add_tunnel_port
method as passthrough in addition to add_port
and delete_port. L2Pop uses add_tunnel_port to
dynamically establish tunnel endpoints on cloud
nodes.

Closes-Bug: #1353885

Change-Id: I2e6d82ee79814e500604f4951e7d89eab662047a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/65/112565/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/ovs_lib.py'],1,82c6a0b1ad3703163d2a60c97956e35232c30a38,bug/1353885," ALLOWED_PASSTHROUGHS = 'add_port', 'add_tunnel_port', 'delete_port'"," ALLOWED_PASSTHROUGHS = 'add_port', 'delete_port'",1,1
openstack%2Fswift~master~I0ca16c1ed181c282d2e16c7de912a64def787aa5,openstack/swift,master,I0ca16c1ed181c282d2e16c7de912a64def787aa5,Make get_*_info helper methods safe after path_info_pop,ABANDONED,2014-04-28 20:01:23.000000000,2014-08-07 18:57:59.000000000,,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 2622}, {'_account_id': 2696}, {'_account_id': 6198}]","[{'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d51bbfacf43690ebb5534e9e5a120c213071c2c6', 'message': ""Make get_*_info helper methods safe after path_info_pop\n\nThe get_*_info utility functions in swift.proxy.controllers.base would\nraise an exception if used after the proxy-server calls\nreq.path_info_pop().  This will be the case when tempauth's authorize()\nmethod gets called and needs to go fetch account ACLs (implemented in\nanother patch).\n\nAlso did some drive-by tidying up of split_path calls and increased the\ntest coverage of the get_*_info functions.\n\nChange-Id: I0ca16c1ed181c282d2e16c7de912a64def787aa5\n""}, {'number': 3, 'created': '2014-04-28 20:01:23.000000000', 'files': ['swift/common/middleware/staticweb.py', 'swift/common/middleware/tempauth.py', 'test/unit/proxy/controllers/test_base.py', 'swift/common/request_helpers.py', 'swift/obj/ssync_receiver.py', 'swift/proxy/controllers/base.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/5e77018f71c6b0282eb0850e1420f2adfbfccb36', 'message': ""Make get_*_info helper methods safe after path_info_pop\n\nThe get_*_info utility functions in swift.proxy.controllers.base would\nraise an exception if used after the proxy-server calls\nreq.path_info_pop().  This will be the case when tempauth's authorize()\nmethod gets called and needs to go fetch account ACLs (implemented in\nanother patch).\n\nAlso did some drive-by tidying up of split_path calls and increased the\ntest coverage of the get_*_info functions.\n\nChange-Id: I0ca16c1ed181c282d2e16c7de912a64def787aa5\n""}, {'number': 2, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/99f900c434573e14d5efd14fa972cba8577c22bf', 'message': ""Make get_*_info helper methods safe after path_info_pop\n\nThe get_*_info utility functions in swift.proxy.controllers.base would\nraise an exception if used after the proxy-server calls\nreq.path_info_pop().  This will be the case when tempauth's authorize()\nmethod gets called and needs to go fetch account ACLs (implemented in\nanother patch).\n\nAlso did some drive-by tidying up of split_path calls and increased the\ntest coverage of the get_*_info functions.\n\nChange-Id: I0ca16c1ed181c282d2e16c7de912a64def787aa5\n""}]",11,59911,5e77018f71c6b0282eb0850e1420f2adfbfccb36,29,5,3,2696,,,0,"Make get_*_info helper methods safe after path_info_pop

The get_*_info utility functions in swift.proxy.controllers.base would
raise an exception if used after the proxy-server calls
req.path_info_pop().  This will be the case when tempauth's authorize()
method gets called and needs to go fetch account ACLs (implemented in
another patch).

Also did some drive-by tidying up of split_path calls and increased the
test coverage of the get_*_info functions.

Change-Id: I0ca16c1ed181c282d2e16c7de912a64def787aa5
",git fetch https://review.opendev.org/openstack/swift refs/changes/11/59911/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/staticweb.py', 'swift/common/middleware/tempauth.py', 'test/unit/proxy/controllers/test_base.py', 'swift/common/request_helpers.py', 'swift/obj/ssync_receiver.py', 'swift/proxy/controllers/base.py']",6,d51bbfacf43690ebb5534e9e5a120c213071c2c6,fix-path-splitting," split_path(env.get('SCRIPT_NAME', '') + (path or env['PATH_INFO']), 4, 4, True) (version, account, container, unused) = Request(env).split_path(3, 4, True) (version, account, _junk, _junk) = Request(env).split_path(2, 4, True)"," split_path(path or env['PATH_INFO'], 4, 4, True) (version, account, container, unused) = \ split_path(env['PATH_INFO'], 3, 4, True) (version, account, _junk, _junk) = \ split_path(env['PATH_INFO'], 2, 4, True)",89,18
openstack%2Fnova~master~I82a5602bdbecb931c046bb693f16917f38a075fb,openstack/nova,master,I82a5602bdbecb931c046bb693f16917f38a075fb,Fix the i18n for some warnings in compute utils,MERGED,2014-07-24 17:09:31.000000000,2014-08-07 18:35:44.000000000,2014-07-24 22:09:36.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 679}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-24 17:09:31.000000000', 'files': ['nova/compute/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/038857d5455aca07b521a681e1315decf0a6d8f6', 'message': 'Fix the i18n for some warnings in compute utils\n\nChange-Id: I82a5602bdbecb931c046bb693f16917f38a075fb\n'}]",0,109353,038857d5455aca07b521a681e1315decf0a6d8f6,14,9,1,1501,,,0,"Fix the i18n for some warnings in compute utils

Change-Id: I82a5602bdbecb931c046bb693f16917f38a075fb
",git fetch https://review.opendev.org/openstack/nova refs/changes/53/109353/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/utils.py'],1,038857d5455aca07b521a681e1315decf0a6d8f6,,"from nova.i18n import _LW LOG.warning(_LW(""Can't access image %(image_id)s: %(error)s""), LOG.warn(_LW(""No host name specified for the notification of "" LOG.warning(_LW(""Value of 0 or None specified for %s.""","from nova.i18n import _ LOG.warning(_(""Can't access image %(image_id)s: %(error)s""), LOG.warn(_(""No host name specified for the notification of "" LOG.warning(_(""Value of 0 or None specified for %s.""",4,4
openstack%2Fglance-specs~master~I2c709f32b3bb9d30dbceef4560f99fccf82de08d,openstack/glance-specs,master,I2c709f32b3bb9d30dbceef4560f99fccf82de08d,Adjust title,MERGED,2014-08-05 07:36:02.000000000,2014-08-07 18:24:03.000000000,2014-08-07 18:24:03.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 616}, {'_account_id': 2537}, {'_account_id': 5314}, {'_account_id': 6482}, {'_account_id': 6547}, {'_account_id': 6549}, {'_account_id': 8759}, {'_account_id': 11080}]","[{'number': 1, 'created': '2014-08-05 07:36:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/8a84853436f29bd08156cb0eb2c892d9cf37e40a', 'message': 'Adjust title\n\nUse proper program name and heading capitalization.\n\nChange-Id: I2c709f32b3bb9d30dbceef4560f99fccf82de08d\n'}, {'number': 2, 'created': '2014-08-06 13:57:08.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/2be7ad0dd8a86805762efc86cd1837198157fd9f', 'message': 'Adjust title\n\nUse proper program name, this is mostly a dummy commit\nso we can populate http://specs.openstack.org/openstack/glance-specs\nwith some content\n\nChange-Id: I2c709f32b3bb9d30dbceef4560f99fccf82de08d\n'}]",5,111941,2be7ad0dd8a86805762efc86cd1837198157fd9f,26,10,2,6482,,,0,"Adjust title

Use proper program name, this is mostly a dummy commit
so we can populate http://specs.openstack.org/openstack/glance-specs
with some content

Change-Id: I2c709f32b3bb9d30dbceef4560f99fccf82de08d
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/41/111941/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,8a84853436f29bd08156cb0eb2c892d9cf37e40a,adjust_title,===================================== Image Service Specifications (glance) =====================================,============================== Glance Project Specifications ==============================,3,3
openstack%2Fcinder~master~If602d33d5cf70931e169ee22157d7a54dbd493ed,openstack/cinder,master,If602d33d5cf70931e169ee22157d7a54dbd493ed,change spelling mistake,ABANDONED,2014-07-27 15:49:51.000000000,2014-08-07 18:13:24.000000000,,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 9008}, {'_account_id': 10068}, {'_account_id': 12016}, {'_account_id': 12033}]","[{'number': 1, 'created': '2014-07-27 15:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ef9fecccc3eb8a2e9ef876c65bf8c7ad69015491', 'message': 'change spelling mistake\n\nChange-Id: If602d33d5cf70931e169ee22157d7a54dbd493ed\n'}, {'number': 2, 'created': '2014-07-28 09:16:24.000000000', 'files': ['cinder/tests/brick/test_brick_connector.py', 'cinder/tests/api/v2/test_volume_metadata.py', 'cinder/openstack/common/lockutils.py', 'cinder/api/middleware/fault.py', 'cinder/volume/drivers/nimble.py', 'cinder/openstack/common/policy.py', 'cinder/tests/api/v2/test_snapshot_metadata.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py', 'cinder/tests/test_storwize_svc.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/1fff81b9126731f58b569dd278b66662ba37d372', 'message': 'change spelling mistake\n\nChange-Id: If602d33d5cf70931e169ee22157d7a54dbd493ed\n'}]",0,109859,1fff81b9126731f58b569dd278b66662ba37d372,15,6,2,12388,,,0,"change spelling mistake

Change-Id: If602d33d5cf70931e169ee22157d7a54dbd493ed
",git fetch https://review.opendev.org/openstack/cinder refs/changes/59/109859/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/api/v2/test_volume_metadata.py', 'cinder/volume/drivers/emc/emc_cli_iscsi.py~', 'cinder/api/middleware/fault.py', 'cinder/volume/drivers/nimble.py', 'cinder/openstack/common/policy.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py', 'cinder/volume/drivers/san/solaris.py~', 'cinder/openstack/common/loopingcall.py~', 'cinder/volume/drivers/netapp/api.py~', 'cinder/tests/brick/test_brick_connector.py~', 'cinder/volume/drivers/emc/emc_smis_common.py~', 'cinder/volume/drivers/ibm/storwize_svc/helpers.py~', 'cinder/volume/drivers/emc/emc_vnx_cli.py~', 'cinder/tests/brick/test_brick_connector.py', 'cinder/volume/drivers/emc/emc_smis_fc.py~', 'cinder/exception.py~', 'cinder/tests/api/v1/test_volume_metadata.py~', 'cinder/tests/test_storwize_svc.py~', 'cinder/volume/flows/manager/create_volume.py~', 'cinder/tests/api/v1/test_snapshot_metadata.py~', 'cinder/tests/test_storwize_svc.py', 'cinder/compute/nova.py~', 'cinder/volume/drivers/vmware/read_write_util.py~', 'cinder/volume/manager.py~', 'cinder/scheduler/filter_scheduler.py~', 'cinder/openstack/common/lockutils.py', 'cinder/tests/api/v2/test_snapshot_metadata.py', 'cinder/volume/drivers/emc/emc_smis_iscsi.py~', 'cinder/volume/drivers/hds/hnas_backend.py~', 'cinder/scheduler/filters/affinity_filter.py~']",30,ef9fecccc3eb8a2e9ef876c65bf8c7ad69015491,openstack-cinder-first-commit,"# Copyright 2014, eBay Inc. # Copyright 2014, OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from cinder.openstack.common import log as logging from cinder.openstack.common.scheduler import filters from cinder.openstack.common import uuidutils from cinder.volume import api as volume LOG = logging.getLogger(__name__) class AffinityFilter(filters.BaseHostFilter): def __init__(self): self.volume_api = volume.API() class DifferentBackendFilter(AffinityFilter): """"""Schedule volume on a different back-end from a set of volumes."""""" def host_passes(self, host_state, filter_properties): context = filter_properties['context'] scheduler_hints = filter_properties.get('scheduler_hints') or {} affinity_uuids = scheduler_hints.get('different_host', []) # scheduler hint verification: affinity_uuids can be a list of uuids # or single uuid. The checks here is to make sure every single string # in the list looks like a uuid, otherwise, this filter will fail to # pass. Note that the filter does *NOT* ignore string doesn't look # like a uuid, it is better to fail the request than serving it wrong. if isinstance(affinity_uuids, list): for uuid in affinity_uuids: if uuidutils.is_uuid_like(uuid): continue else: return False elif uuidutils.is_uuid_like(affinity_uuids): affinity_uuids = [affinity_uuids] else: # Not a list, not a string looks like uuid, don't pass it # to DB for query to avoid potential risk. return False if affinity_uuids: return not self.volume_api.get_all( context, filters={'host': host_state.host, 'id': affinity_uuids, 'deleted': False}) # With no different_host key return True class SameBackendFilter(AffinityFilter): """"""Schedule volume on the same back-end as another volume."""""" def host_passes(self, host_state, filter_properties): context = filter_properties['context'] scheduler_hints = filter_properties.get('scheduler_hints') or {} affinity_uuids = scheduler_hints.get('same_host', []) # scheduler hint verification: affinity_uuids can be a list of uuids # or single uuid. The checks here is to make sure every single string # in the list looks like a uuid, otherwise, this filter will fail to # pass. Note that the filter does *NOT* ignore string doesn't look # like an uuid, it is better to fail the request than serving it wrong. if isinstance(affinity_uuids, list): for uuid in affinity_uuids: if uuidutils.is_uuid_like(uuid): continue else: return False elif uuidutils.is_uuid_like(affinity_uuids): affinity_uuids = [affinity_uuids] else: # Not a list, not a string looks like uuid, don't pass it # to DB for query to avoid potential risk. return False if affinity_uuids: return self.volume_api.get_all( context, filters={'host': host_state.host, 'id': affinity_uuids, 'deleted': False}) # With no same_host key return True ",,13764,16
openstack%2Fnova~master~I846c37fe79931c85384950f6ad6ecd79d4071fec,openstack/nova,master,I846c37fe79931c85384950f6ad6ecd79d4071fec,Fixes wrong usage of mock.assert_not_called(),MERGED,2014-08-06 06:59:48.000000000,2014-08-07 18:06:35.000000000,2014-08-07 12:06:45.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1030}, {'_account_id': 5170}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 9796}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-06 06:59:48.000000000', 'files': ['nova/tests/volume/test_cinder.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a0c769c6e2d75b0ff74c649bc88f3804690ff3d7', 'message': 'Fixes wrong usage of mock.assert_not_called()\n\nThere is no method assert_not_called in mock, use\nassertFalse(mock.called) instead of that.\n\nChange-Id: I846c37fe79931c85384950f6ad6ecd79d4071fec\n'}]",0,112217,a0c769c6e2d75b0ff74c649bc88f3804690ff3d7,30,11,1,9796,,,0,"Fixes wrong usage of mock.assert_not_called()

There is no method assert_not_called in mock, use
assertFalse(mock.called) instead of that.

Change-Id: I846c37fe79931c85384950f6ad6ecd79d4071fec
",git fetch https://review.opendev.org/openstack/nova refs/changes/17/112217/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/volume/test_cinder.py'],1,a0c769c6e2d75b0ff74c649bc88f3804690ff3d7,, self.assertFalse(mock_get_instance_az.called) self.assertFalse(mock_get_instance_az.called), mock_get_instance_az.assert_not_called() mock_get_instance_az.assert_not_called(),2,2
openstack%2Ftempest~master~I34b16ed5a6f9221707f3a9d0d4619bb3b261e14f,openstack/tempest,master,I34b16ed5a6f9221707f3a9d0d4619bb3b261e14f,Do not isolate networks for baremetal,MERGED,2014-07-30 01:37:24.000000000,2014-08-07 18:04:56.000000000,2014-08-07 15:11:07.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-30 01:37:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9ac65f11a2766ebdd28b10f1d1fd581e2fc3bedf', 'message': 'Do not isolate networks for baremetal\n\nNetwork isolaton is not currently a supported feature for baremetal\ndeployments.  This adjusts the isolated credentials to avoid creation of\nisolated network environments for created tenants.  Instead, we rely on\na shared private network serving addresses from a common subnet.\n\nChange-Id: I34b16ed5a6f9221707f3a9d0d4619bb3b261e14f\n'}, {'number': 2, 'created': '2014-08-06 23:40:41.000000000', 'files': ['tempest/common/isolated_creds.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/85395e74945f814ae980aec25bf2ba99daa5f585', 'message': 'Do not isolate networks for baremetal\n\nNetwork isolaton is not currently a supported feature for baremetal\ndeployments.  This adjusts the isolated credentials to avoid creation of\nisolated network environments for created tenants.  Instead, we rely on\na shared private network serving addresses from a common subnet.\n\nChange-Id: I34b16ed5a6f9221707f3a9d0d4619bb3b261e14f\n'}]",2,110520,85395e74945f814ae980aec25bf2ba99daa5f585,30,8,2,1420,,,0,"Do not isolate networks for baremetal

Network isolaton is not currently a supported feature for baremetal
deployments.  This adjusts the isolated credentials to avoid creation of
isolated network environments for created tenants.  Instead, we rely on
a shared private network serving addresses from a common subnet.

Change-Id: I34b16ed5a6f9221707f3a9d0d4619bb3b261e14f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/20/110520/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/common/isolated_creds.py'],1,9ac65f11a2766ebdd28b10f1d1fd581e2fc3bedf,ironic_tempest, if (CONF.service_available.neutron and not CONF.baremetal.driver_enabled):, if CONF.service_available.neutron:,2,1
openstack%2Fnova~master~I5c0d61be35fc4edf647e572c746515988651bcc0,openstack/nova,master,I5c0d61be35fc4edf647e572c746515988651bcc0,Make network/api.py use Network object for associations,MERGED,2014-07-24 16:30:08.000000000,2014-08-07 17:56:07.000000000,2014-08-07 12:05:04.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 2835}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-24 16:30:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d0a1d632de07f8c617b48587fe1d5ee6e36caa83', 'message': 'Make network/api.py use Network object for associations\n\nThis makes the network/api.py module use the Network object for\nnetwork host and project associate/disassociate operations. There\nwas very little testing of this, so this patch adds/corrects tests\nto verify object behavior.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: I5c0d61be35fc4edf647e572c746515988651bcc0\n'}, {'number': 2, 'created': '2014-07-31 14:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1bf8eb118e1c56cbcbc58dee80000bf0b1a010a7', 'message': 'Make network/api.py use Network object for associations\n\nThis makes the network/api.py module use the Network object for\nnetwork host and project associate/disassociate operations. There\nwas very little testing of this, so this patch adds/corrects tests\nto verify object behavior.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: I5c0d61be35fc4edf647e572c746515988651bcc0\n'}, {'number': 3, 'created': '2014-07-31 15:12:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eb2fcae875b26e567516253c81d3011cb10c1985', 'message': 'Make network/api.py use Network object for associations\n\nThis makes the network/api.py module use the Network object for\nnetwork host and project associate/disassociate operations. There\nwas very little testing of this, so this patch adds/corrects tests\nto verify object behavior.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: I5c0d61be35fc4edf647e572c746515988651bcc0\n'}, {'number': 4, 'created': '2014-07-31 19:48:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/03f350094cf69f66471012520f30b305631dbd75', 'message': 'Make network/api.py use Network object for associations\n\nThis makes the network/api.py module use the Network object for\nnetwork host and project associate/disassociate operations. There\nwas very little testing of this, so this patch adds/corrects tests\nto verify object behavior.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: I5c0d61be35fc4edf647e572c746515988651bcc0\n'}, {'number': 5, 'created': '2014-08-05 17:22:38.000000000', 'files': ['nova/network/api.py', 'nova/tests/network/test_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6d12d70a42b922225dd16338ec9db8c60df89e38', 'message': 'Make network/api.py use Network object for associations\n\nThis makes the network/api.py module use the Network object for\nnetwork host and project associate/disassociate operations. There\nwas very little testing of this, so this patch adds/corrects tests\nto verify object behavior.\n\nRelated to blueprint compute-manager-objects-juno\n\nChange-Id: I5c0d61be35fc4edf647e572c746515988651bcc0\n'}]",4,109340,6d12d70a42b922225dd16338ec9db8c60df89e38,50,13,5,4393,,,0,"Make network/api.py use Network object for associations

This makes the network/api.py module use the Network object for
network host and project associate/disassociate operations. There
was very little testing of this, so this patch adds/corrects tests
to verify object behavior.

Related to blueprint compute-manager-objects-juno

Change-Id: I5c0d61be35fc4edf647e572c746515988651bcc0
",git fetch https://review.opendev.org/openstack/nova refs/changes/40/109340/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/api.py', 'nova/tests/network/test_api.py']",2,d0a1d632de07f8c617b48587fe1d5ee6e36caa83,bp/compute-manager-objects-juno," @mock.patch('nova.objects.Network.get_by_uuid') @mock.patch('nova.objects.Network.disassociate') def test_network_disassociate_project(self, mock_disassociate, mock_get): net_obj = objects.Network(context=self.context, id=1) mock_get.return_value = net_obj mock_disassociate.assert_called_once_with(self.context, net_obj.id, host=False, project=True) @mock.patch('nova.objects.Network.get_by_uuid') @mock.patch('nova.objects.Network.disassociate') def test_network_disassociate_host(self, mock_disassociate, mock_get): net_obj = objects.Network(context=self.context, id=1) mock_get.return_value = net_obj self.network_api.associate(self.context, FAKE_UUID, host=None) mock_disassociate.assert_called_once_with(self.context, net_obj.id, host=True, project=False) @mock.patch('nova.objects.Network.get_by_uuid') @mock.patch('nova.objects.Network.associate') def test_network_associate_project(self, mock_associate, mock_get): net_obj = objects.Network(context=self.context, id=1) mock_get.return_value = net_obj project = mock.sentinel.project self.network_api.associate(self.context, FAKE_UUID, project=project) mock_associate.assert_called_once_with(self.context, project, network_id=net_obj.id, force=True) @mock.patch('nova.objects.Network.get_by_uuid') @mock.patch('nova.objects.Network.save') def test_network_associate_host(self, mock_save, mock_get): net_obj = objects.Network(context=self.context, id=1) mock_get.return_value = net_obj host = str(mock.sentinel.host) self.network_api.associate(self.context, FAKE_UUID, host=host) mock_save.assert_called_once_with() self.assertEqual(host, net_obj.host) @mock.patch('nova.objects.Network.get_by_uuid') @mock.patch('nova.objects.Network.disassociate') def test_network_disassociate(self, mock_disassociate, mock_get): mock_get.return_value = objects.Network(context=self.context, id=123) self.network_api.disassociate(self.context, FAKE_UUID) mock_disassociate.assert_called_once_with(self.context, 123)"," def test_network_disassociate_project(self): def fake_network_disassociate(ctx, network_id, disassociate_host, disassociate_project): self.assertEqual(network_id, 1) self.assertEqual(disassociate_host, False) self.assertEqual(disassociate_project, True) def fake_get(context, network_uuid): return {'id': 1} self.stubs.Set(self.network_api.db, 'network_disassociate', fake_network_disassociate) self.stubs.Set(self.network_api, 'get', fake_get) ",54,24
openstack%2Fopenstacksdk~master~I93ab1e021bcb894f730941ecf70c4d877ffefa48,openstack/openstacksdk,master,I93ab1e021bcb894f730941ecf70c4d877ffefa48,Add support for interface add/remove to routers,MERGED,2014-08-01 00:24:16.000000000,2014-08-07 17:34:00.000000000,2014-08-07 17:34:00.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2014-08-01 00:24:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/51e616f22dde1d49a1aa504781a7b01f808615f9', 'message': 'Add support for interface add/remove to routers\n\nA subnet may be added to routers through the interface add and\nremove commands.\n\nChange-Id: I93ab1e021bcb894f730941ecf70c4d877ffefa48\n'}, {'number': 2, 'created': '2014-08-05 11:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8662c6110c35a667a60f64d262b193057a698595', 'message': 'Add support for interface add/remove to routers\n\nA subnet may be added to routers through the interface add and\nremove commands.\n\nChange-Id: I93ab1e021bcb894f730941ecf70c4d877ffefa48\n'}, {'number': 3, 'created': '2014-08-07 16:25:37.000000000', 'files': ['openstack/network/v2/router.py', 'openstack/tests/network/v2/test_router.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/65d1a5463d854b028d323f93f81a17f6340b0046', 'message': 'Add support for interface add/remove to routers\n\nA subnet may be added to routers through the interface add and\nremove commands.\n\nChange-Id: I93ab1e021bcb894f730941ecf70c4d877ffefa48\n'}]",1,111124,65d1a5463d854b028d323f93f81a17f6340b0046,14,2,3,8736,,,0,"Add support for interface add/remove to routers

A subnet may be added to routers through the interface add and
remove commands.

Change-Id: I93ab1e021bcb894f730941ecf70c4d877ffefa48
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/24/111124/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/network/v2/router.py', 'openstack/tests/network/v2/test_router.py']",2,51e616f22dde1d49a1aa504781a7b01f808615f9,router,"import mock def test_interface_add(self): sot = router.Router(EXAMPLE) response = mock.Mock() response.body = {""subnet_id"": ""3"", ""port_id"": ""2""} sess = mock.Mock() sess.put = mock.MagicMock() sess.put.return_value = response self.assertEqual(response.body, sot.interface_add(sess, '3')) url = 'v2.0/routers/IDENTIFIER/add_router_interface' body = {""subnet_id"": ""3""} sess.put.assert_called_with(url, service=sot.service, json=body) def test_interface_remove(self): sot = router.Router(EXAMPLE) response = mock.Mock() response.body = {""subnet_id"": ""3"", ""port_id"": ""2""} sess = mock.Mock() sess.put = mock.MagicMock() sess.put.return_value = response self.assertEqual(response.body, sot.interface_remove(sess, '3')) url = 'v2.0/routers/IDENTIFIER/remove_router_interface' body = {""subnet_id"": ""3""} sess.put.assert_called_with(url, service=sot.service, json=body)",,42,0
openstack%2Fpython-novaclient~master~If7009fdeb5a60fe2e357bcc447313cbdb7b2ff39,openstack/python-novaclient,master,If7009fdeb5a60fe2e357bcc447313cbdb7b2ff39,"Fix the return code of the command ""delete""",MERGED,2014-07-11 08:37:06.000000000,2014-08-07 17:31:47.000000000,2014-08-07 17:31:46.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 7653}, {'_account_id': 9545}]","[{'number': 1, 'created': '2014-07-11 08:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/11e50f2b6de4672901b5ea0f3f8722653c4042fd', 'message': 'Fix the return code of the command ""delete""\n\nCurrently, the command delete return a zore if it failed for any\nof servers, the return code should be a nonzore.\n\nChange-Id: If7009fdeb5a60fe2e357bcc447313cbdb7b2ff39\nCloses-Bug: #1339647\n'}, {'number': 2, 'created': '2014-07-29 07:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/c99a27427a1de64b0b8f17de77a5d1085459cbb0', 'message': 'Fix the return code of the command ""delete""\n\nCurrently, the command delete return a zero if it failed for any\nof servers, the return code should be a nonzero.\n\nChange-Id: If7009fdeb5a60fe2e357bcc447313cbdb7b2ff39\nCloses-Bug: #1339647\n'}, {'number': 3, 'created': '2014-08-07 07:00:47.000000000', 'files': ['novaclient/tests/v1_1/test_shell.py', 'novaclient/tests/v3/test_shell.py', 'novaclient/v1_1/shell.py', 'novaclient/v3/shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/3955440ef2f57caf853a40e1cf28abe0a1d371ff', 'message': 'Fix the return code of the command ""delete""\n\nCurrently, the command delete return a zero if it failed for any\nof servers, the return code should be a nonzero.\n\nChange-Id: If7009fdeb5a60fe2e357bcc447313cbdb7b2ff39\nCloses-Bug: #1339647\n'}]",2,106307,3955440ef2f57caf853a40e1cf28abe0a1d371ff,24,7,3,7653,,,0,"Fix the return code of the command ""delete""

Currently, the command delete return a zero if it failed for any
of servers, the return code should be a nonzero.

Change-Id: If7009fdeb5a60fe2e357bcc447313cbdb7b2ff39
Closes-Bug: #1339647
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/07/106307/1 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/tests/v1_1/test_shell.py', 'novaclient/v1_1/shell.py', 'novaclient/v3/shell.py']",3,11e50f2b6de4672901b5ea0f3f8722653c4042fd,Bug1339647," failure_flag = False failure_flag = True if failure_flag: raise exceptions.CommandError(""Unable to delete the specified "" ""server(s)."")"," failure_count = 0 failure_count += 1 if failure_count == len(args.server): raise exceptions.CommandError(""Unable to delete any of the specified "" ""servers."")",14,12
openstack%2Fironic~master~I7f163d42d1298ce4ba62b1b7d637fb0a4e3409ce,openstack/ironic,master,I7f163d42d1298ce4ba62b1b7d637fb0a4e3409ce,Fix self.fields on API Port object,MERGED,2014-08-05 16:00:41.000000000,2014-08-07 17:27:01.000000000,2014-08-07 17:27:01.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6773}, {'_account_id': 7882}, {'_account_id': 10239}, {'_account_id': 12356}]","[{'number': 1, 'created': '2014-08-05 16:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9a47524abec2625997fb3f39affc8b23d505fbeb', 'message': ""Fix self.fields on API Port object\n\nAll fields from objects.Port were being added to self.fields in the\nAPI Port object. Because of this, when someone would POST, there'd be an\nentry for {'id': None} in the dictionary passed to dbapi.create_port(). We\nshould only set fields we're exposing.\n\nThis also required fixing PATCH to not try to look at fields not set on\nthe API Port object when mapping to objects.Port.\n\nChange-Id: I7f163d42d1298ce4ba62b1b7d637fb0a4e3409ce\n""}, {'number': 2, 'created': '2014-08-06 12:50:42.000000000', 'files': ['ironic/api/controllers/v1/port.py', 'ironic/tests/api/v1/test_ports.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e0efab0b28cb039c14b44bbb3f04e6079c1572bf', 'message': ""Fix self.fields on API Port object\n\nAll fields from objects.Port were being added to self.fields in the\nAPI Port object. Because of this, when someone would POST, there'd be an\nentry for {'id': None} in the dictionary passed to dbapi.create_port(). We\nshould only set fields we're exposing.\n\nThis also required fixing PATCH to not try to look at fields not set on\nthe API Port object when mapping to objects.Port.\n\nChange-Id: I7f163d42d1298ce4ba62b1b7d637fb0a4e3409ce\n""}]",0,112056,e0efab0b28cb039c14b44bbb3f04e6079c1572bf,21,6,2,6773,,,0,"Fix self.fields on API Port object

All fields from objects.Port were being added to self.fields in the
API Port object. Because of this, when someone would POST, there'd be an
entry for {'id': None} in the dictionary passed to dbapi.create_port(). We
should only set fields we're exposing.

This also required fixing PATCH to not try to look at fields not set on
the API Port object when mapping to objects.Port.

Change-Id: I7f163d42d1298ce4ba62b1b7d637fb0a4e3409ce
",git fetch https://review.opendev.org/openstack/ironic refs/changes/56/112056/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/api/controllers/v1/port.py', 'ironic/tests/api/v1/test_ports.py']",2,9a47524abec2625997fb3f39affc8b23d505fbeb,bug/1314732," def test_create_port_doesnt_contain_id(self): with mock.patch.object(self.dbapi, 'create_port', wraps=self.dbapi.create_port) as cp_mock: pdict = post_get_test_port(extra={'foo': 123}) self.post_json('/ports', pdict) result = self.get_json('/ports/%s' % pdict['uuid']) self.assertEqual(pdict['extra'], result['extra']) cp_mock.assert_called_once_with(mock.ANY) # Check that 'id' is not in first arg of positional args self.assertNotIn('id', cp_mock.call_args[0][0]) ",,33,6
openstack%2Ftripleo-image-elements~master~I4d5ea3303d5e05c9f941cc497b2ba15814c64a26,openstack/tripleo-image-elements,master,I4d5ea3303d5e05c9f941cc497b2ba15814c64a26,Adds section templating to swift.conf,ABANDONED,2014-08-06 17:16:21.000000000,2014-08-07 17:26:39.000000000,,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 7134}, {'_account_id': 8532}, {'_account_id': 9051}]","[{'number': 1, 'created': '2014-08-06 17:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/b7a9169e7c22624b5ccb8777d41149825071dcf5', 'message': 'Adds section templating to swift.conf\n\nThis patch adds section templating to swift.conf. This would\nbe needed to add any section to swift.conf via passthrough\nmechanism. This would be mainly useful to add/update storage policies\nvia passthrough mechanism.\n\nChange-Id: I4d5ea3303d5e05c9f941cc497b2ba15814c64a26\n'}, {'number': 2, 'created': '2014-08-06 17:18:35.000000000', 'files': ['elements/swift/os-apply-config/etc/swift/swift.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/34f44c6df1fa7c618728c4412b28fedfec8b4f61', 'message': 'Adds section templating to swift.conf\n\nThis patch adds section templating to swift.conf. This would\nbe needed to add any section to swift.conf via passthrough\nmechanism. This would be mainly useful to add/update storage policies\nvia passthrough mechanism.\n\nBlueprint: passthrough-config\n\nChange-Id: I4d5ea3303d5e05c9f941cc497b2ba15814c64a26\n'}]",0,112362,34f44c6df1fa7c618728c4412b28fedfec8b4f61,12,5,2,9051,,,0,"Adds section templating to swift.conf

This patch adds section templating to swift.conf. This would
be needed to add any section to swift.conf via passthrough
mechanism. This would be mainly useful to add/update storage policies
via passthrough mechanism.

Blueprint: passthrough-config

Change-Id: I4d5ea3303d5e05c9f941cc497b2ba15814c64a26
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/62/112362/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/swift/os-apply-config/etc/swift/swift.conf'],1,b7a9169e7c22624b5ccb8777d41149825071dcf5,swift-conf-template, {{#swift}} {{#config}} [{{{section}}}] {{#values}} {{#comment}} # {{{.}}} {{/comment}} {{#option}} {{{option}}}={{{value}}} {{/option}} {{/values}} {{/config}} {{/swift}},,15,0
openstack%2Fec2-api~master~I085c191d688325bc91ac846782870d18e107a368,openstack/ec2-api,master,I085c191d688325bc91ac846782870d18e107a368,Adding subnets,MERGED,2014-08-07 16:05:48.000000000,2014-08-07 17:12:26.000000000,2014-08-07 17:12:26.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-08-07 16:05:48.000000000', 'files': ['ec2api/tests/test_subnet.py', 'ec2api/api/cloud.py', 'ec2api/api/subnet.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/02013dab4650b82b1697b455cf246e6db61536f0', 'message': 'Adding subnets\n\nChange-Id: I085c191d688325bc91ac846782870d18e107a368\n'}]",0,112616,02013dab4650b82b1697b455cf246e6db61536f0,7,4,1,9312,,,0,"Adding subnets

Change-Id: I085c191d688325bc91ac846782870d18e107a368
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/16/112616/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/tests/test_subnet.py', 'ec2api/api/cloud.py', 'ec2api/api/subnet.py']",3,02013dab4650b82b1697b455cf246e6db61536f0,,"# Copyright 2014 Cloudscaling Group, Inc # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import netaddr from neutronclient.common import exceptions as neutron_exception from oslo.config import cfg from ec2api.api import clients from ec2api.api import ec2utils from ec2api.api import route_table as route_table_api from ec2api.api import utils from ec2api.db import api as db_api from ec2api import exception from ec2api.openstack.common.gettextutils import _ from ec2api.openstack.common import log as logging CONF = cfg.CONF LOG = logging.getLogger(__name__) """"""Subnet related API implementation """""" def create_subnet(context, vpc_id, cidr_block, availability_zone=None): ec2utils.validate_vpc_cidr(cidr_block, exception.InvalidSubnetRange) vpc = ec2utils.get_db_item(context, 'vpc', vpc_id) vpc_ipnet = netaddr.IPNetwork(vpc['cidr_block']) subnet_ipnet = netaddr.IPNetwork(cidr_block) if subnet_ipnet not in vpc_ipnet: raise exception.InvalidSubnetRange(cidr_block=cidr_block) # TODO(ft): # check availability zone # choose default availability zone gateway_ip = str(netaddr.IPAddress(subnet_ipnet.first + 1)) start_ip = str(netaddr.IPAddress(subnet_ipnet.first + 4)) end_ip = str(netaddr.IPAddress(subnet_ipnet.last - 1)) main_route_table = db_api.get_item_by_id(context, 'rtb', vpc['route_table_id']) host_routes = route_table_api._get_subnet_host_routes( context, main_route_table, gateway_ip) neutron = clients.neutron(context) with utils.OnCrashCleaner() as cleaner: os_network_body = {'network': {}} os_network = neutron.create_network(os_network_body)['network'] cleaner.addCleanup(neutron.delete_network, os_network['id']) os_subnet_body = {'subnet': {'network_id': os_network['id'], 'ip_version': '4', 'cidr': cidr_block, 'allocation_pools': [{'start': start_ip, 'end': end_ip}], 'host_routes': host_routes}} os_subnet = neutron.create_subnet(os_subnet_body)['subnet'] cleaner.addCleanup(neutron.delete_subnet, os_subnet['id']) neutron.add_interface_router(vpc['os_id'], {'subnet_id': os_subnet['id']}) cleaner.addCleanup(neutron.remove_interface_router, vpc['os_id'], {'subnet_id': os_subnet['id']}) # TODO(Alex): Handle errors like cidr conflict or overlimit # TODO(ft): # store availability_zone subnet = db_api.add_item(context, 'subnet', {'os_id': os_subnet['id'], 'vpc_id': vpc['id']}) cleaner.addCleanup(db_api.delete_item, context, subnet['id']) ec2_subnet_id = ec2utils.get_ec2_id(subnet['id'], 'subnet') neutron.update_network(os_network['id'], {'network': {'name': ec2_subnet_id}}) neutron.update_subnet(os_subnet['id'], {'subnet': {'name': ec2_subnet_id}}) return {'subnet': _format_subnet(context, subnet, os_subnet, os_network)} def delete_subnet(context, subnet_id): subnet = ec2utils.get_db_item(context, 'subnet', subnet_id) vpc = db_api.get_item_by_id(context, 'vpc', subnet['vpc_id']) # TODO(ft): implement search in DB layer network_interfaces = db_api.get_items(context, 'eni') if any(eni['subnet_id'] == subnet['id'] for eni in network_interfaces): msg = _(""The subnet '%(subnet_id)s' has dependencies and "" ""cannot be deleted."") % {'subnet_id': subnet_id} raise exception.DependencyViolation(msg) neutron = clients.neutron(context) with utils.OnCrashCleaner() as cleaner: db_api.delete_item(context, subnet['id']) cleaner.addCleanup(db_api.restore_item, context, 'subnet', subnet) try: if vpc is not None: neutron.remove_interface_router(vpc['os_id'], {'subnet_id': subnet['os_id']}) cleaner.addCleanup(neutron.add_interface_router, vpc['os_id'], {'subnet_id': subnet['os_id']}) os_subnet = neutron.show_subnet(subnet['os_id'])['subnet'] neutron.delete_subnet(os_subnet['id']) neutron.delete_network(os_subnet['network_id']) except neutron_exception.NeutronClientException: # TODO(ft): do log error # TODO(ft): adjust catched exception classes to catch: # the subnet is already unplugged from the router # no such router # the subnet doesn't exist # some ports exist in the subnet # the network has other not empty subnets pass return True def describe_subnets(context, subnet_id=None, filter=None): # TODO(ft): implement filters neutron = clients.neutron(context) os_subnets = neutron.list_subnets()['subnets'] os_networks = neutron.list_networks()['networks'] subnets = ec2utils.get_db_items(context, 'subnet', subnet_id) formatted_subnets = [] for subnet in subnets: os_subnet = next((s for s in os_subnets if s['id'] == subnet['os_id']), None) if not os_subnet: continue os_network = next((n for n in os_networks if n['id'] == os_subnet['network_id']), None) if os_network: formatted_subnets.append(_format_subnet( context, subnet, os_subnet, os_network)) return {'subnetSet': formatted_subnets} def _format_subnet(context, subnet, os_subnet, os_network): status_map = {'ACTIVE': 'available', 'BUILD': 'pending', 'DOWN': 'available', 'ERROR': 'available'} return { 'subnetId': ec2utils.get_ec2_id(subnet['id'], 'subnet'), 'state': status_map.get(os_network['status'], 'available'), 'vpcId': ec2utils.get_ec2_id(subnet['vpc_id'], 'vpc'), 'cidrBlock': os_subnet['cidr'], 'defaultForAz': 'false', 'mapPublicIpOnLaunch': 'false', # 'availabilityZone' = 'nova' # TODO(Alex) implement # 'availableIpAddressCount' = 20 # TODO(Alex) implement } ",,495,0
openstack%2Fnova~master~I103054b19bd4d5467e46d7e4e8f0095229275ff7,openstack/nova,master,I103054b19bd4d5467e46d7e4e8f0095229275ff7,"Revert ""Stop depending on sitepackages libvirt-python""",ABANDONED,2014-07-30 20:19:58.000000000,2014-08-07 16:48:25.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 4146}, {'_account_id': 5170}, {'_account_id': 5263}, {'_account_id': 6873}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-30 20:19:58.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/5ea1be19ebf23e4055f7ada765db57ad66b25dc9', 'message': 'Revert ""Stop depending on sitepackages libvirt-python""\n\nThis reverts commit 8f505b85268adc226ec0a83826c2d13edcbe3d7c.\n\nThis patch along with\nIbe8d2117e1246e4097d1bedeadcd6d99618f8400 broke Minesweeper along with\nseveral folks, who don\'t have a new enough libvirt. Revert the change\nbefore this causes pain for more people.\n\nConflicts:\n\ttest-requirements.txt\n\nChange-Id: I103054b19bd4d5467e46d7e4e8f0095229275ff7\n'}]",0,110773,5ea1be19ebf23e4055f7ada765db57ad66b25dc9,13,8,1,1849,,,0,"Revert ""Stop depending on sitepackages libvirt-python""

This reverts commit 8f505b85268adc226ec0a83826c2d13edcbe3d7c.

This patch along with
Ibe8d2117e1246e4097d1bedeadcd6d99618f8400 broke Minesweeper along with
several folks, who don't have a new enough libvirt. Revert the change
before this causes pain for more people.

Conflicts:
	test-requirements.txt

Change-Id: I103054b19bd4d5467e46d7e4e8f0095229275ff7
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/110773/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,5ea1be19ebf23e4055f7ada765db57ad66b25dc9,,sitepackages = Truesitepackages = Truesitepackages = Falsesitepackages = False[testenv:py27local] sitepackages = False ,,7,1
openstack%2Fironic~master~Ie5b31455b925ae395995de7b7c638ab5e3543633,openstack/ironic,master,Ie5b31455b925ae395995de7b7c638ab5e3543633,Fix self.fields on API Chassis object,MERGED,2014-08-05 16:00:41.000000000,2014-08-07 16:35:51.000000000,2014-08-07 16:35:51.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 7882}, {'_account_id': 8106}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 12356}]","[{'number': 1, 'created': '2014-08-05 16:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bf405354832c01863afe3d837f908570befa89a2', 'message': ""Fix self.fields on API Chassis object\n\nAll fields from objects.Chassis were being added to self.fields in\nthe API Chassis object. Because of this, when someone would POST,\nthere'd be an entry for {'id': None} in the dictionary passed to\ndbapi.create_chassis(). We should only set fields we're exposing.\n\nThis also required fixing PATCH to not try to look at fields not set on\nthe API Chassis object when mapping to objects.Chassis.\n\nChange-Id: Ie5b31455b925ae395995de7b7c638ab5e3543633\n""}, {'number': 2, 'created': '2014-08-06 12:50:42.000000000', 'files': ['ironic/api/controllers/v1/chassis.py', 'ironic/tests/api/v1/test_chassis.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c95bba10f530f64f17930f054ad1b877ed001a47', 'message': ""Fix self.fields on API Chassis object\n\nAll fields from objects.Chassis were being added to self.fields in\nthe API Chassis object. Because of this, when someone would POST,\nthere'd be an entry for {'id': None} in the dictionary passed to\ndbapi.create_chassis(). We should only set fields we're exposing.\n\nThis also required fixing PATCH to not try to look at fields not set on\nthe API Chassis object when mapping to objects.Chassis.\n\nChange-Id: Ie5b31455b925ae395995de7b7c638ab5e3543633\n""}]",2,112055,c95bba10f530f64f17930f054ad1b877ed001a47,23,7,2,6773,,,0,"Fix self.fields on API Chassis object

All fields from objects.Chassis were being added to self.fields in
the API Chassis object. Because of this, when someone would POST,
there'd be an entry for {'id': None} in the dictionary passed to
dbapi.create_chassis(). We should only set fields we're exposing.

This also required fixing PATCH to not try to look at fields not set on
the API Chassis object when mapping to objects.Chassis.

Change-Id: Ie5b31455b925ae395995de7b7c638ab5e3543633
",git fetch https://review.opendev.org/openstack/ironic refs/changes/55/112055/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/api/controllers/v1/chassis.py', 'ironic/tests/api/v1/test_chassis.py']",2,bf405354832c01863afe3d837f908570befa89a2,bug/1314732," def test_create_chassis_doesnt_contain_id(self): with mock.patch.object(self.dbapi, 'create_chassis', wraps=self.dbapi.create_chassis) as cc_mock: cdict = apiutils.chassis_post_data(extra={'foo': 123}) self.post_json('/chassis', cdict) result = self.get_json('/chassis/%s' % cdict['uuid']) self.assertEqual(cdict['extra'], result['extra']) cc_mock.assert_called_once_with(mock.ANY) # Check that 'id' is not in first arg of positional args self.assertNotIn('id', cc_mock.call_args[0][0]) ",,25,5
openstack%2Ftripleo-ci~master~I21ba471bf16e7541d4ed7981c989f8f544060b21,openstack/tripleo-ci,master,I21ba471bf16e7541d4ed7981c989f8f544060b21,Pull neutron fix for neutron-dhcp-agent,ABANDONED,2014-08-07 14:46:16.000000000,2014-08-07 16:18:59.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-08-07 14:46:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5191f78808ec6c1daa0bd91821d5609b5502effe', 'message': 'Pull neutron fix for neutron-dhcp-agent\n\nChange-Id: I21ba471bf16e7541d4ed7981c989f8f544060b21\nCloses-bug: 1353953\n'}, {'number': 2, 'created': '2014-08-07 14:47:37.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d97874d048b0977394516bc7ebf471b4eee45275', 'message': 'Pull neutron fix for neutron-dhcp-agent\n\nChange-Id: I21ba471bf16e7541d4ed7981c989f8f544060b21\nCloses-bug: 1353953\n'}]",0,112599,d97874d048b0977394516bc7ebf471b4eee45275,7,1,2,951,,,0,"Pull neutron fix for neutron-dhcp-agent

Change-Id: I21ba471bf16e7541d4ed7981c989f8f544060b21
Closes-bug: 1353953
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/99/112599/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,5191f78808ec6c1daa0bd91821d5609b5502effe,bug/1353953,# Cherry pick in neutron fix for bug https://bugs.launchpad.net/tripleo/+bug/1353953 loc=$(pwd) cd $DIB_REPOLOCATION_horizon git fetch https://review.openstack.org/openstack/neutron refs/changes/15/111715/3 && git cherry-pick FETCH_HEAD cd $loc ,,6,0
openstack%2Fhorizon~master~If496652ac082ad9fa2beba26bc7f6849ebf4cc14,openstack/horizon,master,If496652ac082ad9fa2beba26bc7f6849ebf4cc14,Fix 'Associate' and 'Disassociate Monitor' actions,MERGED,2014-08-07 10:04:40.000000000,2014-08-07 16:09:19.000000000,2014-08-07 16:09:19.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 9576}]","[{'number': 1, 'created': '2014-08-07 10:04:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/900acb7dffafaaf0d226c31e6eaf62b4f89eef4f', 'message': ""Fix 'Associate' and 'Disassociate Monitor' actions\n\nSince context['pool_monitors']] is not a list of monitors' ids anymore,\nlists of possible monitors choices were broken. Now 'Associate Monitor'\nand 'Disassociate Monitor' forms show proper health monitors lists for\nassociating/disaccociating.\n\nCloses-Bug: #1351572\nChange-Id: If496652ac082ad9fa2beba26bc7f6849ebf4cc14\n""}, {'number': 2, 'created': '2014-08-07 10:07:04.000000000', 'files': ['openstack_dashboard/dashboards/project/loadbalancers/tests.py', 'openstack_dashboard/dashboards/project/loadbalancers/workflows.py', 'openstack_dashboard/test/test_data/neutron_data.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/8ea670692678031a32eac1f39ca5a2e80c3c8561', 'message': ""Fix 'Associate' and 'Disassociate Monitor' actions\n\nSince context['pool_monitors'] is not a list of monitors' ids anymore,\nlists of possible monitors choices were broken. Now 'Associate Monitor'\nand 'Disassociate Monitor' forms show proper health monitors lists for\nassociating/disaccociating.\n\nCloses-Bug: #1351572\nChange-Id: If496652ac082ad9fa2beba26bc7f6849ebf4cc14\n""}]",0,112540,8ea670692678031a32eac1f39ca5a2e80c3c8561,11,4,2,6914,,,0,"Fix 'Associate' and 'Disassociate Monitor' actions

Since context['pool_monitors'] is not a list of monitors' ids anymore,
lists of possible monitors choices were broken. Now 'Associate Monitor'
and 'Disassociate Monitor' forms show proper health monitors lists for
associating/disaccociating.

Closes-Bug: #1351572
Change-Id: If496652ac082ad9fa2beba26bc7f6849ebf4cc14
",git fetch https://review.opendev.org/openstack/horizon refs/changes/40/112540/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/loadbalancers/tests.py', 'openstack_dashboard/dashboards/project/loadbalancers/workflows.py', 'openstack_dashboard/test/test_data/neutron_data.py']",3,900acb7dffafaaf0d226c31e6eaf62b4f89eef4f,bug/1351572," 'health_monitors': TEST.monitors.list(), 'health_monitors': TEST.monitors.list()[0:1],"," 'health_monitors': ['d4a0500f-db2b-4cc4-afcf-ec026febff96'], 'health_monitors': ['d4a0500f-db2b-4cc4-afcf-ec026febff97'],",7,5
openstack%2Ftooz~master~Iccbc1da162e70d0186131adc0ac9cfeb20f7a647,openstack/tooz,master,Iccbc1da162e70d0186131adc0ac9cfeb20f7a647,coordination: add IPC driver,MERGED,2014-07-31 12:21:21.000000000,2014-08-07 16:08:05.000000000,2014-08-07 16:08:05.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 7450}, {'_account_id': 8122}, {'_account_id': 9107}]","[{'number': 1, 'created': '2014-07-31 12:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/8970045462751c5a495661d637d8f56c41ea4e19', 'message': 'coordination: add IPC driver\n\nFor now it only supports locking.\n\nChange-Id: Iccbc1da162e70d0186131adc0ac9cfeb20f7a647\n'}, {'number': 2, 'created': '2014-07-31 13:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/3d5c4102e32702a7278b18e65e7fd9b22cf413ed', 'message': 'coordination: add IPC driver\n\nFor now it only supports locking.\n\nChange-Id: Iccbc1da162e70d0186131adc0ac9cfeb20f7a647\n'}, {'number': 3, 'created': '2014-07-31 13:44:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/93ca349574788ff0e626b84e0d02f70d383e64d9', 'message': 'coordination: add IPC driver\n\nFor now it only supports locking.\n\nChange-Id: Iccbc1da162e70d0186131adc0ac9cfeb20f7a647\n'}, {'number': 4, 'created': '2014-08-04 13:03:26.000000000', 'files': ['tooz/openstack/common/strutils.py', 'tooz/openstack/common/lockutils.py', 'tooz/openstack/common/__init__.py', 'tooz/drivers/ipc.py', 'tooz/openstack/common/timeutils.py', 'tooz/openstack/common/gettextutils.py', 'tooz/openstack/common/importutils.py', 'tooz/tests/test_coordination.py', 'requirements.txt', 'doc/source/drivers.rst', 'tooz/openstack/common/local.py', 'tooz/openstack/common/jsonutils.py', 'tooz/openstack/__init__.py', 'tooz/openstack/common/log.py', 'openstack-common.conf', 'setup.cfg', 'tooz/openstack/common/excutils.py', 'tox.ini', 'tooz/openstack/common/fileutils.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/f3e11e40f9871f8328e107bf1390c532fbe3a54b', 'message': 'coordination: add IPC driver\n\nFor now it only supports locking.\n\nChange-Id: Iccbc1da162e70d0186131adc0ac9cfeb20f7a647\n'}]",0,110936,f3e11e40f9871f8328e107bf1390c532fbe3a54b,20,7,4,1669,,,0,"coordination: add IPC driver

For now it only supports locking.

Change-Id: Iccbc1da162e70d0186131adc0ac9cfeb20f7a647
",git fetch https://review.opendev.org/openstack/tooz refs/changes/36/110936/2 && git format-patch -1 --stdout FETCH_HEAD,"['tooz/openstack/common/strutils.py', 'tooz/openstack/common/lockutils.py', 'tooz/openstack/common/__init__.py', 'tooz/drivers/ipc.py', 'tooz/openstack/common/timeutils.py', 'tooz/openstack/common/gettextutils.py', 'tooz/openstack/common/importutils.py', 'tooz/tests/test_coordination.py', 'requirements.txt', 'tooz/openstack/common/local.py', 'tooz/openstack/common/jsonutils.py', 'tooz/openstack/__init__.py', 'tooz/openstack/common/log.py', 'openstack-common.conf', 'setup.cfg', 'tooz/openstack/common/excutils.py', 'tox.ini', 'tooz/openstack/common/fileutils.py']",18,8970045462751c5a495661d637d8f56c41ea4e19,jd/ipc,"# Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import contextlib import errno import os import tempfile from tooz.openstack.common import excutils from tooz.openstack.common import log as logging LOG = logging.getLogger(__name__) _FILE_CACHE = {} def ensure_tree(path): """"""Create a directory (and any ancestor directories required) :param path: Directory to create """""" try: os.makedirs(path) except OSError as exc: if exc.errno == errno.EEXIST: if not os.path.isdir(path): raise else: raise def read_cached_file(filename, force_reload=False): """"""Read from a file if it has been modified. :param force_reload: Whether to reload the file. :returns: A tuple with a boolean specifying if the data is fresh or not. """""" global _FILE_CACHE if force_reload: delete_cached_file(filename) reloaded = False mtime = os.path.getmtime(filename) cache_info = _FILE_CACHE.setdefault(filename, {}) if not cache_info or mtime > cache_info.get('mtime', 0): LOG.debug(""Reloading cached file %s"" % filename) with open(filename) as fap: cache_info['data'] = fap.read() cache_info['mtime'] = mtime reloaded = True return (reloaded, cache_info['data']) def delete_cached_file(filename): """"""Delete cached file if present. :param filename: filename to delete """""" global _FILE_CACHE if filename in _FILE_CACHE: del _FILE_CACHE[filename] def delete_if_exists(path, remove=os.unlink): """"""Delete a file, but ignore file not found error. :param path: File to delete :param remove: Optional function to remove passed path """""" try: remove(path) except OSError as e: if e.errno != errno.ENOENT: raise @contextlib.contextmanager def remove_path_on_error(path, remove=delete_if_exists): """"""Protect code that wants to operate on PATH atomically. Any exception will cause PATH to be removed. :param path: File to work with :param remove: Optional function to remove passed path """""" try: yield except Exception: with excutils.save_and_reraise_exception(): remove(path) def file_open(*args, **kwargs): """"""Open file see built-in open() documentation for more details Note: The reason this is kept in a separate module is to easily be able to provide a stub module that doesn't alter system state at all (for unit tests) """""" return open(*args, **kwargs) def write_to_tempfile(content, path=None, suffix='', prefix='tmp'): """"""Create temporary file or use existing file. This util is needed for creating temporary file with specified content, suffix and prefix. If path is not None, it will be used for writing content. If the path doesn't exist it'll be created. :param content: content for temporary file. :param path: same as parameter 'dir' for mkstemp :param suffix: same as parameter 'suffix' for mkstemp :param prefix: same as parameter 'prefix' for mkstemp For example: it can be used in database tests for creating configuration files. """""" if path: ensure_tree(path) (fd, path) = tempfile.mkstemp(suffix=suffix, dir=path, prefix=prefix) try: os.write(fd, content) finally: os.close(fd) return path ",,2749,1
openstack%2Fopenstacksdk~master~I8fe094f62f4373d2dd32fa4cf86e9b89c4c363ca,openstack/openstacksdk,master,I8fe094f62f4373d2dd32fa4cf86e9b89c4c363ca,network/v2 load balancer pool resource,MERGED,2014-07-31 20:46:53.000000000,2014-08-07 16:04:39.000000000,2014-08-07 16:04:38.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-07-31 20:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/583087ae5befa40e081c0c07125f4a534cf2504e', 'message': 'network/v2 pool resource\n\nChange-Id: I8fe094f62f4373d2dd32fa4cf86e9b89c4c363ca\n'}, {'number': 2, 'created': '2014-07-31 20:47:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/1cfca6b98f1ab85e91308daf8015816b647184c1', 'message': 'network/v2 load balancer pool resource\n\nChange-Id: I8fe094f62f4373d2dd32fa4cf86e9b89c4c363ca\n'}, {'number': 3, 'created': '2014-08-05 10:49:39.000000000', 'files': ['openstack/network/v2/pool.py', 'openstack/tests/network/v2/test_pool.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a8e05de08fae318971afccef2390c944c2289dc7', 'message': 'network/v2 load balancer pool resource\n\nChange-Id: I8fe094f62f4373d2dd32fa4cf86e9b89c4c363ca\n'}]",0,111081,a8e05de08fae318971afccef2390c944c2289dc7,18,3,3,8736,,,0,"network/v2 load balancer pool resource

Change-Id: I8fe094f62f4373d2dd32fa4cf86e9b89c4c363ca
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/81/111081/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/network/v2/pool.py', 'openstack/tests/network/v2/test_pool.py']",2,583087ae5befa40e081c0c07125f4a534cf2504e,pool,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import testtools from openstack.network.v2 import pool IDENTIFIER = 'IDENTIFIER' EXAMPLE = { 'admin_state_up': True, 'description': '2', 'healthmonitor_id': '3', 'id': IDENTIFIER, 'lb_algorithm': '5', 'members': '6', 'name': '7', 'tenant_id': '8', 'protocol': '9', 'session_persistence': '10', 'status': '11', } class TestPool(testtools.TestCase): def test_basic(self): sot = pool.Pool() self.assertEqual('pool', sot.resource_key) self.assertEqual('pools', sot.resources_key) self.assertEqual('/v2.0/pools', sot.base_path) self.assertEqual('network', sot.service.service_type) self.assertTrue(sot.allow_create) self.assertTrue(sot.allow_retrieve) self.assertTrue(sot.allow_update) self.assertTrue(sot.allow_delete) self.assertTrue(sot.allow_list) def test_make_it(self): sot = pool.Pool(EXAMPLE) self.assertEqual(EXAMPLE['admin_state_up'], sot.admin_state_up) self.assertEqual(EXAMPLE['description'], sot.description) self.assertEqual(EXAMPLE['healthmonitor_id'], sot.healthmonitor_id) self.assertEqual(EXAMPLE['id'], sot.id) self.assertEqual(EXAMPLE['lb_algorithm'], sot.lb_algorithm) self.assertEqual(EXAMPLE['members'], sot.members) self.assertEqual(EXAMPLE['name'], sot.name) self.assertEqual(EXAMPLE['tenant_id'], sot.project_id) self.assertEqual(EXAMPLE['protocol'], sot.protocol) self.assertEqual(EXAMPLE['session_persistence'], sot.session_persistence) self.assertEqual(EXAMPLE['status'], sot.status) ",,100,0
openstack%2Fhorizon~master~I11d1ce35794f2c6cfebafe5211ab8d880c4a826c,openstack/horizon,master,I11d1ce35794f2c6cfebafe5211ab8d880c4a826c,Re-raise exception using six,MERGED,2014-07-17 14:05:51.000000000,2014-08-07 15:55:29.000000000,2014-08-07 15:55:28.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2424}, {'_account_id': 2455}, {'_account_id': 8871}, {'_account_id': 9576}]","[{'number': 1, 'created': '2014-07-17 14:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2780dacfd4b08bf383e6db16b55fdb5d8f3f1420', 'message': 'Re-raise exception in a compatible way with python 3\n\nThis patch re-raise exception creating an Exception object and attaching\nthe traceback to it. This approach is compatible with python 2 and 3.\n\nChange-Id: I11d1ce35794f2c6cfebafe5211ab8d880c4a826c\n'}, {'number': 2, 'created': '2014-07-17 15:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/da556abc9ab1454d1d748026080000cfb2d2173a', 'message': 'Re-raise exception using six\n\nUsing six.reraise() to re-raise an exception makes it compatible with\nPython 2 and 3\n\nChange-Id: I11d1ce35794f2c6cfebafe5211ab8d880c4a826c\n'}, {'number': 3, 'created': '2014-07-17 15:30:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f722b17dc6b78d17f3c81c9e81293605f5c661ca', 'message': 'Re-raise exception using six\n\nUsing six.reraise() to re-raise an exception makes it compatible with\nPython 2 and 3\n\nChange-Id: I11d1ce35794f2c6cfebafe5211ab8d880c4a826c\n'}, {'number': 4, 'created': '2014-08-04 21:42:20.000000000', 'files': ['horizon/tabs/base.py', 'horizon/exceptions.py', 'horizon/tables/base.py', 'horizon/tables/formset.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/54527fd84f9ee7c488f37c45d98d106149830436', 'message': 'Re-raise exception using six\n\nUsing six.reraise() to re-raise an exception makes it compatible with\nPython 2 and 3\n\nCloses-Bug: 1351973\nChange-Id: I11d1ce35794f2c6cfebafe5211ab8d880c4a826c\n'}]",0,107713,54527fd84f9ee7c488f37c45d98d106149830436,32,6,4,2424,,,0,"Re-raise exception using six

Using six.reraise() to re-raise an exception makes it compatible with
Python 2 and 3

Closes-Bug: 1351973
Change-Id: I11d1ce35794f2c6cfebafe5211ab8d880c4a826c
",git fetch https://review.opendev.org/openstack/horizon refs/changes/13/107713/4 && git format-patch -1 --stdout FETCH_HEAD,['horizon/exceptions.py'],1,2780dacfd4b08bf383e6db16b55fdb5d8f3f1420,bug/1351973, e = exc_type(exc_value) e.__traceback__ = exc_traceback raise e," raise exc_type, exc_value, exc_traceback",4,1
openstack%2Fceilometer~master~I8e6f6040ad9865ed5e57a2462a4d2eb5ad56e11c,openstack/ceilometer,master,I8e6f6040ad9865ed5e57a2462a4d2eb5ad56e11c,Update documentation for new transformer,MERGED,2014-07-25 13:47:58.000000000,2014-08-07 15:50:26.000000000,2014-08-07 15:50:26.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6924}, {'_account_id': 7478}, {'_account_id': 7585}, {'_account_id': 7729}, {'_account_id': 8052}, {'_account_id': 10987}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-07-25 13:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e65534e5079513bc1a7cf5ddaaa95c080bd31ce3', 'message': 'Update documentation for new transformer\n\nThis patch adds documentation for the new multi-meter arithmetic\ntransformer.\n\nChange-Id: I8e6f6040ad9865ed5e57a2462a4d2eb5ad56e11c\nCloses-Bug: #1346883\n'}, {'number': 2, 'created': '2014-08-01 09:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a24d227d3e1f3b64ea570f937661eae9e4c9a7ea', 'message': 'Update documentation for new transformer\n\nThis patch adds documentation for the new multi-meter arithmetic\ntransformer.\n\nChange-Id: I8e6f6040ad9865ed5e57a2462a4d2eb5ad56e11c\nCloses-Bug: #1346883\n'}, {'number': 3, 'created': '2014-08-04 14:53:41.000000000', 'files': ['doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/06d6864c0a4bab2ae8b1d83b15cd9504fc410c5d', 'message': 'Update documentation for new transformer\n\nThis patch adds documentation for the new multi-meter arithmetic\ntransformer.\n\nChange-Id: I8e6f6040ad9865ed5e57a2462a4d2eb5ad56e11c\nCloses-Bug: #1346883\n'}]",4,109579,06d6864c0a4bab2ae8b1d83b15cd9504fc410c5d,42,11,3,8052,,,0,"Update documentation for new transformer

This patch adds documentation for the new multi-meter arithmetic
transformer.

Change-Id: I8e6f6040ad9865ed5e57a2462a4d2eb5ad56e11c
Closes-Bug: #1346883
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/79/109579/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration.rst'],1,e65534e5079513bc1a7cf5ddaaa95c080bd31ce3,arithmetic-documentation,"Multi meter arithmetic transformer ++++++++++++++++++++++++++++++++++ This transformer enables us to perform arithmetic calculations over one more meters and/or their metadata, for example: memory_util = 100 * memory.usage / memory . .. note:: The calculation is limited to meters with the same interval. Example configuration:: transformers: - name: ""arithmetic"" parameters: target: name: ""memory_util"" unit: ""%"" type: ""gauge"" expr: ""100 * $(memory.usage) / $(memory)"" To demonstrate the use of metadata, here is the implementation of a silly metric that shows average CPU time per core:: transformers: - name: ""arithmetic"" parameters: target: name: ""avg_cpu_per_core"" unit: ""ns"" type: ""cumulative"" expr: ""$(cpu) / ($(cpu).resource_metadata.cpu_number or 1)"" Expression evaluation gracefully handles NaNs and exceptions. In such a case it does not create a new sample but only logs a warning.",,36,0
openstack%2Fec2-api~master~Ie910145a2fc215de9afd4237850ca5d7e17522ba,openstack/ec2-api,master,Ie910145a2fc215de9afd4237850ca5d7e17522ba,Adding internet gateways,MERGED,2014-08-07 14:32:05.000000000,2014-08-07 15:39:26.000000000,2014-08-07 15:39:26.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-08-07 14:32:05.000000000', 'files': ['ec2api/tests/test_internet_gateway.py', 'ec2api/api/cloud.py', 'ec2api/api/internet_gateway.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/13eb13b0b913423558b4c4df63280cdb19035280', 'message': 'Adding internet gateways\n\nChange-Id: Ie910145a2fc215de9afd4237850ca5d7e17522ba\n'}]",0,112592,13eb13b0b913423558b4c4df63280cdb19035280,7,4,1,9312,,,0,"Adding internet gateways

Change-Id: Ie910145a2fc215de9afd4237850ca5d7e17522ba
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/92/112592/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/tests/test_internet_gateway.py', 'ec2api/api/cloud.py', 'ec2api/api/internet_gateway.py']",3,13eb13b0b913423558b4c4df63280cdb19035280,,"# Copyright 2014 Cloudscaling Group, Inc # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Cloud Controller: Implementation of EC2 REST API calls, which are dispatched to other nodes via AMQP RPC. State is via distributed datastore. """""" from neutronclient.common import exceptions as neutron_exception from oslo.config import cfg from ec2api.api import clients from ec2api.api import ec2utils from ec2api.api import utils from ec2api.db import api as db_api from ec2api import exception from ec2api.openstack.common.gettextutils import _ from ec2api.openstack.common import log as logging LOG = logging.getLogger(__name__) ec2_opts = [ cfg.StrOpt('external_network', default=None, help='Name of the external network, which is used to connect' 'VPCs to Internet and to allocate Elastic IPs'), ] CONF = cfg.CONF CONF.register_opts(ec2_opts) """"""Internet gateway related API implementation """""" def create_internet_gateway(context): igw = db_api.add_item(context, 'igw', {}) return {'internet_gateway': _format_internet_gateway(igw)} def attach_internet_gateway(context, internet_gateway_id, vpc_id): igw = ec2utils.get_db_item(context, 'igw', internet_gateway_id) if igw.get('vpc_id'): msg_params = {'igw_id': ec2utils.get_ec2_id(igw['id'], 'igw'), 'vpc_id': ec2utils.get_ec2_id(igw['vpc_id'], 'vpc')} msg = _(""resource %(igw_id)s is already attached to "" ""network %(vpc_id)s"") % msg_params raise exception.ResourceAlreadyAssociated(msg) vpc = ec2utils.get_db_item(context, 'vpc', vpc_id) # TODO(ft): move search by vpc_id to DB api for gw in db_api.get_items(context, 'igw'): if gw.get('vpc_id') == vpc['id']: msg_params = {'vpc_id': ec2utils.get_ec2_id(vpc['id'], 'vpc')} msg = _(""Network %(vpc_id)s already has an internet gateway "" ""attached"") % msg_params raise exception.InvalidParameterValue(msg) neutron = clients.neutron(context) # TODO(ft): check no public network exists search_opts = {'router:external': True, 'name': CONF.external_network} os_networks = neutron.list_networks(**search_opts)['networks'] os_public_network = os_networks[0] # TODO(ft): # set attaching state in db with utils.OnCrashCleaner() as cleaner: _attach_internet_gateway_item(context, igw, vpc['id']) cleaner.addCleanup(_detach_internet_gateway_item, context, igw) neutron.add_gateway_router(vpc['os_id'], {'network_id': os_public_network['id']}) return True def detach_internet_gateway(context, internet_gateway_id, vpc_id): igw = ec2utils.get_db_item(context, 'igw', internet_gateway_id) vpc = ec2utils.get_db_item(context, 'vpc', vpc_id) if igw.get('vpc_id') != vpc['id']: raise exception.GatewayNotAttached(igw_id=igw['id'], vpc_id=vpc['id']) neutron = clients.neutron(context) # TODO(ft): # set detaching state in db with utils.OnCrashCleaner() as cleaner: _detach_internet_gateway_item(context, igw) cleaner.addCleanup(_attach_internet_gateway_item, context, igw, vpc['id']) try: neutron.remove_gateway_router(vpc[""os_id""]) except neutron_exception.NotFound: # TODO(ft): do log error # TODO(ft): adjust catched exception classes to catch: # the router doesn't exist pass return True def delete_internet_gateway(context, internet_gateway_id): igw = ec2utils.get_db_item(context, 'igw', internet_gateway_id) if igw.get('vpc_id'): msg_params = {'igw_id': ec2utils.get_ec2_id(igw['id'], 'igw')} msg = _(""The internetGateway '%(igw_id)s' has dependencies and "" ""cannot be deleted."") % msg_params raise exception.DependencyViolation(msg) db_api.delete_item(context, igw['id']) return True def describe_internet_gateways(context, internet_gateway_id=None, filter=None): # TODO(ft): implement filters igws = ec2utils.get_db_items(context, 'igw', internet_gateway_id) formatted_igws = [] for igw in igws: formatted_igws.append(_format_internet_gateway(igw)) return {'internetGatewaySet': formatted_igws} def _format_internet_gateway(igw): ec2_igw = {'internetGatewayId': ec2utils.get_ec2_id(igw['id'], 'igw'), 'attachmentSet': []} if igw.get('vpc_id'): attachment = {'vpcId': ec2utils.get_ec2_id(igw['vpc_id'], 'vpc'), 'state': 'available'} ec2_igw['attachmentSet'].append(attachment) return ec2_igw def _attach_internet_gateway_item(context, igw, vpc_id): igw['vpc_id'] = vpc_id db_api.update_item(context, igw) def _detach_internet_gateway_item(context, igw): igw['vpc_id'] = None db_api.update_item(context, igw) ",,516,0
openstack%2Fbarbican~master~Ifc75213edf20f99448d17304454f12e053f5e947,openstack/barbican,master,Ifc75213edf20f99448d17304454f12e053f5e947,Add abililty to wrap secrets for storage and retrieval,ABANDONED,2014-05-10 02:57:56.000000000,2014-08-07 15:35:37.000000000,,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 2218}, {'_account_id': 7136}, {'_account_id': 7191}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9098}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 11008}]","[{'number': 1, 'created': '2014-05-10 02:57:56.000000000', 'files': ['barbican/crypto/dogtag_crypto.py', 'barbican/crypto/plugin.py', 'barbican/common/validators.py', 'barbican/tests/crypto/test_dogtag_crypto.py', 'barbican/api/resources.py', 'barbican/crypto/extension_manager.py', 'barbican/common/resources.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/54f7a254c86491c416132a367f564b754f8a5904', 'message': 'Add abililty to wrap secrets for storage and retrieval\n\nThis patch adds the parameters to specify whether the payload\nis encrypted with a wrapping key for secret archival, and parameters\nto specify a wrapping key on retrieval.  We also provide an\ninterface to retrieve a wrapping key for transport.\n\nIn the Dogtag case, we expect to receive a PKIArchiveOptions\nstructure when archiving, and a session key wrapped with the DRM\ntransport key on retrieval.  The WrappingKey interface returns the\nbase 64 encoded DRM transport certificate.\n\nChange-Id: Ifc75213edf20f99448d17304454f12e053f5e947\nImplements: add-wrapping-key-to-barbican-server\n'}]",2,93165,54f7a254c86491c416132a367f564b754f8a5904,10,12,1,9914,,,0,"Add abililty to wrap secrets for storage and retrieval

This patch adds the parameters to specify whether the payload
is encrypted with a wrapping key for secret archival, and parameters
to specify a wrapping key on retrieval.  We also provide an
interface to retrieve a wrapping key for transport.

In the Dogtag case, we expect to receive a PKIArchiveOptions
structure when archiving, and a session key wrapped with the DRM
transport key on retrieval.  The WrappingKey interface returns the
base 64 encoded DRM transport certificate.

Change-Id: Ifc75213edf20f99448d17304454f12e053f5e947
Implements: add-wrapping-key-to-barbican-server
",git fetch https://review.opendev.org/openstack/barbican refs/changes/65/93165/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/crypto/dogtag_crypto.py', 'barbican/crypto/plugin.py', 'barbican/common/validators.py', 'barbican/tests/crypto/test_dogtag_crypto.py', 'barbican/api/resources.py', 'barbican/crypto/extension_manager.py', 'barbican/common/resources.py']",7,54f7a254c86491c416132a367f564b754f8a5904,alee_wrapping_1," encrypted = data.get('encrypted') == 'true' enforce_text_only=True, encrypted=encrypted) tenant, crypto_manager, datum_repo, kek_repo, encrypted=False): :param encrypted: set to True if payload consists of encrypted data kek_repo, encrypted=False)"," enforce_text_only=True) tenant, crypto_manager, datum_repo, kek_repo): kek_repo)",133,26
openstack%2Fhorizon~master~Id6e3f3b3f8e354ce077a8f05f2bd5029b7fa9628,openstack/horizon,master,Id6e3f3b3f8e354ce077a8f05f2bd5029b7fa9628,"Automatically discover ""Image Format"" based on file extension",MERGED,2014-06-10 09:59:16.000000000,2014-08-07 15:24:09.000000000,2014-08-07 15:24:09.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2455}, {'_account_id': 10112}, {'_account_id': 10657}]","[{'number': 1, 'created': '2014-06-10 09:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f8da68b3f05c5090d6da85aea9f3365ca9843282', 'message': 'Automatically discover ""Image Format"" based on image file extension\n\nThis commit can automatically prepopulate the ""Format"" field in\nthe ""Create Image"" modal after the user has filled out the ""Image\nSource"" or ""Image File"" fields. This can be done based on the file\nextension and save the user from filling out one additional field\nin this modal.\n\nChange-Id: Id6e3f3b3f8e354ce077a8f05f2bd5029b7fa9628\nCloses-Bug: #1324192\n'}, {'number': 2, 'created': '2014-06-16 07:45:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3567769a241f8db0f2c5aa45fe9fd4562cebc714', 'message': 'Automatically discover ""Image Format"" based on image file extension\n\nThis commit can automatically pre-populate the ""Format"" field in\nthe ""Create Image"" modal after the user has filled out the ""Image\nSource"" or ""Image File"" fields. This can be done based on the file\nextension and save the user from filling out one additional field\nin this modal.\n\nChange-Id: Id6e3f3b3f8e354ce077a8f05f2bd5029b7fa9628\nCloses-Bug: #1324192\n'}, {'number': 3, 'created': '2014-06-17 03:42:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/dbfe32577f121644f02bb9fa7fe6563075850b68', 'message': 'Automatically discover ""Image Format"" based on image file extension\n\nThis commit can automatically pre-populate the ""Format"" field in\nthe ""Create Image"" modal after the user has filled out the ""Image\nSource"" or ""Image File"" fields. This can be done based on the file\nextension and save the user from filling out one additional field\nin this modal.\n\nChange-Id: Id6e3f3b3f8e354ce077a8f05f2bd5029b7fa9628\nCloses-Bug: #1324192\n'}, {'number': 4, 'created': '2014-06-18 03:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6489e0df3402618699d9526df9cdff87947ab259', 'message': 'Automatically discover ""Image Format"" based on image file extension\n\nThis commit can automatically pre-populate the ""Format"" field in\nthe ""Create Image"" modal after the user has filled out the ""Image\nSource"" or ""Image File"" fields. This can be done based on the file\nextension and save the user from filling out one additional field\nin this modal.\n\nChange-Id: Id6e3f3b3f8e354ce077a8f05f2bd5029b7fa9628\nCloses-Bug: #1324192\n'}, {'number': 5, 'created': '2014-08-04 08:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a1adda901929fe8d41b34d898ba07671e62ddac0', 'message': 'Automatically discover ""Image Format"" based on image file extension\n\nThis commit can automatically pre-populate the ""Format"" field in\nthe ""Create Image"" modal after the user has filled out the ""Image\nSource"" or ""Image File"" fields. This can be done based on the file\nextension and save the user from filling out one additional field\nin this modal.\n\nChange-Id: Id6e3f3b3f8e354ce077a8f05f2bd5029b7fa9628\nCloses-Bug: #1324192\n'}, {'number': 6, 'created': '2014-08-04 09:52:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0fbc215a33ce0d14e08737d1f1b034ba00665c28', 'message': 'Automatically discover ""Image Format"" based on file extension\n\nThis commit can automatically pre-populate the ""Format"" field in\nthe ""Create Image"" modal after the user has filled out the ""Image\nSource"" or ""Image File"" fields. This can be done based on the file\nextension and save the user from filling out one additional field\nin this modal.\n\nChange-Id: Id6e3f3b3f8e354ce077a8f05f2bd5029b7fa9628\nCloses-Bug: #1324192\n'}, {'number': 7, 'created': '2014-08-07 07:37:17.000000000', 'files': ['horizon/static/horizon/js/horizon.images.js', 'openstack_dashboard/dashboards/project/images/templates/images/images/_create.html', 'horizon/templates/horizon/_scripts.html', 'openstack_dashboard/dashboards/project/images/images/forms.py', 'openstack_dashboard/dashboards/project/images/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/c16baae8fb66b50347c68aee6d3dab6cf8a4ede4', 'message': 'Automatically discover ""Image Format"" based on file extension\n\nThis commit can automatically pre-populate the ""Format"" field in\nthe ""Create Image"" modal after the user has filled out the ""Image\nSource"" or ""Image File"" fields. This can be done based on the file\nextension and save the user from filling out one additional field\nin this modal.\n\nChange-Id: Id6e3f3b3f8e354ce077a8f05f2bd5029b7fa9628\nCloses-Bug: #1324192\n'}]",6,98995,c16baae8fb66b50347c68aee6d3dab6cf8a4ede4,36,5,7,10657,,,0,"Automatically discover ""Image Format"" based on file extension

This commit can automatically pre-populate the ""Format"" field in
the ""Create Image"" modal after the user has filled out the ""Image
Source"" or ""Image File"" fields. This can be done based on the file
extension and save the user from filling out one additional field
in this modal.

Change-Id: Id6e3f3b3f8e354ce077a8f05f2bd5029b7fa9628
Closes-Bug: #1324192
",git fetch https://review.opendev.org/openstack/horizon refs/changes/95/98995/5 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/horizon/js/horizon.images.js', 'horizon/templates/horizon/_scripts.html']",2,f8da68b3f05c5090d6da85aea9f3365ca9843282,bug/1324192,<script src='{{ STATIC_URL }}horizon/js/horizon.images.js' type='text/javascript' charset='utf-8'></script>,,17,0
openstack%2Ftripleo-image-elements~master~I1cda87e980522f6c668debcf85668bb631d070b3,openstack/tripleo-image-elements,master,I1cda87e980522f6c668debcf85668bb631d070b3,Compile and install custom SELinux policies,MERGED,2014-07-15 00:35:42.000000000,2014-08-07 15:09:15.000000000,2014-08-07 15:09:15.000000000,"[{'_account_id': 3}, {'_account_id': 7144}, {'_account_id': 7471}, {'_account_id': 7582}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-07-15 00:35:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a70897b0321f16ef7a88a588abe7194c38fa10a8', 'message': 'WIP: Compile and install custom SELinux policies\n\nProvides a way to compile and install custom SELinux policies\nto images. Custom policies are placed in a custom-policies\ndirectory. An install.d script will read policy source files from\nthat directory, compile them, and load them into the image.\n\nWhen SElinux is in enforcing mode in the ci, you would need to\ncreate a custom SELinux policy to temporarily fix an upstream\nissue to allow ci to pass before that issue has been fixed in the\nupstream SELinux policy.\n\nChange-Id: I1cda87e980522f6c668debcf85668bb631d070b3\n'}, {'number': 2, 'created': '2014-07-16 05:18:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/7806da19735230054d64e11ab49e6cab729d0a5c', 'message': 'Compile and install custom SELinux policies\n\nProvides a way to compile and install custom SELinux policies\nto images. Custom policies are placed in a custom-policies\ndirectory. An install.d script will read policy source files from\nthat directory, compile them, and load them into the image.\n\nWhen SElinux is in enforcing mode in the ci, you would need to\ncreate a custom SELinux policy to temporarily fix an upstream\nissue to allow ci to pass before that issue has been fixed in the\nupstream SELinux policy.\n\nChange-Id: I1cda87e980522f6c668debcf85668bb631d070b3\n'}, {'number': 3, 'created': '2014-07-16 05:19:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/dc22f6ef77d9361e84f868ab3f525acd784c3bd2', 'message': 'WIP: Compile and install custom SELinux policies\n\nProvides a way to compile and install custom SELinux policies\nto images. Custom policies are placed in a custom-policies\ndirectory. An install.d script will read policy source files from\nthat directory, compile them, and load them into the image.\n\nWhen SElinux is in enforcing mode in the ci, you would need to\ncreate a custom SELinux policy to temporarily fix an upstream\nissue to allow ci to pass before that issue has been fixed in the\nupstream SELinux policy.\n\nChange-Id: I1cda87e980522f6c668debcf85668bb631d070b3\n'}, {'number': 4, 'created': '2014-07-30 17:23:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ef3e46e26af6c774277fce55fa219ef48bbd0588', 'message': 'Compile and install custom SELinux policies\n\nProvides a way to compile and install custom SELinux policies\nto images. Custom policies are placed in a custom-policies\ndirectory. An install.d script will read policy source files from\nthat directory, compile them, and load them into the image.\n\nWhen SElinux is in enforcing mode in the ci, you would need to\ncreate a custom SELinux policy to temporarily fix an upstream\nissue to allow ci to pass before that issue has been fixed in the\nupstream SELinux policy.\n\nChange-Id: I1cda87e980522f6c668debcf85668bb631d070b3\n'}, {'number': 5, 'created': '2014-07-30 18:14:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f7231f061519742530e5e8578f4d0c83d970fe4b', 'message': 'Compile and install custom SELinux policies\n\nProvides a way to compile and install custom SELinux policies\nto images. Custom policies are placed in a custom-policies\ndirectory. An install.d script will read policy source files from\nthat directory, compile them, and load them into the image.\n\nWhen SElinux is in enforcing mode in the ci, you would need to\ncreate a custom SELinux policy to temporarily fix an upstream\nissue to allow ci to pass before that issue has been fixed in the\nupstream SELinux policy.\n\nChange-Id: I1cda87e980522f6c668debcf85668bb631d070b3\n'}, {'number': 6, 'created': '2014-07-31 00:15:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a0b891c24fb439caeffb072eb9a385df0b544d84', 'message': 'Compile and install custom SELinux policies\n\nProvides a way to compile and install custom SELinux policies\nto images. Custom policies are placed in a custom-policies\ndirectory. An install.d script will copy the files to\n/opt/stack/selinux-policy. When an instance boots, an o-r-c\nscript will compile the policy source files in that directory\nand then load them.\n\nWhen SElinux is in enforcing mode in the ci, you would need to\ncreate a custom SELinux policy to temporarily fix an upstream\nissue to allow ci to pass before that issue has been fixed in the\nupstream SELinux policy.\n\nChange-Id: I1cda87e980522f6c668debcf85668bb631d070b3\n'}, {'number': 7, 'created': '2014-07-31 16:28:33.000000000', 'files': ['elements/selinux/install.d/100-install-custom-selinux-policies', 'elements/selinux/os-refresh-config/configure.d/20-compile-and-install-selinux-policies'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/43e2b577b8a3d716d1b16eb17dbf7fc7e887de5b', 'message': 'Compile and install custom SELinux policies\n\nProvides a way to compile and install custom SELinux policies\nto images. Custom policies are placed in a custom-policies\ndirectory. An install.d script will copy the files to\n/opt/stack/selinux-policy. When an instance boots, an o-r-c\nscript will compile the policy source files in that directory\nand then load them.\n\nWhen SElinux is in enforcing mode in the ci, you would need to\ncreate a custom SELinux policy to temporarily fix an upstream\nissue to allow ci to pass before that issue has been fixed in the\nupstream SELinux policy.\n\nChange-Id: I1cda87e980522f6c668debcf85668bb631d070b3\n'}]",4,106909,43e2b577b8a3d716d1b16eb17dbf7fc7e887de5b,54,5,7,7471,,,0,"Compile and install custom SELinux policies

Provides a way to compile and install custom SELinux policies
to images. Custom policies are placed in a custom-policies
directory. An install.d script will copy the files to
/opt/stack/selinux-policy. When an instance boots, an o-r-c
script will compile the policy source files in that directory
and then load them.

When SElinux is in enforcing mode in the ci, you would need to
create a custom SELinux policy to temporarily fix an upstream
issue to allow ci to pass before that issue has been fixed in the
upstream SELinux policy.

Change-Id: I1cda87e980522f6c668debcf85668bb631d070b3
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/09/106909/5 && git format-patch -1 --stdout FETCH_HEAD,['elements/selinux/install.d/100-install-custom-selinux-policies'],1,a70897b0321f16ef7a88a588abe7194c38fa10a8,custom-selinux-policies,#!/bin/bash set -eux for file in $(ls ../custom-policies); do ls ../custom-policies/$file checkmodule -M -m -o /tmp/$file.mod ../custom-policies/$file semodule_package -o /tmp/$file.pp -m /tmp/$file.mod semodule -i /tmp/$file.pp done ,,9,0
openstack%2Fdevstack~master~I749b31dcaad072a35e5921579b50f1ca451b1383,openstack/devstack,master,I749b31dcaad072a35e5921579b50f1ca451b1383,Support Router Advertisement Daemon (radvd) for IPv6,MERGED,2014-07-17 19:10:13.000000000,2014-08-07 15:05:37.000000000,2014-08-07 15:05:36.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 4656}, {'_account_id': 6524}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9009}, {'_account_id': 9656}, {'_account_id': 10257}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-17 19:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c38e4497842738b15eef0d139923b373f368f97e', 'message': 'Support Router Advertisement Daemon (radvd) for IPv6\n\nradvd is not installed by default. This change installs radvd if l3 service is\nenabled\n\nChange-Id: I749b31dcaad072a35e5921579b50f1ca451b1383\nImplements: blueprint neutron-ipv6-radvd-ra\n'}, {'number': 2, 'created': '2014-08-01 19:13:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/8b5ebfcaf2e6e172da0ef23d7925f0f0e23787df', 'message': 'Support Router Advertisement Daemon (radvd) for IPv6\n\nInstall radvd if the l3 service is enabled and IPv6 is enabled.\n\nImplements: blueprint neutron-ipv6-radvd-ra\n\nChange-Id: I749b31dcaad072a35e5921579b50f1ca451b1383\n'}, {'number': 3, 'created': '2014-08-01 20:18:35.000000000', 'files': ['files/rpms/neutron', 'files/rpms-suse/neutron', 'lib/neutron', 'files/apts/neutron'], 'web_link': 'https://opendev.org/openstack/devstack/commit/72b3e448afb1c5e6017fb678df58f6ad6113b8a9', 'message': 'Support Router Advertisement Daemon (radvd) for IPv6\n\nInstall radvd if the l3 service is enabled.\n\nPartially implements blueprint: neutron-ipv6-radvd-ra\n\nChange-Id: I749b31dcaad072a35e5921579b50f1ca451b1383\n'}]",0,107801,72b3e448afb1c5e6017fb678df58f6ad6113b8a9,47,12,3,6685,,,0,"Support Router Advertisement Daemon (radvd) for IPv6

Install radvd if the l3 service is enabled.

Partially implements blueprint: neutron-ipv6-radvd-ra

Change-Id: I749b31dcaad072a35e5921579b50f1ca451b1383
",git fetch https://review.opendev.org/openstack/devstack refs/changes/01/107801/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron'],1,c38e4497842738b15eef0d139923b373f368f97e,bp/neutron-ipv6-radvd-ra, # radvd doesn't come with the OS. install it if l3 is enabled if is_service_enabled q-l3; then install_package radvd fi,,4,0
openstack%2Fceilometer~master~I725d04bee332429e864941199e37aef07a0f6adf,openstack/ceilometer,master,I725d04bee332429e864941199e37aef07a0f6adf,Handle Cinder attach and detach notifications,MERGED,2014-08-06 16:38:58.000000000,2014-08-07 15:05:30.000000000,2014-08-07 15:05:29.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 7478}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-08-06 16:38:58.000000000', 'files': ['ceilometer/tests/volume/test_notifications.py', 'ceilometer/volume/notifications.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e73fc9b5cb79e5c0f5c778e0b1affe3e16c1626c', 'message': 'Handle Cinder attach and detach notifications\n\nHandle attach and detach Cinder notifications so\nthe latest volume state is available in samples.\n\nCloses-bug: #1353590\nChange-Id: I725d04bee332429e864941199e37aef07a0f6adf\n'}]",0,112352,e73fc9b5cb79e5c0f5c778e0b1affe3e16c1626c,14,5,1,7156,,,0,"Handle Cinder attach and detach notifications

Handle attach and detach Cinder notifications so
the latest volume state is available in samples.

Closes-bug: #1353590
Change-Id: I725d04bee332429e864941199e37aef07a0f6adf
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/52/112352/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/volume/test_notifications.py', 'ceilometer/volume/notifications.py']",2,e73fc9b5cb79e5c0f5c778e0b1affe3e16c1626c,bug/1353590," 'volume.attach.*', 'volume.detach.*',",,96,0
openstack%2Fdevstack~master~I7bfe25d42c9429606ee209860685077806eb6756,openstack/devstack,master,I7bfe25d42c9429606ee209860685077806eb6756,Use Mongo DB as the default backend,MERGED,2014-06-26 16:52:17.000000000,2014-08-07 15:05:22.000000000,2014-08-07 15:05:22.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 67}, {'_account_id': 112}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6427}, {'_account_id': 6484}, {'_account_id': 6944}, {'_account_id': 7498}, {'_account_id': 8092}, {'_account_id': 9009}, {'_account_id': 10385}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-06-26 16:52:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/20a4f7ea44734776fc41706d8265f20b3c2b7e09', 'message': 'Use Mongo DB as the default backend\n\nWith the gate upgrade to Trusty, Marconi should now be able to run with\nMongo DB at the gate.\n\nChange-Id: I7bfe25d42c9429606ee209860685077806eb6756\n'}, {'number': 2, 'created': '2014-08-05 21:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/dd2bef39f2321e0dcd77525a9c099673e5b5365f', 'message': 'Use Mongo DB as the default backend\n\nWith the gate upgrade to Trusty, Marconi should now be able to run with\nMongo DB at the gate.\n\nChange-Id: I7bfe25d42c9429606ee209860685077806eb6756\n'}, {'number': 3, 'created': '2014-08-05 21:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/669be69558b9a2edf1e330914a838baea56e687f', 'message': 'Use Mongo DB as the default backend\n\nWith the gate upgrade to Trusty, Marconi should now be able to run with\nMongo DB at the gate.\n\nChange-Id: I7bfe25d42c9429606ee209860685077806eb6756\n'}, {'number': 4, 'created': '2014-08-06 11:44:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/472cd6a13f14e9f6ce8e50b51e132f8fcc5d8a92', 'message': 'Use Mongo DB as the default backend\n\nWith the gate upgrade to Trusty, Marconi should now be able to run with\nMongo DB at the gate.\n\nChange-Id: I7bfe25d42c9429606ee209860685077806eb6756\n'}, {'number': 5, 'created': '2014-08-07 00:58:17.000000000', 'files': ['lib/marconi'], 'web_link': 'https://opendev.org/openstack/devstack/commit/f7ae9ff5dd0f7e20037d49869251d2367b46c459', 'message': 'Use Mongo DB as the default backend\n\nWith the gate upgrade to Trusty, Marconi should now be able to run with\nMongo DB at the gate.\n\nChange-Id: I7bfe25d42c9429606ee209860685077806eb6756\n'}]",2,102883,f7ae9ff5dd0f7e20037d49869251d2367b46c459,56,18,5,7498,,,0,"Use Mongo DB as the default backend

With the gate upgrade to Trusty, Marconi should now be able to run with
Mongo DB at the gate.

Change-Id: I7bfe25d42c9429606ee209860685077806eb6756
",git fetch https://review.opendev.org/openstack/devstack refs/changes/83/102883/3 && git format-patch -1 --stdout FETCH_HEAD,['lib/marconi'],1,20a4f7ea44734776fc41706d8265f20b3c2b7e09,mongo-trusty,MARCONI_BACKEND=${MARCONI_BACKEND:-mongodb},MARCONI_BACKEND=${MARCONI_BACKEND:-sqlite},1,1
openstack%2Ftooz~master~I75b2a45fa44ee7b9bf6a512b196185a0619e5034,openstack/tooz,master,I75b2a45fa44ee7b9bf6a512b196185a0619e5034,memcached: use a timestamp as heartbeat value,ABANDONED,2014-08-06 15:48:47.000000000,2014-08-07 14:54:40.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-08-06 15:48:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/d98a0611706427d6c2e9e36d7d2dda1f2f7f8913', 'message': 'memcached: use a timestamp as heartbeat value\n\nChange-Id: I75b2a45fa44ee7b9bf6a512b196185a0619e5034\n'}, {'number': 2, 'created': '2014-08-07 13:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/8b7c141b682438b4ada2f02610a0fbdd4f95a1a9', 'message': 'memcached: use a timestamp as heartbeat value\n\nChange-Id: I75b2a45fa44ee7b9bf6a512b196185a0619e5034\n'}, {'number': 3, 'created': '2014-08-07 14:06:50.000000000', 'files': ['tooz/tests/test_coordination.py', 'tooz/drivers/memcached.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/05995918e3cdd9a052596a4476df441b8e9a093b', 'message': 'memcached: use a timestamp as heartbeat value\n\nChange-Id: I75b2a45fa44ee7b9bf6a512b196185a0619e5034\n'}]",0,112332,05995918e3cdd9a052596a4476df441b8e9a093b,11,1,3,1669,,,0,"memcached: use a timestamp as heartbeat value

Change-Id: I75b2a45fa44ee7b9bf6a512b196185a0619e5034
",git fetch https://review.opendev.org/openstack/tooz refs/changes/32/112332/3 && git format-patch -1 --stdout FETCH_HEAD,['tooz/drivers/memcached.py'],1,d98a0611706427d6c2e9e36d7d2dda1f2f7f8913,jd/url,"import time def _is_member_alive(self, member_id): timestamp = self.client.get(self._encode_member_id(member_id)) if timestamp: return (time.time() - timestamp) < self.membership_timeout return False if self._is_member_alive(m)) time.time(),"," if self.client.get(self._encode_member_id(m))) ""It's alive!"",",9,2
openstack%2Ftooz~master~Ib4c984831694a2c950c32c4b916064837bc9033b,openstack/tooz,master,Ib4c984831694a2c950c32c4b916064837bc9033b,debug,ABANDONED,2014-08-07 12:19:21.000000000,2014-08-07 14:54:26.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-08-07 12:19:21.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/tooz/commit/1babbdc6b23f6b805dbe66d42982f084b47eed2f', 'message': 'debug\n\nChange-Id: Ib4c984831694a2c950c32c4b916064837bc9033b\n'}]",0,112572,1babbdc6b23f6b805dbe66d42982f084b47eed2f,4,1,1,1669,,,0,"debug

Change-Id: Ib4c984831694a2c950c32c4b916064837bc9033b
",git fetch https://review.opendev.org/openstack/tooz refs/changes/72/112572/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,1babbdc6b23f6b805dbe66d42982f084b47eed2f,jd/url,"memcached -vvv & python setup.py testr --slowest --testr-args=""tests.test_coordination.TestAPI.test_timeout""",memcached & python setup.py testr --slowest,2,2
openstack%2Ffuel-web~master~Id03f6bcaed2a61b4c6d644675ef4cfeb353258a9,openstack/fuel-web,master,Id03f6bcaed2a61b4c6d644675ef4cfeb353258a9,Added image utils,MERGED,2014-07-14 09:48:33.000000000,2014-08-07 14:50:45.000000000,2014-08-07 14:50:44.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8003}, {'_account_id': 8053}, {'_account_id': 8789}, {'_account_id': 8797}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-07-14 09:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/77316c51e6d9fd90bcc6ced4670472e9ecf3ef56', 'message': 'Added image utils\n\nAdded set of image utilities so as to make\nit possible to deal with images when they are\navailable via http or when they are local files,\nwhen they are packed into containers or not, etc.\n\nChange-Id: Id03f6bcaed2a61b4c6d644675ef4cfeb353258a9\nImplements: blueprint image-based-provisioning\n'}, {'number': 2, 'created': '2014-07-14 09:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f0024ec53315da14ebe166307dcbde17500e83f6', 'message': 'Added image utils\n\nAdded set of image utilities so as to make\nit possible to deal with images when they are\navailable via http or when they are local files,\nwhen they are packed into containers or not, etc.\n\nChange-Id: Id03f6bcaed2a61b4c6d644675ef4cfeb353258a9\nImplements: blueprint image-based-provisioning\n'}, {'number': 3, 'created': '2014-07-14 11:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/42593e3b78e1bf840d8ca44824dba49c3e043666', 'message': 'Added image utils\n\nAdded set of image utilities so as to make\nit possible to deal with images when they are\navailable via http or when they are local files,\nwhen they are packed into containers or not, etc.\n\nChange-Id: Id03f6bcaed2a61b4c6d644675ef4cfeb353258a9\nImplements: blueprint image-based-provisioning\n'}, {'number': 4, 'created': '2014-07-15 08:49:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ad65a34e64ccd1fb1a8a907597be29a1439bda45', 'message': 'Added image utils\n\nAdded set of image utilities so as to make\nit possible to deal with images when they are\navailable via http or when they are local files,\nwhen they are packed into containers or not, etc.\n\nChange-Id: Id03f6bcaed2a61b4c6d644675ef4cfeb353258a9\nImplements: blueprint image-based-provisioning\n'}, {'number': 5, 'created': '2014-07-24 16:36:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a6dd241cc953d368082e792cf33f38f5a746799b', 'message': 'Added image utils\n\nAdded set of image utilities so as to make\nit possible to deal with images when they are\navailable via http or when they are local files,\nwhen they are packed into containers or not, etc.\n\nChange-Id: Id03f6bcaed2a61b4c6d644675ef4cfeb353258a9\nImplements: blueprint image-based-provisioning\n'}, {'number': 6, 'created': '2014-07-28 16:38:12.000000000', 'files': ['fuel_agent/fuel_agent/objects/image.py', 'fuel_agent/fuel_agent/tests/test_nailgun.py', 'fuel_agent/fuel_agent/manager.py', 'fuel_agent/fuel_agent/tests/test_img_utils.py', 'fuel_agent/requirements.txt', 'fuel_agent/fuel_agent/utils/img_utils.py', 'fuel_agent/fuel_agent/tests/test_manager.py', 'fuel_agent/fuel_agent/drivers/nailgun.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1abf17806e4b6d16c01e06a9a40d3124916545d4', 'message': 'Added image utils\n\nAdded set of image utilities so as to make\nit possible to deal with images when they are\navailable via http or when they are local files,\nwhen they are packed into containers or not, etc.\n\nChange-Id: Id03f6bcaed2a61b4c6d644675ef4cfeb353258a9\nImplements: blueprint image-based-provisioning\n'}]",2,106720,1abf17806e4b6d16c01e06a9a40d3124916545d4,47,7,6,3009,,,0,"Added image utils

Added set of image utilities so as to make
it possible to deal with images when they are
available via http or when they are local files,
when they are packed into containers or not, etc.

Change-Id: Id03f6bcaed2a61b4c6d644675ef4cfeb353258a9
Implements: blueprint image-based-provisioning
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/20/106720/6 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_agent/fuel_agent/objects/image.py', 'fuel_agent/fuel_agent/manager.py', 'fuel_agent/fuel_agent/utils/img_utils.py', 'fuel_agent/fuel_agent/drivers/nailgun.py']",4,77316c51e6d9fd90bcc6ced4670472e9ecf3ef56,bp/image-based-provisioning," root_image_uri = 'http://%s/image/%s.img.gz' % ( data['ks_meta']['master_ip'], data['profile'].split('_')[0] ) uri=root_image_uri, image_format='ext4', container='gzip',"," uri=data['ks_meta']['image_uri'], image_format=data['ks_meta']['image_format'], container=data['ks_meta']['image_container'], size=data['ks_meta'].get('image_size'),",101,7
openstack%2Fpython-ironicclient~master~If2c2cd766466dca4621e8daa260575fd4f106f06,openstack/python-ironicclient,master,If2c2cd766466dca4621e8daa260575fd4f106f06,Trim trailing slash and version from endpoint,MERGED,2014-07-17 14:13:34.000000000,2014-08-07 14:48:16.000000000,2014-08-07 14:48:16.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 3099}, {'_account_id': 5805}, {'_account_id': 10239}, {'_account_id': 10343}]","[{'number': 1, 'created': '2014-07-17 14:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/234f1bf070da0a5909a9237c84d512d4acdd350e', 'message': 'Trim trailing slash and version from endpoint\n\nThis commit removes trailing slashes and ""/v1"" from the endpoint\ngiven when initializing the HTTP client, in order to fix the bug\nmentioned below. It also removes the rstrip call in\n_make_connection_url, since this is done up front now.\n\nAlso adds tests for get_connection_params.\n\nChange-Id: If2c2cd766466dca4621e8daa260575fd4f106f06\nCloses-Bug: #1342048\n'}, {'number': 2, 'created': '2014-08-05 20:26:13.000000000', 'files': ['ironicclient/common/http.py', 'ironicclient/tests/test_http.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/a07618e722969ca5b0c2b46670ff9d8170e54d5d', 'message': 'Trim trailing slash and version from endpoint\n\nThis commit removes trailing slashes and ""/v1"" from the endpoint\ngiven when initializing the HTTP client, in order to fix the bug\nmentioned below. It also removes the rstrip call in\n_make_connection_url, since this is done up front now.\n\nAlso adds tests for get_connection_params.\n\nChange-Id: If2c2cd766466dca4621e8daa260575fd4f106f06\nCloses-Bug: #1342048\n'}]",1,107715,a07618e722969ca5b0c2b46670ff9d8170e54d5d,26,6,2,10343,,,0,"Trim trailing slash and version from endpoint

This commit removes trailing slashes and ""/v1"" from the endpoint
given when initializing the HTTP client, in order to fix the bug
mentioned below. It also removes the rstrip call in
_make_connection_url, since this is done up front now.

Also adds tests for get_connection_params.

Change-Id: If2c2cd766466dca4621e8daa260575fd4f106f06
Closes-Bug: #1342048
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/15/107715/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/common/http.py', 'ironicclient/tests/test_http.py']",2,234f1bf070da0a5909a9237c84d512d4acdd350e,bug/1342048,"HTTP_CLASS = six.moves.http_client.HTTPConnection HTTPS_CLASS = http.VerifiedHTTPSConnection DEFAULT_TIMEOUT = 600 def test_get_connection_params(self): endpoint = 'http://ironic-host:6385' expected = (HTTP_CLASS, ('ironic-host', 6385, ''), {'timeout': DEFAULT_TIMEOUT}) params = http.HTTPClient.get_connection_params(endpoint) self.assertEqual(expected, params) def test_get_connection_params_with_trailing_slash(self): endpoint = 'http://ironic-host:6385/' expected = (HTTP_CLASS, ('ironic-host', 6385, ''), {'timeout': DEFAULT_TIMEOUT}) params = http.HTTPClient.get_connection_params(endpoint) self.assertEqual(expected, params) def test_get_connection_params_with_ssl(self): endpoint = 'https://ironic-host:6385' expected = (HTTPS_CLASS, ('ironic-host', 6385, ''), { 'timeout': DEFAULT_TIMEOUT, 'ca_file': None, 'cert_file': None, 'key_file': None, 'insecure': False, }) params = http.HTTPClient.get_connection_params(endpoint) self.assertEqual(expected, params) def test_get_connection_params_with_ssl_params(self): endpoint = 'https://ironic-host:6385' ssl_args = { 'ca_file': '/path/to/ca_file', 'cert_file': '/path/to/cert_file', 'key_file': '/path/to/key_file', 'insecure': True, } expected_kwargs = {'timeout': DEFAULT_TIMEOUT} expected_kwargs.update(ssl_args) expected = (HTTPS_CLASS, ('ironic-host', 6385, ''), expected_kwargs) params = http.HTTPClient.get_connection_params(endpoint, **ssl_args) self.assertEqual(expected, params) def test_get_connection_params_with_timeout(self): endpoint = 'http://ironic-host:6385' expected = (HTTP_CLASS, ('ironic-host', 6385, ''), {'timeout': 300.0}) params = http.HTTPClient.get_connection_params(endpoint, timeout=300) self.assertEqual(expected, params) def test_get_connection_params_with_version(self): endpoint = 'http://ironic-host:6385/v1' expected = (HTTP_CLASS, ('ironic-host', 6385, ''), {'timeout': DEFAULT_TIMEOUT}) params = http.HTTPClient.get_connection_params(endpoint) self.assertEqual(expected, params) def test_get_connection_params_with_version_trailing_slash(self): endpoint = 'http://ironic-host:6385/v1/' expected = (HTTP_CLASS, ('ironic-host', 6385, ''), {'timeout': DEFAULT_TIMEOUT}) params = http.HTTPClient.get_connection_params(endpoint) self.assertEqual(expected, params) def test_get_connection_params_with_subpath(self): endpoint = 'http://ironic-host:6385/ironic' expected = (HTTP_CLASS, ('ironic-host', 6385, '/ironic'), {'timeout': DEFAULT_TIMEOUT}) params = http.HTTPClient.get_connection_params(endpoint) self.assertEqual(expected, params) def test_get_connection_params_with_subpath_trailing_slash(self): endpoint = 'http://ironic-host:6385/ironic/' expected = (HTTP_CLASS, ('ironic-host', 6385, '/ironic'), {'timeout': DEFAULT_TIMEOUT}) params = http.HTTPClient.get_connection_params(endpoint) self.assertEqual(expected, params) def test_get_connection_params_with_subpath_version(self): endpoint = 'http://ironic-host:6385/ironic/v1' expected = (HTTP_CLASS, ('ironic-host', 6385, '/ironic'), {'timeout': DEFAULT_TIMEOUT}) params = http.HTTPClient.get_connection_params(endpoint) self.assertEqual(expected, params) def test_get_connection_params_with_subpath_version_trailing_slash(self): endpoint = 'http://ironic-host:6385/ironic/v1/' expected = (HTTP_CLASS, ('ironic-host', 6385, '/ironic'), {'timeout': DEFAULT_TIMEOUT}) params = http.HTTPClient.get_connection_params(endpoint) self.assertEqual(expected, params)",,114,2
openstack%2Ftempest~master~I763212bad849980bea7fdb96384a5fba7889cce7,openstack/tempest,master,I763212bad849980bea7fdb96384a5fba7889cce7,Skip ceilometer test test_check_glance_v*_notifications,MERGED,2014-08-04 23:06:58.000000000,2014-08-07 14:46:01.000000000,2014-08-07 08:51:35.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-04 23:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c1efd8e3171c3f7bc4075b13d6f196359d9aff53', 'message': 'Skip ceilometer test test_check_glance_v1_notifications\n\nThis test was introduced in Id049b6cb8ab3092c50f35894cf5a6bda7ff04617\nand is causing bug 1351627 to cause gate failures.\n\nSince this transient failure is hurting everyone disable the test until\nthe underlying issues are resolved.\n\nChange-Id: I763212bad849980bea7fdb96384a5fba7889cce7\nRelated-Bug: 1351627\n'}, {'number': 2, 'created': '2014-08-06 19:17:21.000000000', 'files': ['tempest/api/telemetry/test_telemetry_notification_api.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b12e2f2adf2365818bd060cd13322e47e0b655a2', 'message': 'Skip ceilometer test test_check_glance_v*_notifications\n\nThis test was introduced in Id049b6cb8ab3092c50f35894cf5a6bda7ff04617\nand is causing bug 1351627 to cause gate failures.\n\nSince this transient failure is hurting everyone disable the test until\nthe underlying issues are resolved.\n\nChange-Id: I763212bad849980bea7fdb96384a5fba7889cce7\nRelated-Bug: 1351627\n'}]",0,111852,b12e2f2adf2365818bd060cd13322e47e0b655a2,15,6,2,1849,,,0,"Skip ceilometer test test_check_glance_v*_notifications

This test was introduced in Id049b6cb8ab3092c50f35894cf5a6bda7ff04617
and is causing bug 1351627 to cause gate failures.

Since this transient failure is hurting everyone disable the test until
the underlying issues are resolved.

Change-Id: I763212bad849980bea7fdb96384a5fba7889cce7
Related-Bug: 1351627
",git fetch https://review.opendev.org/openstack/tempest refs/changes/52/111852/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/telemetry/test_telemetry_notification_api.py'],1,c1efd8e3171c3f7bc4075b13d6f196359d9aff53,bug/1351627, @test.skip_because(bug='1351627'),,1,0
openstack%2Fhorizon~stable%2Ficehouse~I1a6328145a8587e8e65ca1a01664a88a145dbcd6,openstack/horizon,stable/icehouse,I1a6328145a8587e8e65ca1a01664a88a145dbcd6,"template to rely on the the ""id"" attribute",ABANDONED,2014-08-07 06:55:05.000000000,2014-08-07 14:32:16.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1955}]","[{'number': 1, 'created': '2014-08-07 06:55:05.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/templates/instances/_detail_overview.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d954905c0993ceef9ca93bee3c8edc462540b531', 'message': 'template to rely on the the ""id"" attribute\n\nThe exception fixed is the following:\nNoReverseMatch: Reverse for \'detail\' with arguments \'(\'\',)\' and keyword\narguments \'{}\' not found. 1 pattern(s) tried:\n[u\'project/volumes/(?P<volume_id>[^/]+)/$\']\n\nThe test data doesn\'t include a volumeId attribute to volumes but they\ncontain an id attribute.\n\nHere I modify the template to rely on the the ""id"" attribute but maybe\nreal data has a volumeId attribute and it\'s the test data in\nopenstack_dashboard/test/test_data/nova_data.py that needs to be\nmodified instead.\n\nThis is a backport of: https://review.openstack.org/#/c/111936/\n\nChange-Id: I1a6328145a8587e8e65ca1a01664a88a145dbcd6\n'}]",2,112494,d954905c0993ceef9ca93bee3c8edc462540b531,6,3,1,6476,,,0,"template to rely on the the ""id"" attribute

The exception fixed is the following:
NoReverseMatch: Reverse for 'detail' with arguments '('',)' and keyword
arguments '{}' not found. 1 pattern(s) tried:
[u'project/volumes/(?P<volume_id>[^/]+)/$']

The test data doesn't include a volumeId attribute to volumes but they
contain an id attribute.

Here I modify the template to rely on the the ""id"" attribute but maybe
real data has a volumeId attribute and it's the test data in
openstack_dashboard/test/test_data/nova_data.py that needs to be
modified instead.

This is a backport of: https://review.openstack.org/#/c/111936/

Change-Id: I1a6328145a8587e8e65ca1a01664a88a145dbcd6
",git fetch https://review.opendev.org/openstack/horizon refs/changes/94/112494/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/instances/templates/instances/_detail_overview.html'],1,d954905c0993ceef9ca93bee3c8edc462540b531,fix-volume.volumeId-in-detail-overview-icehouse," <a href=""{% url 'horizon:project:volumes:volumes:detail' volume.id %}"">"," <a href=""{% url 'horizon:project:volumes:volumes:detail' volume.volumeId %}"">",1,1
openstack%2Fmonasca-thresh~master~I5272c8ac32e497be978f8c59c4c5b6964ed4e9d2,openstack/monasca-thresh,master,I5272c8ac32e497be978f8c59c4c5b6964ed4e9d2,Change to use monasca everywhere,MERGED,2014-08-06 23:15:09.000000000,2014-08-07 14:26:09.000000000,2014-08-07 14:26:09.000000000,"[{'_account_id': 3}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-08-06 23:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-thresh/commit/91107db95596667c2c26233a4ff66c809217dc58', 'message': 'Change to use monasca everywhere\n\nservice is now monasca_thresh. Config file in /etc/monasca\n\nFixed start and stop in install script\n\nChange-Id: I5272c8ac32e497be978f8c59c4c5b6964ed4e9d2\n'}, {'number': 2, 'created': '2014-08-06 23:23:40.000000000', 'files': ['thresh/src/test/resources/logback.xml', 'thresh/src/deb/control/prerm', 'thresh/src/deb/etc/thresh-config.yml-sample', 'thresh/pom.xml', 'thresh/src/deb/control/control', 'thresh/src/deb/control/postinst', 'thresh/src/deb/init/monasca-thresh', 'thresh/src/main/resources/logback.xml', 'pom.xml', 'thresh/src/main/config/thresh-sample-config.yml'], 'web_link': 'https://opendev.org/openstack/monasca-thresh/commit/d96fb0d85243def5946f4020f3cedcb6ad3e2870', 'message': 'Change to use monasca everywhere\n\nservice is now monasca_thresh. Config file in /etc/monasca\n\nFixed start and stop in install script\n\nChange-Id: I5272c8ac32e497be978f8c59c4c5b6964ed4e9d2\n'}]",0,112435,d96fb0d85243def5946f4020f3cedcb6ad3e2870,10,2,2,11809,,,0,"Change to use monasca everywhere

service is now monasca_thresh. Config file in /etc/monasca

Fixed start and stop in install script

Change-Id: I5272c8ac32e497be978f8c59c4c5b6964ed4e9d2
",git fetch https://review.opendev.org/openstack/monasca-thresh refs/changes/35/112435/2 && git format-patch -1 --stdout FETCH_HEAD,"['thresh/src/test/resources/logback.xml', 'thresh/src/deb/control/prerm', 'thresh/src/deb/etc/thresh-config.yml-sample', 'thresh/pom.xml', 'thresh/src/deb/control/control', 'thresh/src/deb/control/postinst', 'thresh/src/deb/init/monasca-thresh', 'thresh/src/main/resources/logback.xml', 'pom.xml', 'thresh/src/main/config/thresh-sample-config.yml']",10,91107db95596667c2c26233a4ff66c809217dc58,change_to_monasca,,,18,18
openstack%2Fec2-api~master~Icdbd1d0a7e95f777cd7aac4e8c2315d53c115e3f,openstack/ec2-api,master,Icdbd1d0a7e95f777cd7aac4e8c2315d53c115e3f,Adding VPC and Route tables functionality,MERGED,2014-08-06 09:44:37.000000000,2014-08-07 14:26:04.000000000,2014-08-07 14:26:03.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2014-08-06 09:44:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/2d5670c4bdc5ad3fdb923c336ada02760d0a1161', 'message': 'Adding VPC and Route tables functionality\n\nChange-Id: Icdbd1d0a7e95f777cd7aac4e8c2315d53c115e3f\n'}, {'number': 2, 'created': '2014-08-06 16:44:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/c611a1f034ce4eb7d7cc2febb5bcfb69c558fe11', 'message': 'Adding VPC and Route tables functionality\n\nChange-Id: Icdbd1d0a7e95f777cd7aac4e8c2315d53c115e3f\n'}, {'number': 3, 'created': '2014-08-07 13:23:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/7faf861f2a31bc740baa18051ecbc1cf8b0493a4', 'message': 'Adding VPC and Route tables functionality\n\nChange-Id: Icdbd1d0a7e95f777cd7aac4e8c2315d53c115e3f\n'}, {'number': 4, 'created': '2014-08-07 13:29:10.000000000', 'files': ['requirements.txt', 'ec2api/api/utils.py', 'ec2api/api/cloud.py', 'ec2api/tests/base.py', 'ec2api/tests/fakes.py', 'ec2api/api/vpc.py', 'ec2api/tests/test_route_table.py', 'ec2api/api/route_table.py', 'ec2api/tests/test_vpc.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/d2afff474ea4042c0a2075c107d905ad3705a169', 'message': 'Adding VPC and Route tables functionality\n\nChange-Id: Icdbd1d0a7e95f777cd7aac4e8c2315d53c115e3f\n'}]",0,112252,d2afff474ea4042c0a2075c107d905ad3705a169,16,4,4,9312,,,0,"Adding VPC and Route tables functionality

Change-Id: Icdbd1d0a7e95f777cd7aac4e8c2315d53c115e3f
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/52/112252/4 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/utils.py', 'ec2api/api/cloud.py', 'ec2api/tests/base.py', 'ec2api/tests/fakes.py', 'ec2api/api/vpc.py', 'ec2api/tests/test_route_table.py', 'ec2api/api/route_table.py', 'ec2api/tests/test_vpc.py']",8,2d5670c4bdc5ad3fdb923c336ada02760d0a1161,,"# Copyright 2014 Cloudscaling Group, Inc # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock from neutronclient.common import exceptions as neutron_exception from ec2api.tests import base from ec2api.tests import fakes from ec2api.tests import matchers from ec2api.tests import tools class VpcTestCase(base.ApiTestCase): def test_create_vpc(self): self.neutron.create_router.side_effect =\ fakes.get_neutron_create('router', fakes.ID_OS_ROUTER_1) self.db_api.add_item.side_effect =\ fakes.get_db_api_add_item({ 'vpc': fakes.ID_DB_VPC_1, 'rtb': fakes.ID_DB_ROUTE_TABLE_1}) def check_response(response): self.assertEqual(response['status'], 200) self.assertIn('vpc', response) vpc = resp['vpc'] self.assertThat(fakes.EC2_VPC_1, matchers.DictMatches(vpc)) self.neutron.create_router.assert_called_with({'router': {}}) self.neutron.update_router.assert_called_once_with( fakes.ID_OS_ROUTER_1, {'router': {'name': fakes.EC2_VPC_1['vpcId']}}) self.db_api.add_item.assert_any_call( mock.ANY, 'vpc', tools.purge_dict(fakes.DB_VPC_1, ('id', 'vpc_id', 'route_table_id'))) self.db_api.add_item.assert_any_call( mock.ANY, 'rtb', tools.purge_dict(fakes.DB_ROUTE_TABLE_1, ('id',))) self.db_api.update_item.assert_called_once_with( mock.ANY, fakes.DB_VPC_1) self.neutron.reset_mock() self.db_api.reset_mock() self.db_api.update_item.reset_mock() resp = self.execute('CreateVpc', {'CidrBlock': fakes.CIDR_VPC_1}) check_response(resp) resp = self.execute('CreateVpc', {'CidrBlock': fakes.CIDR_VPC_1, 'instanceTenancy': 'default'}) check_response(resp) def test_create_vpc_invalid_cidr(self): self.neutron.create_router.side_effect =\ fakes.get_neutron_create('router', fakes.ID_OS_ROUTER_1) self.db_api.add_item.side_effect = fakes.get_db_api_add_item( fakes.ID_DB_VPC_1) def check_response(resp, error_code): self.assertEqual(400, resp['status']) self.assertEqual(error_code, resp['Error']['Code']) self.assertEqual(0, self.neutron.create_router.call_count) self.neutron.reset_mock() self.db_api.reset_mock() resp = self.execute('CreateVpc', {'CidrBlock': 'bad_cidr'}) check_response(resp, 'InvalidParameterValue') resp = self.execute('CreateVpc', {'CidrBlock': '10.0.0.0/8'}) check_response(resp, 'InvalidVpc.Range') @base.skip_not_implemented def test_create_vpc_overlimit(self): self.neutron.create_router.side_effect = neutron_exception.Conflict self.db_api.add_item.side_effect = fakes.get_db_api_add_item( fakes.ID_DB_VPC_1) resp = self.execute('CreateVpc', {'CidrBlock': fakes.CIDR_VPC_1}) self.assertEqual(400, resp['status']) self.assertEqual('VpcLimitExceeded', resp['Error']['Code']) self.neutron.create_router.assert_called_with({'router': {}}) self.assertEqual(0, self.db_api.add_item.call_count) def test_create_vpc_rollback(self): self.neutron.create_router.side_effect =\ fakes.get_neutron_create('router', fakes.ID_OS_ROUTER_1) self.db_api.add_item.side_effect =\ fakes.get_db_api_add_item({ 'vpc': fakes.ID_DB_VPC_1, 'rtb': fakes.ID_DB_ROUTE_TABLE_1}) self.neutron.update_router.side_effect = Exception() self.execute('CreateVpc', {'CidrBlock': fakes.CIDR_VPC_1}) self.neutron.delete_router.assert_called_once_with( fakes.ID_OS_ROUTER_1) self.db_api.delete_item.assert_any_call(mock.ANY, fakes.ID_DB_VPC_1) self.db_api.delete_item.assert_any_call(mock.ANY, fakes.ID_DB_ROUTE_TABLE_1) def test_delete_vpc(self): self.db_api.get_item_by_id.side_effect =\ fakes.get_db_api_get_item_by_id({ fakes.ID_DB_VPC_1: fakes.DB_VPC_1, fakes.ID_DB_ROUTE_TABLE_1: fakes.DB_ROUTE_TABLE_1}) resp = self.execute('DeleteVpc', {'VpcId': fakes.ID_EC2_VPC_1}) self.assertEqual(200, resp['status']) self.assertEqual(True, resp['return']) self.neutron.delete_router.assert_called_once_with( fakes.ID_OS_ROUTER_1) self.db_api.delete_item.assert_any_call( mock.ANY, fakes.ID_DB_VPC_1) self.db_api.delete_item.assert_any_call( mock.ANY, fakes.ID_DB_ROUTE_TABLE_1) def test_delete_vpc_not_found(self): self.db_api.get_item_by_id.return_value = None resp = self.execute('DeleteVpc', {'VpcId': fakes.ID_EC2_VPC_1}) self.assertEqual(400, resp['status']) self.assertEqual('InvalidVpcID.NotFound', resp['Error']['Code']) self.assertEqual(0, self.neutron.delete_router.call_count) self.assertEqual(0, self.db_api.delete_item.call_count) def test_delete_vpc_dependency_violation(self): def do_check(): resp = self.execute('DeleteVpc', {'VpcId': fakes.ID_EC2_VPC_1}) self.assertEqual(400, resp['status']) self.assertEqual('DependencyViolation', resp['Error']['Code']) self.assertEqual(0, self.neutron.delete_router.call_count) self.assertEqual(0, self.db_api.delete_item.call_count) self.neutron.reset_mock() self.db_api.reset_mock() self.db_api.get_item_by_id.return_value = fakes.DB_VPC_1 self.db_api.get_items.side_effect = fakes.get_db_api_get_items( {'igw': [fakes.DB_IGW_1], 'subnet': []}) do_check() self.db_api.get_items.side_effect = fakes.get_db_api_get_items( {'igw': [], 'subnet': [fakes.DB_SUBNET_1]}) do_check() def test_delete_vpc_not_conststent_os_vpc(self): self.db_api.get_item_by_id.side_effect =\ fakes.get_db_api_get_item_by_id({ fakes.ID_DB_VPC_1: fakes.DB_VPC_1, fakes.ID_DB_ROUTE_TABLE_1: fakes.DB_ROUTE_TABLE_1}) def check_response(resp): self.assertEqual(200, resp['status']) self.assertEqual(True, resp['return']) self.neutron.delete_router.assert_called_once_with( fakes.ID_OS_ROUTER_1) self.db_api.delete_item.assert_any_call( mock.ANY, fakes.ID_DB_VPC_1) self.db_api.delete_item.assert_any_call( mock.ANY, fakes.ID_DB_ROUTE_TABLE_1) self.neutron.reset_mock() self.db_api.reset_mock() self.neutron.delete_router.side_effect = neutron_exception.NotFound resp = self.execute('DeleteVpc', {'VpcId': fakes.ID_EC2_VPC_1}) check_response(resp) self.neutron.delete_router.side_effect = neutron_exception.Conflict resp = self.execute('DeleteVpc', {'VpcId': fakes.ID_EC2_VPC_1}) check_response(resp) def test_delete_vpc_rollback(self): self.db_api.get_item_by_id.side_effect =\ fakes.get_db_api_get_item_by_id({ fakes.ID_DB_VPC_1: fakes.DB_VPC_1, fakes.ID_DB_ROUTE_TABLE_1: fakes.DB_ROUTE_TABLE_1}) self.neutron.delete_router.side_effect = Exception() self.execute('DeleteVpc', {'VpcId': fakes.ID_EC2_VPC_1}) self.db_api.restore_item.assert_any_call( mock.ANY, 'vpc', fakes.DB_VPC_1) self.db_api.restore_item.assert_any_call( mock.ANY, 'rtb', fakes.DB_ROUTE_TABLE_1) def test_describe_vpcs(self): self.neutron.list_routers.return_value =\ {'routers': [fakes.OS_ROUTER_1, fakes.OS_ROUTER_2]} self.db_api.get_items.return_value = [fakes.DB_VPC_1, fakes.DB_VPC_2] resp = self.execute('DescribeVpcs', {}) self.assertEqual(200, resp['status']) self.assertThat(resp['vpcSet'], matchers.DictListMatches([fakes.EC2_VPC_1, fakes.EC2_VPC_2])) self.db_api.get_items.assert_called_once_with(mock.ANY, 'vpc') def test_describe_vpcs_no_router(self): self.neutron.list_routers.return_value = {'routers': []} self.db_api.get_items.return_value = [fakes.DB_VPC_1] resp = self.execute('DescribeVpcs', {}) self.assertEqual(200, resp['status']) self.assertThat(resp['vpcSet'], matchers.DictListMatches([fakes.EC2_VPC_1])) self.db_api.get_items.assert_called_once_with(mock.ANY, 'vpc') ",,2928,0
openstack%2Fhorizon~stable%2Ficehouse~Icd06cf9117757ff40dac07411bedcd08f4853b16,openstack/horizon,stable/icehouse,Icd06cf9117757ff40dac07411bedcd08f4853b16,TEMPLATE_DIRS must be a tuple,ABANDONED,2014-08-07 06:53:05.000000000,2014-08-07 14:25:55.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1955}, {'_account_id': 6476}]","[{'number': 1, 'created': '2014-08-07 06:53:05.000000000', 'files': ['horizon/test/settings.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/64d4752d56668af405913e4ceac73eed6cad3431', 'message': 'TEMPLATE_DIRS must be a tuple\n\nWith Django 1.7, TEMPLATE_DIRS must be a tuple. The\ndefinition in horizon/test/settings.py must therefore\nhave a leading comma. Note that other definitions of\nTEMPLATE_DIRS are already like this in Horizon, so\nthis just fixes the one instance which is wrong.\n\nThis is a backport of: https://review.openstack.org/#/c/111561/\n\nChange-Id: Icd06cf9117757ff40dac07411bedcd08f4853b16\n'}]",3,112492,64d4752d56668af405913e4ceac73eed6cad3431,7,4,1,6476,,,0,"TEMPLATE_DIRS must be a tuple

With Django 1.7, TEMPLATE_DIRS must be a tuple. The
definition in horizon/test/settings.py must therefore
have a leading comma. Note that other definitions of
TEMPLATE_DIRS are already like this in Horizon, so
this just fixes the one instance which is wrong.

This is a backport of: https://review.openstack.org/#/c/111561/

Change-Id: Icd06cf9117757ff40dac07411bedcd08f4853b16
",git fetch https://review.opendev.org/openstack/horizon refs/changes/92/112492/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/test/settings.py'],1,64d4752d56668af405913e4ceac73eed6cad3431,fix-template-dirs-icehouse,"TEMPLATE_DIRS = (os.path.join(ROOT_PATH, 'tests', 'templates'),)","TEMPLATE_DIRS = (os.path.join(ROOT_PATH, 'tests', 'templates'))",1,1
openstack%2Fceilometer~master~I45482ca173347a351fcf0de5e9ee3faa8976600f,openstack/ceilometer,master,I45482ca173347a351fcf0de5e9ee3faa8976600f,Fix unit for vpn connection metric,MERGED,2014-08-01 21:43:12.000000000,2014-08-07 14:15:29.000000000,2014-08-07 14:15:28.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6924}, {'_account_id': 7478}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-08-01 21:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ef253deb245e02e2130724e647d8fb4302967726', 'message': 'Fix unit for vpn connections metric\n\nUnit for cpn connections should use connection\ninstead of vpn. The docs show the right type.\n\nChange-Id: I45482ca173347a351fcf0de5e9ee3faa8976600f\n'}, {'number': 2, 'created': '2014-08-01 21:49:36.000000000', 'files': ['ceilometer/network/services/vpnaas.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8331b0d09af71387af88261692bf34f2e5e9212c', 'message': 'Fix unit for vpn connection metric\n\nUnit for vpn connections should use connection\ninstead of vpn. The docs show the right value.\n\nChange-Id: I45482ca173347a351fcf0de5e9ee3faa8976600f\n'}]",0,111397,8331b0d09af71387af88261692bf34f2e5e9212c,17,7,2,6924,,,0,"Fix unit for vpn connection metric

Unit for vpn connections should use connection
instead of vpn. The docs show the right value.

Change-Id: I45482ca173347a351fcf0de5e9ee3faa8976600f
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/97/111397/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/network/services/vpnaas.py'],1,ef253deb245e02e2130724e647d8fb4302967726,," unit='connection',"," unit='vpn',",1,1
openstack%2Ffuel-main~master~Idc990e1e2d537f2379231513cb1825d2ef6d172d,openstack/fuel-main,master,Idc990e1e2d537f2379231513cb1825d2ef6d172d,Change ceph restart tests to use existing snapshots,MERGED,2014-08-07 08:17:07.000000000,2014-08-07 14:12:59.000000000,2014-08-07 14:08:38.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-08-07 08:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d7a9b6ba5c7a33bebd42ee3c68c3af76377792d6', 'message': 'Change ceph restart tests to use existing snapshots\n\nChange-Id: Idc990e1e2d537f2379231513cb1825d2ef6d172d\nCloses-Bug: #1353543\n'}, {'number': 2, 'created': '2014-08-07 08:31:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d50cc60b20ef8d7b80d0012d35014234244a044c', 'message': 'Change ceph restart tests to use existing snapshots\n\nChange-Id: Idc990e1e2d537f2379231513cb1825d2ef6d172d\nCloses-Bug: #1353543\n'}, {'number': 3, 'created': '2014-08-07 08:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b16b4f3c658ff571c6ec4be4ebddd7b38264b46a', 'message': 'Change ceph restart tests to use existing snapshots\n\nChange-Id: Idc990e1e2d537f2379231513cb1825d2ef6d172d\nCloses-Bug: #1353543\n'}, {'number': 4, 'created': '2014-08-07 11:48:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/cdb5eeb322a58cdd158b4e0d302bb325cde64671', 'message': 'Change ceph restart tests to use existing snapshots\n\nChange-Id: Idc990e1e2d537f2379231513cb1825d2ef6d172d\nCloses-Bug: #1353543\n'}, {'number': 5, 'created': '2014-08-07 11:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/30feb345b1ae71b3a657ffeb6204e757e1d87ea5', 'message': 'Change ceph restart tests to use existing snapshots\n\nChange-Id: Idc990e1e2d537f2379231513cb1825d2ef6d172d\nCloses-Bug: #1353543\n'}, {'number': 6, 'created': '2014-08-07 12:47:32.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_restart.py', 'fuelweb_test/tests/test_ceph.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/97478eb1612655eedcffd25090e7270cfa91cffe', 'message': 'Change ceph restart tests to use existing snapshots\n\nChange-Id: Idc990e1e2d537f2379231513cb1825d2ef6d172d\nCloses-Bug: #1353543\n'}]",0,112506,97478eb1612655eedcffd25090e7270cfa91cffe,37,5,6,10136,,,0,"Change ceph restart tests to use existing snapshots

Change-Id: Idc990e1e2d537f2379231513cb1825d2ef6d172d
Closes-Bug: #1353543
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/06/112506/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/tests_strength/test_restart.py', 'fuelweb_test/tests/test_ceph.py']",2,d7a9b6ba5c7a33bebd42ee3c68c3af76377792d6,refactorCephRestartTests, self.check_run('ceph_multinode_with_cinder') self.check_run('ceph_ha'),,14,50
openstack%2Fhorizon~master~I2c5e0c0a405e6d103341dd92335cbf8e67e3f922,openstack/horizon,master,I2c5e0c0a405e6d103341dd92335cbf8e67e3f922,Cleans up the translation,ABANDONED,2014-08-06 19:05:28.000000000,2014-08-07 14:05:47.000000000,,"[{'_account_id': 3}, {'_account_id': 4978}, {'_account_id': 6610}, {'_account_id': 9622}]","[{'number': 1, 'created': '2014-08-06 19:05:28.000000000', 'files': ['horizon/templatetags/sizeformat.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/35f502c465a584e2f51ced69a2832279f0a6b8b7', 'message': 'Cleans up the translation\n\nReplaces translation.ungettext_lazy with\nungettext_lazy by importing ungettext_lazy from django.utils.translation\nReplaces translation.ugettext_lazy with _\nby importing ugettext_lazy as _ from django.utils.translation\n\nCloses-Bug: 1351478\n\nChange-Id: I2c5e0c0a405e6d103341dd92335cbf8e67e3f922\n'}]",0,112383,35f502c465a584e2f51ced69a2832279f0a6b8b7,6,4,1,12485,,,0,"Cleans up the translation

Replaces translation.ungettext_lazy with
ungettext_lazy by importing ungettext_lazy from django.utils.translation
Replaces translation.ugettext_lazy with _
by importing ugettext_lazy as _ from django.utils.translation

Closes-Bug: 1351478

Change-Id: I2c5e0c0a405e6d103341dd92335cbf8e67e3f922
",git fetch https://review.opendev.org/openstack/horizon refs/changes/83/112383/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templatetags/sizeformat.py'],1,35f502c465a584e2f51ced69a2832279f0a6b8b7,bug/1351478, value = value or _('0 bytes'), value = value or translation.ugettext_lazy('0 bytes'),1,1
openstack%2Ftripleo-image-elements~master~I5af70abb96021146c098f788db349808d806a348,openstack/tripleo-image-elements,master,I5af70abb96021146c098f788db349808d806a348,Support for haproxy server options,MERGED,2014-07-30 23:31:54.000000000,2014-08-07 14:00:03.000000000,2014-08-07 14:00:02.000000000,"[{'_account_id': 3}, {'_account_id': 1605}, {'_account_id': 1872}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 7582}, {'_account_id': 9013}, {'_account_id': 10035}, {'_account_id': 11655}]","[{'number': 1, 'created': '2014-07-30 23:31:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/4d9d3024b5a178f8f3ee88b1890c30d1e63e52df', 'message': 'Support for haproxy server options\n\nThis commit adds support for add additional backend server line\nparameters that can control the behavior of haproxy.\n\nIt is intended to be able to apply the backup configuration flag\nto the server lines in order to lock traffic to a single backend\nserver which is required for mysql.\n\nChange-Id: I5af70abb96021146c098f788db349808d806a348\n'}, {'number': 2, 'created': '2014-08-06 16:20:44.000000000', 'files': ['elements/haproxy/os-apply-config/etc/haproxy/haproxy.cfg', 'elements/haproxy/README.md'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e1603a65a185d61628467ccc65e28629bbf3d7e0', 'message': 'Support for haproxy server options\n\nThis commit adds support for add additional backend server line\nparameters that can control the behavior of haproxy.\n\nIt is intended to be able to apply the backup configuration flag\nto the server lines in order to lock traffic to a single backend\nserver which is required for mysql.\n\nChange-Id: I5af70abb96021146c098f788db349808d806a348\n'}]",0,110809,e1603a65a185d61628467ccc65e28629bbf3d7e0,25,9,2,11655,,,0,"Support for haproxy server options

This commit adds support for add additional backend server line
parameters that can control the behavior of haproxy.

It is intended to be able to apply the backup configuration flag
to the server lines in order to lock traffic to a single backend
server which is required for mysql.

Change-Id: I5af70abb96021146c098f788db349808d806a348
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/09/110809/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/haproxy/os-apply-config/etc/haproxy/haproxy.cfg', 'elements/haproxy/README.md']",2,4d9d3024b5a178f8f3ee88b1890c30d1e63e52df,add-haproxy-server-opts,* extra_server_params: A list of parameters that will be appended to each backend server line that is generated. - name: mysql port: 3306 extra_server_params: - backup,,7,1
openstack%2Fbarbican~master~I51e845c9f40552bed670df4ccdfef1209c91999b,openstack/barbican,master,I51e845c9f40552bed670df4ccdfef1209c91999b,Remove remaining skipTest,MERGED,2014-08-07 11:55:40.000000000,2014-08-07 13:49:18.000000000,2014-08-07 13:49:18.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7354}, {'_account_id': 7355}, {'_account_id': 7687}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 9946}]","[{'number': 1, 'created': '2014-08-07 11:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/1dce6be54769163766dab01188af26e84f90dc35', 'message': 'Remove remaining skipTest\n\nThe usage of the skipTest functions in test_dogtag waas replaced by the skip\ndecorator. Aparently, a subsequent commit contained an instance of the skipTest\nfunction, and thus it was removed.\n\nChange-Id: I51e845c9f40552bed670df4ccdfef1209c91999b\n'}, {'number': 2, 'created': '2014-08-07 11:56:19.000000000', 'files': ['barbican/tests/plugin/test_dogtag.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/248c7d6b106f248b4cbc5cb713af4bbaee8c8b98', 'message': 'Remove remaining skipTest\n\nThe usage of the skipTest functions in test_dogtag waas replaced by\nthe skip decorator. Aparently, a subsequent commit contained an\ninstance of the skipTest function, and thus it was removed.\n\nChange-Id: I51e845c9f40552bed670df4ccdfef1209c91999b\n'}]",0,112567,248c7d6b106f248b4cbc5cb713af4bbaee8c8b98,16,13,2,10873,,,0,"Remove remaining skipTest

The usage of the skipTest functions in test_dogtag waas replaced by
the skip decorator. Aparently, a subsequent commit contained an
instance of the skipTest function, and thus it was removed.

Change-Id: I51e845c9f40552bed670df4ccdfef1209c91999b
",git fetch https://review.opendev.org/openstack/barbican refs/changes/67/112567/1 && git format-patch -1 --stdout FETCH_HEAD,['barbican/tests/plugin/test_dogtag.py'],1,1dce6be54769163766dab01188af26e84f90dc35,skip_test,," if not imports_ok: self.skipTest(""Dogtag imports not available"")",0,2
openstack%2Fnova~master~Ib15b3eb7bf7863f86bebcfacfca54c278b8af5d5,openstack/nova,master,Ib15b3eb7bf7863f86bebcfacfca54c278b8af5d5,VMware: Add _create_array_of_type utility function to fake,ABANDONED,2014-07-09 13:31:07.000000000,2014-08-07 13:48:01.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 8027}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-09 13:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/99f3276c763a620d44e2377500ce53284acacbfa', 'message': 'VMware: Add _create_array_of_type utility function to fake\n\nAdd a function to create an array type which works correctly when\npassed to code. A returned array of Foo must be an instance of class\nArrayOfFoo, and contain a single property, Foo, which is a python\narray of objects of type Foo.\n\nThe initial driver for adding this function is to create\nArrayOfVirtualDevice.\n\nChange-Id: Ib15b3eb7bf7863f86bebcfacfca54c278b8af5d5\n'}, {'number': 2, 'created': '2014-07-10 08:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/922feb8b6612b4e39d841ada3c3338491caad356', 'message': 'VMware: Add _create_array_of_type utility function to fake\n\nAdd a function to create an array type which works correctly when\npassed to code. A returned array of Foo must be an instance of class\nArrayOfFoo, and contain a single property, Foo, which is a python\narray of objects of type Foo.\n\nThe initial driver for adding this function is to create\nArrayOfVirtualDevice.\n\nChange-Id: Ib15b3eb7bf7863f86bebcfacfca54c278b8af5d5\n'}, {'number': 3, 'created': '2014-07-10 17:12:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d0f8c946f8e8b1d4ce7c86a54dc9f777de715255', 'message': 'VMware: Add _create_array_of_type utility function to fake\n\nAdd a function to create an array type which works correctly when\npassed to code. A returned array of Foo must be an instance of class\nArrayOfFoo, and contain a single property, Foo, which is a python\narray of objects of type Foo.\n\nThe initial driver for adding this function is to create\nArrayOfVirtualDevice.\n\nChange-Id: Ib15b3eb7bf7863f86bebcfacfca54c278b8af5d5\n'}, {'number': 4, 'created': '2014-07-10 17:33:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2d3ca512f0a31830593c8b057be9b896bdf0f84', 'message': 'VMware: Add _create_array_of_type utility function to fake\n\nAdd a function to create an array type which works correctly when\npassed to code. A returned array of Foo must be an instance of class\nArrayOfFoo, and contain a single property, Foo, which is a python\narray of objects of type Foo.\n\nThe initial driver for adding this function is to create\nArrayOfVirtualDevice.\n\nChange-Id: Ib15b3eb7bf7863f86bebcfacfca54c278b8af5d5\n'}, {'number': 5, 'created': '2014-07-14 08:45:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c7219312ab3b18a79b50edf389224a408e7ddbca', 'message': 'VMware: Add _create_array_of_type utility function to fake\n\nAdd a function to create an array type which works correctly when\npassed to code. A returned array of Foo must be an instance of class\nArrayOfFoo, and contain a single property, Foo, which is a python\narray of objects of type Foo.\n\nThe initial driver for adding this function is to create\nArrayOfVirtualDevice.\n\nChange-Id: Ib15b3eb7bf7863f86bebcfacfca54c278b8af5d5\n'}, {'number': 6, 'created': '2014-07-14 16:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d190cdea456ff87c76fa92aace124edbc7a64025', 'message': 'VMware: Add _create_array_of_type utility function to fake\n\nAdd a function to create an array type which works correctly when\npassed to code. A returned array of Foo must be an instance of class\nArrayOfFoo, and contain a single property, Foo, which is a python\narray of objects of type Foo.\n\nThe initial driver for adding this function is to create\nArrayOfVirtualDevice.\n\nChange-Id: Ib15b3eb7bf7863f86bebcfacfca54c278b8af5d5\n'}, {'number': 7, 'created': '2014-07-17 11:15:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5b84ea09ce9e6ec2eba2ef823a08aabf246709c1', 'message': 'VMware: Add _create_array_of_type utility function to fake\n\nAdd a function to create an array type which works correctly when\npassed to code. A returned array of Foo must be an instance of class\nArrayOfFoo, and contain a single property, Foo, which is a python\narray of objects of type Foo.\n\nThe initial driver for adding this function is to create\nArrayOfVirtualDevice.\n\nChange-Id: Ib15b3eb7bf7863f86bebcfacfca54c278b8af5d5\n'}, {'number': 8, 'created': '2014-07-28 22:43:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/86b60c16672f9de34bd8abd29c7af1aaaa98e4a6', 'message': 'VMware: Add _create_array_of_type utility function to fake\n\nAdd a function to create an array type which works correctly when\npassed to code. A returned array of Foo must be an instance of class\nArrayOfFoo, and contain a single property, Foo, which is a python\narray of objects of type Foo.\n\nThe initial driver for adding this function is to create\nArrayOfVirtualDevice.\n\nChange-Id: Ib15b3eb7bf7863f86bebcfacfca54c278b8af5d5\n'}, {'number': 9, 'created': '2014-08-04 13:30:15.000000000', 'files': ['nova/tests/virt/vmwareapi/fake.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2e2ae5c3d464874a3803ba9e949bc2d20138472e', 'message': 'VMware: Add _create_array_of_type utility function to fake\n\nAdd a function to create an array type which works correctly when\npassed to code. A returned array of Foo must be an instance of class\nArrayOfFoo, and contain a single property, Foo, which is a python\narray of objects of type Foo.\n\nThe initial driver for adding this function is to create\nArrayOfVirtualDevice.\n\nChange-Id: Ib15b3eb7bf7863f86bebcfacfca54c278b8af5d5\n'}]",0,105737,2e2ae5c3d464874a3803ba9e949bc2d20138472e,102,13,9,9555,,,0,"VMware: Add _create_array_of_type utility function to fake

Add a function to create an array type which works correctly when
passed to code. A returned array of Foo must be an instance of class
ArrayOfFoo, and contain a single property, Foo, which is a python
array of objects of type Foo.

The initial driver for adding this function is to create
ArrayOfVirtualDevice.

Change-Id: Ib15b3eb7bf7863f86bebcfacfca54c278b8af5d5
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/105737/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/vmwareapi/fake.py'],1,99f3276c763a620d44e2377500ce53284acacbfa,spwan-6,"_array_types = {}def _create_array_of_type(t): """"""Returns an array to contain objects of type t."""""" if t in _array_types: return _array_types[t]() array_type_name = 'ArrayOf%s' % t array_type = type(array_type_name, (DataObject,), {}) def __init__(self): super(array_type, self).__init__(array_type_name) setattr(self, t, []) setattr(array_type, '__init__', __init__) _array_types[t] = array_type return array_type() ",,19,0
openstack%2Ftempest~master~Ia3216bddb80d5809a0552041230cbe9d2a5ca4c3,openstack/tempest,master,Ia3216bddb80d5809a0552041230cbe9d2a5ca4c3,skip telemetry notification tests,ABANDONED,2014-08-06 19:09:23.000000000,2014-08-07 13:40:59.000000000,,"[{'_account_id': 3}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-06 19:09:23.000000000', 'files': ['tempest/api/telemetry/test_telemetry_notification_api.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/ae07e2dad16c7da0b677ab7461852241600f349e', 'message': 'skip telemetry notification tests\n\nThese tests are not possible to be stable because there is no\ndeterministic to ensure that notifications have landed in the\ndatabase. They should be skipped, and no additional notification\nchecks should be landed until there is a ceilometer API for\nforcing notification flush.\n\nChange-Id: Ia3216bddb80d5809a0552041230cbe9d2a5ca4c3\nRelated-Bug: #1351627\n'}]",0,112384,ae07e2dad16c7da0b677ab7461852241600f349e,5,3,1,2750,,,0,"skip telemetry notification tests

These tests are not possible to be stable because there is no
deterministic to ensure that notifications have landed in the
database. They should be skipped, and no additional notification
checks should be landed until there is a ceilometer API for
forcing notification flush.

Change-Id: Ia3216bddb80d5809a0552041230cbe9d2a5ca4c3
Related-Bug: #1351627
",git fetch https://review.opendev.org/openstack/tempest refs/changes/84/112384/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/telemetry/test_telemetry_notification_api.py'],1,ae07e2dad16c7da0b677ab7461852241600f349e,skip_notification_tests," @test.skip_because(bug=""1351627"") @test.skip_because(bug=""1351627"")",,2,0
openstack%2Fceilometer~master~I2d3a202aea0ecccf543a8ca20ab9dbceb1664939,openstack/ceilometer,master,I2d3a202aea0ecccf543a8ca20ab9dbceb1664939,Add message translate module in vmware inspector,MERGED,2014-08-07 07:26:58.000000000,2014-08-07 13:39:47.000000000,2014-08-07 13:39:46.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 7478}]","[{'number': 1, 'created': '2014-08-07 07:26:58.000000000', 'files': ['ceilometer/compute/virt/vmware/inspector.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/92a1b827986065982c1d31fda4ed699f9ccbf15b', 'message': 'Add message translate module in vmware inspector\n\nChange-Id: I2d3a202aea0ecccf543a8ca20ab9dbceb1664939\n'}]",0,112497,92a1b827986065982c1d31fda4ed699f9ccbf15b,8,3,1,7641,,,0,"Add message translate module in vmware inspector

Change-Id: I2d3a202aea0ecccf543a8ca20ab9dbceb1664939
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/97/112497/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/compute/virt/vmware/inspector.py'],1,92a1b827986065982c1d31fda4ed699f9ccbf15b,master,from ceilometer.openstack.common.gettextutils import _,,1,0
openstack%2Fceilometer~master~Ic767b257176e05c0b35664968e7f529f507eab11,openstack/ceilometer,master,Ic767b257176e05c0b35664968e7f529f507eab11,[HBase] Improve uniqueness for row in meter table,MERGED,2014-08-01 13:49:11.000000000,2014-08-07 13:30:55.000000000,2014-08-07 13:30:54.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 7478}, {'_account_id': 7729}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-08-01 13:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1cca678f205d49d98982e6b6cafb8ba06c160e0d', 'message': '[HBase] Improve uniqueness for row in meter table\n\nCurrent, row in meter table consists of reversed timestamp,\nmeter and an md5 of user+resource+project for purposes of\nuniqueness. But in some cases, for example in tests for\ncomplex query, rows are same and tests fails on real\nhbase backend.\nIn this patchset row contains a message signature instead of\nmd5 of user+resource+project, because message signature has\ndependecies from all fields of sample, it provides more uniqueness.\n\nChange-Id: Ic767b257176e05c0b35664968e7f529f507eab11\n'}, {'number': 2, 'created': '2014-08-06 11:22:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5e5d938f49067fc31d85286298a1b09d0657b562', 'message': '[HBase] Improve uniqueness for row in meter table\n\nCurrent, row in meter table consists of reversed timestamp,\nmeter and an md5 of user+resource+project for purposes of\nuniqueness. But in some cases, for example in tests for\ncomplex query, rows are same and tests fails on real\nhbase backend.\nIn this patchset row contains a message signature instead of\nmd5 of user+resource+project, because message signature has\ndependecies from all fields of sample, it provides more uniqueness.\n\nChange-Id: Ic767b257176e05c0b35664968e7f529f507eab11\n'}, {'number': 3, 'created': '2014-08-06 15:25:22.000000000', 'files': ['ceilometer/storage/impl_hbase.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bf1b9937f7f50ba725bdb81765b066f9e7ebc633', 'message': '[HBase] Improve uniqueness for row in meter table\n\nCurrently, row in meter table consists of reversed timestamp,\nmeter and an md5 of user+resource+project for purposes of\nuniqueness. But md5 of user+resource+project may be the same\nfor different meters and only ""rts"" provides the difference.\nBut in the tests or under the high load different meters\nfrom the same user, resource and project may have the same\ntimestamp.\nIn this patchset row contains a message signature instead of\nmd5 of user+resource+project, because message signature has\ndependecies from all fields of sample, it provides more uniqueness.\n\nChange-Id: Ic767b257176e05c0b35664968e7f529f507eab11\n'}]",6,111285,bf1b9937f7f50ba725bdb81765b066f9e7ebc633,26,5,3,7729,,,0,"[HBase] Improve uniqueness for row in meter table

Currently, row in meter table consists of reversed timestamp,
meter and an md5 of user+resource+project for purposes of
uniqueness. But md5 of user+resource+project may be the same
for different meters and only ""rts"" provides the difference.
But in the tests or under the high load different meters
from the same user, resource and project may have the same
timestamp.
In this patchset row contains a message signature instead of
md5 of user+resource+project, because message signature has
dependecies from all fields of sample, it provides more uniqueness.

Change-Id: Ic767b257176e05c0b35664968e7f529f507eab11
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/85/111285/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/storage/impl_hbase.py'],1,1cca678f205d49d98982e6b6cafb8ba06c160e0d,row_uniqueness," - row-key: consists of reversed timestamp, meter and a message signature for purposes of uniqueness # Rowkey consists of reversed timestamp, meter and a # message signature for purposes of uniqueness row = ""%s_%d_%s"" % (data['counter_name'], rts, data['message_signature'])","import hashlib - row-key: consists of reversed timestamp, meter and an md5 of user+resource+project for purposes of uniqueness # Rowkey consists of reversed timestamp, meter and an md5 of # user+resource+project for purposes of uniqueness m = hashlib.md5() m.update(""%s%s%s"" % (data['user_id'], data['resource_id'], data['project_id'])) row = ""%s_%d_%s"" % (data['counter_name'], rts, m.hexdigest())",7,9
openstack%2Ffuel-web~master~I9077f9988ca75c2d498515a688828cfe99dbe1c2,openstack/fuel-web,master,I9077f9988ca75c2d498515a688828cfe99dbe1c2,"Upgrades, add new pattern for iptables cleaner",MERGED,2014-08-07 10:53:03.000000000,2014-08-07 13:20:48.000000000,2014-08-07 13:20:47.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}]","[{'number': 1, 'created': '2014-08-07 10:53:03.000000000', 'files': ['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_utils.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/utils.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/engines/docker_engine.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_docker_upgrader.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e1e1a5e23fd02279ab9ea2f6a936ad2b90e72840', 'message': ""Upgrades, add new pattern for iptables cleaner\n\n* add new pattern for iptables cleaner\n  after containers stop, because after\n  new port binding there are rules with\n  new format\n* save iptables rules after cleaning\n* don't raise error if deletion of\n  iptables rules failed, just skip it\n\nChange-Id: I9077f9988ca75c2d498515a688828cfe99dbe1c2\nCloses-bug: #1349287\nCloses-bug: #1353503\n""}]",0,112552,e1e1a5e23fd02279ab9ea2f6a936ad2b90e72840,12,5,1,8749,,,0,"Upgrades, add new pattern for iptables cleaner

* add new pattern for iptables cleaner
  after containers stop, because after
  new port binding there are rules with
  new format
* save iptables rules after cleaning
* don't raise error if deletion of
  iptables rules failed, just skip it

Change-Id: I9077f9988ca75c2d498515a688828cfe99dbe1c2
Closes-bug: #1349287
Closes-bug: #1353503
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/52/112552/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_utils.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/utils.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/engines/docker_engine.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_docker_upgrader.py']",4,e1e1a5e23fd02279ab9ea2f6a936ad2b90e72840,bug/1349287," @mock.patch('fuel_upgrade.engines.docker_engine.utils.safe_exec_cmd') '--to-destination 172.17.0.3:2', '-A DOCKER -d 10.108.0.2/32 -p tcp -m tcp --dport ' '4 -j DNAT --to-destination 172.17.0.11:4'] self.upgrader.clean_docker_iptables_rules([1, 2, 3, 4]) mock.call('iptables -t nat -S'), mock.call('iptables -S'), mock.call('cat /etc/sysconfig/iptables.save'), mock.call( 'iptables -t nat -D DOCKER -d 10.108.0.2/32 -p tcp -m tcp ' '--dport 4 -j DNAT --to-destination 172.17.0.11:4'), mock.call('service iptables save'),"," @mock.patch('fuel_upgrade.engines.docker_engine.utils.exec_cmd') '--to-destination 172.17.0.3:2'] self.upgrader.clean_docker_iptables_rules([1, 2, 3]) mock.call('cat /etc/sysconfig/iptables'),",60,13
openstack%2Fsahara~master~Ib2c8c0296e5e7c00e699dc363a0fa10c3b8a8079,openstack/sahara,master,Ib2c8c0296e5e7c00e699dc363a0fa10c3b8a8079,Migration to oslo.utils,ABANDONED,2014-08-07 11:37:54.000000000,2014-08-07 13:10:12.000000000,,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 7555}]","[{'number': 1, 'created': '2014-08-07 11:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/691b8e015c936cc5a65a9d9670a5dfe8d35afe0e', 'message': 'Migration to oslo.utils\n\nCommon code from sahara.openstack.common.db was replaced\nby usage of oslo.utils library.\nsahara/openstack/common/network_utils.py module was removed.\nexcutils.py, importutils.py, timeutils.py and importutils.py\nmodules are waiting for migration to oslo.utils in other\noslo-incubator modules and still exist.\nChange-Id: Ib2c8c0296e5e7c00e699dc363a0fa10c3b8a8079\n'}, {'number': 2, 'created': '2014-08-07 13:03:13.000000000', 'files': ['sahara/plugins/vanilla/hadoop2/scaling.py', 'etc/sahara/sahara.conf.sample', 'sahara/tests/integration/tests/edp.py', 'sahara/tests/integration/tests/swift.py', 'sahara/service/heat_engine.py', 'sahara/plugins/spark/scaling.py', 'sahara/tests/integration/tests/cluster_configs.py', 'sahara/tests/integration/tests/scaling.py', 'requirements.txt', 'sahara/service/api.py', 'sahara/tests/unit/service/test_periodic.py', 'openstack-common.conf', 'sahara/plugins/general/utils.py', 'sahara/plugins/vanilla/v1_2_1/scaling.py', 'sahara/service/periodic.py', 'sahara/service/volumes.py', 'sahara/tests/integration/tests/gating/test_hdp_gating.py', 'sahara/tests/integration/tests/gating/test_vanilla_gating.py', 'sahara/db/base.py', 'sahara/openstack/common/network_utils.py', 'sahara/tests/integration/tests/map_reduce.py', 'sahara/tests/integration/tests/vanilla_transient_cluster.py', 'sahara/service/direct_engine.py', 'sahara/utils/ssh_remote.py', 'sahara/tests/integration/tests/base.py', 'sahara/db/migration/alembic_migrations/env.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/dc5a4bd9168457007cdae6139f6371aaffbcf2d7', 'message': 'Migration to oslo.utils\n\nCommon code from sahara.openstack.common.db was replaced\nby usage of oslo.utils library.\nsahara/openstack/common/network_utils.py module was removed.\nexcutils.py, importutils.py, timeutils.py and importutils.py\nmodules are waiting for migration to oslo.utils in other\noslo-incubator modules and still exist.\n\nChange-Id: Ib2c8c0296e5e7c00e699dc363a0fa10c3b8a8079\n'}]",0,112561,dc5a4bd9168457007cdae6139f6371aaffbcf2d7,9,3,2,12039,,,0,"Migration to oslo.utils

Common code from sahara.openstack.common.db was replaced
by usage of oslo.utils library.
sahara/openstack/common/network_utils.py module was removed.
excutils.py, importutils.py, timeutils.py and importutils.py
modules are waiting for migration to oslo.utils in other
oslo-incubator modules and still exist.

Change-Id: Ib2c8c0296e5e7c00e699dc363a0fa10c3b8a8079
",git fetch https://review.opendev.org/openstack/sahara refs/changes/61/112561/2 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/vanilla/hadoop2/scaling.py', 'etc/sahara/sahara.conf.sample', 'sahara/tests/integration/tests/edp.py', 'sahara/tests/integration/tests/swift.py', 'sahara/service/heat_engine.py', 'sahara/plugins/spark/scaling.py', 'sahara/tests/integration/tests/cluster_configs.py', 'sahara/tests/integration/tests/scaling.py', 'requirements.txt', 'sahara/service/api.py', 'sahara/tests/unit/service/test_periodic.py', 'openstack-common.conf', 'sahara/plugins/general/utils.py', 'sahara/plugins/vanilla/v1_2_1/scaling.py', 'sahara/service/periodic.py', 'sahara/service/volumes.py', 'sahara/tests/integration/tests/gating/test_hdp_gating.py', 'sahara/tests/integration/tests/gating/test_vanilla_gating.py', 'sahara/db/base.py', 'sahara/openstack/common/network_utils.py', 'sahara/tests/integration/tests/map_reduce.py', 'sahara/tests/integration/tests/vanilla_transient_cluster.py', 'sahara/service/direct_engine.py', 'sahara/utils/ssh_remote.py', 'sahara/tests/integration/tests/base.py', 'sahara/db/migration/alembic_migrations/env.py']",26,691b8e015c936cc5a65a9d9670a5dfe8d35afe0e,oslo.utils,from oslo.utils import importutils importutils.try_import('sahara.db.sqlalchemy.models'),from sahara.openstack.common import importutils importutils.import_module('sahara.db.sqlalchemy.models'),48,210
openstack%2Ftempest~master~Id21a2fccf47d38bdd3e459fda3d0b75a200f28cd,openstack/tempest,master,Id21a2fccf47d38bdd3e459fda3d0b75a200f28cd,Add decorator for safe tearDown,ABANDONED,2014-04-02 07:36:55.000000000,2014-08-07 13:02:54.000000000,,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 7872}, {'_account_id': 8085}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-04-02 07:36:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6b2b661bee517708bf212c11edbd5637741a123b', 'message': 'Add decorator for safe tearDown\n\nInstead of adding a try logic on every single client call this\ndeactivates error checking (and exception raising) of the client\non a global level.\n\nCurrently still WIP since some client function like\nwait_for_server_termination need exceptions.\n\nChange-Id: Id21a2fccf47d38bdd3e459fda3d0b75a200f28cd\n'}, {'number': 2, 'created': '2014-04-03 07:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/770510be107c425a32f8d057b7e4e3825137b76a', 'message': 'Add decorator for safe tearDown\n\nInstead of adding a try logic on every single client call this\ndeactivates error checking (and exception raising) of the client\non a global level. Some function may need exceptions and error handling\nsuch as the wait functions. These functions can flag this demand\nwith another decorator.\n\nChange-Id: Id21a2fccf47d38bdd3e459fda3d0b75a200f28cd\n'}, {'number': 3, 'created': '2014-04-03 08:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8d3ff0a3bc9414166b585297687fd7465650bfef', 'message': 'Add decorator for safe tearDown\n\nInstead of adding a try logic on every single client call this\ndeactivates error checking (and exception raising) of the client\non a global level. Some function may need exceptions and error handling\nsuch as the wait functions. These functions can flag this demand\nwith another decorator.\n\nChange-Id: Id21a2fccf47d38bdd3e459fda3d0b75a200f28cd\n'}, {'number': 4, 'created': '2014-05-28 13:51:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/852bd2f8080fb68b77ed5343296fb21b5bd5324a', 'message': 'Add decorator for safe tearDown\n\nInstead of adding a try logic on every single client call this\ndeactivates error checking (and exception raising) of the client\non a global level. Some function may need exceptions and error handling\nsuch as the wait functions. These functions can flag this demand\nwith another decorator.\n\nChange-Id: Id21a2fccf47d38bdd3e459fda3d0b75a200f28cd\n'}, {'number': 5, 'created': '2014-05-30 09:01:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f7cd16a95285834fde0b8a2b7f1de2b6619f4aa7', 'message': 'Add decorator for safe tearDown\n\nInstead of adding a try logic on every single client call this\ndeactivates error checking (and exception raising) of the client\non a global level. Some function may need exceptions and error handling\nsuch as the wait functions. These functions can flag this demand\nwith another decorator.\n\nChange-Id: Id21a2fccf47d38bdd3e459fda3d0b75a200f28cd\n'}, {'number': 6, 'created': '2014-06-10 12:41:32.000000000', 'files': ['tempest/common/rest_client.py', 'tempest/api/compute/base.py', 'tempest/services/compute/xml/servers_client.py', 'tempest/services/compute/json/servers_client.py', 'tempest/services/compute/v3/json/servers_client.py', 'tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/2b1547921a7d92f4d1b2706f1050ff447ebdafd8', 'message': 'Add decorator for safe tearDown\n\nInstead of adding a try logic on every single client call this\ndeactivates error checking (and exception raising) of the client\non a global level. Some function may need exceptions and error handling\nsuch as the wait functions. These functions can flag this demand\nwith another decorator.\n\nChange-Id: Id21a2fccf47d38bdd3e459fda3d0b75a200f28cd\n'}]",6,84645,2b1547921a7d92f4d1b2706f1050ff447ebdafd8,61,10,6,7872,,,0,"Add decorator for safe tearDown

Instead of adding a try logic on every single client call this
deactivates error checking (and exception raising) of the client
on a global level. Some function may need exceptions and error handling
such as the wait functions. These functions can flag this demand
with another decorator.

Change-Id: Id21a2fccf47d38bdd3e459fda3d0b75a200f28cd
",git fetch https://review.opendev.org/openstack/tempest refs/changes/45/84645/6 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/base.py', 'tempest/common/rest_client.py', 'tempest/test.py']",3,6b2b661bee517708bf212c11edbd5637741a123b,safe_teardown,"def ignore_client_errors(clients=['cls.client']): """"""Sets a flag to only log client errors. This can be used for tearDownClass. Please note that this will disable error checking for all subclasses (super calls). @param clients: a list of clients to disable error checking. """""" def decorator(f): def set_no_error_check_flag(cls, clients, value): for client in clients: try: client_class = getattr(cls, client) except AttributeError: # NOTE(mkoderer): In some cases clients doesn't exist # (e.g. V2 have it and V3 don't) so we can ignore this LOG.warn(""Client %s doesn't exist in %s"" % (client, cls)) continue client_class.no_error_check = value @functools.wraps(f) def wrapper(cls, *func_args, **func_kwargs): set_no_error_check_flag(cls, clients, True) result = f(cls) set_no_error_check_flag(cls, clients, False) return result return wrapper return decorator ",,50,28
openstack%2Fdiskimage-builder~master~Ia698387d0aadc6d5bcabea12902a0c684be41a89,openstack/diskimage-builder,master,Ia698387d0aadc6d5bcabea12902a0c684be41a89,Remove map-packages from RHEL element,ABANDONED,2014-07-03 20:13:07.000000000,2014-08-07 12:49:48.000000000,,"[{'_account_id': 3}, {'_account_id': 8532}, {'_account_id': 9369}, {'_account_id': 9712}]","[{'number': 1, 'created': '2014-07-03 20:13:07.000000000', 'files': ['elements/rhel/bin/map-packages'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/086c69f50494e9f39375e5c87352304d2e88679c', 'message': ""Remove map-packages from RHEL element\n\nThe rhel element depends on redhat-common which already maintains\na much larger map-packages file.  There's no reason to keep both\nfiles.\n\nChange-Id: Ia698387d0aadc6d5bcabea12902a0c684be41a89\n""}]",2,104669,086c69f50494e9f39375e5c87352304d2e88679c,17,4,1,8532,,,0,"Remove map-packages from RHEL element

The rhel element depends on redhat-common which already maintains
a much larger map-packages file.  There's no reason to keep both
files.

Change-Id: Ia698387d0aadc6d5bcabea12902a0c684be41a89
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/69/104669/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/rhel/bin/map-packages'],1,086c69f50494e9f39375e5c87352304d2e88679c,remove-map-packages-from-rhel,,"#!/usr/bin/env python # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import sys # Manually maintained for brevity; consider making this compiled from # distromatch or other rich data sources. # Debian name on the left, RHEL on the right. package_map = { 'augeas-tools': 'augeas', 'build-essential': 'make automake gcc gcc-c++ kernel-devel', 'default-jre': 'java-1.7.0-openjdk', 'extlinux': 'syslinux-extlinux', 'gearman-job-server': 'gearmand', 'grub-pc': 'grub', 'libffi-dev': 'libffi-devel', 'libvirt-bin': 'libvirtd', 'libxml2-dev': 'libxml2-devel', 'libxslt-dev': 'libxslt-devel', 'libz-dev': 'zlib-devel', 'open-iscsi': 'iscsi-initiator-utils', 'openjdk-7-jre-headless': 'java-1.7.0-openjdk-headless', 'openssh-client': 'openssh-clients', 'python-dev': 'python-devel', 'stunnel4': 'stunnel', 'tftpd-hpa': 'tftp-server', 'tgt': 'scsi-target-utils', 'vlan': 'vconfig', } for arg in sys.argv[1:]: print(package_map.get(arg, arg)) sys.exit(0) ",0,45
openstack%2Fpython-glanceclient~master~I7d5a09675cd5dab2e39f0faeaa7c169291eedac6,openstack/python-glanceclient,master,I7d5a09675cd5dab2e39f0faeaa7c169291eedac6,Fix glance-client to work with IPv6 controllers,MERGED,2014-07-26 19:42:09.000000000,2014-08-07 12:49:44.000000000,2014-08-07 12:49:43.000000000,"[{'_account_id': 3}, {'_account_id': 1132}, {'_account_id': 2166}, {'_account_id': 2537}, {'_account_id': 4463}, {'_account_id': 6549}, {'_account_id': 8124}, {'_account_id': 8278}, {'_account_id': 8574}, {'_account_id': 8759}, {'_account_id': 9775}, {'_account_id': 10585}]","[{'number': 1, 'created': '2014-07-26 19:42:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/fbe48440c8562199c5df6fff2d11ba4435d01834', 'message': ""Fix glance-client to work with IPv6 controllers\n\nCurrently the glance client can't operate on IPv6 address based\nopenstack controller IPs. The reason for this is the absence of\ncreation of a IPv6 socket in the glance client code (in https.py).\nThe glance client is trying to create sockets from the AF_INET\nsocket family but this will lead to errors when glance client makes\na call on the IPv6 IP addresses.\n\nIn order to fix this limitation, we ensure that if the hostname\nresolves to IPv6 or an explicit IPv6 address is used to configure\nthe openstack controller - glance client shall be able to detect\nthat and then create a AF_INET6 socket family. In all other cases\na AF_INET socket is created. We default to IPv4 sockets in all\nother cases.\n\nChange-Id: I7d5a09675cd5dab2e39f0faeaa7c169291eedac6\nCloses-bug: #1348030\n""}, {'number': 2, 'created': '2014-08-06 06:40:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/d78901fb255dcfa04d9df4ac364c88186cd6c681', 'message': ""Fix glance-client to work with IPv6 controllers\n\nCurrently the glance client can't operate on IPv6 address based\nopenstack controller IPs. The reason for this is the absence of\ncreation of a IPv6 socket in the glance client code (in https.py).\nThe glance client is trying to create sockets from the AF_INET\nsocket family but this will lead to errors when glance client makes\na call on the IPv6 IP addresses.\n\nIn order to fix this limitation, we ensure that if the hostname\nresolves to IPv6 or an explicit IPv6 address is used to configure\nthe openstack controller - glance client shall be able to detect\nthat and then create a AF_INET6 socket family. In all other cases\na AF_INET socket is created. We default to IPv4 sockets in all\nother cases.\n\nChange-Id: I7d5a09675cd5dab2e39f0faeaa7c169291eedac6\nCloses-bug: #1348030\n""}, {'number': 3, 'created': '2014-08-06 18:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/85a7b8b202de61fcc56862c2dcb0d508ba932a14', 'message': ""Fix glance-client to work with IPv6 controllers\n\nCurrently the glance client can't operate on IPv6 address based\nopenstack controller IPs. The reason for this is the absence of\ncreation of a IPv6 socket in the glance client code (in https.py).\nThe glance client is trying to create sockets from the AF_INET\nsocket family but this will lead to errors when glance client makes\na call on the IPv6 IP addresses.\n\nIn order to fix this limitation, we ensure that if the hostname\nresolves to IPv6 or an explicit IPv6 address is used to configure\nthe openstack controller - glance client shall be able to detect\nthat and then create a AF_INET6 socket family. In all other cases\na AF_INET socket is created. We default to IPv4 sockets in all\nother cases.\n\nChange-Id: I7d5a09675cd5dab2e39f0faeaa7c169291eedac6\nCloses-bug: #1348030\n""}, {'number': 4, 'created': '2014-08-07 02:49:58.000000000', 'files': ['glanceclient/common/https.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/44948533e12e7e3e9bcab66a0b9b5eff032bfe51', 'message': ""Fix glance-client to work with IPv6 controllers\n\nCurrently the glance client can't operate on IPv6 address based\nopenstack controller IPs. The reason for this is the absence of\ncreation of a IPv6 socket in the glance client code (in https.py).\nThe glance client is trying to create sockets from the AF_INET\nsocket family but this will lead to errors when glance client makes\na call on the IPv6 IP addresses.\n\nIn order to fix this limitation, we ensure that if the hostname\nresolves to IPv6 or an explicit IPv6 address is used to configure\nthe openstack controller - glance client shall be able to detect\nthat and then create a AF_INET6 socket family. In all other cases\na AF_INET socket is created. We default to IPv4 sockets in all\nother cases.\n\nChange-Id: I7d5a09675cd5dab2e39f0faeaa7c169291eedac6\nCloses-bug: #1348030\n""}]",8,109823,44948533e12e7e3e9bcab66a0b9b5eff032bfe51,59,12,4,9775,,,0,"Fix glance-client to work with IPv6 controllers

Currently the glance client can't operate on IPv6 address based
openstack controller IPs. The reason for this is the absence of
creation of a IPv6 socket in the glance client code (in https.py).
The glance client is trying to create sockets from the AF_INET
socket family but this will lead to errors when glance client makes
a call on the IPv6 IP addresses.

In order to fix this limitation, we ensure that if the hostname
resolves to IPv6 or an explicit IPv6 address is used to configure
the openstack controller - glance client shall be able to detect
that and then create a AF_INET6 socket family. In all other cases
a AF_INET socket is created. We default to IPv4 sockets in all
other cases.

Change-Id: I7d5a09675cd5dab2e39f0faeaa7c169291eedac6
Closes-bug: #1348030
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/23/109823/4 && git format-patch -1 --stdout FETCH_HEAD,['glanceclient/common/https.py'],1,fbe48440c8562199c5df6fff2d11ba4435d01834,bug/1348030," result = socket.getaddrinfo(self.host, self.port, 0, socket.SOCK_STREAM) if result and len(result) > 0: socket_family = result[0][0] if socket_family == socket.AF_INET6: sock = socket.socket(socket.AF_INET6, socket.SOCK_STREAM) else: sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) else: # If due to some reason the address lookup fails - we still connect # to IPv4 socket. This retains the older behavior. sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)"," sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)",12,1
openstack%2Frally~master~I7f4d3e4b1d3650d97af08e5aca38fa80cc9f6fac,openstack/rally,master,I7f4d3e4b1d3650d97af08e5aca38fa80cc9f6fac,Refactor Move atomic actions from benchmark scenarios,MERGED,2014-08-05 15:13:34.000000000,2014-08-07 12:47:12.000000000,2014-08-07 12:47:11.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 9545}, {'_account_id': 11105}]","[{'number': 1, 'created': '2014-08-05 15:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0cf5e44ca574a94eb330ba7f7d12b76d3dc27477', 'message': 'Refactor Move atomic actions from benchmark scenarios\n\n- Move atomic actions from benchmark/scenario/utils.py\nto benchamrk/scenario/base.py\n- Removed the scenario_utils imports\n- Updated the scenario_base imports and related changes in\nall rally files.\n\nRelated to Trello Card\nhttps://trello.com/c/8YdiRn6T/209-easy-move-atomic-actions-from-\nbenchmark-scenario-utils-py-to-benchamrk-scenario-base-py\n\nChange-Id: I7f4d3e4b1d3650d97af08e5aca38fa80cc9f6fac\n'}, {'number': 2, 'created': '2014-08-06 12:38:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/99036e469579fcb6303760d8d102bca809970ef2', 'message': 'Refactor Move atomic actions from benchmark scenarios\n\n- Move atomic actions from benchmark/scenario/utils.py\nto benchamrk/scenario/base.py\n- Removed the scenario_utils imports\n- Updated the scenario_base imports and related changes in\nall rally files.\n\nCloses-Bug:#1353464\nChange-Id: I7f4d3e4b1d3650d97af08e5aca38fa80cc9f6fac\n'}, {'number': 3, 'created': '2014-08-06 15:37:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b7cf6608b4eae32269ce07a9e83b0e71f27e136b', 'message': 'Refactor Move atomic actions from benchmark scenarios\n\n- Move atomic actions from benchmark/scenario/utils.py\nto benchamrk/scenario/base.py\n- Removed the scenario_utils imports\n- Updated the scenario_base imports and related changes in\nall rally files.\n\nCloses-Bug:#1353464\nChange-Id: I7f4d3e4b1d3650d97af08e5aca38fa80cc9f6fac\n'}, {'number': 4, 'created': '2014-08-06 15:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/48c86a8e18b134b2c8706298987072a0760930e7', 'message': 'Refactor Move atomic actions from benchmark scenarios\n\n- Move atomic actions from benchmark/scenario/utils.py\nto benchamrk/scenario/base.py\n- Removed the scenario_utils imports\n- Updated the scenario_base imports and related changes in\nall rally files.\n\nCloses-Bug:#1353464\nChange-Id: I7f4d3e4b1d3650d97af08e5aca38fa80cc9f6fac\n'}, {'number': 5, 'created': '2014-08-06 15:44:36.000000000', 'files': ['tests/benchmark/runners/test_base.py', 'tests/doc/test_task_samples.py', 'tests/benchmark/scenarios/cinder/test_utils.py', 'rally/benchmark/scenarios/heat/stacks.py', 'tests/benchmark/scenarios/sahara/test_utils.py', 'rally/benchmark/scenarios/ceilometer/queries.py', 'rally/benchmark/runners/base.py', 'rally/benchmark/scenarios/cinder/utils.py', 'rally/benchmark/scenarios/dummy/dummy.py', 'tests/benchmark/scenarios/nova/test_utils.py', 'rally/benchmark/scenarios/cinder/volumes.py', 'rally/benchmark/scenarios/glance/utils.py', 'tests/fakes.py', 'rally/benchmark/scenarios/ceilometer/utils.py', 'tests/benchmark/runners/test_rps.py', 'rally-scenarios/plugins/fake_plugin.py', 'rally/benchmark/scenarios/vm/utils.py', 'tests/benchmark/scenarios/keystone/test_utils.py', 'tests/benchmark/scenarios/test_base.py', 'rally/benchmark/scenarios/sahara/node_group_templates.py', 'tests/benchmark/scenarios/neutron/test_utils.py', 'rally/benchmark/scenarios/neutron/utils.py', 'rally/benchmark/scenarios/keystone/utils.py', 'doc/source/benchmark.rst', 'tests/benchmark/scenarios/test_authenticate.py', 'rally/benchmark/scenarios/glance/images.py', 'rally/benchmark/scenarios/authenticate/authenticate.py', 'rally/benchmark/scenarios/utils.py', 'rally/benchmark/scenarios/quotas/utils.py', 'rally/benchmark/scenarios/sahara/utils.py', 'rally/benchmark/scenarios/heat/utils.py', 'tests/benchmark/scenarios/glance/test_utils.py', 'rally/benchmark/scenarios/ceilometer/resources.py', 'rally/benchmark/scenarios/vm/vmtasks.py', 'rally/benchmark/scenarios/keystone/basic.py', 'rally/benchmark/scenarios/quotas/quotas.py', 'rally/benchmark/scenarios/ceilometer/alarms.py', 'tests/benchmark/scenarios/test_utils.py', 'rally/benchmark/scenarios/ceilometer/meters.py', 'rally/benchmark/scenarios/nova/utils.py', 'tests/benchmark/scenarios/ceilometer/test_utils.py', 'rally/benchmark/scenarios/nova/servers.py', 'rally/benchmark/scenarios/base.py', 'rally/benchmark/scenarios/neutron/network.py', 'tests/benchmark/scenarios/heat/test_utils.py', 'tests/benchmark/scenarios/quotas/test_utils.py', 'rally/benchmark/scenarios/ceilometer/stats.py', 'rally/benchmark/scenarios/tempest/tempest.py', 'tests/orchestrator/test_api.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/132722a76d227a8a228db3cc1d3dfb2f9eb0ed12', 'message': 'Refactor Move atomic actions from benchmark scenarios\n\n- Move atomic actions from benchmark/scenario/utils.py\nto benchamrk/scenario/base.py\n- Removed the scenario_utils imports\n- Updated the scenario_base imports and related changes in\nall rally files.\n\nCloses-Bug:#1353464\nChange-Id: I7f4d3e4b1d3650d97af08e5aca38fa80cc9f6fac\n'}]",6,112045,132722a76d227a8a228db3cc1d3dfb2f9eb0ed12,36,4,5,11105,,,0,"Refactor Move atomic actions from benchmark scenarios

- Move atomic actions from benchmark/scenario/utils.py
to benchamrk/scenario/base.py
- Removed the scenario_utils imports
- Updated the scenario_base imports and related changes in
all rally files.

Closes-Bug:#1353464
Change-Id: I7f4d3e4b1d3650d97af08e5aca38fa80cc9f6fac
",git fetch https://review.opendev.org/openstack/rally refs/changes/45/112045/3 && git format-patch -1 --stdout FETCH_HEAD,"['tests/benchmark/runners/test_base.py', 'tests/doc/test_task_samples.py', 'tests/benchmark/scenarios/cinder/test_utils.py', 'rally/benchmark/scenarios/heat/stacks.py', 'tests/benchmark/scenarios/sahara/test_utils.py', 'rally/benchmark/scenarios/ceilometer/queries.py', 'rally/benchmark/runners/base.py', 'rally/benchmark/scenarios/cinder/utils.py', 'rally/benchmark/scenarios/dummy/dummy.py', 'tests/benchmark/scenarios/nova/test_utils.py', 'rally/benchmark/scenarios/cinder/volumes.py', 'rally/benchmark/scenarios/glance/utils.py', 'tests/fakes.py', 'rally/benchmark/scenarios/ceilometer/utils.py', 'tests/benchmark/runners/test_rps.py', 'rally-scenarios/plugins/fake_plugin.py', 'rally/benchmark/scenarios/vm/utils.py', 'tests/benchmark/scenarios/keystone/test_utils.py', 'tests/benchmark/scenarios/test_base.py', 'rally/benchmark/scenarios/sahara/node_group_templates.py', 'tests/benchmark/scenarios/neutron/test_utils.py', 'rally/benchmark/scenarios/neutron/utils.py', 'rally/benchmark/scenarios/keystone/utils.py', 'doc/source/benchmark.rst', 'tests/benchmark/scenarios/test_authenticate.py', 'rally/benchmark/scenarios/glance/images.py', 'rally/benchmark/scenarios/authenticate/authenticate.py', 'rally/benchmark/scenarios/utils.py', 'rally/benchmark/scenarios/quotas/utils.py', 'rally/benchmark/scenarios/sahara/utils.py', 'rally/benchmark/scenarios/heat/utils.py', 'tests/benchmark/scenarios/glance/test_utils.py', 'rally/benchmark/scenarios/ceilometer/resources.py', 'rally/benchmark/scenarios/vm/vmtasks.py', 'rally/benchmark/scenarios/keystone/basic.py', 'rally/benchmark/scenarios/quotas/quotas.py', 'rally/benchmark/scenarios/ceilometer/alarms.py', 'tests/benchmark/scenarios/test_utils.py', 'rally/benchmark/scenarios/ceilometer/meters.py', 'rally/benchmark/scenarios/nova/utils.py', 'tests/benchmark/scenarios/ceilometer/test_utils.py', 'rally/benchmark/scenarios/nova/servers.py', 'rally/benchmark/scenarios/base.py', 'rally/benchmark/scenarios/neutron/network.py', 'tests/benchmark/scenarios/heat/test_utils.py', 'tests/benchmark/scenarios/quotas/test_utils.py', 'rally/benchmark/scenarios/ceilometer/stats.py', 'rally/benchmark/scenarios/tempest/tempest.py', 'tests/orchestrator/test_api.py']",49,0cf5e44ca574a94eb330ba7f7d12b76d3dc27477,moveautomicaction,from rally.benchmark.scenarios import base as scenario_baseclass FakeScenario(scenario_base.Scenario):# only datascenario_base.operations and actually no more. Each,from rally.benchmark.scenarios import baseclass FakeScenario(base.Scenario):# only database operations and actually no more. Each,348,351
openstack%2Ffuel-main~stable%2F5.0~I587dc15bf4d8f8b47acbc8dd7b6e7f790694b60f,openstack/fuel-main,stable/5.0,I587dc15bf4d8f8b47acbc8dd7b6e7f790694b60f,Determine path to ntpd init script using pattern,MERGED,2014-08-07 11:39:58.000000000,2014-08-07 12:43:54.000000000,2014-08-07 12:43:54.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}]","[{'number': 1, 'created': '2014-08-07 11:39:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6f3c236aabf87af4b668a5e00f6709eebeb58695', 'message': ""Determine path to ntpd init script using pattern\n\nIn different linux distros ntpd daemon init script\ncould be named as 'ntp' or 'ntpd', so we should use\npattern to determine the correct path.\n\nChange-Id: I587dc15bf4d8f8b47acbc8dd7b6e7f790694b60f\nCloses-bug: #1353455\n""}, {'number': 2, 'created': '2014-08-07 11:42:07.000000000', 'files': ['fuelweb_test/models/environment.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2e8814b3e1823d02ebd2456d4653d60e829cc97a', 'message': ""Determine path to ntpd init script using pattern\n\nIn different linux distros ntpd daemon init script\ncould be named as 'ntp' or 'ntpd', so we should use\npattern to determine the correct path.\n\nChange-Id: I587dc15bf4d8f8b47acbc8dd7b6e7f790694b60f\nCloses-bug: #1353455\n""}]",0,112562,2e8814b3e1823d02ebd2456d4653d60e829cc97a,15,6,2,11081,,,0,"Determine path to ntpd init script using pattern

In different linux distros ntpd daemon init script
could be named as 'ntp' or 'ntpd', so we should use
pattern to determine the correct path.

Change-Id: I587dc15bf4d8f8b47acbc8dd7b6e7f790694b60f
Closes-bug: #1353455
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/62/112562/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/environment.py'],1,6f3c236aabf87af4b668a5e00f6709eebeb58695,bug/1353455," self.sync_node_time(self.get_ssh_to_remote(node[""ip""])) self.get_ssh_to_remote_by_name(node.name)) def sync_node_time(self, remote): self.execute_remote_cmd(remote, 'NTPD=$(find /etc/init.d/ -regex \'' '/etc/init.d/ntp.?\'); $NTPD stop ' '&& ntpd -qg && $NTPD start')"," self.sync_node_time(self.get_ssh_to_remote(node[""ip""]), bootstrap=True) if re.compile(""ready_with_[0-9]+_slaves"").match(name): bootsrap = True else: bootsrap = False self.get_ssh_to_remote_by_name(node.name), bootsrap) def sync_node_time(self, remote, bootstrap=False): if settings.OPENSTACK_RELEASE_UBUNTU in settings.OPENSTACK_RELEASE \ and not bootstrap: self.execute_remote_cmd(remote, 'service ntp stop && ntpd -qg' ' && service ntp start') else: self.execute_remote_cmd(remote, 'service ntpd stop && ntpd -qg' ' && service ntpd start')",6,15
openstack%2Ffuel-main~master~Ie0341a72eaaa0ad80033b4680b06b03a1bc3e73e,openstack/fuel-main,master,Ie0341a72eaaa0ad80033b4680b06b03a1bc3e73e,Determine path to ntpd init script using pattern,MERGED,2014-08-07 09:14:16.000000000,2014-08-07 12:43:35.000000000,2014-08-07 12:43:34.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}]","[{'number': 1, 'created': '2014-08-07 09:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f985c5c8c0d9f1fc25891f87413c39add26b6d7d', 'message': ""Determine path to ntpd init script using pattern\n\nIn different linux distros ntpd daemon init script\ncould be named as 'ntp' or 'ntpd', so we should use\npattern to determine the correct path.\n\nChange-Id: Ie0341a72eaaa0ad80033b4680b06b03a1bc3e73e\nCloses-bug: #1353455\n""}, {'number': 2, 'created': '2014-08-07 09:17:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/240694ad47875111092896161f6d9d2fbe61cd4f', 'message': ""Determine path to ntpd init script using pattern\n\nIn different linux distros ntpd daemon init script\ncould be named as 'ntp' or 'ntpd', so we should use\npattern to determine the correct path.\n\nChange-Id: Ie0341a72eaaa0ad80033b4680b06b03a1bc3e73e\nCloses-bug: #1353455\n""}, {'number': 3, 'created': '2014-08-07 09:18:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6293c663b04ad37ab38d1a5f801d4a775ec76859', 'message': ""Determine path to ntpd init script using pattern\n\nIn different linux distros ntpd daemon init script\ncould be named as 'ntp' or 'ntpd', so we should use\npattern to determine the correct path.\n\nChange-Id: Ie0341a72eaaa0ad80033b4680b06b03a1bc3e73e\nCloses-bug: #1353455\n""}, {'number': 4, 'created': '2014-08-07 10:09:56.000000000', 'files': ['fuelweb_test/models/environment.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d4da9b02bdfede50bbc9a9167c3cf4e9891ecba9', 'message': ""Determine path to ntpd init script using pattern\n\nIn different linux distros ntpd daemon init script\ncould be named as 'ntp' or 'ntpd', so we should use\npattern to determine the correct path.\n\nChange-Id: Ie0341a72eaaa0ad80033b4680b06b03a1bc3e73e\nCloses-bug: #1353455\n""}]",0,112525,d4da9b02bdfede50bbc9a9167c3cf4e9891ecba9,26,6,4,11081,,,0,"Determine path to ntpd init script using pattern

In different linux distros ntpd daemon init script
could be named as 'ntp' or 'ntpd', so we should use
pattern to determine the correct path.

Change-Id: Ie0341a72eaaa0ad80033b4680b06b03a1bc3e73e
Closes-bug: #1353455
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/25/112525/4 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/environment.py'],1,f985c5c8c0d9f1fc25891f87413c39add26b6d7d,bug/1353455," self.sync_node_time(self.get_ssh_to_remote(node[""ip""])) self.get_ssh_to_remote_by_name(node.name)) def sync_node_time(self, remote): self.execute_remote_cmd(remote, 'NTPD=(find /etc/init.d/ -regex \'' '/etc/init.d/ntp.?\'); $NTPD stop ' '&& ntpd -qg; $NTPD start')"," self.sync_node_time(self.get_ssh_to_remote(node[""ip""]), bootstrap=True) if re.compile(""ready_with_[0-9]+_slaves"").match(name): bootsrap = True else: bootsrap = False self.get_ssh_to_remote_by_name(node.name), bootsrap) def sync_node_time(self, remote, bootstrap=False): if settings.OPENSTACK_RELEASE_UBUNTU in settings.OPENSTACK_RELEASE \ and not bootstrap: self.execute_remote_cmd(remote, 'service ntp stop && ntpd -qg' ' && service ntp start') else: self.execute_remote_cmd(remote, 'service ntpd stop && ntpd -qg' ' && service ntpd start')",6,15
openstack%2Ftempest~master~Ic14a9aa1ac24a7756e390a4f6e26e3af2952a52d,openstack/tempest,master,Ic14a9aa1ac24a7756e390a4f6e26e3af2952a52d,Add image-list to glance cli help test,MERGED,2014-07-18 11:56:54.000000000,2014-08-07 12:17:12.000000000,2014-08-07 12:17:11.000000000,"[{'_account_id': 3}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7139}, {'_account_id': 7872}, {'_account_id': 8556}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-18 11:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7d52296409df916a6ec62c6277c66fba80bbf247', 'message': ""Add image-list to glance cli help test\n\nIn the glance client, there is 'image-list' that is not deprecated.\nSo this should be added to wanted_commands.\n\nChange-Id: Ic14a9aa1ac24a7756e390a4f6e26e3af2952a52d\n""}, {'number': 2, 'created': '2014-08-06 05:02:14.000000000', 'files': ['tempest/cli/simple_read_only/test_glance.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1d8a9cbe3f790c65f0836e96bc8c7e95bf633ea0', 'message': ""Add image-list to glance cli help test\n\nIn the glance client, there is 'image-list' that is not deprecated.\nSo this should be added to wanted_commands.\n\nChange-Id: Ic14a9aa1ac24a7756e390a4f6e26e3af2952a52d\n""}]",0,107982,1d8a9cbe3f790c65f0836e96bc8c7e95bf633ea0,32,9,2,5689,,,0,"Add image-list to glance cli help test

In the glance client, there is 'image-list' that is not deprecated.
So this should be added to wanted_commands.

Change-Id: Ic14a9aa1ac24a7756e390a4f6e26e3af2952a52d
",git fetch https://review.opendev.org/openstack/tempest refs/changes/82/107982/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cli/simple_read_only/test_glance.py'],1,7d52296409df916a6ec62c6277c66fba80bbf247,image-list-to-glance-cli," 'member-list', 'image-list'))", 'member-list')),1,1
openstack%2Fhorizon~master~I1f558cf7f3198a68629738a011e9cae0c3749320,openstack/horizon,master,I1f558cf7f3198a68629738a011e9cae0c3749320,Rename add_error methods: Django 1.7 conflict,MERGED,2014-08-05 06:51:10.000000000,2014-08-07 12:06:58.000000000,2014-08-07 12:06:57.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 4978}, {'_account_id': 6476}, {'_account_id': 7976}, {'_account_id': 9317}, {'_account_id': 10295}, {'_account_id': 10442}, {'_account_id': 12071}]","[{'number': 1, 'created': '2014-08-05 06:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5e5f33d68733579f3bbb61658992520321419288', 'message': ""Rename add_error methods: Django 1.7 conflict\n\nIn Django 1.7, Forms have an add_error() method and our definition\nwas conflicting with Django's method. Thanks to hertzog@debian.org\nfor the patch.\n\nChange-Id: I1f558cf7f3198a68629738a011e9cae0c3749320\n""}, {'number': 2, 'created': '2014-08-05 14:17:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/49a326f984694dfdf61f1236a67a771d4e538c67', 'message': ""Rename add_error methods: Django 1.7 conflict\n\nIn Django 1.7, Forms have an add_error() method and our definition\nwas conflicting with Django's method. Thanks to hertzog@debian.org\nfor the patch.\n\nRelated-bug: #1352919\nChange-Id: I1f558cf7f3198a68629738a011e9cae0c3749320\n""}, {'number': 3, 'created': '2014-08-07 06:48:11.000000000', 'files': ['horizon/workflows/base.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/04dd1568c1c927901085941124e4c6852183f4f0', 'message': ""Rename add_error methods: Django 1.7 conflict\n\nIn Django 1.7, Forms have an add_error() method and our definition\nwas conflicting with Django's method. Thanks to hertzog@debian.org\nfor the patch.\n\nClose-bug: #1352919\nChange-Id: I1f558cf7f3198a68629738a011e9cae0c3749320\n""}]",1,111930,04dd1568c1c927901085941124e4c6852183f4f0,26,9,3,6476,,,0,"Rename add_error methods: Django 1.7 conflict

In Django 1.7, Forms have an add_error() method and our definition
was conflicting with Django's method. Thanks to hertzog@debian.org
for the patch.

Close-bug: #1352919
Change-Id: I1f558cf7f3198a68629738a011e9cae0c3749320
",git fetch https://review.opendev.org/openstack/horizon refs/changes/30/111930/3 && git format-patch -1 --stdout FETCH_HEAD,['horizon/workflows/base.py'],1,5e5f33d68733579f3bbb61658992520321419288,bug/1352919," def add_action_error(self, message): def add_step_error(self, message): self.action.add_action_error(message) step.add_step_error(message)"," def add_error(self, message): def add_error(self, message): self.action.add_error(message) step.add_error(message)",4,4
openstack%2Fnova~master~I79e55c32b3d0768430132275ebe050f38c63bc87,openstack/nova,master,I79e55c32b3d0768430132275ebe050f38c63bc87,Don't mask out HostState details in WeighedHost,MERGED,2014-07-14 03:40:34.000000000,2014-08-07 12:06:27.000000000,2014-08-07 12:06:25.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1561}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6062}, {'_account_id': 7166}, {'_account_id': 7461}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-14 03:40:34.000000000', 'files': ['nova/scheduler/weights/__init__.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/97b667d651b6ed543c6a11955b05fb5e2c5d0b49', 'message': ""Don't mask out HostState details in WeighedHost\n\nWeighedHost's __repr__ was poking under the HostState hood to use\n.host in its own __repr__ but this hides some important details.\nSpecifically it hides the hypervisor_hostname, which is important for\nIronic as one 'node' can have thousands of hostnames. The other\ndetails such as available RAM and so on are also useful for ops trying\nto debug scheduling issues, so rather than add hypervisor_hostname, I\nam just delegating to the underlying __repr__.\n\nChange-Id: I79e55c32b3d0768430132275ebe050f38c63bc87\n""}]",0,106676,97b667d651b6ed543c6a11955b05fb5e2c5d0b49,53,13,1,4190,,,0,"Don't mask out HostState details in WeighedHost

WeighedHost's __repr__ was poking under the HostState hood to use
.host in its own __repr__ but this hides some important details.
Specifically it hides the hypervisor_hostname, which is important for
Ironic as one 'node' can have thousands of hostnames. The other
details such as available RAM and so on are also useful for ops trying
to debug scheduling issues, so rather than add hypervisor_hostname, I
am just delegating to the underlying __repr__.

Change-Id: I79e55c32b3d0768430132275ebe050f38c63bc87
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/106676/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/weights/__init__.py'],1,97b667d651b6ed543c6a11955b05fb5e2c5d0b49,," return ""WeighedHost [host: %r, weight: %s]"" % ( self.obj, self.weight)"," return ""WeighedHost [host: %s, weight: %s]"" % ( self.obj.host, self.weight)",2,2
openstack%2Fpython-ceilometerclient~master~I0e027c33ee42b6de032d33269caeea33e7837f40,openstack/python-ceilometerclient,master,I0e027c33ee42b6de032d33269caeea33e7837f40,Use HTTPClient from common Oslo code,MERGED,2014-01-24 15:35:34.000000000,2014-08-07 12:05:00.000000000,2014-08-07 12:05:00.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7729}, {'_account_id': 7763}, {'_account_id': 8041}, {'_account_id': 8334}, {'_account_id': 8871}, {'_account_id': 9545}, {'_account_id': 9550}]","[{'number': 1, 'created': '2014-01-24 15:35:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/23ea03349713dca5d0237e4b3cab01c8c8e07325', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: I0e027c33ee42b6de032d33269caeea33e7837f40\n'}, {'number': 2, 'created': '2014-01-27 12:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/9607ed0e88ff940958b78c3d4a536672e9c6b274', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: I0e027c33ee42b6de032d33269caeea33e7837f40\n'}, {'number': 3, 'created': '2014-01-29 10:50:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/eb6a0afae367597a2babab1e92c7fa8208ac50e1', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: I0e027c33ee42b6de032d33269caeea33e7837f40\n'}, {'number': 4, 'created': '2014-01-29 16:26:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/5d451e429aa27fc95bbe294096e0d6df51573ea8', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: I0e027c33ee42b6de032d33269caeea33e7837f40\n'}, {'number': 5, 'created': '2014-02-04 13:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/629c56a29429deb0bb9c50951375fe724fb79e23', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: I0e027c33ee42b6de032d33269caeea33e7837f40\n'}, {'number': 6, 'created': '2014-02-21 13:34:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/4542656df759979ec2d9f2a22e3304d103f5a57c', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: I0e027c33ee42b6de032d33269caeea33e7837f40\n'}, {'number': 7, 'created': '2014-05-08 16:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/8fa4ee61805d6a23ab4ad25a96602a1aa15a70c6', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: I0e027c33ee42b6de032d33269caeea33e7837f40\n'}, {'number': 8, 'created': '2014-05-13 13:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/163c29713648afa4decd8fa3859910616770e6a2', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: I0e027c33ee42b6de032d33269caeea33e7837f40\n'}, {'number': 9, 'created': '2014-05-19 17:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/1dde0802ceb219e30ca2fc1d253858b9982ccf63', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: I0e027c33ee42b6de032d33269caeea33e7837f40\n'}, {'number': 10, 'created': '2014-05-26 16:14:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/77d38243045f60d9547d23eaff002d9b9b949f35', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: I0e027c33ee42b6de032d33269caeea33e7837f40\n'}, {'number': 11, 'created': '2014-06-06 09:36:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/927eaf1b1d1d03fc0e166f27b5ecd91e63611394', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: I0e027c33ee42b6de032d33269caeea33e7837f40\n'}, {'number': 12, 'created': '2014-06-10 13:48:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/cdca06f4f1fa0805c22a283133ae22893797cd4f', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: I0e027c33ee42b6de032d33269caeea33e7837f40\n'}, {'number': 13, 'created': '2014-06-23 14:40:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/0c28887647a9453933c85eec27e2d64aa51eb163', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: I0e027c33ee42b6de032d33269caeea33e7837f40\n'}, {'number': 14, 'created': '2014-06-23 15:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/54c571ea88542d28358c12f8568ce4a855059262', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: I0e027c33ee42b6de032d33269caeea33e7837f40\n'}, {'number': 15, 'created': '2014-07-30 15:21:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/35d12633c22744c7b2132f4d57013d6d5e83b258', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: I0e027c33ee42b6de032d33269caeea33e7837f40\n'}, {'number': 16, 'created': '2014-07-31 11:33:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/34ed8600a9fdd6fc5e25b3566e83e1a85ad47a0f', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: I0e027c33ee42b6de032d33269caeea33e7837f40\n'}, {'number': 17, 'created': '2014-07-31 16:00:09.000000000', 'files': ['ceilometerclient/v1/client.py', 'ceilometerclient/tests/v2/test_options.py', 'ceilometerclient/common/base.py', 'ceilometerclient/tests/v2/test_alarms.py', 'ceilometerclient/tests/v2/test_samples.py', 'ceilometerclient/tests/v1/test_meters.py', 'ceilometerclient/tests/v1/test_resources.py', 'ceilometerclient/tests/v2/test_query_samples.py', 'ceilometerclient/tests/test_http.py', 'requirements.txt', 'ceilometerclient/common/http.py', 'ceilometerclient/client.py', 'ceilometerclient/tests/v1/test_users.py', 'ceilometerclient/tests/utils.py', 'ceilometerclient/tests/v2/test_events.py', 'ceilometerclient/v2/client.py', 'ceilometerclient/tests/v2/test_resources.py', 'ceilometerclient/tests/v2/test_query_alarm_history.py', 'ceilometerclient/v2/query.py', 'ceilometerclient/tests/test_shell.py', 'ceilometerclient/tests/v2/test_traits.py', 'ceilometerclient/tests/test_client.py', 'ceilometerclient/tests/v2/test_statistics.py', 'ceilometerclient/v2/alarms.py', 'ceilometerclient/shell.py', 'ceilometerclient/tests/v2/test_trait_descriptions.py', 'ceilometerclient/tests/v2/test_query_alarms.py', 'ceilometerclient/v2/samples.py', 'ceilometerclient/tests/v2/test_event_types.py', 'ceilometerclient/tests/v1/test_projects.py', 'ceilometerclient/tests/v1/test_samples.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/47934c777c50897b649793e0960eebdaad322c45', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: I0e027c33ee42b6de032d33269caeea33e7837f40\n'}]",42,68939,47934c777c50897b649793e0960eebdaad322c45,156,13,17,9550,,,0,"Use HTTPClient from common Oslo code

In the process of unification of the clients code we should
reuse common functionality from Oslo.

bp common-client-library-2

Change-Id: I0e027c33ee42b6de032d33269caeea33e7837f40
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/39/68939/17 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometerclient/v1/client.py', 'ceilometerclient/tests/v2/test_options.py', 'ceilometerclient/common/base.py', 'ceilometerclient/tests/v2/test_alarms.py', 'ceilometerclient/tests/v2/test_samples.py', 'ceilometerclient/tests/v1/test_meters.py', 'ceilometerclient/tests/v1/test_resources.py', 'ceilometerclient/tests/test_http.py', 'requirements.txt', 'ceilometerclient/common/http.py', 'ceilometerclient/client.py', 'ceilometerclient/tests/v1/test_users.py', 'ceilometerclient/tests/utils.py', 'ceilometerclient/tests/v2/test_events.py', 'ceilometerclient/v2/client.py', 'ceilometerclient/tests/v2/test_resources.py', 'ceilometerclient/openstack/common/apiclient/client.py', 'ceilometerclient/tests/test_shell.py', 'ceilometerclient/tests/v2/test_traits.py', 'ceilometerclient/tests/v2/test_statistics.py', 'ceilometerclient/v2/alarms.py', 'ceilometerclient/shell.py', 'ceilometerclient/tests/v2/test_trait_descriptions.py', 'ceilometerclient/v2/samples.py', 'ceilometerclient/tests/v2/test_event_types.py', 'ceilometerclient/tests/v1/test_projects.py', 'ceilometerclient/tests/v1/test_samples.py']",27,23ea03349713dca5d0237e4b3cab01c8c8e07325,bp/common-client-library-2,"from ceilometerclient.openstack.common.apiclient import client from ceilometerclient.openstack.common.apiclient import fake_client self.http_client = fake_client.FakeHTTPClient(fixtures=fixtures) self.api = client.BaseClient(self.http_client) 'GET', '/v1/meters' self.http_client.assert_called(*expect) 'GET', '/v1/sources/openstack/meters/this' self.http_client.assert_called(*expect) 'GET', '/v1/users/freddy/meters/balls' self.http_client.assert_called(*expect) 'GET', '/v1/projects/dig_the_ditch/meters/meters' self.http_client.assert_called(*expect) 'GET', '/v1/meters?metadata.zxc_id=foo' self.http_client.assert_called(*expect) 'GET', '/v1/users/freddy/meters/balls?' + 'start_timestamp=now&end_timestamp=now' self.http_client.assert_called(*expect)"," self.api = utils.FakeAPI(fixtures) ('GET', '/v1/meters', {}, None), self.assertEqual(self.api.calls, expect) ('GET', '/v1/sources/openstack/meters/this', {}, None), self.assertEqual(self.api.calls, expect) ('GET', '/v1/users/freddy/meters/balls', {}, None), self.assertEqual(self.api.calls, expect) ('GET', '/v1/projects/dig_the_ditch/meters/meters', {}, None), self.assertEqual(self.api.calls, expect) ('GET', '/v1/meters?metadata.zxc_id=foo', {}, None), self.assertEqual(self.api.calls, expect) ('GET', '/v1/users/freddy/meters/balls?' + 'start_timestamp=now&end_timestamp=now', {}, None), self.assertEqual(self.api.calls, expect)",312,726
openstack%2Ffuel-library~stable%2F5.0~I30a1dd556bd60cc6067c52eba5881efc20906f83,openstack/fuel-library,stable/5.0,I30a1dd556bd60cc6067c52eba5881efc20906f83,Provide oslo.messaging debug logs for Nova,ABANDONED,2014-08-04 17:04:50.000000000,2014-08-07 12:00:45.000000000,,"[{'_account_id': 3}, {'_account_id': 6849}, {'_account_id': 7225}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-08-04 17:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bf3af8016a3bf04f3cca299a335bd4cdf5231382', 'message': 'Provide oslo.messaging debug logs for Nova\n\nConfigure oslo.messaging logger for Nova\nto provide debug messages in order to better\ntroubleshooting RPC dialogs after HA failover\n\nRelated-bug: #1340711\n\nChange-Id: I30a1dd556bd60cc6067c52eba5881efc20906f83\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 2, 'created': '2014-08-05 09:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c1de0420f0c68233d3a0456a79bd7fc487efa462', 'message': 'Provide oslo.messaging debug logs for Nova\n\n* Configure oslo.messaging logger for Nova\nto provide debug messages in order to better\ntroubleshooting RPC dialogs after HA failover\n* Use defaults for other libs\n\nRelated-bug: #1340711\n\nChange-Id: I30a1dd556bd60cc6067c52eba5881efc20906f83\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 3, 'created': '2014-08-05 11:02:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b2c2bbca891ab23c587ce0e0a4fe8638e740607e', 'message': 'Provide oslo.messaging debug logs for Nova\n\n* Configure oslo.messaging logger for Nova\nto provide debug messages in order to better\ntroubleshooting RPC dialogs after HA failover\n* Use defaults for other libs.\n\nRelated-bug: #1340711\n\nChange-Id: I30a1dd556bd60cc6067c52eba5881efc20906f83\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 4, 'created': '2014-08-07 09:52:45.000000000', 'files': ['deployment/puppet/osnailyfacter/manifests/cluster_ha.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1d8e5ed478acca98ce9641f4eb531d9d92d764c3', 'message': 'Provide oslo.messaging debug logs for Nova\n\n* Configure oslo.messaging logger for Nova\nto provide debug messages in order to better\ntroubleshooting RPC dialogs after HA failover\n* Use defaults for other libs\n\nRelated-bug: #1340711\n\nChange-Id: I30a1dd556bd60cc6067c52eba5881efc20906f83\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",1,111776,1d8e5ed478acca98ce9641f4eb531d9d92d764c3,30,6,4,6926,,,0,"Provide oslo.messaging debug logs for Nova

* Configure oslo.messaging logger for Nova
to provide debug messages in order to better
troubleshooting RPC dialogs after HA failover
* Use defaults for other libs

Related-bug: #1340711

Change-Id: I30a1dd556bd60cc6067c52eba5881efc20906f83
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/76/111776/3 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/manifests/cluster_ha.pp'],1,bf3af8016a3bf04f3cca299a335bd4cdf5231382,related1340711_5.0, if ($::debug) { nova_config { 'DEFAULT/default_log_levels': value => 'oslo.messaging=DEBUG' } },,3,0
openstack%2Ffuel-library~master~I30a1dd556bd60cc6067c52eba5881efc20906f83,openstack/fuel-library,master,I30a1dd556bd60cc6067c52eba5881efc20906f83,Provide oslo.messaging debug logs for Nova,ABANDONED,2014-08-04 17:03:07.000000000,2014-08-07 12:00:32.000000000,,"[{'_account_id': 3}, {'_account_id': 6849}, {'_account_id': 7225}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-08-04 17:03:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0cc5768fe0fa624df673e2ccc52c3714dce4b9e9', 'message': 'Provide oslo.messaging debug logs for Nova\n\nConfigure oslo.messaging logger for Nova\nto provide debug messages in order to better\ntroubleshooting RPC dialogs after HA failover\n\nRelated-bug: #1340711\n\nChange-Id: I30a1dd556bd60cc6067c52eba5881efc20906f83\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 2, 'created': '2014-08-05 09:15:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4e96b845e0b16715bc01911430a5325a57319005', 'message': 'Provide oslo.messaging debug logs for Nova\n\n* Configure oslo.messaging logger for Nova\nto provide debug messages in order to better\ntroubleshooting RPC dialogs after HA failover\n* Use defaults for other libs\n\nRelated-bug: #1340711\n\nChange-Id: I30a1dd556bd60cc6067c52eba5881efc20906f83\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 3, 'created': '2014-08-05 11:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d809dd3bc1de6b7eba636a5c5cac0d3ca9bcb25f', 'message': 'Provide oslo.messaging debug logs for Nova\n\n* Configure oslo.messaging logger for Nova\nto provide debug messages in order to better\ntroubleshooting RPC dialogs after HA failover\n* Use defaults for other libs.\n\nRelated-bug: #1340711\n\nChange-Id: I30a1dd556bd60cc6067c52eba5881efc20906f83\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 4, 'created': '2014-08-07 09:52:31.000000000', 'files': ['deployment/puppet/osnailyfacter/manifests/cluster_ha.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4a336750d86ab4cb5cfeaa6d488f5e4b966926c2', 'message': 'Provide oslo.messaging debug logs for Nova\n\n* Configure oslo.messaging logger for Nova\nto provide debug messages in order to better\ntroubleshooting RPC dialogs after HA failover\n* Use defaults for other libs\n\nRelated-bug: #1340711\n\nChange-Id: I30a1dd556bd60cc6067c52eba5881efc20906f83\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",1,111775,4a336750d86ab4cb5cfeaa6d488f5e4b966926c2,32,6,4,6926,,,0,"Provide oslo.messaging debug logs for Nova

* Configure oslo.messaging logger for Nova
to provide debug messages in order to better
troubleshooting RPC dialogs after HA failover
* Use defaults for other libs

Related-bug: #1340711

Change-Id: I30a1dd556bd60cc6067c52eba5881efc20906f83
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/75/111775/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/manifests/cluster_ha.pp'],1,0cc5768fe0fa624df673e2ccc52c3714dce4b9e9,related1340711, if ($::debug) { nova_config { 'DEFAULT/default_log_levels': value => 'oslo.messaging=DEBUG' } },,3,0
openstack%2Fneutron~master~I6327c8f44ff022f4f87a11bc0d6cb88bed2aa785,openstack/neutron,master,I6327c8f44ff022f4f87a11bc0d6cb88bed2aa785,(DON'T MERGE) Squash DVR commits together Add L3 Extension for Distributed Routers,ABANDONED,2014-07-09 20:18:54.000000000,2014-08-07 11:35:11.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 7016}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-07-09 20:18:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/03137b3baed09b7c819ee8266defea7d2c3fa4d4', 'message': ""(DON'T MERGE) Squash DVR commits together\n\nAdd L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n\nL2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n\nRPC additions to support DVR\n\nThis patch introduces the RPC contract changes\nrequired for both the server (plugin) and agent\nto propagate and retrieve additional information\nabout Distributed Routers, like MAC addresses\nand Port Bindings.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n\nML2 additions to support DVR\n\nThis patch introduces the changes necessary to\nsupport DVR at Layer 2 with ML2, and L2pop.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nAdd L3 Scheduler Changes for Distributed Routers\n\nThis patch implements the L3 Scheduler changes for the\nDistributed Virtual Routers.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nCo-Authored-By: Carl Baldwin <carl.baldwin@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n\nModify L3 Agent for Distributed Routers\n\nThis patch is an enhancement to the existing L3 Agent.\nThis allows the L3 Agent to support distributed routers\nby enhancing the router object to function across\nmultiple nodes.\n\nUtilized two new types of namespaces:\n\n- FIP to handle multiple VM fips and routers per node\n- SNAT to handle centralized SNAT per router\n\nRules and tables are enhanced and added to support routing\nacross distributed routers without going to a centralized\nrouter.\n\nFinally, a new configuration param 'agent_mode' is introduced\nand it controls what the L3 agent can do: the available values\nare: 'legacy', 'dvr', 'dvr_snat' (more details inline).\n\nThe l3-scheduler uses the newly introduced agent_mode to\ndetermine what L3 agent to select during the scheduling\nprocess.\n\nPartially-Implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nCo-Authored-By: Rajeev Grover <rajeev.grover@hp.com>\n\nL2 Agent-side additions to support DVR\n\nThis patch introduces changes to the L2 agent, whereby the L2 agent\nrelies on a DVR component that takes care of the port wiring and the\nmanagement of tunnels in face of topology changes due to the life\ncycles or VM's as well as the life cycles of distributed virtual\nrouters.\n\nSupport for DVR needs to be explicitly enabled. Default behavior\nremains unchanged.\n\nChange-Id: I6327c8f44ff022f4f87a11bc0d6cb88bed2aa785\nPartially-implements: blueprint neutron-ovs-dvr\n""}, {'number': 2, 'created': '2014-07-10 14:48:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/015fd1cc9250064dcfece996f32f7990ff648b75', 'message': ""(DON'T MERGE) Squash DVR commits together\nAdd L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n\nL2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n\nRPC additions to support DVR\n\nThis patch introduces the RPC contract changes\nrequired for both the server (plugin) and agent\nto propagate and retrieve additional information\nabout Distributed Routers, like MAC addresses\nand Port Bindings.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n\nML2 additions to support DVR\n\nThis patch introduces the changes necessary to\nsupport DVR at Layer 2 with ML2, and L2pop.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nAdd L3 Scheduler Changes for Distributed Routers\n\nThis patch implements the L3 Scheduler changes for the\nDistributed Virtual Routers.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nCo-Authored-By: Carl Baldwin <carl.baldwin@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n\nL2 Agent-side additions to support DVR\n\nThis patch introduces changes to the L2 agent, whereby the L2 agent\nrelies on a DVR component that takes care of the port wiring and the\nmanagement of tunnels in face of topology changes due to the life\ncycles or VM's as well as the life cycles of distributed virtual\nrouters.\n\nSupport for DVR needs to be explicitly enabled. Default behavior\nremains unchanged.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nModify L3 Agent for Distributed Routers\n\nThis patch is an enhancement to the existing L3 Agent.\nThis allows the L3 Agent to support distributed routers\nby enhancing the router object to function across\nmultiple nodes.\n\nUtilized two new types of namespaces:\n\n- FIP to handle multiple VM fips and routers per node\n- SNAT to handle centralized SNAT per router\n\nRules and tables are enhanced and added to support routing\nacross distributed routers without going to a centralized\nrouter.\n\nFinally, a new configuration param 'agent_mode' is introduced\nand it controls what the L3 agent can do: the available values\nare: 'legacy', 'dvr', 'dvr_snat' (more details inline).\n\nThe l3-scheduler uses the newly introduced agent_mode to\ndetermine what L3 agent to select during the scheduling\nprocess.\n\nPartially-Implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nCo-Authored-By: Rajeev Grover <rajeev.grover@hp.com>\n\nImplement migration of legacy routers to distributed\n\nFor now, this is a place-holder only.  I will be getting to this soon.\n\nChange-Id: I6327c8f44ff022f4f87a11bc0d6cb88bed2aa785\nPartially-implements: blueprint neutron-ovs-dvr\n""}, {'number': 3, 'created': '2014-07-10 16:03:25.000000000', 'files': ['neutron/tests/unit/db/test_l3_dvr_db.py', 'neutron/db/migration/alembic_migrations/versions/2026156eab2f_l2_dvr_models.py', 'neutron/db/l3_gwmode_db.py', 'neutron/db/l3_dvr_db.py', 'etc/l3_agent.ini', 'neutron/agent/l3_agent.py', 'neutron/common/utils.py', 'neutron/tests/unit/ml2/test_rpcapi.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/services/vpn/test_vpn_agent.py', 'neutron/tests/unit/openvswitch/test_ovs_rpcapi.py', 'neutron/plugins/ml2/db.py', 'neutron/tests/unit/openvswitch/test_ovs_tunnel.py', 'etc/policy.json', 'neutron/plugins/ml2/rpc.py', 'neutron/tests/unit/openvswitch/test_ovs_neutron_agent.py', 'etc/neutron.conf', 'neutron/db/l3_db.py', 'neutron/db/l3_attrs_db.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/agent/rpc.py', 'neutron/plugins/ml2/drivers/l2pop/db.py', 'neutron/common/constants.py', 'neutron/db/l3_dvrscheduler_db.py', 'neutron/plugins/nec/nec_router.py', 'neutron/plugins/openvswitch/agent/ovs_dvr_neutron_agent.py', 'neutron/plugins/openvswitch/common/constants.py', 'neutron/tests/unit/ml2/db/__init__.py', 'neutron/api/v2/attributes.py', 'neutron/db/l3_rpc_base.py', 'neutron/tests/unit/mlnx/test_rpcapi.py', 'neutron/common/topics.py', 'neutron/extensions/l3agentscheduler.py', 'neutron/tests/unit/hyperv/test_hyperv_rpcapi.py', 'neutron/tests/unit/ml2/db/test_ml2_dvr_db.py', 'neutron/db/l3_agentschedulers_db.py', 'neutron/tests/unit/linuxbridge/test_rpcapi.py', 'neutron/plugins/ml2/drivers/l2pop/mech_driver.py', 'neutron/plugins/openvswitch/common/config.py', 'neutron/tests/unit/vmware/test_nsx_plugin.py', 'etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini', 'neutron/db/migration/alembic_migrations/versions/5589aa32bf80_l3_dvr_scheduler.py', 'neutron/plugins/ml2/plugin.py', 'neutron/db/migration/alembic_migrations/versions/3927f7f7c456_l3_extension_distributed_mode.py', 'neutron/plugins/ml2/driver_api.py', 'neutron/tests/unit/test_extension_ext_gw_mode.py', 'neutron/tests/unit/db/test_dvr_mac_db.py', 'neutron/tests/unit/ml2/_test_mech_agent.py', 'neutron/api/rpc/dvr_rpc.py', 'neutron/scheduler/l3_agent_scheduler.py', 'neutron/api/rpc/agentnotifiers/l3_rpc_agent_api.py', 'neutron/tests/unit/test_l3_agent.py', 'neutron/tests/unit/ofagent/test_ofa_neutron_agent.py', 'neutron/tests/unit/test_l3_plugin.py', 'neutron/plugins/ml2/driver_context.py', 'neutron/tests/unit/ml2/drivers/test_l2population.py', 'neutron/db/dvr_mac_db.py', 'neutron/plugins/ml2/models.py', 'neutron/extensions/dvr.py', 'neutron/services/l3_router/l3_router_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/103d5f6e0f2e21aaf04d4ca99fde340d69afda72', 'message': ""(DON'T MERGE) Squash DVR commits together\nAdd L3 Extension for Distributed Routers\n\nThis patch introduces the model and extension\nframework for implementing distributed virtual\nrouting on top of Open vSwitch.\n\nA new admin-only 'distributed' (as opposed to a\n'centralized' or legacy-mode) attribute is added\nto the API router resource. It is possible to convert\nan existing (centralized) router to a distributed\none; the opposite conversion, even though allowed by\nthe API, may not be honored by the underlying\nplugin implementation and an appropriate error will\nbe reported.\n\nWhen creating a router (regardless of the user role),\nNeutron will rely on a system wide configuration, whose\ndefault currently allows to create 'centralized' routers.\n\nTests are added for basic unit coverage; when the first\nbuilding blocks for neutron-testing-refactor\nare complete, functional testing will be added.\nThis is because we should be moving away from how\nextension tests have been done up until now.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nAuthored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n\nL2 Model additions to support DVR\n\nThis patch introduces the models, the DB migrations\nand the config options required by the L2 layer to\nsupport DVR east/west traffic.\n\nThese changes will be used by the control-plane made\nof ML2, L2pop and L2 agent.\n\nTwo new configuration options have been introduced:\n'dvr_base_mac' is used to set DVR MAC addresses apart\nfrom tenant ones (every distributed router will have\nports being created on compute hosts) and\n'enable_distributed_routing' is used to enable dvr\nsupport in the L2 agent. This gives the capability of\nrolling out the dvr functionality in stages.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n\nRPC additions to support DVR\n\nThis patch introduces the RPC contract changes\nrequired for both the server (plugin) and agent\nto propagate and retrieve additional information\nabout Distributed Routers, like MAC addresses\nand Port Bindings.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nAuthored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n\nML2 additions to support DVR\n\nThis patch introduces the changes necessary to\nsupport DVR at Layer 2 with ML2, and L2pop.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nAdd L3 Scheduler Changes for Distributed Routers\n\nThis patch implements the L3 Scheduler changes for the\nDistributed Virtual Routers.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nCo-Authored-By: Carl Baldwin <carl.baldwin@hp.com>\nCo-Authored-By: Armando Migliaccio <armamig@gmail.com>\n\nModify L3 Agent for Distributed Routers\n\nThis patch is an enhancement to the existing L3 Agent.\nThis allows the L3 Agent to support distributed routers\nby enhancing the router object to function across\nmultiple nodes.\n\nUtilized two new types of namespaces:\n\n- FIP to handle multiple VM fips and routers per node\n- SNAT to handle centralized SNAT per router\n\nRules and tables are enhanced and added to support routing\nacross distributed routers without going to a centralized\nrouter.\n\nFinally, a new configuration param 'agent_mode' is introduced\nand it controls what the L3 agent can do: the available values\nare: 'legacy', 'dvr', 'dvr_snat' (more details inline).\n\nThe l3-scheduler uses the newly introduced agent_mode to\ndetermine what L3 agent to select during the scheduling\nprocess.\n\nPartially-Implements: blueprint neutron-ovs-dvr\n\nDocImpact\n\nCo-Authored-By: Rajeev Grover <rajeev.grover@hp.com>\n\nL2 Agent-side additions to support DVR\n\nThis patch introduces changes to the L2 agent, whereby the L2 agent\nrelies on a DVR component that takes care of the port wiring and the\nmanagement of tunnels in face of topology changes due to the life\ncycles or VM's as well as the life cycles of distributed virtual\nrouters.\n\nSupport for DVR needs to be explicitly enabled. Default behavior\nremains unchanged.\n\nPartially-implements: blueprint neutron-ovs-dvr\n\nChange-Id: I6327c8f44ff022f4f87a11bc0d6cb88bed2aa785\n""}]",0,105864,103d5f6e0f2e21aaf04d4ca99fde340d69afda72,49,18,3,6788,,,0,"(DON'T MERGE) Squash DVR commits together
Add L3 Extension for Distributed Routers

This patch introduces the model and extension
framework for implementing distributed virtual
routing on top of Open vSwitch.

A new admin-only 'distributed' (as opposed to a
'centralized' or legacy-mode) attribute is added
to the API router resource. It is possible to convert
an existing (centralized) router to a distributed
one; the opposite conversion, even though allowed by
the API, may not be honored by the underlying
plugin implementation and an appropriate error will
be reported.

When creating a router (regardless of the user role),
Neutron will rely on a system wide configuration, whose
default currently allows to create 'centralized' routers.

Tests are added for basic unit coverage; when the first
building blocks for neutron-testing-refactor
are complete, functional testing will be added.
This is because we should be moving away from how
extension tests have been done up until now.

Partially-implements: blueprint neutron-ovs-dvr

DocImpact

Authored-by:    Swaminathan Vasudevan <swaminathan.vasudevan@hp.com>
Co-Authored-By: Armando Migliaccio <armamig@gmail.com>

L2 Model additions to support DVR

This patch introduces the models, the DB migrations
and the config options required by the L2 layer to
support DVR east/west traffic.

These changes will be used by the control-plane made
of ML2, L2pop and L2 agent.

Two new configuration options have been introduced:
'dvr_base_mac' is used to set DVR MAC addresses apart
from tenant ones (every distributed router will have
ports being created on compute hosts) and
'enable_distributed_routing' is used to enable dvr
support in the L2 agent. This gives the capability of
rolling out the dvr functionality in stages.

Partially-implements: blueprint neutron-ovs-dvr

DocImpact

Authored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>
Co-Authored-By: Armando Migliaccio <armamig@gmail.com>

RPC additions to support DVR

This patch introduces the RPC contract changes
required for both the server (plugin) and agent
to propagate and retrieve additional information
about Distributed Routers, like MAC addresses
and Port Bindings.

Partially-implements: blueprint neutron-ovs-dvr

Authored-by: Vivekanandan Narasimhan <vivekanandan.narasimhan@hp.com>
Co-Authored-By: Armando Migliaccio <armamig@gmail.com>

ML2 additions to support DVR

This patch introduces the changes necessary to
support DVR at Layer 2 with ML2, and L2pop.

Partially-implements: blueprint neutron-ovs-dvr

Add L3 Scheduler Changes for Distributed Routers

This patch implements the L3 Scheduler changes for the
Distributed Virtual Routers.

Partially-implements: blueprint neutron-ovs-dvr

Co-Authored-By: Carl Baldwin <carl.baldwin@hp.com>
Co-Authored-By: Armando Migliaccio <armamig@gmail.com>

Modify L3 Agent for Distributed Routers

This patch is an enhancement to the existing L3 Agent.
This allows the L3 Agent to support distributed routers
by enhancing the router object to function across
multiple nodes.

Utilized two new types of namespaces:

- FIP to handle multiple VM fips and routers per node
- SNAT to handle centralized SNAT per router

Rules and tables are enhanced and added to support routing
across distributed routers without going to a centralized
router.

Finally, a new configuration param 'agent_mode' is introduced
and it controls what the L3 agent can do: the available values
are: 'legacy', 'dvr', 'dvr_snat' (more details inline).

The l3-scheduler uses the newly introduced agent_mode to
determine what L3 agent to select during the scheduling
process.

Partially-Implements: blueprint neutron-ovs-dvr

DocImpact

Co-Authored-By: Rajeev Grover <rajeev.grover@hp.com>

L2 Agent-side additions to support DVR

This patch introduces changes to the L2 agent, whereby the L2 agent
relies on a DVR component that takes care of the port wiring and the
management of tunnels in face of topology changes due to the life
cycles or VM's as well as the life cycles of distributed virtual
routers.

Support for DVR needs to be explicitly enabled. Default behavior
remains unchanged.

Partially-implements: blueprint neutron-ovs-dvr

Change-Id: I6327c8f44ff022f4f87a11bc0d6cb88bed2aa785
",git fetch https://review.opendev.org/openstack/neutron refs/changes/64/105864/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/db/test_l3_dvr_db.py', 'neutron/db/migration/alembic_migrations/versions/2026156eab2f_l2_dvr_models.py', 'neutron/db/l3_gwmode_db.py', 'neutron/db/l3_dvr_db.py', 'etc/l3_agent.ini', 'neutron/agent/l3_agent.py', 'neutron/common/utils.py', 'neutron/tests/unit/ml2/test_rpcapi.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/services/vpn/test_vpn_agent.py', 'neutron/tests/unit/openvswitch/test_ovs_rpcapi.py', 'neutron/plugins/ml2/db.py', 'neutron/tests/unit/openvswitch/test_ovs_tunnel.py', 'etc/policy.json', 'neutron/plugins/ml2/rpc.py', 'neutron/tests/unit/openvswitch/test_ovs_neutron_agent.py', 'etc/neutron.conf', 'neutron/db/l3_db.py', 'neutron/db/l3_attrs_db.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/agent/rpc.py', 'neutron/plugins/ml2/drivers/l2pop/db.py', 'neutron/common/constants.py', 'neutron/db/l3_dvrscheduler_db.py', 'neutron/plugins/nec/nec_router.py', 'neutron/plugins/openvswitch/agent/ovs_dvr_neutron_agent.py', 'neutron/plugins/openvswitch/common/constants.py', 'neutron/tests/unit/ml2/db/__init__.py', 'neutron/api/v2/attributes.py', 'neutron/db/l3_rpc_base.py', 'neutron/tests/unit/mlnx/test_rpcapi.py', 'neutron/common/topics.py', 'neutron/extensions/l3agentscheduler.py', 'neutron/tests/unit/hyperv/test_hyperv_rpcapi.py', 'neutron/tests/unit/ml2/db/test_ml2_dvr_db.py', 'neutron/db/l3_agentschedulers_db.py', 'neutron/tests/unit/linuxbridge/test_rpcapi.py', 'neutron/plugins/ml2/drivers/l2pop/mech_driver.py', 'neutron/plugins/openvswitch/common/config.py', 'etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini', 'neutron/db/migration/alembic_migrations/versions/5589aa32bf80_l3_dvr_scheduler.py', 'neutron/plugins/ml2/plugin.py', 'neutron/db/migration/alembic_migrations/versions/3927f7f7c456_l3_extension_distributed_mode.py', 'neutron/plugins/ml2/driver_api.py', 'neutron/tests/unit/test_extension_ext_gw_mode.py', 'neutron/tests/unit/db/test_dvr_mac_db.py', 'neutron/tests/unit/ml2/_test_mech_agent.py', 'neutron/api/rpc/dvr_rpc.py', 'neutron/scheduler/l3_agent_scheduler.py', 'neutron/api/rpc/agentnotifiers/l3_rpc_agent_api.py', 'neutron/tests/unit/test_l3_agent.py', 'neutron/tests/unit/ofagent/test_ofa_neutron_agent.py', 'neutron/plugins/ml2/driver_context.py', 'neutron/tests/unit/ml2/drivers/test_l2population.py', 'neutron/db/dvr_mac_db.py', 'neutron/plugins/ml2/models.py', 'neutron/extensions/dvr.py', 'neutron/services/l3_router/l3_router_plugin.py']",58,03137b3baed09b7c819ee8266defea7d2c3fa4d4,up-master,"from neutron.db import l3_dvr_db RPC_API_VERSION = '1.2' # history # 1.2 Added methods for DVR support l3_dvr_db.L3_NAT_with_dvr_db_mixin, l3_db.L3_NAT_db_mixin, l3_dvr_db.L3_NAT_with_dvr_db_mixin, and extraroute_db.ExtraRoute_db_mixin. supported_extension_aliases = [""dvr"", ""router"", ""ext-gw-mode"","," RPC_API_VERSION = '1.1' l3_db.L3_NAT_db_mixin and extraroute_db.ExtraRoute_db_mixin. supported_extension_aliases = [""router"", ""ext-gw-mode"",",5082,343
openstack%2Fneutron~master~I76d93e0f32f661064afaac8014b87c14fa2cb96b,openstack/neutron,master,I76d93e0f32f661064afaac8014b87c14fa2cb96b,(DON'T MERGE) Hard code config defaults to use DVR,ABANDONED,2014-07-09 20:00:55.000000000,2014-08-07 11:34:55.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-07-09 20:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a2895cb38cd1e20ed9b825bb97b6b42a6a7885ab', 'message': ""(DON'T MERGE) Hard code config defaults to use DVR\n\nThis is a commit for testing, do not merge.\n\nChange-Id: I76d93e0f32f661064afaac8014b87c14fa2cb96b\n""}, {'number': 2, 'created': '2014-07-09 20:20:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/23e3a0787258895e0fc3db4b6182ece99ceb4622', 'message': ""(DON'T MERGE) Hard code config defaults to use DVR\n\nThis is a commit for testing, do not merge.\n\nChange-Id: I76d93e0f32f661064afaac8014b87c14fa2cb96b\n""}, {'number': 3, 'created': '2014-07-10 14:48:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7c92b52f0656ba77a1828a997e0bb62e7aa9c2ee', 'message': ""(DON'T MERGE) Hard code config defaults to use DVR\n\nThis is a commit for testing, do not merge.\n\nChange-Id: I76d93e0f32f661064afaac8014b87c14fa2cb96b\n""}, {'number': 4, 'created': '2014-07-10 16:03:25.000000000', 'files': ['neutron/plugins/ml2/managers.py', 'neutron/db/l3_dvr_db.py', 'neutron/plugins/linuxbridge/common/config.py', 'neutron/plugins/openvswitch/common/config.py', 'neutron/agent/l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/dd452aa9b001e6ba66a652572ca050ffb0e446fd', 'message': ""(DON'T MERGE) Hard code config defaults to use DVR\n\nThis is a commit for testing, do not merge.\n\nChange-Id: I76d93e0f32f661064afaac8014b87c14fa2cb96b\n""}]",0,105861,dd452aa9b001e6ba66a652572ca050ffb0e446fd,58,16,4,6788,,,0,"(DON'T MERGE) Hard code config defaults to use DVR

This is a commit for testing, do not merge.

Change-Id: I76d93e0f32f661064afaac8014b87c14fa2cb96b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/61/105861/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/managers.py', 'neutron/db/l3_dvr_db.py', 'neutron/plugins/linuxbridge/common/config.py', 'neutron/plugins/openvswitch/common/config.py', 'neutron/agent/l3_agent.py']",5,a2895cb38cd1e20ed9b825bb97b6b42a6a7885ab,up-master," cfg.StrOpt('agent_mode', default='dvr_snat',"," cfg.StrOpt('agent_mode', default='legacy',",8,7
openstack%2Ftripleo-heat-templates~master~I1c12497ff99d210c52026883bfae2a5ee6ba77c3,openstack/tripleo-heat-templates,master,I1c12497ff99d210c52026883bfae2a5ee6ba77c3,NovaCompute0AllNodesDeploy typo change,ABANDONED,2014-08-05 08:44:00.000000000,2014-08-07 11:28:56.000000000,,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 4330}, {'_account_id': 6488}, {'_account_id': 6796}, {'_account_id': 7579}, {'_account_id': 10373}]","[{'number': 1, 'created': '2014-08-05 08:44:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bdce37a7b3abb104fb5bf7b3d88890efcb8e6a49', 'message': 'NovaCompute0AllNodesDeploy typo change\n\n""config: {get_param: AllNodesConfig}"" should be\n""config: {get_resource: AllNodesConfig}"" to correctly represent\nhot.\n\nChange-Id: I1c12497ff99d210c52026883bfae2a5ee6ba77c3\n'}, {'number': 2, 'created': '2014-08-05 14:50:49.000000000', 'files': ['nova-compute-instance.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ebc3bb12ab8debb0f5e7a1857cc9010d8720945a', 'message': 'NovaCompute0AllNodesDeploy typo change\n\n""config: {get_param: AllNodesConfig}"" should be\n""config: {get_resource: AllNodesConfig}"" to correctly represent\nhot.\n\nChange-Id: I1c12497ff99d210c52026883bfae2a5ee6ba77c3\n'}]",0,111954,ebc3bb12ab8debb0f5e7a1857cc9010d8720945a,17,7,2,10373,,,0,"NovaCompute0AllNodesDeploy typo change

""config: {get_param: AllNodesConfig}"" should be
""config: {get_resource: AllNodesConfig}"" to correctly represent
hot.

Change-Id: I1c12497ff99d210c52026883bfae2a5ee6ba77c3
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/54/111954/1 && git format-patch -1 --stdout FETCH_HEAD,['nova-compute-instance.yaml'],1,bdce37a7b3abb104fb5bf7b3d88890efcb8e6a49,typo, config: {get_resource: AllNodesConfig}, config: {get_param: AllNodesConfig},1,1
openstack%2Fpython-mistralclient~master~I4c25aa4c83bdc6df782832d625cc821a389f784d,openstack/python-mistralclient,master,I4c25aa4c83bdc6df782832d625cc821a389f784d,Add negative tests for CLI,MERGED,2014-08-06 08:52:01.000000000,2014-08-07 10:46:20.000000000,2014-08-07 10:46:20.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 8824}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-08-06 08:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/bd90266f732f310e8b63981d1dbf80d24d64479a', 'message': ""Add negative tests for CLI\n\nNegative tests were added, they check:\n- that we can't create two workflows with the same name\n- that we can't send command for nonexisting object\n(for example get list of executions from nonexisting workbook)\n- that we can't set more parameter than requires\n- that we can't set less parameter thatn requires\n\nChange-Id: I4c25aa4c83bdc6df782832d625cc821a389f784d\nImplements: blueprint mistral-cli-integration-tests\n""}, {'number': 2, 'created': '2014-08-06 09:00:18.000000000', 'files': ['functionaltests/cli/cli_tests.py'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/dcff776a592bcad084c3a2114da966bbc3ffebbe', 'message': ""Add negative tests for CLI\n\nNegative tests were added, they check:\n- that we can't create two workflows with the same name\n- that we can't send command for nonexisting object\n(for example get list of executions from nonexisting workbook)\n- that we can't set more parameter than requires\n- that we can't set less parameter than requires\n\nChange-Id: I4c25aa4c83bdc6df782832d625cc821a389f784d\nImplements: blueprint mistral-cli-integration-tests\n""}]",0,112242,dcff776a592bcad084c3a2114da966bbc3ffebbe,17,6,2,8592,,,0,"Add negative tests for CLI

Negative tests were added, they check:
- that we can't create two workflows with the same name
- that we can't send command for nonexisting object
(for example get list of executions from nonexisting workbook)
- that we can't set more parameter than requires
- that we can't set less parameter than requires

Change-Id: I4c25aa4c83bdc6df782832d625cc821a389f784d
Implements: blueprint mistral-cli-integration-tests
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/42/112242/1 && git format-patch -1 --stdout FETCH_HEAD,['functionaltests/cli/cli_tests.py'],1,bd90266f732f310e8b63981d1dbf80d24d64479a,bp/mistral-cli-integration-tests,"from tempest import exceptions class NegativeCLITests(ClientTestBase): """"""This class contains negative tests."""""" def test_wb_list_extra_param(self): self.assertRaises(exceptions.CommandFailed, self.mistral, 'workbook-list', params='param') def test_wb_get_unexist_wb(self): self.assertRaises(exceptions.CommandFailed, self.mistral, 'workbook-get', params='wb') def test_wb_get_without_param(self): self.assertRaises(exceptions.CommandFailed, self.mistral, 'workbook-get') def test_wb_create_same_name(self): self.mistral('workbook-create', params='wb') self.assertRaises(exceptions.CommandFailed, self.mistral, 'workbook-create', params='wb') def test_wb_create_with_wrong_path_to_definition(self): self.assertRaises(exceptions.CommandFailed, self.mistral, 'workbook-create', params='wb pam pam pam') def test_wb_delete_unexist_wb(self): self.assertRaises(exceptions.CommandFailed, self.mistral, 'workbook-delete', params='wb') def test_wb_update_unexist_wb(self): self.assertRaises(exceptions.CommandFailed, self.mistral, 'workbook-update', params='wb pam pam') def test_wb_upload_definition_unexist_wb(self): self.assertRaises(exceptions.CommandFailed, self.mistral, 'workbook-upload-definition', params='wb') def test_wb_upload_definition_using_wrong_path(self): self.mistral('workbook-create', params='wb') self.assertRaises(exceptions.CommandFailed, self.mistral, 'workbook-upload-definition', params='wb param') def test_wb_get_definition_wb_without_definition(self): self.mistral('workbook-create', params='wb') self.assertRaises(exceptions.CommandFailed, self.mistral, 'workbook-get-definition', params='wb') def test_ex_list_unexist_wb(self): self.assertRaises(exceptions.CommandFailed, self.mistral, 'execution-list', params='wb') def test_ex_create_unexist_wb(self): self.assertRaises(exceptions.CommandFailed, self.mistral, 'execution-create', params='wb') def test_ex_create_unexist_task(self): self.mistral('workbook-create', params='wb') self.assertRaises(exceptions.CommandFailed, self.mistral, 'execution-create', params='wb param {}') def test_ex_create_without_context(self): self.mistral('workbook-create', params='wb') self.assertRaises(exceptions.CommandFailed, self.mistral, 'execution-create', params='wb param') def test_ex_create_wrong_context_format(self): self.mistral('workbook-create', params='wb') self.assertRaises(exceptions.CommandFailed, self.mistral, 'execution-create', params='wb param pam') def test_ex_get_from_nonexist_wb(self): self.assertRaises(exceptions.CommandFailed, self.mistral, 'execution-get', params='wb id') def test_ex_get_nonexist_execution(self): self.mistral('workbook-create', params='wb') self.assertRaises(exceptions.CommandFailed, self.mistral, 'execution-get', params='wb id') def test_ex_update_set_wrong_state(self): self.mistral('workbook-create', params='wb') self.mistral('workbook-upload-definition', params='""wb"" ""{0}""'.format(self.definition)) execution = self.parser.listing(self.mistral( 'execution-create', params='""wb"" ""hello"" ""{}""')) exec_id = self.get_value_of_field(execution, 'ID') self.assertRaises(exceptions.CommandFailed, self.mistral, 'execution-update', params='""wb"" ""{0}"" ""OK""'.format(exec_id)) def test_task_get_nonexisting_task(self): self.mistral('workbook-create', params='wb') self.mistral('workbook-upload-definition', params='""wb"" ""{0}""'.format(self.definition)) self.mistral('execution-create', params='""wb"" ""hello"" ""{}""') self.assertRaises(exceptions.CommandFailed, self.mistral, 'task-get', params='""wb"" ""hello"" ""id""')",,110,0
openstack%2Ffuel-main~master~I90f70a00ccefba557e1a2465accb19dd6b0b123c,openstack/fuel-main,master,I90f70a00ccefba557e1a2465accb19dd6b0b123c,Increase timeout on launching of murano ostf,MERGED,2014-08-07 10:10:40.000000000,2014-08-07 10:43:32.000000000,2014-08-07 10:43:32.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7126}, {'_account_id': 7227}, {'_account_id': 7428}, {'_account_id': 8592}, {'_account_id': 8882}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-08-07 10:10:40.000000000', 'files': ['fuelweb_test/tests/test_services.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/3d452c04345ca3b0ab0615661e8cf36e277c1d50', 'message': 'Increase timeout on launching of murano ostf\n\nChange-Id: I90f70a00ccefba557e1a2465accb19dd6b0b123c\nCloses-bug: #1353937\n'}]",0,112543,3d452c04345ca3b0ab0615661e8cf36e277c1d50,10,8,1,8824,,,0,"Increase timeout on launching of murano ostf

Change-Id: I90f70a00ccefba557e1a2465accb19dd6b0b123c
Closes-bug: #1353937
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/43/112543/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_services.py'],1,3d452c04345ca3b0ab0615661e8cf36e277c1d50,," test_name=test_name, timeout=60 * 31)"," test_name=test_name, timeout=60 * 20)",1,1
openstack%2Fswift~feature%2Fec~I9ff3b1415e3112789493c84a14299acc16dcf1cc,openstack/swift,feature/ec,I9ff3b1415e3112789493c84a14299acc16dcf1cc,Updates to EC user docs from EC design meet-up,MERGED,2014-08-05 14:41:20.000000000,2014-08-07 10:42:56.000000000,2014-08-07 10:42:56.000000000,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 7847}]","[{'number': 1, 'created': '2014-08-05 14:41:20.000000000', 'files': ['doc/source/overview_erasure_code.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/ce43f9fd68ff3436e01b4114a8ccbf56d3da6f52', 'message': 'Updates to EC user docs from EC design meet-up\n\nChange-Id: I9ff3b1415e3112789493c84a14299acc16dcf1cc\nImplements: blueprint swift-ec\n'}]",0,112037,ce43f9fd68ff3436e01b4114a8ccbf56d3da6f52,18,3,1,7479,,,0,"Updates to EC user docs from EC design meet-up

Change-Id: I9ff3b1415e3112789493c84a14299acc16dcf1cc
Implements: blueprint swift-ec
",git fetch https://review.opendev.org/openstack/swift refs/changes/37/112037/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/overview_erasure_code.rst'],1,ce43f9fd68ff3436e01b4114a8ccbf56d3da6f52,bp/swift-ec,"Region Support -------------- For at least the initial version of EC, it is not recommended that an EC scheme span beyond a single region, Neither performance nor functional validation will be been done in in such a configuration. ",,7,0
openstack%2Fpython-mistralclient~master~Iaca6a547678bd0594e5deb8b159578fea356ded1,openstack/python-mistralclient,master,Iaca6a547678bd0594e5deb8b159578fea356ded1,"Add CLI tests for workbook, execution and task",MERGED,2014-08-04 13:51:38.000000000,2014-08-07 10:41:26.000000000,2014-08-07 10:41:26.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 8824}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-08-04 13:51:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/6d5f2a70287a5e57ca5769ed3e5698d6eb5a937f', 'message': 'Add CLI tests for workbook, execution and task\n\nWere added tests which check CLI commands for work with workbooks,\nexecutions and tasks.\nTests check:\n- structure of return table,\n- object creation, deletion\n- uploading definition\n\nTargets blueprint: mistral-cli-integrational-tests\nChange-Id: Iaca6a547678bd0594e5deb8b159578fea356ded1\n'}, {'number': 2, 'created': '2014-08-05 10:06:05.000000000', 'files': ['functionaltests/cli/cli_tests.py'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/3fe2681677b0682800e2d44ff9a106fa3ededa88', 'message': 'Add CLI tests for workbook, execution and task\n\nWere added tests which check CLI commands for work with workbooks,\nexecutions and tasks.\nTests check:\n- structure of return table,\n- object creation, deletion\n- uploading definition\n\nTargets blueprint: mistral-cli-integrational-tests\nChange-Id: Iaca6a547678bd0594e5deb8b159578fea356ded1\n'}]",2,111735,3fe2681677b0682800e2d44ff9a106fa3ededa88,17,7,2,8592,,,0,"Add CLI tests for workbook, execution and task

Were added tests which check CLI commands for work with workbooks,
executions and tasks.
Tests check:
- structure of return table,
- object creation, deletion
- uploading definition

Targets blueprint: mistral-cli-integrational-tests
Change-Id: Iaca6a547678bd0594e5deb8b159578fea356ded1
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/35/111735/1 && git format-patch -1 --stdout FETCH_HEAD,['functionaltests/cli/cli_tests.py'],1,6d5f2a70287a5e57ca5769ed3e5698d6eb5a937f,bp/mistral-cli-integrational-tests,"import os class MistralCLIAuth(cli.ClientTestBase):class SimpleMistralCLITests(MistralCLIAuth): mistral_help = self.mistral('--help') self.assertIn('Command-line interface to the Mistral APIs', mistral_help) self.assertIn('Commands:', mistral_help) self.assertIn(command, mistral_help) class ClientTestBase(MistralCLIAuth): @classmethod def setUpClass(cls): super(ClientTestBase, cls).setUpClass() cls.definition = os.path.relpath( 'functionaltests/hello.yaml', os.getcwd()) def tearDown(self): super(ClientTestBase, self).tearDown() for wb in self.parser.listing(self.mistral('workbook-list')): if wb['Name'] != ""<none>"": execs = self.parser.listing(self.mistral( 'execution-list', params='{0}'.format(wb['Name']))) ids = [ex['ID'] for ex in execs] for id in ids: if id != ""<none>"": self.parser.listing(self.mistral( 'execution-delete', params='""{0}"" ""{1}""'.format(wb['Name'], id))) self.parser.listing(self.mistral( 'workbook-delete', params=wb['Name'])) def get_value_of_field(self, obj, field): return [o['Value'] for o in obj if o['Field'] == ""{0}"".format(field)][0] class WorkbookCLITests(ClientTestBase): """"""Test suite checks commands to work with workbooks."""""" @classmethod def setUpClass(cls): super(WorkbookCLITests, cls).setUpClass() def test_workbook_create_delete(self): wb = self.parser.listing(self.mistral('workbook-create', params='wb')) self.assertTableStruct(wb, ['Field', 'Value']) name = self.get_value_of_field(wb, ""Name"") self.assertEqual('wb', name) wbs = self.parser.listing(self.mistral('workbook-list')) self.assertIn('wb', [workbook['Name'] for workbook in wbs]) self.parser.listing(self.mistral('workbook-delete', params='wb')) wbs = self.parser.listing(self.mistral('workbook-list')) self.assertNotIn('wb', [workbook['Name'] for workbook in wbs]) def test_workbook_update(self): self.parser.listing(self.mistral('workbook-create', params='wb')) wb = self.parser.listing(self.mistral( 'workbook-update', params='""wb"" ""Test Description"" ""tag""')) self.assertTableStruct(wb, ['Field', 'Value']) name = self.get_value_of_field(wb, ""Name"") description = self.get_value_of_field(wb, ""Description"") tags = self.get_value_of_field(wb, ""Tags"") self.assertEqual('wb', name) self.assertIn('Test Description', description) self.assertIn('tag', tags) def test_workbook_upload_get_definition(self): self.parser.listing(self.mistral('workbook-create', params='wb')) self.parser.listing(self.mistral( 'workbook-upload-definition', params='""wb"" ""{0}""'.format(self.definition))) definition = self.mistral('workbook-get-definition', params='wb') self.assertNotIn('404 Not Found', definition) class ExecutionCLITests(ClientTestBase): """"""Test suite checks commands to work with executions."""""" def setUp(self): super(ExecutionCLITests, self).setUp() self.mistral('workbook-create', params='wb') self.mistral('workbook-upload-definition', params='""wb"" ""{0}""'.format(self.definition)) def tearDown(self): super(ExecutionCLITests, self).tearDown() def test_execution_create_delete(self): execution = self.parser.listing(self.mistral( 'execution-create', params='""wb"" ""hello"" ""{}""')) self.assertTableStruct(execution, ['Field', 'Value']) exec_id = self.get_value_of_field(execution, 'ID') wb = self.get_value_of_field(execution, 'Workbook') task = self.get_value_of_field(execution, 'Task') status = self.get_value_of_field(execution, 'State') self.assertEqual('wb', wb) self.assertEqual('hello', task) self.assertEqual('RUNNING', status) execs = self.parser.listing( self.mistral('execution-list', params='wb')) self.assertIn(exec_id, [ex['ID'] for ex in execs]) self.assertIn(wb, [ex['Workbook'] for ex in execs]) self.assertIn(task, [ex['Task'] for ex in execs]) self.assertIn('SUCCESS', [ex['State'] for ex in execs]) self.parser.listing(self.mistral( 'execution-delete', params='""wb"" ""{0}""'.format(exec_id))) execs = self.parser.listing( self.mistral('execution-list', params='wb')) self.assertNotIn(exec_id, [ex['ID'] for ex in execs]) def test_update_execution(self): execution = self.parser.listing(self.mistral( 'execution-create', params='""wb"" ""hello"" ""{}""')) self.assertTableStruct(execution, ['Field', 'Value']) exec_id = self.get_value_of_field(execution, 'ID') status = self.get_value_of_field(execution, 'State') self.assertEqual('RUNNING', status) execution = self.parser.listing(self.mistral( 'execution-update', params='""wb"" ""{0}"" ""STOPPED""'.format(exec_id))) self.assertTableStruct(execution, ['Field', 'Value']) updated_exec_id = self.get_value_of_field(execution, 'ID') status = self.get_value_of_field(execution, 'State') self.assertEqual(exec_id, updated_exec_id) self.assertEqual('STOPPED', status) def test_get_execution(self): execution = self.parser.listing(self.mistral( 'execution-create', params='""wb"" ""hello"" ""{}""')) exec_id = self.get_value_of_field(execution, 'ID') execution = self.parser.listing(self.mistral( 'execution-get', params='""wb"" ""{0}""'.format(exec_id))) gotten_id = self.get_value_of_field(execution, 'ID') wb = self.get_value_of_field(execution, 'Workbook') task = self.get_value_of_field(execution, 'Task') self.assertEqual(exec_id, gotten_id) self.assertEqual('wb', wb) self.assertEqual('hello', task) class TaskCLITests(ClientTestBase): """"""Test suite checks commands to work with tasks."""""" def test_get_task(self): self.mistral('workbook-create', params='wb') self.mistral('workbook-upload-definition', params='""wb"" ""{0}""'.format(self.definition)) execution = self.parser.listing(self.mistral( 'execution-create', params='""wb"" ""hello"" ""{}""')) exec_id = self.get_value_of_field(execution, 'ID') tasks = self.parser.listing( self.mistral('task-list', params='""wb"" ""{0}""'.format(exec_id))) task_id = [task['ID'] for task in tasks][0] task = self.parser.listing(self.mistral( 'task-get', params='""wb"" ""hello"" ""{0}""'.format(task_id))) gotten_id = self.get_value_of_field(task, 'ID') wb = self.get_value_of_field(task, 'Workbook') self.assertEqual(task_id, gotten_id) self.assertEqual('wb', wb) ","class ClientTestBase(cli.ClientTestBase):class SimpleMistralCLITests(ClientTestBase): help = self.mistral('--help') self.assertIn('Command-line interface to the Mistral APIs', help) self.assertIn('Commands:', help) self.assertIn(command, help)",197,6
openstack%2Fhorizon~master~I58035cf8c44636d9a24a93b8d00ca54afc2403e1,openstack/horizon,master,I58035cf8c44636d9a24a93b8d00ca54afc2403e1,Imported Translations from Transifex,MERGED,2014-08-07 06:02:33.000000000,2014-08-07 10:22:35.000000000,2014-08-07 10:22:35.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-08-07 06:02:33.000000000', 'files': ['horizon/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0a717c8346354073a629cd7be9d73d23c1328b02', 'message': 'Imported Translations from Transifex\n\nChange-Id: I58035cf8c44636d9a24a93b8d00ca54afc2403e1\n'}]",0,112481,0a717c8346354073a629cd7be9d73d23c1328b02,10,3,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I58035cf8c44636d9a24a93b8d00ca54afc2403e1
",git fetch https://review.opendev.org/openstack/horizon refs/changes/81/112481/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po']",17,0a717c8346354073a629cd7be9d73d23c1328b02,transifex/translations,"""POT-Creation-Date: 2014-08-06 17:57-0500\n"" ""PO-Revision-Date: 2014-08-06 22:13+0000\n""msgid ""Unable to retrieve data source details""#: dashboards/project/volumes/backups/tables.py:49#: dashboards/project/stacks/views.py:79#: dashboards/project/stacks/views.py:111 #: dashboards/project/stacks/views.py:188 #: dashboards/project/stacks/views.py:212#: dashboards/project/stacks/views.py:240#: dashboards/project/stacks/views.py:253","""POT-Creation-Date: 2014-08-05 23:34-0500\n"" ""PO-Revision-Date: 2014-08-06 04:34+0000\n""msgid ""Unable to retreive data source details""#: dashboards/project/stacks/views.py:62#: dashboards/project/stacks/views.py:94 #: dashboards/project/stacks/views.py:171 #: dashboards/project/stacks/views.py:195#: dashboards/project/stacks/views.py:223#: dashboards/project/stacks/views.py:236#: dashboards/project/volumes/backups/tables.py:49 msgid ""Scheduled deletion of"" msgstr ""Scheduled deletion of"" ",322,369
openstack%2Fmanila~master~I138a0dfc119f2fd58621a0e07fe1338dbf61b10a,openstack/manila,master,I138a0dfc119f2fd58621a0e07fe1338dbf61b10a,Fix setting up security-services in Cmode,MERGED,2014-07-29 10:17:18.000000000,2014-08-07 10:00:19.000000000,2014-08-07 10:00:19.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-07-29 10:17:18.000000000', 'files': ['manila/share/drivers/netapp/cluster_mode.py', 'manila/tests/netapp/test_cmode_drv.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/f4269ca2fd5e67583ec6ab6aac0a92ea96d50330', 'message': 'Fix setting up security-services in Cmode\n\nAdded setting name-service-switch and\nname-mapping-switch to ldap, file\n\nChange-Id: I138a0dfc119f2fd58621a0e07fe1338dbf61b10a\nCloses-Bug: #1294575\n'}]",0,110254,f4269ca2fd5e67583ec6ab6aac0a92ea96d50330,16,4,1,7534,,,0,"Fix setting up security-services in Cmode

Added setting name-service-switch and
name-mapping-switch to ldap, file

Change-Id: I138a0dfc119f2fd58621a0e07fe1338dbf61b10a
Closes-Bug: #1294575
",git fetch https://review.opendev.org/openstack/manila refs/changes/54/110254/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/netapp/cluster_mode.py', 'manila/tests/netapp/test_cmode_drv.py']",2,f4269ca2fd5e67583ec6ab6aac0a92ea96d50330,," def test_setup_security_services(self): fake_sevice_ldap = {'type': 'ldap'} fake_sevice_krb = {'type': 'kerberos'} fake_sevice_ad = {'type': 'active_directory'} vserver_name = 'fake_vserver' modify_args = { 'name-mapping-switch': { 'nmswitch': 'ldap,file'}, 'name-server-switch': { 'nsswitch': 'ldap,file'}, 'vserver-name': 'fake_vserver'} self.driver._configure_kerberos = mock.Mock() self.driver._configure_ldap = mock.Mock() self.driver._configure_active_directory = mock.Mock() self.driver._setup_security_services( [fake_sevice_ad, fake_sevice_krb, fake_sevice_ldap], self._vserver_client, vserver_name) self.driver._client.send_request.assert_called_once_with( 'vserver-modify', modify_args) self.driver._configure_active_directory.assert_called_once_with( fake_sevice_ad, self._vserver_client) self.driver._configure_kerberos.assert_called_once_with( vserver_name, fake_sevice_krb, self._vserver_client) self.driver._configure_ldap.assert_called_once_with( fake_sevice_ldap, self._vserver_client) ",,57,14
openstack%2Fneutron~master~I571da230f66d270a44597a5869f1c818f792e4c0,openstack/neutron,master,I571da230f66d270a44597a5869f1c818f792e4c0,Imported Translations from Transifex,MERGED,2014-08-03 06:04:16.000000000,2014-08-07 09:41:06.000000000,2014-08-06 13:10:35.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-08-03 06:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7aa3e19bfc447c1545d0d59776cc699494fb8b32', 'message': 'Imported Translations from Transifex\n\nChange-Id: I571da230f66d270a44597a5869f1c818f792e4c0\n'}, {'number': 2, 'created': '2014-08-04 06:04:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/34b0f2a96d4da2735d8e894cedc7a4e02d50d5eb', 'message': 'Imported Translations from Transifex\n\nChange-Id: I571da230f66d270a44597a5869f1c818f792e4c0\n'}, {'number': 3, 'created': '2014-08-05 06:04:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2c36db690773d10d80a46b7da8cf3c2daa18e3f1', 'message': 'Imported Translations from Transifex\n\nChange-Id: I571da230f66d270a44597a5869f1c818f792e4c0\n'}, {'number': 4, 'created': '2014-08-06 06:04:25.000000000', 'files': ['neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2c404c3bf24e02d4633445eb6fa98cff74f22e48', 'message': 'Imported Translations from Transifex\n\nChange-Id: I571da230f66d270a44597a5869f1c818f792e4c0\n'}]",0,111547,2c404c3bf24e02d4633445eb6fa98cff74f22e48,79,18,4,11131,,,0,"Imported Translations from Transifex

Change-Id: I571da230f66d270a44597a5869f1c818f792e4c0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/47/111547/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot']",2,7aa3e19bfc447c1545d0d59776cc699494fb8b32,transifex/translations,"""Project-Id-Version: neutron 2014.2.dev127.ga566fb7\n""""POT-Creation-Date: 2014-08-03 06:03+0000\n""#: neutron/db/l3_dvrscheduler_db.py:268""No Tenants configured in Neutron DB. But %d tenants discovered in EOS "" ""during synchronization.Entire EOS region is cleared""","""Project-Id-Version: neutron 2014.2.dev119.g9d677ce\n""""POT-Creation-Date: 2014-08-02 06:05+0000\n""#: neutron/db/l3_dvrscheduler_db.py:269""No Tenants configured in Neutron DB. But %d tenants disovered in EOS "" ""during synchronization.Enitre EOS region is cleared""",9,9
openstack%2Ffuel-main~master~Iad94285853c06a36afcc7ce2006cae4a241f9932,openstack/fuel-main,master,Iad94285853c06a36afcc7ce2006cae4a241f9932,"Revert ""Fix issue with snapshot name on error""",ABANDONED,2014-08-06 13:31:26.000000000,2014-08-07 09:33:33.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-08-06 13:31:26.000000000', 'files': ['fuelweb_test/helpers/decorators.py', 'fuelweb_test/helpers/patch_test_docstring_template.py', 'fuelweb_test/run_tests.py', 'fuelweb_test/tests/tests_os_patching/test_os_patching.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/e11c8f2083af7793fa9c78b5d998ff48d65c251b', 'message': 'Revert ""Fix issue with snapshot name on error""\n\nThis reverts commit 342796c683d2e8bff01a04adc66f18c451300a68.\n\nChange-Id: Iad94285853c06a36afcc7ce2006cae4a241f9932\n'}]",0,112298,e11c8f2083af7793fa9c78b5d998ff48d65c251b,5,2,1,8882,,,0,"Revert ""Fix issue with snapshot name on error""

This reverts commit 342796c683d2e8bff01a04adc66f18c451300a68.

Change-Id: Iad94285853c06a36afcc7ce2006cae4a241f9932
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/98/112298/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/helpers/decorators.py', 'fuelweb_test/helpers/patch_test_docstring_template.py', 'fuelweb_test/run_tests.py', 'fuelweb_test/tests/tests_os_patching/test_os_patching.py']",4,e11c8f2083af7793fa9c78b5d998ff48d65c251b,fix_err_snap_creation," self.deploy_and_patch.__func__.func_name = ""{0}_and_patch"".format( self.snapshot) self.deploy_and_rollback.__func__.func_name = ""{0}_rollback"".format( self.snapshot) """"""Update os on reverted cluster 6. Run update script raise SkipTest() """"""Rollback os on reverted cluster 2. Identify release id for rollback 3. Run rollback 4. Check that rollback was successful 6. Create snapshot raise SkipTest() self.env.make_snapshot('{0}_and_rollback'.format(self.snapshot), is_make=True)"," """"""Update OS on reverted env 6. Run upgrade script logger.info(""snapshot name is {0}"".format(self.snapshot)) logger.error('There is no shaphot found {0}'.format(self.snapshot)) raise SkipTest('Can not find snapshot {0}'.format(self.snapshot)) """"""Rollback/Downgrade os on reverted env 2. Identify release id for rollback/downgrade 3. Run rollback/downgrade 4. Check that operation was successful logger.info(""snapshot name is {0}"".format(self.snapshot)) raise SkipTest('Can not find snapshot {0}'.format(self.snapshot)) self.env.make_snapshot('{0}_and_rollback'.format(self.snapshot))",20,54
openstack%2Fhorizon~master~Ib1198711589ac704278db53d4d53fd655146aaa9,openstack/horizon,master,Ib1198711589ac704278db53d4d53fd655146aaa9,Provide docstrings for horizon tables DeleteAction,MERGED,2014-08-05 23:03:33.000000000,2014-08-07 09:22:58.000000000,2014-08-07 09:22:57.000000000,"[{'_account_id': 3}, {'_account_id': 2455}, {'_account_id': 7007}, {'_account_id': 9317}, {'_account_id': 9576}, {'_account_id': 10068}, {'_account_id': 10786}, {'_account_id': 12071}]","[{'number': 1, 'created': '2014-08-05 23:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a0f234805d22500811ae95b1a2ed320dfe9d7eb8', 'message': 'Provide docstrings for horizon tables DeleteAction\n\nChange-Id: Ib1198711589ac704278db53d4d53fd655146aaa9\n'}, {'number': 2, 'created': '2014-08-06 00:27:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c82eb4aa931b6f49893c3386a57523664a3e5762', 'message': 'Provide docstrings for horizon tables DeleteAction\n\nChange-Id: Ib1198711589ac704278db53d4d53fd655146aaa9\n'}, {'number': 3, 'created': '2014-08-06 11:22:38.000000000', 'files': ['horizon/tables/actions.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d33a91e010b0003854b1d6bf5a545913ebd86d07', 'message': 'Provide docstrings for horizon tables DeleteAction\n\nWhile it\'s true that the `horizon.tables.actions.DeleteAction`\ncode is self explanatory (and hence documentation on its own),\nthe motivation behind this was to replace """"""Doc missing."""""" with\nsomething more descriptive that will show up at:-\nhttp://docs.openstack.org/developer/horizon/ref/tables.html#horizon.tables.DeleteAction\n\nIt would also be good to call `help(DeleteAction)` to get a decent\ndescription of the class.\n\nChange-Id: Ib1198711589ac704278db53d4d53fd655146aaa9\n'}]",4,112166,d33a91e010b0003854b1d6bf5a545913ebd86d07,21,8,3,10786,,,0,"Provide docstrings for horizon tables DeleteAction

While it's true that the `horizon.tables.actions.DeleteAction`
code is self explanatory (and hence documentation on its own),
the motivation behind this was to replace """"""Doc missing."""""" with
something more descriptive that will show up at:-
http://docs.openstack.org/developer/horizon/ref/tables.html#horizon.tables.DeleteAction

It would also be good to call `help(DeleteAction)` to get a decent
description of the class.

Change-Id: Ib1198711589ac704278db53d4d53fd655146aaa9
",git fetch https://review.opendev.org/openstack/horizon refs/changes/66/112166/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/tables/actions.py'],1,a0f234805d22500811ae95b1a2ed320dfe9d7eb8,provide-deleteaction-docstring," """"""A table action used to perform delete operations on table data. .. attribute:: name A short name or ""slug"" representing this action. Defaults to 'delete' .. attribute:: action_present A string containing the transitive verb describing the delete action. Defaults to 'Delete' .. attribute:: action_past A string set to the past tense of action_present. Defaults to 'Deleted' .. attribute:: data_type_singular A string used to name the data to be deleted. .. attribute:: data_type_plural Optional. Plural of ``data_type_singular``. Defaults to ``data_type_singular`` appended with an 's'. """""" """"""Required. Override this method in your subclass to provide delete functionality for your table data. :param obj_id: unique identifier used to fetch the object to delete. :raises: NotImplementedError """""" """"""Appends ``btn-danger`` to the default css classes to highlight the corresponding button as a triger for a potentially dangerous action. """""""," """"""Doc missing.""""""",36,1
openstack%2Fneutron~master~I6a391951e00fb63905b2027270af9f401841d5b9,openstack/neutron,master,I6a391951e00fb63905b2027270af9f401841d5b9,Move from Python logging to Openstack logging,MERGED,2014-07-31 23:10:17.000000000,2014-08-07 09:20:37.000000000,2014-08-07 09:20:35.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 841}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7776}, {'_account_id': 8124}, {'_account_id': 8788}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10980}, {'_account_id': 12134}]","[{'number': 1, 'created': '2014-07-31 23:10:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b08180e5049d87a9a0425092336960d34a2c5703', 'message': 'Relacing usage of python standard logging module with Openstack Logging\n\nApart from the said replaces, this patch also removes basicConfig()\nsetup from a couple of modules since its not needed.\n\nChange-Id: I6a391951e00fb63905b2027270af9f401841d5b9\nCloses-Bug: #1350937\n'}, {'number': 2, 'created': '2014-08-01 00:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/55f8f74c71ac811bd624b08e8ec1a92bdb33eed7', 'message': 'Replacing usage of python standard logging module with Openstack Logging\n\nApart from the said replacements, this patch also removes basicConfig()\nsetup from a couple of modules since its not needed.\n\nChange-Id: I6a391951e00fb63905b2027270af9f401841d5b9\nCloses-Bug: #1350937\n'}, {'number': 3, 'created': '2014-08-01 16:14:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7c3c57c9e59a9523ae438a4193a3a130c8652044', 'message': 'Replacing usage of python standard logging module with Openstack Logging\n\nApart from the said replacements, this patch also removes basicConfig()\nsetup from a couple of modules since its not needed.\n\nChange-Id: I6a391951e00fb63905b2027270af9f401841d5b9\nCloses-Bug: #1350937\n'}, {'number': 4, 'created': '2014-08-01 16:30:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b879396f2dda7a157a49151b603542e40eae936a', 'message': 'Replacing usage of python standard logging module with Openstack Logging\n\nApart from the said replacements, this patch also removes basicConfig()\nsetup from a couple of modules since its not needed. Similarly we dont\nneed to set the logging level specifically using the setLevel() method\nbecause openstack logging wrapper handles the logging level when used.\n\nChange-Id: I6a391951e00fb63905b2027270af9f401841d5b9\nCloses-Bug: #1350937\n'}, {'number': 5, 'created': '2014-08-01 16:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d8a2f0c78b8f8621f9d4ff347f7dab7ef60e9394', 'message': 'Replacing usage of python standard logging module with Openstack Logging\n\nApart from the said replacements, this patch also removes basicConfig()\nsetup from a couple of modules since its not needed. Similarly we dont\nneed to set the logging level specifically using the setLevel() method\nbecause openstack logging wrapper handles the logging level when used.\n\nChange-Id: I6a391951e00fb63905b2027270af9f401841d5b9\nCloses-Bug: #1350937\n'}, {'number': 6, 'created': '2014-08-01 19:49:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5a9beae42423d7d211e114c9dda31ef11920c637', 'message': 'Move from Python logging to Openstack logging\n\nReplacing usage of python standard logging module with Openstack commong\nlogging module.Apart from the said replacements, this patch also removes\nbasicConfig() setup from a couple of modules since its not needed.\nSimilarly we dont need to set the logging level specifically using the\nsetLevel() method because openstack logging wrapper handles the logging\nlevel when used.\n\nChange-Id: I6a391951e00fb63905b2027270af9f401841d5b9\nCloses-Bug: #1350937\n'}, {'number': 7, 'created': '2014-08-01 19:54:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/03ed7a4555f9f62cc98ba41dbe8f2ba19a3dceec', 'message': 'Move from Python logging to Openstack logging\n\nReplacing usage of python standard logging module with Openstack commong\nlogging module.Apart from the said replacements, this patch also removes\nbasicConfig() setup from a couple of modules since its not needed.\nSimilarly we dont need to set the logging level specifically using the\nsetLevel() method because openstack logging wrapper handles the logging\nlevel when used.\n\nChange-Id: I6a391951e00fb63905b2027270af9f401841d5b9\nCloses-Bug: #1350937\n'}, {'number': 8, 'created': '2014-08-01 23:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a92c38abd9ca5a91c28f6c37e7cea5222c98a119', 'message': 'Move from Python logging to Openstack logging\n\nReplacing usage of python standard logging module with Openstack common\nlogging module. Apart from the said replacements, this patch also removes\nbasicConfig() setup from a couple of modules since its not needed.\nSimilarly we dont need to set the logging level specifically using the\nsetLevel() method because openstack logging wrapper handles the logging\nlevel when used. Also removes unused LOG & imports.\n\nChange-Id: I6a391951e00fb63905b2027270af9f401841d5b9\nCloses-Bug: #1350937\n'}, {'number': 9, 'created': '2014-08-05 18:13:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7f77ac62f5b75bc642945823fdddaedeac8e54a5', 'message': 'Move from Python logging to Openstack logging\n\nReplacing usage of python standard logging module with Openstack common\nlogging module. Apart from the said replacements, this patch also removes\nbasicConfig() setup from a couple of modules since its not needed.\nSimilarly we dont need to set the logging level specifically using the\nsetLevel() method because openstack logging wrapper handles the logging\nlevel when used. Also removes unused LOG & imports.\n\nChange-Id: I6a391951e00fb63905b2027270af9f401841d5b9\nCloses-Bug: #1350937\n'}, {'number': 10, 'created': '2014-08-05 21:47:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/320d822cfeb695c6f3b3acb8f05c027539590b06', 'message': 'Move from Python logging to Openstack logging\n\nReplacing usage of python standard logging module with Openstack common\nlogging module. Apart from the said replacements, this patch also removes\nbasicConfig() setup from a couple of modules since its not needed. Also\nremoves unused LOG & imports.\n\nChange-Id: I6a391951e00fb63905b2027270af9f401841d5b9\nCloses-Bug: #1350937\n'}, {'number': 11, 'created': '2014-08-05 22:43:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/696124a3eae43775992e25e8b81396e8993b167a', 'message': 'Move from Python logging to Openstack logging\n\nReplacing usage of python standard logging module with Openstack common\nlogging module. Apart from the said replacements, this patch also removes\nbasicConfig() setup from a couple of modules since its not needed. Also\nremoves unused LOG & imports.\n\nChange-Id: I6a391951e00fb63905b2027270af9f401841d5b9\nCloses-Bug: #1350937\n'}, {'number': 12, 'created': '2014-08-06 17:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1aa845c8e567344e3c11491e75fd184f25ebad6b', 'message': 'Move from Python logging to Openstack logging\n\nReplacing usage of python standard logging module with Openstack common\nlogging module. Apart from the said replacements, this patch also removes\nbasicConfig() setup from a couple of modules since its not needed. Also\nremoves unused LOG & imports.\n\nChange-Id: I6a391951e00fb63905b2027270af9f401841d5b9\nCloses-Bug: #1350937\n'}, {'number': 13, 'created': '2014-08-06 19:04:19.000000000', 'files': ['neutron/tests/unit/db/metering/test_db_metering.py', 'neutron/tests/unit/test_servicetype.py', 'neutron/tests/base.py', 'neutron/tests/unit/ml2/test_helpers.py', 'neutron/plugins/cisco/network_plugin.py', 'neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py', 'neutron/plugins/cisco/common/cisco_credentials_v2.py', 'neutron/plugins/vmware/plugins/base.py', 'neutron/plugins/cisco/models/virt_phy_sw_v2.py', 'neutron/tests/unit/cisco/test_network_plugin.py', 'neutron/plugins/cisco/nexus/cisco_nexus_snippets.py', 'neutron/plugins/cisco/nexus/cisco_nexus_network_driver_v2.py', 'neutron/plugins/ml2/drivers/cisco/nexus/nexus_snippets.py', 'neutron/tests/unit/db/firewall/test_db_firewall.py', 'neutron/tests/unit/vmware/apiclient/test_api_eventlet_request.py', 'neutron/db/migration/alembic_migrations/heal_script.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1a0be0e05f8d299820b60cd888d74ed5ed73e265', 'message': 'Move from Python logging to Openstack logging\n\nReplacing usage of python standard logging module\nwith Openstack common logging module. Apart from\nthe said replacements, this patch also removes\nbasicConfig() setup from a couple of modules since\nits not needed. Also removes unused LOG & imports.\n\nChange-Id: I6a391951e00fb63905b2027270af9f401841d5b9\nCloses-Bug: #1350937\n'}]",21,111113,1a0be0e05f8d299820b60cd888d74ed5ed73e265,238,28,13,12134,,,0,"Move from Python logging to Openstack logging

Replacing usage of python standard logging module
with Openstack common logging module. Apart from
the said replacements, this patch also removes
basicConfig() setup from a couple of modules since
its not needed. Also removes unused LOG & imports.

Change-Id: I6a391951e00fb63905b2027270af9f401841d5b9
Closes-Bug: #1350937
",git fetch https://review.opendev.org/openstack/neutron refs/changes/13/111113/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/db/metering/test_db_metering.py', 'neutron/tests/unit/test_servicetype.py', 'neutron/common/utils.py', 'neutron/tests/base.py', 'neutron/tests/unit/ml2/test_helpers.py', 'neutron/plugins/cisco/network_plugin.py', 'neutron/plugins/cisco/nexus/cisco_nexus_plugin_v2.py', 'neutron/plugins/cisco/common/cisco_credentials_v2.py', 'neutron/plugins/vmware/plugins/base.py', 'neutron/plugins/cisco/models/virt_phy_sw_v2.py', 'neutron/service.py', 'neutron/tests/unit/cisco/test_network_plugin.py', 'neutron/plugins/cisco/nexus/cisco_nexus_snippets.py', 'neutron/plugins/cisco/nexus/cisco_nexus_network_driver_v2.py', 'neutron/plugins/ml2/drivers/cisco/nexus/nexus_snippets.py', 'neutron/tests/unit/db/firewall/test_db_firewall.py', 'neutron/tests/unit/vmware/apiclient/test_api_eventlet_request.py', 'neutron/db/migration/alembic_migrations/heal_script.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py']",19,b08180e5049d87a9a0425092336960d34a2c5703,bug/1350937,from neutron.openstack.commong import log as logging,import logging,32,38
openstack%2Fironic~master~Ic0af04ebd07b23eb94df32a6abf0e490d597f32a,openstack/ironic,master,Ic0af04ebd07b23eb94df32a6abf0e490d597f32a,Migration to oslo.utils library,MERGED,2014-07-30 10:18:29.000000000,2014-08-07 09:16:37.000000000,2014-08-07 09:16:36.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 1994}, {'_account_id': 6623}, {'_account_id': 6773}, {'_account_id': 7882}, {'_account_id': 8106}]","[{'number': 1, 'created': '2014-07-30 10:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/98951599aa82fc19612da42ced9cd0bb529391a2', 'message': 'Migration to oslo.utils library\n\noslo.utils has been released with the modules excutils, importutils,\nstrutils and timeutils.\n\nChanges done:\n- Use the new oslo.utils modules when possible (not updated in the\nnova.ironic driver and other oslo.incubator modules)\n- importutils.import_module is now importutils.try_import\n- Updated requirements.txt with the new library\n\nOnce the nova.ironic driver is migrated into nova tree, old references\nand libraries can be cleaned (Bug: #1350269)\n\nChange-Id: Ic0af04ebd07b23eb94df32a6abf0e490d597f32a\n'}, {'number': 2, 'created': '2014-07-30 20:44:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/08bc42b2b33f59c34b543005a35197a4096ce473', 'message': 'Migration to oslo.utils library\n\noslo.utils has been released with the modules excutils, importutils,\nstrutils and timeutils.\n\nChanges done:\n- Use the new oslo.utils modules when possible (not updated in the\nnova.ironic driver and other oslo.incubator modules)\n- importutils.import_module is now importutils.try_import\n- Updated requirements.txt with the new library\n\nOnce the nova.ironic driver is migrated into nova tree, old references\nand libraries can be cleaned (Bug: #1350269)\n\nChange-Id: Ic0af04ebd07b23eb94df32a6abf0e490d597f32a\n'}, {'number': 3, 'created': '2014-07-30 21:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c5addf9e111ba02139269fcec8637c69b36187d4', 'message': 'Migration to oslo.utils library\n\noslo.utils has been released with the modules excutils, importutils,\nstrutils and timeutils.\n\nChanges done:\n- Use the new oslo.utils modules when possible (not updated in the\nnova.ironic driver and other oslo.incubator modules)\n- importutils.import_module now is importutils.try_import\n- Updated requirements.txt with the new library\n- strutils.to_bytes now is strutils.string_to_bytes\n\nOnce the nova.ironic driver is migrated into nova tree, old references\nand libraries can be cleaned (Bug: #1350269)\n\nChange-Id: Ic0af04ebd07b23eb94df32a6abf0e490d597f32a\n'}, {'number': 4, 'created': '2014-07-31 00:27:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7aef7b906d92051884ffaaf60693688c560611e9', 'message': 'Migration to oslo.utils library\n\noslo.utils has been released with the modules excutils, importutils,\nstrutils and timeutils.\n\nChanges done:\n- Use the new oslo.utils modules when possible (not updated in the\nnova.ironic driver and other oslo.incubator modules)\n- importutils.import_module now is importutils.try_import\n- Updated requirements.txt with the new library\n- strutils.to_bytes now is strutils.string_to_bytes\n\nOnce the nova.ironic driver is migrated into nova tree, old references\nand libraries can be cleaned (Bug: #1350269)\n\nChange-Id: Ic0af04ebd07b23eb94df32a6abf0e490d597f32a\n'}, {'number': 5, 'created': '2014-08-05 09:23:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/259d2d840db5dc6b17f7e2c5a89b087c142219af', 'message': 'Migration to oslo.utils library\n\noslo.utils has been released with the modules excutils, importutils,\nstrutils and timeutils.\n\nChanges done:\n- Use the new oslo.utils modules when possible (not updated in the\nnova.ironic driver and other oslo.incubator modules)\n- importutils.import_module now is importutils.try_import\n- Updated requirements.txt with the new library\n- strutils.to_bytes now is strutils.string_to_bytes\n\nOnce the nova.ironic driver is migrated into nova tree, old references\nand libraries can be cleaned (Bug: #1350269)\n\nChange-Id: Ic0af04ebd07b23eb94df32a6abf0e490d597f32a\n'}, {'number': 6, 'created': '2014-08-06 14:50:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/79d6649527e9b9491904470325f196e195b8ef1b', 'message': 'Migration to oslo.utils library\n\noslo.utils has been released with the modules excutils, importutils,\nstrutils and timeutils.\n\nChanges done:\n- Use the new oslo.utils modules when possible (not updated in the\nnova.ironic driver and other oslo.incubator modules)\n- importutils.import_module now is importutils.try_import\n- Updated requirements.txt with the new library\n- strutils.to_bytes now is strutils.string_to_bytes\n\nOnce the nova.ironic driver is migrated into nova tree, old references\nand libraries can be cleaned (Bug: #1350269)\n\nChange-Id: Ic0af04ebd07b23eb94df32a6abf0e490d597f32a\n'}, {'number': 7, 'created': '2014-08-06 14:54:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a74eb2f29dc58dc030591e2458ab964a0c1cb3a7', 'message': 'Migration to oslo.utils library\n\noslo.utils has been released with the modules excutils, importutils,\nstrutils and timeutils.\n\nChanges done:\n- Use the new oslo.utils modules when possible (not updated in the\nnova.ironic driver and other oslo.incubator modules)\n- importutils.import_module now is importutils.try_import\n- Updated requirements.txt with the new library\n- strutils.to_bytes now is strutils.string_to_bytes\n\nOnce the nova.ironic driver is migrated into nova tree, old references\nand libraries can be cleaned (Bug: #1350269)\n\nCloses-Bug: #1353540\n\nChange-Id: Ic0af04ebd07b23eb94df32a6abf0e490d597f32a\n'}, {'number': 8, 'created': '2014-08-06 16:20:14.000000000', 'files': ['ironic/tests/drivers/ilo/test_common.py', 'ironic/common/service.py', 'ironic/tests/api/v1/test_chassis.py', 'ironic/tests/objects/test_node.py', 'ironic/drivers/fake.py', 'ironic/tests/api/v1/test_nodes.py', 'ironic/drivers/pxe.py', 'ironic/tests/objects/test_conductor.py', 'requirements.txt', 'ironic/drivers/modules/deploy_utils.py', 'ironic/db/sqlalchemy/api.py', 'ironic/drivers/modules/ilo/common.py', 'ironic/conductor/utils.py', 'ironic/drivers/modules/seamicro.py', 'ironic/tests/db/test_nodes.py', 'openstack-common.conf', 'ironic/tests/db/test_conductor.py', 'ironic/conductor/task_manager.py', 'ironic/tests/objects/test_objects.py', 'ironic/drivers/modules/agent.py', 'ironic/drivers/modules/iboot.py', 'ironic/common/glance_service/service_utils.py', 'ironic/common/image_service.py', 'ironic/api/controllers/v1/types.py', 'ironic/drivers/modules/ilo/power.py', 'ironic/drivers/ilo.py', 'ironic/conductor/manager.py', 'ironic/tests/api/v1/test_ports.py', 'ironic/drivers/modules/pxe.py', 'ironic/tests/test_images.py', 'ironic/tests/drivers/third_party_driver_mocks.py', 'ironic/drivers/modules/ipmitool.py', 'ironic/drivers/modules/ipminative.py', 'ironic/tests/drivers/ilo/test_power.py', 'ironic/objects/utils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/4723aec443f550feeebd09c4c66e7a26e04de596', 'message': 'Migration to oslo.utils library\n\noslo.utils has been released with the modules excutils, importutils,\nstrutils and timeutils.\n\nChanges done:\n- Use the new oslo.utils modules when possible (not updated in the\nnova.ironic driver and other oslo.incubator modules)\n- importutils.import_module now is importutils.try_import\n- Updated requirements.txt with the new library\n- strutils.to_bytes now is strutils.string_to_bytes\n\nOnce the nova.ironic driver is migrated into nova tree, old references\nand libraries can be cleaned (Bug: #1350269)\n\nCloses-Bug: #1353540\n\nChange-Id: Ic0af04ebd07b23eb94df32a6abf0e490d597f32a\n'}]",0,110596,4723aec443f550feeebd09c4c66e7a26e04de596,48,7,8,1726,,,0,"Migration to oslo.utils library

oslo.utils has been released with the modules excutils, importutils,
strutils and timeutils.

Changes done:
- Use the new oslo.utils modules when possible (not updated in the
nova.ironic driver and other oslo.incubator modules)
- importutils.import_module now is importutils.try_import
- Updated requirements.txt with the new library
- strutils.to_bytes now is strutils.string_to_bytes

Once the nova.ironic driver is migrated into nova tree, old references
and libraries can be cleaned (Bug: #1350269)

Closes-Bug: #1353540

Change-Id: Ic0af04ebd07b23eb94df32a6abf0e490d597f32a
",git fetch https://review.opendev.org/openstack/ironic refs/changes/96/110596/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/drivers/ilo/test_common.py', 'ironic/common/service.py', 'ironic/tests/api/v1/test_chassis.py', 'ironic/tests/objects/test_node.py', 'ironic/drivers/fake.py', 'ironic/tests/api/v1/test_nodes.py', 'ironic/drivers/pxe.py', 'ironic/tests/objects/test_conductor.py', 'requirements.txt', 'ironic/drivers/modules/deploy_utils.py', 'ironic/db/sqlalchemy/api.py', 'ironic/drivers/modules/ilo/common.py', 'ironic/conductor/utils.py', 'ironic/drivers/modules/seamicro.py', 'ironic/common/images.py', 'ironic/tests/db/test_nodes.py', 'ironic/tests/db/test_conductor.py', 'ironic/conductor/task_manager.py', 'ironic/tests/objects/test_objects.py', 'ironic/common/glance_service/service_utils.py', 'ironic/common/image_service.py', 'ironic/openstack/common/fileutils.py', 'ironic/api/controllers/v1/types.py', 'ironic/drivers/modules/ilo/power.py', 'ironic/drivers/ilo.py', 'ironic/conductor/manager.py', 'ironic/tests/api/v1/test_ports.py', 'ironic/drivers/modules/pxe.py', 'ironic/tests/test_images.py', 'ironic/tests/drivers/third_party_driver_mocks.py', 'ironic/drivers/modules/ipmitool.py', 'ironic/drivers/modules/ipminative.py', 'ironic/tests/drivers/ilo/test_power.py', 'ironic/objects/utils.py']",34,98951599aa82fc19612da42ced9cd0bb529391a2,oslo.utils,from oslo.utils import timeutils,from ironic.openstack.common import timeutils ,42,37
openstack%2Fhorizon~master~Ied5a800bf8cec7c846c28149d732f769af56f354,openstack/horizon,master,Ied5a800bf8cec7c846c28149d732f769af56f354,Fix network select widget for launching instances,MERGED,2014-08-06 17:11:33.000000000,2014-08-07 09:09:10.000000000,2014-08-07 09:09:10.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 10295}]","[{'number': 1, 'created': '2014-08-06 17:11:33.000000000', 'files': ['horizon/static/horizon/js/horizon.firewalls.js', 'horizon/static/horizon/js/horizon.instances.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/c30087c100999e644f76b85ea859c989b890b9e3', 'message': 'Fix network select widget for launching instances\n\nThis fixes the problem where the Networking tab of the Launch\nInstance panel does not work if there is more than one network.\nAlso fixes the similar widget used for firewall rules.\n\nChange-Id: Ied5a800bf8cec7c846c28149d732f769af56f354\nCloses-Bug: 1352775\n'}]",0,112358,c30087c100999e644f76b85ea859c989b890b9e3,14,5,1,9647,,,0,"Fix network select widget for launching instances

This fixes the problem where the Networking tab of the Launch
Instance panel does not work if there is more than one network.
Also fixes the similar widget used for firewall rules.

Change-Id: Ied5a800bf8cec7c846c28149d732f769af56f354
Closes-Bug: 1352775
",git fetch https://review.opendev.org/openstack/horizon refs/changes/58/112358/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/horizon/js/horizon.firewalls.js', 'horizon/static/horizon/js/horizon.instances.js']",2,c30087c100999e644f76b85ea859c989b890b9e3,bug/1352775," var lists = $(""#networkListId li"").attr('data-index',100); $(""#networkListId input:checkbox"").removeAttr('checked'); active_networks.each(function(index, value){ $(""#networkListId input:checkbox[value="" + value + ""]"") .prop('checked', true) $(""#networkListId ul"").html("," var lists = $(""#networkListId div.input li"").attr('data-index',100); $(""#networkListId div.input input:checkbox"").removeAttr('checked'); active_networks.each(function(index, value){ $(""#networkListId div.input input:checkbox[value="" + value + ""]"") .attr('checked','checked') $(""#networkListId div.input ul"").html(",10,10
openstack%2Ftempest~master~I4a867ba9ffa43801bb05ce1d33687cb5b9a3e0fb,openstack/tempest,master,I4a867ba9ffa43801bb05ce1d33687cb5b9a3e0fb,Allow out of quota failure status code to be 413 or 403,MERGED,2014-07-02 08:27:59.000000000,2014-08-07 08:57:41.000000000,2014-08-07 08:57:40.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 7139}, {'_account_id': 7148}, {'_account_id': 7872}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-02 08:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0f56fd79c55f530a8257c3bc78b9b862f7d91526', 'message': 'Skip quota-out tests temporary to change error codes\n\nThe commit I2bb8a60ef254afbfed514cfeebe75355d0de4475 tries to change\nerror codes of quota-out to suitable ones (HTTPForbidden).\nWe need to make some quota-out tests skip temporary to merge the above\ncommit. The few ones of this kind of test are already skiped with the\nfollowing commits:\n * If376eda0a7929ba2baa4ac4acbb457883bcfc96d\n * I95c2c7c40763a74ca6eae9f8a28de3e6b482d31b\nHowever some tests still exist.\nThis patch makes the rest of them skip.\n\nChange-Id: I4a867ba9ffa43801bb05ce1d33687cb5b9a3e0fb\nRelated-Bug: #1298131\n'}, {'number': 2, 'created': '2014-07-02 08:31:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/426088b4ee72d984c0b20e57ea07bfe4e7f2219b', 'message': 'Skip quota-out tests temporary to change error codes\n\nThe commit I2bb8a60ef254afbfed514cfeebe75355d0de4475 tries to change\nerror codes of quota-out to suitable ones (HTTPForbidden).\nWe need to make some quota-out tests skip temporary to merge the above\ncommit. The few ones of this kind of test are already skiped with the\nfollowing commits:\n * If376eda0a7929ba2baa4ac4acbb457883bcfc96d\n * I95c2c7c40763a74ca6eae9f8a28de3e6b482d31b\nHowever some tests still exist.\nThis patch makes the rest of them skip.\n\nThe remaining tests are\nhttp://logs.openstack.org/71/95671/11/check/check-tempest-dsvm-full/9b89d3f/logs/testr_results.html.gz\n\nChange-Id: I4a867ba9ffa43801bb05ce1d33687cb5b9a3e0fb\nRelated-Bug: #1298131\n'}, {'number': 3, 'created': '2014-08-05 00:38:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3c31a4d4fa8ebb293398df1b11d562bd32f47cac', 'message': 'Allow out of quota failure status code to be 413 or 403\n\nThe commit I2bb8a60ef254afbfed514cfeebe75355d0de4475 tries to change\nerror codes of quota-out to suitable ones (HTTPForbidden).\nWe need to allow both HTTP413 and HTTP403 because branchless Tempest\nneeds to support both master and icehouse/stable branches.\n\nChange-Id: I4a867ba9ffa43801bb05ce1d33687cb5b9a3e0fb\nRelated-Bug: #1298131\n'}, {'number': 4, 'created': '2014-08-05 01:50:52.000000000', 'files': ['tempest/api/compute/limits/test_absolute_limits_negative.py', 'tempest/api/compute/servers/test_server_personality.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/20f43ed1ba80ee44a74193031b85d4c8cd5130e5', 'message': 'Allow out of quota failure status code to be 413 or 403\n\nThe commit I2bb8a60ef254afbfed514cfeebe75355d0de4475 tries to change\nerror codes of quota-out to suitable ones (HTTPForbidden).\nWe need to allow both HTTP413 and HTTP403 because branchless Tempest\nneeds to support both master and icehouse/stable branches.\n\nChange-Id: I4a867ba9ffa43801bb05ce1d33687cb5b9a3e0fb\nRelated-Bug: #1298131\n'}]",0,104112,20f43ed1ba80ee44a74193031b85d4c8cd5130e5,45,11,4,6167,,,0,"Allow out of quota failure status code to be 413 or 403

The commit I2bb8a60ef254afbfed514cfeebe75355d0de4475 tries to change
error codes of quota-out to suitable ones (HTTPForbidden).
We need to allow both HTTP413 and HTTP403 because branchless Tempest
needs to support both master and icehouse/stable branches.

Change-Id: I4a867ba9ffa43801bb05ce1d33687cb5b9a3e0fb
Related-Bug: #1298131
",git fetch https://review.opendev.org/openstack/tempest refs/changes/12/104112/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/limits/test_absolute_limits_negative.py'],1,0f56fd79c55f530a8257c3bc78b9b862f7d91526,bug/1298131," @test.skip_because(bug=""1298131"") self.assertRaises(exceptions.Unauthorized,"," self.assertRaises(exceptions.OverLimit,",2,1
openstack%2Ftempest~master~I1618344f49cf151cf30ed5470417b27962a70999,openstack/tempest,master,I1618344f49cf151cf30ed5470417b27962a70999,More comments to doc strings,MERGED,2014-08-04 01:21:44.000000000,2014-08-07 08:57:33.000000000,2014-08-07 08:57:32.000000000,"[{'_account_id': 3}, {'_account_id': 5689}, {'_account_id': 6854}, {'_account_id': 7872}, {'_account_id': 9533}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-04 01:21:44.000000000', 'files': ['tempest/api/identity/admin/test_roles.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/a3702fe47826d7884048be8e458a48a3b16299cf', 'message': 'More comments to doc strings\n\nThis patch continues to change comments back to doc strings.\n\nCo-Authored With: Jamie Lennox <jamielennox@redhat.com>\n\nChange-Id: I1618344f49cf151cf30ed5470417b27962a70999\n'}]",0,111605,a3702fe47826d7884048be8e458a48a3b16299cf,15,7,1,6316,,,0,"More comments to doc strings

This patch continues to change comments back to doc strings.

Co-Authored With: Jamie Lennox <jamielennox@redhat.com>

Change-Id: I1618344f49cf151cf30ed5470417b27962a70999
",git fetch https://review.opendev.org/openstack/tempest refs/changes/05/111605/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/identity/admin/test_roles.py'],1,a3702fe47826d7884048be8e458a48a3b16299cf,doc-strings," """"""Return a list of all roles."""""" """"""Role should be created, verified, and deleted."""""" """"""Get a role by its id."""""" """"""Assign a role to a user on a tenant."""""" """"""Remove a role assigned to a user on a tenant."""""" """"""List roles assigned to a user on tenant."""""""," # Return a list of all roles # Role should be created, verified, and deleted # Get a role by its id # Assign a role to a user on a tenant # Remove a role assigned to a user on a tenant # List roles assigned to a user on tenant",6,6
openstack%2Fmanila~master~I02036081e5737bd7b4f11a3fd478acce431c069c,openstack/manila,master,I02036081e5737bd7b4f11a3fd478acce431c069c,Added calculating capacity info in Cmode,MERGED,2014-07-28 11:50:47.000000000,2014-08-07 08:53:34.000000000,2014-08-07 08:53:33.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-07-28 11:50:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/41aa4015d966c3bc9bcf390a76263ccec5af193a', 'message': 'Added calculating capacity info in Cmode\n\nChange-Id: I02036081e5737bd7b4f11a3fd478acce431c069c\nCloses-Bug: 1335113\n'}, {'number': 2, 'created': '2014-07-28 14:07:38.000000000', 'files': ['manila/share/drivers/netapp/cluster_mode.py', 'manila/tests/netapp/test_cmode_drv.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/2ed2c64e6b8dda4c799c1319604636cee90ac426', 'message': 'Added calculating capacity info in Cmode\n\nChange-Id: I02036081e5737bd7b4f11a3fd478acce431c069c\nCloses-Bug: 1335113\n'}]",1,109964,2ed2c64e6b8dda4c799c1319604636cee90ac426,19,4,2,7534,,,0,"Added calculating capacity info in Cmode

Change-Id: I02036081e5737bd7b4f11a3fd478acce431c069c
Closes-Bug: 1335113
",git fetch https://review.opendev.org/openstack/manila refs/changes/64/109964/2 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/netapp/cluster_mode.py', 'manila/tests/netapp/test_cmode_drv.py']",2,41aa4015d966c3bc9bcf390a76263ccec5af193a,bug/1335113," def test_update_share_stats(self): """"""Retrieve status info from share volume group."""""" fake_aggr1_struct = { 'aggr-space-attributes': { 'size-total': '3774873600', 'size-available': '3688566784' } } fake_aggr2_struct = { 'aggr-space-attributes': { 'size-total': '943718400', 'size-available': '45506560' } } fake_aggr1 = naapi.NaElement('root') fake_aggr1.translate_struct(fake_aggr1_struct) fake_aggr2 = naapi.NaElement('root') fake_aggr2.translate_struct(fake_aggr2_struct) self.driver._find_match_aggregates = mock.Mock( return_value=[fake_aggr1, fake_aggr2]) self.driver._update_share_status() res = self.driver._stats expected = {} expected[""share_backend_name""] = self.driver.backend_name expected[""vendor_name""] = 'NetApp' expected[""driver_version""] = '1.0' expected[""storage_protocol""] = 'NFS_CIFS' expected['total_capacity_gb'] = 4 expected['free_capacity_gb'] = 3 expected['reserved_percentage'] = 0 expected['QoS_support'] = False self.assertDictMatch(res, expected) ",,61,8
openstack%2Fdevstack~master~I8a1820946bfc5d8f8c25692f9db67df59506126e,openstack/devstack,master,I8a1820946bfc5d8f8c25692f9db67df59506126e,Set Tempest feature flags for Ironic,MERGED,2014-07-24 14:07:37.000000000,2014-08-07 08:52:00.000000000,2014-08-07 08:51:59.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1420}, {'_account_id': 2750}, {'_account_id': 9009}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-24 14:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f3e02360ee6330701538d6fb8ae5696478ad329a', 'message': 'Set Tempest feature flags for Ironic\n\nMany features tested by Tempest are not relevant to baremetal deployments.\nThis sets compute-feature-enabled flags accordingly.\n\nChange-Id: I8a1820946bfc5d8f8c25692f9db67df59506126e\n'}, {'number': 2, 'created': '2014-07-24 15:11:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4b0ea1e71a0c98d3729b5be435cb6946a40caa28', 'message': 'Set Tempest feature flags for Ironic\n\nMany features tested by Tempest are not relevant to baremetal deployments.\nThis sets compute-feature-enabled flags accordingly.\n\nChange-Id: I8a1820946bfc5d8f8c25692f9db67df59506126e\n'}, {'number': 3, 'created': '2014-08-06 23:42:04.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/fdfe7a010e65935fde22c2af7093e49934035f87', 'message': 'Set Tempest feature flags for Ironic\n\nMany features tested by Tempest are not relevant to baremetal deployments.\nThis sets compute-feature-enabled flags accordingly.\n\nChange-Id: I8a1820946bfc5d8f8c25692f9db67df59506126e\n'}]",0,109300,fdfe7a010e65935fde22c2af7093e49934035f87,24,6,3,1420,,,0,"Set Tempest feature flags for Ironic

Many features tested by Tempest are not relevant to baremetal deployments.
This sets compute-feature-enabled flags accordingly.

Change-Id: I8a1820946bfc5d8f8c25692f9db67df59506126e
",git fetch https://review.opendev.org/openstack/devstack refs/changes/00/109300/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,f3e02360ee6330701538d6fb8ae5696478ad329a,ironic_tempest, iniset $TEMPEST_CONFIG compute-feature-enabled change_password False iniset $TEMPEST_CONFIG compute-feature-enabled console_output False iniset $TEMPEST_CONFIG compute-feature-enabled interace_attach False iniset $TEMPEST_CONFIG compute-feature-enabled live_migration False iniset $TEMPEST_CONFIG compute-feature-enabled pause False iniset $TEMPEST_CONFIG compute-feature-enabled rescue False iniset $TEMPEST_CONFIG compute-feature-enabled resize False iniset $TEMPEST_CONFIG compute-feature-enabled shelve False iniset $TEMPEST_CONFIG compute-feature-enabled snapshot False,,9,0
openstack%2Ftempest~master~Ia0cec5c699470554a25c077082878772158f4c5a,openstack/tempest,master,Ia0cec5c699470554a25c077082878772158f4c5a,Remove unnecessary log message,MERGED,2014-07-02 01:00:29.000000000,2014-08-07 08:51:44.000000000,2014-08-07 08:51:43.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5174}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 10016}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-02 01:00:29.000000000', 'files': ['tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/70ea1ca2ff4c0b0adc3d5f84a787ad496078868d', 'message': ""Remove unnecessary log message\n\nThis commit removes a useless log message from call_until_true. The\ndebug log there provides no useful debug information, just printing\nthat the sleep loop iterated doesn't enable any extra debugging. In\nthe worst case it ends up polluting the logs with the same message\nwhile the loop times out. So let's just remove it.\n\nCloses-Bug: #1336591\nChange-Id: Ia0cec5c699470554a25c077082878772158f4c5a\n""}]",1,104045,70ea1ca2ff4c0b0adc3d5f84a787ad496078868d,22,10,1,5196,,,0,"Remove unnecessary log message

This commit removes a useless log message from call_until_true. The
debug log there provides no useful debug information, just printing
that the sleep loop iterated doesn't enable any extra debugging. In
the worst case it ends up polluting the logs with the same message
while the loop times out. So let's just remove it.

Closes-Bug: #1336591
Change-Id: Ia0cec5c699470554a25c077082878772158f4c5a
",git fetch https://review.opendev.org/openstack/tempest refs/changes/45/104045/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/test.py'],1,70ea1ca2ff4c0b0adc3d5f84a787ad496078868d,remove-useless-logs,," LOG.debug(""Sleeping for %d seconds"", sleep_for)",0,1
openstack%2Ftrove~master~If3c001ed57000dfe53201c509ca3671ca4e20fd7,openstack/trove,master,If3c001ed57000dfe53201c509ca3671ca4e20fd7,lost pycrypto requirement leads to ImportError,ABANDONED,2014-08-07 03:50:08.000000000,2014-08-07 08:46:45.000000000,,"[{'_account_id': 3}, {'_account_id': 7092}]","[{'number': 1, 'created': '2014-08-07 03:50:08.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/trove/commit/3c9659ae4ccdff59957b29184a6ae14e9f2539c8', 'message': 'lost pycrypto requirement leads to ImportError\n\nWhen porting oslo.config.generator to automatically generate trove\nconf files, an ImportError happens\nwhen trove.openstack.common.rpc.securemessage is imported as module.\n\nChange-Id: If3c001ed57000dfe53201c509ca3671ca4e20fd7\nCloses-Bug: #1353799\nRelated-Bug: #1234338\n'}]",0,112464,3c9659ae4ccdff59957b29184a6ae14e9f2539c8,6,2,1,7805,,,0,"lost pycrypto requirement leads to ImportError

When porting oslo.config.generator to automatically generate trove
conf files, an ImportError happens
when trove.openstack.common.rpc.securemessage is imported as module.

Change-Id: If3c001ed57000dfe53201c509ca3671ca4e20fd7
Closes-Bug: #1353799
Related-Bug: #1234338
",git fetch https://review.opendev.org/openstack/trove refs/changes/64/112464/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3c9659ae4ccdff59957b29184a6ae14e9f2539c8,bug/1353799,pycrypto,,1,0
openstack%2Fneutron~master~I29165dc8966e434aec786374b14cb24a6d3f6df5,openstack/neutron,master,I29165dc8966e434aec786374b14cb24a6d3f6df5,Removed unnecessary patch and used native mock capabilities.,ABANDONED,2014-08-06 05:50:07.000000000,2014-08-07 08:40:41.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-08-06 05:50:07.000000000', 'files': ['neutron/tests/unit/ml2/drivers/cisco/nexus/test_cisco_mech.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bd6ec2a9811ad0f9e91e615ef88f473354dd8019', 'message': ""Removed unnecessary patch and used native mock capabilities.\n\nBased on Henry's review feedback for bug 1352635.\n\nChange-Id: I29165dc8966e434aec786374b14cb24a6d3f6df5\nCloses-Bug: 1352635\n""}]",0,112198,bd6ec2a9811ad0f9e91e615ef88f473354dd8019,17,14,1,6139,,,0,"Removed unnecessary patch and used native mock capabilities.

Based on Henry's review feedback for bug 1352635.

Change-Id: I29165dc8966e434aec786374b14cb24a6d3f6df5
Closes-Bug: 1352635
",git fetch https://review.opendev.org/openstack/neutron refs/changes/98/112198/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/ml2/drivers/cisco/nexus/test_cisco_mech.py'],1,bd6ec2a9811ad0f9e91e615ef88f473354dd8019,bug/1352635," # The code we are exercising calls connect() twice, if there is a # TypeError on the first call (if the old ncclient is installed). # The second call should succeed. That's what we are simulating here. connect = self.mock_ncclient.connect with self._patch_ncclient('connect.side_effect', [ TypeError, connect ]): def test_ncclient_fail_on_second_connect(self): """"""Test that other errors during the connect() call sequence are still handled. If the old ncclient is installed, we expect to get a TypeError first, but should still handle other errors in the usual way, whether they appear on the first or second call to connect(). """""" with self._patch_ncclient('connect.side_effect', [ TypeError, IOError ]): with self._create_resources() as result: self._assertExpectedHTTP(result.status_int, c_exc.NexusConnectFailed) "," def _patch_ncclient_connect(self): """"""Patch ncclient.connect to cause TypeError on first call. Subsequent call shouldn't cause exception and should be handled normally. This is to emulate the expected behavior if the old ncclient library is installed: It doesn't understand a new parameter that's passed to it by the Cisco ML2 driver. The driver will retry a second time with the old function signature if this happens. This second call is expected to succeed. """""" # Mock connect excepts everything, so we put that back in place # the second call. orig_mock_connect = self.mock_ncclient.connect def patch_newsig_connect(**kwargs): self.mock_ncclient.connect = orig_mock_connect raise TypeError() self.mock_ncclient.connect = patch_newsig_connect yield @contextlib.contextmanager # Patching ncclient.connect so that it causes a TypeError on the # first call. Cisco ML2 driver code will then retry with different # calling signature (no TypeError on second try) with self._patch_ncclient_connect():",20,26
openstack%2Fnova~master~I73f1a15d8e08a3eda3190e660338e274358ddd33,openstack/nova,master,I73f1a15d8e08a3eda3190e660338e274358ddd33,Fix duplicated images in test_block_device_mapping,MERGED,2014-07-24 09:58:07.000000000,2014-08-07 08:05:18.000000000,2014-08-07 08:05:15.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 642}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-07-24 09:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dcc82420f7489d39559a6f10be6abd01811114fd', 'message': 'Fix duplicated images in test_block_device_mapping\n\nIn test_block_device_mapping, each test can select to specify\nimage_ref, block_device_mapping or both. The ""both"" should be\nnegative tests because nova API gets image_id from either image_ref\nor block_device_mapping.\nHowever, there are some ""both"" tests which are not their purposes.\nThis patch fixes these tests for their purposes.\n\nThese bugs were found through jsonschema validation framework\ndevelopment, because the schema could detect ""both"" cases fastly\nand these tests could not get their purposes.\n\nChange-Id: I73f1a15d8e08a3eda3190e660338e274358ddd33\n'}, {'number': 2, 'created': '2014-07-24 10:05:09.000000000', 'files': ['nova/tests/api/openstack/compute/plugins/v3/test_block_device_mapping.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/62e33be84d7ad3931104b27a02bd796f58972d04', 'message': 'Fix duplicated images in test_block_device_mapping\n\nIn test_block_device_mapping, each test can select to specify\nimage_ref, block_device_mapping or both. The ""both"" should be\nnegative tests because nova API gets image_id from either image_ref\nor block_device_mapping.\nHowever, there are some ""both"" tests which are not their purposes.\nThis patch fixes these tests for their purposes by passing True as\nno_image.\n\nThese bugs were found through jsonschema validation framework\ndevelopment, because the schema could detect ""both"" cases fastly\nand these tests could not get their purposes.\n\nChange-Id: I73f1a15d8e08a3eda3190e660338e274358ddd33\n'}]",0,109236,62e33be84d7ad3931104b27a02bd796f58972d04,26,8,2,6167,,,0,"Fix duplicated images in test_block_device_mapping

In test_block_device_mapping, each test can select to specify
image_ref, block_device_mapping or both. The ""both"" should be
negative tests because nova API gets image_id from either image_ref
or block_device_mapping.
However, there are some ""both"" tests which are not their purposes.
This patch fixes these tests for their purposes by passing True as
no_image.

These bugs were found through jsonschema validation framework
development, because the schema could detect ""both"" cases fastly
and these tests could not get their purposes.

Change-Id: I73f1a15d8e08a3eda3190e660338e274358ddd33
",git fetch https://review.opendev.org/openstack/nova refs/changes/36/109236/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/api/openstack/compute/plugins/v3/test_block_device_mapping.py'],1,dcc82420f7489d39559a6f10be6abd01811114fd,fix_unittests," self.assertRaises(exc.HTTPBadRequest, self._test_create, params, no_image=True) self.assertRaises(exc.HTTPBadRequest, self._test_create, params, no_image=True) self.assertRaises(exc.HTTPBadRequest, self._test_create, params, no_image=True) self.assertRaises(exc.HTTPBadRequest, self._test_create, params, no_image=True) self.assertRaises(exc.HTTPBadRequest, self._test_create, params, no_image=True) self._test_create(params, no_image=True) self._test_create(params, no_image=True) self.assertRaises(exc.HTTPBadRequest, self._test_create, params, no_image=True)"," self.assertRaises(exc.HTTPBadRequest, self._test_create, params) self.assertRaises(exc.HTTPBadRequest, self._test_create, params) self.assertRaises(exc.HTTPBadRequest, self._test_create, params) self.assertRaises(exc.HTTPBadRequest, self._test_create, params) self.assertRaises(exc.HTTPBadRequest, self._test_create, params) self._test_create(params) self._test_create(params) self.assertRaises(exc.HTTPBadRequest, self._test_create, params)",14,8
openstack%2Ffuel-library~master~Id047599a496564de1cdfce6457bd1bedd4adf7a5,openstack/fuel-library,master,Id047599a496564de1cdfce6457bd1bedd4adf7a5,Configure ubuntu upstart to start Mellanox OFED drivers before openvswitch starts,MERGED,2014-08-04 11:27:25.000000000,2014-08-07 07:54:23.000000000,2014-08-07 07:54:23.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11968}, {'_account_id': 12065}, {'_account_id': 12171}, {'_account_id': 12177}]","[{'number': 1, 'created': '2014-08-04 11:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/93b08c1f56425eaf5f4e694273a29c7d77323d08', 'message': 'Configure ubuntu upstart to start Mellanox OFED drivers before openvswitch starts\n\nChange-Id: Id047599a496564de1cdfce6457bd1bedd4adf7a5\nCloses-bug: #1351852\nSigned-off-by: gilmeir <gilmeir@mellanox.com>\n'}, {'number': 2, 'created': '2014-08-04 11:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4693497f17c4c2ffc8279746c36243cf6df1988a', 'message': 'Configure ubuntu upstart to start Mellanox OFED drivers before openvswitch starts\n\nChange-Id: Id047599a496564de1cdfce6457bd1bedd4adf7a5\nCloses-bug: #1351852\nSigned-off-by: gilmeir <gilmeir@mellanox.com>\n'}, {'number': 3, 'created': '2014-08-06 13:10:10.000000000', 'files': ['deployment/puppet/mellanox_openstack/manifests/openibd.pp', 'deployment/puppet/mellanox_openstack/files/openibd.conf', 'deployment/puppet/osnailyfacter/examples/site.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/85a2bb44ae2e92aaef9138579045297a44a6b769', 'message': 'Configure ubuntu upstart to start Mellanox OFED drivers before openvswitch starts\n\nChange-Id: Id047599a496564de1cdfce6457bd1bedd4adf7a5\nCloses-bug: #1351852\nSigned-off-by: gilmeir <gilmeir@mellanox.com>\n'}]",25,111696,85a2bb44ae2e92aaef9138579045297a44a6b769,55,13,3,12177,,,0,"Configure ubuntu upstart to start Mellanox OFED drivers before openvswitch starts

Change-Id: Id047599a496564de1cdfce6457bd1bedd4adf7a5
Closes-bug: #1351852
Signed-off-by: gilmeir <gilmeir@mellanox.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/96/111696/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/mellanox_openstack/manifests/openibd.pp', 'deployment/puppet/mellanox_openstack/files/openibd.conf', 'deployment/puppet/osnailyfacter/examples/site.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp']",5,93b08c1f56425eaf5f4e694273a29c7d77323d08,mellanox, if ($::mellanox_mode == 'ethernet') { if ($::mellanox_mode == 'ethernet') { if ($::mellanox_mode == 'ethernet') {, if $::use_mellanox_plugin { if $::use_mellanox_plugin { if $::use_mellanox_plugin {,38,10
openstack%2Fironic~master~I60ea98b3381cbbc3d2905af224792ee68b423825,openstack/ironic,master,I60ea98b3381cbbc3d2905af224792ee68b423825,Sync oslo.incubator modules,MERGED,2014-07-31 12:32:03.000000000,2014-08-07 07:38:41.000000000,2014-08-07 07:38:40.000000000,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 1994}, {'_account_id': 6623}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-07-31 12:32:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b3018927b6835a75904a2d88f5331ba52de6bc80', 'message': 'Sync oslo.incubator modules\n\nUpdate the openstack.common modules from oslo.incubator\nto have a current copy needed to start using new released\noslo libraries.\n\nChange-Id: I60ea98b3381cbbc3d2905af224792ee68b423825\n'}, {'number': 2, 'created': '2014-07-31 14:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4511062c6bd17441614e8aef7d53607aa2fd3ff9', 'message': 'Sync oslo.incubator modules\n\nUpdate the openstack.common modules from oslo.incubator\nto have a current copy needed to start using new released\noslo libraries.\n\nChange-Id: I60ea98b3381cbbc3d2905af224792ee68b423825\n'}, {'number': 3, 'created': '2014-08-05 08:45:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b950f2d40e17713d7984c25d7891d56837d043aa', 'message': 'Sync oslo.incubator modules\n\nUpdate the openstack.common modules from oslo.incubator\nto have a current copy needed to start using new released\noslo libraries.\n\nChange-Id: I60ea98b3381cbbc3d2905af224792ee68b423825\n'}, {'number': 4, 'created': '2014-08-05 22:29:05.000000000', 'files': ['ironic/openstack/common/loopingcall.py', 'ironic/openstack/common/lockutils.py', 'tools/config/generate_sample.sh', 'ironic/openstack/common/local.py', 'ironic/openstack/common/apiclient/base.py', 'ironic/openstack/common/threadgroup.py', 'ironic/openstack/common/log.py', 'ironic/openstack/common/apiclient/exceptions.py', 'ironic/openstack/common/importutils.py', 'etc/ironic/ironic.conf.sample', 'tools/config/check_uptodate.sh', 'ironic/openstack/common/apiclient/__init__.py', 'ironic/openstack/common/apiclient/client.py', 'ironic/openstack/common/cliutils.py', 'ironic/openstack/common/config/generator.py', 'ironic/openstack/common/network_utils.py', 'ironic/openstack/common/uuidutils.py', 'ironic/openstack/common/periodic_task.py', 'ironic/openstack/common/service.py', 'ironic/openstack/common/apiclient/fake_client.py', 'ironic/openstack/common/jsonutils.py', 'ironic/openstack/common/versionutils.py', 'ironic/openstack/common/fileutils.py', 'ironic/openstack/common/gettextutils.py', 'ironic/openstack/common/systemd.py', 'ironic/openstack/common/context.py', 'ironic/openstack/common/eventlet_backdoor.py', 'ironic/openstack/common/processutils.py', 'ironic/openstack/common/apiclient/auth.py', 'tools/install_venv_common.py', 'ironic/openstack/common/timeutils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/689052700c74fdc19c116641eb22df04a42f817f', 'message': 'Sync oslo.incubator modules\n\nUpdate the openstack.common modules from oslo.incubator\nto have a current copy needed to start using new released\noslo libraries.\n\nChange-Id: I60ea98b3381cbbc3d2905af224792ee68b423825\n'}]",0,110941,689052700c74fdc19c116641eb22df04a42f817f,45,8,4,1726,,,0,"Sync oslo.incubator modules

Update the openstack.common modules from oslo.incubator
to have a current copy needed to start using new released
oslo libraries.

Change-Id: I60ea98b3381cbbc3d2905af224792ee68b423825
",git fetch https://review.opendev.org/openstack/ironic refs/changes/41/110941/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/openstack/common/loopingcall.py', 'ironic/openstack/common/lockutils.py', 'tools/config/generate_sample.sh', 'ironic/openstack/common/local.py', 'ironic/openstack/common/apiclient/base.py', 'ironic/openstack/common/strutils.py', 'ironic/openstack/common/threadgroup.py', 'ironic/openstack/common/log.py', 'ironic/openstack/common/apiclient/exceptions.py', 'ironic/openstack/common/importutils.py', 'tools/config/check_uptodate.sh', 'ironic/openstack/common/apiclient/__init__.py', 'ironic/openstack/common/apiclient/client.py', 'ironic/openstack/common/cliutils.py', 'ironic/openstack/common/config/generator.py', 'ironic/openstack/common/network_utils.py', 'ironic/openstack/common/uuidutils.py', 'ironic/openstack/common/periodic_task.py', 'ironic/openstack/common/service.py', 'ironic/openstack/common/apiclient/fake_client.py', 'ironic/openstack/common/jsonutils.py', 'ironic/openstack/common/versionutils.py', 'ironic/openstack/common/gettextutils.py', 'ironic/openstack/common/systemd.py', 'ironic/openstack/common/context.py', 'ironic/openstack/common/eventlet_backdoor.py', 'ironic/openstack/common/processutils.py', 'ironic/openstack/common/apiclient/auth.py', 'tools/install_venv_common.py', 'ironic/openstack/common/timeutils.py']",30,b3018927b6835a75904a2d88f5331ba52de6bc80,oslo.incubator," else: before = before.replace(tzinfo=None) else: after = after.replace(tzinfo=None) """"""Returns an iso8601 formatted date from timestamp."""""" assert utcnow.override_time is not None return total_seconds(delta) def total_seconds(delta): """"""Return the total seconds of datetime.timedelta object. Compute total seconds of datetime.timedelta, datetime.timedelta doesn't have method total_seconds in Python2.6, calculate it manually. """""" :param dt: the time :param window: minimum seconds to remain to consider the time not soon","# vim: tabstop=4 shiftwidth=4 softtabstop=4 """"""Returns a iso8601 formated date from timestamp."""""" assert(not utcnow.override_time is None) :params dt: the time :params window: minimum seconds to remain to consider the time not soon",3240,527
openstack%2Fnova~master~Id0109c56070e2f920be0f95738749aa969258bc1,openstack/nova,master,Id0109c56070e2f920be0f95738749aa969258bc1,servers list API support specify multi-status,MERGED,2014-06-03 15:00:17.000000000,2014-08-07 06:48:08.000000000,2014-08-07 06:48:05.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 9847}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-06-03 15:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/525cd7c7475d94b52d62ec96e9be6cc0fabdd249', 'message': 'servers list API support specify multi-status\n\nSupport to specify multiple status values concurrently in servers list API.\nblueprint servers-list-support-multi-status\n\nChange-Id: Id0109c56070e2f920be0f95738749aa969258bc1\n'}, {'number': 2, 'created': '2014-06-05 00:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ae25d0fe437962d7b3a7b28c3b7b1e1118759047', 'message': 'servers list API support specify multi-status\n\nSupport to specify multiple status values concurrently in servers list API.\nblueprint servers-list-support-multi-status\n\nChange-Id: Id0109c56070e2f920be0f95738749aa969258bc1\n'}, {'number': 3, 'created': '2014-06-05 02:20:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9bbe5f51543ab76fb3aed980749610d818ccdb2a', 'message': 'servers list API support specify multi-status\n\nSupport to specify multiple status values concurrently in servers list API.\nblueprint servers-list-support-multi-status\n\nChange-Id: Id0109c56070e2f920be0f95738749aa969258bc1\n'}, {'number': 4, 'created': '2014-06-05 08:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce166cbb5d7dff699c2f5607c5f0a36817b3d15c', 'message': 'servers list API support specify multi-status\n\nSupport to specify multiple status values concurrently in servers list API.\nblueprint servers-list-support-multi-status\n\nChange-Id: Id0109c56070e2f920be0f95738749aa969258bc1\n'}, {'number': 5, 'created': '2014-06-05 14:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e03115a977213734275bd811cf7c78d10fa885b5', 'message': 'servers list API support specify multi-status\n\nSupport to specify multiple status values concurrently in servers list API.\nblueprint servers-list-support-multi-status\n\nChange-Id: Id0109c56070e2f920be0f95738749aa969258bc1\n'}, {'number': 6, 'created': '2014-06-06 15:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1978eedc383644c6020916a193f8c0dd4809a34d', 'message': 'servers list API support specify multi-status\n\nSupport to specify multiple status values concurrently in servers list API.\n\nblueprint servers-list-support-multi-status\nChange-Id: Id0109c56070e2f920be0f95738749aa969258bc1\n'}, {'number': 7, 'created': '2014-06-09 17:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/27f51f9f272eadf91c82ebce620ad2e3bb7aed5e', 'message': 'servers list API support specify multi-status\n\nSupport to specify multiple status values concurrently in servers list API.\n\nblueprint servers-list-support-multi-status\n\nChange-Id: Id0109c56070e2f920be0f95738749aa969258bc1\n'}, {'number': 8, 'created': '2014-07-02 08:45:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e5a03277bdc4605886725c6aca0f8db605e2c5e0', 'message': 'servers list API support specify multi-status\n\nCurrently the service list API allows the user to specify an optional status\nvalue to use as a filter - for example to limit the list to only servers with\na status of Active.\n\nHowever often the user wants to filter the list by a set of status values,\nfor example list servers with a status of Active or Error,\nwhich requires two separate API calls.\n\nAllowing the API to accept a list of status values would reduce this to a\nsingle API call.\nAllow to specify status value for many times in a request.\nFor example::\n    GET /v2/{tenant_id}/servers?status=ACTIVE&status=ERROR\n    GET /v3/servers?status=ACTIVE&status=ERROR\nV2 API extension::\n    {\n        ""alias"": ""os-server-list-multi-status"",\n        ""description"": ""Allow to filter the\n            servers by a set of status values."",\n        ""links"": [],\n        ""name"": ""ServerListMultiStatus"",\n        ""namespace"": ""http://docs.openstack.org/compute/ext/\n            os-server-list-multi-status/api/v2"",\n        ""updated"": ""2014-05-11T00:00:00Z""\n    }\n\nDocImpact: Adds os-server-list-multi-status extension.\n\nblueprint servers-list-support-multi-status\n\nChange-Id: Id0109c56070e2f920be0f95738749aa969258bc1\n'}, {'number': 9, 'created': '2014-07-02 17:45:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/97342ca08556d32594ae6375e6b2cd2d49d09ed7', 'message': 'servers list API support specify multi-status\n\nCurrently the service list API allows the user to specify an optional status\nvalue to use as a filter - for example to limit the list to only servers with\na status of Active.\n\nHowever often the user wants to filter the list by a set of status values,\nfor example list servers with a status of Active or Error,\nwhich requires two separate API calls.\n\nAllowing the API to accept a list of status values would reduce this to a\nsingle API call.\nAllow to specify status value for many times in a request.\nFor example::\n    GET /v2/{tenant_id}/servers?status=ACTIVE&status=ERROR\n    GET /v3/servers?status=ACTIVE&status=ERROR\nV2 API extension::\n    {\n        ""alias"": ""os-server-list-multi-status"",\n        ""description"": ""Allow to filter the\n            servers by a set of status values."",\n        ""links"": [],\n        ""name"": ""ServerListMultiStatus"",\n        ""namespace"": ""http://docs.openstack.org/compute/ext/\n            os-server-list-multi-status/api/v2"",\n        ""updated"": ""2014-05-11T00:00:00Z""\n    }\n\nDocImpact: Adds os-server-list-multi-status extension.\n\nblueprint servers-list-support-multi-status\n\nChange-Id: Id0109c56070e2f920be0f95738749aa969258bc1\n'}, {'number': 10, 'created': '2014-07-03 02:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd3247289ecfe625d65db6f6fdafbd065fc68ff3', 'message': 'servers list API support specify multi-status\n\nCurrently the service list API allows the user to specify an optional status\nvalue to use as a filter - for example to limit the list to only servers with\na status of Active.\n\nHowever often the user wants to filter the list by a set of status values,\nfor example list servers with a status of Active or Error,\nwhich requires two separate API calls.\n\nAllowing the API to accept a list of status values would reduce this to a\nsingle API call.\nAllow to specify status value for many times in a request.\nFor example::\n    GET /v2/{tenant_id}/servers?status=ACTIVE&status=ERROR\n    GET /v3/servers?status=ACTIVE&status=ERROR\nV2 API extension::\n    {\n        ""alias"": ""os-server-list-multi-status"",\n        ""description"": ""Allow to filter the\n            servers by a set of status values."",\n        ""links"": [],\n        ""name"": ""ServerListMultiStatus"",\n        ""namespace"": ""http://docs.openstack.org/compute/ext/\n            os-server-list-multi-status/api/v2"",\n        ""updated"": ""2014-05-11T00:00:00Z""\n    }\n\nDocImpact: Adds os-server-list-multi-status extension.\n\nblueprint servers-list-support-multi-status\n\nChange-Id: Id0109c56070e2f920be0f95738749aa969258bc1\n'}, {'number': 11, 'created': '2014-07-03 12:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/181655d05450f06171260e87dce855b6665b4e1b', 'message': 'servers list API support specify multi-status\n\nCurrently the service list API allows the user to specify an optional status\nvalue to use as a filter - for example to limit the list to only servers with\na status of Active.\n\nHowever often the user wants to filter the list by a set of status values,\nfor example list servers with a status of Active or Error,\nwhich requires two separate API calls.\n\nAllowing the API to accept a list of status values would reduce this to a\nsingle API call.\nAllow to specify status value for many times in a request.\nFor example::\n    GET /v2/{tenant_id}/servers?status=ACTIVE&status=ERROR\n    GET /v3/servers?status=ACTIVE&status=ERROR\nV2 API extension::\n    {\n        ""alias"": ""os-server-list-multi-status"",\n        ""description"": ""Allow to filter the\n            servers by a set of status values."",\n        ""links"": [],\n        ""name"": ""ServerListMultiStatus"",\n        ""namespace"": ""http://docs.openstack.org/compute/ext/\n            os-server-list-multi-status/api/v2"",\n        ""updated"": ""2014-05-11T00:00:00Z""\n    }\n\nDocImpact: Adds os-server-list-multi-status extension.\n\nblueprint servers-list-support-multi-status\n\nChange-Id: Id0109c56070e2f920be0f95738749aa969258bc1\n'}, {'number': 12, 'created': '2014-07-03 16:04:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/82c40f704bf1b7f031d6f384e040ce00d25b5adb', 'message': 'servers list API support specify multi-status\n\nCurrently the service list API allows the user to specify an optional status\nvalue to use as a filter - for example to limit the list to only servers with\na status of Active.\n\nHowever often the user wants to filter the list by a set of status values,\nfor example list servers with a status of Active or Error,\nwhich requires two separate API calls.\n\nAllowing the API to accept a list of status values would reduce this to a\nsingle API call.\nAllow to specify status value for many times in a request.\nFor example::\n    GET /v2/{tenant_id}/servers?status=ACTIVE&status=ERROR\n    GET /v3/servers?status=ACTIVE&status=ERROR\nV2 API extension::\n    {\n        ""alias"": ""os-server-list-multi-status"",\n        ""description"": ""Allow to filter the\n            servers by a set of status values."",\n        ""links"": [],\n        ""name"": ""ServerListMultiStatus"",\n        ""namespace"": ""http://docs.openstack.org/compute/ext/\n            os-server-list-multi-status/api/v2"",\n        ""updated"": ""2014-05-11T00:00:00Z""\n    }\n\nDocImpact: Adds os-server-list-multi-status extension.\n\nblueprint servers-list-support-multi-status\n\nChange-Id: Id0109c56070e2f920be0f95738749aa969258bc1\n'}, {'number': 13, 'created': '2014-07-18 08:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/355053ba4062aa2510f8476c963b3677b61d9234', 'message': 'servers list API support specify multi-status\n\nCurrently the service list API allows the user to specify an optional status\nvalue to use as a filter - for example to limit the list to only servers with\na status of Active.\n\nHowever often the user wants to filter the list by a set of status values,\nfor example list servers with a status of Active or Error,\nwhich requires two separate API calls.\n\nAllowing the API to accept a list of status values would reduce this to a\nsingle API call.\nAllow to specify status value for many times in a request.\nFor example::\n    GET /v2/{tenant_id}/servers?status=ACTIVE&status=ERROR\n    GET /v3/servers?status=ACTIVE&status=ERROR\nV2 API extension::\n    {\n        ""alias"": ""os-server-list-multi-status"",\n        ""description"": ""Allow to filter the\n            servers by a set of status values."",\n        ""links"": [],\n        ""name"": ""ServerListMultiStatus"",\n        ""namespace"": ""http://docs.openstack.org/compute/ext/\n            os-server-list-multi-status/api/v2"",\n        ""updated"": ""2014-05-11T00:00:00Z""\n    }\n\nDocImpact: Adds os-server-list-multi-status extension.\n\nblueprint servers-list-support-multi-status\n\nChange-Id: Id0109c56070e2f920be0f95738749aa969258bc1\n'}, {'number': 14, 'created': '2014-07-18 15:26:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/656f98b63b436d4791d5a8764c8b92904c4b5724', 'message': 'servers list API support specify multi-status\n\nCurrently the service list API allows the user to specify an optional status\nvalue to use as a filter - for example to limit the list to only servers with\na status of Active.\n\nHowever often the user wants to filter the list by a set of status values,\nfor example list servers with a status of Active or Error,\nwhich requires two separate API calls.\n\nAllowing the API to accept a list of status values would reduce this to a\nsingle API call.\nAllow to specify status value for many times in a request.\nFor example::\n    GET /v2/{tenant_id}/servers?status=ACTIVE&status=ERROR\n    GET /v3/servers?status=ACTIVE&status=ERROR\nV2 API extension::\n    {\n        ""alias"": ""os-server-list-multi-status"",\n        ""description"": ""Allow to filter the\n            servers by a set of status values."",\n        ""links"": [],\n        ""name"": ""ServerListMultiStatus"",\n        ""namespace"": ""http://docs.openstack.org/compute/ext/\n            os-server-list-multi-status/api/v2"",\n        ""updated"": ""2014-05-11T00:00:00Z""\n    }\n\nDocImpact: Adds os-server-list-multi-status extension.\n\nblueprint servers-list-support-multi-status\n\nChange-Id: Id0109c56070e2f920be0f95738749aa969258bc1\n'}, {'number': 15, 'created': '2014-07-22 16:25:01.000000000', 'files': ['nova/tests/api/openstack/test_common.py', 'doc/api_samples/os-server-list-multi-status/server-post-resp.xml', 'nova/tests/integrated/api_samples/os-server-list-multi-status/servers-list-resp.xml.tpl', 'doc/api_samples/os-server-list-multi-status/server-post-resp.json', 'nova/api/openstack/common.py', 'nova/tests/integrated/api_samples/all_extensions/extensions-get-resp.xml.tpl', 'doc/api_samples/all_extensions/extensions-get-resp.xml', 'doc/api_samples/os-server-list-multi-status/servers-list-resp.xml', 'nova/tests/integrated/api_samples/os-server-list-multi-status/server-post-req.xml.tpl', 'nova/tests/integrated/api_samples/os-server-list-multi-status/server-post-resp.xml.tpl', 'nova/tests/integrated/test_api_samples.py', 'nova/tests/integrated/api_samples/os-server-list-multi-status/server-post-req.json.tpl', 'nova/tests/integrated/api_samples/os-server-list-multi-status/servers-list-resp.json.tpl', 'nova/tests/api/openstack/compute/test_servers.py', 'doc/api_samples/all_extensions/extensions-get-resp.json', 'nova/api/openstack/compute/contrib/server_list_multi_status.py', 'nova/tests/integrated/api_samples/os-server-list-multi-status/server-post-resp.json.tpl', 'doc/api_samples/os-server-list-multi-status/servers-list-resp.json', 'nova/api/openstack/compute/servers.py', 'nova/tests/api/openstack/compute/test_extensions.py', 'doc/api_samples/os-server-list-multi-status/server-post-req.xml', 'doc/api_samples/os-server-list-multi-status/server-post-req.json', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/tests/integrated/api_samples/all_extensions/extensions-get-resp.json.tpl'], 'web_link': 'https://opendev.org/openstack/nova/commit/ab32995fed7084c68147eb837201767f673e89f5', 'message': 'servers list API support specify multi-status\n\nCurrently the service list API allows the user to specify an optional status\nvalue to use as a filter - for example to limit the list to only servers with\na status of Active.\n\nHowever often the user wants to filter the list by a set of status values,\nfor example list servers with a status of Active or Error,\nwhich requires two separate API calls.\n\nAllowing the API to accept a list of status values would reduce this to a\nsingle API call.\nAllow to specify status value for many times in a request.\nFor example::\n    GET /v2/{tenant_id}/servers?status=ACTIVE&status=ERROR\n    GET /v3/servers?status=ACTIVE&status=ERROR\nV2 API extension::\n    {\n        ""alias"": ""os-server-list-multi-status"",\n        ""description"": ""Allow to filter the\n            servers by a set of status values."",\n        ""links"": [],\n        ""name"": ""ServerListMultiStatus"",\n        ""namespace"": ""http://docs.openstack.org/compute/ext/\n            os-server-list-multi-status/api/v2"",\n        ""updated"": ""2014-05-11T00:00:00Z""\n    }\n\nDocImpact: Adds os-server-list-multi-status extension.\n\nblueprint servers-list-support-multi-status\n\nChange-Id: Id0109c56070e2f920be0f95738749aa969258bc1\n'}]",32,97529,ab32995fed7084c68147eb837201767f673e89f5,177,15,15,9847,,,0,"servers list API support specify multi-status

Currently the service list API allows the user to specify an optional status
value to use as a filter - for example to limit the list to only servers with
a status of Active.

However often the user wants to filter the list by a set of status values,
for example list servers with a status of Active or Error,
which requires two separate API calls.

Allowing the API to accept a list of status values would reduce this to a
single API call.
Allow to specify status value for many times in a request.
For example::
    GET /v2/{tenant_id}/servers?status=ACTIVE&status=ERROR
    GET /v3/servers?status=ACTIVE&status=ERROR
V2 API extension::
    {
        ""alias"": ""os-server-list-multi-status"",
        ""description"": ""Allow to filter the
            servers by a set of status values."",
        ""links"": [],
        ""name"": ""ServerListMultiStatus"",
        ""namespace"": ""http://docs.openstack.org/compute/ext/
            os-server-list-multi-status/api/v2"",
        ""updated"": ""2014-05-11T00:00:00Z""
    }

DocImpact: Adds os-server-list-multi-status extension.

blueprint servers-list-support-multi-status

Change-Id: Id0109c56070e2f920be0f95738749aa969258bc1
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/97529/9 && git format-patch -1 --stdout FETCH_HEAD,"['doc/api_samples/all_extensions/extensions-get-resp.xml', 'nova/tests/api/openstack/compute/test_extensions.py', 'nova/tests/api/openstack/compute/test_servers.py', 'doc/api_samples/all_extensions/extensions-get-resp.json', 'nova/tests/api/openstack/test_common.py', 'nova/api/openstack/compute/plugins/v3/servers.py', 'nova/api/openstack/compute/contrib/server_list_multi_status.py', 'nova/api/openstack/common.py', 'nova/tests/integrated/api_samples/all_extensions/extensions-get-resp.json.tpl', 'nova/tests/integrated/api_samples/all_extensions/extensions-get-resp.xml.tpl', 'nova/api/openstack/compute/servers.py']",11,525cd7c7475d94b52d62ec96e9be6cc0fabdd249,bp/servers-list-support-multi-status," search_opts.pop('status', None) if 'status' in req.GET.keys(): statuses = req.GET.getall('status') vm_state, task_state = \ common.task_and_vm_state_from_status(statuses)"," status = search_opts.pop('status', None) if status is not None: vm_state, task_state = common.task_and_vm_state_from_status(status)",103,14
openstack%2Fapi-site~master~I55fe32c86ee5901e0830ccd706e29aafed014d82,openstack/api-site,master,I55fe32c86ee5901e0830ccd706e29aafed014d82,Imported Translations from Transifex,MERGED,2014-08-07 06:03:20.000000000,2014-08-07 06:40:08.000000000,2014-08-07 06:40:08.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-07 06:03:20.000000000', 'files': ['api-ref/locale/api-ref.pot', 'api-ref/locale/fr.po'], 'web_link': 'https://opendev.org/openstack/api-site/commit/0bdc1d6634b47156dc773fce2cc1c19af219b69d', 'message': 'Imported Translations from Transifex\n\nChange-Id: I55fe32c86ee5901e0830ccd706e29aafed014d82\n'}]",0,112483,0bdc1d6634b47156dc773fce2cc1c19af219b69d,7,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I55fe32c86ee5901e0830ccd706e29aafed014d82
",git fetch https://review.opendev.org/openstack/api-site refs/changes/83/112483/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/locale/api-ref.pot', 'api-ref/locale/fr.po']",2,0bdc1d6634b47156dc773fce2cc1c19af219b69d,transifex/translations,"""POT-Creation-Date: 2014-08-06 21:53+0000\n"" ""PO-Revision-Date: 2014-08-06 22:13+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""#: ./api-ref/src/docbkx/ch_compute-v2.xml38(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml17(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml230(title)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml34(para) msgid ""List, create, show information for, update, and delete networks."" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml48(title)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml49(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml52(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml54(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml56(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml67(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml73(title)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml74(para) msgid ""List, create, show information for, and update ports."" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml87(title)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml88(para) msgid """" ""List, create, show information for, and delete security groups and security "" ""group rules."" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml112(title)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml113(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml115(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml118(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml123(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml131(title)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml132(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml137(title)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml138(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml144(caption) msgid ""Load balancer statuses"" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml150(th) msgid ""Status"" msgstr ""Statut"" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml151(th) msgid ""Description"" msgstr ""Description"" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml152(th) msgid ""Operational"" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml157(td) msgid ""DEFERRED"" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml158(td) msgid ""An entity was created but is not yet linked to a load balancer."" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml159(td) #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml164(td) #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml174(td) #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml184(td) msgid ""No"" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml162(td) msgid ""PENDING_CREATE"" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml163(td) msgid ""An entity is being created."" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml167(td) msgid ""PENDING_UPDATE"" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml168(td) msgid ""An entity was updated. It remains in an operational state."" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml169(td) #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml179(td) msgid ""Yes"" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml172(td) msgid ""PENDING_DELETE"" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml173(td) msgid ""An entity is in the process of being deleted."" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml177(td) msgid ""ACTIVE"" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml178(td) msgid ""An entity is in a normal operational state."" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml182(td) msgid ""INACTIVE"" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml183(td) msgid ""Applies to members that fail health checks."" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml187(td) msgid ""ERROR"" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml188(td) msgid ""Something has gone wrong."" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml189(td) msgid ""This might be in either an operational or non-operational state."" msgstr """" #: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml193(para) msgid """" ""Use this extension to create and manage load balancers, listeners, pools, "" ""members, and health monitors."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml9(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml10(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml18(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml29(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml30(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml39(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml51(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml52(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml55(emphasis) msgid ""Passwords"" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml56(para) msgid """" ""When you create a server, you can specify a password through the optional "" ""<property>adminPass</property> attribute. The specified password must meet "" ""the complexity requirements set by your OpenStack Compute provider. The "" ""server might enter an <code>ERROR</code> state if the complexity "" ""requirements are not met. In this case, a client might issue a change "" ""password action to reset the server password."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml62(para) msgid """" ""If you do not specify a password, a randomly generated password is assigned "" ""and returned in the response object. This password is guaranteed to meet the"" "" security requirements set by the compute provider. For security reasons, "" ""the password is not returned in subsequent calls."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml70(emphasis) #: ./api-ref/src/docbkx/ch_compute-v2.xml172(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml71(para) msgid """" ""You can specify custom server metadata at server launch time. The maximum "" ""size for each metadata key-value pair is 255 bytes. The maximum number of "" ""key-value pairs that can be supplied per server is determined by the compute"" "" provider. You can query this value through the <code>maxServerMeta</code> "" ""absolute limit."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml80(emphasis) msgid ""Server networks"" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml81(para) msgid """" ""You can specify networks to which the server connects at launch time. You "" ""can specify one or more networks. Users can also specify a specific port on "" ""the network or the fixed IP address to assign to the server interface."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml85(para) msgid """" ""You can use both IPv4 and IPv6 addresses as access addresses and you can "" ""assign both addresses simultaneously. You can update access addresses after "" ""you create a server."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml93(emphasis) msgid ""Server personality"" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml94(para) msgid """" ""You can customize the personality of a server instance by injecting data "" ""into its file system. For example, you might want to insert ssh keys, set "" ""configuration files, or store data that you want to retrieve from inside the"" "" instance. This feature provides a minimal amount of launch-time "" ""personalization. If you require significant customization, create a custom "" ""image."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml99(para) msgid ""Follow these guidelines when you inject files:"" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml102(para) msgid ""The maximum size of the file path data is 255 bytes."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml105(para) msgid """" ""Encode the file contents as a Base64 string. The compute providers "" ""determines the maximum size of the file contents. This value can vary based "" ""on the image that is used to create the server."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml109(para) msgid """" ""The maximum limit refers to the number of bytes in the decoded data and not "" ""to the number of characters in the encoded data."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml114(para) msgid """" ""You can inject text files only. You cannot inject binary or ZIP files into a"" "" new build."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml118(para) msgid """" ""The maximum number of file path/content pairs that you can supply is also "" ""determined by the compute provider and is defined by the maxPersonality "" ""absolute limit."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml123(para) msgid """" ""The absolute limit, <code>maxPersonalitySize</code>, is a byte limit that is"" "" guaranteed to apply to all images in the deployment. Providers can set "" ""additional per-image personality limits."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml128(para) msgid """" ""The file injection might not occur until after the server is built and "" ""booted."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml130(para) msgid """" ""During file injection, any existing files that match specified files are "" ""renamed to include the BAK extension appended with a time stamp. For "" ""example, if the <filename>/etc/passwd</filename> file exists, it is backed "" ""up as <filename>/etc/passwd.bak.1246036261.5785</filename>."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml134(para) msgid """" ""After file injection, personality files are accessible by only system "" ""administrators. For example, on Linux, all files have root and the root "" ""group as the owner and group owner, respectively, and allow user and group "" ""read access only ( )."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml142(emphasis) msgid ""Server access addresses"" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml143(para) msgid """" ""In a hybrid environment, the IP address of a server might not be controlled "" ""by the underlying implementation. Instead, the access IP address might be "" ""part of the dedicated hardware; for example, a router/NAT device. In this "" ""case, the addresses provided by the implementation cannot actually be used "" ""to access the server (from outside the local LAN). Here, a separate "" ""<firstterm>access address</firstterm> might be assigned at creation time to "" ""provide access to the server. This address might not be directly bound to a "" ""network interface on the server and might not necessarily appear when you "" ""query the server addresses. See <xref linkend=\""compute_server-"" ""addresses\""/>. Nonetheless, clients that must access the server directly are"" "" encouraged to do so through an access address."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2.xml173(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml189(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml190(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml197(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml198(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml213(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml214(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml231(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml232(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml233(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml250(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml251(para)","""POT-Creation-Date: 2014-08-04 06:48+0000\n"" ""PO-Revision-Date: 2014-08-04 17:20+0000\n"" ""Last-Translator: Lo Carr <carre.leo+transifex@gmail.com>\n""#: ./api-ref/src/docbkx/ch_compute-v2.xml41(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml16(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml148(title)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml47(title)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml48(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml51(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml53(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml55(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml66(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml72(title)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml85(title)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml108(title)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml109(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml111(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml114(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml119(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml127(title)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml128(para)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml133(title)#: ./api-ref/src/docbkx/ch_netconn-ext-v2.xml134(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml10(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml11(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml17(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml31(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml32(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml42(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml56(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml57(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml78(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml79(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml97(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml98(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml109(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml110(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml127(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml128(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml149(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml151(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml153(para)#: ./api-ref/src/docbkx/ch_compute-v2.xml175(title)#: ./api-ref/src/docbkx/ch_compute-v2.xml176(para)",529,91
openstack%2Fopenstack-manuals~master~I4123e98ab80bd09ff304dff91a78118ce9cb995e,openstack/openstack-manuals,master,I4123e98ab80bd09ff304dff91a78118ce9cb995e,Imported Translations from Transifex,MERGED,2014-08-07 06:04:51.000000000,2014-08-07 06:38:57.000000000,2014-08-07 06:38:56.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-07 06:04:51.000000000', 'files': ['doc/high-availability-guide/locale/ja.po', 'doc/arch-design/locale/arch-design.pot', 'doc/high-availability-guide/locale/high-availability-guide.pot'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5659c36a2b72f740d70fdc534ba956f94f25fe18', 'message': 'Imported Translations from Transifex\n\nChange-Id: I4123e98ab80bd09ff304dff91a78118ce9cb995e\n'}]",0,112484,5659c36a2b72f740d70fdc534ba956f94f25fe18,7,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: I4123e98ab80bd09ff304dff91a78118ce9cb995e
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/84/112484/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/high-availability-guide/locale/ja.po', 'doc/arch-design/locale/arch-design.pot', 'doc/high-availability-guide/locale/high-availability-guide.pot']",3,5659c36a2b72f740d70fdc534ba956f94f25fe18,transifex/translations,"""POT-Creation-Date: 2014-08-07 06:04+0000\n""msgid ""MySQL with Galera is by no means the only way to achieve database HA. MariaDB (<link href=\""https://mariadb.org/\"">https://mariadb.org/</link>) and Percona (<link href=\""http://www.percona.com/\"">http://www.percona.com/</link>) also work with Galera. You also have the option to use PostgreSQL, which has its own replication, or another database HA option.""","""POT-Creation-Date: 2014-07-29 06:09+0000\n""msgid ""MySQL with Galera is by no means the only way to achieve database HA. MariaDB (<link href=\""https://mariadb.org/\"">https://mariadb.org/</link>) and Percona (<link href=\""http://www.percona.com/\"">http://www.percona.com/</link>) also work with Galera. You also have the option to use Postgres, which has its own replication, or another database HA option.""",9,9
openstack%2Fsecurity-doc~master~If2b5ae862e043cb4da1208e6c50af5cb5d79f6f2,openstack/security-doc,master,If2b5ae862e043cb4da1208e6c50af5cb5d79f6f2,Imported Translations from Transifex,MERGED,2014-08-07 06:02:59.000000000,2014-08-07 06:35:46.000000000,2014-08-07 06:35:46.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-07 06:02:59.000000000', 'files': ['security-guide/locale/security-guide.pot', 'security-guide/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/0becd2d6011aae5b202f56bc28491a0d1445145a', 'message': 'Imported Translations from Transifex\n\nChange-Id: If2b5ae862e043cb4da1208e6c50af5cb5d79f6f2\n'}]",0,112482,0becd2d6011aae5b202f56bc28491a0d1445145a,7,2,1,11131,,,0,"Imported Translations from Transifex

Change-Id: If2b5ae862e043cb4da1208e6c50af5cb5d79f6f2
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/82/112482/1 && git format-patch -1 --stdout FETCH_HEAD,"['security-guide/locale/security-guide.pot', 'security-guide/locale/ja.po']",2,0becd2d6011aae5b202f56bc28491a0d1445145a,transifex/translations,"""POT-Creation-Date: 2014-08-06 21:45+0000\n"" ""PO-Revision-Date: 2014-08-06 22:12+0000\n""""are a number of solutions anticipated in the near future, with several "" ""proposals for message signing and encryption making their way through the "" ""OpenStack development process."" msgstr """"""In this case, Alice's controls are the same as Bob's controls, which are "" ""described below."" msgstr """"""Bob assumes the infrastructure or networks underpinning the Compute service "" ""could become compromised, therefore he recognizes the importance of "" ""hardening the system by restricting access to the message queue. In order to"" "" accomplish this task Bob deploys his RabbitMQ servers with SSL and X.509 "" ""client auth for access control. Hardening activities assists in limiting the"" "" capabilities of a malicious user that has compromised the system by "" ""disallowing queue access, provided that this user does not have valid "" ""credentials to override the controls."" msgstr """"","""POT-Creation-Date: 2014-08-05 07:03+0000\n"" ""PO-Revision-Date: 2014-08-05 06:58+0000\n""""are a number of solutions on the horizon to fix this, with several proposals"" "" for message signing and encryption making their way through the OpenStack "" ""development process."" msgstr "" OpenStack \n OpenStack """"In this case Alice's controls mimic those Bob has deployed for the public "" ""cloud."" msgstr """"""Bob assumes that at some point infrastructure or networks underpinning the "" ""Compute service may become compromised. Due to this, he recognizes the "" ""importance of locking down access to the message queue. To do this Bob "" ""deploys his RabbitMQ servers with SSL and X.509 client auth for access "" ""control. This in turn limits the capabilities of an attacker who has "" ""compromised a system that does not have queue access."" msgstr ""\nRabbitMQ  SSL  X.509 """,22,20
openstack%2Fopenstack-doc-tools~master~I6455c02dec3980f07984a884035b5ec41e8687e7,openstack/openstack-doc-tools,master,I6455c02dec3980f07984a884035b5ec41e8687e7,jsoncheck: fix handling of formatting argument,MERGED,2014-08-06 13:49:04.000000000,2014-08-07 06:34:31.000000000,2014-08-07 06:34:31.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-08-06 13:49:04.000000000', 'files': ['os_doc_tools/jsoncheck.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/e75e7eeb3676a3d77ccf0124c0250a0d22c73381', 'message': 'jsoncheck: fix handling of formatting argument\n\nRaise ValueError rather than returning it, add None as an allowed\nvalue for the formatting option, and change the error/doc string\naccordingly.\n\nblueprint modularize-doctest\nChange-Id: I6455c02dec3980f07984a884035b5ec41e8687e7\n'}]",0,112302,e75e7eeb3676a3d77ccf0124c0250a0d22c73381,7,2,1,11109,,,0,"jsoncheck: fix handling of formatting argument

Raise ValueError rather than returning it, add None as an allowed
value for the formatting option, and change the error/doc string
accordingly.

blueprint modularize-doctest
Change-Id: I6455c02dec3980f07984a884035b5ec41e8687e7
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/02/112302/1 && git format-patch -1 --stdout FETCH_HEAD,['os_doc_tools/jsoncheck.py'],1,e75e7eeb3676a3d77ccf0124c0250a0d22c73381,bp/modularize-doctest," :param formatting: one of 'check' or 'fix' (default: None) if formatting in (None, 'check', 'fix'): raise ValueError(""Called with invalid formatting value."")"," :param formatting: one of 'check' or 'fix' if formatting in ('check', 'fix'): return ValueError(""formatting arg must be 'check' or 'fix'"")",3,3
