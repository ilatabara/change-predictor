id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fcharm-ceilometer-agent~master~I56fea3a4ac2d8c991a81ccf68809b90f7b0ef77f,openstack/charm-ceilometer-agent,master,I56fea3a4ac2d8c991a81ccf68809b90f7b0ef77f,Sync charm-helpers for Ussuri/Focal release and version details,MERGED,2020-01-17 19:21:16.000000000,2020-01-31 23:06:41.000000000,2020-01-31 23:06:41.000000000,"[{'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-17 19:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/78e7108fe0752abf41102c1291c40c1a8b9ca12b', 'message': 'Sync charm-helpers for Ussuri/Focal release and version details\n\nChange-Id: I56fea3a4ac2d8c991a81ccf68809b90f7b0ef77f\n'}, {'number': 2, 'created': '2020-01-21 21:33:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/5f02c28bd1917d12db6d78f62783312cbd8301fc', 'message': 'Sync charm-helpers for Ussuri/Focal release and version details\n\nAlso add placement service to Train deployment.\n\nChange-Id: I56fea3a4ac2d8c991a81ccf68809b90f7b0ef77f\n'}, {'number': 3, 'created': '2020-01-30 19:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/944268792acbd9d747b5815b1e822f9eda09e20c', 'message': 'Sync charm-helpers for Ussuri/Focal release and version details\n\nDepends-On: https://review.opendev.org/#/c/685631/\nChange-Id: I56fea3a4ac2d8c991a81ccf68809b90f7b0ef77f\n'}, {'number': 4, 'created': '2020-01-30 21:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/f2c42e607537dd263cfbb558b0c89d80bd8293c0', 'message': 'Sync charm-helpers for Ussuri/Focal release and version details\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/163\nDepends-On: https://review.opendev.org/#/c/685631/\nChange-Id: I56fea3a4ac2d8c991a81ccf68809b90f7b0ef77f\n'}, {'number': 5, 'created': '2020-01-31 18:17:51.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/amulet/deployment.py', 'charmhelpers/contrib/openstack/audits/openstack_security_guide.py', 'charmhelpers/core/hookenv.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/ha/utils.py', 'charmhelpers/contrib/openstack/templates/section-placement', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/openstack/vaultlocker.py', 'charmhelpers/contrib/openstack/policyd.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/charmsupport/nrpe.py'], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/c109dffc30e73284902ebbb729c8aa9dc6dd40ef', 'message': 'Sync charm-helpers for Ussuri/Focal release and version details\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/163\nDepends-On: https://review.opendev.org/#/c/685631/\nChange-Id: I56fea3a4ac2d8c991a81ccf68809b90f7b0ef77f\n'}]",0,703163,c109dffc30e73284902ebbb729c8aa9dc6dd40ef,41,4,5,11805,,,0,"Sync charm-helpers for Ussuri/Focal release and version details

func-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/163
Depends-On: https://review.opendev.org/#/c/685631/
Change-Id: I56fea3a4ac2d8c991a81ccf68809b90f7b0ef77f
",git fetch https://review.opendev.org/openstack/charm-ceilometer-agent refs/changes/63/703163/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/amulet/deployment.py', 'charmhelpers/contrib/openstack/audits/openstack_security_guide.py', 'charmhelpers/core/hookenv.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/ha/utils.py', 'charmhelpers/contrib/openstack/templates/section-placement', 'charmhelpers/contrib/openstack/vaultlocker.py', 'charmhelpers/contrib/openstack/policyd.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/charmsupport/nrpe.py']",13,78e7108fe0752abf41102c1291c40c1a8b9ca12b,batch-update," def remove_deprecated_check(nrpe, deprecated_services): """""" Remove checks fro deprecated services in list :param nrpe: NRPE object to remove check from :type nrpe: NRPE :param deprecated_services: List of deprecated services that are removed :type deprecated_services: list """""" for dep_svc in deprecated_services: log('Deprecated service: {}'.format(dep_svc)) nrpe.remove_check(shortname=dep_svc)",,541,148
openstack%2Fcharm-ceilometer-agent~master~I1cfebeb15485dd6d92638323d2c9e6bb85f568cb,openstack/charm-ceilometer-agent,master,I1cfebeb15485dd6d92638323d2c9e6bb85f568cb,Port tests from Amulet to Zaza,MERGED,2019-09-30 01:05:09.000000000,2020-01-31 22:58:07.000000000,2020-01-31 22:58:07.000000000,"[{'_account_id': 11805}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}, {'_account_id': 29556}]","[{'number': 1, 'created': '2019-09-30 01:05:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/e9eb1a5baa089343559babbf828f402257b51ee6', 'message': 'Porting tests from Amulet to Zaza\n\nMoving the tests from Amulet to Zaza.\n\nZaza tests can be found here:\nhttps://github.com/openstack-charmers/zaza-openstack-tests/pull/68\n\nCloses-Bug: #1828424\n\nChange-Id: I1cfebeb15485dd6d92638323d2c9e6bb85f568cb\n'}, {'number': 2, 'created': '2019-10-01 15:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/b3a014a29b8d45178f5cadc24c4f2d474295567f', 'message': 'Porting tests from Amulet to Zaza\n\nMoving the tests from Amulet to Zaza.\n\nZaza tests can be found here:\nhttps://github.com/openstack-charmers/zaza-openstack-tests/pull/68\n\nCloses-Bug: #1828424\n\nChange-Id: I1cfebeb15485dd6d92638323d2c9e6bb85f568cb\n'}, {'number': 3, 'created': '2019-10-03 14:40:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/3d654884cb3801fb156adf680b54dff6f8af28ab', 'message': 'Porting tests from Amulet to Zaza\n\nMoving the tests from Amulet to Zaza.\n\nZaza tests can be found here:\nhttps://github.com/openstack-charmers/zaza-openstack-tests/pull/68\n\nCloses-Bug: #1828424\n\nChange-Id: I1cfebeb15485dd6d92638323d2c9e6bb85f568cb\n'}, {'number': 4, 'created': '2019-10-04 11:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/357fcd8ccf31c83eefb8781385a744edd614c510', 'message': 'Porting tests from Amulet to Zaza\n\nMoving the tests from Amulet to Zaza.\n\nZaza tests can be found here:\nhttps://github.com/openstack-charmers/zaza-openstack-tests/pull/68\n\nCloses-Bug: #1828424\n\nChange-Id: I1cfebeb15485dd6d92638323d2c9e6bb85f568cb\n'}, {'number': 5, 'created': '2019-10-05 16:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/22ad7a282032a8d4e358c684dca914f9e39cae8d', 'message': 'Porting tests from Amulet to Zaza\n\nMoving the tests from Amulet to Zaza.\n\nZaza tests can be found here:\nhttps://github.com/openstack-charmers/zaza-openstack-tests/pull/68\n\nCloses-Bug: #1828424\n\nChange-Id: I1cfebeb15485dd6d92638323d2c9e6bb85f568cb\n'}, {'number': 6, 'created': '2020-01-29 20:36:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/085e50c3c0bacd0a6d15cc7613c1b35e50a49181', 'message': 'Porting tests from Amulet to Zaza\n\nZaza tests can be found here:\nhttps://github.com/openstack-charmers/zaza-openstack-tests/pull/68\n\nCloses-Bug: #1828424\nChange-Id: I1cfebeb15485dd6d92638323d2c9e6bb85f568cb\n'}, {'number': 7, 'created': '2020-01-29 21:52:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/08136be9565cefc1e4551f24c21ec17a41cd3fe1', 'message': 'Porting tests from Amulet to Zaza\n\nZaza tests can be found here:\nhttps://github.com/openstack-charmers/zaza-openstack-tests/pull/68\n\nCloses-Bug: #1828424\nChange-Id: I1cfebeb15485dd6d92638323d2c9e6bb85f568cb\n'}, {'number': 8, 'created': '2020-01-30 18:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/6d2bce655c8b318867fd295d225134eab61a7658', 'message': 'Porting tests from Amulet to Zaza\n\nZaza tests can be found here:\nhttps://github.com/openstack-charmers/zaza-openstack-tests/pull/68\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/163\nCloses-Bug: #1828424\nChange-Id: I1cfebeb15485dd6d92638323d2c9e6bb85f568cb\n'}, {'number': 9, 'created': '2020-01-30 18:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/5458d8c0983615bcd3648c66f497d6eb628ead4a', 'message': 'Porting tests from Amulet to Zaza\n\nZaza tests can be found here:\nhttps://github.com/openstack-charmers/zaza-openstack-tests/pull/68\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/163\nCloses-Bug: #1828424\nChange-Id: I1cfebeb15485dd6d92638323d2c9e6bb85f568cb\n'}, {'number': 10, 'created': '2020-01-31 18:17:51.000000000', 'files': ['tests/gate-basic-xenial-pike', 'test-requirements.txt', 'Makefile', 'tests/gate-basic-trusty-mitaka', 'tests/bundles/xenial-queens.yaml', 'tests/bundles/xenial-pike.yaml', 'tests/README.md', 'tests/bundles/bionic-rocky.yaml', 'tests/gate-basic-xenial-mitaka', 'tests/bundles/bionic-queens.yaml', 'tests/gate-basic-bionic-stein', 'tests/bundles/xenial-ocata.yaml', 'tests/gate-basic-xenial-ocata', 'tests/gate-basic-disco-stein', 'tests/bundles/xenial-mitaka.yaml', 'tests/gate-basic-bionic-train', 'tests/bundles/bionic-stein.yaml', 'tests/bundles/bionic-train.yaml', 'tests/bundles/trusty-mitaka.yaml', 'tests/tests.yaml', 'tests/basic_deployment.py', 'tests/dev-basic-cosmic-rocky', 'tests/gate-basic-bionic-queens', 'tests/gate-basic-xenial-queens', 'tests/gate-basic-bionic-rocky', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/72107bc963af334840eddd9638d821b408018db8', 'message': 'Port tests from Amulet to Zaza\n\nZaza tests can be found here:\nhttps://github.com/openstack-charmers/zaza-openstack-tests/pull/68\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/163\nCloses-Bug: #1828424\nChange-Id: I1cfebeb15485dd6d92638323d2c9e6bb85f568cb\n'}]",0,685631,72107bc963af334840eddd9638d821b408018db8,42,6,10,29556,,,0,"Port tests from Amulet to Zaza

Zaza tests can be found here:
https://github.com/openstack-charmers/zaza-openstack-tests/pull/68

func-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/163
Closes-Bug: #1828424
Change-Id: I1cfebeb15485dd6d92638323d2c9e6bb85f568cb
",git fetch https://review.opendev.org/openstack/charm-ceilometer-agent refs/changes/31/685631/7 && git format-patch -1 --stdout FETCH_HEAD,"['tests/gate-basic-xenial-pike', 'test-requirements.txt', 'Makefile', 'tests/gate-basic-trusty-mitaka', 'tests/bundles/xenial-queens.yaml', 'tests/bundles/xenial-pike.yaml', 'tests/README.md', 'tests/bundles/bionic-rocky.yaml', 'tests/gate-basic-xenial-mitaka', 'tests/bundles/bionic-queens.yaml', 'tests/gate-basic-bionic-stein', 'tests/bundles/xenial-ocata.yaml', 'tests/bundles/disco-stein.yaml', 'tests/gate-basic-xenial-ocata', 'tests/gate-basic-disco-stein', 'tests/bundles/xenial-mitaka.yaml', 'tests/bundles/bionic-stein.yaml', 'tests/bundles/bionic-train.yaml', 'tests/bundles/trusty-mitaka.yaml', 'tests/tests.yaml', 'tests/basic_deployment.py', 'tests/dev-basic-cosmic-rocky', 'tests/gate-basic-bionic-queens', 'tests/gate-basic-xenial-queens', 'tests/gate-basic-bionic-rocky', 'tox.ini']",26,e9eb1a5baa089343559babbf828f402257b51ee6,batch-update,passenv = HOME TERM CS_API_* OS_* deps = -r{toxinidir}/test-requirements.txt[testenv:py3] basepython = python3 deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt commands = /bin/true [testenv:func] basepython = python3 functest-run-suite --keep-model [testenv:func-smoke] basepython = python3 functest-run-suite --keep-model --smoke [testenv:func-dev] basepython = python3 functest-run-suite --keep-model --dev [testenv:func-target] basepython = python3 functest-run-suite --keep-model --bundle {posargs}," AMULET_SETUP_TIMEOUT=5400passenv = HOME TERM AMULET_* CS_API_*commands = {posargs} [testenv:func27-noop] # DRY RUN - For Debug basepython = python2.7 deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt bundletester -vl DEBUG -r json -o func-results.json --test-pattern ""gate-*"" -n --no-destroy [testenv:func27] # Charm Functional Test # Run all gate tests which are +x (expected to always pass) basepython = python2.7 deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt bundletester -vl DEBUG -r json -o func-results.json --test-pattern ""gate-*"" --no-destroy [testenv:func27-smoke] # Charm Functional Test # Run a specific test as an Amulet smoke test (expected to always pass) basepython = python2.7 deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt bundletester -vl DEBUG -r json -o func-results.json gate-basic-bionic-stein --no-destroy [testenv:func27-dfs] # Charm Functional Test # Run all deploy-from-source tests which are +x (may not always pass!) basepython = python2.7 deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt bundletester -vl DEBUG -r json -o func-results.json --test-pattern ""dfs-*"" --no-destroy [testenv:func27-dev] # Charm Functional Test # Run all development test targets which are +x (may not always pass!) basepython = python2.7 deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt commands = bundletester -vl DEBUG -r json -o func-results.json --test-pattern ""dev-*"" --no-destroy",1380,1216
openstack%2Fopenstack-helm~master~I801d04559a526d3a7339cd5102f2e738af9f72e0,openstack/openstack-helm,master,I801d04559a526d3a7339cd5102f2e738af9f72e0,[Keystone] Fix status code logic,MERGED,2020-01-31 20:29:47.000000000,2020-01-31 22:52:18.000000000,2020-01-31 22:50:39.000000000,"[{'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28719}]","[{'number': 1, 'created': '2020-01-31 20:29:47.000000000', 'files': ['keystone/templates/bin/_domain-manage.py.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/45e22e45a5f9619bc53871847512a93cedb22347', 'message': ""[Keystone] Fix status code logic\n\nThis patch set fixes an issue with where the keystone chart's\ndomain-manage job/pod always restart once due to a calculation\nlogic error.\n\nChange-Id: I801d04559a526d3a7339cd5102f2e738af9f72e0\nSigned-off-by: Tin Lam <tin@irrational.io>\n""}]",0,705292,45e22e45a5f9619bc53871847512a93cedb22347,9,4,1,20466,,,0,"[Keystone] Fix status code logic

This patch set fixes an issue with where the keystone chart's
domain-manage job/pod always restart once due to a calculation
logic error.

Change-Id: I801d04559a526d3a7339cd5102f2e738af9f72e0
Signed-off-by: Tin Lam <tin@irrational.io>
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/92/705292/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/templates/bin/_domain-manage.py.tpl'],1,45e22e45a5f9619bc53871847512a93cedb22347,fix/domain-manage," # Put and Patch can return 200 or 201. If it is not a 2XX code, error out. if (response.status_code // 100) != 2:", if (int(response.status_code) / 100) != 2:,2,1
openstack%2Fswift~master~I9ca2511651e9b2bc0045894baa4062d20bc15369,openstack/swift,master,I9ca2511651e9b2bc0045894baa4062d20bc15369,probe: Add test for syncing a delete when the remote 404s,MERGED,2019-10-26 04:59:24.000000000,2020-01-31 22:47:21.000000000,2020-01-31 22:45:24.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}, {'_account_id': 27887}]","[{'number': 1, 'created': '2019-10-26 04:59:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/21ae9295bf7d80e300b17c3a023d2ba1bae61a57', 'message': 'probe: Add test for syncing a delete when the remote 404s\n\nThis works fine; we continue processing the other rows in the DB. But it\n*does* take longer than it really ought to require. See the related bug;\nwe ought to be able to shave some 17s off the test time by not retrying\non the 404.\n\nChange-Id: I9ca2511651e9b2bc0045894baa4062d20bc15369\nRelated-Bug: #1849841\n'}, {'number': 2, 'created': '2019-10-28 17:55:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4b9dd8f1012eb725531698eab76b188e702e0e8d', 'message': 'probe: Add test for syncing a delete when the remote 404s\n\nThis works fine; we continue processing the other rows in the DB. But it\n*does* take longer than it really ought to require. See the related bug;\nwe ought to be able to shave some 17s off the test time by not retrying\non the 404.\n\nChange-Id: I9ca2511651e9b2bc0045894baa4062d20bc15369\nRelated-Bug: #1849841\n'}, {'number': 3, 'created': '2019-11-06 17:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2ba244dbed0183fc9d30ab74ccbb48b8b07bc75b', 'message': 'probe: Add test for syncing a delete when the remote 404s\n\nThis works fine; we continue processing the other rows in the DB. But it\n*does* take longer than it really ought to require. See the related bug;\nwe ought to be able to shave some 17s off the test time by not retrying\non the 404.\n\nChange-Id: I9ca2511651e9b2bc0045894baa4062d20bc15369\nRelated-Bug: #1849841\n'}, {'number': 4, 'created': '2020-01-21 06:07:01.000000000', 'files': ['test/probe/test_container_sync.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/73a0e8e9cf7d26e3a06d3b48164d345478de4161', 'message': 'probe: Add test for syncing a delete when the remote 404s\n\nThis works fine; we continue processing the other rows in the DB. But it\n*does* take longer than it really ought to require. See the related bug;\nwe ought to be able to shave some 17s off the test time by not retrying\non the 404.\n\nChange-Id: I9ca2511651e9b2bc0045894baa4062d20bc15369\nRelated-Bug: #1849841\n'}]",0,691463,73a0e8e9cf7d26e3a06d3b48164d345478de4161,13,3,4,15343,,,0,"probe: Add test for syncing a delete when the remote 404s

This works fine; we continue processing the other rows in the DB. But it
*does* take longer than it really ought to require. See the related bug;
we ought to be able to shave some 17s off the test time by not retrying
on the 404.

Change-Id: I9ca2511651e9b2bc0045894baa4062d20bc15369
Related-Bug: #1849841
",git fetch https://review.opendev.org/openstack/swift refs/changes/63/691463/2 && git format-patch -1 --stdout FETCH_HEAD,['test/probe/test_container_sync.py'],1,21ae9295bf7d80e300b17c3a023d2ba1bae61a57,containersync_fix_retry," def test_sync_delete_when_object_never_synced(self): source_container, dest_container = self._setup_synced_containers() # create a tombstone row object_name = 'object-%s' % uuid.uuid4() client.put_object(self.url, self.token, source_container, object_name, 'source-body') client.delete_object(self.url, self.token, source_container, object_name) # upload some other name, too object_name = 'object-%s' % uuid.uuid4() client.put_object(self.url, self.token, source_container, object_name, 'other-source-body') # cycle container-sync Manager(['container-sync']).once() # verify that the deletes (which 404ed) didn't block # that last row from syncing resp_headers, body = client.get_object(self.url, self.token, dest_container, object_name) self.assertEqual(body, b'other-source-body') ",,24,0
openstack%2Fopenstack-helm-infra~master~I8e832db276095771d6a869e998d7a69795dfee37,openstack/openstack-helm-infra,master,I8e832db276095771d6a869e998d7a69795dfee37,Fluentd: Update kernel and auth inputs to use systemd,MERGED,2019-08-14 18:06:09.000000000,2020-01-31 22:21:59.000000000,2020-01-31 22:20:22.000000000,"[{'_account_id': 8749}, {'_account_id': 8898}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 28543}, {'_account_id': 28618}, {'_account_id': 28849}, {'_account_id': 30777}]","[{'number': 1, 'created': '2019-08-14 18:06:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/425f45eb5429f196088ae73d7f9839460d3e7f26', 'message': 'Fluentd: Update kernel log input to use systemd\n\nThis updates the overrides provided for deploying fluentd as a\ndaemonset to get kernel messages from the journal instead of\n/var/log/kern.log directly. This provides additional metadata and\na cleaner interface for gathering these logs via fluentd\n\nChange-Id: I8e832db276095771d6a869e998d7a69795dfee37\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 2, 'created': '2019-08-14 18:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/aaabc9c1b8eb3c0d7d28f0cb7a642c17fae4ead4', 'message': 'Fluentd: Update kernel and auth inputs to use systemd\n\nThis updates the overrides provided for deploying fluentd as a\ndaemonset to get kernel messages from the journal instead of\n/var/log/kern.log directly, and also uses the journal to get\nmessages associated with logging to auth.log (syslog facility\n10). This provides additional metadata and\na cleaner interface for gathering these logs via fluentd\n\nChange-Id: I8e832db276095771d6a869e998d7a69795dfee37\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 3, 'created': '2019-08-19 14:20:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1f117aa3d6285948609f5bdd22628df4c7ff7485', 'message': 'Fluentd: Update kernel and auth inputs to use systemd\n\nThis updates the overrides provided for deploying fluentd as a\ndaemonset to get kernel messages from the journal instead of\n/var/log/kern.log directly, and also uses the journal to get\nmessages associated with logging to auth.log (syslog facility\n10). This provides additional metadata and\na cleaner interface for gathering these logs via fluentd\n\nChange-Id: I8e832db276095771d6a869e998d7a69795dfee37\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 4, 'created': '2019-08-21 15:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/485079916ae8d115bc14e895f3e10e0704efbb67', 'message': 'Fluentd: Update kernel and auth inputs to use systemd\n\nThis updates the overrides provided for deploying fluentd as a\ndaemonset to get kernel messages from the journal instead of\n/var/log/kern.log directly, and also uses the journal to get\nmessages associated with logging to auth.log (syslog facility\n10). This provides additional metadata and\na cleaner interface for gathering these logs via fluentd\n\nChange-Id: I8e832db276095771d6a869e998d7a69795dfee37\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 5, 'created': '2019-09-16 18:23:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7545aa6892f98489f6a98dd1c040f96f6c0013ff', 'message': 'Fluentd: Update kernel and auth inputs to use systemd\n\nThis updates the overrides provided for deploying fluentd as a\ndaemonset to get kernel messages from the journal instead of\n/var/log/kern.log directly, and also uses the journal to get\nmessages associated with logging to auth.log (syslog facility\n10). This provides additional metadata and\na cleaner interface for gathering these logs via fluentd\n\nChange-Id: I8e832db276095771d6a869e998d7a69795dfee37\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 6, 'created': '2019-10-14 14:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7bbdedeecb60d7f819d332d8e523f0cd33a76ea7', 'message': 'Fluentd: Update kernel and auth inputs to use systemd\n\nThis updates the overrides provided for deploying fluentd as a\ndaemonset to get kernel messages from the journal instead of\n/var/log/kern.log directly, and also uses the journal to get\nmessages associated with logging to auth.log (syslog facility\n10). This provides additional metadata and\na cleaner interface for gathering these logs via fluentd\n\nChange-Id: I8e832db276095771d6a869e998d7a69795dfee37\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 7, 'created': '2019-11-11 01:05:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/0af59fb44619c338008cc44b12e3e2b7b57cd7f7', 'message': 'Fluentd: Update kernel and auth inputs to use systemd\n\nThis updates the overrides provided for deploying fluentd as a\ndaemonset to get kernel messages from the journal instead of\n/var/log/kern.log directly, and also uses the journal to get\nmessages associated with logging to auth.log (syslog facility\n10). This provides additional metadata and\na cleaner interface for gathering these logs via fluentd\n\nChange-Id: I8e832db276095771d6a869e998d7a69795dfee37\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 8, 'created': '2020-01-16 13:38:52.000000000', 'files': ['tools/deployment/common/fluentd-daemonset.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/781e65ac5dde325b3771859c41709633cff32a42', 'message': 'Fluentd: Update kernel and auth inputs to use systemd\n\nThis updates the overrides provided for deploying fluentd as a\ndaemonset to get kernel messages from the journal instead of\n/var/log/kern.log directly, and also uses the journal to get\nmessages associated with logging to auth.log (syslog facility\n10). This provides additional metadata and\na cleaner interface for gathering these logs via fluentd\n\nChange-Id: I8e832db276095771d6a869e998d7a69795dfee37\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}]",0,676478,781e65ac5dde325b3771859c41709633cff32a42,32,8,8,17591,,,0,"Fluentd: Update kernel and auth inputs to use systemd

This updates the overrides provided for deploying fluentd as a
daemonset to get kernel messages from the journal instead of
/var/log/kern.log directly, and also uses the journal to get
messages associated with logging to auth.log (syslog facility
10). This provides additional metadata and
a cleaner interface for gathering these logs via fluentd

Change-Id: I8e832db276095771d6a869e998d7a69795dfee37
Signed-off-by: Steve Wilkerson <sw5822@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/78/676478/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/deployment/common/fluentd-daemonset.sh'],1,425f45eb5429f196088ae73d7f9839460d3e7f26,fluentd-systemd-inputs," <source> @type systemd tag kernel path /var/log/journal matches [{ ""_TRANSPORT"": ""kernel"" }] read_from_head true <entry> fields_strip_underscores true fields_lowercase true </entry> </source> "," tag kernel path /var/log/kern.log read_from_head true <parse> @type none </parse> </source> <source> @type tail <filter kernel> @type record_transformer <record> hostname ""#{ENV['NODE_NAME']}"" fluentd_pod ""#{ENV['POD_NAME']}"" </record> </filter> ",13,19
openstack%2Fkolla-ansible~master~I7387ccd0cb394c54c79bfba8b1c09fce7ee2973e,openstack/kolla-ansible,master,I7387ccd0cb394c54c79bfba8b1c09fce7ee2973e,CI: Reduce unnecessary gate image builds,MERGED,2020-01-28 16:47:53.000000000,2020-01-31 22:13:00.000000000,2020-01-31 22:11:20.000000000,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-28 16:47:53.000000000', 'files': ['tools/setup_gate.sh'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8b86c8194b2726dcecbc1487a8f567043828dcde', 'message': 'CI: Reduce unnecessary gate image builds\n\nDue to regex matching of images, we are currently building quite a few\nunnecessary images in CI. Images that can unexpectedly match:\n\n* barbican-keystone-listener\n* ironic-neutron-agent\n* prometheus-haproxy-exporter\n* prometheus-memcached-exporter\n\nThis change improves the situation by anchoring matches to the start of\nthe name. A full solution would be to specify every image required for\neach job. This would be quite verbose and require maintenance.\n\nChange-Id: I7387ccd0cb394c54c79bfba8b1c09fce7ee2973e\n'}]",1,704629,8b86c8194b2726dcecbc1487a8f567043828dcde,19,5,1,14826,,,0,"CI: Reduce unnecessary gate image builds

Due to regex matching of images, we are currently building quite a few
unnecessary images in CI. Images that can unexpectedly match:

* barbican-keystone-listener
* ironic-neutron-agent
* prometheus-haproxy-exporter
* prometheus-memcached-exporter

This change improves the situation by anchoring matches to the start of
the name. A full solution would be to specify every image required for
each job. This would be quite verbose and require maintenance.

Change-Id: I7387ccd0cb394c54c79bfba8b1c09fce7ee2973e
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/29/704629/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/setup_gate.sh'],1,8b86c8194b2726dcecbc1487a8f567043828dcde,bp/centos-rhel-8," GATE_IMAGES=""^cron,^fluentd,^glance,^haproxy,^keepalived,^keystone,^kolla-toolbox,^mariadb,^memcached,^neutron,^nova-,^openvswitch,^rabbitmq,^horizon,^chrony,^heat,^placement"" GATE_IMAGES+="",^ceph,^cinder"" GATE_IMAGES+="",^cinder"" GATE_IMAGES+="",^cinder,^iscsid"" GATE_IMAGES+="",^tgtd"" GATE_IMAGES+="",^zun,^kuryr,^etcd,^cinder,^iscsid"" GATE_IMAGES+="",^tgtd"" GATE_IMAGES+="",^tacker,^mistral,^redis,^barbican"" GATE_IMAGES+="",^dnsmasq,^ironic,^iscsid"" GATE_IMAGES+="",^masakari"" GATE_IMAGES=""^cron,^haproxy,^keepalived,^kolla-toolbox,^mariadb"""," GATE_IMAGES=""cron,fluentd,glance,haproxy,keepalived,keystone,kolla-toolbox,mariadb,memcached,neutron,nova,openvswitch,rabbitmq,horizon,chrony,heat,placement"" GATE_IMAGES+="",ceph,cinder"" GATE_IMAGES+="",cinder"" GATE_IMAGES+="",cinder,iscsid"" GATE_IMAGES+="",tgtd"" GATE_IMAGES+="",zun,kuryr,etcd,cinder,iscsid"" GATE_IMAGES+="",tgtd"" GATE_IMAGES+="",tacker,mistral,redis,barbican"" GATE_IMAGES+="",dnsmasq,ironic,iscsid"" GATE_IMAGES+="",masakari"" GATE_IMAGES=""cron,haproxy,keepalived,kolla-toolbox,mariadb""",11,11
openstack%2Ftripleo-ci~master~I30f474cfece69117acddfb6601cbff36bbe2c561,openstack/tripleo-ci,master,I30f474cfece69117acddfb6601cbff36bbe2c561,turn off  validate_services,MERGED,2020-01-30 16:04:30.000000000,2020-01-31 21:46:45.000000000,2020-01-31 21:46:45.000000000,"[{'_account_id': 6469}, {'_account_id': 6926}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-30 16:04:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/097f51ae8f08573febee29bda458563099883402', 'message': ""turn off  validate_services\n\nvalidate_services should be isolated\nto it's own jobs and not append to current\ncheck / gate jobs\n\nChange-Id: I30f474cfece69117acddfb6601cbff36bbe2c561\n""}, {'number': 2, 'created': '2020-01-30 16:08:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b2191b73a72688cd57e6933499cd054db3fac1d9', 'message': ""turn off  validate_services\n\nvalidate_services should be isolated\nto it's own jobs and not append to current\ncheck / gate jobs\n\nChange-Id: I30f474cfece69117acddfb6601cbff36bbe2c561\n""}, {'number': 3, 'created': '2020-01-31 01:28:42.000000000', 'files': ['zuul.d/undercloud-jobs.yaml', 'zuul.d/standalone-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c427f6ab0e9bbeb8fea71acc69d8c45dbf2f893b', 'message': ""turn off  validate_services\n\nvalidate_services should be isolated\nto it's own jobs and not append to current\ncheck / gate jobs\n\ncontainers-update is checking / gating\nso depends on a fix for that job.\n\nDepends-On: https://review.opendev.org/#/c/704885\nChange-Id: I30f474cfece69117acddfb6601cbff36bbe2c561\n""}]",0,705051,c427f6ab0e9bbeb8fea71acc69d8c45dbf2f893b,30,10,3,9592,,,0,"turn off  validate_services

validate_services should be isolated
to it's own jobs and not append to current
check / gate jobs

containers-update is checking / gating
so depends on a fix for that job.

Depends-On: https://review.opendev.org/#/c/704885
Change-Id: I30f474cfece69117acddfb6601cbff36bbe2c561
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/51/705051/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/undercloud-jobs.yaml', 'zuul.d/standalone-jobs.yaml']",2,097f51ae8f08573febee29bda458563099883402,, validate_services: false validate_services: false validate_services: false, validate_services: true validate_services: true validate_services: true,4,4
openstack%2Ftripleo-heat-templates~master~Id45eee817aff0a780f0fc2da2453bb8fec66d380,openstack/tripleo-heat-templates,master,Id45eee817aff0a780f0fc2da2453bb8fec66d380,"Revert ""Use YAML anchors/aliases to reduce playbook task repetition""",MERGED,2020-01-29 21:04:51.000000000,2020-01-31 21:46:43.000000000,2020-01-31 21:46:43.000000000,"[{'_account_id': 3153}, {'_account_id': 6816}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 9592}, {'_account_id': 11166}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-29 21:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e21480ceb474a9d08209e0e56de1b3795034c38d', 'message': 'Revert ""Use YAML anchors/aliases to reduce playbook task repetition""\n\nThis reverts commit bc4df9c5a994183c71347691e9eb3633e1c00951.\n\nThese don\'t always exist in the the same file because of\nthe usage of template. Some of these work but the updates\nis broken now.\n\nChange-Id: Id45eee817aff0a780f0fc2da2453bb8fec66d380\nCloses-Bug: #1861335\n'}, {'number': 2, 'created': '2020-01-31 01:14:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9f18be7c1784e90017b447478c7c01d87dea0f1e', 'message': 'Revert ""Use YAML anchors/aliases to reduce playbook task repetition""\n\nThis reverts commit bc4df9c5a994183c71347691e9eb3633e1c00951.\n\nThese don\'t always exist in the the same file because of\nthe usage of template. Some of these work but the updates\nis broken now.\n\nChange-Id: Id45eee817aff0a780f0fc2da2453bb8fec66d380\nCloses-Bug: #1861335\n'}, {'number': 3, 'created': '2020-01-31 14:55:56.000000000', 'files': ['common/deploy-steps.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1f98e96d3533121db7e57e43b8e69db73337e074', 'message': 'Revert ""Use YAML anchors/aliases to reduce playbook task repetition""\n\nThis reverts commit bc4df9c5a994183c71347691e9eb3633e1c00951.\n\nThese don\'t always exist in the the same file because of\nthe usage of template. Some of these work but the updates\nis broken now.\n\nChange-Id: Id45eee817aff0a780f0fc2da2453bb8fec66d380\nCloses-Bug: #1861335\n'}]",0,704885,1f98e96d3533121db7e57e43b8e69db73337e074,36,12,3,14985,,,0,"Revert ""Use YAML anchors/aliases to reduce playbook task repetition""

This reverts commit bc4df9c5a994183c71347691e9eb3633e1c00951.

These don't always exist in the the same file because of
the usage of template. Some of these work but the updates
is broken now.

Change-Id: Id45eee817aff0a780f0fc2da2453bb8fec66d380
Closes-Bug: #1861335
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/85/704885/1 && git format-patch -1 --stdout FETCH_HEAD,['common/deploy-steps.j2'],1,e21480ceb474a9d08209e0e56de1b3795034c38d,ffwd-upgrade2," - hosts: DEPLOY_SOURCE_HOST - hosts: DEPLOY_TARGET_HOST - hosts: all - hosts: DEPLOY_TARGET_HOST - hosts: DEPLOY_TARGET_HOST - hosts: DEPLOY_SOURCE_HOST name: Gather facts from undercloud gather_facts: yes become: false - hosts: DEPLOY_TARGET_HOST name: Gather facts from overcloud gather_facts: yes - hosts: all name: Load global variables gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - include_vars: global_vars.yaml no_log: true - hosts: DEPLOY_TARGET_HOST name: Render all_nodes data as group_vars for overcloud gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - name: Render all_nodes data as group_vars for overcloud delegate_to: localhost become: false run_once: true when: not ansible_check_mode|bool block: - name: Get current user command: whoami register: whoami - name: render all_nodes data as group_vars for overcloud template: src: ""{{ '{{' }} lookup('first_found', lookup('config', 'DEFAULT_ROLES_PATH') | map('regex_replace', '$', '/tripleo-hieradata') | list) ~ '/templates/all_nodes.j2' {{ '}}'}}"" dest: ""{{ '{{' }} playbook_dir {{ '}}' }}/group_vars/overcloud.json"" owner: ""{{ '{{' }} whoami.stdout {{ '}}' }}"" group: ""{{ '{{' }} whoami.stdout {{ '}}' }}"" tags: - facts - hosts: DEPLOY_TARGET_HOST name: Set all_nodes data as group_vars for overcloud gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - name: Set all_nodes data as group_vars for overcloud include_vars: ""{{ '{{ ' }} playbook_dir {{ ' }}' }}/group_vars/overcloud.json"" no_log: true when: not ansible_check_mode|bool tags: - facts - hosts: DEPLOY_SOURCE_HOST:DEPLOY_TARGET_HOST name: Gather facts from undercloud gather_facts: no become: false tags: always tasks: - name: Force facts refresh before upgrade. setup: - hosts: all name: Load global variables gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - include_vars: global_vars.yaml no_log: true - name: ensure we get the right selinux context command: chcon -R -t svirt_sandbox_file_t /var/lib/config-data args: warn: no tags: - always - hosts: DEPLOY_TARGET_HOST name: Render all_nodes data as group_vars for overcloud gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - name: Render all_nodes data as group_vars for overcloud delegate_to: localhost become: false run_once: true when: not ansible_check_mode|bool block: - name: Get current user command: whoami register: whoami - name: render all_nodes data as group_vars for overcloud template: src: ""{{ '{{' }} lookup('first_found', lookup('config', 'DEFAULT_ROLES_PATH') | map('regex_replace', '$', '/tripleo-hieradata') | list) ~ '/templates/all_nodes.j2' {{ '}}'}}"" dest: ""{{ '{{' }} playbook_dir {{ '}}' }}/group_vars/overcloud.json"" owner: ""{{ '{{' }} whoami.stdout {{ '}}' }}"" group: ""{{ '{{' }} whoami.stdout {{ '}}' }}"" tags: - facts - hosts: DEPLOY_TARGET_HOST name: Set all_nodes data as group_vars for overcloud gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - name: Set all_nodes data as group_vars for overcloud include_vars: ""{{ '{{ ' }} playbook_dir {{ ' }}' }}/group_vars/overcloud.json"" no_log: true when: not ansible_check_mode|bool tags: - facts - hosts: DEPLOY_SOURCE_HOST name: Gather facts from undercloud gather_facts: yes become: false tags: - always - facts # facts from overcloud may be needed for external installer inventory - hosts: DEPLOY_TARGET_HOST name: Gather facts from overcloud gather_facts: yes tags: - always - facts - hosts: all name: Load global variables gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - include_vars: global_vars.yaml no_log: true tags: - always - hosts: DEPLOY_TARGET_HOST name: Render all_nodes data as group_vars for overcloud gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - name: Render all_nodes data as group_vars for overcloud delegate_to: localhost become: false run_once: true when: not ansible_check_mode|bool block: - name: Get current user command: whoami register: whoami - name: render all_nodes data as group_vars for overcloud template: src: ""{{ '{{' }} lookup('first_found', lookup('config', 'DEFAULT_ROLES_PATH') | map('regex_replace', '$', '/tripleo-hieradata') | list) ~ '/templates/all_nodes.j2' {{ '}}'}}"" dest: ""{{ '{{' }} playbook_dir {{ '}}' }}/group_vars/overcloud.json"" owner: ""{{ '{{' }} whoami.stdout {{ '}}' }}"" group: ""{{ '{{' }} whoami.stdout {{ '}}' }}"" tags: - facts - hosts: DEPLOY_TARGET_HOST name: Set all_nodes data as group_vars for overcloud gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - name: Set all_nodes data as group_vars for overcloud include_vars: ""{{ '{{ ' }} playbook_dir {{ ' }}' }}/group_vars/overcloud.json"" no_log: true when: not ansible_check_mode|bool tags: - facts - hosts: DEPLOY_SOURCE_HOST:DEPLOY_TARGET_HOST name: Gather facts from overcloud gather_facts: no tags: - always - facts tasks: - name: Force facts refresh before scale. setup: - hosts: all name: Load global variables gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - include_vars: global_vars.yaml no_log: true tags: - always - hosts: DEPLOY_TARGET_HOST name: Render all_nodes data as group_vars for overcloud gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - name: Render all_nodes data as group_vars for overcloud delegate_to: localhost become: false run_once: true when: not ansible_check_mode|bool block: - name: Get current user command: whoami register: whoami - name: render all_nodes data as group_vars for overcloud template: src: ""{{ '{{' }} lookup('first_found', lookup('config', 'DEFAULT_ROLES_PATH') | map('regex_replace', '$', '/tripleo-hieradata') | list) ~ '/templates/all_nodes.j2' {{ '}}'}}"" dest: ""{{ '{{' }} playbook_dir {{ '}}' }}/group_vars/overcloud.json"" owner: ""{{ '{{' }} whoami.stdout {{ '}}' }}"" group: ""{{ '{{' }} whoami.stdout {{ '}}' }}"" tags: - facts - hosts: DEPLOY_TARGET_HOST name: Set all_nodes data as group_vars for overcloud gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - name: Set all_nodes data as group_vars for overcloud include_vars: ""{{ '{{ ' }} playbook_dir {{ ' }}' }}/group_vars/overcloud.json"" no_log: true when: not ansible_check_mode|bool tags: - facts"," - &gather_facts_undercloud hosts: DEPLOY_SOURCE_HOST - &gather_facts_overcloud hosts: DEPLOY_TARGET_HOST - &load_global_variables hosts: all - name: ensure we get the right selinux context shell: |- set -o pipefail if [[ -e /var/lib/config-data ]]; then chcon -R -t svirt_sandbox_file_t /var/lib/config-data exit 2 fi args: executable: /bin/bash warn: no register: _selinux_config_data changed_when: _selinux_config_data.rc == 2 failed_when: _selinux_config_data.rc not in [0,2] - &render_overcloud_group_vars hosts: DEPLOY_TARGET_HOST - &set_overcloud_group_vars hosts: DEPLOY_TARGET_HOST - *gather_facts_undercloud - *gather_facts_overcloud - *load_global_variables - *render_overcloud_group_vars - *set_overcloud_group_vars - *gather_facts_undercloud - *gather_facts_overcloud - *load_global_variables - *render_overcloud_group_vars - *set_overcloud_group_vars - *gather_facts_undercloud - *gather_facts_overcloud - *load_global_variables - *render_overcloud_group_vars - *set_overcloud_group_vars - <<: *gather_facts_undercloud - <<: *gather_facts_overcloud ignore_unreachable: True - *load_global_variables - *render_overcloud_group_vars - *set_overcloud_group_vars",202,44
openstack%2Fopenstack-helm~master~I94fc8d067b421248cf74fe40b2e8520f63d4417c,openstack/openstack-helm,master,I94fc8d067b421248cf74fe40b2e8520f63d4417c,Add rally clean up script,MERGED,2019-09-22 01:49:21.000000000,2020-01-31 21:46:24.000000000,2020-01-31 21:44:41.000000000,"[{'_account_id': 8749}, {'_account_id': 8898}, {'_account_id': 17499}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 24780}, {'_account_id': 30356}]","[{'number': 1, 'created': '2019-09-22 01:49:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/94e75bf42a603c1fd3e260873351d4e2551eb20f', 'message': 'DNM: Add ability to add rally cleanup script\n\nDepends-On: https://review.opendev.org/#/c/683759/\n\nChange-Id: I94fc8d067b421248cf74fe40b2e8520f63d4417c\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 2, 'created': '2019-09-22 17:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/559e81a641de0e475ac41385b52dd8ee258112a0', 'message': 'DNM: Add ability to add rally cleanup script\n\nDepends-On: https://review.opendev.org/#/c/683759/\n\nChange-Id: I94fc8d067b421248cf74fe40b2e8520f63d4417c\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 3, 'created': '2019-09-23 02:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/64fe658422003592867d7c09ff14481c9b5e55bb', 'message': '[RFC] Add ability to add rally cleanup script\n\nDepends-On: https://review.opendev.org/#/c/683759/\n\nChange-Id: I94fc8d067b421248cf74fe40b2e8520f63d4417c\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 4, 'created': '2019-09-23 13:20:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/a1bac011e163e093b76a64ffedd78847b13936e3', 'message': '[RFC] Add ability to add rally cleanup script\n\nDepends-On: https://review.opendev.org/#/c/683759/\n\nChange-Id: I94fc8d067b421248cf74fe40b2e8520f63d4417c\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 5, 'created': '2019-09-24 15:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e5faad1b237a7e578d7166107041c6c6d00e70ab', 'message': '[RFC] Add ability to add rally cleanup script\n\nDepends-On: https://review.opendev.org/#/c/683759/\n\nChange-Id: I94fc8d067b421248cf74fe40b2e8520f63d4417c\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 6, 'created': '2019-09-25 13:17:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d2fac14bc8e633bc66d991164d766089e2a456be', 'message': '[RFC] Add ability to add rally cleanup script\n\nDepends-On: https://review.opendev.org/#/c/683759/\n\nChange-Id: I94fc8d067b421248cf74fe40b2e8520f63d4417c\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 7, 'created': '2020-01-17 20:19:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/47d8b49f65e129a694f4259cd3b9bd92edf5c2cb', 'message': 'Add rally clean up script\n\nThis patch set adds in a script that cleans up orphaned or\nlingering rally helm test pods.\n\nDepends-On: https://review.opendev.org/#/c/683759/\n\nChange-Id: I94fc8d067b421248cf74fe40b2e8520f63d4417c\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 8, 'created': '2020-01-31 19:18:01.000000000', 'files': ['tools/deployment/component/compute-kit/compute-kit.sh', 'tools/deployment/component/keystone/keystone.sh', 'cinder/values.yaml', 'nova/values.yaml', 'tools/deployment/component/cinder/cinder.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b17b378390579b3ba6b70076464ba732c0a7f3bf', 'message': 'Add rally clean up script\n\nThis patch set adds in a script that cleans up orphaned or\nlingering rally helm test pods.\n\nDepends-On: https://review.opendev.org/#/c/683759/\n\nChange-Id: I94fc8d067b421248cf74fe40b2e8520f63d4417c\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}]",7,683799,b17b378390579b3ba6b70076464ba732c0a7f3bf,40,9,8,20466,,,0,"Add rally clean up script

This patch set adds in a script that cleans up orphaned or
lingering rally helm test pods.

Depends-On: https://review.opendev.org/#/c/683759/

Change-Id: I94fc8d067b421248cf74fe40b2e8520f63d4417c
Signed-off-by: Tin Lam <tin@irrational.io>
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/99/683799/8 && git format-patch -1 --stdout FETCH_HEAD,"['tools/deployment/component/compute-kit/compute-kit.sh', 'tools/deployment/component/keystone/keystone.sh', 'cinder/values.yaml', 'nova/values.yaml', 'tools/deployment/component/cinder/cinder.sh']",5,94e75bf42a603c1fd3e260873351d4e2551eb20f,rally-tests-cleanup," # Delete the test pod if it still exists kubectl delete pods -l application=cinder,release_group=cinder,component=test --namespace=openstack --ignore-not-found helm test cinder --timeout 900",,26,0
openstack%2Fpython-manilaclient~master~I14fe8601b0a9b82d55473a38916b13ded38f4bc5,openstack/python-manilaclient,master,I14fe8601b0a9b82d55473a38916b13ded38f4bc5,Fix osc delete share and show share tests,MERGED,2020-01-27 22:11:40.000000000,2020-01-31 21:12:57.000000000,2020-01-31 21:11:19.000000000,"[{'_account_id': 6413}, {'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 30002}]","[{'number': 1, 'created': '2020-01-27 22:11:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/1ac24ca419af0f779c0a6c2a1d8d318c9ae31411', 'message': 'Fix osc delete share and show share tests\n\nDelete one share, force delete one share,\ndelete many shares and show share unit tests\nwere broken. Those failures were not caught up\nbecause we were not running tests on our gate.\n\nThis patch set fix those tests. The dependeny will\nadd osc unit tests to main python jobs\n\nChange-Id: I14fe8601b0a9b82d55473a38916b13ded38f4bc5\n'}, {'number': 2, 'created': '2020-01-27 22:16:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/a8316605f96717a895528a78a824db109cdd4376', 'message': 'Fix osc delete share and show share tests\n\nDelete one share, force delete one share,\ndelete many shares and show share unit tests\nwere broken. Those failures were not caught up\nbecause we were not running tests on our gate.\n\nThis patch set fix those tests. The dependeny will\nadd osc unit tests to main python jobs\n\nChange-Id: I14fe8601b0a9b82d55473a38916b13ded38f4bc5\n'}, {'number': 3, 'created': '2020-01-29 16:38:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/9edc41761c14f94ba4a4ce8808b17e7ca4e99df6', 'message': 'Fix osc delete share and show share tests\n\nDelete one share, force delete one share,\ndelete many shares and show share unit tests\nwere broken. Those failures were not caught up\nbecause we were not running tests on our gate.\n\nThis patch set fix those tests. The dependeny will\nadd osc unit tests to main python jobs\n\nChange-Id: I14fe8601b0a9b82d55473a38916b13ded38f4bc5\n'}, {'number': 4, 'created': '2020-01-31 18:28:19.000000000', 'files': ['manilaclient/tests/osc/unit/v2/test_share.py', 'manilaclient/tests/osc/unit/v2/fakes.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/ee78e6486a8b8649c78d487cc469225d656d1037', 'message': 'Fix osc delete share and show share tests\n\nDelete one share, force delete one share,\ndelete many shares and show share unit tests\nwere broken. Those failures were not caught up\nbecause we were not running tests on our gate.\n\nThis patch set fix those tests. The dependeny will\nadd osc unit tests to main python jobs\n\nChange-Id: I14fe8601b0a9b82d55473a38916b13ded38f4bc5\n'}]",2,704445,ee78e6486a8b8649c78d487cc469225d656d1037,16,4,4,6413,,,0,"Fix osc delete share and show share tests

Delete one share, force delete one share,
delete many shares and show share unit tests
were broken. Those failures were not caught up
because we were not running tests on our gate.

This patch set fix those tests. The dependeny will
add osc unit tests to main python jobs

Change-Id: I14fe8601b0a9b82d55473a38916b13ded38f4bc5
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/45/704445/4 && git format-patch -1 --stdout FETCH_HEAD,"['manilaclient/tests/unit/osc/v2/fakes.py', 'manilaclient/tests/unit/osc/v2/test_share.py']",2,1ac24ca419af0f779c0a6c2a1d8d318c9ae31411,,"from manilaclient.common import cliutils self.shares_mock.delete.assert_called_with(shares[0], None) calls = [call(s, None) for s in shares] self.shares_mock.force_delete.assert_called_once_with(shares[0]) self._export_location = ( manila_fakes.FakeShareExportLocation.create_one_exportlocation()) # Get the command object to test cliutils.transform_export_locations_to_string_view = mock.Mock() cliutils.transform_export_locations_to_string_view.return_value = dict( self._export_location) "," # TODO(vkmc) Add test with snapshot when # we implement snapshot support in OSC # def test_share_create_with_snapshot(self): self.shares_mock.delete.assert_called_with(shares[0].name, None) calls = [call(s.name, None) for s in shares] self.shares_mock.force_delete.assert_called_once_with(shares[0].name) # Get the command object to test ",46,8
openstack%2Fnova~master~Idacfff98842fde38fb39791090f2da3310b441b5,openstack/nova,master,Idacfff98842fde38fb39791090f2da3310b441b5,docs: Fix the monkeypatching of blockdiag,MERGED,2020-01-31 17:51:06.000000000,2020-01-31 20:55:43.000000000,2020-01-31 20:53:27.000000000,"[{'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2020-01-31 17:51:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5df7886b99ef5b89887518e41e598a54d5ae0ad4', 'message': ""docs: Fix the monkeypatching of blockdiag\n\nblockdiag has a longstanding bug whereby it tries to access an attribute\non an 'io.BufferedReader' that doesn't exist. We had previously fixed\nthis in change Ibd32d30aacae65702d0ccbdb8a02b1667ec4e8ee, which undid\nthe damage blockdiag was doing. However, this worked because the monkey\npatching blockdiag does happens when the 'blockdiag.utils.compat' module\nis loaded [1], which was happening implicitly with our import of\n'blockdiag.imagedraw.textfolder' [2]. However, that module no longer\nimports the 'compat' [3] module so this doesn't work. Fix the issue by\njust importing the 'compat' module manually, triggering the monkey\npatching...which we can then undo.\n\n[1] https://github.com/blockdiag/blockdiag/blob/2.0.0/src/blockdiag/utils/compat.py#L19-L26\n[2] https://github.com/blockdiag/blockdiag/blob/1.5.4/src/blockdiag/imagedraw/textfolder.py#L18\n[3] https://github.com/blockdiag/blockdiag/tree/2.0.0/src/blockdiag/imagedraw/textfolder.py\n\nChange-Id: Idacfff98842fde38fb39791090f2da3310b441b5\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2020-01-31 17:53:18.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4bdecee385ccf68b1b27ae9ead9a72861ea6cc8d', 'message': ""docs: Fix the monkeypatching of blockdiag\n\nblockdiag has a longstanding bug whereby it tries to access an attribute\non an 'io.BufferedReader' that doesn't exist. We had previously fixed\nthis in change Ibd32d30aacae65702d0ccbdb8a02b1667ec4e8ee, which undid\nthe damage blockdiag was doing. However, this worked because the monkey\npatching blockdiag does happens when the 'blockdiag.utils.compat' module\nis loaded [1], which was happening implicitly with our import of\n'blockdiag.imagedraw.textfolder' [2]. However, that module no longer\nimports the 'compat' [3] module so this doesn't work. Fix the issue by\njust importing the 'compat' module manually, triggering the monkey\npatching...which we can then undo.\n\n[1] https://github.com/blockdiag/blockdiag/blob/2.0.0/src/blockdiag/utils/compat.py#L19-L26\n[2] https://github.com/blockdiag/blockdiag/blob/1.5.4/src/blockdiag/imagedraw/textfolder.py#L18\n[3] https://github.com/blockdiag/blockdiag/tree/2.0.0/src/blockdiag/imagedraw/textfolder.py\n\nChange-Id: Idacfff98842fde38fb39791090f2da3310b441b5\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",2,705263,4bdecee385ccf68b1b27ae9ead9a72861ea6cc8d,13,6,2,15334,,,0,"docs: Fix the monkeypatching of blockdiag

blockdiag has a longstanding bug whereby it tries to access an attribute
on an 'io.BufferedReader' that doesn't exist. We had previously fixed
this in change Ibd32d30aacae65702d0ccbdb8a02b1667ec4e8ee, which undid
the damage blockdiag was doing. However, this worked because the monkey
patching blockdiag does happens when the 'blockdiag.utils.compat' module
is loaded [1], which was happening implicitly with our import of
'blockdiag.imagedraw.textfolder' [2]. However, that module no longer
imports the 'compat' [3] module so this doesn't work. Fix the issue by
just importing the 'compat' module manually, triggering the monkey
patching...which we can then undo.

[1] https://github.com/blockdiag/blockdiag/blob/2.0.0/src/blockdiag/utils/compat.py#L19-L26
[2] https://github.com/blockdiag/blockdiag/blob/1.5.4/src/blockdiag/imagedraw/textfolder.py#L18
[3] https://github.com/blockdiag/blockdiag/tree/2.0.0/src/blockdiag/imagedraw/textfolder.py

Change-Id: Idacfff98842fde38fb39791090f2da3310b441b5
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/63/705263/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,5df7886b99ef5b89887518e41e598a54d5ae0ad4,remove-blockdiag, from blockdiag.utils import compat,,1,0
openstack%2Fswift~master~Ic67c6698fd98a38f6ddf3ba92057331e437a888a,openstack/swift,master,Ic67c6698fd98a38f6ddf3ba92057331e437a888a,clarify s3api ACL test HEADs,MERGED,2019-06-27 14:10:22.000000000,2020-01-31 20:55:25.000000000,2020-01-31 20:53:24.000000000,"[{'_account_id': 9625}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-06-27 14:10:22.000000000', 'files': ['test/unit/common/middleware/s3api/test_multi_upload.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/deba3a63052d639e26252afb9a7f71aa66c04c91', 'message': 'clarify s3api ACL test HEADs\n\nChange-Id: Ic67c6698fd98a38f6ddf3ba92057331e437a888a\n'}]",1,667933,deba3a63052d639e26252afb9a7f71aa66c04c91,9,3,1,1179,,,0,"clarify s3api ACL test HEADs

Change-Id: Ic67c6698fd98a38f6ddf3ba92057331e437a888a
",git fetch https://review.opendev.org/openstack/swift refs/changes/33/667933/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/common/middleware/s3api/test_multi_upload.py'],1,deba3a63052d639e26252afb9a7f71aa66c04c91,bug/1780204," self, cache, existance_cached, should_head, should_put): # This is the get_container_info existance check :'( expected = [] if not existance_cached: expected.append(('HEAD', '/v1/AUTH_test/bucket')) # XXX: For some reason check ACLs always does second HEAD (???) kwargs = { 'existance_cached': False, 'should_head': True, 'should_put': False, } FakeMemcache(), **kwargs) get_cache_key('AUTH_test', 'bucket'): {'status': 204}, kwargs = { 'existance_cached': True, 'should_head': False, 'should_put': False, } fake_memcache, **kwargs) get_cache_key('AUTH_test', 'bucket'): {'status': 204}, kwargs = { 'existance_cached': True, 'should_head': False, 'should_put': True, } fake_memcache, **kwargs)"," self, cache, should_head, should_put): # Always need to check ACLs for the bucket expected = [('HEAD', '/v1/AUTH_test/bucket')] # XXX: For some reason there's always this second HEAD (???) FakeMemcache(), True, False) fake_memcache, False, False) fake_memcache, False, True)",26,7
openstack%2Fneutron~master~If74487a5e437531826437d91b148065eec2bc20c,openstack/neutron,master,If74487a5e437531826437d91b148065eec2bc20c,Use distutils.version to check dnsmasq supported version,MERGED,2020-01-16 11:15:33.000000000,2020-01-31 20:44:15.000000000,2020-01-31 20:41:23.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 5756}, {'_account_id': 8313}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 15554}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 24791}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-16 11:15:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7efc3af51f5a8045df5c3492e4cf2d6bf7295eed', 'message': 'Use tuple comparison to check dnsmasq supported version\n\nChange-Id: If74487a5e437531826437d91b148065eec2bc20c\nCloses-Bug: #1859962\n'}, {'number': 2, 'created': '2020-01-16 16:27:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4ddd406478fb2f20e203f03a28261620a64770c8', 'message': 'Use tuple comparison to check dnsmasq supported version\n\nChange-Id: If74487a5e437531826437d91b148065eec2bc20c\nCloses-Bug: #1859962\n'}, {'number': 3, 'created': '2020-01-17 09:54:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b1d8290cdb06111d7e4586256d53f451a55adf0d', 'message': 'Use tuple comparison to check dnsmasq supported version\n\nChange-Id: If74487a5e437531826437d91b148065eec2bc20c\nCloses-Bug: #1859962\n'}, {'number': 4, 'created': '2020-01-21 12:29:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6a785d9310932cf396593593a1746cb55c2cb64b', 'message': 'Use tuple comparison to check dnsmasq supported version\n\nChange-Id: If74487a5e437531826437d91b148065eec2bc20c\nCloses-Bug: #1859962\n'}, {'number': 5, 'created': '2020-01-21 15:30:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c6d28c4c78da726da8a74fd79e5dc5092f6470f1', 'message': 'Use tuple comparison to check dnsmasq supported version\n\nChange-Id: If74487a5e437531826437d91b148065eec2bc20c\nCloses-Bug: #1859962\n'}, {'number': 6, 'created': '2020-01-21 15:34:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/28bd89337cc48fa039585900a21c7aa176aa3b76', 'message': 'Use distutils.version to check dnsmasq supported version\n\nChange-Id: If74487a5e437531826437d91b148065eec2bc20c\nCloses-Bug: #1859962\n'}, {'number': 7, 'created': '2020-01-23 23:50:56.000000000', 'files': ['neutron/cmd/sanity/checks.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc0b38b2820b305753120c4f677b2e4bd565d16f', 'message': 'Use distutils.version to check dnsmasq supported version\n\nChange-Id: If74487a5e437531826437d91b148065eec2bc20c\nCloses-Bug: #1859962\n'}]",7,702847,bc0b38b2820b305753120c4f677b2e4bd565d16f,83,13,7,16688,,,0,"Use distutils.version to check dnsmasq supported version

Change-Id: If74487a5e437531826437d91b148065eec2bc20c
Closes-Bug: #1859962
",git fetch https://review.opendev.org/openstack/neutron refs/changes/47/702847/7 && git format-patch -1 --stdout FETCH_HEAD,['neutron/cmd/sanity/checks.py'],1,7efc3af51f5a8045df5c3492e4cf2d6bf7295eed,bug/1859962,from oslo_utils import versionutils ver = versionutils.convert_version_to_tuple(m.group(1) if m else '0.0') minver = versionutils.convert_version_to_tuple(MINIMUM_DNSMASQ_VERSION) if ver < minver:, ver = float(m.group(1)) if m else 0 if ver < MINIMUM_DNSMASQ_VERSION:,4,2
openstack%2Fswift~master~If6a25d6573502eebff3e28aa503721eda73af556,openstack/swift,master,If6a25d6573502eebff3e28aa503721eda73af556,Add new versioning flag to docker image,MERGED,2020-01-30 04:57:10.000000000,2020-01-31 20:43:22.000000000,2020-01-31 20:41:25.000000000,"[{'_account_id': 9625}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-30 04:57:10.000000000', 'files': ['docker/rootfs/etc/swift/proxy-server.conf'], 'web_link': 'https://opendev.org/openstack/swift/commit/4a776c4fbd69271b6197b2c20beaaae8a2b2e980', 'message': 'Add new versioning flag to docker image\n\nChange-Id: If6a25d6573502eebff3e28aa503721eda73af556\n'}]",0,704924,4a776c4fbd69271b6197b2c20beaaae8a2b2e980,17,3,1,9625,,,0,"Add new versioning flag to docker image

Change-Id: If6a25d6573502eebff3e28aa503721eda73af556
",git fetch https://review.opendev.org/openstack/swift refs/changes/24/704924/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/rootfs/etc/swift/proxy-server.conf'],1,4a776c4fbd69271b6197b2c20beaaae8a2b2e980,versioning_flag,allow_object_versioning = true,,1,0
openstack%2Fcinder-specs~master~Ia8cc65b59e3ab0c295634a6da743de9143c07856,openstack/cinder-specs,master,Ia8cc65b59e3ab0c295634a6da743de9143c07856,FUP: Add backup id to volume's metadata,MERGED,2020-01-31 02:30:53.000000000,2020-01-31 20:37:28.000000000,2020-01-31 20:35:57.000000000,"[{'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 30092}]","[{'number': 1, 'created': '2020-01-31 02:30:53.000000000', 'files': ['specs/ussuri/add_backup_id_to_volume.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/40882782094c803a487ce4421b4e8201155f83dd', 'message': ""FUP: Add backup id to volume's metadata\n\nFix some comments in\nhttps://review.opendev.org/#/c/700977/22/specs/ussuri/add_backup_id_to_volume.rst\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Ia8cc65b59e3ab0c295634a6da743de9143c07856\n""}]",1,705146,40882782094c803a487ce4421b4e8201155f83dd,9,6,1,26458,,,0,"FUP: Add backup id to volume's metadata

Fix some comments in
https://review.opendev.org/#/c/700977/22/specs/ussuri/add_backup_id_to_volume.rst

Implements: blueprint add-volume-backup-id

Change-Id: Ia8cc65b59e3ab0c295634a6da743de9143c07856
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/46/705146/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/ussuri/add_backup_id_to_volume.rst'],1,40882782094c803a487ce4421b4e8201155f83dd,bp/add-volume-backup-id,"from the new volume created. But when the end user has restored a backup volume, in the volume show response, we cannot see its source. This can cause a lot of confusion for end users.As an end user, I would like to know the restored volume comes from which backup resource. to record from which backup the new volume was created from. When restoring from a chain of incremental backups, ``src_backup_id``* the volume-metadata-show-key response, only if the key is ``src_backup_id``Release note should point out that since this is stored in the volume metadata, it can be modified or removed by end users, so operators should not rely upon it being present for administrative or auditing purposes. Add a similar note somewhere in the admin docs, probably a page about volume metadata written by Cinder (which may not currently exist). In addition to reminding admins that end users can overwrite volume metadata, should explain how to read the ``src_backup_id`` (particularly","from the new volume created. But when the end user has restored a backup volume, in the volume's response, we cannot see its source. This can cause a lot of confusion for end users.As an end user, I would like to know the restored volume comes from which backup file. to record where the new volume was created from. When restoring from a chain of incremental backups, src_backup_id* the volume-metadata-show-key responseRelease note should point out that since this is stored in the volume metadata, it can be modified or removed by end users, so operators should not rely upon it being present for administrative or auditing purposes. Add a similar note somewhere in the admin docs, probably a page about volume metadata written by Cinder (which may not currently exist). In addition to reminding admins that end users can overwrite volume metadata, should explain how to read the 'src_backup_id'(particularly",15,17
openstack%2Ftripleo-heat-templates~master~If9eeec2b027cfd1c65360d8130c2e748100ae8d0,openstack/tripleo-heat-templates,master,If9eeec2b027cfd1c65360d8130c2e748100ae8d0,mark scen10 and scen000 update/upgrade non-voting,MERGED,2020-01-31 14:25:59.000000000,2020-01-31 20:34:49.000000000,2020-01-31 20:34:49.000000000,"[{'_account_id': 6469}, {'_account_id': 9592}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-31 14:25:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6b5724881e838e090dd12bc69d7c47b713eaf5dc', 'message': 'mark tht/common to be ignored by check/gate\n\nrevert this patch after:\nhttps://review.opendev.org/#/c/705051\nhttps://review.opendev.org/#/c/704885\n\nChange-Id: If9eeec2b027cfd1c65360d8130c2e748100ae8d0\n'}, {'number': 2, 'created': '2020-01-31 14:43:25.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c350126be05d6a78920bfa5cd711db39f260f835', 'message': 'mark scen10 and scen000 update/upgrade non-voting\n\nrevert this patch after:\nhttps://review.opendev.org/#/c/705051\nhttps://review.opendev.org/#/c/704885\n\nChange-Id: If9eeec2b027cfd1c65360d8130c2e748100ae8d0\n'}]",0,705225,c350126be05d6a78920bfa5cd711db39f260f835,11,6,2,9592,,,0,"mark scen10 and scen000 update/upgrade non-voting

revert this patch after:
https://review.opendev.org/#/c/705051
https://review.opendev.org/#/c/704885

Change-Id: If9eeec2b027cfd1c65360d8130c2e748100ae8d0
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/25/705225/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,6b5724881e838e090dd12bc69d7c47b713eaf5dc,, - tripleo-ci-centos-7-scenario010-standalone: irrelevant-files: - ^common/.*$ - tripleo-ci-centos-7-scenario010-standalone: irrelevant-files: - ^common/.*$,,6,0
openstack%2Ftripleo-common~stable%2Fqueens~I6bd73fde6f1d78ceb89eb5cd04ac06d1b95263a3,openstack/tripleo-common,stable/queens,I6bd73fde6f1d78ceb89eb5cd04ac06d1b95263a3,Derive new nova compute parameter,MERGED,2020-01-31 13:39:59.000000000,2020-01-31 20:16:17.000000000,2020-01-31 20:16:17.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-31 13:39:59.000000000', 'files': ['workbooks/derive_params_formulas.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c4839a8b09d996a2bf29e2773e2f7180632dbd05', 'message': 'Derive new nova compute parameter\n\nDerive NovaComputeCpuSharedSet parameter based on\nhost introspection.\n\nChange-Id: I6bd73fde6f1d78ceb89eb5cd04ac06d1b95263a3\nCloses-Bug: #1858678\n(cherry picked from commit 95138e9d4e8ee012616fcb7ad89be0eef1632960)\n(cherry picked from commit 8f40c8499de5ebd9b90dbca29b565b46dbe92ef4)\n'}]",0,705214,c4839a8b09d996a2bf29e2773e2f7180632dbd05,8,5,1,22865,,,0,"Derive new nova compute parameter

Derive NovaComputeCpuSharedSet parameter based on
host introspection.

Change-Id: I6bd73fde6f1d78ceb89eb5cd04ac06d1b95263a3
Closes-Bug: #1858678
(cherry picked from commit 95138e9d4e8ee012616fcb7ad89be0eef1632960)
(cherry picked from commit 8f40c8499de5ebd9b90dbca29b565b46dbe92ef4)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/14/705214/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/derive_params_formulas.yaml'],1,c4839a8b09d996a2bf29e2773e2f7180632dbd05,," host_parameters: <% dict(concat($.role_name, 'Parameters') => dict('NovaVcpuPinSet' => $.get('nova_cpus', ''), 'NovaComputeCpuSharedSet' => $.get('host_cpus', ''), 'NovaReservedHostMemory' => $.get('host_mem', ''), 'KernelArgs' => $.get('kernel_args', ''), 'IsolCpusList' => $.get('isol_cpus', ''))) %>"," host_parameters: <% dict(concat($.role_name, 'Parameters') => dict('NovaVcpuPinSet' => $.get('nova_cpus', ''), 'NovaReservedHostMemory' => $.get('host_mem', ''), 'KernelArgs' => $.get('kernel_args', ''), 'IsolCpusList' => $.get('isol_cpus', ''))) %>",1,1
openstack%2Ftripleo-common~stable%2Frocky~I6bd73fde6f1d78ceb89eb5cd04ac06d1b95263a3,openstack/tripleo-common,stable/rocky,I6bd73fde6f1d78ceb89eb5cd04ac06d1b95263a3,Derive new nova compute parameter,MERGED,2020-01-31 13:39:18.000000000,2020-01-31 20:16:16.000000000,2020-01-31 20:16:16.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-31 13:39:18.000000000', 'files': ['workbooks/derive_params_formulas.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0750f4cb35963267d5ecec721fed45d1d5261aed', 'message': 'Derive new nova compute parameter\n\nDerive NovaComputeCpuSharedSet parameter based on\nhost introspection.\n\nChange-Id: I6bd73fde6f1d78ceb89eb5cd04ac06d1b95263a3\nCloses-Bug: #1858678\n(cherry picked from commit 95138e9d4e8ee012616fcb7ad89be0eef1632960)\n(cherry picked from commit 8f40c8499de5ebd9b90dbca29b565b46dbe92ef4)\n'}]",0,705213,0750f4cb35963267d5ecec721fed45d1d5261aed,9,5,1,22865,,,0,"Derive new nova compute parameter

Derive NovaComputeCpuSharedSet parameter based on
host introspection.

Change-Id: I6bd73fde6f1d78ceb89eb5cd04ac06d1b95263a3
Closes-Bug: #1858678
(cherry picked from commit 95138e9d4e8ee012616fcb7ad89be0eef1632960)
(cherry picked from commit 8f40c8499de5ebd9b90dbca29b565b46dbe92ef4)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/13/705213/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/derive_params_formulas.yaml'],1,0750f4cb35963267d5ecec721fed45d1d5261aed,," host_parameters: <% dict(concat($.role_name, 'Parameters') => dict('NovaVcpuPinSet' => $.get('nova_cpus', ''), 'NovaComputeCpuSharedSet' => $.get('host_cpus', ''), 'NovaReservedHostMemory' => $.get('host_mem', ''), 'KernelArgs' => $.get('kernel_args', ''), 'IsolCpusList' => $.get('isol_cpus', ''))) %>"," host_parameters: <% dict(concat($.role_name, 'Parameters') => dict('NovaVcpuPinSet' => $.get('nova_cpus', ''), 'NovaReservedHostMemory' => $.get('host_mem', ''), 'KernelArgs' => $.get('kernel_args', ''), 'IsolCpusList' => $.get('isol_cpus', ''))) %>",1,1
openstack%2Fkolla~master~I1d5cd3d9af98444acac5bedd7daeaa6c6673dcd6,openstack/kolla,master,I1d5cd3d9af98444acac5bedd7daeaa6c6673dcd6,nova-libvirt: add UEFI packages to support UEFI instances,MERGED,2019-09-16 07:02:32.000000000,2020-01-31 19:28:59.000000000,2020-01-31 17:57:29.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23181}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-09-16 07:02:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/acf33407f62177074a9069e3f5d1560daa59f717', 'message': 'Add OVMF package to support UEFI instance\n\nChange-Id: I1d5cd3d9af98444acac5bedd7daeaa6c6673dcd6\nCloses-Bug: #1814552\n'}, {'number': 2, 'created': '2020-01-30 15:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2b37092af4597ec801224b8e430ef87a9b763d71', 'message': 'nova-libvirt: add uefi package to support UEFI instances\n\nCloses-Bug: #1814552\n\nChange-Id: I1d5cd3d9af98444acac5bedd7daeaa6c6673dcd6\n'}, {'number': 3, 'created': '2020-01-31 09:19:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/7f94a3cf31ef2d619305b6080a81ad511eb91dda', 'message': 'nova-libvirt: add UEFI packages to support UEFI instances\n\nFix inability to run UEFI-based images/instances by installing UEFI\npackages also in nova-libvirt image which is not based on nova-base.\n\nIncludes support for C8.\nBackport below Train w/o C8.\n\nCloses-Bug: #1814552\n\nChange-Id: I1d5cd3d9af98444acac5bedd7daeaa6c6673dcd6\n'}, {'number': 4, 'created': '2020-01-31 09:20:55.000000000', 'files': ['docker/nova/nova-libvirt/Dockerfile.j2', 'releasenotes/notes/bug-1814552-a037354969dcf7e5.yaml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/15b68c15c1dd0c2df1cc49b550f2fa03a4c65e8e', 'message': 'nova-libvirt: add UEFI packages to support UEFI instances\n\nFix inability to run UEFI-based images/instances by installing UEFI\npackages also in nova-libvirt image which is not based on nova-base.\n\nIncludes support for C8.\nBackport below Train w/o C8.\n\nCloses-Bug: #1814552\nCo-authored-by: Marcin Juszkiewicz <marcin.juszkiewicz@linaro.org>\nCo-authored-by: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\nChange-Id: I1d5cd3d9af98444acac5bedd7daeaa6c6673dcd6\n'}]",10,682280,15b68c15c1dd0c2df1cc49b550f2fa03a4c65e8e,32,6,4,19779,,,0,"nova-libvirt: add UEFI packages to support UEFI instances

Fix inability to run UEFI-based images/instances by installing UEFI
packages also in nova-libvirt image which is not based on nova-base.

Includes support for C8.
Backport below Train w/o C8.

Closes-Bug: #1814552
Co-authored-by: Marcin Juszkiewicz <marcin.juszkiewicz@linaro.org>
Co-authored-by: Radosaw Piliszek <radoslaw.piliszek@gmail.com>
Change-Id: I1d5cd3d9af98444acac5bedd7daeaa6c6673dcd6
",git fetch https://review.opendev.org/openstack/kolla refs/changes/80/682280/4 && git format-patch -1 --stdout FETCH_HEAD,['docker/nova/nova-libvirt/Dockerfile.j2'],1,acf33407f62177074a9069e3f5d1560daa59f717,bug/1814552," 'trousers', 'OVMF' 'trousers', 'ovmf'{% elif base_package_type == 'rpm' %} RUN ln -s /usr/share/OVMF/OVMF_CODE.secboot.fd /usr/share/OVMF/OVMF_CODE.fd ", 'trousers' 'trousers',8,2
openstack%2Ftripleo-operator-ansible~master~Ie0c6ccc654ef3b04bcb0f4da81bad16220a973a6,openstack/tripleo-operator-ansible,master,Ie0c6ccc654ef3b04bcb0f4da81bad16220a973a6,Switch cli data to environment vars,MERGED,2020-01-28 22:15:46.000000000,2020-01-31 19:26:42.000000000,2020-01-31 19:26:42.000000000,"[{'_account_id': 3153}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-28 22:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/9406453727eea34869ad87cdd13fac8ef4ffccb7', 'message': 'Switch cli data to environment vars\n\nIn order to not have to do special shell quoting, we can use environment\nvars to handle that instead.\n\nChange-Id: Ie0c6ccc654ef3b04bcb0f4da81bad16220a973a6\n'}, {'number': 2, 'created': '2020-01-28 22:38:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/40607ee29dec6edcebfe07e03c5e30d421a6c77f', 'message': 'Switch cli data to environment vars\n\nIn order to not have to do special shell quoting, we can use environment\nvars to handle that instead.\n\nChange-Id: Ie0c6ccc654ef3b04bcb0f4da81bad16220a973a6\n'}, {'number': 3, 'created': '2020-01-28 23:17:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/47f49af91b461c819db5e80fcf1617467e7e3a75', 'message': 'Switch cli data to environment vars\n\nIn order to not have to do special shell quoting, we can use environment\nvars to handle that instead.\n\nChange-Id: Ie0c6ccc654ef3b04bcb0f4da81bad16220a973a6\n'}, {'number': 4, 'created': '2020-01-28 23:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/1ff1ce53dc5c15dc8570f19cc7555443ca2c6a5d', 'message': 'Switch cli data to environment vars\n\nIn order to not have to do special shell quoting, we can use environment\nvars to handle that instead.\n\nChange-Id: Ie0c6ccc654ef3b04bcb0f4da81bad16220a973a6\n'}, {'number': 5, 'created': '2020-01-29 18:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/5f2f8d24008787e69ebb5bbd25710d1e6d113d45', 'message': 'Switch cli data to environment vars\n\nIn order to not have to do special shell quoting, we can use environment\nvars to handle that instead.\n\nChange-Id: Ie0c6ccc654ef3b04bcb0f4da81bad16220a973a6\n'}, {'number': 6, 'created': '2020-01-29 20:50:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/49d79ef7b704656951e3d416c1cafc9c242b791f', 'message': 'Switch cli data to environment vars\n\nIn order to not have to do special shell quoting, we can use environment\nvars to handle that instead.\n\nChange-Id: Ie0c6ccc654ef3b04bcb0f4da81bad16220a973a6\n'}, {'number': 7, 'created': '2020-01-29 21:15:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/6bfe39e1c592cc91756142685f2ddf74609e342a', 'message': 'Switch cli data to environment vars\n\nIn order to not have to do special shell quoting, we can use environment\nvars to handle that instead.\n\nChange-Id: Ie0c6ccc654ef3b04bcb0f4da81bad16220a973a6\n'}, {'number': 8, 'created': '2020-01-29 21:55:13.000000000', 'files': ['roles/tripleo_container_image_show/molecule/default/playbook.yml', 'roles/tripleo_container_image_list/molecule/default/playbook.yml', 'roles/tripleo_container_image_list/tasks/main.yml', 'roles/tripleo_container_image_show/tasks/main.yml', 'roles/tripleo_container_image_delete/molecule/default/playbook.yml', 'roles/tripleo_container_image_list/defaults/main.yml', 'roles/tripleo_container_image_push/molecule/default/molecule.yml', 'roles/tripleo_container_image_push/molecule/default/playbook.yml', 'roles/tripleo_container_image_push/tasks/main.yml', 'roles/tripleo_container_image_delete/defaults/main.yml', 'roles/tripleo_container_image_show/defaults/main.yml', 'roles/tripleo_container_image_delete/molecule/default/molecule.yml', 'zuul.d/molecule.yaml', 'roles/tripleo_container_image_delete/tasks/main.yml', 'roles/tripleo_container_image_list/molecule/default/molecule.yml', 'roles/tripleo_container_image_push/defaults/main.yml', 'roles/tripleo_container_image_show/molecule/default/molecule.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/55997d64018762b09319ef547d9bd9caec87a7dd', 'message': 'Switch cli data to environment vars\n\nIn order to not have to do special shell quoting, we can use environment\nvars to handle that instead.\n\nChange-Id: Ie0c6ccc654ef3b04bcb0f4da81bad16220a973a6\n'}]",0,704700,55997d64018762b09319ef547d9bd9caec87a7dd,21,4,8,14985,,,0,"Switch cli data to environment vars

In order to not have to do special shell quoting, we can use environment
vars to handle that instead.

Change-Id: Ie0c6ccc654ef3b04bcb0f4da81bad16220a973a6
",git fetch https://review.opendev.org/openstack/tripleo-operator-ansible refs/changes/00/704700/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/tripleo_container_image_delete/molecule/default/molecule.yml', 'zuul.d/molecule.yaml', 'roles/tripleo_container_image_delete/tasks/main.yml', 'roles/tripleo_container_image_delete/molecule/default/playbook.yml', 'roles/tripleo_container_image_delete/defaults/main.yml']",5,9406453727eea34869ad87cdd13fac8ef4ffccb7,env-vars,openstack_bin: openstack,,170,4
openstack%2Fswift~master~I8a961302a8905f483433976f6105b138a1acd7ba,openstack/swift,master,I8a961302a8905f483433976f6105b138a1acd7ba,s3token: Raise error on negative secret_cache_duration config,MERGED,2018-12-11 18:48:57.000000000,2020-01-31 19:07:33.000000000,2020-01-31 19:03:56.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-11 18:48:57.000000000', 'files': ['swift/common/middleware/s3api/s3token.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/46bde0c0b2a99580584f34e4dd72c9ac8b611fac', 'message': 's3token: Raise error on negative secret_cache_duration config\n\nChange-Id: I8a961302a8905f483433976f6105b138a1acd7ba\n'}]",0,624464,46bde0c0b2a99580584f34e4dd72c9ac8b611fac,9,2,1,15343,,,0,"s3token: Raise error on negative secret_cache_duration config

Change-Id: I8a961302a8905f483433976f6105b138a1acd7ba
",git fetch https://review.opendev.org/openstack/swift refs/changes/64/624464/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/middleware/s3api/s3token.py'],1,46bde0c0b2a99580584f34e4dd72c9ac8b611fac,603529, if self._secret_cache_duration < 0: raise ValueError('secret_cache_duration must be non-negative') if self._secret_cache_duration:, if self._secret_cache_duration > 0:,3,1
openstack%2Fswift~master~Ifddbb9df60207dfaaf0434877f4fe6af5c26bdf8,openstack/swift,master,Ifddbb9df60207dfaaf0434877f4fe6af5c26bdf8,"s3token: When caching is enabled, default auth_type to password",MERGED,2018-12-11 18:44:21.000000000,2020-01-31 19:05:41.000000000,2020-01-31 19:01:10.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-11 18:44:21.000000000', 'files': ['swift/common/middleware/s3api/s3token.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/ec70cf9605752e3b8a5c33ee7ef145f97df7567f', 'message': ""s3token: When caching is enabled, default auth_type to password\n\nOtherwise, if you just set secret_cache_duration and skip configuring\nauth_type, you get a not-very-obvious\n\n    TypeError: sequence item 0: expected string, NoneType found\n\nbubbling up from stevedore. Now, you'd get something like\n\n    MissingRequiredOptions: Auth plugin requires parameters which were\n    not given: auth_url\n\nChange-Id: Ifddbb9df60207dfaaf0434877f4fe6af5c26bdf8\n""}]",0,624462,ec70cf9605752e3b8a5c33ee7ef145f97df7567f,7,2,1,15343,,,0,"s3token: When caching is enabled, default auth_type to password

Otherwise, if you just set secret_cache_duration and skip configuring
auth_type, you get a not-very-obvious

    TypeError: sequence item 0: expected string, NoneType found

bubbling up from stevedore. Now, you'd get something like

    MissingRequiredOptions: Auth plugin requires parameters which were
    not given: auth_url

Change-Id: Ifddbb9df60207dfaaf0434877f4fe6af5c26bdf8
",git fetch https://review.opendev.org/openstack/swift refs/changes/62/624462/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/middleware/s3api/s3token.py'],1,ec70cf9605752e3b8a5c33ee7ef145f97df7567f,603529," conf.get('auth_type', 'password'))", conf.get('auth_type')),1,1
openstack%2Fswift~master~I1611e34846e586703e9d3709fa64e8df41f2d685,openstack/swift,master,I1611e34846e586703e9d3709fa64e8df41f2d685,proxy-logging: add fields ttfb and pid,MERGED,2020-01-27 20:56:06.000000000,2020-01-31 19:03:52.000000000,2020-01-31 19:01:09.000000000,"[{'_account_id': 13852}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-27 20:56:06.000000000', 'files': ['swift/common/middleware/proxy_logging.py', 'test/unit/common/middleware/test_proxy_logging.py', 'doc/manpages/proxy-server.conf.5', 'doc/source/logs.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/d8821c75bd79c2b95ab7635b58754d059be2079b', 'message': 'proxy-logging: add fields ttfb and pid\n\nChange-Id: I1611e34846e586703e9d3709fa64e8df41f2d685\n'}]",9,704424,d8821c75bd79c2b95ab7635b58754d059be2079b,10,3,1,13852,,,0,"proxy-logging: add fields ttfb and pid

Change-Id: I1611e34846e586703e9d3709fa64e8df41f2d685
",git fetch https://review.opendev.org/openstack/swift refs/changes/24/704424/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/proxy_logging.py', 'test/unit/common/middleware/test_proxy_logging.py', 'doc/manpages/proxy-server.conf.5', 'doc/source/logs.rst']",4,d8821c75bd79c2b95ab7635b58754d059be2079b,loggingPidTtfb,ttfb Duration between the request and the first bytes is sent.pid PID of the process emitting the log line.,,26,33
openstack%2Fswift~master~I0ac6dd0808fb041ba7663f4a472a06ee3f1d9a71,openstack/swift,master,I0ac6dd0808fb041ba7663f4a472a06ee3f1d9a71,Return correct etag for raw manifest,MERGED,2020-01-23 08:17:37.000000000,2020-01-31 18:55:57.000000000,2020-01-31 18:53:27.000000000,"[{'_account_id': 9625}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 08:17:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c676e740ed7918bfc0754e460b3fc9b37365b279', 'message': ""Return correct etag for raw manifest\n\nWhen client sends a '?multipart-manifest=get&format=raw' request\nmiddleware will change the manifest returned from object server.\nThis patch makes sure the response etag is updated to reflect\nchanges to manifest content\n\nChange-Id: I0ac6dd0808fb041ba7663f4a472a06ee3f1d9a71\n""}, {'number': 2, 'created': '2020-01-31 01:04:55.000000000', 'files': ['swift/common/middleware/slo.py', 'test/unit/common/middleware/test_slo.py', 'test/functional/test_slo.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/b8c16de0238054b7757c6c0f541af853232b54a9', 'message': ""Return correct etag for raw manifest\n\nWhen client sends a '?multipart-manifest=get&format=raw' request\nmiddleware will change the manifest returned from object server.\nThis patch makes sure the response etag is updated to reflect\nchanges to manifest content\n\nChange-Id: I0ac6dd0808fb041ba7663f4a472a06ee3f1d9a71\n""}]",5,703933,b8c16de0238054b7757c6c0f541af853232b54a9,12,3,2,9625,,,0,"Return correct etag for raw manifest

When client sends a '?multipart-manifest=get&format=raw' request
middleware will change the manifest returned from object server.
This patch makes sure the response etag is updated to reflect
changes to manifest content

Change-Id: I0ac6dd0808fb041ba7663f4a472a06ee3f1d9a71
",git fetch https://review.opendev.org/openstack/swift refs/changes/33/703933/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/slo.py', 'test/functional/test_slo.py']",2,c676e740ed7918bfc0754e460b3fc9b37365b279,," expected_etag = 'fail' for h, v in manifest.conn.response.getheaders(): if h == 'etag': expected_etag = v body_md5 = hashlib.md5(got_body).hexdigest() self.assertEqual(expected_etag, body_md5)",,8,0
openstack%2Fswift~master~Ifcb5013a5728d93cf5491fbff81b2677450698e6,openstack/swift,master,Ifcb5013a5728d93cf5491fbff81b2677450698e6,Dockerhub description of saio image,MERGED,2020-01-30 04:38:13.000000000,2020-01-31 18:49:29.000000000,2020-01-31 18:47:34.000000000,"[{'_account_id': 9625}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-30 04:38:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c880cdc62400de153894d864b109fe73fbf9f35f', 'message': 'Dockerhub description of saio image\n\nChange-Id: Ifcb5013a5728d93cf5491fbff81b2677450698e6\n'}, {'number': 2, 'created': '2020-01-30 04:41:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b5f90fcc8d7f82c2b4dfe6c2f8a77f5f13a2ca46', 'message': 'Dockerhub description of saio image\n\nChange-Id: Ifcb5013a5728d93cf5491fbff81b2677450698e6\n'}, {'number': 3, 'created': '2020-01-30 20:17:19.000000000', 'files': ['docker/dockerhub_description.md'], 'web_link': 'https://opendev.org/openstack/swift/commit/c7cb34ad61feb5b830ccb79437b32965916220ef', 'message': 'Dockerhub description of saio image\n\nChange-Id: Ifcb5013a5728d93cf5491fbff81b2677450698e6\n'}]",2,704923,c7cb34ad61feb5b830ccb79437b32965916220ef,14,3,3,9625,,,0,"Dockerhub description of saio image

Change-Id: Ifcb5013a5728d93cf5491fbff81b2677450698e6
",git fetch https://review.opendev.org/openstack/swift refs/changes/23/704923/2 && git format-patch -1 --stdout FETCH_HEAD,['docker/dockerhub_description.md'],1,c880cdc62400de153894d864b109fe73fbf9f35f,dockerhub_description,"# SAIO (Swift All in One) SAIO is a containerized instance of Openstack Swift object storage. It is running the main services of Swift, designed to provide an endpoint for application developers to test against both the Swift and AWS S3 API. It can also be used when integrating with a CI/CD system. These images are not configured to provide data durability and are not intended for production use. # Quickstart ``` docker pull openstackswift/saio docker run -d -p 8080:8080 openstackswift/saio ``` ### Test against Swift API: Example using swift client to target endpoint: ``` swift -A http://127.0.0.1:8080/auth/v1.0 -U test:tester -K testing stat ``` ### Test against S3 API: Example using s3cmd to test AWS S3: 1. Create config file: ``` [default] access_key = test:tester secret_key = testing host_base = localhost:8081 host_bucket = localhost:8081 use_https = False ``` 2. Test with s3cmd: ``` s3cmd -c s3cfg_saio mb s3://bucket ``` # Quick Reference - **Image tags**: `latest` automatically built/published by Zuul, follows master branch. Releases are also tagged in case you want to test against a specific release. - **Source Code**: github.com/openstack/swift - **Maintained by**: Openstack Swift community - **Feedback/Questions**: #openstack-swift on freenode ",,46,0
openstack%2Fglance~master~I5a1c61430879a910e7b6c79effba538431959d56,openstack/glance,master,I5a1c61430879a910e7b6c79effba538431959d56,Ensure store ID parsed from URI is properly encoded,MERGED,2020-01-31 14:46:01.000000000,2020-01-31 18:18:30.000000000,2020-01-31 18:10:19.000000000,"[{'_account_id': 5314}, {'_account_id': 9303}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-31 14:46:01.000000000', 'files': ['glance/common/store_utils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/8649fdc2a293009899d2aa918ec360e30adc8e77', 'message': ""Ensure store ID parsed from URI is properly encoded\n\nEnsure the store ID parsed from a request URI is unicode. This fixes\na py27 issue that allowed an incorrectly encoded value to be added to\nthe image's metadata.\n\nSupport for py27 is dropped in Ussuri, but this fix is required on\nearlier releases that do support py27.\n\nCloses-Bug: #1861501\nChange-Id: I5a1c61430879a910e7b6c79effba538431959d56\n""}]",0,705229,8649fdc2a293009899d2aa918ec360e30adc8e77,9,3,1,21129,,,0,"Ensure store ID parsed from URI is properly encoded

Ensure the store ID parsed from a request URI is unicode. This fixes
a py27 issue that allowed an incorrectly encoded value to be added to
the image's metadata.

Support for py27 is dropped in Ussuri, but this fix is required on
earlier releases that do support py27.

Closes-Bug: #1861501
Change-Id: I5a1c61430879a910e7b6c79effba538431959d56
",git fetch https://review.opendev.org/openstack/glance refs/changes/29/705229/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/common/store_utils.py'],1,8649fdc2a293009899d2aa918ec360e30adc8e77,bug/1861501," return u""%s"" % store", return store,1,1
openstack%2Fneutron~master~I0a9b91b09d6260ff96fdba2f0a455de53bbc1f00,openstack/neutron,master,I0a9b91b09d6260ff96fdba2f0a455de53bbc1f00,"Check ""security_group_rule"" quota during security group creation",MERGED,2020-01-08 15:45:07.000000000,2020-01-31 17:59:07.000000000,2020-01-31 17:40:46.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 9845}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 24791}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-08 15:45:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/26bffbbb816d1c3a4dda3432e76408411b0204b6', 'message': 'Check ""security_group_rule"" quota during security group creation\n\nThe tracked resources quota check is done at the beginning of an API\ncall to the Neutron server. The API call contains a resource and an\naction over the resource. In case of creation, the server checks if\nthe number of items requested fit in the existing quota.\n\nIn case of security group creation, the tracked resource checked is\n""security_group"". But ""SecurityGroupDbMixin.create_security_group""\nmethod also creates several default rules for the new group and the\nquota for ""security_group_rule"" is not enforced.\n\nThis patch checks the number of security group rules being created\n(""delta"") and checks in the plugin method (not in the API method) if\nthere is enough room for those new rules (tracked resource\n""security_group_rule"").\n\nChange-Id: I0a9b91b09d6260ff96fdba2f0a455de53bbc1f00\nCloses-Bug: #1858680\n'}, {'number': 2, 'created': '2020-01-08 15:46:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7fcaca9991c07824565a9aeab546264d41895dc1', 'message': 'Check ""security_group_rule"" quota during security group creation\n\nThe tracked resources quota check is done at the beginning of an API\ncall to the Neutron server. The API call contains a resource and an\naction over the resource. In case of creation, the server checks if\nthe number of items requested fit in the existing quota.\n\nIn case of security group creation, the tracked resource checked is\n""security_group"". But ""SecurityGroupDbMixin.create_security_group""\nmethod also creates several default rules for the new group and the\nquota for ""security_group_rule"" is not enforced.\n\nThis patch checks the number of security group rules being created\n(""delta"") and checks in the plugin method (not in the API method) if\nthere is enough room for those new rules (tracked resource\n""security_group_rule"").\n\nChange-Id: I0a9b91b09d6260ff96fdba2f0a455de53bbc1f00\nCloses-Bug: #1858680\n'}, {'number': 3, 'created': '2020-01-09 14:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4d770dd38ea6d69c9eb05dff6a0179fe800a28be', 'message': 'Check ""security_group_rule"" quota during security group creation\n\nThe tracked resources quota check is done at the beginning of an API\ncall to the Neutron server. The API call contains a resource and an\naction over the resource. In case of creation, the server checks if\nthe number of items requested fit in the existing quota.\n\nIn case of security group creation, the tracked resource checked is\n""security_group"". But ""SecurityGroupDbMixin.create_security_group""\nmethod also creates several default rules for the new group and the\nquota for ""security_group_rule"" is not enforced.\n\nThis patch checks the number of security group rules being created\n(""delta"") and checks in the plugin method (not in the API method) if\nthere is enough room for those new rules (tracked resource\n""security_group_rule"").\n\nChange-Id: I0a9b91b09d6260ff96fdba2f0a455de53bbc1f00\nCloses-Bug: #1858680\n'}, {'number': 4, 'created': '2020-01-17 18:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ee835913c9bb2ad20e968876c83a97b4552f1f4b', 'message': 'Check ""security_group_rule"" quota during security group creation\n\nThe tracked resources quota check is done at the beginning of an API\ncall to the Neutron server. The API call contains a resource and an\naction over the resource. In case of creation, the server checks if\nthe number of items requested fit in the existing quota.\n\nIn case of security group creation, the tracked resource checked is\n""security_group"". But ""SecurityGroupDbMixin.create_security_group""\nmethod also creates several default rules for the new group and the\nquota for ""security_group_rule"" is not enforced.\n\nThis patch checks the number of security group rules being created\n(""delta"") and checks in the plugin method (not in the API method) if\nthere is enough room for those new rules (tracked resource\n""security_group_rule"").\n\nChange-Id: I0a9b91b09d6260ff96fdba2f0a455de53bbc1f00\nCloses-Bug: #1858680\n'}, {'number': 5, 'created': '2020-01-18 11:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3e29a16ca3450e90c03dda8907905c6946bb76f5', 'message': 'Check ""security_group_rule"" quota during security group creation\n\nThe tracked resources quota check is done at the beginning of an API\ncall to the Neutron server. The API call contains a resource and an\naction over the resource. In case of creation, the server checks if\nthe number of items requested fit in the existing quota.\n\nIn case of security group creation, the tracked resource checked is\n""security_group"". But ""SecurityGroupDbMixin.create_security_group""\nmethod also creates several default rules for the new group and the\nquota for ""security_group_rule"" is not enforced.\n\nThis patch checks the number of security group rules being created\n(""delta"") and checks in the plugin method (not in the API method) if\nthere is enough room for those new rules (tracked resource\n""security_group_rule"").\n\nChange-Id: I0a9b91b09d6260ff96fdba2f0a455de53bbc1f00\nCloses-Bug: #1858680\n'}, {'number': 6, 'created': '2020-01-28 12:02:54.000000000', 'files': ['neutron/db/securitygroups_db.py', 'neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/tests/unit/db/test_securitygroups_db.py', 'neutron/tests/unit/scheduler/test_l3_agent_scheduler.py', 'neutron/tests/fullstack/resources/client.py', 'neutron/tests/unit/db/test_l3_hamode_db.py', 'neutron/tests/functional/db/test_network.py', 'neutron/tests/fullstack/test_securitygroup.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/936bd67aa42b2e06241d309315b895c9c9c49dcc', 'message': 'Check ""security_group_rule"" quota during security group creation\n\nThe tracked resources quota check is done at the beginning of an API\ncall to the Neutron server. The API call contains a resource and an\naction over the resource. In case of creation, the server checks if\nthe number of items requested fits in the existing quota.\n\nIn case of security group creation, the tracked resource checked is\n""security_group"". But ""SecurityGroupDbMixin.create_security_group""\nmethod also creates several default rules for the new group and the\nquota for ""security_group_rule"" is not enforced.\n\nThis patch checks the number of security group rules being created\n(""delta"") and checks in the plugin method (not in the API method) if\nthere is enough room for those new rules (tracked resource\n""security_group_rule"").\n\nChange-Id: I0a9b91b09d6260ff96fdba2f0a455de53bbc1f00\nCloses-Bug: #1858680\n'}]",4,701565,936bd67aa42b2e06241d309315b895c9c9c49dcc,65,7,6,16688,,,0,"Check ""security_group_rule"" quota during security group creation

The tracked resources quota check is done at the beginning of an API
call to the Neutron server. The API call contains a resource and an
action over the resource. In case of creation, the server checks if
the number of items requested fits in the existing quota.

In case of security group creation, the tracked resource checked is
""security_group"". But ""SecurityGroupDbMixin.create_security_group""
method also creates several default rules for the new group and the
quota for ""security_group_rule"" is not enforced.

This patch checks the number of security group rules being created
(""delta"") and checks in the plugin method (not in the API method) if
there is enough room for those new rules (tracked resource
""security_group_rule"").

Change-Id: I0a9b91b09d6260ff96fdba2f0a455de53bbc1f00
Closes-Bug: #1858680
",git fetch https://review.opendev.org/openstack/neutron refs/changes/65/701565/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/securitygroups_db.py', 'neutron/tests/fullstack/resources/client.py', 'neutron/tests/fullstack/test_securitygroup.py']",3,26bffbbb816d1c3a4dda3432e76408411b0204b6,bug/1858680,"from neutronclient.common import exceptions as nc_exc # ('ovs-hybrid', { # 'firewall_driver': 'iptables_hybrid', # 'l2_agent_type': constants.AGENT_TYPE_OVS, # 'num_hosts': 1}), # ('ovs-openflow', { # 'firewall_driver': 'openvswitch', # 'l2_agent_type': constants.AGENT_TYPE_OVS, # 'num_hosts': 2}), class SecurityGroupRulesTest(base.BaseFullStackTestCase): def setUp(self): host_descriptions = [environment.HostDescription()] env = environment.Environment(environment.EnvironmentDescription(), host_descriptions) super(SecurityGroupRulesTest, self).setUp(env) def test_security_group_rule_quota(self): project_id = uuidutils.generate_uuid() quota = self.client.show_quota_details(project_id) sg_rules_used = quota['quota']['security_group_rule']['used'] self.assertEqual(0, sg_rules_used) self.safe_client.create_security_group(project_id) quota = self.client.show_quota_details(project_id) sg_rules_used = quota['quota']['security_group_rule']['used'] self.safe_client.update_quota(project_id, 'security_group_rule', sg_rules_used) self.assertRaises(nc_exc.OverQuotaClient, self.safe_client.create_security_group, project_id)"," ('ovs-hybrid', { 'firewall_driver': 'iptables_hybrid', 'l2_agent_type': constants.AGENT_TYPE_OVS, 'num_hosts': 1}), ('ovs-openflow', { 'firewall_driver': 'openvswitch', 'l2_agent_type': constants.AGENT_TYPE_OVS, 'num_hosts': 2}),",46,8
openstack%2Fopenstack-ansible-os_tempest~master~I710f9ddccdd657bcdcd7e950a353c3c5ffa3e25c,openstack/openstack-ansible-os_tempest,master,I710f9ddccdd657bcdcd7e950a353c3c5ffa3e25c,"Revert ""Mark ubuntu distro install as non voting""",MERGED,2020-01-30 09:41:15.000000000,2020-01-31 17:53:06.000000000,2020-01-31 17:47:50.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-01-30 09:41:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/a6422fa6c34282764ac93202a932e7a7478626db', 'message': 'Revert ""Mark ubuntu distro install as non voting""\n\nThis reverts commit 0e17aafba9535d86399d1512f2fc3a6891883283.\n\nChange-Id: I710f9ddccdd657bcdcd7e950a353c3c5ffa3e25c\n'}, {'number': 2, 'created': '2020-01-30 09:41:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/5b708f04b99e83bffc674fc578d37e5b30107ac4', 'message': 'Revert ""Mark ubuntu distro install as non voting""\n\nThis reverts commit 0e17aafba9535d86399d1512f2fc3a6891883283.\n\nChange-Id: I710f9ddccdd657bcdcd7e950a353c3c5ffa3e25c\n'}, {'number': 3, 'created': '2020-01-31 12:16:14.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/81507e82607882b0ddf553c85647f4151c813ea8', 'message': 'Revert ""Mark ubuntu distro install as non voting""\n\nThis reverts commit 0e17aafba9535d86399d1512f2fc3a6891883283.\n\nChange-Id: I710f9ddccdd657bcdcd7e950a353c3c5ffa3e25c\n'}]",0,704946,81507e82607882b0ddf553c85647f4151c813ea8,15,4,3,25023,,,0,"Revert ""Mark ubuntu distro install as non voting""

This reverts commit 0e17aafba9535d86399d1512f2fc3a6891883283.

Change-Id: I710f9ddccdd657bcdcd7e950a353c3c5ffa3e25c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/46/704946/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,a6422fa6c34282764ac93202a932e7a7478626db,,, - openstack-ansible-deploy-aio_distro_metal-ubuntu-bionic: voting: false - openstack-ansible-deploy-aio_distro_metal-ubuntu-bionic: voting: false,0,4
openstack%2Fnova~stable%2Frocky~I58bd50e869fc00dde5dd388efb686a7196c8db80,openstack/nova,stable/rocky,I58bd50e869fc00dde5dd388efb686a7196c8db80,tox: Stop build *all* docs in 'docs',MERGED,2019-06-07 10:37:33.000000000,2020-01-31 17:45:10.000000000,2020-01-31 17:40:52.000000000,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 10135}, {'_account_id': 15334}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-06-07 10:37:33.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/76b4997c42bd5e95eb70ac850b73612aa2cbfa77', 'message': ""tox: Stop build *all* docs in 'docs'\n\nThe 'docs' target currently builds the documentation trees in 'api-ref',\n'api-guide' and 'placement-api-ref', in addition to 'doc'. This\nmassively increases the amount of time docs take to build both locally\nand in the gate. It's not necessary for gate, since separate jobs take\ncare of the other documents for us [1]. As such, we should stop doing\nit. For users that *do* care about this (for whatever reason) a new\n'all-docs' target is included.\n\n[1] https://github.com/openstack-infra/project-config/blob/master/zuul.d/projects.yaml#L5578-L5595\n\nChange-Id: I58bd50e869fc00dde5dd388efb686a7196c8db80\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n(cherry picked from commit f49b81fa2bd692583370bab569f25215073a5bc2)\n""}]",0,663888,76b4997c42bd5e95eb70ac850b73612aa2cbfa77,13,8,1,15334,,,0,"tox: Stop build *all* docs in 'docs'

The 'docs' target currently builds the documentation trees in 'api-ref',
'api-guide' and 'placement-api-ref', in addition to 'doc'. This
massively increases the amount of time docs take to build both locally
and in the gate. It's not necessary for gate, since separate jobs take
care of the other documents for us [1]. As such, we should stop doing
it. For users that *do* care about this (for whatever reason) a new
'all-docs' target is included.

[1] https://github.com/openstack-infra/project-config/blob/master/zuul.d/projects.yaml#L5578-L5595

Change-Id: I58bd50e869fc00dde5dd388efb686a7196c8db80
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
(cherry picked from commit f49b81fa2bd692583370bab569f25215073a5bc2)
",git fetch https://review.opendev.org/openstack/nova refs/changes/88/663888/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,76b4997c42bd5e95eb70ac850b73612aa2cbfa77,bug/1830926, Build main documentation.[testenv:all-docs] description = Build all documentation including API guides and refs. envdir = {toxworkdir}/docs deps = -r{toxinidir}/doc/requirements.txt commands = {[testenv:docs]commands} {[testenv:api-guide]commands} {[testenv:api-ref]commands} {[testenv:placement-api-ref]commands} {[testenv:releasenotes]commands} , Build all documentation including API guides and refs. {[testenv:api-guide]commands} {[testenv:api-ref]commands} {[testenv:placement-api-ref]commands},13,4
openstack%2Ftripleo-common~stable%2Ftrain~Ifbaa2d44550581d1acd9351b14192e6654cf05a1,openstack/tripleo-common,stable/train,Ifbaa2d44550581d1acd9351b14192e6654cf05a1,"Revert ""Make healthchecks more strict""",MERGED,2020-01-31 09:18:20.000000000,2020-01-31 17:44:55.000000000,2020-01-31 17:43:24.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 8449}, {'_account_id': 11090}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-31 09:18:20.000000000', 'files': ['healthcheck/common.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/f805411eec552398aa8c0dfa280008cdc3299fdc', 'message': 'Revert ""Make healthchecks more strict""\n\nThis reverts commit dddf584505bb24c53ba9d5fd92396695dc7a540c.\n\nApparently this makes a specific healthcheck fail - some\ninvestigations are needed.\nReverting this patch allows to avoid dropping a CI check\nas done https://review.opendev.org/705051\n\nMaster is being reverted - backport should be as well.\n\nChange-Id: Ifbaa2d44550581d1acd9351b14192e6654cf05a1\n'}]",3,705178,f805411eec552398aa8c0dfa280008cdc3299fdc,12,8,1,28223,,,0,"Revert ""Make healthchecks more strict""

This reverts commit dddf584505bb24c53ba9d5fd92396695dc7a540c.

Apparently this makes a specific healthcheck fail - some
investigations are needed.
Reverting this patch allows to avoid dropping a CI check
as done https://review.opendev.org/705051

Master is being reverted - backport should be as well.

Change-Id: Ifbaa2d44550581d1acd9351b14192e6654cf05a1
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/78/705178/1 && git format-patch -1 --stdout FETCH_HEAD,['healthcheck/common.sh'],1,f805411eec552398aa8c0dfa280008cdc3299fdc,healthchecks/strict-pipefail-stable/train," (ss -ntuap; sudo -u $puser ss -ntuap) | sort -u | grep -qE "":($ports).*,pid=($pids),""","set -eo pipefail # https://bugs.launchpad.net/tripleo/+bug/1860556 # do ot use ""-q"" option for grep, since it returns 141 for some reason with # set -o pipefail. # See https://stackoverflow.com/questions/19120263/why-exit-code-141-with-grep-q (ss -ntuap; sudo -u $puser ss -ntuap) | sort -u | grep -E "":($ports).*,pid=($pids),"">/dev/null",1,6
openstack%2Frequirements~master~Ica3a41629f0f5951c3da601a2d4fcc3cf732d9c5,openstack/requirements,master,Ica3a41629f0f5951c3da601a2d4fcc3cf732d9c5,Fix zipp for python3<3.6,MERGED,2020-01-31 10:15:40.000000000,2020-01-31 17:43:26.000000000,2020-01-31 17:40:48.000000000,"[{'_account_id': 6547}, {'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 14826}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-31 10:15:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/2dfaac90ffdb55444c8554b8659e6bed99966c73', 'message': 'Fix zipp for python3<3.6\n\nRepeats [1].\n\n[1] https://review.opendev.org/704263\n\nChange-Id: Ica3a41629f0f5951c3da601a2d4fcc3cf732d9c5\n'}, {'number': 2, 'created': '2020-01-31 10:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/a584fafc3818b02408ab7dbe50f6863f96d87fb5', 'message': 'Fix zipp for python3<3.6\n\nRepeats [1], this time with g-r pinning per request.\n\n[1] https://review.opendev.org/704263\n\nChange-Id: Ica3a41629f0f5951c3da601a2d4fcc3cf732d9c5\n'}, {'number': 3, 'created': '2020-01-31 12:59:15.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/5c646dae0f712c5e33c830250b71b56dc9872f60', 'message': 'Fix zipp for python3<3.6\n\nRepeats [1], this time with g-r pinning per request.\n\n[1] https://review.opendev.org/704263\n\nChange-Id: Ica3a41629f0f5951c3da601a2d4fcc3cf732d9c5\n'}]",0,705184,5c646dae0f712c5e33c830250b71b56dc9872f60,20,8,3,30491,,,0,"Fix zipp for python3<3.6

Repeats [1], this time with g-r pinning per request.

[1] https://review.opendev.org/704263

Change-Id: Ica3a41629f0f5951c3da601a2d4fcc3cf732d9c5
",git fetch https://review.opendev.org/openstack/requirements refs/changes/84/705184/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,2dfaac90ffdb55444c8554b8659e6bed99966c73,fix-zipp-old-py,zipp===1.1.0;python_version=='3.4' zipp===1.1.0;python_version=='3.5',zipp===2.1.0;python_version=='3.4' zipp===2.1.0;python_version=='3.5',2,2
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I111242773685c6461bd49dc564ae56072d1a7745,openstack/tripleo-heat-templates,stable/train,I111242773685c6461bd49dc564ae56072d1a7745,"Drop z flag on /var/run, it prevents redeployment",MERGED,2020-01-27 07:10:05.000000000,2020-01-31 17:43:25.000000000,2020-01-31 17:43:25.000000000,"[{'_account_id': 3153}, {'_account_id': 4264}, {'_account_id': 6469}, {'_account_id': 9592}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-27 07:10:05.000000000', 'files': ['deployment/metrics/collectd-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ad95b28c87e722603e94edec0f510b72dd942fab', 'message': 'Drop z flag on /var/run, it prevents redeployment\n\nThis is related to\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1784608\n\nIn short, it will mess up selinux labeling for /var/run and it\nis likely to break the system.\n\nChange-Id: I111242773685c6461bd49dc564ae56072d1a7745\n(cherry picked from commit 719d8329d285942157d8461f74af59001e5b8e4c)\n'}]",0,704272,ad95b28c87e722603e94edec0f510b72dd942fab,16,7,1,4264,,,0,"Drop z flag on /var/run, it prevents redeployment

This is related to
https://bugzilla.redhat.com/show_bug.cgi?id=1784608

In short, it will mess up selinux labeling for /var/run and it
is likely to break the system.

Change-Id: I111242773685c6461bd49dc564ae56072d1a7745
(cherry picked from commit 719d8329d285942157d8461f74af59001e5b8e4c)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/72/704272/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/metrics/collectd-container-puppet.yaml'],1,ad95b28c87e722603e94edec0f510b72dd942fab,, - /var/run/:/var/run:rw," - /var/run/:/var/run:rw,z",1,1
openstack%2Fswift~master~Ic67584f98c41b68ce053c4e8f3449bb8bd148899,openstack/swift,master,Ic67584f98c41b68ce053c4e8f3449bb8bd148899,Store version id when copying object to archive,ABANDONED,2017-02-23 16:49:42.000000000,2020-01-31 17:43:07.000000000,,"[{'_account_id': 3}, {'_account_id': 4608}, {'_account_id': 7233}, {'_account_id': 12279}, {'_account_id': 13052}, {'_account_id': 15343}, {'_account_id': 22348}, {'_account_id': 23861}, {'_account_id': 28111}]","[{'number': 1, 'created': '2017-02-23 16:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ee320a1880adc9a2e6383e30c0a0ddd9017fc1ec', 'message': 'Store version id if restoring object from archive\n\nWhen the current object is deleted and the versioning mode is set to\n""stack"", an older object from the archive container is restored as the\ncurrent object.  The ""version id"" is only part of the object name when\nit is in the archive container, which means that when it becomes the\ncurrent object, the ""version id"" is lost.  swift3 needs to know the\nversion id even after it is restored, but right now there is no way to\nget the version id.\n\nThis change stores the version id as metadata\n""X-Object-Meta-Version-Id"" as the object is restored so it is possible\nto get the version id.\n\nChange-Id: Ic67584f98c41b68ce053c4e8f3449bb8bd148899\n'}, {'number': 2, 'created': '2017-03-27 15:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/818e375ace7c9140f255b0acb3492bd9f3eabf51', 'message': 'Store version id if restoring object from archive\n\nWhen the current object is deleted and the versioning mode is set to\n""stack"", an older object from the archive container is restored as the\ncurrent object.  The ""version id"" is only part of the object name when\nit is in the archive container, which means that when it becomes the\ncurrent object, the ""version id"" is lost.  swift3 needs to know the\nversion id even after it is restored, but right now there is no way to\nget the version id.\n\nThis change stores the version id as metadata\n""X-Object-Sysmeta-Version-Id"" as the object is restored so it is\npossible to get the version id.\n\nChange-Id: Ic67584f98c41b68ce053c4e8f3449bb8bd148899\n'}, {'number': 3, 'created': '2017-03-28 12:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/416600464d5036336846f5d082fbed50441575b8', 'message': 'Store version id if restoring object from archive\n\nWhen the current object is deleted and the versioning mode is set to\n""stack"", an older object from the archive container is restored as the\ncurrent object.  The ""version id"" is only part of the object name when\nit is in the archive container, which means that when it becomes the\ncurrent object, the ""version id"" is lost.  swift3 needs to know the\nversion id even after it is restored, but right now there is no way to\nget the version id.\n\nThis change stores the version id as metadata\n""X-Object-Sysmeta-Version-Id"" as the object is restored so it is\npossible to get the version id.\n\nChange-Id: Ic67584f98c41b68ce053c4e8f3449bb8bd148899\n'}, {'number': 4, 'created': '2017-05-04 10:21:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c990babb11ea5af8aa17325c5b6eccb28586e4cc', 'message': 'Store version id if restoring object from archive\n\nWhen the current object is deleted and the versioning mode is set to\n""stack"", an older object from the archive container is restored as the\ncurrent object.  The ""version id"" is only part of the object name when\nit is in the archive container, which means that when it becomes the\ncurrent object, the ""version id"" is lost.  swift3 needs to know the\nversion id even after it is restored, but right now there is no way to\nget the version id.\n\nThis change stores the version id as metadata\n""X-Object-Sysmeta-Version-Id"" as the object is restored so it is\npossible to get the version id.\n\nChange-Id: Ic67584f98c41b68ce053c4e8f3449bb8bd148899\n'}, {'number': 5, 'created': '2017-05-04 11:07:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fec5bbbd8c055c28e33d972ef8e23b96f5c76f9c', 'message': 'Store version id when copying object to archive\n\nWhen the current object is deleted and the versioning mode is set to\n""stack"", an older object from the archive container is restored as the\ncurrent object.  The ""version id"" is only part of the object name when\nit is in the archive container, which means that when it becomes the\ncurrent object, the ""version id"" is lost.  swift3 needs to know the\nversion id even after it is restored, but right now there is no way to\nget the version id.\n\nThis change stores the version id as metadata\n""X-Object-Sysmeta-Version-Id"" when an object is copied to the archive\ncontainer and given a version id.\n\nChange-Id: Ic67584f98c41b68ce053c4e8f3449bb8bd148899\n'}, {'number': 6, 'created': '2017-05-10 16:07:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f15b84c85082cbd2fb43a123afab5b5809255b78', 'message': 'Store version id when copying object to archive\n\nWhen the current object is deleted and the versioning mode is set to\n""stack"", an older object from the archive container is restored as the\ncurrent object.  The ""version id"" is only part of the object name when\nit is in the archive container, which means that when it becomes the\ncurrent object, the ""version id"" is lost.  swift3 needs to know the\nversion id even after it is restored, but right now there is no way to\nget the version id.\n\nThis change stores the version id as metadata\n""X-Object-Sysmeta-Version-Id"" when an object is copied to the archive\ncontainer and given a version id.\n\nChange-Id: Ic67584f98c41b68ce053c4e8f3449bb8bd148899\n'}, {'number': 7, 'created': '2017-05-15 11:14:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f90a9f25a4a15abd3504c81b70d8814d8b44d55f', 'message': 'Store version id when copying object to archive\n\nWhen the current object is deleted and the versioning mode is set to\n""stack"", an older object from the archive container is restored as the\ncurrent object.  The ""version id"" is only part of the object name when\nit is in the archive container, which means that when it becomes the\ncurrent object, the ""version id"" is lost.  swift3 needs to know the\nversion id even after it is restored, but right now there is no way to\nget the version id.\n\nThis change stores the version id as metadata\n""X-Object-Sysmeta-Version-Id"" when an object is copied to the archive\ncontainer and given a version id.\n\nChange-Id: Ic67584f98c41b68ce053c4e8f3449bb8bd148899\n'}, {'number': 8, 'created': '2017-05-15 11:19:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d3852433b69c1e42c6fea09703b9f1125dc4438e', 'message': 'Store version id when copying object to archive\n\nWhen the current object is deleted and the versioning mode is set to\n""stack"", an older object from the archive container is restored as the\ncurrent object.  The ""version id"" is only part of the object name when\nit is in the archive container, which means that when it becomes the\ncurrent object, the ""version id"" is lost.  swift3 needs to know the\nversion id even after it is restored, but right now there is no way to\nget the version id.\n\nThis change stores the version id as metadata\n""X-Object-Sysmeta-Version-Id"" when an object is copied to the archive\ncontainer and given a version id.\n\nChange-Id: Ic67584f98c41b68ce053c4e8f3449bb8bd148899\n'}, {'number': 9, 'created': '2019-01-15 23:24:56.000000000', 'files': ['swift/common/middleware/versioned_writes.py', 'test/unit/common/middleware/test_versioned_writes.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/741d4fc69f9214902b53d00c2f65c9115d0040ee', 'message': 'Store version id when copying object to archive\n\nWhen the current object is deleted and the versioning mode is set to\n""stack"", an older object from the archive container is restored as the\ncurrent object.  The ""version id"" is only part of the object name when\nit is in the archive container, which means that when it becomes the\ncurrent object, the ""version id"" is lost.  swift3 needs to know the\nversion id even after it is restored, but right now there is no way to\nget the version id.\n\nThis change stores the version id as metadata\n""X-Object-Sysmeta-Version-Id"" when an object is copied to the archive\ncontainer and given a version id.\n\nChange-Id: Ic67584f98c41b68ce053c4e8f3449bb8bd148899\n'}]",12,437523,741d4fc69f9214902b53d00c2f65c9115d0040ee,41,9,9,23861,,,0,"Store version id when copying object to archive

When the current object is deleted and the versioning mode is set to
""stack"", an older object from the archive container is restored as the
current object.  The ""version id"" is only part of the object name when
it is in the archive container, which means that when it becomes the
current object, the ""version id"" is lost.  swift3 needs to know the
version id even after it is restored, but right now there is no way to
get the version id.

This change stores the version id as metadata
""X-Object-Sysmeta-Version-Id"" when an object is copied to the archive
container and given a version id.

Change-Id: Ic67584f98c41b68ce053c4e8f3449bb8bd148899
",git fetch https://review.opendev.org/openstack/swift refs/changes/23/437523/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/versioned_writes.py', 'test/functional/swift_test_client.py', 'test/functional/test_versioned_writes.py']",3,ee320a1880adc9a2e6383e30c0a0ddd9017fc1ec,s3-versioning," versions = [v.split('/')[-1] for v in versions_container.files(parms={'reverse': 'on'})] self.assertNotIn('x_object_meta_version_id', versioned_obj.info()) self.assertEqual(versions.pop(0), versioned_obj.info()['x_object_meta_version_id']) self.assertEqual(versions.pop(0), versioned_obj.info()['x_object_meta_version_id']) self.assertEqual(versions.pop(0), versioned_obj.info()['x_object_meta_version_id'])",,14,1
openstack%2Fswift~master~Ice083531f3663d875fbc8f9f583fe7104443b5d5,openstack/swift,master,Ice083531f3663d875fbc8f9f583fe7104443b5d5,Add X-Backend-Versioning-Mode-Override,ABANDONED,2017-02-23 00:05:28.000000000,2020-01-31 17:42:57.000000000,,"[{'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 7847}, {'_account_id': 9625}, {'_account_id': 13052}, {'_account_id': 14766}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-02-23 00:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c50eb138ea2e2fc16c01ff5b59513dab434a8106', 'message': 'Add X-Backend-Versioning-Mode-Override\n\nswift3 needs both the stack mode delete and history mode delete.  When\nan object without specifying a ""versionId"" is deleted, swift3 uses the\nhistory mode delete, which means the object is marked as deleted and\nreturns 404.  When an object with a specific ""versionId"" is deleted and\nthat object is the current object, swift3 uses the stack mode delete,\nwhich means the most recent non-deleted object in the versioning\ncontainer becomes the current object.  Right now, swift only supports\nsetting the mode once and using it to determine the behavior of the\ndeletion.\n\nAdding X-Backend-Versioning-Mode-Override allows swift3 to override the\nstored versioning mode for one request.  This means that even if the\nversioning mode is set to ""history"", if the request has the header\n""X-Backend-Versioning-Mode-Override: stack"", swift will use ""stack"" as\nthe versioning mode.\n\nChange-Id: Ice083531f3663d875fbc8f9f583fe7104443b5d5\n'}, {'number': 2, 'created': '2017-03-28 12:56:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/81dfa428612d3f7b55b584860cafd50bcd070576', 'message': 'Add X-Backend-Versioning-Mode-Override\n\nswift3 needs both the stack mode delete and history mode delete.  When\nan object without specifying a ""versionId"" is deleted, swift3 uses the\nhistory mode delete, which means the object is marked as deleted and\nreturns 404.  When an object with a specific ""versionId"" is deleted and\nthat object is the current object, swift3 uses the stack mode delete,\nwhich means the most recent non-deleted object in the versioning\ncontainer becomes the current object.  Right now, swift only supports\nsetting the mode once and using it to determine the behavior of the\ndeletion.\n\nAdding X-Backend-Versioning-Mode-Override allows swift3 to override the\nstored versioning mode for one request.  This means that even if the\nversioning mode is set to ""history"", if the request has the header\n""X-Backend-Versioning-Mode-Override: stack"", swift will use ""stack"" as\nthe versioning mode.\n\nChange-Id: Ice083531f3663d875fbc8f9f583fe7104443b5d5\n'}, {'number': 3, 'created': '2019-01-15 23:24:56.000000000', 'files': ['swift/common/middleware/versioned_writes.py', 'test/unit/common/middleware/test_versioned_writes.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/409341c2d0f1f2e3c0f710594c9047057ffdb477', 'message': 'Add X-Backend-Versioning-Mode-Override\n\nswift3 needs both the stack mode delete and history mode delete.  When\nan object without specifying a ""versionId"" is deleted, swift3 uses the\nhistory mode delete, which means the object is marked as deleted and\nreturns 404.  When an object with a specific ""versionId"" is deleted and\nthat object is the current object, swift3 uses the stack mode delete,\nwhich means the most recent non-deleted object in the versioning\ncontainer becomes the current object.  Right now, swift only supports\nsetting the mode once and using it to determine the behavior of the\ndeletion.\n\nAdding X-Backend-Versioning-Mode-Override allows swift3 to override the\nstored versioning mode for one request.  This means that even if the\nversioning mode is set to ""history"", if the request has the header\n""X-Backend-Versioning-Mode-Override: stack"", swift will use ""stack"" as\nthe versioning mode.\n\nChange-Id: Ice083531f3663d875fbc8f9f583fe7104443b5d5\n'}]",1,437196,409341c2d0f1f2e3c0f710594c9047057ffdb477,16,8,3,23861,,,0,"Add X-Backend-Versioning-Mode-Override

swift3 needs both the stack mode delete and history mode delete.  When
an object without specifying a ""versionId"" is deleted, swift3 uses the
history mode delete, which means the object is marked as deleted and
returns 404.  When an object with a specific ""versionId"" is deleted and
that object is the current object, swift3 uses the stack mode delete,
which means the most recent non-deleted object in the versioning
container becomes the current object.  Right now, swift only supports
setting the mode once and using it to determine the behavior of the
deletion.

Adding X-Backend-Versioning-Mode-Override allows swift3 to override the
stored versioning mode for one request.  This means that even if the
versioning mode is set to ""history"", if the request has the header
""X-Backend-Versioning-Mode-Override: stack"", swift will use ""stack"" as
the versioning mode.

Change-Id: Ice083531f3663d875fbc8f9f583fe7104443b5d5
",git fetch https://review.opendev.org/openstack/swift refs/changes/96/437196/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/versioned_writes.py', 'test/unit/common/middleware/test_versioned_writes.py']",2,c50eb138ea2e2fc16c01ff5b59513dab434a8106,s3-versioning," @mock.patch('swift.common.middleware.versioned_writes.time.time', return_value=1234) def test_mode_override_delete_history(self, _): self.app.register( 'GET', '/v1/a/c/o', swob.HTTPOk, { 'content-type': '10', 'last-modified': 'Wed, 22 Feb 2017 23:44:50 GMT', }, '0123456789') self.app.register( 'PUT', '/v1/a/ver_cont/001o/1487807090.00000', swob.HTTPCreated, {}, None) self.app.register( 'PUT', '/v1/a/ver_cont/001o/0000001234.00000', swob.HTTPCreated, {}, None) self.app.register('DELETE', '/v1/a/c/o', swob.HTTPOk, {}, 'passed') cache = FakeCache({'sysmeta': { 'versions-location': 'ver_cont', 'versions-mode': 'stack', }}) req = Request.blank( '/v1/a/c/o', headers={'X-Backend-Versioning-Mode-Override': 'history'}, environ={'REQUEST_METHOD': 'DELETE', 'swift.cache': cache, 'CONTENT_LENGTH': '0'}) status, headers, body = self.call_vw(req) self.assertEqual(status, '200 OK') self.assertEqual(body, 'passed') def test_mode_override_delete_stack(self): self.app.register('DELETE', '/v1/a/c/o', swob.HTTPOk, {}, None) self.app.register( 'GET', '/v1/a/ver_cont?format=json&prefix=001o/&marker=&reverse=on', swob.HTTPOk, {}, '[{""hash"": ""y"",' ' ""last_modified"": ""2017-02-22 23:29:25.841068"",' ' ""bytes"": 20,' ' ""name"": ""001o/1"",' ' ""content_type"": ""text/plain""}]') self.app.register( 'GET', '/v1/a/ver_cont/001o/1', swob.HTTPOk, {'content-length': '20'}, None) self.app.register( 'PUT', '/v1/a/c/o', swob.HTTPCreated, {}, None) self.app.register( 'DELETE', '/v1/a/ver_cont/001o/1', swob.HTTPOk, {}, 'passed') cache = FakeCache({'sysmeta': { 'versions-location': 'ver_cont', 'versions-mode': 'history', }}) req = Request.blank( '/v1/a/c/o', headers={'X-Backend-Versioning-Mode-Override': 'stack'}, environ={'REQUEST_METHOD': 'DELETE', 'swift.cache': cache, 'CONTENT_LENGTH': '0'}) status, headers, body = self.call_vw(req) self.assertEqual(status, '200 OK') self.assertEqual(body, 'passed') ",,64,0
openstack%2Fneutron~master~I45a51736e4075e3dbc16827486869d70b659622d,openstack/neutron,master,I45a51736e4075e3dbc16827486869d70b659622d,Fix resource schemas and releated `get_sorts` test cases,MERGED,2019-05-20 11:39:00.000000000,2020-01-31 17:30:08.000000000,2019-06-01 08:25:59.000000000,"[{'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 5367}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 26622}, {'_account_id': 28889}]","[{'number': 1, 'created': '2019-05-20 11:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/25de2f9051454e2e3ae0c0b7c5714c248f2625dc', 'message': ""Fix resource schemas and releated `get_sorts` test cases\n\nWhen i'm trying to introduce a central sort-keys validation within\npatch [1] to `get_sorts` method in `neutron.api.api_common` module,\ni get blocked by some resource schemas and test cases. After reading\nneutron API docs and some inspection, i believe there exists uses of\nimproper sort keys in test cases and some resource schemes need to\nkeep aligned with offical statements.\n\n* Schemas of resource SecurityGroups/SG Rules/Segments don't provide\n`is_sort_key` flag for their sort key properties claimed in offical\ndocs as neutron-lib does. See [3][4][5] for more details.\n\n* Test cases of resource NetworkSegmentRange use unsupported sort keys,\ne.g: physical_network. Replace it with `name` property. See [6] for more\ndetails.\n\nSee [2] for failed unit tests that blocked me.\n\n[1] https://review.opendev.org/#/c/653903/\n[2] http://logs.openstack.org/03/653903/13/check/openstack-tox-py3\n    6/bd2562d/testr_results.html.gz\n[3] https://developer.openstack.org/api-ref/network/v2/index.html?\n    expanded=list-security-groups-detail\n[4] https://developer.openstack.org/api-ref/network/v2/index.html?\n    expanded=list-security-group-rules-detail\n[5] https://developer.openstack.org/api-ref/network/v2/index.html?\n    expanded=list-segments-detail#segments\n[6] https://developer.openstack.org/api-ref/network/v2/index.html?\n    expanded=list-network-segment-ranges-detail#network-segment-ranges\n\nChange-Id: I45a51736e4075e3dbc16827486869d70b659622d\n""}, {'number': 2, 'created': '2019-05-20 12:02:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/20f00e17f5f67a9d4e614309d64f4d9bb77987f3', 'message': ""Fix resource schemas and releated `get_sorts` test cases\n\nWhen i'm trying to introduce a central sort-keys validation within\npatch [1] to `get_sorts` method in `neutron.api.api_common` module,\ni get blocked by some resource schemas and test cases. After reading\nneutron API docs and some inspection, i believe there exists uses of\nimproper sort keys in test cases and some resource schemes need to\nkeep aligned with offical statements.\n\n* Schemas of resource SecurityGroups/SG Rules/Segments don't provide\n`is_sort_key` flag for their sort key properties claimed in offical\ndocs as neutron-lib does. See [3][4][5] for more details.\n\n* Test cases of resource NetworkSegmentRange use unsupported sort keys,\ne.g: physical_network. Replace it with `name` property. See [6] for more\ndetails.\n\nSee [2] for failed unit tests that blocked me.\n\n[1] https://review.opendev.org/#/c/653903/\n[2] http://logs.openstack.org/03/653903/13/check/openstack-tox-py36/bd2562d/testr_results.html.gz\n[3] https://developer.openstack.org/api-ref/network/v2/index.html?expanded=list-security-groups-detail\n[4] https://developer.openstack.org/api-ref/network/v2/index.html?expanded=list-security-group-rules-detail\n[5] https://developer.openstack.org/api-ref/network/v2/index.html?expanded=list-segments-detail#segments\n[6] https://developer.openstack.org/api-ref/network/v2/index.html?expanded=list-network-segment-ranges-detail#network-segment-ranges\n\nChange-Id: I45a51736e4075e3dbc16827486869d70b659622d\n""}, {'number': 3, 'created': '2019-05-29 03:21:54.000000000', 'files': ['neutron/extensions/securitygroup.py', 'neutron/extensions/segment.py', 'neutron/tests/unit/extensions/test_network_segment_range.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ed3f1087fa354a91721d3046ce134e18c86f22b3', 'message': ""Fix resource schemas and releated `get_sorts` test cases\n\nWhen I'm trying to introduce a central sort-keys validation within\npatch [1] to `get_sorts` method in `neutron.api.api_common` module,\nI get blocked by some resource schemas and test cases. After reading\nneutron API docs and some inspection, I believe there exists uses of\nimproper sort keys in test cases and some resource schemes need to\nkeep aligned with offical documents.\n\n* Schemas of resource SecurityGroups/SG Rules/Segments don't provide\n`is_sort_key` flag for their sort key properties claimed in offical\ndocs as neutron-lib does. See [2] for more details.\n\n* Test cases of resource NetworkSegmentRange use unsupported sort keys,\ne.g: physical_network. Replace it with `name` property. See [2] for more\ndetails.\n\n[1] https://review.opendev.org/#/c/653903/\n[2] https://developer.openstack.org/api-ref/network/v2/index.html\n\nChange-Id: I45a51736e4075e3dbc16827486869d70b659622d\n""}]",21,660097,ed3f1087fa354a91721d3046ce134e18c86f22b3,42,13,3,28889,,,0,"Fix resource schemas and releated `get_sorts` test cases

When I'm trying to introduce a central sort-keys validation within
patch [1] to `get_sorts` method in `neutron.api.api_common` module,
I get blocked by some resource schemas and test cases. After reading
neutron API docs and some inspection, I believe there exists uses of
improper sort keys in test cases and some resource schemes need to
keep aligned with offical documents.

* Schemas of resource SecurityGroups/SG Rules/Segments don't provide
`is_sort_key` flag for their sort key properties claimed in offical
docs as neutron-lib does. See [2] for more details.

* Test cases of resource NetworkSegmentRange use unsupported sort keys,
e.g: physical_network. Replace it with `name` property. See [2] for more
details.

[1] https://review.opendev.org/#/c/653903/
[2] https://developer.openstack.org/api-ref/network/v2/index.html

Change-Id: I45a51736e4075e3dbc16827486869d70b659622d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/97/660097/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/extensions/securitygroup.py', 'neutron/extensions/segment.py', 'neutron/tests/unit/extensions/test_network_segment_range.py']",3,25de2f9051454e2e3ae0c0b7c5714c248f2625dc,660097," [('name', 'desc')]) ('name', 'asc'), 2, 2) ('name', 'asc'), 2, 2)"," [('physical_network', 'desc')]) ('physical_network', 'asc'), 2, 2) ('physical_network', 'asc'), 2, 2)",23,10
openstack%2Fpuppet-tripleo~master~Id69ab97b26379fd8a031600bd2f77bc5a3f34659,openstack/puppet-tripleo,master,Id69ab97b26379fd8a031600bd2f77bc5a3f34659,mysql: allow container-puppet-mysql to initiate the database,ABANDONED,2020-01-30 02:01:58.000000000,2020-01-31 17:06:44.000000000,,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-30 02:01:58.000000000', 'files': ['manifests/profile/base/database/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/a099607d0a52375d8ceb5bac791724118ef7d6ba', 'message': 'mysql: allow container-puppet-mysql to initiate the database\n\nA few facts for the context of this patch:\n\n- The default STEP number in THT/common/container-puppet.py is set to 6.\n- When called at step 1, container-puppet.py is called without\n  overriding the STEP environment, so 6 is taken as default.\n- Therefore, the mysql manifest is well executed since we have a\n  condition like ""if $step >= $mysql_step"".\n\nI would like to fix the item #2 and call container-puppet.py at step 1\nwith STEP=1 (it makes sense right?) but of course since we have this\ncondition in the puppet manifest, the mysql resources don\'t get created.\n\nThis changes removes the legacy ""mysql_step"" variable and deploy the\nmysql resources starting at step 1.\n\nChange-Id: Id69ab97b26379fd8a031600bd2f77bc5a3f34659\n'}]",0,704916,a099607d0a52375d8ceb5bac791724118ef7d6ba,7,3,1,3153,,,0,"mysql: allow container-puppet-mysql to initiate the database

A few facts for the context of this patch:

- The default STEP number in THT/common/container-puppet.py is set to 6.
- When called at step 1, container-puppet.py is called without
  overriding the STEP environment, so 6 is taken as default.
- Therefore, the mysql manifest is well executed since we have a
  condition like ""if $step >= $mysql_step"".

I would like to fix the item #2 and call container-puppet.py at step 1
with STEP=1 (it makes sense right?) but of course since we have this
condition in the puppet manifest, the mysql resources don't get created.

This changes removes the legacy ""mysql_step"" variable and deploy the
mysql resources starting at step 1.

Change-Id: Id69ab97b26379fd8a031600bd2f77bc5a3f34659
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/16/704916/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/database/mysql.pp'],1,a099607d0a52375d8ceb5bac791724118ef7d6ba,step, if $step >= 1 {, # non-ha scenario if $manage_resources { $mysql_step = 2 } else { # ha scenario $mysql_step = 1 } if $step >= $mysql_step {,1,8
openstack%2Fironic~stable%2Ftrain~I59a046c06334a3366d0c7070114446efa832df23,openstack/ironic,stable/train,I59a046c06334a3366d0c7070114446efa832df23,Fix typo in setup-network.sh script,MERGED,2020-01-31 10:12:00.000000000,2020-01-31 17:03:46.000000000,2020-01-31 17:01:52.000000000,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-01-31 10:12:00.000000000', 'files': ['devstack/tools/ironic/scripts/setup-network.sh'], 'web_link': 'https://opendev.org/openstack/ironic/commit/6ceec86ad4082390b7226ca66d524b562e74101b', 'message': ""Fix typo in setup-network.sh script\n\nRemoving a $ sign that shouldn't be there and can cause trouble.\n\nChange-Id: I59a046c06334a3366d0c7070114446efa832df23\n(cherry picked from commit 90b747ac669ee8985335930945ee6fe20d8157fa)\n""}]",0,705182,6ceec86ad4082390b7226ca66d524b562e74101b,10,5,1,15519,,,0,"Fix typo in setup-network.sh script

Removing a $ sign that shouldn't be there and can cause trouble.

Change-Id: I59a046c06334a3366d0c7070114446efa832df23
(cherry picked from commit 90b747ac669ee8985335930945ee6fe20d8157fa)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/82/705182/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/tools/ironic/scripts/setup-network.sh'],1,6ceec86ad4082390b7226ca66d524b562e74101b,minor-fix-bash-stable/train,(sudo ovs-vsctl list-br | grep ${BRIDGE_NAME}) || sudo ovs-vsctl add-br ${BRIDGE_NAME},(sudo ovs-vsctl list-br | grep ${BRIDGE_NAME}$) || sudo ovs-vsctl add-br ${BRIDGE_NAME},1,1
openstack%2Fcharm-interface-mysql-shared~master~If31eaad0b781d4250524335377152f3bd140f57b,openstack/charm-interface-mysql-shared,master,If31eaad0b781d4250524335377152f3bd140f57b,Remove DB available states if maintenance mode,MERGED,2020-01-30 19:40:22.000000000,2020-01-31 16:56:21.000000000,2020-01-31 16:56:21.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-30 19:40:22.000000000', 'files': ['requires.py'], 'web_link': 'https://opendev.org/openstack/charm-interface-mysql-shared/commit/6c1b8d41927f0e4687fa8d4b5423d5349ca1c27f', 'message': ""Remove DB available states if maintenance mode\n\nIf the DB is in maintance mode then remove the 'availble' states\nto let the charms now the db cannot be accessed.\n\nDepends-On: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f\nChange-Id: If31eaad0b781d4250524335377152f3bd140f57b\n""}]",0,705101,6c1b8d41927f0e4687fa8d4b5423d5349ca1c27f,7,3,1,12549,,,0,"Remove DB available states if maintenance mode

If the DB is in maintance mode then remove the 'availble' states
to let the charms now the db cannot be accessed.

Depends-On: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f
Change-Id: If31eaad0b781d4250524335377152f3bd140f57b
",git fetch https://review.opendev.org/openstack/charm-interface-mysql-shared refs/changes/01/705101/1 && git format-patch -1 --stdout FETCH_HEAD,['requires.py'],1,6c1b8d41927f0e4687fa8d4b5423d5349ca1c27f,gate-on-db-maintenance-mode," 'ssl_ca', 'ssl_cert', 'ssl_key', 'cluster-series-upgrading'] if self.cluster_series_upgrading() == 'True': self.remove_state('{relation_name}.available') self.remove_state('{relation_name}.available.access_network') self.remove_state('{relation_name}.available.ssl') else: if self.base_data_complete(): self.set_state('{relation_name}.available') if self.access_network_data_complete(): self.set_state('{relation_name}.available.access_network') if self.ssl_data_complete(): self.set_state('{relation_name}.available.ssl')"," 'ssl_ca', 'ssl_cert', 'ssl_key'] if self.base_data_complete(): self.set_state('{relation_name}.available') if self.access_network_data_complete(): self.set_state('{relation_name}.available.access_network') if self.ssl_data_complete(): self.set_state('{relation_name}.available.ssl')",13,7
openstack%2Fpython-dracclient~master~I4ca1b7f6df47ce808920b5e24ad0be6b76963917,openstack/python-dracclient,master,I4ca1b7f6df47ce808920b5e24ad0be6b76963917,Fix parsing for virtual disk RAIDStatus attribute,MERGED,2020-01-29 06:39:27.000000000,2020-01-31 16:49:08.000000000,2020-01-31 16:49:08.000000000,"[{'_account_id': 10250}, {'_account_id': 10644}, {'_account_id': 22348}, {'_account_id': 29405}]","[{'number': 1, 'created': '2020-01-29 06:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-dracclient/commit/744f5de2d87fe4d84642f19de3c21a87ea4fc626', 'message': 'Changed DCIM_VirtualDiskView.RAIDStatus to RaidStatus\n\nThis patch fixes the RAIDStatus attribute to RaidStatus in\nDCIM_VirtualDiskView enumeration for the servers with\nLCC version 4.0.0\n\nChange-Id: I4ca1b7f6df47ce808920b5e24ad0be6b76963917\n'}, {'number': 2, 'created': '2020-01-30 05:17:47.000000000', 'files': ['dracclient/tests/test_raid.py', 'dracclient/tests/utils.py', 'dracclient/tests/wsman_mocks/virtual_disk_view-enum-with-raid-status-ok.xml', 'dracclient/resources/raid.py'], 'web_link': 'https://opendev.org/openstack/python-dracclient/commit/01e7ca19ce4161d9153dfe45520072521b0164b0', 'message': 'Fix parsing for virtual disk RAIDStatus attribute\n\nThis patch changes the parsing of virtual disks so\nthat if the DCIM_VirutalDiskView.RAIDStatus attribute\nis not present then DCIM_VirutalDiskView.RaidStatus\nwill be used instead.\nThis is needed due to the attribute being renamed in\nLCC version 4.0.0\n\nChange-Id: I4ca1b7f6df47ce808920b5e24ad0be6b76963917\n'}]",2,704731,01e7ca19ce4161d9153dfe45520072521b0164b0,13,4,2,29405,,,0,"Fix parsing for virtual disk RAIDStatus attribute

This patch changes the parsing of virtual disks so
that if the DCIM_VirutalDiskView.RAIDStatus attribute
is not present then DCIM_VirutalDiskView.RaidStatus
will be used instead.
This is needed due to the attribute being renamed in
LCC version 4.0.0

Change-Id: I4ca1b7f6df47ce808920b5e24ad0be6b76963917
",git fetch https://review.opendev.org/openstack/python-dracclient refs/changes/31/704731/1 && git format-patch -1 --stdout FETCH_HEAD,"['dracclient/tests/test_raid.py', 'dracclient/tests/utils.py', 'dracclient/resources/raid.py', 'dracclient/tests/wsman_mocks/virtual_disk_view-enum-with-raid-status-ok.xml']",4,744f5de2d87fe4d84642f19de3c21a87ea4fc626,raid_status_fix,"<s:Envelope xmlns:s=""http://www.w3.org/2003/05/soap-envelope"" xmlns:wsa=""http://schemas.xmlsoap.org/ws/2004/08/addressing"" xmlns:wsen=""http://schemas.xmlsoap.org/ws/2004/09/enumeration"" xmlns:wsman=""http://schemas.dmtf.org/wbem/wsman/1/wsman.xsd"" xmlns:n1=""http://schemas.dell.com/wbem/wscim/1/cim-schema/2/DCIM_VirtualDiskView"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""> <s:Header> <wsa:To>http://schemas.xmlsoap.org/ws/2004/08/addressing/role/anonymous</wsa:To> <wsa:Action>http://schemas.xmlsoap.org/ws/2004/09/enumeration/EnumerateResponse</wsa:Action> <wsa:RelatesTo>uuid:b182f1ee-103a-103a-8002-fd0aa2bdb228</wsa:RelatesTo> <wsa:MessageID>uuid:b80f21ed-103f-103f-8992-a36fc6fe83b0</wsa:MessageID> </s:Header> <s:Body> <wsen:EnumerateResponse> <wsman:Items> <n1:DCIM_VirtualDiskView> <n1:BlockSizeInBytes>512</n1:BlockSizeInBytes> <n1:BusProtocol>6</n1:BusProtocol> <n1:Cachecade>0</n1:Cachecade> <n1:DeviceDescription>Virtual Disk 0 on Integrated RAID Controller 1</n1:DeviceDescription> <n1:DiskCachePolicy>1024</n1:DiskCachePolicy> <n1:FQDD>Disk.Virtual.0:RAID.Integrated.1-1</n1:FQDD> <n1:InstanceID>Disk.Virtual.0:RAID.Integrated.1-1</n1:InstanceID> <n1:LastSystemInventoryTime>20150301200527.000000+000</n1:LastSystemInventoryTime> <n1:LastUpdateTime>20150301200527.000000+000</n1:LastUpdateTime> <n1:LockStatus>0</n1:LockStatus> <n1:MediaType>1</n1:MediaType> <n1:Name>disk 0</n1:Name> <n1:ObjectStatus>0</n1:ObjectStatus> <n1:OperationName>Background Intialization</n1:OperationName> <n1:OperationPercentComplete>8</n1:OperationPercentComplete> <n1:PendingOperations>0</n1:PendingOperations> <n1:PhysicalDiskIDs>Disk.Bay.4:Enclosure.Internal.0-1:RAID.Integrated.1-1</n1:PhysicalDiskIDs> <n1:PhysicalDiskIDs>Disk.Bay.5:Enclosure.Internal.0-1:RAID.Integrated.1-1</n1:PhysicalDiskIDs> <n1:PrimaryStatus>1</n1:PrimaryStatus> <n1:RaidStatus>2</n1:RaidStatus> <n1:RAIDTypes>4</n1:RAIDTypes> <n1:ReadCachePolicy>16</n1:ReadCachePolicy> <n1:RemainingRedundancy>1</n1:RemainingRedundancy> <n1:RollupStatus>1</n1:RollupStatus> <n1:SizeInBytes>599550590976</n1:SizeInBytes> <n1:SpanDepth>1</n1:SpanDepth> <n1:SpanLength>2</n1:SpanLength> <n1:StartingLBAinBlocks>0</n1:StartingLBAinBlocks> <n1:StripeSize>128</n1:StripeSize> <n1:T10PIStatus>0</n1:T10PIStatus> <n1:VirtualDiskTargetID>0</n1:VirtualDiskTargetID> <n1:WriteCachePolicy>2</n1:WriteCachePolicy> </n1:DCIM_VirtualDiskView> </wsman:Items> <wsen:EnumerationContext/> <wsman:EndOfSequence/> </wsen:EnumerateResponse> </s:Body> </s:Envelope> ",,96,3
openstack%2Fkolla-ansible~master~I4d987e1516c979e30e82da1c49051e7786c5104a,openstack/kolla-ansible,master,I4d987e1516c979e30e82da1c49051e7786c5104a,DNM: remove ceph.conf from nova_libvirt,ABANDONED,2019-12-12 11:37:46.000000000,2020-01-31 16:38:28.000000000,,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24849}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-12-12 11:37:46.000000000', 'files': ['ansible/roles/nova-cell/templates/nova-libvirt.json.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/efb4addbbf181813510e0b81b490931d4627ff25', 'message': 'DNM: remove ceph.conf from nova_libvirt\n\nTo check some hypothesis.\n\nChange-Id: I4d987e1516c979e30e82da1c49051e7786c5104a\n'}]",0,698699,efb4addbbf181813510e0b81b490931d4627ff25,9,4,1,30491,,,0,"DNM: remove ceph.conf from nova_libvirt

To check some hypothesis.

Change-Id: I4d987e1516c979e30e82da1c49051e7786c5104a
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/99/698699/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/nova-cell/templates/nova-libvirt.json.j2'],1,efb4addbbf181813510e0b81b490931d4627ff25,dnm-ceph-conf-libvirt,," }{% endif %}{% if nova_backend == ""rbd"" %}, { ""source"": ""{{ container_config_directory }}/ceph.conf"", ""dest"": ""/etc/ceph/ceph.conf"", ""owner"": ""root"", ""perm"": ""0600""",0,6
openstack%2Fnova~master~I2aeba5a147d2e5fa053f03b7d29753897b70df21,openstack/nova,master,I2aeba5a147d2e5fa053f03b7d29753897b70df21,tests: Further simplification of test_numa_servers,ABANDONED,2018-08-27 16:08:20.000000000,2020-01-31 16:28:58.000000000,,"[{'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2018-08-27 16:08:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ef288b041b6cc966f2b92a1ab3fd3cf75b79a23c', 'message': 'tests: Further simplification of test_numa_servers\n\nThere are two inner tests functions which are nearly identical. Merge\nthe two of them, removing a lot of pointless [1] checks in the process.\n\n[1] https://review.openstack.org/#/c/583288/4/nova/tests/functional/libvirt/test_numa_servers.py@265\n\nChange-Id: I2aeba5a147d2e5fa053f03b7d29753897b70df21\n'}, {'number': 2, 'created': '2018-08-28 16:39:39.000000000', 'files': ['nova/tests/functional/libvirt/test_numa_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/83ff1625729131b38b63aa2f5d67f881cd724aaf', 'message': 'tests: Further simplification of test_numa_servers\n\nThere are two inner tests functions which are nearly identical. Merge\nthe two of them, removing a lot of pointless [1] checks in the process.\n\n[1] https://review.openstack.org/#/c/583288/4/nova/tests/functional/libvirt/test_numa_servers.py@265\n\nChange-Id: I2aeba5a147d2e5fa053f03b7d29753897b70df21\n'}]",0,596832,83ff1625729131b38b63aa2f5d67f881cd724aaf,24,11,2,15334,,,0,"tests: Further simplification of test_numa_servers

There are two inner tests functions which are nearly identical. Merge
the two of them, removing a lot of pointless [1] checks in the process.

[1] https://review.openstack.org/#/c/583288/4/nova/tests/functional/libvirt/test_numa_servers.py@265

Change-Id: I2aeba5a147d2e5fa053f03b7d29753897b70df21
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/596832/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/libvirt/test_numa_servers.py'],1,ef288b041b6cc966f2b92a1ab3fd3cf75b79a23c,sriov_numa_func_test," def _test_create_server(self, flavor_id, server_body=None, end_status='ACTIVE'): good_server.update(server_body or {}) found_server = self._wait_for_state_change(created_server, 'BUILD') return found_server class NUMAServersTest(NUMAServersTestBase): self._test_create_server(flavor_id) server = self._test_create_server(flavor_id) self._test_create_server(flavor_id, end_status='ERROR') def _test_create_server_with_networks(self, flavor_id, networks, end_status='ACTIVE'): return super(NUMAServersWithNetworksTest, self)._test_create_server( flavor_id, {'networks': networks}, end_status=end_status) self._test_create_server_with_networks(flavor_id, networks) self._test_create_server_with_networks(flavor_id, networks) self._test_create_server_with_networks(flavor_id, networks, end_status='ERROR') self._test_create_server_with_networks(flavor_id, networks)"," class NUMAServersTest(NUMAServersTestBase): def _run_build_test(self, flavor_id, end_status='ACTIVE'): self.assertTrue(created_server['id']) created_server_id = created_server['id'] # Validate that the server has been created found_server = self.api.get_server(created_server_id) self.assertEqual(created_server_id, found_server['id']) # It should also be in the all-servers list servers = self.api.get_servers() server_ids = [s['id'] for s in servers] self.assertIn(created_server_id, server_ids) found_server = self._wait_for_state_change(found_server, 'BUILD') self.addCleanup(self._delete_server, created_server_id) return created_server self._run_build_test(flavor_id) server = self._run_build_test(flavor_id) self._run_build_test(flavor_id, end_status='ERROR') def _test_create_server_with_networks(self, flavor_id, networks): self.compute = self.start_service('compute', host='test_compute0') # Create server good_server = self._build_server(flavor_id) good_server['networks'] = networks post = {'server': good_server} created_server = self.api.post_server(post) LOG.debug(""created_server: %s"", created_server) found_server = self.api.get_server(created_server['id']) return self._wait_for_state_change(found_server, 'BUILD') status = self._test_create_server_with_networks( flavor_id, networks)['status'] self.assertTrue(self.mock_filter.called) self.assertEqual('ACTIVE', status) status = self._test_create_server_with_networks( flavor_id, networks)['status'] self.assertTrue(self.mock_filter.called) self.assertEqual('ACTIVE', status) status = self._test_create_server_with_networks( flavor_id, networks)['status'] self.assertTrue(self.mock_filter.called) self.assertEqual('ERROR', status) status = self._test_create_server_with_networks( flavor_id, networks)['status'] self.assertTrue(self.mock_filter.called) self.assertEqual('ACTIVE', status) self.assertEqual('ACTIVE', server['status']) ",21,59
openstack%2Ftripleo-heat-templates~stable%2Ftrain~Icd4595be844443b6c9c6cd099e61fd08b52d12a3,openstack/tripleo-heat-templates,stable/train,Icd4595be844443b6c9c6cd099e61fd08b52d12a3,Fix Placement password hiera is not set for Neutron,ABANDONED,2020-01-31 16:01:57.000000000,2020-01-31 16:04:35.000000000,,[],"[{'number': 1, 'created': '2020-01-31 16:01:57.000000000', 'files': ['deployment/neutron/neutron-api-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b4b6945829b5772bb775aef69dd3bf934db96d19', 'message': 'Fix Placement password hiera is not set for Neutron\n\nPlacement password hiera is not set for Neutron\nwhen deployed with Novacontrol role. With Novacontrol\nrole the Placement service is not deployed\non controllers so the hiera is not set in\nservice_config_settings secion.\n\nChange-Id: Icd4595be844443b6c9c6cd099e61fd08b52d12a3\nCloses-Bug: #1861508\n'}]",0,705245,b4b6945829b5772bb775aef69dd3bf934db96d19,2,0,1,30133,,,0,"Fix Placement password hiera is not set for Neutron

Placement password hiera is not set for Neutron
when deployed with Novacontrol role. With Novacontrol
role the Placement service is not deployed
on controllers so the hiera is not set in
service_config_settings secion.

Change-Id: Icd4595be844443b6c9c6cd099e61fd08b52d12a3
Closes-Bug: #1861508
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/45/705245/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/neutron/neutron-api-container-puppet.yaml'],1,b4b6945829b5772bb775aef69dd3bf934db96d19,bug/1861508, neutron::server::placement::password: {get_param: NovaPassword}, neutron::server::placement::password: {get_param: NovaPassword},1,1
openstack%2Fnova~master~I7485c3249c75c6010765655a5d0e62a459afeea2,openstack/nova,master,I7485c3249c75c6010765655a5d0e62a459afeea2,Don't mock something globally,ABANDONED,2019-08-02 16:48:47.000000000,2020-01-31 16:03:19.000000000,,"[{'_account_id': 9008}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-08-02 16:48:47.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8292da352706390e15655f293011be00774aceae', 'message': ""Don't mock something globally\n\nThe 'test_create_domain_define_xml_fails' intermittently fails with the\nfollowing error:\n\n  '<test>this is a test</test>safe decoded' != '<test>this is a test</test>'\n\nThis seems to be happening because we're using 'stub_out' which is\nresulting in shared state between tests. Switch to the context manager\nand resolve the issue.\n\nChange-Id: I7485c3249c75c6010765655a5d0e62a459afeea2\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",0,674351,8292da352706390e15655f293011be00774aceae,12,10,1,15334,,,0,"Don't mock something globally

The 'test_create_domain_define_xml_fails' intermittently fails with the
following error:

  '<test>this is a test</test>safe decoded' != '<test>this is a test</test>'

This seems to be happening because we're using 'stub_out' which is
resulting in shared state between tests. Switch to the context manager
and resolve the issue.

Change-Id: I7485c3249c75c6010765655a5d0e62a459afeea2
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/674351/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/virt/libvirt/test_driver.py'],1,8292da352706390e15655f293011be00774aceae,trivial," with test.nested( mock.patch('oslo_utils.encodeutils.safe_decode', side_effect=fake_safe_decode), mock.patch('nova.virt.libvirt.guest.LOG.error', side_effect=fake_error)): self.create_fake_libvirt_mock(defineXML=fake_defineXML) drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) self.assertRaises(fakelibvirt.libvirtError, drvr._create_domain, fake_xml) self.assertTrue(self.log_error_called)"," self.stub_out('oslo_utils.encodeutils.safe_decode', fake_safe_decode) self.stub_out('nova.virt.libvirt.guest.LOG.error', fake_error) self.create_fake_libvirt_mock(defineXML=fake_defineXML) drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) self.assertRaises(fakelibvirt.libvirtError, drvr._create_domain, fake_xml) self.assertTrue(self.log_error_called)",10,8
openstack%2Fcharm-heat~master~I881c3569a25c0f0a84c14ee086b3f3adfdbc97f9,openstack/charm-heat,master,I881c3569a25c0f0a84c14ee086b3f3adfdbc97f9,Disable Apache port 80,MERGED,2019-11-02 10:46:51.000000000,2020-01-31 15:54:12.000000000,2020-01-31 15:54:12.000000000,"[{'_account_id': 935}, {'_account_id': 6737}, {'_account_id': 12549}, {'_account_id': 14567}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-11-02 10:46:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-heat/commit/19c07e42c6dbeca2e548ac6d6fb80603943195e2', 'message': ""Disable Apache default ports\n\nOpenstack services don't use the default ports (80 and 443), so\nchange Apache to not open them.\n\nChange-Id: I881c3569a25c0f0a84c14ee086b3f3adfdbc97f9\nCloses-bug: #1845665\n""}, {'number': 2, 'created': '2019-11-06 19:07:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-heat/commit/ef95cc04e8037e3e1cc529b3a4267aa425ad1b75', 'message': ""Disable Apache default ports\n\nOpenstack services don't use the default ports (80 and 443), so\nchange Apache to not open them.\n\nChange-Id: I881c3569a25c0f0a84c14ee086b3f3adfdbc97f9\nCloses-bug: #1845665\n""}, {'number': 3, 'created': '2019-11-27 12:52:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-heat/commit/3ff285c287159c7ac09641bcbc389051a7b9cacb', 'message': ""Disable Apache default ports\n\nOpenstack services don't use the default ports (80 and 443), so\nchange Apache to not open them.\n\nChange-Id: I881c3569a25c0f0a84c14ee086b3f3adfdbc97f9\nCloses-bug: #1845665\n""}, {'number': 4, 'created': '2019-12-20 01:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-heat/commit/984f71f318656104e5e8204c511fd1cf6b774911', 'message': ""Disable Apache default ports\n\nOpenstack services don't use the default ports (80 and 443), so\nchange Apache to not open them.\n\nChange-Id: I881c3569a25c0f0a84c14ee086b3f3adfdbc97f9\nCloses-bug: #1845665\n""}, {'number': 5, 'created': '2020-01-20 15:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-heat/commit/901ebfd364c8163a62f71be2afe627f84cb10f81', 'message': 'Disable Apache por 80\n\nThis patch changes Apache to not port 80 on SSL environments.\n\nChange-Id: I881c3569a25c0f0a84c14ee086b3f3adfdbc97f9\nCloses-bug: #1845665\n'}, {'number': 6, 'created': '2020-01-20 16:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-heat/commit/ade3712810a3eb78f60eeb15e5c28574d2bbc3b0', 'message': 'Disable Apache por 80\n\nThis patch changes Apache to not port 80 on SSL environments.\n\nChange-Id: I881c3569a25c0f0a84c14ee086b3f3adfdbc97f9\nCloses-bug: #1845665\n'}, {'number': 7, 'created': '2020-01-27 17:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-heat/commit/4abbfd90c581fdf385cf6d8fc923b508fb794112', 'message': 'Disable Apache port 80\n\nCurrently, Apache ports.conf file is not being configured by this\ncharm. This patch changes the ports.conf default file with another one\nthat does not open port 80 on SSL environments.\n\nChange-Id: I881c3569a25c0f0a84c14ee086b3f3adfdbc97f9\nCloses-bug: #1845665\n'}, {'number': 8, 'created': '2020-01-28 14:52:33.000000000', 'files': ['unit_tests/test_heat_utils.py', 'hooks/heat_utils.py', 'templates/ports.conf'], 'web_link': 'https://opendev.org/openstack/charm-heat/commit/0ef0ebb9b08ebe5692f870a6bb20528c4ac1dd0c', 'message': 'Disable Apache port 80\n\nCurrently, Apache ports.conf file is not being configured by this\ncharm. This patch changes the ports.conf default file with another one\nthat does not open port 80 on SSL environments.\n\nChange-Id: I881c3569a25c0f0a84c14ee086b3f3adfdbc97f9\nCloses-bug: #1845665\n'}]",0,692660,0ef0ebb9b08ebe5692f870a6bb20528c4ac1dd0c,52,6,8,17097,,,0,"Disable Apache port 80

Currently, Apache ports.conf file is not being configured by this
charm. This patch changes the ports.conf default file with another one
that does not open port 80 on SSL environments.

Change-Id: I881c3569a25c0f0a84c14ee086b3f3adfdbc97f9
Closes-bug: #1845665
",git fetch https://review.opendev.org/openstack/charm-heat refs/changes/60/692660/8 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_heat_utils.py', 'hooks/heat_utils.py', 'templates/ports.conf']",3,19c07e42c6dbeca2e548ac6d6fb80603943195e2,bug/1845665,,,6,0
openstack%2Fcharm-nova-cloud-controller~master~Id0b3ce106e2779ce6a44b59c0b08fb1011dfdd54,openstack/charm-nova-cloud-controller,master,Id0b3ce106e2779ce6a44b59c0b08fb1011dfdd54,Disable Apache port 80,MERGED,2020-01-20 16:04:04.000000000,2020-01-31 15:52:57.000000000,2020-01-31 15:52:57.000000000,"[{'_account_id': 6737}, {'_account_id': 12549}, {'_account_id': 14567}, {'_account_id': 17097}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-20 16:04:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/94cc11f2ebdb2a2f2626e50de0d2f925460c5ac4', 'message': 'Disable Apache por 80\n\nThis patch changes Apache to not port 80 on SSL environments.\n\nChange-Id: Id0b3ce106e2779ce6a44b59c0b08fb1011dfdd54\nCloses-bug: #1845665\n'}, {'number': 2, 'created': '2020-01-20 16:47:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/a1373050725d18ef6266f07c537e882864218f1e', 'message': 'Disable Apache por 80\n\nThis patch changes Apache to not port 80 on SSL environments.\n\nChange-Id: Id0b3ce106e2779ce6a44b59c0b08fb1011dfdd54\nCloses-bug: #1845665\n'}, {'number': 3, 'created': '2020-01-27 17:34:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/500614156439cacc9abe5094bfecb698ae7527b2', 'message': 'Disable Apache port 80\n\nCurrently, Apache ports.conf file is not being configured by this\ncharm. This patch changes the ports.conf default file with another one\nthat does not open port 80 on SSL environments..\n\nChange-Id: Id0b3ce106e2779ce6a44b59c0b08fb1011dfdd54\nCloses-bug: #1845665\n'}, {'number': 4, 'created': '2020-01-28 14:53:13.000000000', 'files': ['unit_tests/test_nova_cc_utils.py', 'templates/ports.conf', 'hooks/nova_cc_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/56c70d055a3949c7fe150ff2aed83c052fe4c232', 'message': 'Disable Apache port 80\n\nCurrently, Apache ports.conf file is not being configured by this\ncharm. This patch changes the ports.conf default file with another one\nthat does not open port 80 on SSL environments..\n\nChange-Id: Id0b3ce106e2779ce6a44b59c0b08fb1011dfdd54\nCloses-bug: #1845665\n'}]",0,703438,56c70d055a3949c7fe150ff2aed83c052fe4c232,26,6,4,17097,,,0,"Disable Apache port 80

Currently, Apache ports.conf file is not being configured by this
charm. This patch changes the ports.conf default file with another one
that does not open port 80 on SSL environments..

Change-Id: Id0b3ce106e2779ce6a44b59c0b08fb1011dfdd54
Closes-bug: #1845665
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/38/703438/4 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_nova_cc_utils.py', 'templates/ports.conf', 'hooks/nova_cc_utils.py']",3,94cc11f2ebdb2a2f2626e50de0d2f925460c5ac4,bug/1845665,"APACHE_PORTS_CONF = '/etc/apache2/ports.conf' (APACHE_PORTS_CONF, { 'contexts': [], 'services': ['apache2'], }),",,13,1
openstack%2Fcharm-cinder~master~Iaa80573dc2661089093c4c87ab100bf941f8b3b8,openstack/charm-cinder,master,Iaa80573dc2661089093c4c87ab100bf941f8b3b8,Disable Apache port 80,MERGED,2020-01-20 15:59:23.000000000,2020-01-31 15:50:01.000000000,2020-01-31 15:50:01.000000000,"[{'_account_id': 6737}, {'_account_id': 12549}, {'_account_id': 14567}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-20 15:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/e2175d8439e6760cf9d325029a619626bc9b4491', 'message': 'Disable Apache por 80\n\nThis patch changes Apache to not port 80 on SSL environments.\n\nChange-Id: Iaa80573dc2661089093c4c87ab100bf941f8b3b8\nCloses-bug: #1845665\n'}, {'number': 2, 'created': '2020-01-20 16:48:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/c5ae5440ce6bfb33077be33769eac0ff994b08c3', 'message': 'Disable Apache por 80\n\nThis patch changes Apache to not port 80 on SSL environments.\n\nChange-Id: Iaa80573dc2661089093c4c87ab100bf941f8b3b8\nCloses-bug: #1845665\n'}, {'number': 3, 'created': '2020-01-27 17:33:54.000000000', 'files': ['templates/ports.conf', 'hooks/cinder_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/962225eccae57e45af2df69541aab0b60340c8c7', 'message': 'Disable Apache port 80\n\nCurrently, Apache ports.conf file is not being configured by this\ncharm. This patch changes the ports.conf default file with another one\nthat does not open port 80 on SSL environments.\n\nChange-Id: Iaa80573dc2661089093c4c87ab100bf941f8b3b8\nCloses-bug: #1845665\n'}]",0,703435,962225eccae57e45af2df69541aab0b60340c8c7,17,5,3,17097,,,0,"Disable Apache port 80

Currently, Apache ports.conf file is not being configured by this
charm. This patch changes the ports.conf default file with another one
that does not open port 80 on SSL environments.

Change-Id: Iaa80573dc2661089093c4c87ab100bf941f8b3b8
Closes-bug: #1845665
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/35/703435/3 && git format-patch -1 --stdout FETCH_HEAD,"['templates/ports.conf', 'hooks/cinder_utils.py']",2,e2175d8439e6760cf9d325029a619626bc9b4491,bug/1845665,"APACHE_PORTS_CONF = '/etc/apache2/ports.conf' (APACHE_PORTS_CONF, { 'contexts': [], 'services': ['apache2'], }),",,8,0
openstack%2Fcharm-glance~master~I3f8eb69813058a9291540634ad262bfdaa7b8731,openstack/charm-glance,master,I3f8eb69813058a9291540634ad262bfdaa7b8731,Disable Apache port 80,MERGED,2020-01-20 15:57:40.000000000,2020-01-31 15:49:43.000000000,2020-01-31 15:49:43.000000000,"[{'_account_id': 6737}, {'_account_id': 12549}, {'_account_id': 14567}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-20 15:57:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/2d9bd6a04c5d3dd310e345d642409d9344395ffb', 'message': 'Disable Apache por 80\n\nThis patch changes Apache to not port 80 on SSL environments.\n\nChange-Id: I3f8eb69813058a9291540634ad262bfdaa7b8731\nCloses-bug: #1845665\n'}, {'number': 2, 'created': '2020-01-20 16:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/9a9d5c3081fa379a62e929bef3dca9f0c816083e', 'message': 'Disable Apache por 80\n\nThis patch changes Apache to not port 80 on SSL environments.\n\nChange-Id: I3f8eb69813058a9291540634ad262bfdaa7b8731\nCloses-bug: #1845665\n'}, {'number': 3, 'created': '2020-01-27 17:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/7d142eb7af89f26f2a85d4d968bbd0f25a2dd39c', 'message': 'Disable Apache port 80\n\nCurrently, Apache ports.conf file is not being configured by this\ncharm. This patch changes the ports.conf default file with another one\nthat does not open port 80 on SSL environments.\n\nChange-Id: I3f8eb69813058a9291540634ad262bfdaa7b8731\nCloses-bug: #1845665\n'}, {'number': 4, 'created': '2020-01-28 14:53:01.000000000', 'files': ['hooks/glance_utils.py', 'templates/ports.conf', 'unit_tests/test_glance_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/8eb305f3f1da565d909cd4beb8992322a1a36892', 'message': 'Disable Apache port 80\n\nCurrently, Apache ports.conf file is not being configured by this\ncharm. This patch changes the ports.conf default file with another one\nthat does not open port 80 on SSL environments.\n\nChange-Id: I3f8eb69813058a9291540634ad262bfdaa7b8731\nCloses-bug: #1845665\n'}]",0,703433,8eb305f3f1da565d909cd4beb8992322a1a36892,22,5,4,17097,,,0,"Disable Apache port 80

Currently, Apache ports.conf file is not being configured by this
charm. This patch changes the ports.conf default file with another one
that does not open port 80 on SSL environments.

Change-Id: I3f8eb69813058a9291540634ad262bfdaa7b8731
Closes-bug: #1845665
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/33/703433/4 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/glance_utils.py', 'templates/ports.conf', 'unit_tests/test_glance_utils.py']",3,2d9bd6a04c5d3dd310e345d642409d9344395ffb,bug/1845665," (utils.APACHE_PORTS_CONF, ['apache2']), (utils.APACHE_PORTS_CONF, ['apache2']), (utils.APACHE_PORTS_CONF, ['apache2']),",,12,1
openstack%2Fcharm-swift-proxy~master~I63f46223c64f2561f505828491a482dea79dc39a,openstack/charm-swift-proxy,master,I63f46223c64f2561f505828491a482dea79dc39a,Disable Apache port 80,MERGED,2020-01-20 16:02:52.000000000,2020-01-31 15:49:22.000000000,2020-01-31 15:49:22.000000000,"[{'_account_id': 6737}, {'_account_id': 12549}, {'_account_id': 14567}, {'_account_id': 17097}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-20 16:02:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/1b7f81331437d64089ae1d229b142e6f9539cf42', 'message': 'Disable Apache por 80\n\nThis patch changes Apache to not port 80 on SSL environments.\n\nChange-Id: I63f46223c64f2561f505828491a482dea79dc39a\nCloses-bug: #1845665\n'}, {'number': 2, 'created': '2020-01-20 16:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/99632aadb6d7ad9c006ad391af9399d7e5c48757', 'message': 'Disable Apache por 80\n\nThis patch changes Apache to not port 80 on SSL environments.\n\nChange-Id: I63f46223c64f2561f505828491a482dea79dc39a\nCloses-bug: #1845665\n'}, {'number': 3, 'created': '2020-01-27 17:34:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/34ebe3e9cb8115290c6aef12980e352bb52b1807', 'message': 'Disable Apache port 80\n\nCurrently, Apache ports.conf file is not being configured by this\ncharm. This patch changes the ports.conf default file with another one\nthat does not open port 80 on SSL environments.\n\nChange-Id: I63f46223c64f2561f505828491a482dea79dc39a\nCloses-bug: #1845665\n'}, {'number': 4, 'created': '2020-01-28 14:53:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/826e9a033131abbec55ab17a51fd50276c96ea12', 'message': 'Disable Apache port 80\n\nCurrently, Apache ports.conf file is not being configured by this\ncharm. This patch changes the ports.conf default file with another one\nthat does not open port 80 on SSL environments.\n\nChange-Id: I63f46223c64f2561f505828491a482dea79dc39a\nCloses-bug: #1845665\n'}, {'number': 5, 'created': '2020-01-29 18:23:08.000000000', 'files': ['lib/swift_utils.py', 'templates/ports.conf'], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/2d8d80e47e792c93d0158a0c82d45d5f66caba97', 'message': 'Disable Apache port 80\n\nCurrently, Apache ports.conf file is not being configured by this\ncharm. This patch changes the ports.conf default file with another one\nthat does not open port 80 on SSL environments.\n\nChange-Id: I63f46223c64f2561f505828491a482dea79dc39a\nCloses-bug: #1845665\n'}]",0,703437,2d8d80e47e792c93d0158a0c82d45d5f66caba97,30,6,5,17097,,,0,"Disable Apache port 80

Currently, Apache ports.conf file is not being configured by this
charm. This patch changes the ports.conf default file with another one
that does not open port 80 on SSL environments.

Change-Id: I63f46223c64f2561f505828491a482dea79dc39a
Closes-bug: #1845665
",git fetch https://review.opendev.org/openstack/charm-swift-proxy refs/changes/37/703437/2 && git format-patch -1 --stdout FETCH_HEAD,"['lib/swift_utils.py', 'templates/ports.conf']",2,1b7f81331437d64089ae1d229b142e6f9539cf42,bug/1845665,<IfModule !ssl_module> Listen 80 </IfModule>,,8,0
openstack%2Fcharm-neutron-api~master~I0d935de2eada861b986e2f17ead6a5674afd2969,openstack/charm-neutron-api,master,I0d935de2eada861b986e2f17ead6a5674afd2969,Disable Apache port 80,MERGED,2019-11-02 09:45:26.000000000,2020-01-31 15:48:35.000000000,2020-01-31 15:48:35.000000000,"[{'_account_id': 935}, {'_account_id': 6737}, {'_account_id': 12549}, {'_account_id': 14567}, {'_account_id': 17097}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-11-02 09:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/ed205a682e0e6d647d5059aee3cead55ff7607a0', 'message': ""Disable Apache default ports\n\nOpenstack services don't use the default ports (80 and 443), so\nchange Apache to not open them.\n\nChange-Id: I0d935de2eada861b986e2f17ead6a5674afd2969\nCloses-bug: #1845665\n""}, {'number': 2, 'created': '2019-11-06 19:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/914e6aaf54b99e176e571cfd3c6ca7f2b6aef9b5', 'message': ""Disable Apache default ports\n\nOpenstack services don't use the default ports (80 and 443), so\nchange Apache to not open them.\n\nChange-Id: I0d935de2eada861b986e2f17ead6a5674afd2969\nCloses-bug: #1845665\n""}, {'number': 3, 'created': '2019-11-27 12:52:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/83e6481e04ce6a1c1c1f6771076026defa821bbd', 'message': ""Disable Apache default ports\n\nOpenstack services don't use the default ports (80 and 443), so\nchange Apache to not open them.\n\nChange-Id: I0d935de2eada861b986e2f17ead6a5674afd2969\nCloses-bug: #1845665\n""}, {'number': 4, 'created': '2019-12-18 22:34:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/52b125c065efdacb65d5e854da4af1c6391e6235', 'message': ""Disable Apache default ports\n\nOpenstack services don't use the default ports (80 and 443), so\nchange Apache to not open them.\n\nChange-Id: I0d935de2eada861b986e2f17ead6a5674afd2969\nCloses-bug: #1845665\n""}, {'number': 5, 'created': '2019-12-20 02:00:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/210b68467792f2445e215aab080c107bf66b6427', 'message': ""Disable Apache default ports\n\nOpenstack services don't use the default ports (80 and 443), so\nchange Apache to not open them.\n\nChange-Id: I0d935de2eada861b986e2f17ead6a5674afd2969\nCloses-bug: #1845665\n""}, {'number': 6, 'created': '2020-01-20 15:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/efd8d71e74ccc7cca4e9639074188a494a1c2478', 'message': 'Disable Apache por 80\n\nThis patch changes Apache to not port 80 on SSL environments.\n\nChange-Id: I0d935de2eada861b986e2f17ead6a5674afd2969\nCloses-bug: #1845665\n'}, {'number': 7, 'created': '2020-01-20 16:48:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/dad8244d660b32cd876e668f46703ff497582f65', 'message': 'Disable Apache por 80\n\nThis patch changes Apache to not port 80 on SSL environments.\n\nChange-Id: I0d935de2eada861b986e2f17ead6a5674afd2969\nCloses-bug: #1845665\n'}, {'number': 8, 'created': '2020-01-27 17:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/abd4537d2b417d7d645396d409f5fd8f88121a83', 'message': 'Disable Apache port 80\n\nThis patch changes Apache to not open port 80 on SSL environments.\n\nChange-Id: I0d935de2eada861b986e2f17ead6a5674afd2969\nCloses-bug: #1845665\n'}, {'number': 9, 'created': '2020-01-27 17:32:52.000000000', 'files': ['hooks/neutron_api_utils.py', 'templates/ports.conf', 'unit_tests/test_neutron_api_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/b972488ad2630790a956d132546afc7102c71524', 'message': 'Disable Apache port 80\n\nCurrently, Apache ports.conf file is not being configured by this\ncharm. This patch changes the ports.conf default file with another one\nthat does not open port 80 on SSL environments.\n\nChange-Id: I0d935de2eada861b986e2f17ead6a5674afd2969\nCloses-bug: #1845665\n'}]",1,692656,b972488ad2630790a956d132546afc7102c71524,50,8,9,17097,,,0,"Disable Apache port 80

Currently, Apache ports.conf file is not being configured by this
charm. This patch changes the ports.conf default file with another one
that does not open port 80 on SSL environments.

Change-Id: I0d935de2eada861b986e2f17ead6a5674afd2969
Closes-bug: #1845665
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/56/692656/3 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/neutron_api_utils.py', 'templates/ports.conf', 'unit_tests/test_neutron_api_utils.py']",3,ed205a682e0e6d647d5059aee3cead55ff7607a0,bug/1845665," (nutils.APACHE_PORTS_CONF, ['apache2']), (nutils.APACHE_PORTS_CONF, ['apache2']), '/etc/apache2/ports.conf',",,8,0
openstack%2Fcharm-keystone~master~I35ba6bb31af6d795d02d90d0d127ac5c6c129d0f,openstack/charm-keystone,master,I35ba6bb31af6d795d02d90d0d127ac5c6c129d0f,Disable Apache port 80,MERGED,2020-01-20 16:01:34.000000000,2020-01-31 15:48:16.000000000,2020-01-31 15:48:16.000000000,"[{'_account_id': 6737}, {'_account_id': 12549}, {'_account_id': 14567}, {'_account_id': 17097}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-20 16:01:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/8b228d090bf3c91f76b299600dd8e2a384aff268', 'message': 'Disable Apache por 80\n\nThis patch changes Apache to not port 80 on SSL environments.\n\nChange-Id: I35ba6bb31af6d795d02d90d0d127ac5c6c129d0f\nCloses-bug: #1845665\n'}, {'number': 2, 'created': '2020-01-20 16:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/01d03ec3e98c8088c1e49a9034b35e4d0116fb14', 'message': 'Disable Apache por 80\n\nThis patch changes Apache to not port 80 on SSL environments.\n\nChange-Id: I35ba6bb31af6d795d02d90d0d127ac5c6c129d0f\nCloses-bug: #1845665\n'}, {'number': 3, 'created': '2020-01-27 17:34:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/3291bbb01d30209773353db8d9ec3a0c570158a9', 'message': 'Disable Apache port 80\n\nCurrently, Apache ports.conf file is not being configured by this\ncharm. This patch changes the ports.conf default file with another one\nthat does not open port 80 on SSL environments.\n\nChange-Id: I35ba6bb31af6d795d02d90d0d127ac5c6c129d0f\nCloses-bug: #1845665\n'}, {'number': 4, 'created': '2020-01-28 14:53:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/2337c0adac9f1acc43e52553c84e4792b25ae964', 'message': 'Disable Apache port 80\n\nCurrently, Apache ports.conf file is not being configured by this\ncharm. This patch changes the ports.conf default file with another one\nthat does not open port 80 on SSL environments.\n\nChange-Id: I35ba6bb31af6d795d02d90d0d127ac5c6c129d0f\nCloses-bug: #1845665\n'}, {'number': 5, 'created': '2020-01-29 18:22:27.000000000', 'files': ['hooks/keystone_utils.py', 'templates/ports.conf'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/92e75b5aad36a557f769dc2106e49af25ef98cc8', 'message': 'Disable Apache port 80\n\nCurrently, Apache ports.conf file is not being configured by this\ncharm. This patch changes the ports.conf default file with another one\nthat does not open port 80 on SSL environments.\n\nChange-Id: I35ba6bb31af6d795d02d90d0d127ac5c6c129d0f\nCloses-bug: #1845665\n'}]",0,703436,92e75b5aad36a557f769dc2106e49af25ef98cc8,31,6,5,17097,,,0,"Disable Apache port 80

Currently, Apache ports.conf file is not being configured by this
charm. This patch changes the ports.conf default file with another one
that does not open port 80 on SSL environments.

Change-Id: I35ba6bb31af6d795d02d90d0d127ac5c6c129d0f
Closes-bug: #1845665
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/36/703436/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/keystone_utils.py', 'templates/ports.conf']",2,8b228d090bf3c91f76b299600dd8e2a384aff268,bug/1845665,<IfModule !ssl_module> Listen 80 </IfModule>,,8,0
openstack%2Fnova~stable%2Fstein~I8975e524cd5a9c7dfb065bb2dc8ceb03f1b89e7b,openstack/nova,stable/stein,I8975e524cd5a9c7dfb065bb2dc8ceb03f1b89e7b,FUP for in-place numa rebuild,MERGED,2020-01-16 19:59:44.000000000,2020-01-31 15:46:44.000000000,2020-01-31 15:43:27.000000000,"[{'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-01-16 19:59:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d6018b880158fbaf34c17c6044583d1f2ca2aa3', 'message': 'FUP for in-place numa rebuild\n\nThis patch addresses a number of typos and minor\nissues raised during review of [1][2]. A summary\nof the changes are corrections to typos in comments,\na correction to the exception message, an update to\nthe release note and the addition of debug logging.\n\n[1] I0322d872bdff68936033a6f5a54e8296a6fb3434\n[2] I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132\n\nRelated-Bug: #1804502\nRelated-Bug: #1763766\n\nConflicts:\n    nova/tests/functional/libvirt/test_numa_servers.py\nNOTE(sean-k-mooney): conflict was due to the use of\nNUMAHostInfo instead of HostInfo.\n\nChange-Id: I8975e524cd5a9c7dfb065bb2dc8ceb03f1b89e7b\n(cherry picked from commit f6060ab6b54261ff50b8068732f6e509619d713e)\n(cherry picked from commit 48bb9a9663374936221144bb6a24688128a51146)\n'}, {'number': 2, 'created': '2020-01-20 15:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/de3361ac4f89a44546284aec70e395bc33db9dd1', 'message': 'FUP for in-place numa rebuild\n\nThis patch addresses a number of typos and minor\nissues raised during review of [1][2]. A summary\nof the changes are corrections to typos in comments,\na correction to the exception message, an update to\nthe release note and the addition of debug logging.\n\n[1] I0322d872bdff68936033a6f5a54e8296a6fb3434\n[2] I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132\n\nRelated-Bug: #1804502\nRelated-Bug: #1763766\n\nConflicts:\n    nova/tests/functional/libvirt/test_numa_servers.py\nNOTE(sean-k-mooney): conflict was due to the use of\nNUMAHostInfo instead of HostInfo.\n\nChange-Id: I8975e524cd5a9c7dfb065bb2dc8ceb03f1b89e7b\n(cherry picked from commit f6060ab6b54261ff50b8068732f6e509619d713e)\n(cherry picked from commit 48bb9a9663374936221144bb6a24688128a51146)\n'}, {'number': 3, 'created': '2020-01-22 15:06:25.000000000', 'files': ['nova/exception.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/scheduler/filters/numa_topology_filter.py', 'releasenotes/notes/numa-rebuild-b75f9a1966f576ea.yaml', 'nova/tests/functional/libvirt/test_numa_servers.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8346c527b379395851a9de063b4978b489076bf6', 'message': 'FUP for in-place numa rebuild\n\nThis patch addresses a number of typos and minor\nissues raised during review of [1][2]. A summary\nof the changes are corrections to typos in comments,\na correction to the exception message, an update to\nthe release note and the addition of debug logging.\n\n[1] I0322d872bdff68936033a6f5a54e8296a6fb3434\n[2] I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132\n\nRelated-Bug: #1804502\nRelated-Bug: #1763766\n\nConflicts:\n    nova/tests/functional/libvirt/test_numa_servers.py\nNOTE(sean-k-mooney): conflict was due to the use of\nNUMAHostInfo instead of HostInfo.\n\nChange-Id: I8975e524cd5a9c7dfb065bb2dc8ceb03f1b89e7b\n(cherry picked from commit f6060ab6b54261ff50b8068732f6e509619d713e)\n(cherry picked from commit 48bb9a9663374936221144bb6a24688128a51146)\n'}]",5,702974,8346c527b379395851a9de063b4978b489076bf6,44,8,3,11604,,,0,"FUP for in-place numa rebuild

This patch addresses a number of typos and minor
issues raised during review of [1][2]. A summary
of the changes are corrections to typos in comments,
a correction to the exception message, an update to
the release note and the addition of debug logging.

[1] I0322d872bdff68936033a6f5a54e8296a6fb3434
[2] I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132

Related-Bug: #1804502
Related-Bug: #1763766

Conflicts:
    nova/tests/functional/libvirt/test_numa_servers.py
NOTE(sean-k-mooney): conflict was due to the use of
NUMAHostInfo instead of HostInfo.

Change-Id: I8975e524cd5a9c7dfb065bb2dc8ceb03f1b89e7b
(cherry picked from commit f6060ab6b54261ff50b8068732f6e509619d713e)
(cherry picked from commit 48bb9a9663374936221144bb6a24688128a51146)
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/702974/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/scheduler/filters/numa_topology_filter.py', 'releasenotes/notes/numa-rebuild-b75f9a1966f576ea.yaml', 'nova/tests/functional/libvirt/test_numa_servers.py', 'nova/compute/api.py']",6,1d6018b880158fbaf34c17c6044583d1f2ca2aa3,bug/1763766," return # if only one of the constraints are non-None (or 'set') then the action = ""removing"" if old_constraints else ""introducing"" LOG.debug(""NUMA rebuild validation failed. The requested image "" ""would alter the NUMA constraints by %s a NUMA "" ""topology."", action, instance=instance) # otherwise since both the old a new constraints are non none compare LOG.debug(""NUMA rebuild validation failed. The requested image "" ""conflicts with the existing NUMA constraints."", instance=instance)", :returns: True or raises on failure. # return true for easy unit testing return True # if only one of the constrains are non-None (or 'set') then the # otherwise since both the old a new constrains are non none compare # return true for easy unit testing return True ,41,36
openstack%2Fneutron~master~Ibac91d24da2b82cdce72165d1295fa5d4475ffd3,openstack/neutron,master,Ibac91d24da2b82cdce72165d1295fa5d4475ffd3,Add description field to portforwarding NAT rules,MERGED,2019-07-16 00:55:16.000000000,2020-01-31 15:45:53.000000000,2020-01-31 15:43:23.000000000,"[{'_account_id': 4694}, {'_account_id': 8313}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10068}, {'_account_id': 11975}, {'_account_id': 15554}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 25564}, {'_account_id': 26622}, {'_account_id': 27654}, {'_account_id': 28356}, {'_account_id': 30695}]","[{'number': 1, 'created': '2019-07-16 00:55:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/20d03f245fc14adb82bca527142429f62971c9ae', 'message': 'Add description field to portforwarding NAT rules\n\nProblem Description\n===================\n\nAs users create and update theirs floating ip rules, the reason\nbehind those rules might get lost throughout time. Moreover, in\nan environment with many people writing rules, it is important\nto track down the reason behind each one of the rules\ncreated/added in a floating IP port forwarding configuration.\nThe addition of a description field would allow operators to\ndetermine the reason why a rule was created and help the users\nto know if the existence of a rule is still reasonable.\n\nProposed Change\n===============\n\nTo address the described scenario, we propose to create a new\ndescription field in the Neutrons Floating IP port forwarding\nrules API JSON. This new field will be a nullable String\ncontaining the description/reason why this new port forwarding\nrule is being created.\n\nExample of a modified JSON:\n\n```Json\n{\n   ""port_forwarding"":{\n      ""protocol"":""tcp"",\n      ""internal_ip_address"":""172.16.0.7"",\n      ""internal_port"":2230,\n      ""internal_port_id"":""b67a7746-dc69-45b4-9b84-bb229fe198a0"",\n      ""external_port"":2230,\n      ""description"":""Some description""\n   }\n}\n```\n\nI create a column description in the `portforwardings` table on\nNeutron schema to persist the new field. Also, I used the\n`constants.LONG_DESCRIPTION_FIELD_SIZE` to limit the size of the\nnew field.\n\nChange-Id: Ibac91d24da2b82cdce72165d1295fa5d4475ffd3\nSigned-off-by: Pedro Martins <phpm13@gmail.com>\n'}, {'number': 2, 'created': '2019-07-17 01:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0c0b1a9e3eccc4229a68773cb0ceedf4c6ab481a', 'message': 'Add description field to portforwarding NAT rules\n\nProblem Description\n===================\n\nAs users create and update theirs floating ip rules, the reason\nbehind those rules might get lost throughout time. Moreover, in\nan environment with many people writing rules, it is important\nto track down the reason behind each one of the rules\ncreated/added in a floating IP port forwarding configuration.\nThe addition of a description field would allow operators to\ndetermine the reason why a rule was created and help the users\nto know if the existence of a rule is still reasonable.\n\nProposed Change\n===============\n\nTo address the described scenario, we propose to create a new\ndescription field in the Neutrons Floating IP port forwarding\nrules API JSON. This new field will be a nullable String\ncontaining the description/reason why this new port forwarding\nrule is being created.\n\nExample of a modified JSON:\n\n```Json\n{\n   ""port_forwarding"":{\n      ""protocol"":""tcp"",\n      ""internal_ip_address"":""172.16.0.7"",\n      ""internal_port"":2230,\n      ""internal_port_id"":""b67a7746-dc69-45b4-9b84-bb229fe198a0"",\n      ""external_port"":2230,\n      ""description"":""Some description""\n   }\n}\n```\n\nI create a column description in the `portforwardings` table on\nNeutron schema to persist the new field. Also, I used the\n`constants.LONG_DESCRIPTION_FIELD_SIZE` to limit the size of the\nnew field.\n\nChange-Id: Ibac91d24da2b82cdce72165d1295fa5d4475ffd3\nSigned-off-by: Pedro Martins <phpm13@gmail.com>\n'}, {'number': 3, 'created': '2019-07-18 10:06:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/accb4111bbe81ddba86103b58e63b25b09ba9db9', 'message': 'Add description field to portforwarding NAT rules\n\nProblem Description\n===================\n\nAs users create and update theirs floating ip rules, the reason\nbehind those rules might get lost throughout time. Moreover, in\nan environment with many people writing rules, it is important\nto track down the reason behind each one of the rules\ncreated/added in a floating IP port forwarding configuration.\nThe addition of a description field would allow operators to\ndetermine the reason why a rule was created and help the users\nto know if the existence of a rule is still reasonable.\n\nProposed Change\n===============\n\nTo address the described scenario, we propose to create a new\ndescription field in the Neutrons Floating IP port forwarding\nrules API JSON. This new field will be a nullable String\ncontaining the description/reason why this new port forwarding\nrule is being created.\n\nExample of a modified JSON:\n\n```Json\n{\n   ""port_forwarding"":{\n      ""protocol"":""tcp"",\n      ""internal_ip_address"":""172.16.0.7"",\n      ""internal_port"":2230,\n      ""internal_port_id"":""b67a7746-dc69-45b4-9b84-bb229fe198a0"",\n      ""external_port"":2230,\n      ""description"":""Some description""\n   }\n}\n```\n\nI create a column description in the `portforwardings` table on\nNeutron schema to persist the new field. Also, I used the\n`constants.LONG_DESCRIPTION_FIELD_SIZE` to limit the size of the\nnew field.\n\nChange-Id: Ibac91d24da2b82cdce72165d1295fa5d4475ffd3\nSigned-off-by: Pedro Martins <phpm13@gmail.com>\n'}, {'number': 4, 'created': '2019-10-31 13:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/41566b8abf87581d96bb3f9c45274e4e8f23e073', 'message': 'Add description field to portforwarding NAT rules\n\nProblem Description\n===================\n\nAs users create and update theirs floating ip rules, the reason\nbehind those rules might get lost throughout time. Moreover, in\nan environment with many people writing rules, it is important\nto track down the reason behind each one of the rules\ncreated/added in a floating IP port forwarding configuration.\nThe addition of a description field would allow operators to\ndetermine the reason why a rule was created and help the users\nto know if the existence of a rule is still reasonable.\n\nProposed Change\n===============\n\nTo address the described scenario, we propose to create a new\ndescription field in the Neutrons Floating IP port forwarding\nrules API JSON. This new field will be a nullable String\ncontaining the description/reason why this new port forwarding\nrule is being created.\n\nExample of a modified JSON:\n\n```Json\n{\n   ""port_forwarding"":{\n      ""protocol"":""tcp"",\n      ""internal_ip_address"":""172.16.0.7"",\n      ""internal_port"":2230,\n      ""internal_port_id"":""b67a7746-dc69-45b4-9b84-bb229fe198a0"",\n      ""external_port"":2230,\n      ""description"":""Some description""\n   }\n}\n```\n\nI create a column description in the `portforwardings` table on\nNeutron schema to persist the new field. Also, I used the\n`constants.LONG_DESCRIPTION_FIELD_SIZE` to limit the size of the\nnew field.\n\nImplements: blueprint portforwarding-description\nChange-Id: Ibac91d24da2b82cdce72165d1295fa5d4475ffd3\nSigned-off-by: Pedro Martins <phpm13@gmail.com>\n'}, {'number': 5, 'created': '2019-10-31 16:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e9b8970033a6cf65d3a2865a0ea68c646e4d9ea0', 'message': 'Add description field to portforwarding NAT rules\n\nProblem Description\n===================\n\nAs users create and update theirs floating ip rules, the reason\nbehind those rules might get lost throughout time. Moreover, in\nan environment with many people writing rules, it is important\nto track down the reason behind each one of the rules\ncreated/added in a floating IP port forwarding configuration.\nThe addition of a description field would allow operators to\ndetermine the reason why a rule was created and help the users\nto know if the existence of a rule is still reasonable.\n\nProposed Change\n===============\n\nTo address the described scenario, we propose to create a new\ndescription field in the Neutrons Floating IP port forwarding\nrules API JSON. This new field will be a nullable String\ncontaining the description/reason why this new port forwarding\nrule is being created.\n\nExample of a modified JSON:\n\n```Json\n{\n   ""port_forwarding"":{\n      ""protocol"":""tcp"",\n      ""internal_ip_address"":""172.16.0.7"",\n      ""internal_port"":2230,\n      ""internal_port_id"":""b67a7746-dc69-45b4-9b84-bb229fe198a0"",\n      ""external_port"":2230,\n      ""description"":""Some description""\n   }\n}\n```\n\nI create a column description in the `portforwardings` table on\nNeutron schema to persist the new field. Also, I used the\n`constants.LONG_DESCRIPTION_FIELD_SIZE` to limit the size of the\nnew field.\n\nImplements: blueprint portforwarding-description\nCloses-Bug: #1850818\nChange-Id: Ibac91d24da2b82cdce72165d1295fa5d4475ffd3\nSigned-off-by: Pedro Martins <phpm13@gmail.com>\n'}, {'number': 6, 'created': '2019-11-01 17:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/73c42e75094dd974ea45f1e3a2bb7b0a47abb6db', 'message': 'Add description field to portforwarding NAT rules\n\nProblem Description\n===================\n\nAs users create and update theirs floating ip rules, the reason\nbehind those rules might get lost throughout time. Moreover, in\nan environment with many people writing rules, it is important\nto track down the reason behind each one of the rules\ncreated/added in a floating IP port forwarding configuration.\nThe addition of a description field would allow operators to\ndetermine the reason why a rule was created and help the users\nto know if the existence of a rule is still reasonable.\n\nProposed Change\n===============\n\nTo address the described scenario, we propose to create a new\ndescription field in the Neutrons Floating IP port forwarding\nrules API JSON. This new field will be a nullable String\ncontaining the description/reason why this new port forwarding\nrule is being created.\n\nExample of a modified JSON:\n\n```Json\n{\n   ""port_forwarding"":{\n      ""protocol"":""tcp"",\n      ""internal_ip_address"":""172.16.0.7"",\n      ""internal_port"":2230,\n      ""internal_port_id"":""b67a7746-dc69-45b4-9b84-bb229fe198a0"",\n      ""external_port"":2230,\n      ""description"":""Some description""\n   }\n}\n```\n\nI create a column description in the `portforwardings` table on\nNeutron schema to persist the new field. Also, I used the\n`constants.LONG_DESCRIPTION_FIELD_SIZE` to limit the size of the\nnew field.\n\nDepends-On: https://review.opendev.org/#/c/692580/\nImplements: blueprint portforwarding-description\nCloses-Bug: #1850818\nChange-Id: Ibac91d24da2b82cdce72165d1295fa5d4475ffd3\nSigned-off-by: Pedro Martins <phpm13@gmail.com>\n'}, {'number': 7, 'created': '2019-12-05 18:36:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bfd3eae57394fb9640adb59108413e975a3260ce', 'message': 'Add description field to portforwarding NAT rules\n\nProblem Description\n===================\n\nAs users create and update theirs floating ip rules, the reason\nbehind those rules might get lost throughout time. Moreover, in\nan environment with many people writing rules, it is important\nto track down the reason behind each one of the rules\ncreated/added in a floating IP port forwarding configuration.\nThe addition of a description field would allow operators to\ndetermine the reason why a rule was created and help the users\nto know if the existence of a rule is still reasonable.\n\nProposed Change\n===============\n\nTo address the described scenario, we propose to create a new\ndescription field in the Neutrons Floating IP port forwarding\nrules API JSON. This new field will be a nullable String\ncontaining the description/reason why this new port forwarding\nrule is being created.\n\nExample of a modified JSON:\n\n```Json\n{\n   ""port_forwarding"":{\n      ""protocol"":""tcp"",\n      ""internal_ip_address"":""172.16.0.7"",\n      ""internal_port"":2230,\n      ""internal_port_id"":""b67a7746-dc69-45b4-9b84-bb229fe198a0"",\n      ""external_port"":2230,\n      ""description"":""Some description""\n   }\n}\n```\n\nI create a column description in the `portforwardings` table on\nNeutron schema to persist the new field. Also, I used the\n`constants.LONG_DESCRIPTION_FIELD_SIZE` to limit the size of the\nnew field.\n\nDepends-On: https://review.opendev.org/#/c/692580/\nImplements: blueprint portforwarding-description\nCloses-Bug: #1850818\nChange-Id: Ibac91d24da2b82cdce72165d1295fa5d4475ffd3\nSigned-off-by: Pedro Martins <phpm13@gmail.com>\n'}, {'number': 8, 'created': '2019-12-10 20:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e0e3135c68aa320f9ecd41ad48cdbddaa8f1efc7', 'message': 'Add description field to portforwarding NAT rules\n\nAdd the `description` field to `PortForwardings`\nusing the standard attributes like in the\n`FloatingIPs`.\n\nDepends-On: https://review.opendev.org/#/c/692580/\nImplements: blueprint portforwarding-description\nCloses-Bug: #1850818\nChange-Id: Ibac91d24da2b82cdce72165d1295fa5d4475ffd3\nSigned-off-by: Pedro Martins <phpm13@gmail.com>\n'}, {'number': 9, 'created': '2019-12-11 18:42:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb087ae2946e7e7e4697aceaabed474ba1157013', 'message': 'Add description field to portforwarding NAT rules\n\nAdd the `description` field to `PortForwardings`\nusing the standard attributes like in the\n`FloatingIPs`.\n\nDepends-On: https://review.opendev.org/#/c/692580/\nImplements: blueprint portforwarding-description\nCloses-Bug: #1850818\nChange-Id: Ibac91d24da2b82cdce72165d1295fa5d4475ffd3\nSigned-off-by: Pedro Martins <phpm13@gmail.com>\n'}, {'number': 10, 'created': '2019-12-12 13:55:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2c6db96590c0751f01c0aece486e2a207d820250', 'message': 'Add description field to portforwarding NAT rules\n\nAdd the `description` field to `PortForwardings`\nusing the standard attributes like in the\n`FloatingIPs`.\n\nDepends-On: https://review.opendev.org/#/c/692580/\nImplements: blueprint portforwarding-description\nCloses-Bug: #1850818\nChange-Id: Ibac91d24da2b82cdce72165d1295fa5d4475ffd3\nSigned-off-by: Pedro Martins <phpm13@gmail.com>\n'}, {'number': 11, 'created': '2019-12-13 12:48:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7ae8c7fc064bc3070ec47e3b2f48b6726fb00a91', 'message': 'Add description field to portforwarding NAT rules\n\nAdd the `description` field to `PortForwardings`\nusing the standard attributes like in the\n`FloatingIPs`.\n\nDepends-On: https://review.opendev.org/#/c/692580/\nImplements: blueprint portforwarding-description\nCloses-Bug: #1850818\nChange-Id: Ibac91d24da2b82cdce72165d1295fa5d4475ffd3\nSigned-off-by: Pedro Martins <phpm13@gmail.com>\n'}, {'number': 12, 'created': '2019-12-13 12:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9db3f1da066099df29bb7fa9d7e25bcd5d6b2c88', 'message': 'Add description field to portforwarding NAT rules\n\nAdd the `description` field to `PortForwardings`\nusing the standard attributes like in the\n`FloatingIPs`.\n\nDepends-On: https://review.opendev.org/#/c/692580/\nDepends-On: https://review.opendev.org/#/c/698662/\nImplements: blueprint portforwarding-description\nCloses-Bug: #1850818\nChange-Id: Ibac91d24da2b82cdce72165d1295fa5d4475ffd3\nSigned-off-by: Pedro Martins <phpm13@gmail.com>\n'}, {'number': 13, 'created': '2019-12-16 11:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b05f0f5354c2fa44d35082f23fbf7ae1e1ed026a', 'message': 'Add description field to portforwarding NAT rules\n\nAdd the `description` field to `PortForwardings`\nusing the standard attributes like in the\n`FloatingIPs`.\n\nDepends-On: https://review.opendev.org/#/c/692580/\nDepends-On: https://review.opendev.org/#/c/698662/\nImplements: blueprint portforwarding-description\nCloses-Bug: #1850818\nChange-Id: Ibac91d24da2b82cdce72165d1295fa5d4475ffd3\nSigned-off-by: Pedro Martins <phpm13@gmail.com>\n'}, {'number': 14, 'created': '2019-12-20 17:21:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d43ecb59dd0eba81fba47edba4349f858a312bb1', 'message': 'Add description field to portforwarding NAT rules\n\nAdd the `description` field to `PortForwardings`\nusing the standard attributes like in the\n`FloatingIPs`.\n\nDepends-On: https://review.opendev.org/#/c/692580/\nDepends-On: https://review.opendev.org/#/c/698662/\nImplements: blueprint portforwarding-description\nCloses-Bug: #1850818\nChange-Id: Ibac91d24da2b82cdce72165d1295fa5d4475ffd3\nSigned-off-by: Pedro Martins <phpm13@gmail.com>\n'}, {'number': 15, 'created': '2020-01-22 14:20:59.000000000', 'files': ['neutron/db/models/port_forwarding.py', 'neutron/db/migration/alembic_migrations/versions/EXPAND_HEAD', 'neutron/db/migration/alembic_migrations/versions/ussuri/expand/Ibac91d24da2_port_forwarding_description.py', 'releasenotes/notes/add-description-field-in-port-forwarding-5db3b3f407c7eef4.yaml', 'neutron/tests/functional/services/portforwarding/test_port_forwarding.py', 'neutron/objects/port_forwarding.py', 'neutron/tests/unit/objects/test_objects.py', 'neutron/tests/unit/agent/l3/extensions/test_port_forwarding.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/06e43dd95d39af5c77f60bf7c89fee762c1afa13', 'message': 'Add description field to portforwarding NAT rules\n\nAdd the `description` field to `PortForwardings`\nusing the standard attributes like in the\n`FloatingIPs`.\n\nDepends-On: https://review.opendev.org/#/c/692580/\nDepends-On: https://review.opendev.org/#/c/698662/\nImplements: blueprint portforwarding-description\nCloses-Bug: #1850818\nChange-Id: Ibac91d24da2b82cdce72165d1295fa5d4475ffd3\nSigned-off-by: Pedro Martins <phpm13@gmail.com>\n'}]",43,670930,06e43dd95d39af5c77f60bf7c89fee762c1afa13,110,16,15,30695,,,0,"Add description field to portforwarding NAT rules

Add the `description` field to `PortForwardings`
using the standard attributes like in the
`FloatingIPs`.

Depends-On: https://review.opendev.org/#/c/692580/
Depends-On: https://review.opendev.org/#/c/698662/
Implements: blueprint portforwarding-description
Closes-Bug: #1850818
Change-Id: Ibac91d24da2b82cdce72165d1295fa5d4475ffd3
Signed-off-by: Pedro Martins <phpm13@gmail.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/30/670930/12 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/alembic_migrations/versions/train/expand/Ibac91d24da2_port_forwarding_description.py', 'neutron/db/models/port_forwarding.py', 'neutron/extensions/floating_ip_port_forwarding_extended_api.py', 'neutron/extensions/floating_ip_port_forwarding.py', 'neutron/objects/port_forwarding.py', 'neutron/tests/unit/agent/l3/extensions/test_port_forwarding.py', 'neutron/tests/unit/objects/test_objects.py']",7,20d03f245fc14adb82bca527142429f62971c9ae,bug/1850818," 'PortForwarding': '1.1-3f5441ffe592701ee76aa1903e383b26',"," 'PortForwarding': '1.1-db61273978c497239be5389a8aeb1c61',",85,8
openstack%2Fnova~stable%2Fstein~I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132,openstack/nova,stable/stein,I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132,Disable NUMATopologyFilter on rebuild,MERGED,2020-01-16 19:59:44.000000000,2020-01-31 15:18:55.000000000,2020-01-31 15:16:11.000000000,"[{'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-01-16 19:59:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6001bff0ff18a9712b538114f9ea57d086b4961b', 'message': 'Disable NUMATopologyFilter on rebuild\n\nThis change leverages the new NUMA constraint checking added in\nin I0322d872bdff68936033a6f5a54e8296a6fb3434 to allow the\nNUMATopologyFilter to be skipped on rebuild.\n\nAs the new behavior of rebuild enfroces that no changes\nto the numa constraints are allowed on rebuild we no longer\nneed to execute the NUMATopologyFilter. Previously\nthe NUMATopologyFilter would process the rebuild request\nas if it was a request to spawn a new instnace as the\nnuma_fit_instance_to_host function is not rebuild aware.\n\nAs such prior to this change a rebuild would only succeed\nif a host had enough additional capacity for a second instance\non the same host meeting the requirement of the new image and\nexisting flavor. This behavior was incorrect on two counts as\na rebuild uses a noop claim. First the resouce usage cannot\nchange so it was incorrect to require the addtional capacity\nto rebuild an instance. Secondly it was incorrect not to assert\nthe resouce usage remained the same.\n\nI0322d872bdff68936033a6f5a54e8296a6fb3434 adressed guarding the\nrebuild against altering the resouce usage and this change\nallows in place rebuild.\n\nThis change found a latent bug that will be adressed in a follow\nup change and updated the functional tests to note the incorrect\nbehavior.\n\nChange-Id: I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132\nCloses-Bug: #1804502\nImplements: blueprint inplace-rebuild-of-numa-instances\n(cherry picked from commit 3f9411071d4c1a04ab0b68fd635597bf6959c0ca)\n(cherry picked from commit 94c0362918169a1fa06aa6cf5a483e9285d7b91f)\n'}, {'number': 2, 'created': '2020-01-20 15:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a82bd3f183bff8fe19dfcc01e3b7209efba2afb5', 'message': 'Disable NUMATopologyFilter on rebuild\n\nThis change leverages the new NUMA constraint checking added in\nin I0322d872bdff68936033a6f5a54e8296a6fb3434 to allow the\nNUMATopologyFilter to be skipped on rebuild.\n\nAs the new behavior of rebuild enfroces that no changes\nto the numa constraints are allowed on rebuild we no longer\nneed to execute the NUMATopologyFilter. Previously\nthe NUMATopologyFilter would process the rebuild request\nas if it was a request to spawn a new instnace as the\nnuma_fit_instance_to_host function is not rebuild aware.\n\nAs such prior to this change a rebuild would only succeed\nif a host had enough additional capacity for a second instance\non the same host meeting the requirement of the new image and\nexisting flavor. This behavior was incorrect on two counts as\na rebuild uses a noop claim. First the resouce usage cannot\nchange so it was incorrect to require the addtional capacity\nto rebuild an instance. Secondly it was incorrect not to assert\nthe resouce usage remained the same.\n\nI0322d872bdff68936033a6f5a54e8296a6fb3434 adressed guarding the\nrebuild against altering the resouce usage and this change\nallows in place rebuild.\n\nThis change found a latent bug that will be adressed in a follow\nup change and updated the functional tests to note the incorrect\nbehavior.\n\nChange-Id: I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132\nCloses-Bug: #1804502\nImplements: blueprint inplace-rebuild-of-numa-instances\n(cherry picked from commit 3f9411071d4c1a04ab0b68fd635597bf6959c0ca)\n(cherry picked from commit 94c0362918169a1fa06aa6cf5a483e9285d7b91f)\n'}, {'number': 3, 'created': '2020-01-22 15:06:25.000000000', 'files': ['nova/scheduler/filters/numa_topology_filter.py', 'releasenotes/notes/numa-rebuild-b75f9a1966f576ea.yaml', 'nova/tests/functional/libvirt/test_numa_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4a691c33d13611714135b9390cb53de726fc901d', 'message': 'Disable NUMATopologyFilter on rebuild\n\nThis change leverages the new NUMA constraint checking added in\nin I0322d872bdff68936033a6f5a54e8296a6fb3434 to allow the\nNUMATopologyFilter to be skipped on rebuild.\n\nAs the new behavior of rebuild enfroces that no changes\nto the numa constraints are allowed on rebuild we no longer\nneed to execute the NUMATopologyFilter. Previously\nthe NUMATopologyFilter would process the rebuild request\nas if it was a request to spawn a new instnace as the\nnuma_fit_instance_to_host function is not rebuild aware.\n\nAs such prior to this change a rebuild would only succeed\nif a host had enough additional capacity for a second instance\non the same host meeting the requirement of the new image and\nexisting flavor. This behavior was incorrect on two counts as\na rebuild uses a noop claim. First the resouce usage cannot\nchange so it was incorrect to require the addtional capacity\nto rebuild an instance. Secondly it was incorrect not to assert\nthe resouce usage remained the same.\n\nI0322d872bdff68936033a6f5a54e8296a6fb3434 adressed guarding the\nrebuild against altering the resouce usage and this change\nallows in place rebuild.\n\nThis change found a latent bug that will be adressed in a follow\nup change and updated the functional tests to note the incorrect\nbehavior.\n\nChange-Id: I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132\nCloses-Bug: #1804502\nImplements: blueprint inplace-rebuild-of-numa-instances\n(cherry picked from commit 3f9411071d4c1a04ab0b68fd635597bf6959c0ca)\n(cherry picked from commit 94c0362918169a1fa06aa6cf5a483e9285d7b91f)\n'}]",0,702973,4a691c33d13611714135b9390cb53de726fc901d,37,8,3,11604,,,0,"Disable NUMATopologyFilter on rebuild

This change leverages the new NUMA constraint checking added in
in I0322d872bdff68936033a6f5a54e8296a6fb3434 to allow the
NUMATopologyFilter to be skipped on rebuild.

As the new behavior of rebuild enfroces that no changes
to the numa constraints are allowed on rebuild we no longer
need to execute the NUMATopologyFilter. Previously
the NUMATopologyFilter would process the rebuild request
as if it was a request to spawn a new instnace as the
numa_fit_instance_to_host function is not rebuild aware.

As such prior to this change a rebuild would only succeed
if a host had enough additional capacity for a second instance
on the same host meeting the requirement of the new image and
existing flavor. This behavior was incorrect on two counts as
a rebuild uses a noop claim. First the resouce usage cannot
change so it was incorrect to require the addtional capacity
to rebuild an instance. Secondly it was incorrect not to assert
the resouce usage remained the same.

I0322d872bdff68936033a6f5a54e8296a6fb3434 adressed guarding the
rebuild against altering the resouce usage and this change
allows in place rebuild.

This change found a latent bug that will be adressed in a follow
up change and updated the functional tests to note the incorrect
behavior.

Change-Id: I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132
Closes-Bug: #1804502
Implements: blueprint inplace-rebuild-of-numa-instances
(cherry picked from commit 3f9411071d4c1a04ab0b68fd635597bf6959c0ca)
(cherry picked from commit 94c0362918169a1fa06aa6cf5a483e9285d7b91f)
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/702973/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/filters/numa_topology_filter.py', 'releasenotes/notes/numa-rebuild-b75f9a1966f576ea.yaml', 'nova/tests/functional/libvirt/test_numa_servers.py']",3,6001bff0ff18a9712b538114f9ea57d086b4961b,bug/1763766,"from testtools import skip # FIXME(sean-k-mooney): The logic of this test is incorrect. # The test was written to assert that we failed to rebuild # because the NUMA constraints were violated due to the attachment # of an interface from a second host NUMA node to an instance with # a NUMA topology of 1 that is affined to a different NUMA node. # Nova should reject the interface attachment if the NUMA constraints # would be violated and it should fail at that point not when the # instance is rebuilt. This is a latent bug which will be addressed # in a separate patch. @skip(""bug 1855332"") def test_attach_interface_with_network_affinity_violation(self): # FIXME(sean-k-mooney): This should raise an exception as this # interface attachment would violate the NUMA constraints. # NOTE(sean-k-mooney): the rest of the test is incorrect but # is left to show the currently broken behavior. # This should succeed as the numa constraints do not change. self._rebuild_server(server, self.image_ref_1)"," def test_rebuild_server_with_network_affinity(self): # TODO(sean-k-mooney): this should pass but i currently expect it to # fail because the NUMA topology filter does not support in place # rebuild and we have used all the resources on the compute node. self.assertRaises( client.OpenStackApiException, self._rebuild_server, server, self.image_ref_1)",37,9
openstack%2Fcharm-nova-cloud-controller~master~I7d5b7a20573b38d12b1ead708ee446472f21e9f8,openstack/charm-nova-cloud-controller,master,I7d5b7a20573b38d12b1ead708ee446472f21e9f8,Do not access DB when it is in maintenance mode.,MERGED,2020-01-30 12:38:28.000000000,2020-01-31 15:05:59.000000000,2020-01-31 15:05:59.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-30 12:38:28.000000000', 'files': ['unit_tests/test_nova_cc_hooks.py', 'hooks/nova_cc_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/90ecd0f7712fa6f089dae5ef0817652fc1f89176', 'message': 'Do not access DB when it is in maintenance mode.\n\nIf the database is in maintenace mode do not attempt to access\nit.\n\nDepends-On: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f\nChange-Id: I7d5b7a20573b38d12b1ead708ee446472f21e9f8\n'}]",0,704994,90ecd0f7712fa6f089dae5ef0817652fc1f89176,7,3,1,12549,,,0,"Do not access DB when it is in maintenance mode.

If the database is in maintenace mode do not attempt to access
it.

Depends-On: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f
Change-Id: I7d5b7a20573b38d12b1ead708ee446472f21e9f8
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/94/704994/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_nova_cc_hooks.py', 'hooks/nova_cc_hooks.py']",2,90ecd0f7712fa6f089dae5ef0817652fc1f89176,gate-on-db-maintenance-mode," if ch_utils.is_db_maintenance_mode(): hookenv.log( 'Database maintenance mode, aborting hook.', level=hookenv.DEBUG) return ",,8,0
openstack%2Fcharm-neutron-api~master~I42cc19aedff2bc060343f4431c1b4834f9389f03,openstack/charm-neutron-api,master,I42cc19aedff2bc060343f4431c1b4834f9389f03,Do not access DB when it is in maintenance mode.,MERGED,2020-01-30 12:38:27.000000000,2020-01-31 14:57:34.000000000,2020-01-31 14:57:34.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-30 12:38:27.000000000', 'files': ['unit_tests/test_neutron_api_hooks.py', 'hooks/neutron_api_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/6fafb5abc5536e5333467324629e67bf2489bf3a', 'message': 'Do not access DB when it is in maintenance mode.\n\nIf the database is in maintenace mode do not attempt to access\nit.\n\nChange-Id: I42cc19aedff2bc060343f4431c1b4834f9389f03\nDepends-On: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f\n'}]",0,704993,6fafb5abc5536e5333467324629e67bf2489bf3a,7,3,1,12549,,,0,"Do not access DB when it is in maintenance mode.

If the database is in maintenace mode do not attempt to access
it.

Change-Id: I42cc19aedff2bc060343f4431c1b4834f9389f03
Depends-On: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/93/704993/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_neutron_api_hooks.py', 'hooks/neutron_api_hooks.py']",2,6fafb5abc5536e5333467324629e67bf2489bf3a,gate-on-db-maintenance-mode," is_db_maintenance_mode, if is_db_maintenance_mode(): log('Database maintenance mode, aborting hook.', level=DEBUG) return",,7,0
openstack%2Fcharm-keystone~master~I8cdb42364b7da03129bb8e2debebf6f6947d7ff3,openstack/charm-keystone,master,I8cdb42364b7da03129bb8e2debebf6f6947d7ff3,Do not access DB when it is in maintenance mode.,MERGED,2020-01-30 12:38:26.000000000,2020-01-31 14:56:00.000000000,2020-01-31 14:56:00.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-30 12:38:26.000000000', 'files': ['unit_tests/test_keystone_hooks.py', 'hooks/keystone_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/848ce4b5f4c990ea604b64f8be3c6b130588a773', 'message': 'Do not access DB when it is in maintenance mode.\n\nIf the database is in maintenace mode do not attempt to access\nit.\n\nDepends-On: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f\nChange-Id: I8cdb42364b7da03129bb8e2debebf6f6947d7ff3\n'}]",0,704992,848ce4b5f4c990ea604b64f8be3c6b130588a773,7,3,1,12549,,,0,"Do not access DB when it is in maintenance mode.

If the database is in maintenace mode do not attempt to access
it.

Depends-On: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f
Change-Id: I8cdb42364b7da03129bb8e2debebf6f6947d7ff3
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/92/704992/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_keystone_hooks.py', 'hooks/keystone_hooks.py']",2,848ce4b5f4c990ea604b64f8be3c6b130588a773,gate-on-db-maintenance-mode," is_db_maintenance_mode, if is_db_maintenance_mode(): log('Database maintenance mode, aborting hook.', level=INFO) return",,12,0
openstack%2Fcharm-openstack-dashboard~master~I91d3f858888a169cf85d51533a54ef37d7a72c58,openstack/charm-openstack-dashboard,master,I91d3f858888a169cf85d51533a54ef37d7a72c58,Do not access DB when it is in maintenance mode.,MERGED,2020-01-30 12:38:29.000000000,2020-01-31 14:53:54.000000000,2020-01-31 14:53:54.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-30 12:38:29.000000000', 'files': ['hooks/horizon_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/c9e844a4a3f6b8d490393b11dd2f78b0e03a5d72', 'message': 'Do not access DB when it is in maintenance mode.\n\nIf the database is in maintenace mode do not attempt to access\nit.\n\nDepends-On: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f\nChange-Id: I91d3f858888a169cf85d51533a54ef37d7a72c58\n'}]",0,704995,c9e844a4a3f6b8d490393b11dd2f78b0e03a5d72,7,3,1,12549,,,0,"Do not access DB when it is in maintenance mode.

If the database is in maintenace mode do not attempt to access
it.

Depends-On: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f
Change-Id: I91d3f858888a169cf85d51533a54ef37d7a72c58
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/95/704995/1 && git format-patch -1 --stdout FETCH_HEAD,['hooks/horizon_hooks.py'],1,c9e844a4a3f6b8d490393b11dd2f78b0e03a5d72,gate-on-db-maintenance-mode," is_db_maintenance_mode, if is_db_maintenance_mode(): log('Database maintenance mode, aborting hook.') return",,4,0
openstack%2Fcharm-heat~master~Ib654a82fd91cd73c6ab5c178d87d054d8717ce4f,openstack/charm-heat,master,Ib654a82fd91cd73c6ab5c178d87d054d8717ce4f,Do not access DB when it is in maintenance mode.,MERGED,2020-01-30 12:38:26.000000000,2020-01-31 14:53:09.000000000,2020-01-31 14:53:09.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-30 12:38:26.000000000', 'files': ['hooks/heat_relations.py', 'unit_tests/test_heat_relations.py'], 'web_link': 'https://opendev.org/openstack/charm-heat/commit/e74c9a4d5f36ded783723d3ce30a11c502651498', 'message': 'Do not access DB when it is in maintenance mode.\n\nIf the database is in maintenace mode do not attempt to access\nit.\n\nDepends-On: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f\nChange-Id: Ib654a82fd91cd73c6ab5c178d87d054d8717ce4f\n'}]",0,704991,e74c9a4d5f36ded783723d3ce30a11c502651498,7,3,1,12549,,,0,"Do not access DB when it is in maintenance mode.

If the database is in maintenace mode do not attempt to access
it.

Depends-On: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f
Change-Id: Ib654a82fd91cd73c6ab5c178d87d054d8717ce4f
",git fetch https://review.opendev.org/openstack/charm-heat refs/changes/91/704991/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/heat_relations.py', 'unit_tests/test_heat_relations.py']",2,e74c9a4d5f36ded783723d3ce30a11c502651498,gate-on-db-maintenance-mode," 'is_db_maintenance_mode', self.is_db_maintenance_mode.return_value = False self.is_db_maintenance_mode.return_value = False",,7,0
openstack%2Fcharm-cinder~master~I131079ea390d11c1208f75b8b97ab4cff7fb47ff,openstack/charm-cinder,master,I131079ea390d11c1208f75b8b97ab4cff7fb47ff,Do not access DB when it is in maintenance mode.,MERGED,2020-01-30 12:38:21.000000000,2020-01-31 14:49:06.000000000,2020-01-31 14:49:06.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-30 12:38:21.000000000', 'files': ['unit_tests/test_cinder_hooks.py', 'hooks/cinder_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/0585d9a96b515dac9ad2fb645163a9da0079f7ac', 'message': 'Do not access DB when it is in maintenance mode.\n\nIf the database is in maintenace mode do not attempt to access\nit.\n\nDepends-On: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f\nChange-Id: I131079ea390d11c1208f75b8b97ab4cff7fb47ff\n'}]",0,704990,0585d9a96b515dac9ad2fb645163a9da0079f7ac,7,3,1,12549,,,0,"Do not access DB when it is in maintenance mode.

If the database is in maintenace mode do not attempt to access
it.

Depends-On: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f
Change-Id: I131079ea390d11c1208f75b8b97ab4cff7fb47ff
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/90/704990/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_cinder_hooks.py', 'hooks/cinder_hooks.py']",2,0585d9a96b515dac9ad2fb645163a9da0079f7ac,gate-on-db-maintenance-mode," is_db_maintenance_mode, if is_db_maintenance_mode(): juju_log('Database maintenance mode, aborting hook.') return",,10,0
openstack%2Fcharm-openstack-dashboard~master~Ib3fc0b0525dabf70f45fd050af2ed05ba31129b9,openstack/charm-openstack-dashboard,master,Ib3fc0b0525dabf70f45fd050af2ed05ba31129b9,Fix issue with plugins breaking packages,MERGED,2020-01-28 14:09:30.000000000,2020-01-31 14:48:06.000000000,2020-01-31 14:48:06.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31420}]","[{'number': 1, 'created': '2020-01-28 14:09:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/39026b59dda23ef32f938d2dc7df59054606b5fd', 'message': 'Fix issue with plugins breaking packages\n\nThe core issue is that the plugin had no way to signal to the\nprincipal charm what packages needed to be installed, and crucially,\nwhich conflicted with the packages that the plugin needs to operate.\nThe referenced bug exhibits this issue in that, on install, a package\nis removed by the plugin, but the principal charm ""doesn\'t know"".  Then\non upgrade, the principal charm re-installs the package, and breaks\nthe plugin.\n\nThis patch allows the plugin to signal which packages it requires to\noperate via the dashboard-plugin interface.  This ensures that when\nthe openstack-dashboard charm upgrades it already ""knows"" what a\nplugin needs and acts accordingly.  Equally, plugins can change their\nrequirements and this patch allows them to update/remove/install\npackages as needed.\n\nThe local_settings.py is already controlled by the principal, and this\njust shifts absolute control over packaging to the principal as well.\nThe plugin charm\'s purpose is to indicate packages and config to the\nprincipal.\n\nNote.  There should be no backwards compatibility issues with this\nchange. If a plugin doesn\'t notify the principal of any packages then it\nwon\'t take any action.  This does mean that the openstack-charm should\nbe upgrade prior to any plugins that gain this feature.\n\nChange-Id: Ib3fc0b0525dabf70f45fd050af2ed05ba31129b9\nRelated-Bug: #1853851\n'}, {'number': 2, 'created': '2020-01-29 14:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/927b9ffe34791f18965ec419b2da537f50d41834', 'message': 'Fix issue with plugins breaking packages\n\nThe core issue is that the plugin had no way to signal to the\nprincipal charm what packages needed to be installed, and crucially,\nwhich conflicted with the packages that the plugin needs to operate.\nThe referenced bug exhibits this issue in that, on install, a package\nis removed by the plugin, but the principal charm ""doesn\'t know"".  Then\non upgrade, the principal charm re-installs the package, and breaks\nthe plugin.\n\nThis patch allows the plugin to signal which packages it requires to\noperate via the dashboard-plugin interface.  This ensures that when\nthe openstack-dashboard charm upgrades it already ""knows"" what a\nplugin needs and acts accordingly.  Equally, plugins can change their\nrequirements and this patch allows them to update/remove/install\npackages as needed.\n\nThe local_settings.py is already controlled by the principal, and this\njust shifts absolute control over packaging to the principal as well.\nThe plugin charm\'s purpose is to indicate packages and config to the\nprincipal.\n\nNote.  There should be no backwards compatibility issues with this\nchange. If a plugin doesn\'t notify the principal of any packages then it\nwon\'t take any action.  This does mean that the openstack-charm should\nbe upgrade prior to any plugins that gain this feature.\n\nChange-Id: Ib3fc0b0525dabf70f45fd050af2ed05ba31129b9\nRelated-Bug: #1853851\n'}, {'number': 3, 'created': '2020-01-30 16:18:55.000000000', 'files': ['tests/tests.yaml', 'hooks/horizon_hooks.py', 'hooks/horizon_utils.py', 'tests/bundles/eoan-train.yaml', 'unit_tests/test_horizon_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/1e2515e13fb71c2ad5fe41251a581c9edf4f654b', 'message': 'Fix issue with plugins breaking packages\n\nThe core issue is that the plugin had no way to signal to the\nprincipal charm what packages needed to be installed, and crucially,\nwhich conflicted with the packages that the plugin needs to operate.\nThe referenced bug exhibits this issue in that, on install, a package\nis removed by the plugin, but the principal charm ""doesn\'t know"".  Then\non upgrade, the principal charm re-installs the package, and breaks\nthe plugin.\n\nThis patch allows the plugin to signal which packages it requires to\noperate via the dashboard-plugin interface.  This ensures that when\nthe openstack-dashboard charm upgrades it already ""knows"" what a\nplugin needs and acts accordingly.  Equally, plugins can change their\nrequirements and this patch allows them to update/remove/install\npackages as needed.\n\nThe local_settings.py is already controlled by the principal, and this\njust shifts absolute control over packaging to the principal as well.\nThe plugin charm\'s purpose is to indicate packages and config to the\nprincipal.\n\nNote.  There should be no backwards compatibility issues with this\nchange. If a plugin doesn\'t notify the principal of any packages then it\nwon\'t take any action.  This does mean that the openstack-charm should\nbe upgrade prior to any plugins that gain this feature.\n\nAlso disable disco test as disco is EOL.\n\nChange-Id: Ib3fc0b0525dabf70f45fd050af2ed05ba31129b9\nRelated-Bug: #1853851\n'}]",8,704574,1e2515e13fb71c2ad5fe41251a581c9edf4f654b,20,5,3,20870,,,0,"Fix issue with plugins breaking packages

The core issue is that the plugin had no way to signal to the
principal charm what packages needed to be installed, and crucially,
which conflicted with the packages that the plugin needs to operate.
The referenced bug exhibits this issue in that, on install, a package
is removed by the plugin, but the principal charm ""doesn't know"".  Then
on upgrade, the principal charm re-installs the package, and breaks
the plugin.

This patch allows the plugin to signal which packages it requires to
operate via the dashboard-plugin interface.  This ensures that when
the openstack-dashboard charm upgrades it already ""knows"" what a
plugin needs and acts accordingly.  Equally, plugins can change their
requirements and this patch allows them to update/remove/install
packages as needed.

The local_settings.py is already controlled by the principal, and this
just shifts absolute control over packaging to the principal as well.
The plugin charm's purpose is to indicate packages and config to the
principal.

Note.  There should be no backwards compatibility issues with this
change. If a plugin doesn't notify the principal of any packages then it
won't take any action.  This does mean that the openstack-charm should
be upgrade prior to any plugins that gain this feature.

Also disable disco test as disco is EOL.

Change-Id: Ib3fc0b0525dabf70f45fd050af2ed05ba31129b9
Related-Bug: #1853851
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/74/704574/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/horizon_hooks.py', 'hooks/horizon_utils.py', 'unit_tests/test_horizon_utils.py']",3,39026b59dda23ef32f938d2dc7df59054606b5fd,bug/1853851," 'relation_ids', 'related_units', 'relation_get', horizon_utils.relation_ids.return_value = [] horizon_utils.relation_ids.return_value = [] verify_pkgs = ( self.assertEqual( sorted(horizon_utils.determine_purge_packages()), sorted(verify_pkgs)) def _patch_fopr_dashboard_plugin_packages(self): def relation_ids_side_effect(rname): return { 'dashboard-plugin': [ 'dashboard-plugin:0', 'dashboard-plugin:1', ], }[rname] horizon_utils.relation_ids.side_effect = relation_ids_side_effect def related_units_side_effect(rid): return { 'dashboard-plugin:0': ['r0', 'r1'], 'dashboard-plugin:1': ['r2'], }[rid] horizon_utils.related_units.side_effect = related_units_side_effect def relation_get_side_effect(unit=None, rid=None): return { ""dashboard-plugin:0/r0"": { 'install-packages': '[""p1"", ""p3"", ""p2""]', 'conflicting-packages': '[""n2""]', }, ""dashboard-plugin:0/r1"": { 'install-packages': '[""p5"", ""p6""]', 'conflicting-packages': """", }, ""dashboard-plugin:1/r2"": { 'install-packages': '[""p4"", ""p6""]', 'conflicting-packages': '[""n1""]', }, }[""{}/{}"".format(rid, unit)] horizon_utils.relation_get.side_effect = relation_get_side_effect def test_determine_packages_dashboard_plugin(self): 'Ensure that plugins can provide their packages.' self._patch_fopr_dashboard_plugin_packages() self.assertEqual( sorted(horizon_utils.determine_packages_dashboard_plugin()), sorted(['p1', 'p2', 'p3', 'p4', 'p5', 'p6'])) def test_determine_packages_with_dashboard_plugin_rocky(self): 'Ensure that plugin packages are part of determine_packages()' horizon_utils.os_release.return_value = 'rocky' pkgs = ([p for p in horizon_utils.BASE_PACKAGES if not p.startswith('python-')] + horizon_utils.PY3_PACKAGES + ['p1', 'p2', 'p3', 'p4', 'p5', 'p6']) self._patch_fopr_dashboard_plugin_packages() self.assertEqual( sorted(horizon_utils.determine_packages()), sorted(pkgs) ) def test_determine_purge_packages_dashboard_plugin(self): 'Ensure that plugins can provide their conflicting packages' self._patch_fopr_dashboard_plugin_packages() self.assertEqual( sorted(horizon_utils.determine_purge_packages_dashboard_plugin()), sorted(['n1', 'n2'])) def test_determine_purge_packages_dashboard_plugin_rocky(self): 'Ensure python packages are identified for purge at rocky' self._patch_fopr_dashboard_plugin_packages() horizon_utils.os_release.return_value = 'rocky' verify_pkgs = ( [p for p in horizon_utils.BASE_PACKAGES if p.startswith('python-')] + ['python-django-horizon', 'python-django-openstack-auth', 'python-pymysql', 'python-neutron-lbaas-dashboard', 'python-designate-dashboard', 'python-heat-dashboard']) self.assertEqual( sorted(horizon_utils.determine_purge_packages()), sorted(verify_pkgs + [""n1"", ""n2""])) @patch('charmhelpers.core.unitdata.kv') def test_store_plugin_packages_in_kv(self, mock_kv): 'Ensure that plugin packages state can be stored.' _key = None _value = None _flush = None class MockKV(): def set(key, value): nonlocal _key, _value _key = key _value = value def flush(): nonlocal _flush _flush = True mock_kv.return_value = MockKV horizon_utils.store_plugin_packages_in_kv('r1', 'u1', ['n1'], ['p1', 'p2', 'p3']) self.assertEqual(_value, {""conflicting_packages"": ['n1'], ""install_packages"": ['p1', 'p2', 'p3']}) self.assertEqual( _key, horizon_utils.make_dashboard_plugin_packages_kv_key('r1', 'u1')) self.assertTrue(_flush) @patch('charmhelpers.core.unitdata.kv') def test_get_plugin_packages_from_kv(self, mock_kv): 'Ensure that plugin packages state can be recovered.' # no data stored yet; ensure that it handles it gracefully _key = None _value = None class MockKV(): def get(key, default=None): nonlocal _key _key = key return _value mock_kv.return_value = MockKV self.assertEqual(horizon_utils.get_plugin_packages_from_kv('r1', 'u1'), {""conflicting_packages"": [], ""install_packages"": []}) self.assertEqual( _key, horizon_utils.make_dashboard_plugin_packages_kv_key('r1', 'u1')) # just packages are configured. _key = None _value = {""install_packages"": ['p1', 'p2']} self.assertEqual(horizon_utils.get_plugin_packages_from_kv('r1', 'u1'), {""conflicting_packages"": [], ""install_packages"": ['p1', 'p2']}) # just conflicting packages are configured. _key = None _value = {""conflicting_packages"": ['n1']} self.assertEqual(horizon_utils.get_plugin_packages_from_kv('r1', 'u1'), {""conflicting_packages"": ['n1'], ""install_packages"": []}) # configure both being stored. _key = None _value = {""install_packages"": ['p1', 'p2'], ""conflicting_packages"": ['n1']} self.assertEqual(horizon_utils.get_plugin_packages_from_kv('r1', 'u1'), {""conflicting_packages"": ['n1'], ""install_packages"": ['p1', 'p2']}) @patch.object(horizon_utils, 'get_plugin_packages_from_kv') @patch.object(horizon_utils, 'store_plugin_packages_in_kv') def test_update_plugin_packages_in_kv(self, mock_store_plugin_packages_in_kv, mock_get_plugin_packages_from_kv): 'Ensure that plugin packages state can be faithfully held' self._patch_fopr_dashboard_plugin_packages() mock_get_plugin_packages_from_kv.return_value = { ""install_packages"": [""p1"", ""q1""], ""conflicting_packages"": [""m1""], } (added, removed) = horizon_utils.update_plugin_packages_in_kv( ""dashboard-plugin:0"", ""r0"") self.assertEqual(sorted(added), [""m1"", ""p2"", ""p3""]) self.assertEqual(sorted(removed), [""n2"", ""q1""]) mock_store_plugin_packages_in_kv.assert_called_once_with( ""dashboard-plugin:0"", ""r0"", [""n2""], [""p1"", ""p3"", ""p2""])"," self.assertEqual( horizon_utils.determine_purge_packages(),",425,25
openstack%2Fcharm-glance~master~I9550452e78608589592265fca9549a51c88d65bc,openstack/charm-glance,master,I9550452e78608589592265fca9549a51c88d65bc,Do not access DB when it is in maintenance mode.,MERGED,2020-01-30 12:38:30.000000000,2020-01-31 14:47:28.000000000,2020-01-31 14:47:28.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-30 12:38:30.000000000', 'files': ['unit_tests/test_glance_relations.py', 'hooks/glance_relations.py'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/3cdd23514497b83e2306885e97fa04704995c387', 'message': 'Do not access DB when it is in maintenance mode.\n\nIf the database is in maintenace mode do not attempt to access\nit.\n\nDepends-On: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f\nChange-Id: I9550452e78608589592265fca9549a51c88d65bc\n'}]",0,704996,3cdd23514497b83e2306885e97fa04704995c387,7,3,1,12549,,,0,"Do not access DB when it is in maintenance mode.

If the database is in maintenace mode do not attempt to access
it.

Depends-On: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f
Change-Id: I9550452e78608589592265fca9549a51c88d65bc
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/96/704996/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_glance_relations.py', 'hooks/glance_relations.py']",2,3cdd23514497b83e2306885e97fa04704995c387,gate-on-db-maintenance-mode," is_db_maintenance_mode, if is_db_maintenance_mode(): juju_log('Database maintenance mode, aborting hook.') return",,7,0
openstack%2Fkolla-ansible~stable%2Ftrain~Ib603923099e3821389a71a601bb55cc5a68aca8c,openstack/kolla-ansible,stable/train,Ib603923099e3821389a71a601bb55cc5a68aca8c,CI: Add ceph-ansible related files to ignores in check-config.sh,MERGED,2020-01-31 11:25:36.000000000,2020-01-31 14:27:00.000000000,2020-01-31 14:23:27.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-31 11:25:36.000000000', 'files': ['tests/check-config.sh'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/85c3e4b368eb3834c84e9a55c80fc51c2c8299fe', 'message': 'CI: Add ceph-ansible related files to ignores in check-config.sh\n\nIn order to support upgrade-ceph-ansible jobs in master (Ussuri),\nwe need to add files generated by this job to previous release,\nwhich is Train.\n\nChange-Id: Ib603923099e3821389a71a601bb55cc5a68aca8c\n'}]",0,705194,85c3e4b368eb3834c84e9a55c80fc51c2c8299fe,8,3,1,22629,,,0,"CI: Add ceph-ansible related files to ignores in check-config.sh

In order to support upgrade-ceph-ansible jobs in master (Ussuri),
we need to add files generated by this job to previous release,
which is Train.

Change-Id: Ib603923099e3821389a71a601bb55cc5a68aca8c
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/94/705194/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/check-config.sh'],1,85c3e4b368eb3834c84e9a55c80fc51c2c8299fe,, -not -name ceph-ansible.yml \ -not -name ceph-inventory \,,2,0
openstack%2Foctavia~master~Ib3d6aa0f2fd550c3a8756c41e0159c5ae8127c7c,openstack/octavia,master,Ib3d6aa0f2fd550c3a8756c41e0159c5ae8127c7c,Fix house keeping graceful shutdown,MERGED,2019-12-11 16:51:39.000000000,2020-01-31 14:00:15.000000000,2020-01-30 22:39:22.000000000,"[{'_account_id': 1131}, {'_account_id': 6469}, {'_account_id': 7249}, {'_account_id': 10273}, {'_account_id': 22348}, {'_account_id': 29244}]","[{'number': 1, 'created': '2019-12-11 16:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/4165aa9ff2466c6c425b69de2ecf3278bf6cc1bb', 'message': 'Fix house keeping graceful shutdown\n\nSIGTERM was not caught by house keeping service, threads were not\ncorrectly terminated and spare amphora creation may have been killed\nwhen restarting the service, leaving amphorae in BOOTING status.\n\nStory: 2007008\nTask: 37788\n\nChange-Id: Ib3d6aa0f2fd550c3a8756c41e0159c5ae8127c7c\n'}, {'number': 2, 'created': '2019-12-11 18:08:53.000000000', 'files': ['octavia/cmd/house_keeping.py', 'octavia/tests/unit/cmd/test_house_keeping.py', 'releasenotes/notes/fix-house-keeping-shutdown-17b04417a2c4849f.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/df0ba06c1e96dc5ad4855d24435970ee926175ca', 'message': 'Fix house keeping graceful shutdown\n\nSIGTERM was not caught by house keeping service, threads were not\ncorrectly terminated and spare amphora creation may have been killed\nwhen restarting the service, leaving amphorae in BOOTING status.\n\nStory: 2007008\nTask: 37788\n\nChange-Id: Ib3d6aa0f2fd550c3a8756c41e0159c5ae8127c7c\n'}]",0,698536,df0ba06c1e96dc5ad4855d24435970ee926175ca,13,6,2,29244,,,0,"Fix house keeping graceful shutdown

SIGTERM was not caught by house keeping service, threads were not
correctly terminated and spare amphora creation may have been killed
when restarting the service, leaving amphorae in BOOTING status.

Story: 2007008
Task: 37788

Change-Id: Ib3d6aa0f2fd550c3a8756c41e0159c5ae8127c7c
",git fetch https://review.opendev.org/openstack/octavia refs/changes/36/698536/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/cmd/house_keeping.py', 'releasenotes/notes/fix-house-keeping-shutdown-17b04417a2c4849f.yaml']",2,4165aa9ff2466c6c425b69de2ecf3278bf6cc1bb,,--- fixes: - | Fix a bug that could interrupt resource creation when performing a graceful shutdown of the house keeping service and leave resources such as amphorae in a BOOTING status. ,,22,7
openstack%2Fopenstack-helm-infra~master~I7f20a3eb9a98669ae4af657d36a776830b82dfca,openstack/openstack-helm-infra,master,I7f20a3eb9a98669ae4af657d36a776830b82dfca,[htk] Increase job default backoffLimit to 1000,MERGED,2020-01-30 19:47:38.000000000,2020-01-31 13:58:58.000000000,2020-01-30 21:49:19.000000000,"[{'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 30777}]","[{'number': 1, 'created': '2020-01-30 19:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1fcb4222b555a592c5fb7c47c90763198842022d', 'message': '[htk] Increase job default backoffLimit to 1000\n\nSometimes jobs fail, the default of 6 reties is far too brief to get\nlogs (which are purged after the final failure); as we need the jobs\nto succeed always, having a much higher default here seems prudent.\n\nChange-Id: I7f20a3eb9a98669ae4af657d36a776830b82dfca\n'}, {'number': 2, 'created': '2020-01-30 19:53:10.000000000', 'files': ['helm-toolkit/templates/manifests/_job-s3-user.yaml.tpl', 'helm-toolkit/templates/manifests/_job-ks-endpoints.tpl', 'helm-toolkit/templates/manifests/_job-bootstrap.tpl', 'helm-toolkit/templates/manifests/_job-db-init-mysql.tpl', 'helm-toolkit/templates/manifests/_job_image_repo_sync.tpl', 'helm-toolkit/templates/manifests/_job-ks-service.tpl', 'helm-toolkit/templates/manifests/_job-db-sync.tpl', 'helm-toolkit/templates/manifests/_job-db-drop-mysql.tpl', 'helm-toolkit/templates/manifests/_job-s3-bucket.yaml.tpl', 'helm-toolkit/templates/manifests/_job-ks-user.yaml.tpl', 'helm-toolkit/templates/manifests/_job-rabbit-init.yaml.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/578511cd3906694c608ffbb31af9c7eac9b55fb4', 'message': '[htk] Increase job default backoffLimit to 1000\n\nSometimes jobs fail, the default of 6 retries is far too brief to get\nlogs (which are purged after the final failure); as we need the jobs\nto succeed always, having a much higher default here seems prudent.\n\nChange-Id: I7f20a3eb9a98669ae4af657d36a776830b82dfca\n'}]",0,705105,578511cd3906694c608ffbb31af9c7eac9b55fb4,12,4,2,8898,,,0,"[htk] Increase job default backoffLimit to 1000

Sometimes jobs fail, the default of 6 retries is far too brief to get
logs (which are purged after the final failure); as we need the jobs
to succeed always, having a much higher default here seems prudent.

Change-Id: I7f20a3eb9a98669ae4af657d36a776830b82dfca
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/05/705105/2 && git format-patch -1 --stdout FETCH_HEAD,"['helm-toolkit/templates/manifests/_job-s3-user.yaml.tpl', 'helm-toolkit/templates/manifests/_job-bootstrap.tpl', 'helm-toolkit/templates/manifests/_job-ks-endpoints.tpl', 'helm-toolkit/templates/manifests/_job-db-init-mysql.tpl', 'helm-toolkit/templates/manifests/_job-ks-service.tpl', 'helm-toolkit/templates/manifests/_job_image_repo_sync.tpl', 'helm-toolkit/templates/manifests/_job-db-sync.tpl', 'helm-toolkit/templates/manifests/_job-db-drop-mysql.tpl', 'helm-toolkit/templates/manifests/_job-s3-bucket.yaml.tpl', 'helm-toolkit/templates/manifests/_job-ks-user.yaml.tpl', 'helm-toolkit/templates/manifests/_job-rabbit-init.yaml.tpl']",11,1fcb4222b555a592c5fb7c47c90763198842022d,htk-increase-job-defaults,"{{- $backoffLimit := index . ""backoffLimit"" | default ""1000"" -}}","{{- $backoffLimit := index . ""backoffLimit"" | default ""6"" -}}",11,11
openstack%2Fneutron~stable%2Ftrain~Id019fa7649bd1158f9d56e63f8dad108d0ca8c1f,openstack/neutron,stable/train,Id019fa7649bd1158f9d56e63f8dad108d0ca8c1f,Allow to kill keepalived state change monitor process,MERGED,2020-01-28 15:39:24.000000000,2020-01-31 13:53:13.000000000,2020-01-31 13:49:46.000000000,"[{'_account_id': 1131}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-28 15:39:24.000000000', 'files': ['etc/neutron/rootwrap.d/l3.filters'], 'web_link': 'https://opendev.org/openstack/neutron/commit/79ea54b21dff0baaaaa8f83a60557c0be642e49e', 'message': 'Allow to kill keepalived state change monitor process\n\nUsually Neutron stops neutron-keepalived-state-change-monitor process\ngracefully with SIGTERM.\nBut in case if this will not stop process for some time, Neutron will\ntry to kill this process with SIGKILL (-9).\nThat was causing problem with rootwrap as kill filters for this process\nallowed to send only ""-15"" to it.\nNow it is possible to kill this process with ""-9"" too.\n\nConflicts:\n    etc/neutron/rootwrap.d/l3.filters\n\nChange-Id: Id019fa7649bd1158f9d56e63f8dad108d0ca8c1f\nCloses-bug: #1860326\n(cherry picked from commit d6fccd247f70abc84c8a480138e135717836c7b3)\n'}]",0,704593,79ea54b21dff0baaaaa8f83a60557c0be642e49e,31,6,1,11975,,,0,"Allow to kill keepalived state change monitor process

Usually Neutron stops neutron-keepalived-state-change-monitor process
gracefully with SIGTERM.
But in case if this will not stop process for some time, Neutron will
try to kill this process with SIGKILL (-9).
That was causing problem with rootwrap as kill filters for this process
allowed to send only ""-15"" to it.
Now it is possible to kill this process with ""-9"" too.

Conflicts:
    etc/neutron/rootwrap.d/l3.filters

Change-Id: Id019fa7649bd1158f9d56e63f8dad108d0ca8c1f
Closes-bug: #1860326
(cherry picked from commit d6fccd247f70abc84c8a480138e135717836c7b3)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/93/704593/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/neutron/rootwrap.d/l3.filters'],1,79ea54b21dff0baaaaa8f83a60557c0be642e49e,bug/1860326,"kill_keepalived_monitor_py: KillFilter, root, python, -15, -9 kill_keepalived_monitor_py27: KillFilter, root, python2.7, -15, -9 kill_keepalived_monitor_py3: KillFilter, root, python3, -15, -9 kill_keepalived_monitor_py35: KillFilter, root, python3.5, -15, -9 kill_keepalived_monitor_py36: KillFilter, root, python3.6, -15, -9 kill_keepalived_monitor_py37: KillFilter, root, python3.7, -15, -9kill_keepalived_monitor_platform_py: KillFilter, root, /usr/libexec/platform-python, -15, -9 kill_keepalived_monitor_platform_py36: KillFilter, root, /usr/libexec/platform-python3.6, -15, -9","kill_keepalived_monitor_py: KillFilter, root, python, -15 kill_keepalived_monitor_py27: KillFilter, root, python2.7, -15 kill_keepalived_monitor_py3: KillFilter, root, python3, -15 kill_keepalived_monitor_py35: KillFilter, root, python3.5, -15 kill_keepalived_monitor_py36: KillFilter, root, python3.6, -15 kill_keepalived_monitor_py37: KillFilter, root, python3.7, -15kill_keepalived_monitor_platform_py: KillFilter, root, /usr/libexec/platform-python, -15 kill_keepalived_monitor_platform_py36: KillFilter, root, /usr/libexec/platform-python3.6, -15",8,8
openstack%2Fneutron~master~I1185c1ca2556e2aed27051efd98a1d141f5298c9,openstack/neutron,master,I1185c1ca2556e2aed27051efd98a1d141f5298c9,Enable ovsdb debug messages in functional and fullstack,MERGED,2020-01-22 13:35:23.000000000,2020-01-31 13:41:03.000000000,2020-01-31 13:36:55.000000000,"[{'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-22 13:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/274c493f54b216d0625c7ba588954602ae299074', 'message': 'Enable ovsdb debug messages in functional and fullstack\n\nChange-Id: I1185c1ca2556e2aed27051efd98a1d141f5298c9\nRelated-Bug: #1802640\n'}, {'number': 2, 'created': '2020-01-24 09:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/af8d65f53f058ed56d6c29ad8f5c2bb30aec7909', 'message': 'Enable ovsdb debug messages in functional and fullstack\n\nChange-Id: I1185c1ca2556e2aed27051efd98a1d141f5298c9\nRelated-Bug: #1802640\n'}, {'number': 3, 'created': '2020-01-28 16:11:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4cafbc18e58187bee490ca2a33ba094e14a260bd', 'message': 'Enable ovsdb debug messages in functional and fullstack\n\nChange-Id: I1185c1ca2556e2aed27051efd98a1d141f5298c9\nRelated-Bug: #1802640\n'}, {'number': 4, 'created': '2020-01-29 08:26:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0256cf5606ac9d7ea95482f3cbafcc2b414d5277', 'message': 'Enable ovsdb debug messages in functional and fullstack\n\nChange-Id: I1185c1ca2556e2aed27051efd98a1d141f5298c9\nRelated-Bug: #1802640\n'}, {'number': 5, 'created': '2020-01-29 17:14:35.000000000', 'files': ['neutron/common/config.py', 'neutron/tests/functional/base.py', 'neutron/tests/fullstack/resources/config.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cf36bd4ca52bec4a707c35df261b8a2630850e68', 'message': 'Enable ovsdb debug messages in functional and fullstack\n\nEnable the configuration flag ""ovsdb_debug"" for functional and\nfullstack tests. If enable, NeutronOvsdbIdl won\'t define any log\nlevel when setting up the logger; if not ""max_level"" is defined,\nall messages are logged.\n\nChange-Id: I1185c1ca2556e2aed27051efd98a1d141f5298c9\nRelated-Bug: #1802640\n'}]",2,703791,cf36bd4ca52bec4a707c35df261b8a2630850e68,45,8,5,16688,,,0,"Enable ovsdb debug messages in functional and fullstack

Enable the configuration flag ""ovsdb_debug"" for functional and
fullstack tests. If enable, NeutronOvsdbIdl won't define any log
level when setting up the logger; if not ""max_level"" is defined,
all messages are logged.

Change-Id: I1185c1ca2556e2aed27051efd98a1d141f5298c9
Related-Bug: #1802640
",git fetch https://review.opendev.org/openstack/neutron refs/changes/91/703791/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/common/config.py', 'zuul.d/base.yaml']",2,274c493f54b216d0625c7ba588954602ae299074,bug/1802640," post-config: ""/$NEUTRON_CORE_PLUGIN_CONF"": ovs: ovsdb_debug: True devstack_localrc: post-config: ""/$NEUTRON_CORE_PLUGIN_CONF"": ovs: ovsdb_debug: True post-config: ""/$NEUTRON_CORE_PLUGIN_CONF"": ovs: ovsdb_debug: True post-config: ""/$NEUTRON_CORE_PLUGIN_CONF"": ovs: ovsdb_debug: True",,17,1
openstack%2Fironic-python-agent~stable%2Ftrain~Ief8b360d11e654d8fae3a04a2a9f8d474a06e167,openstack/ironic-python-agent,stable/train,Ief8b360d11e654d8fae3a04a2a9f8d474a06e167,Skip read-only devices with metadata erase,MERGED,2020-01-30 16:19:06.000000000,2020-01-31 13:40:48.000000000,2020-01-31 13:38:11.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-01-30 16:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/6d7ecae6ecc404a41304bb5f979c1f50f2d8e066', 'message': 'Skip read-only devices with metadata erase\n\nHPE ""Virtual Install Devices"" appear as read-only block\ndevices, and may... or may not be visible depending on the\nbios configuration state.\n\nThese devices can no longer be disabled from the bios settings\nso the simplest course of action seems to be that we should\nhandle the existence of a read-only device.\n\nIn the event of secure erase, this is treated as a hard failure\ncase and a driver_internal_info flag has been added to enable\na future bypass method for knowledgable operators.\n\nChange-Id: Ief8b360d11e654d8fae3a04a2a9f8d474a06e167\nStory: 2007229\nTask: 38502\n(cherry picked from commit cd7b2693f873bde72706f8b6ab8c1f21e68f0fd1)\n'}, {'number': 2, 'created': '2020-01-31 10:19:33.000000000', 'files': ['ironic_python_agent/hardware.py', 'ironic_python_agent/tests/unit/test_hardware.py', 'releasenotes/notes/fix-cleaning-read-only-device-c8a0f4cc2f434d99.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/205f89a944ab47da44aa9e16417c21ee314b6da0', 'message': 'Skip read-only devices with metadata erase\n\nHPE ""Virtual Install Devices"" appear as read-only block\ndevices, and may... or may not be visible depending on the\nbios configuration state.\n\nThese devices can no longer be disabled from the bios settings\nso the simplest course of action seems to be that we should\nhandle the existence of a read-only device.\n\nIn the event of secure erase, this is treated as a hard failure\ncase and a driver_internal_info flag has been added to enable\na future bypass method for knowledgable operators.\n\nBackport note: the unit tests have been modified to account for Python 2\n\nChange-Id: Ief8b360d11e654d8fae3a04a2a9f8d474a06e167\nStory: 2007229\nTask: 38502\n(cherry picked from commit cd7b2693f873bde72706f8b6ab8c1f21e68f0fd1)\n'}]",0,705055,205f89a944ab47da44aa9e16417c21ee314b6da0,15,4,2,11655,,,0,"Skip read-only devices with metadata erase

HPE ""Virtual Install Devices"" appear as read-only block
devices, and may... or may not be visible depending on the
bios configuration state.

These devices can no longer be disabled from the bios settings
so the simplest course of action seems to be that we should
handle the existence of a read-only device.

In the event of secure erase, this is treated as a hard failure
case and a driver_internal_info flag has been added to enable
a future bypass method for knowledgable operators.

Backport note: the unit tests have been modified to account for Python 2

Change-Id: Ief8b360d11e654d8fae3a04a2a9f8d474a06e167
Story: 2007229
Task: 38502
(cherry picked from commit cd7b2693f873bde72706f8b6ab8c1f21e68f0fd1)
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/55/705055/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/hardware.py', 'ironic_python_agent/tests/unit/test_hardware.py', 'releasenotes/notes/fix-cleaning-read-only-device-c8a0f4cc2f434d99.yaml']",3,6d7ecae6ecc404a41304bb5f979c1f50f2d8e066,704725-stable/train,"--- fixes: - | Fixes an issue where metadata erasure cleaning would fail on devices that are read-only at the hardware level. Typically these are virtual devices being offered to the operating system for purposes like OS self-installation. In the case of full device erasure, this is explicitly raised as a hard failure requiring operator intervention. ",,75,0
openstack%2Ftripleo-common~stable%2Fstein~I6bd73fde6f1d78ceb89eb5cd04ac06d1b95263a3,openstack/tripleo-common,stable/stein,I6bd73fde6f1d78ceb89eb5cd04ac06d1b95263a3,Derive new nova compute parameter,MERGED,2020-01-30 08:35:54.000000000,2020-01-31 13:39:18.000000000,2020-01-31 13:11:01.000000000,"[{'_account_id': 3153}, {'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 22865}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-30 08:35:54.000000000', 'files': ['workbooks/derive_params_formulas.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8f40c8499de5ebd9b90dbca29b565b46dbe92ef4', 'message': 'Derive new nova compute parameter\n\nDerive NovaComputeCpuSharedSet parameter based on\nhost introspection.\n\nChange-Id: I6bd73fde6f1d78ceb89eb5cd04ac06d1b95263a3\nCloses-Bug: #1858678\n(cherry picked from commit 95138e9d4e8ee012616fcb7ad89be0eef1632960)\n'}]",0,704937,8f40c8499de5ebd9b90dbca29b565b46dbe92ef4,16,7,1,22865,,,0,"Derive new nova compute parameter

Derive NovaComputeCpuSharedSet parameter based on
host introspection.

Change-Id: I6bd73fde6f1d78ceb89eb5cd04ac06d1b95263a3
Closes-Bug: #1858678
(cherry picked from commit 95138e9d4e8ee012616fcb7ad89be0eef1632960)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/37/704937/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/derive_params_formulas.yaml'],1,8f40c8499de5ebd9b90dbca29b565b46dbe92ef4,," host_parameters: <% dict(concat($.role_name, 'Parameters') => dict('NovaVcpuPinSet' => $.get('nova_cpus', ''), 'NovaComputeCpuSharedSet' => $.get('host_cpus', ''), 'NovaReservedHostMemory' => $.get('host_mem', ''), 'KernelArgs' => $.get('kernel_args', ''), 'IsolCpusList' => $.get('isol_cpus', ''))) %>"," host_parameters: <% dict(concat($.role_name, 'Parameters') => dict('NovaVcpuPinSet' => $.get('nova_cpus', ''), 'NovaReservedHostMemory' => $.get('host_mem', ''), 'KernelArgs' => $.get('kernel_args', ''), 'IsolCpusList' => $.get('isol_cpus', ''))) %>",1,1
openstack%2Fneutron~master~Ifb795626dc9c2ac4f0104f491dd38c9b4cc902c9,openstack/neutron,master,Ifb795626dc9c2ac4f0104f491dd38c9b4cc902c9,[OVN] Remove VLAN check when setting external_mac,MERGED,2020-01-22 15:03:55.000000000,2020-01-31 13:39:08.000000000,2020-01-31 13:36:51.000000000,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 9845}, {'_account_id': 22348}, {'_account_id': 23804}, {'_account_id': 24791}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-22 15:03:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/09b02b7db9aee1f9d8c4e02c24f0ae464658318d', 'message': '[OVN] Remove VLAN check when setting external_mac\n\nCurrently in the code there\'s an incosistency to how we set the\n""external_mac"" field in the NAT table from OVN NB DB.\n\nWhen we created the FIP, the code is checking for the network type and\nnot setting the ""external_mac"" if its VLAN. I believe this was due to\nthe VLAN type not playing nice with DVR in the past.\n\nNow, when events are generated for the port DOWN/UP and the\n""external_mac"" field gets cleared [0], this network type is not set.\n\nFor more context see bug #1842988.\n\n[0]\nhttps://github.com/openstack/networking-ovn/blob/eda5d7f80d877601170631c5f5485370ea701f42/networking_ovn/ml2/mech_driver.py#L794-L800\n\nChange-Id: Ifb795626dc9c2ac4f0104f491dd38c9b4cc902c9\nCloses-Bug: #1842988\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}, {'number': 2, 'created': '2020-01-23 10:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cf3d6918453779203ede0e700ee10a4bc1a77c8c', 'message': '[OVN] Remove VLAN check when setting external_mac\n\nCurrently in the code there\'s an incosistency to how we set the\n""external_mac"" field in the NAT table from OVN NB DB.\n\nWhen we created the FIP, the code is checking for the network type and\nnot setting the ""external_mac"" if its VLAN. I believe this was due to\nthe VLAN type not playing nice with DVR in the past.\n\nNow, when events are generated for the port DOWN/UP and the\n""external_mac"" field gets cleared [0], this network type is not set.\n\nFor more context see bug #1842988.\n\n[0]\nhttps://github.com/openstack/networking-ovn/blob/eda5d7f80d877601170631c5f5485370ea701f42/networking_ovn/ml2/mech_driver.py#L794-L800\n\nChange-Id: Ifb795626dc9c2ac4f0104f491dd38c9b4cc902c9\nCloses-Bug: #1842988\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}, {'number': 3, 'created': '2020-01-29 09:46:05.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/services/ovn_l3/test_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c471c7330c6c7a642e11ceae5fd604177059a3e8', 'message': ""[OVN] Remove VLAN check when setting external_mac\n\nThis patch reverts [0].\n\nThe code wasn't accounting for VLAN provider networks, as stated in the\nbug #1842988, DVR won't work if the provider network (where the FIP is\ncreated) is VLAN.\n\nThere was also an incosistency in how the external_mac was set for the\nVLAN networks. Upon creating the FIP the code was checking for the\nnetwork type and not setting the external_mac attribute in case the\nnetwork was VLAN type. But, if the port went down and up again (e.g if\nyou reboot the VM) the event handler that set/unset the external_mac [1]\nwasn't check for the type. This is how people worked around the DVR\nproblem (as stated in bug #1842988).\n\nFor more information see bug #1842988.\n\n[0]\nhttps://github.com/openstack/networking-ovn/commit/c5aef51edc9843db605303ec8bd8610b6c55e9c2\n[1]\nhttps://github.com/openstack/networking-ovn/blob/eda5d7f80d877601170631c5f5485370ea701f42/networking_ovn/ml2/mech_driver.py#L794-L800\n\nChange-Id: Ifb795626dc9c2ac4f0104f491dd38c9b4cc902c9\nCloses-Bug: #1842988\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n""}]",0,703813,c471c7330c6c7a642e11ceae5fd604177059a3e8,27,7,3,6773,,,0,"[OVN] Remove VLAN check when setting external_mac

This patch reverts [0].

The code wasn't accounting for VLAN provider networks, as stated in the
bug #1842988, DVR won't work if the provider network (where the FIP is
created) is VLAN.

There was also an incosistency in how the external_mac was set for the
VLAN networks. Upon creating the FIP the code was checking for the
network type and not setting the external_mac attribute in case the
network was VLAN type. But, if the port went down and up again (e.g if
you reboot the VM) the event handler that set/unset the external_mac [1]
wasn't check for the type. This is how people worked around the DVR
problem (as stated in bug #1842988).

For more information see bug #1842988.

[0]
https://github.com/openstack/networking-ovn/commit/c5aef51edc9843db605303ec8bd8610b6c55e9c2
[1]
https://github.com/openstack/networking-ovn/blob/eda5d7f80d877601170631c5f5485370ea701f42/networking_ovn/ml2/mech_driver.py#L794-L800

Change-Id: Ifb795626dc9c2ac4f0104f491dd38c9b4cc902c9
Closes-Bug: #1842988
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/13/703813/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/services/ovn_l3/test_plugin.py']",2,09b02b7db9aee1f9d8c4e02c24f0ae464658318d,bug/1842988-external_mac," def test_update_floatingip_associate_distributed(self, uf, gf, gp, gn): fake_network_vlan[pnet.NETWORK_TYPE] = constants.TYPE_FLAT self.l3_inst._ovn.add_nat_rule_in_lrouter.assert_called_once_with( 'neutron-new-router-id', type='dnat_and_snat', logical_ip='10.10.10.10', external_ip='192.168.0.10', external_mac='00:01:02:03:04:05', logical_port='new-port_id', external_ids=expected_ext_ids)"," def _test_update_floatingip_associate_distributed(self, network_type, uf, gf, gp, gn): fake_network_vlan[pnet.NETWORK_TYPE] = network_type if network_type == constants.TYPE_VLAN: self.l3_inst._ovn.add_nat_rule_in_lrouter.assert_called_once_with( 'neutron-new-router-id', type='dnat_and_snat', logical_ip='10.10.10.10', external_ip='192.168.0.10', logical_port='new-port_id', external_ids=expected_ext_ids) else: self.l3_inst._ovn.add_nat_rule_in_lrouter.assert_called_once_with( 'neutron-new-router-id', type='dnat_and_snat', logical_ip='10.10.10.10', external_ip='192.168.0.10', external_mac='00:01:02:03:04:05', logical_port='new-port_id', external_ids=expected_ext_ids) def test_update_floatingip_associate_distributed_flat(self): self._test_update_floatingip_associate_distributed(constants.TYPE_FLAT) def test_update_floatingip_associate_distributed_vlan(self): self._test_update_floatingip_associate_distributed(constants.TYPE_VLAN)",8,22
openstack%2Foslo.log~master~I2a5a8b83d965ab6837ae01640ea4525284a0e7be,openstack/oslo.log,master,I2a5a8b83d965ab6837ae01640ea4525284a0e7be,Ignore releasenote artifacts files.,MERGED,2020-01-31 09:55:52.000000000,2020-01-31 13:10:41.000000000,2020-01-31 13:08:58.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-31 09:55:52.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/b3e9862cccac949156001f02270b0fb4e43f14c5', 'message': 'Ignore releasenote artifacts files.\n\nChange-Id: I2a5a8b83d965ab6837ae01640ea4525284a0e7be\n'}]",0,705181,b3e9862cccac949156001f02270b0fb4e43f14c5,7,2,1,28522,,,0,"Ignore releasenote artifacts files.

Change-Id: I2a5a8b83d965ab6837ae01640ea4525284a0e7be
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/81/705181/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,b3e9862cccac949156001f02270b0fb4e43f14c5,ignore_rules,RELEASENOTES.rst releasenotes/notes/reno.cache,,2,0
openstack%2Fneutron~master~I5971d078bd68c3c0b104eea0d443511e741540c4,openstack/neutron,master,I5971d078bd68c3c0b104eea0d443511e741540c4,Randomize BaseFullStackTestCase._find_available_ips,MERGED,2019-09-24 11:08:51.000000000,2020-01-31 12:51:57.000000000,2019-10-14 11:18:12.000000000,"[{'_account_id': 1131}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 30356}]","[{'number': 1, 'created': '2019-09-24 11:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/730ec3530e110a328d1b7996a3b9acbb22b9c19a', 'message': 'Randomize BaseFullStackTestCase._find_available_ips\n\nInstead of retrieving an IP address of the CIDR network in\nascending order, this patch randomizes the IP address selection.\n\nChange-Id: I5971d078bd68c3c0b104eea0d443511e741540c4\nRelated-Bug: #1808595\n'}, {'number': 2, 'created': '2019-09-24 18:18:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ecd20dabfd1aced7a2f452b323d737f541af2744', 'message': 'Randomize BaseFullStackTestCase._find_available_ips\n\nInstead of retrieving an IP address of the CIDR network in\nascending order, this patch randomizes the IP address selection.\n\nChange-Id: I5971d078bd68c3c0b104eea0d443511e741540c4\nRelated-Bug: #1808595\n'}, {'number': 3, 'created': '2019-09-25 12:42:49.000000000', 'files': ['neutron/tests/fullstack/base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/94f69ab407d081ce49fa5a93946c4cd41bf6ee89', 'message': 'Randomize BaseFullStackTestCase._find_available_ips\n\nInstead of retrieving an IP address of the CIDR network in\nascending order, this patch randomizes the IP address selection.\n\nChange-Id: I5971d078bd68c3c0b104eea0d443511e741540c4\nRelated-Bug: #1808595\n'}]",9,684279,94f69ab407d081ce49fa5a93946c4cd41bf6ee89,27,12,3,16688,,,0,"Randomize BaseFullStackTestCase._find_available_ips

Instead of retrieving an IP address of the CIDR network in
ascending order, this patch randomizes the IP address selection.

Change-Id: I5971d078bd68c3c0b104eea0d443511e741540c4
Related-Bug: #1808595
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/684279/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/fullstack/base.py'],1,730ec3530e110a328d1b7996a3b9acbb22b9c19a,bug/1808595,"import itertoolsimport random def random_ip_in_cidr(cidr): while True: num_ips = random.randrange( 1, min(netaddr.IPNetwork(cidr).size, 1000)) ip_list = list(itertools.islice( netaddr.IPNetwork(cidr).iter_hosts(), num_ips)) yield str(ip_list[-1]) for ip in random_ip_in_cidr(subnet['cidr']): if ip not in itertools.chain(used_ips, available_ips):", for ip in netaddr.IPNetwork(subnet['cidr']).iter_hosts(): ip = str(ip) if ip not in used_ips:,12,3
openstack%2Fneutron~master~I24fcecd9686ad17fa50093bb8bccab0d6c711298,openstack/neutron,master,I24fcecd9686ad17fa50093bb8bccab0d6c711298,Remove L3 IP QoS cache when router is down,MERGED,2019-04-28 03:16:27.000000000,2020-01-31 12:12:19.000000000,2019-08-22 05:17:50.000000000,"[{'_account_id': 841}, {'_account_id': 4694}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 11975}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 20147}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27609}, {'_account_id': 30388}, {'_account_id': 30413}]","[{'number': 1, 'created': '2019-04-28 03:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e9980a235e02f05516ce83ef62ad381a5b2ec8ff', 'message': ""Remove L3 IP QoS cache when router is down\n\nWhen router admin-state is down or removed, fip-qos and gateway-ip-qos\nextension should delete the router IPs' QoS rate limit cache. Then if\nthe router is up again the router floating IPs QoS can be reconfigured.\nThis patch achives these:\n1. make sure floating IP or gateway IP QoS cache removed.\n2. floating IP QoS can be re-configured to snat device when router\n   doing admin_state down/up.\n\nCloses-Bug: #1826695\nChange-Id: I24fcecd9686ad17fa50093bb8bccab0d6c711298\n""}, {'number': 2, 'created': '2019-05-18 04:41:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a47d26943ad0be0944a0d71ffddf06e6024841b9', 'message': ""Remove L3 IP QoS cache when router is down\n\nWhen router admin-state is down or removed, fip-qos and gateway-ip-qos\nextension should delete the router IPs' QoS rate limit cache. Then if\nthe router is up again the router floating IPs QoS can be reconfigured.\nThis patch achives these:\n1. make sure floating IP or gateway IP QoS cache removed.\n2. floating IP QoS can be re-configured to snat device when router\n   doing admin_state down/up.\n\nCloses-Bug: #1826695\nChange-Id: I24fcecd9686ad17fa50093bb8bccab0d6c711298\n""}, {'number': 3, 'created': '2019-05-22 09:42:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c9da5c0c513f201704367f5ed3d483c1791f8d44', 'message': ""Remove L3 IP QoS cache when router is down\n\nWhen router admin-state is down or removed, fip-qos and gateway-ip-qos\nextension should delete the router IPs' QoS rate limit cache. Then if\nthe router is up again the router floating IPs QoS can be reconfigured.\nThis patch achives these:\n1. make sure floating IP or gateway IP QoS cache removed.\n2. floating IP QoS can be re-configured to snat device when router\n   doing admin_state down/up.\n\nCloses-Bug: #1826695\nChange-Id: I24fcecd9686ad17fa50093bb8bccab0d6c711298\n""}, {'number': 4, 'created': '2019-05-22 13:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b5c3fdfa85444b8a69d87206f2be9b9da46dd447', 'message': ""Remove L3 IP QoS cache when router is down\n\nWhen router admin-state is down or removed, fip-qos and gateway-ip-qos\nextension should delete the router IPs' QoS rate limit cache. Then if\nthe router is up again the router floating IPs QoS can be reconfigured.\nThis patch achives these:\n1. make sure floating IP or gateway IP QoS cache removed.\n2. floating IP QoS can be re-configured to snat device when router\n   doing admin_state down/up.\n\nCloses-Bug: #1826695\nChange-Id: I24fcecd9686ad17fa50093bb8bccab0d6c711298\n""}, {'number': 5, 'created': '2019-05-23 10:26:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/23fe1b77561500d42abc9b1c5475ec278015ab88', 'message': ""Remove L3 IP QoS cache when router is down\n\nWhen router admin-state is down or removed, fip-qos and gateway-ip-qos\nextension should delete the router IPs' QoS rate limit cache. Then if\nthe router is up again the router floating IPs QoS can be reconfigured.\nThis patch achives these:\n1. make sure floating IP or gateway IP QoS cache removed.\n2. floating IP QoS can be re-configured to snat device when router\n   doing admin_state down/up.\n\nCloses-Bug: #1826695\nChange-Id: I24fcecd9686ad17fa50093bb8bccab0d6c711298\n""}, {'number': 6, 'created': '2019-05-29 16:00:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/84ea9db8e4027cef58d040d8525f740bc55dee86', 'message': ""Remove L3 IP QoS cache when router is down\n\nWhen router admin-state is down or removed, fip-qos and gateway-ip-qos\nextension should delete the router IPs' QoS rate limit cache. Then if\nthe router is up again the router floating IPs QoS can be reconfigured.\nThis patch achives these:\n1. make sure floating IP or gateway IP QoS cache removed.\n2. floating IP QoS can be re-configured to snat device when router\n   doing admin_state down/up.\n\nCloses-Bug: #1826695\nChange-Id: I24fcecd9686ad17fa50093bb8bccab0d6c711298\n""}, {'number': 7, 'created': '2019-06-02 13:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ad8129b15cefac53cf640f29436b8aefa6b77c6c', 'message': ""Remove L3 IP QoS cache when router is down\n\nWhen router admin-state is down or removed, fip-qos and gateway-ip-qos\nextension should delete the router IPs' QoS rate limit cache. Then if\nthe router is up again the router floating IPs QoS can be reconfigured.\nThis patch achives these:\n1. make sure floating IP or gateway IP QoS cache removed.\n2. floating IP QoS can be re-configured to snat device when router\n   doing admin_state down/up.\n\nCloses-Bug: #1826695\nChange-Id: I24fcecd9686ad17fa50093bb8bccab0d6c711298\n""}, {'number': 8, 'created': '2019-06-02 13:20:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/803a66a9963d8c96c25990a81662047abdda80d6', 'message': ""Remove L3 IP QoS cache when router is down\n\nWhen router admin-state is down or removed, fip-qos and gateway-ip-qos\nextension should delete the router IPs' QoS rate limit cache. Then if\nthe router is up again the router floating IPs QoS can be reconfigured.\nThis patch achives these:\n1. make sure floating IP or gateway IP QoS cache removed.\n2. floating IP QoS can be re-configured to snat device when router\n   doing admin_state down/up.\n\nCloses-Bug: #1826695\nChange-Id: I24fcecd9686ad17fa50093bb8bccab0d6c711298\n""}, {'number': 9, 'created': '2019-06-06 02:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/122a7a37baf685cba463d9074af794d70e4175a5', 'message': ""Remove L3 IP QoS cache when router is down\n\nWhen router admin-state is down or removed, fip-qos and gateway-ip-qos\nextension should delete the router IPs' QoS rate limit cache. Then if\nthe router is up again the router floating IPs QoS can be reconfigured.\nThis patch achives these:\n1. make sure floating IP or gateway IP QoS cache removed.\n2. floating IP QoS can be re-configured to snat device when router\n   doing admin_state down/up.\n\nCloses-Bug: #1826695\nChange-Id: I24fcecd9686ad17fa50093bb8bccab0d6c711298\n""}, {'number': 10, 'created': '2019-06-14 09:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6f12cac165afac17136a99774156cfc762898c96', 'message': ""Remove L3 IP QoS cache when router is down\n\nWhen router admin-state is down or removed, fip-qos and gateway-ip-qos\nextension should delete the router IPs' QoS rate limit cache. Then if\nthe router is up again the router floating IPs QoS can be reconfigured.\nThis patch achives these:\n1. make sure floating IP or gateway IP QoS cache removed.\n2. floating IP QoS can be re-configured to snat device when router\n   doing admin_state down/up.\n\nCloses-Bug: #1826695\nChange-Id: I24fcecd9686ad17fa50093bb8bccab0d6c711298\n""}, {'number': 11, 'created': '2019-07-02 15:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/754c0da4415596e8fc0f0253c5343e248fb08ebb', 'message': ""Remove L3 IP QoS cache when router is down\n\nWhen router admin-state is down or removed, fip-qos and gateway-ip-qos\nextension should delete the router IPs' QoS rate limit cache. Then if\nthe router is up again the router floating IPs QoS can be reconfigured.\nThis patch achives these:\n1. make sure floating IP or gateway IP QoS cache removed.\n2. floating IP QoS can be re-configured to snat device when router\n   doing admin_state down/up.\n\nCloses-Bug: #1826695\nChange-Id: I24fcecd9686ad17fa50093bb8bccab0d6c711298\n""}, {'number': 12, 'created': '2019-07-02 23:24:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b8ee0395e22c08bb4e6543775214f4c3bd4ff0bd', 'message': ""Remove L3 IP QoS cache when router is down\n\nWhen router admin-state is down or removed, fip-qos and gateway-ip-qos\nextension should delete the router IPs' QoS rate limit cache. Then if\nthe router is up again the router floating IPs QoS can be reconfigured.\nThis patch achives these:\n1. make sure floating IP or gateway IP QoS cache removed.\n2. floating IP QoS can be re-configured to snat device when router\n   doing admin_state down/up.\n\nCloses-Bug: #1826695\nChange-Id: I24fcecd9686ad17fa50093bb8bccab0d6c711298\n""}, {'number': 13, 'created': '2019-08-06 15:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cf783d42b1d28da63dd6868ee42200b45968440f', 'message': ""Remove L3 IP QoS cache when router is down\n\nWhen router admin-state is down or removed, fip-qos and gateway-ip-qos\nextension should delete the router IPs' QoS rate limit cache. Then if\nthe router is up again the router floating IPs QoS can be reconfigured.\nThis patch achives these:\n1. make sure floating IP or gateway IP QoS cache removed.\n2. floating IP QoS can be re-configured to snat device when router\n   doing admin_state down/up.\n\nCloses-Bug: #1826695\nChange-Id: I24fcecd9686ad17fa50093bb8bccab0d6c711298\n""}, {'number': 14, 'created': '2019-08-16 15:40:49.000000000', 'files': ['neutron/tests/unit/agent/l3/extensions/qos/test_fip.py', 'neutron/tests/fullstack/resources/client.py', 'neutron/agent/l3/extensions/qos/fip.py', 'neutron/tests/unit/agent/l3/extensions/qos/test_gateway_ip.py', 'neutron/tests/fullstack/resources/environment.py', 'neutron/tests/fullstack/resources/config.py', 'neutron/tests/fullstack/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/78629e0d3780af4a8a8cc1b5b0762e0bc8a48f1f', 'message': ""Remove L3 IP QoS cache when router is down\n\nWhen router admin-state is down or removed, fip-qos and gateway-ip-qos\nextension should delete the router IPs' QoS rate limit cache. Then if\nthe router is up again the router floating IPs QoS can be reconfigured.\nThis patch achives these:\n1. make sure floating IP or gateway IP QoS cache removed.\n2. floating IP QoS can be re-configured to snat device when router\n   doing admin_state down/up.\n\nCloses-Bug: #1826695\nChange-Id: I24fcecd9686ad17fa50093bb8bccab0d6c711298\n""}]",32,656105,78629e0d3780af4a8a8cc1b5b0762e0bc8a48f1f,126,14,14,9531,,,0,"Remove L3 IP QoS cache when router is down

When router admin-state is down or removed, fip-qos and gateway-ip-qos
extension should delete the router IPs' QoS rate limit cache. Then if
the router is up again the router floating IPs QoS can be reconfigured.
This patch achives these:
1. make sure floating IP or gateway IP QoS cache removed.
2. floating IP QoS can be re-configured to snat device when router
   doing admin_state down/up.

Closes-Bug: #1826695
Change-Id: I24fcecd9686ad17fa50093bb8bccab0d6c711298
",git fetch https://review.opendev.org/openstack/neutron refs/changes/05/656105/14 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/agent/l3/extensions/qos/test_fip.py', 'neutron/agent/l3/extensions/qos/fip.py', 'neutron/tests/unit/agent/l3/extensions/qos/test_gateway_ip.py']",3,e9980a235e02f05516ce83ef62ad381a5b2ec8ff,bug/1826695," def test_delete_router(self): tc_wrapper = mock.Mock() with mock.patch.object(self.gw_ip_qos_ext, '_get_tc_wrapper', return_value=tc_wrapper): self.gw_ip_qos_ext.add_router(self.context, self.router) tc_wrapper.set_ip_rate_limit.assert_has_calls( [mock.call(lib_const.INGRESS_DIRECTION, TEST_QOS_GW_IP, 1111, 2222), mock.call(lib_const.EGRESS_DIRECTION, TEST_QOS_GW_IP, 3333, 4444)], any_order=True) self.gw_ip_qos_ext.delete_router(self.context, self.router) self.assertIsNone( self.gw_ip_qos_ext.gateway_ip_qos_map.get_resource_policy( self.router_info.router_id)) ",,61,6
openstack%2Fneutron~master~I8d206f909b09f1279dfcdc25c39989a67bff93d5,openstack/neutron,master,I8d206f909b09f1279dfcdc25c39989a67bff93d5,Fix bug: AttributeError arises while sorting with standard attributes,MERGED,2019-04-19 03:35:44.000000000,2020-01-31 11:48:06.000000000,2019-06-02 03:48:33.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 9200}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 22378}, {'_account_id': 23312}, {'_account_id': 26458}, {'_account_id': 26622}, {'_account_id': 28889}]","[{'number': 1, 'created': '2019-04-19 03:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8fbac83dec9a55606b9be91b57655fbed1379bdb', 'message': 'Fix bug: AttributeError arises while sorting with standard attributes\n\nChange-Id: I8d206f909b09f1279dfcdc25c39989a67bff93d5\nCloses-Bug: #1659175\n'}, {'number': 2, 'created': '2019-04-30 01:26:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6c9f7e8f2e60b8d7a20118eeca2b8d8826d61301', 'message': ""Fix bug: AttributeError arises while sorting with standard attributes\n\nCommon neutron resource(e.g, Port) consists of:\n1. Resource Attributes, e.g: Port.mac_address, etc.\n2. Standard Attributes, e.g: ctrated_at, and are shared among all\n   neutron resources.\nThe `sort` opt only supports limited Resource Attributes. We need\nto filter standard attrs (in neutron.api_commons.`get_sorts`) and\nit's preferred to explicitly warn CLI & API users of illegal sort\nkeys rather than just accept & un-check & pass-forward and then hit\na internal error which's quite confusing.\n\nChange-Id: I8d206f909b09f1279dfcdc25c39989a67bff93d5\nCloses-Bug: #1659175\n""}, {'number': 3, 'created': '2019-05-07 11:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e6b7ad5e3894a5d75dff89ec20571b1c0d82f4e5', 'message': ""Fix bug: AttributeError arises while sorting with standard attributes\n\nCommon neutron resource(e.g, Port) consists of:\n1. Resource Attributes, e.g: Port.mac_address, etc.\n2. Standard Attributes, e.g: created_at, and are shared among all\n   neutron resources.\nThe `sort` opt only supports limited Resource Attributes. We need\nto filter standard attrs (neutron.api.api_commons.`get_sorts`) and\nit's preferred to explicitly warn CLI & API users of illegal sort\nkeys rather than just accept & un-check & pass-forward and then hit\na internal error which's quite confusing.\n\nChange-Id: I8d206f909b09f1279dfcdc25c39989a67bff93d5\nCloses-Bug: #1659175\n""}, {'number': 4, 'created': '2019-05-07 17:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/69da1f0c7ce1836c7f089f395c65271d95343d75', 'message': ""Fix bug: AttributeError arises while sorting with standard attributes\n\nCommon neutron resource(e.g, Port) consists of:\n1. Resource Attributes, e.g: Port.mac_address, etc.\n2. Standard Attributes, e.g: created_at, and are shared among all\n   neutron resources.\nThe `sort` opt only supports limited Resource Attributes. We need\nto filter standard attrs (neutron.api.api_commons.`get_sorts`) and\nit's preferred to explicitly warn CLI & API users of illegal sort\nkeys rather than just accept & un-check & pass-forward and then hit\na internal error which's quite confusing.\n\nChange-Id: I8d206f909b09f1279dfcdc25c39989a67bff93d5\nCloses-Bug: #1659175\n""}, {'number': 5, 'created': '2019-05-07 17:34:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c838ffe1e2f1cece97c192a5e20d5964316c8da7', 'message': ""Fix bug: AttributeError arises while sorting with standard attributes\n\nCommon neutron resource(e.g, Port) consists of:\n1. Resource Attributes, e.g: Port.mac_address, etc.\n2. Standard Attributes, e.g: created_at, and are shared among all\n   neutron resources.\nThe `sort` opt only supports limited Resource Attributes. We need\nto filter standard attrs (neutron.api.api_commons.`get_sorts`) and\nit's preferred to explicitly warn CLI & API users of illegal sort\nkeys rather than just accept & un-check & pass-forward and then hit\na internal error which's quite confusing.\n\nChange-Id: I8d206f909b09f1279dfcdc25c39989a67bff93d5\nCloses-Bug: #1659175\n""}, {'number': 6, 'created': '2019-05-08 01:26:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fc825a3f9b0df9a2002ffac774178569f711d23f', 'message': ""Fix bug: AttributeError arises while sorting with standard attributes\n\nCommon neutron resource(e.g, Port) consists of:\n1. Resource Attributes, e.g: Port.mac_address, etc.\n2. Standard Attributes, e.g: created_at, and are shared among all\n   neutron resources.\nThe `sort` opt only supports limited Resource Attributes. We need\nto filter standard attrs (neutron.api.api_commons.`get_sorts`) and\nit's preferred to explicitly warn CLI & API users of illegal sort\nkeys rather than just accept & un-check & pass-forward and then hit\na internal error which's quite confusing.\n\nChange-Id: I8d206f909b09f1279dfcdc25c39989a67bff93d5\nCloses-Bug: #1659175\n""}, {'number': 7, 'created': '2019-05-08 07:34:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/79f3af8d8501497ef23690a1fe2fd89e73457af2', 'message': ""Fix bug: AttributeError arises while sorting with standard attributes\n\nCommon neutron resource(e.g, Port) consists of:\n1. Resource Attributes, e.g: Port.mac_address, etc.\n2. Standard Attributes, e.g: created_at, and are shared among all\n   neutron resources.\nThe `sort` opt only supports limited Resource Attributes. We need\nto filter standard attrs (neutron.api.api_commons.`get_sorts`) and\nit's preferred to explicitly warn CLI & API users of illegal sort\nkeys rather than just accept & un-check & pass-forward and then hit\na internal error which's quite confusing.\n\nChange-Id: I8d206f909b09f1279dfcdc25c39989a67bff93d5\nCloses-Bug: #1659175\n""}, {'number': 8, 'created': '2019-05-15 08:28:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0f19243e10baa4072ec683ed129efe6fd58d3832', 'message': ""Fix bug: AttributeError arises while sorting with standard attributes\n\nCommon neutron resource(e.g, Port) consists of:\n1. Resource Attributes, e.g: Port.mac_address, etc.\n2. Standard Attributes, e.g: created_at, and are shared among all\n   neutron resources.\nThe `sort` opt only supports limited attributes. We need to filter\nattributes that are defined with `is_sort_key=True` and it's preferred\nto explicitly warn CLI & API users of illegal sort keys rather than\njust accept without check, pass forward and then hit a internal error\nwhich's quite confusing.\n\nDepends-on: https://review.opendev.org/#/c/657913/\nChange-Id: I8d206f909b09f1279dfcdc25c39989a67bff93d5\nCloses-Bug: #1659175\n""}, {'number': 9, 'created': '2019-05-16 00:51:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b6877069c0c660111c3134b59cdd8e97820bf750', 'message': ""Fix bug: AttributeError arises while sorting with standard attributes\n\nCommon neutron resource(e.g, Port) consists of:\n1. Resource Attributes, e.g: Port.mac_address, etc.\n2. Standard Attributes, e.g: created_at, and are shared among all\n   neutron resources.\nThe `sort` opt only supports limited attributes. We need to filter\nattributes that are defined with `is_sort_key=True` and it's preferred\nto explicitly warn CLI & API users of illegal sort keys rather than\njust accept without check, pass forward and then hit a internal error\nwhich's quite confusing.\n\nDepends-on: https://review.opendev.org/#/c/657913/\nChange-Id: I8d206f909b09f1279dfcdc25c39989a67bff93d5\nCloses-Bug: #1659175\n""}, {'number': 10, 'created': '2019-05-17 07:06:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0a2aa9243dbf0fe959b61c2cf2b78118a5feaccf', 'message': ""Fix bug: AttributeError arises while sorting with standard attributes\n\nCommon neutron resource(e.g, Port) consists of:\n1. Resource Attributes, e.g: Port.mac_address, etc.\n2. Standard Attributes, e.g: created_at, and are shared among all\n   neutron resources.\nThe `sort` opt only supports limited attributes. We need to filter\nattributes that are defined with `is_sort_key=True` and it's preferred\nto explicitly warn CLI & API users of illegal sort keys rather than\njust accept without check, pass forward and then hit a internal error\nwhich's quite confusing.\n\nDepends-on: https://review.opendev.org/#/c/657913/\nChange-Id: I8d206f909b09f1279dfcdc25c39989a67bff93d5\nCloses-Bug: #1659175\n""}, {'number': 11, 'created': '2019-05-17 12:43:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1addc422b0fc81ae1a5b499e2acea91a150f81fd', 'message': ""Fix bug: AttributeError arises while sorting with standard attributes\n\nCommon neutron resource(e.g, Port) consists of:\n1. Resource Attributes, e.g: Port.mac_address, etc.\n2. Standard Attributes, e.g: created_at, and are shared among all\n   neutron resources.\nThe `sort` opt only supports limited attributes. We need to filter\nattributes that are defined with `is_sort_key=True` and it's preferred\nto explicitly warn CLI & API users of illegal sort keys rather than\njust accept without check, pass forward and then hit a internal error\nwhich's quite confusing.\n\nDepends-on: https://review.opendev.org/#/c/657913/\nChange-Id: I8d206f909b09f1279dfcdc25c39989a67bff93d5\nCloses-Bug: #1659175\n""}, {'number': 12, 'created': '2019-05-17 12:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4bc3bddb56cfb786c498a2a918312aa54676eeab', 'message': ""Fix bug: AttributeError arises while sorting with standard attributes\n\nCommon neutron resource(e.g, Port) consists of:\n1. Resource Attributes, e.g: Port.mac_address, etc.\n2. Standard Attributes, e.g: created_at, and are shared among all\n   neutron resources.\nThe `sort` opt only supports limited attributes. We need to filter\nattributes that are defined with `is_sort_key=True` and it's preferred\nto explicitly warn CLI & API users of illegal sort keys rather than\njust accept without check, pass forward and then hit a internal error\nwhich's quite confusing.\n\nDepends-on: https://review.opendev.org/#/c/657913/\nChange-Id: I8d206f909b09f1279dfcdc25c39989a67bff93d5\nCloses-Bug: #1659175\n""}, {'number': 13, 'created': '2019-05-17 12:55:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c4c8d5aef34369af260a76c7f80c50b168a0e27e', 'message': ""Fix bug: AttributeError arises while sorting with standard attributes\n\nCommon neutron resource(e.g, Port) consists of:\n1. Resource Attributes, e.g: Port.mac_address, etc.\n2. Standard Attributes, e.g: created_at, and are shared among all\n   neutron resources.\nThe `sort` opt only supports limited attributes. We need to filter\nattributes that are defined with `is_sort_key=True` and it's preferred\nto explicitly warn CLI & API users of illegal sort keys rather than\njust accept without check, pass forward and then hit a internal error\nwhich's quite confusing.\n\nDepends-on: https://review.opendev.org/#/c/657913/\nChange-Id: I8d206f909b09f1279dfcdc25c39989a67bff93d5\nCloses-Bug: #1659175\n""}, {'number': 14, 'created': '2019-05-31 06:00:28.000000000', 'files': ['neutron/tests/unit/api/v2/test_base.py', 'neutron/api/api_common.py', 'releasenotes/notes/add-sort-keys-check-for-get-sorts-b9e3e86ddcb3bc3a.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/335ac4e2d95c164d66a3b09d9fd08e9c563edfc2', 'message': ""Fix bug: AttributeError arises while sorting with standard attributes\n\nCommon neutron resource(e.g, Port) consists of:\n1. Resource Attributes, e.g: Port.mac_address, etc.\n2. Standard Attributes, e.g: created_at, and are shared among all\n   neutron resources.\nThe `sort` opt only supports limited attributes. We need to filter\nattributes that are defined with `is_sort_key=True` and it's preferred\nto explicitly warn CLI & API users of illegal sort keys rather than\njust accept without check, pass forward and then hit a internal error\nwhich's quite confusing.\n\nDepends-on: https://review.opendev.org/#/c/660097/\nChange-Id: I8d206f909b09f1279dfcdc25c39989a67bff93d5\nCloses-Bug: #1659175\n""}]",26,653903,335ac4e2d95c164d66a3b09d9fd08e9c563edfc2,128,17,14,28889,,,0,"Fix bug: AttributeError arises while sorting with standard attributes

Common neutron resource(e.g, Port) consists of:
1. Resource Attributes, e.g: Port.mac_address, etc.
2. Standard Attributes, e.g: created_at, and are shared among all
   neutron resources.
The `sort` opt only supports limited attributes. We need to filter
attributes that are defined with `is_sort_key=True` and it's preferred
to explicitly warn CLI & API users of illegal sort keys rather than
just accept without check, pass forward and then hit a internal error
which's quite confusing.

Depends-on: https://review.opendev.org/#/c/660097/
Change-Id: I8d206f909b09f1279dfcdc25c39989a67bff93d5
Closes-Bug: #1659175
",git fetch https://review.opendev.org/openstack/neutron refs/changes/03/653903/8 && git format-patch -1 --stdout FETCH_HEAD,['neutron/api/api_common.py'],1,8fbac83dec9a55606b9be91b57655fbed1379bdb,bug/1659175,from neutron.db.standard_attr import StandardAttribute as standard_attr sa_dict = standard_attr.__dict__ valid_keys = set(attr_info.keys()) - set(sa_dict.keys()) | set(['id']) absent_keys = [x for x in sort_keys if x not in valid_keys], absent_keys = [x for x in sort_keys if x not in attr_info],4,1
openstack%2Fneutron~master~I943e6397319b9a4a7fc1a5b3acb721920ddffb02,openstack/neutron,master,I943e6397319b9a4a7fc1a5b3acb721920ddffb02,Define orm relationships after db classes,MERGED,2019-05-16 09:47:36.000000000,2020-01-31 11:34:22.000000000,2019-05-24 16:27:56.000000000,"[{'_account_id': 5948}, {'_account_id': 7249}, {'_account_id': 9373}, {'_account_id': 11816}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 30427}]","[{'number': 1, 'created': '2019-05-16 09:47:36.000000000', 'files': ['neutron/db/models/flavor.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/38daf9eaae8538c74933b19c952ad0612751c027', 'message': 'Define orm relationships after db classes\n\nThis is to fix race conditions on neutron server init.\nPlease see bug for details.\n\nChange-Id: I943e6397319b9a4a7fc1a5b3acb721920ddffb02\nPartial-Bug: #1824299\n'}]",1,659511,38daf9eaae8538c74933b19c952ad0612751c027,16,10,1,5948,,,0,"Define orm relationships after db classes

This is to fix race conditions on neutron server init.
Please see bug for details.

Change-Id: I943e6397319b9a4a7fc1a5b3acb721920ddffb02
Partial-Bug: #1824299
",git fetch https://review.opendev.org/openstack/neutron refs/changes/11/659511/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/models/flavor.py'],1,38daf9eaae8538c74933b19c952ad0612751c027,bug/1824299," flavor = orm.relationship(Flavor, backref=orm.backref( ""service_profiles"", lazy='subquery', cascade=""all, delete-orphan"")) service_profile = orm.relationship(ServiceProfile, backref=""flavors"")"," service_profiles = orm.relationship(""FlavorServiceProfileBinding"", cascade=""all, delete-orphan"", lazy=""subquery"") flavors = orm.relationship(""FlavorServiceProfileBinding"") flavor = orm.relationship(Flavor) service_profile = orm.relationship(ServiceProfile)",7,6
openstack%2Fopenstack-ansible-os_tempest~master~Ic146e011ec15889303061527e17cdc16ed914799,openstack/openstack-ansible-os_tempest,master,Ic146e011ec15889303061527e17cdc16ed914799,Always use virtualenv and pip to install tempest on Ubuntu,MERGED,2020-01-28 13:56:14.000000000,2020-01-31 11:19:43.000000000,2020-01-31 11:17:24.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-01-28 13:56:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/8038523d9a34339204b92e129f4d22462e3ac527', 'message': ""[WIP] Always use virtualenv and pip to install tempest on Ubuntu\n\nFor ubuntu distro jobs there are no tempest plugins packages so drop the\n'mixed setup' where tempest comes from a distro package and the plugins\ncome from pip, and then fail to install into the system python environment.\n\nChange-Id: Ic146e011ec15889303061527e17cdc16ed914799\n""}, {'number': 2, 'created': '2020-01-28 15:57:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/ab2580d65181ce46aa3a2632eab8ebe7a1c393b6', 'message': ""[WIP] Always use virtualenv and pip to install tempest on Ubuntu\n\nFor ubuntu distro jobs there are no tempest plugins packages so drop the\n'mixed setup' where tempest comes from a distro package and the plugins\ncome from pip, and then fail to install into the system python environment.\n\nChange-Id: Ic146e011ec15889303061527e17cdc16ed914799\n""}, {'number': 3, 'created': '2020-01-28 15:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/0c7d26630b0baa33fe00286356a7a1ba73e0b477', 'message': ""[WIP] Always use virtualenv and pip to install tempest on Ubuntu\n\nFor ubuntu distro jobs there are no tempest plugins packages so drop the\n'mixed setup' where tempest comes from a distro package and the plugins\ncome from pip, and then fail to install into the system python environment.\n\nChange-Id: Ic146e011ec15889303061527e17cdc16ed914799\n""}, {'number': 4, 'created': '2020-01-28 16:14:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/ef9f1443903c6999359440c849eb350b3be9e5ae', 'message': ""[WIP] Always use virtualenv and pip to install tempest on Ubuntu\n\nFor ubuntu distro jobs there are no tempest plugins packages so drop the\n'mixed setup' where tempest comes from a distro package and the plugins\ncome from pip, and then fail to install into the system python environment.\n\nChange-Id: Ic146e011ec15889303061527e17cdc16ed914799\n""}, {'number': 5, 'created': '2020-01-28 17:28:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/b17dd79331c25dec2bc805b93939cb198fddda95', 'message': ""[WIP] Always use virtualenv and pip to install tempest on Ubuntu\n\nFor ubuntu distro jobs there are no tempest plugins packages so drop the\n'mixed setup' where tempest comes from a distro package and the plugins\ncome from pip, and then fail to install into the system python environment.\n\nChange-Id: Ic146e011ec15889303061527e17cdc16ed914799\n""}, {'number': 6, 'created': '2020-01-28 22:21:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/7da6d27d19fe3882c3c98da03f3261d92f79e947', 'message': ""[WIP] Always use virtualenv and pip to install tempest on Ubuntu\n\nFor ubuntu distro jobs there are no tempest plugins packages so drop the\n'mixed setup' where tempest comes from a distro package and the plugins\ncome from pip, and then fail to install into the system python environment.\n\nChange-Id: Ic146e011ec15889303061527e17cdc16ed914799\n""}, {'number': 7, 'created': '2020-01-29 09:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/5500fb2ea845c72f4cb799fc03977e6c0a79bfab', 'message': ""[WIP] Always use virtualenv and pip to install tempest on Ubuntu\n\nFor ubuntu distro jobs there are no tempest plugins packages so drop the\n'mixed setup' where tempest comes from a distro package and the plugins\ncome from pip, and then fail to install into the system python environment.\n\nChange-Id: Ic146e011ec15889303061527e17cdc16ed914799\n""}, {'number': 8, 'created': '2020-01-29 10:29:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/8dc770d4bbc3d68435339d84a3eada693b92bdcb', 'message': ""[WIP] Always use virtualenv and pip to install tempest on Ubuntu\n\nFor ubuntu distro jobs there are no tempest plugins packages so drop the\n'mixed setup' where tempest comes from a distro package and the plugins\ncome from pip, and then fail to install into the system python environment.\n\nChange-Id: Ic146e011ec15889303061527e17cdc16ed914799\n""}, {'number': 9, 'created': '2020-01-29 17:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/0e71f3c5f959b3c87208c20fbfee551acb086359', 'message': ""Always use virtualenv and pip to install tempest on Ubuntu\n\nFor ubuntu distro jobs there are no tempest plugins packages so drop the\n'mixed setup' where tempest comes from a distro package and the plugins\ncome from pip, and then fail to install into the system python environment.\n\nChange-Id: Ic146e011ec15889303061527e17cdc16ed914799\n""}, {'number': 10, 'created': '2020-01-30 10:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/285458d38aaaeb7ef32876f665603a0933c33043', 'message': ""Always use virtualenv and pip to install tempest on Ubuntu\n\nFor ubuntu distro jobs there are no tempest plugins packages so drop the\n'mixed setup' where tempest comes from a distro package and the plugins\ncome from pip, and then fail to install into the system python environment.\n\nChange-Id: Ic146e011ec15889303061527e17cdc16ed914799\n""}, {'number': 11, 'created': '2020-01-30 10:16:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/10232b4b37e08ed3d8ad503134bd881db1f07171', 'message': ""Always use virtualenv and pip to install tempest on Ubuntu\n\nFor ubuntu distro jobs there are no tempest plugins packages so drop the\n'mixed setup' where tempest comes from a distro package and the plugins\ncome from pip, and then fail to install into the system python environment.\n\nChange-Id: Ic146e011ec15889303061527e17cdc16ed914799\n""}, {'number': 12, 'created': '2020-01-30 10:35:45.000000000', 'files': ['tasks/main.yml', 'tasks/tempest_install_source.yml', 'tasks/tempest_install.yml', 'vars/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/61f3c986808b7270152e4a8a598bf89166a867bd', 'message': ""Always use virtualenv and pip to install tempest on Ubuntu\n\nFor ubuntu distro jobs there are no tempest plugins packages so drop the\n'mixed setup' where tempest comes from a distro package and the plugins\ncome from pip, and then fail to install into the system python environment.\n\nChange-Id: Ic146e011ec15889303061527e17cdc16ed914799\n""}]",2,704567,61f3c986808b7270152e4a8a598bf89166a867bd,41,5,12,25023,,,0,"Always use virtualenv and pip to install tempest on Ubuntu

For ubuntu distro jobs there are no tempest plugins packages so drop the
'mixed setup' where tempest comes from a distro package and the plugins
come from pip, and then fail to install into the system python environment.

Change-Id: Ic146e011ec15889303061527e17cdc16ed914799
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/67/704567/2 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/tempest_install_source.yml', 'tasks/tempest_install.yml']",3,8038523d9a34339204b92e129f4d22462e3ac527,, when: (tempest_install_method | default('source')) == 'source' or (tempest_install_method == 'distro' and ansible_distribution == 'Ubuntu'), when: (tempest_install_method | default('source')) == 'source' or (tempest_plugin_install_source | default(False)),15,10
openstack%2Fnova~stable%2Fpike~I0390c9ff51f49b063f736ca6ef868a4fa782ede5,openstack/nova,stable/pike,I0390c9ff51f49b063f736ca6ef868a4fa782ede5,Avoid redundant initialize_connection on source post live migration,MERGED,2019-09-18 23:30:46.000000000,2020-01-31 11:08:46.000000000,2020-01-27 19:18:32.000000000,"[{'_account_id': 1916}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5997}, {'_account_id': 6873}, {'_account_id': 7198}, {'_account_id': 9535}, {'_account_id': 9555}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 11604}, {'_account_id': 12898}, {'_account_id': 14595}, {'_account_id': 14892}, {'_account_id': 15334}, {'_account_id': 16128}, {'_account_id': 17068}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26286}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-09-18 23:30:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/105bc55eab6cba14a0e4dfa528ce00d8afd36831', 'message': ""WIP: Avoid redundant initialize_connection on source post live migration\n\nTODO: resolve conflicts in unit test modules\n\nDuring live migration we update bdm.connection_info for attached volumes\nin pre_live_migration to reflect the new connection on the destination\nnode. This means that after migration completes the BDM no longer has a\nreference to the original connection_info to do the detach on the source\nhost. To address this, change I3dfb75eb added a second call to\ninitialize_connection on the source host to re-fetch the source host\nconnection_info before calling disconnect.\n\nUnfortunately the cinder driver interface does not strictly require that\nmultiple calls to initialize_connection will return consistent results.\nAlthough they normally do in practice, there is at least one cinder\ndriver (delliscsi) which doesn't. This results in a failure to\ndisconnect on the source host post migration.\n\nThis change avoids the issue entirely by fetching the BDMs prior to\nmodification on the destination node. As well as working round this\nspecific issue, it also avoids a redundant cinder call in all cases.\n\nNote that this massively simplifies post_live_migration in the libvirt\ndriver. The complexity removed was concerned with reconstructing the\noriginal connection_info. This required considering the cinder v2 and v3\nuse cases, and reconstructing the multipath_id which was written to\nconnection_info by the libvirt fibrechannel volume connector on\nconnection. These things are not necessary when we just use the original\ndata unmodified.\n\nOther drivers affected are Xenapi and HyperV. Xenapi doesn't touch\nvolumes in post_live_migration, so is unaffected. HyperV did not\npreviously account for differences in connection_info between source and\ndestination, so was likely previously broken. This change should fix it.\n\nConflicts:\n      nova/compute/manager.py\n      nova/objects/migrate_data.py\n      nova/tests/unit/compute/test_compute.py\n      nova/tests/unit/compute/test_compute_mgr.py\n      nova/tests/unit/virt/libvirt/test_driver.py\n      nova/virt/libvirt/driver.py\n\nNOTE(mriedem): The conflicts are primarily due to not having change\nI0bfb11296430dfffe9b091ae7c3a793617bd9d0d in Pike. In addition, the\nlibvirt driver conflicts are also due to not having change\nI61a0bee9e71e9a67f6a7c04a7bfd6e77fe818a77 nor change\nIca323b87fa85a454fca9d46ada3677f18fe50022 in Pike.\n\nCloses-Bug: #1754716\nCloses-Bug: #1814245\nChange-Id: I0390c9ff51f49b063f736ca6ef868a4fa782ede5\n(cherry picked from commit b626c0dc7b113365002e743e6de2aeb40121fc81)\n(cherry picked from commit 75e0f5a9b18293546db0ddf0fb073854e6704115)\n(cherry picked from commit 013f421bca4067bd430a9fac1e3b290cf1388ee4)\n""}, {'number': 2, 'created': '2019-09-19 18:10:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b5d12853c3f8f35bfc04f6e2d28650a961bee46e', 'message': ""WIP: Avoid redundant initialize_connection on source post live migration\n\nTODO: resolve conflicts in unit test modules\n\nDuring live migration we update bdm.connection_info for attached volumes\nin pre_live_migration to reflect the new connection on the destination\nnode. This means that after migration completes the BDM no longer has a\nreference to the original connection_info to do the detach on the source\nhost. To address this, change I3dfb75eb added a second call to\ninitialize_connection on the source host to re-fetch the source host\nconnection_info before calling disconnect.\n\nUnfortunately the cinder driver interface does not strictly require that\nmultiple calls to initialize_connection will return consistent results.\nAlthough they normally do in practice, there is at least one cinder\ndriver (delliscsi) which doesn't. This results in a failure to\ndisconnect on the source host post migration.\n\nThis change avoids the issue entirely by fetching the BDMs prior to\nmodification on the destination node. As well as working round this\nspecific issue, it also avoids a redundant cinder call in all cases.\n\nNote that this massively simplifies post_live_migration in the libvirt\ndriver. The complexity removed was concerned with reconstructing the\noriginal connection_info. This required considering the cinder v2 and v3\nuse cases, and reconstructing the multipath_id which was written to\nconnection_info by the libvirt fibrechannel volume connector on\nconnection. These things are not necessary when we just use the original\ndata unmodified.\n\nOther drivers affected are Xenapi and HyperV. Xenapi doesn't touch\nvolumes in post_live_migration, so is unaffected. HyperV did not\npreviously account for differences in connection_info between source and\ndestination, so was likely previously broken. This change should fix it.\n\nConflicts:\n      nova/compute/manager.py\n      nova/objects/migrate_data.py\n      nova/tests/unit/compute/test_compute.py\n      nova/tests/unit/compute/test_compute_mgr.py\n      nova/tests/unit/virt/libvirt/test_driver.py\n      nova/virt/libvirt/driver.py\n\nNOTE(mriedem): The conflicts are primarily due to not having change\nI0bfb11296430dfffe9b091ae7c3a793617bd9d0d in Pike. In addition, the\nlibvirt driver conflicts are also due to not having change\nI61a0bee9e71e9a67f6a7c04a7bfd6e77fe818a77 nor change\nIca323b87fa85a454fca9d46ada3677f18fe50022 in Pike.\n\nCloses-Bug: #1754716\nCloses-Bug: #1814245\nChange-Id: I0390c9ff51f49b063f736ca6ef868a4fa782ede5\n(cherry picked from commit b626c0dc7b113365002e743e6de2aeb40121fc81)\n(cherry picked from commit 75e0f5a9b18293546db0ddf0fb073854e6704115)\n(cherry picked from commit 013f421bca4067bd430a9fac1e3b290cf1388ee4)\n""}, {'number': 3, 'created': '2019-09-20 14:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/960218ff9167d8e6a3273804c19207aa50c4dba4', 'message': ""WIP: Avoid redundant initialize_connection on source post live migration\n\nTODO: resolve conflicts in unit test modules\n\nDuring live migration we update bdm.connection_info for attached volumes\nin pre_live_migration to reflect the new connection on the destination\nnode. This means that after migration completes the BDM no longer has a\nreference to the original connection_info to do the detach on the source\nhost. To address this, change I3dfb75eb added a second call to\ninitialize_connection on the source host to re-fetch the source host\nconnection_info before calling disconnect.\n\nUnfortunately the cinder driver interface does not strictly require that\nmultiple calls to initialize_connection will return consistent results.\nAlthough they normally do in practice, there is at least one cinder\ndriver (delliscsi) which doesn't. This results in a failure to\ndisconnect on the source host post migration.\n\nThis change avoids the issue entirely by fetching the BDMs prior to\nmodification on the destination node. As well as working round this\nspecific issue, it also avoids a redundant cinder call in all cases.\n\nNote that this massively simplifies post_live_migration in the libvirt\ndriver. The complexity removed was concerned with reconstructing the\noriginal connection_info. This required considering the cinder v2 and v3\nuse cases, and reconstructing the multipath_id which was written to\nconnection_info by the libvirt fibrechannel volume connector on\nconnection. These things are not necessary when we just use the original\ndata unmodified.\n\nOther drivers affected are Xenapi and HyperV. Xenapi doesn't touch\nvolumes in post_live_migration, so is unaffected. HyperV did not\npreviously account for differences in connection_info between source and\ndestination, so was likely previously broken. This change should fix it.\n\nConflicts:\n      nova/compute/manager.py\n      nova/objects/migrate_data.py\n      nova/tests/unit/compute/test_compute.py\n      nova/tests/unit/compute/test_compute_mgr.py\n      nova/tests/unit/virt/libvirt/test_driver.py\n      nova/virt/libvirt/driver.py\n\nNOTE(mriedem): The conflicts are primarily due to not having change\nI0bfb11296430dfffe9b091ae7c3a793617bd9d0d in Pike. In addition, the\nlibvirt driver conflicts are also due to not having change\nI61a0bee9e71e9a67f6a7c04a7bfd6e77fe818a77 nor change\nIca323b87fa85a454fca9d46ada3677f18fe50022 in Pike.\n\nCloses-Bug: #1754716\nCloses-Bug: #1814245\nChange-Id: I0390c9ff51f49b063f736ca6ef868a4fa782ede5\n(cherry picked from commit b626c0dc7b113365002e743e6de2aeb40121fc81)\n(cherry picked from commit 75e0f5a9b18293546db0ddf0fb073854e6704115)\n(cherry picked from commit 013f421bca4067bd430a9fac1e3b290cf1388ee4)\n""}, {'number': 4, 'created': '2019-09-24 19:54:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/66ba08b42d444c7b9ae6b2fae9554111b3f31519', 'message': ""WIP: Avoid redundant initialize_connection on source post live migration\n\nTODO: resolve conflicts in unit test modules\n\nDuring live migration we update bdm.connection_info for attached volumes\nin pre_live_migration to reflect the new connection on the destination\nnode. This means that after migration completes the BDM no longer has a\nreference to the original connection_info to do the detach on the source\nhost. To address this, change I3dfb75eb added a second call to\ninitialize_connection on the source host to re-fetch the source host\nconnection_info before calling disconnect.\n\nUnfortunately the cinder driver interface does not strictly require that\nmultiple calls to initialize_connection will return consistent results.\nAlthough they normally do in practice, there is at least one cinder\ndriver (delliscsi) which doesn't. This results in a failure to\ndisconnect on the source host post migration.\n\nThis change avoids the issue entirely by fetching the BDMs prior to\nmodification on the destination node. As well as working round this\nspecific issue, it also avoids a redundant cinder call in all cases.\n\nNote that this massively simplifies post_live_migration in the libvirt\ndriver. The complexity removed was concerned with reconstructing the\noriginal connection_info. This required considering the cinder v2 and v3\nuse cases, and reconstructing the multipath_id which was written to\nconnection_info by the libvirt fibrechannel volume connector on\nconnection. These things are not necessary when we just use the original\ndata unmodified.\n\nOther drivers affected are Xenapi and HyperV. Xenapi doesn't touch\nvolumes in post_live_migration, so is unaffected. HyperV did not\npreviously account for differences in connection_info between source and\ndestination, so was likely previously broken. This change should fix it.\n\nConflicts:\n      nova/compute/manager.py\n      nova/objects/migrate_data.py\n      nova/tests/unit/compute/test_compute.py\n      nova/tests/unit/compute/test_compute_mgr.py\n      nova/tests/unit/virt/libvirt/test_driver.py\n      nova/virt/libvirt/driver.py\n\nNOTE(mriedem): The conflicts are primarily due to not having change\nI0bfb11296430dfffe9b091ae7c3a793617bd9d0d in Pike. In addition, the\nlibvirt driver conflicts are also due to not having change\nI61a0bee9e71e9a67f6a7c04a7bfd6e77fe818a77 nor change\nIca323b87fa85a454fca9d46ada3677f18fe50022 in Pike.\n\nCloses-Bug: #1754716\nCloses-Bug: #1814245\nChange-Id: I0390c9ff51f49b063f736ca6ef868a4fa782ede5\n(cherry picked from commit b626c0dc7b113365002e743e6de2aeb40121fc81)\n(cherry picked from commit 75e0f5a9b18293546db0ddf0fb073854e6704115)\n(cherry picked from commit 013f421bca4067bd430a9fac1e3b290cf1388ee4)\n""}, {'number': 5, 'created': '2019-09-26 15:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3138fb0836cb9d14aa8dda005652e9e6be1906d4', 'message': ""WIP: Avoid redundant initialize_connection on source post live migration\n\nTODO: resolve conflicts in unit test modules\n\nDuring live migration we update bdm.connection_info for attached volumes\nin pre_live_migration to reflect the new connection on the destination\nnode. This means that after migration completes the BDM no longer has a\nreference to the original connection_info to do the detach on the source\nhost. To address this, change I3dfb75eb added a second call to\ninitialize_connection on the source host to re-fetch the source host\nconnection_info before calling disconnect.\n\nUnfortunately the cinder driver interface does not strictly require that\nmultiple calls to initialize_connection will return consistent results.\nAlthough they normally do in practice, there is at least one cinder\ndriver (delliscsi) which doesn't. This results in a failure to\ndisconnect on the source host post migration.\n\nThis change avoids the issue entirely by fetching the BDMs prior to\nmodification on the destination node. As well as working round this\nspecific issue, it also avoids a redundant cinder call in all cases.\n\nNote that this massively simplifies post_live_migration in the libvirt\ndriver. The complexity removed was concerned with reconstructing the\noriginal connection_info. This required considering the cinder v2 and v3\nuse cases, and reconstructing the multipath_id which was written to\nconnection_info by the libvirt fibrechannel volume connector on\nconnection. These things are not necessary when we just use the original\ndata unmodified.\n\nOther drivers affected are Xenapi and HyperV. Xenapi doesn't touch\nvolumes in post_live_migration, so is unaffected. HyperV did not\npreviously account for differences in connection_info between source and\ndestination, so was likely previously broken. This change should fix it.\n\nConflicts:\n      nova/compute/manager.py\n      nova/objects/migrate_data.py\n      nova/tests/unit/compute/test_compute.py\n      nova/tests/unit/compute/test_compute_mgr.py\n      nova/tests/unit/virt/libvirt/test_driver.py\n      nova/virt/libvirt/driver.py\n\nNOTE(mriedem): The conflicts are primarily due to not having change\nI0bfb11296430dfffe9b091ae7c3a793617bd9d0d in Pike. In addition, the\nlibvirt driver conflicts are also due to not having change\nI61a0bee9e71e9a67f6a7c04a7bfd6e77fe818a77 nor change\nIca323b87fa85a454fca9d46ada3677f18fe50022 in Pike.\n\nCloses-Bug: #1754716\nCloses-Bug: #1814245\nChange-Id: I0390c9ff51f49b063f736ca6ef868a4fa782ede5\n(cherry picked from commit b626c0dc7b113365002e743e6de2aeb40121fc81)\n(cherry picked from commit 75e0f5a9b18293546db0ddf0fb073854e6704115)\n(cherry picked from commit 013f421bca4067bd430a9fac1e3b290cf1388ee4)\n""}, {'number': 6, 'created': '2019-09-27 13:22:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7edeaca31a2851ccaee21c8dd607a87de57d6674', 'message': ""Avoid redundant initialize_connection on source post live migration\n\nDuring live migration we update bdm.connection_info for attached volumes\nin pre_live_migration to reflect the new connection on the destination\nnode. This means that after migration completes the BDM no longer has a\nreference to the original connection_info to do the detach on the source\nhost. To address this, change I3dfb75eb added a second call to\ninitialize_connection on the source host to re-fetch the source host\nconnection_info before calling disconnect.\n\nUnfortunately the cinder driver interface does not strictly require that\nmultiple calls to initialize_connection will return consistent results.\nAlthough they normally do in practice, there is at least one cinder\ndriver (delliscsi) which doesn't. This results in a failure to\ndisconnect on the source host post migration.\n\nThis change avoids the issue entirely by fetching the BDMs prior to\nmodification on the destination node. As well as working round this\nspecific issue, it also avoids a redundant cinder call in all cases.\n\nNote that this massively simplifies post_live_migration in the libvirt\ndriver. The complexity removed was concerned with reconstructing the\noriginal connection_info. This required considering the cinder v2 and v3\nuse cases, and reconstructing the multipath_id which was written to\nconnection_info by the libvirt fibrechannel volume connector on\nconnection. These things are not necessary when we just use the original\ndata unmodified.\n\nOther drivers affected are Xenapi and HyperV. Xenapi doesn't touch\nvolumes in post_live_migration, so is unaffected. HyperV did not\npreviously account for differences in connection_info between source and\ndestination, so was likely previously broken. This change should fix it.\n\nConflicts:\n      nova/compute/manager.py\n      nova/objects/migrate_data.py\n      nova/tests/unit/compute/test_compute.py\n      nova/tests/unit/compute/test_compute_mgr.py\n      nova/tests/unit/virt/libvirt/test_driver.py\n      nova/virt/libvirt/driver.py\n\nNOTE(mriedem): The conflicts are primarily due to not having change\nI0bfb11296430dfffe9b091ae7c3a793617bd9d0d in Pike. In addition, the\nlibvirt driver conflicts are also due to not having change\nI61a0bee9e71e9a67f6a7c04a7bfd6e77fe818a77 nor change\nIca323b87fa85a454fca9d46ada3677f18fe50022 in Pike.\n\nCloses-Bug: #1754716\nCloses-Bug: #1814245\nChange-Id: I0390c9ff51f49b063f736ca6ef868a4fa782ede5\n(cherry picked from commit b626c0dc7b113365002e743e6de2aeb40121fc81)\n(cherry picked from commit 75e0f5a9b18293546db0ddf0fb073854e6704115)\n(cherry picked from commit 013f421bca4067bd430a9fac1e3b290cf1388ee4)\n""}, {'number': 7, 'created': '2020-01-22 02:55:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5668faef76b1d28b09855bc981c1df6d6f8ec067', 'message': ""Avoid redundant initialize_connection on source post live migration\n\nDuring live migration we update bdm.connection_info for attached volumes\nin pre_live_migration to reflect the new connection on the destination\nnode. This means that after migration completes the BDM no longer has a\nreference to the original connection_info to do the detach on the source\nhost. To address this, change I3dfb75eb added a second call to\ninitialize_connection on the source host to re-fetch the source host\nconnection_info before calling disconnect.\n\nUnfortunately the cinder driver interface does not strictly require that\nmultiple calls to initialize_connection will return consistent results.\nAlthough they normally do in practice, there is at least one cinder\ndriver (delliscsi) which doesn't. This results in a failure to\ndisconnect on the source host post migration.\n\nThis change avoids the issue entirely by fetching the BDMs prior to\nmodification on the destination node. As well as working round this\nspecific issue, it also avoids a redundant cinder call in all cases.\n\nNote that this massively simplifies post_live_migration in the libvirt\ndriver. The complexity removed was concerned with reconstructing the\noriginal connection_info. This required considering the cinder v2 and v3\nuse cases, and reconstructing the multipath_id which was written to\nconnection_info by the libvirt fibrechannel volume connector on\nconnection. These things are not necessary when we just use the original\ndata unmodified.\n\nOther drivers affected are Xenapi and HyperV. Xenapi doesn't touch\nvolumes in post_live_migration, so is unaffected. HyperV did not\npreviously account for differences in connection_info between source and\ndestination, so was likely previously broken. This change should fix it.\n\nConflicts:\n      nova/compute/manager.py\n      nova/objects/migrate_data.py\n      nova/tests/unit/compute/test_compute.py\n      nova/tests/unit/compute/test_compute_mgr.py\n      nova/tests/unit/virt/libvirt/test_driver.py\n      nova/virt/libvirt/driver.py\n\nNOTE(mriedem): The conflicts are primarily due to not having change\nI0bfb11296430dfffe9b091ae7c3a793617bd9d0d in Pike. In addition, the\nlibvirt driver conflicts are also due to not having change\nI61a0bee9e71e9a67f6a7c04a7bfd6e77fe818a77 nor change\nIca323b87fa85a454fca9d46ada3677f18fe50022 in Pike.\n\nNOTE(melwitt): The difference from the Queens change in\nnova/compute/manager.py to be able to treat the instance variable as\na dict is because _do_live_migration is expected to be able to handle\nan old-style instance in Pike (this is exposed in the unit test).\nOther sources of conflict in nova/tests/unit/compute/test_compute.py\nare because change I9068a5a5b47cef565802a6d58f37777464644100 is not in\nPike. The difference from the Queens change in\nnova/tests/unit/compute/test_compute_mgr.py to add a mock for the new\nget_by_instance_uuid database call is needed because in Queens the\ntest was using a MagicMock as the compute manager whereas in Pike the\ntest is using a real compute manager. The mock needs to be added to\navoid a test error accessing the database in a NoDBTestCase. Another\nsource of conflicts in nova/tests/unit/compute/test_compute_mgr.py is\nbecause changes I0f3ab6604d8b79bdb75cf67571e359cfecc039d8 and\nI9068a5a5b47cef565802a6d58f37777464644100 are not in Pike.\n\nCloses-Bug: #1754716\nCloses-Bug: #1814245\nChange-Id: I0390c9ff51f49b063f736ca6ef868a4fa782ede5\n(cherry picked from commit b626c0dc7b113365002e743e6de2aeb40121fc81)\n(cherry picked from commit 75e0f5a9b18293546db0ddf0fb073854e6704115)\n(cherry picked from commit 013f421bca4067bd430a9fac1e3b290cf1388ee4)\n""}, {'number': 8, 'created': '2020-01-22 19:31:38.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/virt/libvirt/driver.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/manager.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c8396dcae3eee4bdf7d2d5b4d0cc0f9b58d16117', 'message': ""Avoid redundant initialize_connection on source post live migration\n\nDuring live migration we update bdm.connection_info for attached volumes\nin pre_live_migration to reflect the new connection on the destination\nnode. This means that after migration completes the BDM no longer has a\nreference to the original connection_info to do the detach on the source\nhost. To address this, change I3dfb75eb added a second call to\ninitialize_connection on the source host to re-fetch the source host\nconnection_info before calling disconnect.\n\nUnfortunately the cinder driver interface does not strictly require that\nmultiple calls to initialize_connection will return consistent results.\nAlthough they normally do in practice, there is at least one cinder\ndriver (delliscsi) which doesn't. This results in a failure to\ndisconnect on the source host post migration.\n\nThis change avoids the issue entirely by fetching the BDMs prior to\nmodification on the destination node. As well as working round this\nspecific issue, it also avoids a redundant cinder call in all cases.\n\nNote that this massively simplifies post_live_migration in the libvirt\ndriver. The complexity removed was concerned with reconstructing the\noriginal connection_info. This required considering the cinder v2 and v3\nuse cases, and reconstructing the multipath_id which was written to\nconnection_info by the libvirt fibrechannel volume connector on\nconnection. These things are not necessary when we just use the original\ndata unmodified.\n\nOther drivers affected are Xenapi and HyperV. Xenapi doesn't touch\nvolumes in post_live_migration, so is unaffected. HyperV did not\npreviously account for differences in connection_info between source and\ndestination, so was likely previously broken. This change should fix it.\n\nConflicts:\n      nova/compute/manager.py\n      nova/objects/migrate_data.py\n      nova/tests/unit/compute/test_compute.py\n      nova/tests/unit/compute/test_compute_mgr.py\n      nova/tests/unit/virt/libvirt/test_driver.py\n      nova/virt/libvirt/driver.py\n\nNOTE(mriedem): The conflicts are primarily due to not having change\nI0bfb11296430dfffe9b091ae7c3a793617bd9d0d in Pike. In addition, the\nlibvirt driver conflicts are also due to not having change\nI61a0bee9e71e9a67f6a7c04a7bfd6e77fe818a77 nor change\nIca323b87fa85a454fca9d46ada3677f18fe50022 in Pike.\n\nNOTE(melwitt): The difference from the Queens change in\nnova/compute/manager.py to be able to treat the instance variable as\na dict is because _do_live_migration is expected to be able to handle\nan old-style instance in Pike (this is exposed in the unit test).\nOther sources of conflict in nova/tests/unit/compute/test_compute.py\nare because change I9068a5a5b47cef565802a6d58f37777464644100 is not in\nPike. The difference from the Queens change in\nnova/tests/unit/compute/test_compute_mgr.py to add a mock for the new\nget_by_instance_uuid database call is needed because in Queens the\ntest was using a MagicMock as the compute manager whereas in Pike the\ntest is using a real compute manager. The mock needs to be added to\navoid a test error accessing the database in a NoDBTestCase. Another\nsource of conflicts in nova/tests/unit/compute/test_compute_mgr.py is\nbecause changes I0f3ab6604d8b79bdb75cf67571e359cfecc039d8 and\nI9068a5a5b47cef565802a6d58f37777464644100 are not in Pike.\n\nCloses-Bug: #1754716\nCloses-Bug: #1814245\nChange-Id: I0390c9ff51f49b063f736ca6ef868a4fa782ede5\n(cherry picked from commit b626c0dc7b113365002e743e6de2aeb40121fc81)\n(cherry picked from commit 75e0f5a9b18293546db0ddf0fb073854e6704115)\n(cherry picked from commit 013f421bca4067bd430a9fac1e3b290cf1388ee4)\n""}]",18,683008,c8396dcae3eee4bdf7d2d5b4d0cc0f9b58d16117,130,22,8,6873,,,0,"Avoid redundant initialize_connection on source post live migration

During live migration we update bdm.connection_info for attached volumes
in pre_live_migration to reflect the new connection on the destination
node. This means that after migration completes the BDM no longer has a
reference to the original connection_info to do the detach on the source
host. To address this, change I3dfb75eb added a second call to
initialize_connection on the source host to re-fetch the source host
connection_info before calling disconnect.

Unfortunately the cinder driver interface does not strictly require that
multiple calls to initialize_connection will return consistent results.
Although they normally do in practice, there is at least one cinder
driver (delliscsi) which doesn't. This results in a failure to
disconnect on the source host post migration.

This change avoids the issue entirely by fetching the BDMs prior to
modification on the destination node. As well as working round this
specific issue, it also avoids a redundant cinder call in all cases.

Note that this massively simplifies post_live_migration in the libvirt
driver. The complexity removed was concerned with reconstructing the
original connection_info. This required considering the cinder v2 and v3
use cases, and reconstructing the multipath_id which was written to
connection_info by the libvirt fibrechannel volume connector on
connection. These things are not necessary when we just use the original
data unmodified.

Other drivers affected are Xenapi and HyperV. Xenapi doesn't touch
volumes in post_live_migration, so is unaffected. HyperV did not
previously account for differences in connection_info between source and
destination, so was likely previously broken. This change should fix it.

Conflicts:
      nova/compute/manager.py
      nova/objects/migrate_data.py
      nova/tests/unit/compute/test_compute.py
      nova/tests/unit/compute/test_compute_mgr.py
      nova/tests/unit/virt/libvirt/test_driver.py
      nova/virt/libvirt/driver.py

NOTE(mriedem): The conflicts are primarily due to not having change
I0bfb11296430dfffe9b091ae7c3a793617bd9d0d in Pike. In addition, the
libvirt driver conflicts are also due to not having change
I61a0bee9e71e9a67f6a7c04a7bfd6e77fe818a77 nor change
Ica323b87fa85a454fca9d46ada3677f18fe50022 in Pike.

NOTE(melwitt): The difference from the Queens change in
nova/compute/manager.py to be able to treat the instance variable as
a dict is because _do_live_migration is expected to be able to handle
an old-style instance in Pike (this is exposed in the unit test).
Other sources of conflict in nova/tests/unit/compute/test_compute.py
are because change I9068a5a5b47cef565802a6d58f37777464644100 is not in
Pike. The difference from the Queens change in
nova/tests/unit/compute/test_compute_mgr.py to add a mock for the new
get_by_instance_uuid database call is needed because in Queens the
test was using a MagicMock as the compute manager whereas in Pike the
test is using a real compute manager. The mock needs to be added to
avoid a test error accessing the database in a NoDBTestCase. Another
source of conflicts in nova/tests/unit/compute/test_compute_mgr.py is
because changes I0f3ab6604d8b79bdb75cf67571e359cfecc039d8 and
I9068a5a5b47cef565802a6d58f37777464644100 are not in Pike.

Closes-Bug: #1754716
Closes-Bug: #1814245
Change-Id: I0390c9ff51f49b063f736ca6ef868a4fa782ede5
(cherry picked from commit b626c0dc7b113365002e743e6de2aeb40121fc81)
(cherry picked from commit 75e0f5a9b18293546db0ddf0fb073854e6704115)
(cherry picked from commit 013f421bca4067bd430a9fac1e3b290cf1388ee4)
",git fetch https://review.opendev.org/openstack/nova refs/changes/08/683008/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/virt/libvirt/driver.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/manager.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",5,105bc55eab6cba14a0e4dfa528ce00d8afd36831,bug/1754716,"<<<<<<< HEAD======= vol1_conn_info = {'data': {'test_data': mock.sentinel.vol1}, 'serial': 'fake_serial1'} vol2_conn_info = {'data': {'test_data': mock.sentinel.vol2}, 'serial': 'fake_serial2'} bdi = {'block_device_mapping': [ {'attachment_id': None, 'connection_info': vol1_conn_info, 'mount_device': '/dev/sda', }, {'attachment_id': None, 'connection_info': vol2_conn_info, >>>>>>> 013f421bca... Avoid redundant initialize_connection on source post live migration 'mount_device': '/dev/sdb', }]}<<<<<<< HEAD======= @mock.patch.object(driver, 'block_device_info_get_mapping', return_value=bdi['block_device_mapping']) @mock.patch.object(drvr, '_disconnect_volume') def _test(_disconnect_volume, block_device_info_get_mapping): drvr.post_live_migration(cntx, inst_ref, bdi) block_device_info_get_mapping.assert_called_once_with(bdi) _disconnect_volume.assert_has_calls([ mock.call(cntx, vol1_conn_info, inst_ref), mock.call(cntx, vol2_conn_info, inst_ref)]) _test() >>>>>>> 013f421bca... Avoid redundant initialize_connection on source post live migration"," 'mount_device': '/dev/sdb', }]} def fake_initialize_connection(context, volume_id, connector): return {'data': {}} fake_connector = {'host': 'fake'}",426,45
openstack%2Fneutron~stable%2Ftrain~I7ed1a742849dfce9e65b8eb36566112501fb0e39,openstack/neutron,stable/train,I7ed1a742849dfce9e65b8eb36566112501fb0e39,Ensure driver error preventing trunk port deletion is logged,MERGED,2020-01-28 21:55:52.000000000,2020-01-31 11:07:51.000000000,2020-01-31 11:05:37.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 9732}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-28 21:55:52.000000000', 'files': ['neutron/services/trunk/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a618a26bf4f8782d6f16a5090f1c7ce8d824476b', 'message': 'Ensure driver error preventing trunk port deletion is logged\n\nWhen trunk port deletion is attempted but fails because the driver does\nnot permit it, the logs do not contain the driver error message that\nspecifies the precise rationale for preventing the trunk port deletion.\nLog it explicitly.\n\nChange-Id: I7ed1a742849dfce9e65b8eb36566112501fb0e39\n(cherry picked from commit 3b56299e1fa0b48bd4d674e57be2e289c4c28547)\n'}]",0,704690,a618a26bf4f8782d6f16a5090f1c7ce8d824476b,17,6,1,13995,,,0,"Ensure driver error preventing trunk port deletion is logged

When trunk port deletion is attempted but fails because the driver does
not permit it, the logs do not contain the driver error message that
specifies the precise rationale for preventing the trunk port deletion.
Log it explicitly.

Change-Id: I7ed1a742849dfce9e65b8eb36566112501fb0e39
(cherry picked from commit 3b56299e1fa0b48bd4d674e57be2e289c4c28547)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/90/704690/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/trunk/plugin.py'],1,a618a26bf4f8782d6f16a5090f1c7ce8d824476b,report_trunk_port_deletion-stable/train,"from oslo_utils import excutils try: trunk.delete() except Exception as e: with excutils.save_and_reraise_exception(): LOG.warning('Trunk driver raised exception when ' 'deleting trunk port %s: %s', trunk_id, str(e)) registry.notify(resources.TRUNK, events.PRECOMMIT_DELETE, self, payload=payload) else: LOG.info('Trunk driver does not consider trunk %s ' 'untrunkable', trunk_id)"," trunk.delete() registry.notify(resources.TRUNK, events.PRECOMMIT_DELETE, self, payload=payload) else:",13,3
openstack%2Fcloudkitty~master~I91f38b9aded2dc6453507edaa55cfd9ddf7e995b,openstack/cloudkitty,master,I91f38b9aded2dc6453507edaa55cfd9ddf7e995b,Update oslo.policy and oslo.context usage,MERGED,2019-10-31 11:08:36.000000000,2020-01-31 10:51:06.000000000,2020-01-31 10:45:52.000000000,"[{'_account_id': 22348}, {'_account_id': 23060}, {'_account_id': 29503}]","[{'number': 1, 'created': '2019-10-31 11:08:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/53f2ae4350a6abe19e8694a8609a0323fce2f340', 'message': 'WIP: Update oslo.policy usage\n\nChange-Id: I91f38b9aded2dc6453507edaa55cfd9ddf7e995b\n'}, {'number': 2, 'created': '2019-11-04 15:13:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/41f14564a3f8c6ec16081fc6c69c5188b323065b', 'message': 'Update oslo.policy and oslo.context usage\n\nThis changes the way oslo.policy and oslo.context are used. This aims at\ndelegating as much work as possible to these libraries in order to ease\nmaintainability.\n\nWork items:\n\n* Use oslo_context.RequestContext\'s from_environ() method instead of building\n  the context manually.\n\n* Replace ""tenant_id"" with ""project_id"" in policy rule definition/enforcement.\n\n* Introduce a cloudkitty.context module allowing to easily tweak request\n  context creation.\n\nChange-Id: I91f38b9aded2dc6453507edaa55cfd9ddf7e995b\n'}, {'number': 3, 'created': '2019-11-04 16:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/f4eb8ed1a0c8ff844daa6b32eaf45c20433a457c', 'message': 'Update oslo.policy and oslo.context usage\n\nThis changes the way oslo.policy and oslo.context are used. This aims at\ndelegating as much work as possible to these libraries in order to ease\nmaintainability.\n\nWork items:\n\n* Use oslo_context.RequestContext\'s from_environ() method instead of building\n  the context manually.\n\n* Replace ""tenant_id"" with ""project_id"" in policy rule definition/enforcement.\n\n* Introduce a cloudkitty.context module allowing to easily tweak request\n  context creation.\n\nChange-Id: I91f38b9aded2dc6453507edaa55cfd9ddf7e995b\n'}, {'number': 4, 'created': '2019-11-20 08:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/1087cf6b035061f6de04a531fe110814fd8ec4f2', 'message': 'Update oslo.policy and oslo.context usage\n\nThis changes the way oslo.policy and oslo.context are used. This aims at\ndelegating as much work as possible to these libraries in order to ease\nmaintainability.\n\nWork items:\n\n* Use oslo_context.RequestContext\'s from_environ() method instead of building\n  the context manually.\n\n* Replace ""tenant_id"" with ""project_id"" in policy rule definition/enforcement.\n\n* Introduce a cloudkitty.context module allowing to easily tweak request\n  context creation.\n\nChange-Id: I91f38b9aded2dc6453507edaa55cfd9ddf7e995b\n'}, {'number': 5, 'created': '2019-12-12 15:54:51.000000000', 'files': ['cloudkitty/common/policies/base.py', 'cloudkitty/tests/test_policy.py', 'doc/source/_static/cloudkitty.policy.yaml.sample', 'cloudkitty/api/v2/summary/summary.py', 'cloudkitty/api/v2/__init__.py', 'cloudkitty/api/v1/controllers/storage.py', 'cloudkitty/api/v2/scope/state.py', 'cloudkitty/common/context.py', 'cloudkitty/api/v1/controllers/report.py', 'cloudkitty/api/v1/hooks.py', 'cloudkitty/common/policy.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/a80d0e977dc606d1f171f4eebb3bb799f7059e34', 'message': 'Update oslo.policy and oslo.context usage\n\nThis changes the way oslo.policy and oslo.context are used. This aims at\ndelegating as much work as possible to these libraries in order to ease\nmaintainability.\n\nWork items:\n\n* Use oslo_context.RequestContext\'s from_environ() method instead of building\n  the context manually.\n\n* Replace ""tenant_id"" with ""project_id"" in policy rule definition/enforcement.\n\n* Introduce a cloudkitty.context module allowing to easily tweak request\n  context creation.\n\nChange-Id: I91f38b9aded2dc6453507edaa55cfd9ddf7e995b\n'}]",0,692333,a80d0e977dc606d1f171f4eebb3bb799f7059e34,19,3,5,23060,,,0,"Update oslo.policy and oslo.context usage

This changes the way oslo.policy and oslo.context are used. This aims at
delegating as much work as possible to these libraries in order to ease
maintainability.

Work items:

* Use oslo_context.RequestContext's from_environ() method instead of building
  the context manually.

* Replace ""tenant_id"" with ""project_id"" in policy rule definition/enforcement.

* Introduce a cloudkitty.context module allowing to easily tweak request
  context creation.

Change-Id: I91f38b9aded2dc6453507edaa55cfd9ddf7e995b
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/33/692333/5 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/api/v2/__init__.py', 'cloudkitty/common/policy.py']",2,53f2ae4350a6abe19e8694a8609a0323fce2f340,," return _ENFORCER.authorize(action, target, context,#.to_dict(),"," return _ENFORCER.authorize(action, target, context.to_dict(),",15,14
openstack%2Fhorizon~master~I6be10a92a1f43b3e0effee8148987c7e2c5690ff,openstack/horizon,master,I6be10a92a1f43b3e0effee8148987c7e2c5690ff,Manually registering 2 Dashboards breaks get_dashboards() (python3),MERGED,2019-07-12 05:25:43.000000000,2020-01-31 10:50:18.000000000,2020-01-31 10:44:42.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 3031}, {'_account_id': 10068}, {'_account_id': 11880}, {'_account_id': 18418}, {'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 29313}, {'_account_id': 30676}]","[{'number': 1, 'created': '2019-07-12 05:25:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9f4664c52e8d1911b0d41b23ab955ca482c1bf5d', 'message': ""Manually registering 2 Dashboards breaks get_dashboards()\n\nThe get_dashboards() method used sorted(<values>) to sort the\ndashboards that have been registered manually.  This breaks if\ntwo or more are registered that way because the Dashboard class\ndoesn't define a natural ordering.  The fix is to sort using\nthe Dashboard name as the sort key.  (Unit test included.)\n\nChange-Id: I6be10a92a1f43b3e0effee8148987c7e2c5690ff\nCloses-bug: 1836295\n""}, {'number': 2, 'created': '2019-07-12 14:29:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/321e3a29ba733f2dbbfefb632d36e5b6c0e31fb7', 'message': ""Manually registering 2 Dashboards breaks get_dashboards()\n\nThe get_dashboards() method used sorted(<values>) to sort the\ndashboards that have been registered manually.  This breaks if\ntwo or more are registered that way because the Dashboard class\ndoesn't define a natural ordering.  The fix is to sort using\nthe Dashboard name as the sort key.  (Unit test included.)\n\nChange-Id: I6be10a92a1f43b3e0effee8148987c7e2c5690ff\nCloses-bug: 1836295\n""}, {'number': 3, 'created': '2019-07-13 12:13:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/148fde445eee35e36c8db1f0c3ea06d1a862d612', 'message': ""Manually registering 2 Dashboards breaks get_dashboards()\n\nThe get_dashboards() method used sorted(<values>) to sort the\ndashboards that have been registered manually.  This breaks if\ntwo or more are registered that way because the Dashboard class\ndoesn't define a natural ordering.  The fix is to sort using\nthe Dashboard name as the sort key.  (Unit test included.)\n\nChange-Id: I6be10a92a1f43b3e0effee8148987c7e2c5690ff\nCloses-bug: 1836295\n""}, {'number': 4, 'created': '2019-07-26 10:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a0136190a428a3009cba068689ac4a34c74fad03', 'message': ""Manually registering 2 Dashboards breaks get_dashboards() (python3)\n\nThe get_dashboards() method used sorted(<values>) to sort the\ndashboards that have been registered manually.  This breaks if\ntwo or more are registered that way because the Dashboard class\ndoesn't define a natural ordering.  The fix is to sort using\nthe Dashboard name as the sort key.  (Unit test included.)\n\nThis problem doesn't occur in python 2.7.\n\nChange-Id: I6be10a92a1f43b3e0effee8148987c7e2c5690ff\nCloses-bug: 1836295\n""}, {'number': 5, 'created': '2020-01-29 05:43:13.000000000', 'files': ['horizon/test/unit/test_base.py', 'horizon/base.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a95398d012ffdd82e7d4a5e591dfd88e68f44f24', 'message': ""Manually registering 2 Dashboards breaks get_dashboards() (python3)\n\nThe get_dashboards() method used sorted(<values>) to sort the\ndashboards that have been registered manually.  This breaks if\ntwo or more are registered that way because the Dashboard class\ndoesn't define a natural ordering.  The fix is to sort using\nthe Dashboard name as the sort key.  (Unit test included.)\n\nThis problem doesn't occur in python 2.7.\n\nP.S.\nIt turns out that AdminPanel in horizon/test/unit/test_base.py is not\nused during the review. It is dropped too as it is a simple change.\n\nChange-Id: I6be10a92a1f43b3e0effee8148987c7e2c5690ff\nCloses-bug: #1836295\n""}]",6,670446,a95398d012ffdd82e7d4a5e591dfd88e68f44f24,33,10,5,30676,,,0,"Manually registering 2 Dashboards breaks get_dashboards() (python3)

The get_dashboards() method used sorted(<values>) to sort the
dashboards that have been registered manually.  This breaks if
two or more are registered that way because the Dashboard class
doesn't define a natural ordering.  The fix is to sort using
the Dashboard name as the sort key.  (Unit test included.)

This problem doesn't occur in python 2.7.

P.S.
It turns out that AdminPanel in horizon/test/unit/test_base.py is not
used during the review. It is dropped too as it is a simple change.

Change-Id: I6be10a92a1f43b3e0effee8148987c7e2c5690ff
Closes-bug: #1836295
",git fetch https://review.opendev.org/openstack/horizon refs/changes/46/670446/2 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/test/unit/test_base.py', 'horizon/base.py']",2,9f4664c52e8d1911b0d41b23ab955ca482c1bf5d,bug/1836295," extra = sorted(registered.values(), key=(lambda d: d.name))", extra = sorted(registered.values()),40,1
openstack%2Fhorizon~master~I611573a41c47e99e41a54bf53cea55322a493de1,openstack/horizon,master,I611573a41c47e99e41a54bf53cea55322a493de1,Remove errant references to mox,MERGED,2020-01-30 11:45:16.000000000,2020-01-31 10:48:35.000000000,2020-01-31 10:44:39.000000000,"[{'_account_id': 841}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-01-30 11:45:16.000000000', 'files': ['doc/source/contributor/topics/testing.rst', 'openstack_dashboard/dashboards/admin/instances/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/2b3ab46440947099cbbf828da0ef75fe74e0c710', 'message': 'Remove errant references to mox\n\nThere is still a single user of mox but all other references to this can\nbe removed. Do just that.\n\nChange-Id: I611573a41c47e99e41a54bf53cea55322a493de1\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",0,704974,2b3ab46440947099cbbf828da0ef75fe74e0c710,8,3,1,15334,,,0,"Remove errant references to mox

There is still a single user of mox but all other references to this can
be removed. Do just that.

Change-Id: I611573a41c47e99e41a54bf53cea55322a493de1
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/horizon refs/changes/74/704974/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributor/topics/testing.rst', 'openstack_dashboard/dashboards/admin/instances/tests.py']",2,2b3ab46440947099cbbf828da0ef75fe74e0c710,remove-mox, mock_servers = self.servers.list() expected_servers = mock_servers[:size] expected_servers = mock_servers[size:2 * size] expected_servers = mock_servers[-size:] mock_servers = self.servers.list() expected_servers = mock_servers[size:2 * size] marker = mock_servers[0].id expected_servers = mock_servers[:size] marker = mock_servers[0].id, mox_servers = self.servers.list() expected_servers = mox_servers[:size] expected_servers = mox_servers[size:2 * size] expected_servers = mox_servers[-size:] mox_servers = self.servers.list() expected_servers = mox_servers[size:2 * size] marker = mox_servers[0].id expected_servers = mox_servers[:size] marker = mox_servers[0].id,9,48
openstack%2Fcloudkitty~master~I570db3db4c969042038a286829c8df2ee06fb5d7,openstack/cloudkitty,master,I570db3db4c969042038a286829c8df2ee06fb5d7,"Fix processing of ""rate:xxx"" re-aggregation configuration",MERGED,2020-01-29 17:40:25.000000000,2020-01-31 10:47:39.000000000,2020-01-31 10:45:48.000000000,"[{'_account_id': 22348}, {'_account_id': 29503}]","[{'number': 1, 'created': '2020-01-29 17:40:25.000000000', 'files': ['cloudkitty/collector/gnocchi.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/cbdd3545b55586b00ddd9565caffefea58fe162c', 'message': 'Fix processing of ""rate:xxx"" re-aggregation configuration\n\nThe aggregation API in Gnocchi does not return anything for Granularity\n3600, when the time-range is just one hour for ""rate:xxx""\nre-aggregation methods. That behavior on Gnocchi side is correct. The\n""rate:xxx"" aggregation method needs at least two data points (we are\ntaking the diff, right?). Therefore, when configured to work with\n""rate:xxx"" CloudKitty needs to call the aggregation API with a two\nhours interval (for granularity 3600), and not just one.\n\nWith this patch, when CloudKitty detects a ""rate:xxx"" configuration, it\nwill use the range as two times (*) the granularity we are using to\nprocess data. Therefore, if the granularity is one hour, it uses a\ntwo-hour time frame; on the other hand, if the granularity is\nconfigured to 10 minutes, it would consider a 20 minutes timeframe. I\nam doing that to retrieve two data points at a time in the aggregation\nAPI; thus, we can compute the diffs between the data points.\n\nDepends-On: https://review.opendev.org/#/c/704787/\nChange-Id: I570db3db4c969042038a286829c8df2ee06fb5d7\n'}]",0,704857,cbdd3545b55586b00ddd9565caffefea58fe162c,7,2,1,28356,,,0,"Fix processing of ""rate:xxx"" re-aggregation configuration

The aggregation API in Gnocchi does not return anything for Granularity
3600, when the time-range is just one hour for ""rate:xxx""
re-aggregation methods. That behavior on Gnocchi side is correct. The
""rate:xxx"" aggregation method needs at least two data points (we are
taking the diff, right?). Therefore, when configured to work with
""rate:xxx"" CloudKitty needs to call the aggregation API with a two
hours interval (for granularity 3600), and not just one.

With this patch, when CloudKitty detects a ""rate:xxx"" configuration, it
will use the range as two times (*) the granularity we are using to
process data. Therefore, if the granularity is one hour, it uses a
two-hour time frame; on the other hand, if the granularity is
configured to 10 minutes, it would consider a 20 minutes timeframe. I
am doing that to retrieve two data points at a time in the aggregation
API; thus, we can compute the diffs between the data points.

Depends-On: https://review.opendev.org/#/c/704787/
Change-Id: I570db3db4c969042038a286829c8df2ee06fb5d7
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/57/704857/1 && git format-patch -1 --stdout FETCH_HEAD,['cloudkitty/collector/gnocchi.py'],1,cbdd3545b55586b00ddd9565caffefea58fe162c,fixProcessingOfRateXXXReAggregationMetrics," agg_kwargs = self.get_aggregation_api_arguments(end, metric_name, project_id, q_filter, start) op = self.build_operation_command(metric_name) def get_aggregation_api_arguments(self, end, metric_name, project_id, q_filter, start): extra_args = self.conf[metric_name]['extra_args'] resource_type = extra_args['resource_type'] query_parameters = self.build_query_parameters(project_id, q_filter, resource_type) agg_kwargs = { 'resource_type': resource_type, 'start': start, 'stop': end, 'groupby': self.conf[metric_name]['groupby'], 'search': self.extend_filter(*query_parameters), } force_granularity = extra_args['force_granularity'] if force_granularity > 0: agg_kwargs['granularity'] = force_granularity re_aggregation_method = extra_args['re_aggregation_method'] if re_aggregation_method.startswith('rate:'): agg_kwargs['start'] = start - timedelta(seconds=force_granularity) LOG.debug(""Re-aggregation method for metric [%s] configured as"" "" [%s]. Therefore, we need two data points. Start date"" "" modified from [%s] to [%s]."", metric_name, re_aggregation_method, start, agg_kwargs['start']) return agg_kwargs def build_query_parameters(self, project_id, q_filter, resource_type): query_parameters = list() query_parameters.append( self.gen_filter(cop=""="", type=resource_type)) if project_id: scope_key = CONF.collect.scope_key kwargs = {scope_key: project_id} query_parameters.append(self.gen_filter(**kwargs)) if q_filter: query_parameters.append(q_filter) return query_parameters def build_operation_command(self, metric_name): extra_args = self.conf[metric_name]['extra_args'] "," :type resource_name: str # Get gnocchi specific conf extra_args = self.conf[metric_name]['extra_args'] # get resource type resource_type = extra_args['resource_type'] scope_key = CONF.collect.scope_key # build search query using resource type and project_id if provided query_parameters = list() query_parameters.append( self.gen_filter(cop=""="", type=resource_type)) if project_id: kwargs = {scope_key: project_id} query_parameters.append(self.gen_filter(**kwargs)) if q_filter: query_parameters.append(q_filter) op = self.build_operation_command(extra_args, metric_name) agg_kwargs = { 'resource_type': resource_type, 'start': start, 'stop': end, 'groupby': self.conf[metric_name]['groupby'], 'search': self.extend_filter(*query_parameters), } if extra_args['force_granularity'] > 0: agg_kwargs['granularity'] = extra_args['force_granularity'] @staticmethod def build_operation_command(extra_args, metric_name):",49,33
openstack%2Fhorizon~stable%2Fstein~Ia865a6c02e206fa49efc3095e8d3488f5638d0e3,openstack/horizon,stable/stein,Ia865a6c02e206fa49efc3095e8d3488f5638d0e3,Allow to evacuate without specifying a target host,MERGED,2020-01-29 05:07:08.000000000,2020-01-31 10:47:19.000000000,2020-01-31 10:44:45.000000000,"[{'_account_id': 841}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-01-29 05:07:08.000000000', 'files': ['openstack_dashboard/dashboards/admin/hypervisors/compute/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/42d9a8d2e8736c5a8e94eaf7074755a1add3922b', 'message': 'Allow to evacuate without specifying a target host\n\nWhen the evacuate is run without specifying a target host, horizon\nsets an empty string for target host. But the evacuate api doesn\'t\nallow an empty string. As a result, nova returns ""HTTP 400 Bad\nrequest"".\n\nSo this patch sets None as the target host when it isn\'t specified.\n\nChange-Id: Ia865a6c02e206fa49efc3095e8d3488f5638d0e3\nCloses-Bug: 1793694\n(cherry picked from commit f9e0f8a976b82088ef095a69cd1fa892cddde3ba)\n'}]",0,704727,42d9a8d2e8736c5a8e94eaf7074755a1add3922b,8,4,1,8988,,,0,"Allow to evacuate without specifying a target host

When the evacuate is run without specifying a target host, horizon
sets an empty string for target host. But the evacuate api doesn't
allow an empty string. As a result, nova returns ""HTTP 400 Bad
request"".

So this patch sets None as the target host when it isn't specified.

Change-Id: Ia865a6c02e206fa49efc3095e8d3488f5638d0e3
Closes-Bug: 1793694
(cherry picked from commit f9e0f8a976b82088ef095a69cd1fa892cddde3ba)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/27/704727/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/admin/hypervisors/compute/forms.py'],1,42d9a8d2e8736c5a8e94eaf7074755a1add3922b,bug/1793694, # The target_host value will be an empty string when the target # host wasn't specified. But the evacuate api doesn't allow # an empty string. So set None as the target_host value. if not target_host: target_host = None,,5,0
openstack%2Fhorizon~stable%2Ftrain~Ia865a6c02e206fa49efc3095e8d3488f5638d0e3,openstack/horizon,stable/train,Ia865a6c02e206fa49efc3095e8d3488f5638d0e3,Allow to evacuate without specifying a target host,MERGED,2020-01-29 05:10:52.000000000,2020-01-31 10:46:30.000000000,2020-01-31 10:44:44.000000000,"[{'_account_id': 841}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-01-29 05:10:52.000000000', 'files': ['openstack_dashboard/dashboards/admin/hypervisors/compute/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e058e381607e93439a59f47c36e6a9b7cf61cc71', 'message': 'Allow to evacuate without specifying a target host\n\nWhen the evacuate is run without specifying a target host, horizon\nsets an empty string for target host. But the evacuate api doesn\'t\nallow an empty string. As a result, nova returns ""HTTP 400 Bad\nrequest"".\n\nSo this patch sets None as the target host when it isn\'t specified.\n\nChange-Id: Ia865a6c02e206fa49efc3095e8d3488f5638d0e3\nCloses-Bug: 1793694\n(cherry picked from commit f9e0f8a976b82088ef095a69cd1fa892cddde3ba)\n'}]",0,704728,e058e381607e93439a59f47c36e6a9b7cf61cc71,9,4,1,8988,,,0,"Allow to evacuate without specifying a target host

When the evacuate is run without specifying a target host, horizon
sets an empty string for target host. But the evacuate api doesn't
allow an empty string. As a result, nova returns ""HTTP 400 Bad
request"".

So this patch sets None as the target host when it isn't specified.

Change-Id: Ia865a6c02e206fa49efc3095e8d3488f5638d0e3
Closes-Bug: 1793694
(cherry picked from commit f9e0f8a976b82088ef095a69cd1fa892cddde3ba)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/28/704728/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/admin/hypervisors/compute/forms.py'],1,e058e381607e93439a59f47c36e6a9b7cf61cc71,bug/1793694, # The target_host value will be an empty string when the target # host wasn't specified. But the evacuate api doesn't allow # an empty string. So set None as the target_host value. if not target_host: target_host = None,,5,0
openstack%2Fcloudkitty~master~I1a147be155b12175d7f031c14d0e90ab13aec700,openstack/cloudkitty,master,I1a147be155b12175d7f031c14d0e90ab13aec700,Add support for the range_function field to the Prometheus collector,MERGED,2020-01-14 13:53:16.000000000,2020-01-31 10:45:49.000000000,2020-01-31 10:45:48.000000000,"[{'_account_id': 22348}, {'_account_id': 29503}, {'_account_id': 30959}, {'_account_id': 30960}]","[{'number': 1, 'created': '2020-01-14 13:53:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/dfd6ebfa4091bffc0fe05b4ef8c57f17fced0fcc', 'message': 'Add support for the range_function field to the Prometheus collector\n\nThis extends the possibilities for manipulating data with the Prometheus\ncollector without using custom scripts.\n\nWork items:\n * Implemented the range_function field in the Prometheus collector.\n\n * Documented the range_function field.\n\n * Updated the tests on the Prometheus collector to include the\n   range_function field.\n\nChange-Id: I1a147be155b12175d7f031c14d0e90ab13aec700\nStory: 2006427\nTask: 36328\n'}, {'number': 2, 'created': '2020-01-14 15:49:48.000000000', 'files': ['doc/source/admin/configuration/collector.rst', 'cloudkitty/collector/prometheus.py', 'cloudkitty/tests/collectors/test_prometheus.py', 'cloudkitty/tests/collectors/test_validation.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/6dfe2a6c8d68f1b1dfb6d4c5df87707344672891', 'message': 'Add support for the range_function field to the Prometheus collector\n\nThis extends the possibilities for manipulating data with the Prometheus\ncollector without using custom scripts.\n\nWork items:\n * Implemented the range_function field in the Prometheus collector.\n\n * Documented the range_function field.\n\n * Updated the tests on the Prometheus collector to include the\n   range_function field.\n\nChange-Id: I1a147be155b12175d7f031c14d0e90ab13aec700\nStory: 2006427\nTask: 36328\n'}]",0,702431,6dfe2a6c8d68f1b1dfb6d4c5df87707344672891,12,4,2,30844,,,0,"Add support for the range_function field to the Prometheus collector

This extends the possibilities for manipulating data with the Prometheus
collector without using custom scripts.

Work items:
 * Implemented the range_function field in the Prometheus collector.

 * Documented the range_function field.

 * Updated the tests on the Prometheus collector to include the
   range_function field.

Change-Id: I1a147be155b12175d7f031c14d0e90ab13aec700
Story: 2006427
Task: 36328
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/31/702431/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/configuration/collector.rst', 'cloudkitty/collector/prometheus.py', 'cloudkitty/tests/collectors/test_prometheus.py', 'cloudkitty/tests/collectors/test_validation.py']",4,dfd6ebfa4091bffc0fe05b4ef8c57f17fced0fcc,," 'range_function': 'delta', 'range_function': 'delta',",,30,7
openstack%2Fcloudkitty-tempest-plugin~master~Ie7a80ac58dc425e66cf2b7334b99e22a07759dbc,openstack/cloudkitty-tempest-plugin,master,Ie7a80ac58dc425e66cf2b7334b99e22a07759dbc,More cleanup for py2 drop,MERGED,2020-01-23 22:44:35.000000000,2020-01-31 10:45:48.000000000,2020-01-31 10:45:48.000000000,"[{'_account_id': 22348}, {'_account_id': 29503}]","[{'number': 1, 'created': '2020-01-23 22:44:35.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/cloudkitty-tempest-plugin/commit/44b8c4ed91f875e54ab3e4f9591196710f17ef3b', 'message': 'More cleanup for py2 drop\n\nThis commit cleanup requirement file and add\nignore_basepython_conflict flag into tox to avoid\npython version conflct.\n\nChange-Id: Ie7a80ac58dc425e66cf2b7334b99e22a07759dbc\n'}]",0,704077,44b8c4ed91f875e54ab3e4f9591196710f17ef3b,8,2,1,8556,,,0,"More cleanup for py2 drop

This commit cleanup requirement file and add
ignore_basepython_conflict flag into tox to avoid
python version conflct.

Change-Id: Ie7a80ac58dc425e66cf2b7334b99e22a07759dbc
",git fetch https://review.opendev.org/openstack/cloudkitty-tempest-plugin refs/changes/77/704077/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,44b8c4ed91f875e54ab3e4f9591196710f17ef3b,drop-py27-support,minversion = 3.1.1ignore_basepython_conflict = True,minversion = 2.0,3,2
openstack%2Fcloudkitty~master~I8a1a75a74e04cb9babdf09f115620b152861e218,openstack/cloudkitty,master,I8a1a75a74e04cb9babdf09f115620b152861e218,Standardize aggregation methods and granularities for Gnocchi collector,MERGED,2020-01-29 12:29:34.000000000,2020-01-31 10:45:41.000000000,2020-01-31 10:42:33.000000000,"[{'_account_id': 22348}, {'_account_id': 29503}]","[{'number': 1, 'created': '2020-01-29 12:29:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/da1c0ddbbd0573c4c332ff05e36eecd4a2910b61', 'message': 'Standardize aggregation methods and granularities for Gnocchi collector\n\nThis PR proposes the standardization of aggregation methods allowed by\nCloudKitty in Gnocchi collector as the aggregation methods available in\nGnocchi API for both archive policies and aggregation API. The rationale is\nthat we need to support the same aggregation methods available there.\nOtherwise, users can try to use something available in the Gnocchi API, and it\ndoes not work due to a limitation in CloudKitty.\n\nWe also propose to set the default granularity as 3600. CloudKitty is already\nusing one hour time frames by default. There is no sense in not setting the\ngranularity as 3600 as well. If we do not define the granularity 3600 by\ndefault, CloudKitty will always retrieve (in the aggregation API) measurements\nfor all available granularities, which is an overhead. Besides being an\noverhead, it can cause huge inconsistencies, if for some reason (that we\npainfully discovered in production), the granularity of 3600 is not returned.\nThe method ""_format_data""  does not check if the data being\n""formated""/obtained from the measurements object represents the 3600 (1h) time\nframe, it just retrieves the first element, and moves on; thus, leading to\nwrong billing information.\n\nAnd last, but not least, we propose a debug log to show in the log files, when\ndebug log level is enabled, the response received in the aggregation API. This\ncan enable debug for operation people. Otherwise, we need to change code to be\nable to troubleshoot problems with CloudKitty processing when using Gnocchi\ncollector.\n\nChange-Id: I8a1a75a74e04cb9babdf09f115620b152861e218\n'}, {'number': 2, 'created': '2020-01-29 12:41:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/647118482d2fb43dac8260aa5be376f015ee85dc', 'message': 'Standardize aggregation methods and granularities for Gnocchi collector\n\nThis PR proposes the standardization of aggregation methods allowed by\nCloudKitty in Gnocchi collector as the aggregation methods available in\nGnocchi API for both archive policies and aggregation API. The rationale is\nthat we need to support the same aggregation methods available there.\nOtherwise, users can try to use something available in the Gnocchi API, and it\ndoes not work due to a limitation in CloudKitty.\n\nWe also propose to set the default granularity as 3600. CloudKitty is already\nusing one hour time frames by default. There is no sense in not setting the\ngranularity as 3600 as well. If we do not define the granularity 3600 by\ndefault, CloudKitty will always retrieve (in the aggregation API) measurements\nfor all available granularities, which is an overhead. Besides being an\noverhead, it can cause huge inconsistencies, if for some reason (that we\npainfully discovered in production), the granularity of 3600 is not returned.\nThe method ""_format_data""  does not check if the data being\n""formated""/obtained from the measurements object represents the 3600 (1h) time\nframe, it just retrieves the first element, and moves on; thus, leading to\nwrong billing information.\n\nAnd last, but not least, we propose a debug log to show in the log files, when\ndebug log level is enabled, the response received in the aggregation API. This\ncan enable debug for operation people. Otherwise, we need to change code to be\nable to troubleshoot problems with CloudKitty processing when using Gnocchi\ncollector.\n\nChange-Id: I8a1a75a74e04cb9babdf09f115620b152861e218\n'}, {'number': 3, 'created': '2020-01-29 12:44:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/05afa720612e5d382263e5a9a6ebd3ab3766736c', 'message': 'Standardize aggregation methods and granularities for Gnocchi collector\n\nThis PR proposes the standardization of aggregation methods allowed by\nCloudKitty in Gnocchi collector as the aggregation methods available in\nGnocchi API for both archive policies and aggregation API. The rationale is\nthat we need to support the same aggregation methods available there.\nOtherwise, users can try to use something available in the Gnocchi API, and it\ndoes not work due to a limitation in CloudKitty.\n\nWe also propose to set the default granularity as 3600. CloudKitty is already\nusing one hour time frames by default. There is no sense in not setting the\ngranularity as 3600 as well. If we do not define the granularity 3600 by\ndefault, CloudKitty will always retrieve (in the aggregation API) measurements\nfor all available granularities, which is an overhead. Besides being an\noverhead, it can cause huge inconsistencies, if for some reason (that we\npainfully discovered in production), the granularity of 3600 is not returned.\nThe method ""_format_data""  does not check if the data being\n""formated""/obtained from the measurements object represents the 3600 (1h) time\nframe, it just retrieves the first element, and moves on; thus, leading to\nwrong billing information.\n\nAnd last, but not least, we propose a debug log to show in the log files, when\ndebug log level is enabled, the response received in the aggregation API. This\ncan enable debug for operation people. Otherwise, we need to change code to be\nable to troubleshoot problems with CloudKitty processing when using Gnocchi\ncollector.\n\nChange-Id: I8a1a75a74e04cb9babdf09f115620b152861e218\n'}, {'number': 4, 'created': '2020-01-29 12:46:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/bbe53f99cdb9ed0dd364c9c3e3df86edad3dcea9', 'message': 'Standardize aggregation methods and granularities for Gnocchi collector\n\nThis PR proposes the standardization of aggregation methods allowed by\nCloudKitty in Gnocchi collector as the aggregation methods available in\nGnocchi API for both archive policies and aggregation API. The rationale is\nthat we need to support the same aggregation methods available there.\nOtherwise, users can try to use something available in the Gnocchi API, and it\ndoes not work due to a limitation in CloudKitty.\n\nWe also propose to set the default granularity as 3600. CloudKitty is already\nusing one hour time frames by default. There is no sense in not setting the\ngranularity as 3600 as well. If we do not define the granularity 3600 by\ndefault, CloudKitty will always retrieve (in the aggregation API) measurements\nfor all available granularities, which is an overhead. Besides being an\noverhead, it can cause huge inconsistencies, if for some reason (that we\npainfully discovered in production), the granularity of 3600 is not returned.\nThe method ""_format_data""  does not check if the data being\n""formated""/obtained from the measurements object represents the 3600 (1h) time\nframe, it just retrieves the first element, and moves on; thus, leading to\nwrong billing information.\n\nAnd last, but not least, we propose a debug log to show in the log files, when\ndebug log level is enabled, the response received in the aggregation API. This\ncan enable debug for operation people. Otherwise, we need to change code to be\nable to troubleshoot problems with CloudKitty processing when using Gnocchi\ncollector.\n\nChange-Id: I8a1a75a74e04cb9babdf09f115620b152861e218\n'}, {'number': 5, 'created': '2020-01-29 13:57:36.000000000', 'files': ['cloudkitty/tests/collectors/test_gnocchi.py', 'cloudkitty/collector/gnocchi.py', 'cloudkitty/tests/collectors/test_validation.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/385d20520f7163c08d39d17d0dc87ffc80839ec9', 'message': 'Standardize aggregation methods and granularities for Gnocchi collector\n\nThis PR proposes the standardization of aggregation methods allowed by\nCloudKitty in Gnocchi collector as the aggregation methods available in\nGnocchi API for both archive policies and aggregation API. The rationale is\nthat we need to support the same aggregation methods available there.\nOtherwise, users can try to use something available in the Gnocchi API, and it\ndoes not work due to a limitation in CloudKitty.\n\nWe also propose to set the default granularity as 3600. CloudKitty is already\nusing one hour time frames by default. There is no sense in not setting the\ngranularity as 3600 as well. If we do not define the granularity 3600 by\ndefault, CloudKitty will always retrieve (in the aggregation API) measurements\nfor all available granularities, which is an overhead. Besides being an\noverhead, it can cause huge inconsistencies, if for some reason (that we\npainfully discovered in production), the granularity of 3600 is not returned.\nThe method ""_format_data""  does not check if the data being\n""formated""/obtained from the measurements object represents the 3600 (1h) time\nframe, it just retrieves the first element, and moves on; thus, leading to\nwrong billing information.\n\nAnd last, but not least, we propose a debug log to show in the log files, when\ndebug log level is enabled, the response received in the aggregation API. This\ncan enable debug for operation people. Otherwise, we need to change code to be\nable to troubleshoot problems with CloudKitty processing when using Gnocchi\ncollector.\n\nChange-Id: I8a1a75a74e04cb9babdf09f115620b152861e218\n'}]",0,704787,385d20520f7163c08d39d17d0dc87ffc80839ec9,12,2,5,28356,,,0,"Standardize aggregation methods and granularities for Gnocchi collector

This PR proposes the standardization of aggregation methods allowed by
CloudKitty in Gnocchi collector as the aggregation methods available in
Gnocchi API for both archive policies and aggregation API. The rationale is
that we need to support the same aggregation methods available there.
Otherwise, users can try to use something available in the Gnocchi API, and it
does not work due to a limitation in CloudKitty.

We also propose to set the default granularity as 3600. CloudKitty is already
using one hour time frames by default. There is no sense in not setting the
granularity as 3600 as well. If we do not define the granularity 3600 by
default, CloudKitty will always retrieve (in the aggregation API) measurements
for all available granularities, which is an overhead. Besides being an
overhead, it can cause huge inconsistencies, if for some reason (that we
painfully discovered in production), the granularity of 3600 is not returned.
The method ""_format_data""  does not check if the data being
""formated""/obtained from the measurements object represents the 3600 (1h) time
frame, it just retrieves the first element, and moves on; thus, leading to
wrong billing information.

And last, but not least, we propose a debug log to show in the log files, when
debug log level is enabled, the response received in the aggregation API. This
can enable debug for operation people. Otherwise, we need to change code to be
able to troubleshoot problems with CloudKitty processing when using Gnocchi
collector.

Change-Id: I8a1a75a74e04cb9babdf09f115620b152861e218
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/87/704787/5 && git format-patch -1 --stdout FETCH_HEAD,['cloudkitty/collector/gnocchi.py'],1,da1c0ddbbd0573c4c332ff05e36eecd4a2910b61,,"# According to 'gnocchi/rest/aggregates/operations.py#AGG_MAP' and # 'gnocchi/rest/aggregates/operations.py#AGG_MAP' the following are the basic # aggregation methods that one can use when configuring an aggregation # method in the archive policy in Gnocchi or using the aggregation API. BASIC_AGGREGATION_METHODS = set(('mean', 'sum', 'last', 'max', 'min', 'std', 'median', 'first', 'count')) for agg in list(BASIC_AGGREGATION_METHODS): BASIC_AGGREGATION_METHODS.add(""rate:%s"" % agg) EXTRA_AGGREGATION_METHODS_FOR_ARCHIVE_POLICY = set( (str(i) + 'pct' for i in six.moves.range(1, 100))) for agg in list(EXTRA_AGGREGATION_METHODS_FOR_ARCHIVE_POLICY): EXTRA_AGGREGATION_METHODS_FOR_ARCHIVE_POLICY.add(""rate:%s"" % agg) # The aggregation method that one can use in to configure the archive # policies also supports the 'pct' (percentile) operation. Therefore, # we also expose this as a configuration. VALID_AGGREGATION_METHODS_FOR_METRICS = BASIC_AGGREGATION_METHODS.union( EXTRA_AGGREGATION_METHODS_FOR_ARCHIVE_POLICY) In(VALID_AGGREGATION_METHODS_FOR_METRICS), Required('re_aggregation_method', default='max'): In(BASIC_AGGREGATION_METHODS), Required('force_granularity', default=3600): All(int, Range(min=0)), op = self.build_operation_command(extra_args, metric_name) try: measurements = self._conn.aggregates.fetch(op, **agg_kwargs) LOG.debug(""Measurements [%s] received with operation [%s] and "" ""arguments [%s]."", measurements, op, agg_kwargs) return measurements def build_operation_command(self, extra_args, metric_name): re_aggregation_method = extra_args['re_aggregation_method'] # build aggregration operation op = [""aggregate"", re_aggregation_method, [""metric"", metric_name, extra_args['aggregation_method']]] return op "," In(['max', 'mean', 'min', 'rate:max', 'rate:mean', 'rate:min']), Required('re_aggregation_method', default=None): In([None, 'mean', 'median', 'std', 'min', 'max', 'sum', 'var', 'count']), Required('force_granularity', default=0): All(int, Range(min=0)), re_aggregation_method = extra_args['re_aggregation_method'] if re_aggregation_method is None: re_aggregation_method = extra_args['aggregation_method'] # build aggregration operation op = [""aggregate"", re_aggregation_method, [""metric"", metric_name, extra_args['aggregation_method']]] try: return self._conn.aggregates.fetch(op, **agg_kwargs)",38,13
openstack%2Fpython-cloudkittyclient~master~I7615601540419e45259291a7bfce1cc038c27986,openstack/python-cloudkittyclient,master,I7615601540419e45259291a7bfce1cc038c27986,[ussuri][goal] Drop python 2.7 support and testing,MERGED,2019-11-19 13:13:52.000000000,2020-01-31 10:41:17.000000000,2020-01-31 10:37:43.000000000,"[{'_account_id': 8556}, {'_account_id': 20182}, {'_account_id': 22348}, {'_account_id': 23060}, {'_account_id': 29503}]","[{'number': 1, 'created': '2019-11-19 13:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cloudkittyclient/commit/51597e31e94817ee46fefc0c2438c4cc7bbba67d', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nThis drops python2.7 support for cloudkittyclient. Even if this should be\ndone between milestone-1 and milestone-2, zuul jobs running on python2 are\ncurrently broken since nova dropped python2.7 support.\n\nChange-Id: I7615601540419e45259291a7bfce1cc038c27986\n'}, {'number': 2, 'created': '2019-11-20 09:22:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cloudkittyclient/commit/b8159e024f335669cdfaf5d69c6e226e2d84c024', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nThis drops python2.7 support for cloudkittyclient. Even if this should be\ndone between milestone-1 and milestone-2, zuul jobs running on python2 are\ncurrently broken since nova dropped python2.7 support.\n\nDepends-On: https://review.opendev.org/#/c/693631/\nChange-Id: I7615601540419e45259291a7bfce1cc038c27986\n'}, {'number': 3, 'created': '2019-12-17 08:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cloudkittyclient/commit/08cce4229ae45227a19f2f88c2f3eb7ae17b826f', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nThis drops python2.7 support for cloudkittyclient. Even if this should be\ndone between milestone-1 and milestone-2, zuul jobs running on python2 are\ncurrently broken since nova dropped python2.7 support.\n\nDepends-On: https://review.opendev.org/#/c/693631/\nChange-Id: I7615601540419e45259291a7bfce1cc038c27986\n'}, {'number': 4, 'created': '2019-12-17 09:27:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cloudkittyclient/commit/c570729a9afd99377d175b952b2327adf00cab33', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nThis drops python2.7 support for cloudkittyclient. Even if this should be\ndone between milestone-1 and milestone-2, zuul jobs running on python2 are\ncurrently broken since nova dropped python2.7 support.\n\nDepends-On: https://review.opendev.org/#/c/693631/\nChange-Id: I7615601540419e45259291a7bfce1cc038c27986\n'}, {'number': 5, 'created': '2019-12-18 13:17:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cloudkittyclient/commit/34078c6373c686a32c8a0c1867ba62f861670b72', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nThis drops python2.7 support for cloudkittyclient. Even if this should be\ndone between milestone-1 and milestone-2, zuul jobs running on python2 are\ncurrently broken since nova dropped python2.7 support.\n\nDepends-On: https://review.opendev.org/#/c/693631/\nChange-Id: I7615601540419e45259291a7bfce1cc038c27986\n'}, {'number': 6, 'created': '2020-01-23 13:42:39.000000000', 'files': ['releasenotes/notes/drop-py27-27ea9fb3e40d4987.yaml', '.zuul.yaml', 'doc/requirements.txt', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-cloudkittyclient/commit/9424e67f2104a6e8458b8259ab8fe6186b8efaa0', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nThis drops python2.7 support for cloudkittyclient. Even if this should be\ndone between milestone-1 and milestone-2, zuul jobs running on python2 are\ncurrently broken since nova dropped python2.7 support.\n\nDepends-On: https://review.opendev.org/#/c/693631/\nChange-Id: I7615601540419e45259291a7bfce1cc038c27986\n'}]",2,694999,9424e67f2104a6e8458b8259ab8fe6186b8efaa0,28,5,6,23060,,,0,"[ussuri][goal] Drop python 2.7 support and testing

This drops python2.7 support for cloudkittyclient. Even if this should be
done between milestone-1 and milestone-2, zuul jobs running on python2 are
currently broken since nova dropped python2.7 support.

Depends-On: https://review.opendev.org/#/c/693631/
Change-Id: I7615601540419e45259291a7bfce1cc038c27986
",git fetch https://review.opendev.org/openstack/python-cloudkittyclient refs/changes/99/694999/6 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/drop-py27-27ea9fb3e40d4987.yaml', '.zuul.yaml', 'doc/requirements.txt', 'setup.cfg', 'tox.ini']",5,51597e31e94817ee46fefc0c2438c4cc7bbba67d,drop-py27-support,"envlist = py36,py37,pep8basepython = python3","envlist = py27,py36,py37,pypy,pep8basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3",12,43
openstack%2Fneutron~master~I5b259717c0fdb8991f1df86b1ef4fb8ad0f18e70,openstack/neutron,master,I5b259717c0fdb8991f1df86b1ef4fb8ad0f18e70,"Improve ""OVSFirewallDriver.process_trusted_ports""",MERGED,2019-07-10 18:58:19.000000000,2020-01-31 10:35:39.000000000,2019-07-15 18:32:36.000000000,"[{'_account_id': 1131}, {'_account_id': 5948}, {'_account_id': 9732}, {'_account_id': 11975}, {'_account_id': 15554}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-07-10 18:58:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/db3f247c73d98cff04ce954d5da08f2154154e42', 'message': '[WIP] Improve ""OVSFirewallDriver.process_trusted_ports""\n\nChange-Id: I5b259717c0fdb8991f1df86b1ef4fb8ad0f18e70\nCloses-Bug: #1836095\nRelated-Bug: #1836023\n'}, {'number': 2, 'created': '2019-07-11 14:23:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e8f2a6f58937ad6506889c6b95c414334e89ac1c', 'message': 'Improve ""OVSFirewallDriver.process_trusted_ports""\n\nFirewallDriver.process_trusted_ports"" is called with many ports,\n""_initialize_egress_no_port_security"" retrieves the VIF ports\n(""Interface"" registers in OVS DB), one per iteration, based in the\nport_id. Instead of this procedure, if the DB is called only once to\nretrieve all the VIF ports, the performance increase is noticeable.\nE.g.: bridge with 1000 ports and interfaces.\n\nRetrieving 100 ports:\n- Bulk operation: 0.08 secs\n- Loop operation: 5.6 secs\n\nRetrieving 1000 ports:\n- Bulk operation: 0.08 secs\n- Loop operation: 59 secs\n\nCloses-Bug: #1836095\nRelated-Bug: #1836023\n\nChange-Id: I5b259717c0fdb8991f1df86b1ef4fb8ad0f18e70\n'}, {'number': 3, 'created': '2019-07-11 14:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/64168df744e1619ab9290327ad64298e1facf1a6', 'message': 'Improve ""OVSFirewallDriver.process_trusted_ports""\n\nFirewallDriver.process_trusted_ports"" is called with many ports,\n""_initialize_egress_no_port_security"" retrieves the VIF ports\n(""Interface"" registers in OVS DB), one per iteration, based in the\nport_id. Instead of this procedure, if the DB is called only once to\nretrieve all the VIF ports, the performance increase is noticeable.\nE.g.: bridge with 1000 ports and interfaces.\n\nRetrieving 100 ports:\n- Bulk operation: 0.08 secs\n- Loop operation: 5.6 secs\n\nRetrieving 1000 ports:\n- Bulk operation: 0.08 secs\n- Loop operation: 59 secs\n\nCloses-Bug: #1836095\nRelated-Bug: #1836023\n\nChange-Id: I5b259717c0fdb8991f1df86b1ef4fb8ad0f18e70\n'}, {'number': 4, 'created': '2019-07-12 15:59:09.000000000', 'files': ['neutron/agent/linux/openvswitch_firewall/firewall.py', 'neutron/tests/unit/agent/linux/openvswitch_firewall/test_firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ae1d36fa9d8e2115a5241b5da2e941cdefa2c463', 'message': 'Improve ""OVSFirewallDriver.process_trusted_ports""\n\nFirewallDriver.process_trusted_ports"" is called with many ports,\n""_initialize_egress_no_port_security"" retrieves the VIF ports\n(""Interface"" registers in OVS DB), one per iteration, based in the\nport_id. Instead of this procedure, if the DB is called only once to\nretrieve all the VIF ports, the performance increase is noticeable.\nE.g.: bridge with 1000 ports and interfaces.\n\nRetrieving 100 ports:\n- Bulk operation: 0.08 secs\n- Loop operation: 5.6 secs\n\nRetrieving 1000 ports:\n- Bulk operation: 0.08 secs\n- Loop operation: 59 secs\n\nCloses-Bug: #1836095\nRelated-Bug: #1836023\n\nChange-Id: I5b259717c0fdb8991f1df86b1ef4fb8ad0f18e70\n'}]",5,670162,ae1d36fa9d8e2115a5241b5da2e941cdefa2c463,30,8,4,16688,,,0,"Improve ""OVSFirewallDriver.process_trusted_ports""

FirewallDriver.process_trusted_ports"" is called with many ports,
""_initialize_egress_no_port_security"" retrieves the VIF ports
(""Interface"" registers in OVS DB), one per iteration, based in the
port_id. Instead of this procedure, if the DB is called only once to
retrieve all the VIF ports, the performance increase is noticeable.
E.g.: bridge with 1000 ports and interfaces.

Retrieving 100 ports:
- Bulk operation: 0.08 secs
- Loop operation: 5.6 secs

Retrieving 1000 ports:
- Bulk operation: 0.08 secs
- Loop operation: 59 secs

Closes-Bug: #1836095
Related-Bug: #1836023

Change-Id: I5b259717c0fdb8991f1df86b1ef4fb8ad0f18e70
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/670162/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/openvswitch_firewall/firewall.py'],1,db3f247c73d98cff04ce954d5da08f2154154e42,bug/1836095," def get_ovs_ports(self, port_ids): return self.int_br.br.get_vifs_by_ids(port_ids) ovs_ports = self.get_ovs_ports(port_ids) for port_id in port_ids: self._initialize_egress_no_port_security(port_id, ovs_ports=ovs_ports) def _initialize_egress_no_port_security(self, port_id, ovs_ports=None): try: if ovs_ports is not None: ovs_port = ovs_ports.get(port_id) if not ovs_port: raise exceptions.OVSFWPortNotFound(port_id=port_id) else: ovs_port = self.get_ovs_port(port_id)"," for port_id in port_ids: self._initialize_egress_no_port_security(port_id) def _initialize_egress_no_port_security(self, port_id): try: ovs_port = self.get_ovs_port(port_id)",13,3
openstack%2Fneutron~master~If865c4683645f9bd11f5e1b528bade0547505bfd,openstack/neutron,master,If865c4683645f9bd11f5e1b528bade0547505bfd,Re execute a test case if fixtures.TimeoutException is thrown,MERGED,2019-09-11 10:22:13.000000000,2020-01-31 10:14:56.000000000,2019-09-15 05:21:52.000000000,"[{'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 17499}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 28543}, {'_account_id': 28935}]","[{'number': 1, 'created': '2019-09-11 10:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d419f179688ab40f8e40265a9e97e985fb9c4c6', 'message': 'Re execute a test case if fixtures.TimeoutException is thrown\n\nSince [1] was introduced, it\'s very frequent to have\n""fixtures._fixtures.timeout.TimeoutException"" exceptions during the\nexecution of UTs and FTs. Because the privsep includes the synchronized\ndecorator, the synchronization wait is done inside the privsep context.\nThis is prone to timeouts if the wait is too long.\n\nUntil we can reorder the decorators of ip_lib [2] or we can remove the\nsync decorators [3], this patch can mitigate the errors in the CI.\n\n[1]https://review.opendev.org/#/c/631275/\n[2]https://review.opendev.org/#/c/666853/\n[3]https://review.opendev.org/#/c/657608/\n\nCloses-Bug: #1843478\n\nChange-Id: If865c4683645f9bd11f5e1b528bade0547505bfd\n'}, {'number': 2, 'created': '2019-09-12 10:50:23.000000000', 'files': ['neutron/tests/base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/63715ea361ea94fb48842c83deef1e5850bcc44d', 'message': 'Re execute a test case if fixtures.TimeoutException is thrown\n\nSince [1] was introduced, it\'s very frequent to have\n""fixtures._fixtures.timeout.TimeoutException"" exceptions during the\nexecution of UTs and FTs. Because the privsep includes the synchronized\ndecorator, the synchronization wait is done inside the privsep context.\nThis is prone to timeouts if the wait is too long.\n\nUntil we can reorder the decorators of ip_lib [2] or we can remove the\nsync decorators [3], this patch can mitigate the errors in the CI.\n\n[1]https://review.opendev.org/#/c/631275/\n[2]https://review.opendev.org/#/c/666853/\n[3]https://review.opendev.org/#/c/657608/\n\nCloses-Bug: #1843478\n\nChange-Id: If865c4683645f9bd11f5e1b528bade0547505bfd\n'}]",4,681432,63715ea361ea94fb48842c83deef1e5850bcc44d,25,14,2,16688,,,0,"Re execute a test case if fixtures.TimeoutException is thrown

Since [1] was introduced, it's very frequent to have
""fixtures._fixtures.timeout.TimeoutException"" exceptions during the
execution of UTs and FTs. Because the privsep includes the synchronized
decorator, the synchronization wait is done inside the privsep context.
This is prone to timeouts if the wait is too long.

Until we can reorder the decorators of ip_lib [2] or we can remove the
sync decorators [3], this patch can mitigate the errors in the CI.

[1]https://review.opendev.org/#/c/631275/
[2]https://review.opendev.org/#/c/666853/
[3]https://review.opendev.org/#/c/657608/

Closes-Bug: #1843478

Change-Id: If865c4683645f9bd11f5e1b528bade0547505bfd
",git fetch https://review.opendev.org/openstack/neutron refs/changes/32/681432/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/base.py'],1,6d419f179688ab40f8e40265a9e97e985fb9c4c6,bug/1843478,"TESTCASE_RETRIES = 3 for idx in range(1, TESTCASE_RETRIES + 1): try: return f(self, *args, **kwargs) except eventlet.Timeout as e: self.fail('Execution of this test timed out: %s' % e) except fixtures.TimeoutException: with excutils.save_and_reraise_exception() as ctxt: if idx < TESTCASE_RETRIES: msg = ('""fixtures.TimeoutException"" during test case ' 'execution no %s; test case re-executed' % idx) self.addDetail('DietTestCase', msg) ctxt.reraise = False"," try: return f(self, *args, **kwargs) except eventlet.Timeout as e: self.fail('Execution of this test timed out: %s' % e)",14,4
openstack%2Fironic~master~I59a046c06334a3366d0c7070114446efa832df23,openstack/ironic,master,I59a046c06334a3366d0c7070114446efa832df23,Fix typo in setup-network.sh script,MERGED,2020-01-29 11:05:55.000000000,2020-01-31 10:12:00.000000000,2020-01-29 15:45:07.000000000,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 11292}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 11:05:55.000000000', 'files': ['devstack/tools/ironic/scripts/setup-network.sh'], 'web_link': 'https://opendev.org/openstack/ironic/commit/90b747ac669ee8985335930945ee6fe20d8157fa', 'message': ""Fix typo in setup-network.sh script\n\nRemoving a $ sign that shouldn't be there and can cause trouble.\n\nChange-Id: I59a046c06334a3366d0c7070114446efa832df23\n""}]",1,704777,90b747ac669ee8985335930945ee6fe20d8157fa,11,5,1,23851,,,0,"Fix typo in setup-network.sh script

Removing a $ sign that shouldn't be there and can cause trouble.

Change-Id: I59a046c06334a3366d0c7070114446efa832df23
",git fetch https://review.opendev.org/openstack/ironic refs/changes/77/704777/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/tools/ironic/scripts/setup-network.sh'],1,90b747ac669ee8985335930945ee6fe20d8157fa,minor-fix-bash,(sudo ovs-vsctl list-br | grep ${BRIDGE_NAME}) || sudo ovs-vsctl add-br ${BRIDGE_NAME},(sudo ovs-vsctl list-br | grep ${BRIDGE_NAME}$) || sudo ovs-vsctl add-br ${BRIDGE_NAME},1,1
openstack%2Frequirements~master~I92db8edd3f0906dff28966e68f782795b2d54607,openstack/requirements,master,I92db8edd3f0906dff28966e68f782795b2d54607,manual update to sync upper-constraints,MERGED,2020-01-30 22:45:37.000000000,2020-01-31 10:10:44.000000000,2020-01-31 08:22:37.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-30 22:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/12b54309c106356b1bff65c073c0e33c626166c9', 'message': 'manual update to sync upper-constraints\n\nran with same options gate normally does\n\nChange-Id: I92db8edd3f0906dff28966e68f782795b2d54607\n'}, {'number': 2, 'created': '2020-01-31 00:29:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/061fc3340b6ede242b54541ce7b1bf20d5a48aac', 'message': 'manual update to sync upper-constraints\n\nran with same options gate normally does\n\nChange-Id: I92db8edd3f0906dff28966e68f782795b2d54607\n'}, {'number': 3, 'created': '2020-01-31 02:04:07.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/6a1c38d7270bffec543fb28c6acc7ffb16eac730', 'message': 'manual update to sync upper-constraints\n\nran with same options gate normally does\n\nChange-Id: I92db8edd3f0906dff28966e68f782795b2d54607\n'}]",1,705128,6a1c38d7270bffec543fb28c6acc7ffb16eac730,13,3,3,14288,,,0,"manual update to sync upper-constraints

ran with same options gate normally does

Change-Id: I92db8edd3f0906dff28966e68f782795b2d54607
",git fetch https://review.opendev.org/openstack/requirements refs/changes/28/705128/3 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,12b54309c106356b1bff65c073c0e33c626166c9,,lxml===4.5.0pytest===4.6.9;python_version=='2.7' pytest===5.3.5;python_version=='3.4' pytest===5.3.5;python_version=='3.5' pytest===5.3.5;python_version=='3.6' pytest===5.3.5;python_version=='3.7'neutron-lib===2.0.0;python_version=='3.4' neutron-lib===2.0.0;python_version=='3.5'pyghmi===1.5.5google-auth===1.11.0pyudev===0.22.0libvirt-python===5.10.0;python_version=='2.7' libvirt-python===6.0.0;python_version=='3.4' libvirt-python===6.0.0;python_version=='3.5' libvirt-python===6.0.0;python_version=='3.6' libvirt-python===6.0.0;python_version=='3.7'Jinja2===2.11.1zhmcclient===0.26.0autobahn===20.1.3;python_version=='3.4' autobahn===20.1.3;python_version=='3.5' autobahn===20.1.3;python_version=='3.6' autobahn===20.1.3;python_version=='3.7'coverage===5.0.3nwdiag===2.0.0importlib-metadata===1.5.0docutils===0.16boto3===1.11.9s3transfer===0.3.2packaging===20.1blockdiag===1.5.4;python_version=='2.7' blockdiag===2.0.0;python_version=='3.4' blockdiag===2.0.0;python_version=='3.5' blockdiag===2.0.0;python_version=='3.6' blockdiag===2.0.0;python_version=='3.7'WebTest===2.0.34more-itertools===8.2.0;python_version=='3.4' more-itertools===8.2.0;python_version=='3.5' more-itertools===8.2.0;python_version=='3.6' more-itertools===8.2.0;python_version=='3.7' seqdiag===0.9.6;python_version=='2.7' seqdiag===2.0.0;python_version=='3.4' seqdiag===2.0.0;python_version=='3.5' seqdiag===2.0.0;python_version=='3.6' seqdiag===2.0.0;python_version=='3.7'oslo.config===7.0.0httplib2===0.17.0botocore===1.14.9jsonpatch===1.25stomp.py===4.1.23;python_version=='2.7' stomp.py===5.0.1;python_version=='3.4' stomp.py===5.0.1;python_version=='3.5' stomp.py===5.0.1;python_version=='3.6' stomp.py===5.0.1;python_version=='3.7'dulwich===0.19.15etcd3gw===0.2.5python-ironicclient===3.1.1Paste===3.3.0Werkzeug===0.16.1python-magnumclient===2.16.0ovsdbapp===0.18.0;python_version=='2.7' ovsdbapp===1.0.0;python_version=='3.4' ovsdbapp===1.0.0;python_version=='3.5' ovsdbapp===1.0.0;python_version=='3.6' ovsdbapp===1.0.0;python_version=='3.7'zipp===2.1.0;python_version=='3.4' zipp===2.1.0;python_version=='3.5' zipp===2.1.0;python_version=='3.6' zipp===2.1.0;python_version=='3.7'actdiag===0.5.4;python_version=='2.7' actdiag===2.0.0;python_version=='3.4' actdiag===2.0.0;python_version=='3.5' actdiag===2.0.0;python_version=='3.6' actdiag===2.0.0;python_version=='3.7',lxml===4.4.2pytest===4.6.8;python_version=='2.7' pytest===5.3.2;python_version=='3.4' pytest===5.3.2;python_version=='3.5' pytest===5.3.2;python_version=='3.6' pytest===5.3.2;python_version=='3.7'neutron-lib===1.30.0;python_version=='3.4' neutron-lib===1.30.0;python_version=='3.5'pyghmi===1.5.3google-auth===1.10.2pyudev===0.21.0libvirt-python===5.10.0Jinja2===2.10.3zhmcclient===0.25.1autobahn===20.1.2;python_version=='3.4' autobahn===20.1.2;python_version=='3.5' autobahn===20.1.2;python_version=='3.6' autobahn===20.1.2;python_version=='3.7'coverage===5.0.1nwdiag===1.0.4importlib-metadata===1.4.0docutils===0.15.2boto3===1.11.7s3transfer===0.3.1packaging===20.0blockdiag===1.5.4WebTest===2.0.33more-itertools===8.1.0;python_version=='3.4' more-itertools===8.1.0;python_version=='3.5' more-itertools===8.1.0;python_version=='3.6' more-itertools===8.1.0;python_version=='3.7' seqdiag===0.9.6oslo.config===6.12.0httplib2===0.16.0botocore===1.14.7jsonpatch===1.24stomp.py===5.0.1dulwich===0.19.14etcd3gw===0.2.4python-ironicclient===3.1.0Paste===3.2.6Werkzeug===0.16.0python-magnumclient===2.15.0ovsdbapp===1.0.0zipp===1.1.0;python_version=='3.4' zipp===1.1.0;python_version=='3.5' zipp===2.0.1;python_version=='3.6' zipp===2.0.1;python_version=='3.7'actdiag===0.5.4,75,50
openstack%2Fcloudkitty-dashboard~master~I14f8982914ba690d47570319e3dce1ea492853c2,openstack/cloudkitty-dashboard,master,I14f8982914ba690d47570319e3dce1ea492853c2,Change README.rst with a better title,MERGED,2019-12-26 02:14:23.000000000,2020-01-31 10:08:34.000000000,2020-01-31 10:05:22.000000000,"[{'_account_id': 22348}, {'_account_id': 29503}]","[{'number': 1, 'created': '2019-12-26 02:14:23.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/cloudkitty-dashboard/commit/1ac189339e44fd9df64f4c966f541abf4b242726', 'message': 'Change README.rst with a better title\n\nChange-Id: I14f8982914ba690d47570319e3dce1ea492853c2\n'}]",0,700577,1ac189339e44fd9df64f4c966f541abf4b242726,8,2,1,27399,,,0,"Change README.rst with a better title

Change-Id: I14f8982914ba690d47570319e3dce1ea492853c2
",git fetch https://review.opendev.org/openstack/cloudkitty-dashboard refs/changes/77/700577/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,1ac189339e44fd9df64f4c966f541abf4b242726,developer,.. image:: https://governance.openstack.org/badges/cloudkitty-dashboard.svg :target: https://governance.openstack.org/tc/reference/tags/index.html .. Change things from this point on ,======================== Team and repository tags ======================== .. image:: https://governance.openstack.org/badges/cloudkitty-dashboard.svg :target: https://governance.openstack.org/reference/tags/index.html .. Change things from this point on ,6,9
openstack%2Fcloudkitty-dashboard~master~I6f393b85306e514f9e00567dfd2b9940d6f26253,openstack/cloudkitty-dashboard,master,I6f393b85306e514f9e00567dfd2b9940d6f26253,Drop Django 1.11 support,MERGED,2020-01-01 19:50:31.000000000,2020-01-31 10:07:13.000000000,2020-01-31 10:05:21.000000000,"[{'_account_id': 1736}, {'_account_id': 22348}, {'_account_id': 29313}, {'_account_id': 29503}]","[{'number': 1, 'created': '2020-01-01 19:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty-dashboard/commit/89c24eebe7b6e574fbe90832ce0262824d01b60a', 'message': 'Drop Django 1.11 support\n\nDjango 1.11 ends its extended support in April 2020 (which is before\nUssuri release), so horizon drops Django 1.11 support in Ussuri.\n\ntox envs for non-primary Django versions are no longer needed in tox.ini\nas testing environments for non-primary Django versions are setup in\nthe zuul jobs now.\n\nhorizon>=17.1.0 is required to use Django 2.2.\nrequirements.txt is updated accordingly.\n\nDepends-On: https://review.opendev.org/#/c/700733/\nChange-Id: I6f393b85306e514f9e00567dfd2b9940d6f26253\n'}, {'number': 2, 'created': '2020-01-01 21:03:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty-dashboard/commit/1095f42a07aa626bd3d9c30baf15379633438b93', 'message': 'Drop Django 1.11 support\n\nDjango 1.11 ends its extended support in April 2020 (which is before\nUssuri release), so horizon drops Django 1.11 support in Ussuri.\n\ntox envs for non-primary Django versions are no longer needed in tox.ini\nas testing environments for non-primary Django versions are setup in\nthe zuul jobs now.\n\nDepends-On: https://review.opendev.org/#/c/700733/\nChange-Id: I6f393b85306e514f9e00567dfd2b9940d6f26253\n'}, {'number': 3, 'created': '2020-01-08 02:46:43.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/cloudkitty-dashboard/commit/cade8de98453c66e37ecf0af270a1c21e76b0e23', 'message': 'Drop Django 1.11 support\n\nDjango 1.11 ends its extended support in April 2020 (which is before\nUssuri release), so horizon drops Django 1.11 support in Ussuri.\n\ntox envs for non-primary Django versions are no longer needed in tox.ini\nas testing environments for non-primary Django versions are setup in\nthe zuul jobs now.\n\nhorizon>=17.1.0 is required to use Django 2.2.\nrequirements.txt is updated accordingly.\nFor more info. please refer [1], [2].\n\n[1] https://review.opendev.org/#/c/700733/\n[2] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin\n\nChange-Id: I6f393b85306e514f9e00567dfd2b9940d6f26253\n'}]",0,700839,cade8de98453c66e37ecf0af270a1c21e76b0e23,16,4,3,29313,,,0,"Drop Django 1.11 support

Django 1.11 ends its extended support in April 2020 (which is before
Ussuri release), so horizon drops Django 1.11 support in Ussuri.

tox envs for non-primary Django versions are no longer needed in tox.ini
as testing environments for non-primary Django versions are setup in
the zuul jobs now.

horizon>=17.1.0 is required to use Django 2.2.
requirements.txt is updated accordingly.
For more info. please refer [1], [2].

[1] https://review.opendev.org/#/c/700733/
[2] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin

Change-Id: I6f393b85306e514f9e00567dfd2b9940d6f26253
",git fetch https://review.opendev.org/openstack/cloudkitty-dashboard refs/changes/39/700839/3 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'tox.ini']",2,89c24eebe7b6e574fbe90832ce0262824d01b60a,drop-django111-support,"envlist = py36,py37,pep8","envlist = py36,py37,py3-{dj111,dj22},pypy,pep8 dj111: pip install django>=1.11,<2 dj22: pip install django>=2.2,<2.3",2,3
openstack%2Fpuppet-openstacklib~master~I737fb14739a69ac12c39c7faf6dd2be1f772daa6,openstack/puppet-openstacklib,master,I737fb14739a69ac12c39c7faf6dd2be1f772daa6,Have doubled workers for keystone service,MERGED,2020-01-30 15:30:19.000000000,2020-01-31 10:01:06.000000000,2020-01-31 10:01:06.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-30 15:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/e7c9781b388d6cbb51eea5e12d0e92cfe5afdb3a', 'message': 'Have doubled workers for keystone service\n\nSince we have merged 2 keystone services(public and admin) into one,\nwe need to double keystone workers so that we have the same number of\nworkers, which is necessory to avoid performance degradation.\n\nThis patch introduced new facter, os_workers_keystone, which returns\n2 x os_workers .\n\nChange-Id: I737fb14739a69ac12c39c7faf6dd2be1f772daa6\n'}, {'number': 2, 'created': '2020-01-30 15:40:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/c2d708d2403a328d804b9f21de461bde2b667036', 'message': 'Have doubled workers for keystone service\n\nSince we have merged 2 keystone services(public and admin) into one,\nwe need to double keystone workers so that we have the same number of\nworkers, which is necessory to avoid performance degradation.\n\nThis patch introduced new facter, os_workers_keystone, which returns\n2 x os_workers .\n\nChange-Id: I737fb14739a69ac12c39c7faf6dd2be1f772daa6\n'}, {'number': 3, 'created': '2020-01-30 15:51:31.000000000', 'files': ['spec/unit/facter/os_workers_keystone_spec.rb', 'lib/facter/os_workers.rb'], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/74e0f5a3170b09632ad4ede7e20d3ebeb4514586', 'message': 'Have doubled workers for keystone service\n\nSince we have merged 2 keystone services(public and admin) into one,\nwe need to double keystone workers so that we have the same number of\nworkers, which is necessory to avoid performance degradation.\n\nThis patch introduced new facter, os_workers_keystone, which returns\n2 x os_workers .\n\nChange-Id: I737fb14739a69ac12c39c7faf6dd2be1f772daa6\n'}]",0,705041,74e0f5a3170b09632ad4ede7e20d3ebeb4514586,9,3,3,9816,,,0,"Have doubled workers for keystone service

Since we have merged 2 keystone services(public and admin) into one,
we need to double keystone workers so that we have the same number of
workers, which is necessory to avoid performance degradation.

This patch introduced new facter, os_workers_keystone, which returns
2 x os_workers .

Change-Id: I737fb14739a69ac12c39c7faf6dd2be1f772daa6
",git fetch https://review.opendev.org/openstack/puppet-openstacklib refs/changes/41/705041/3 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/facter/os_workers_keystone_spec.rb', 'lib/facter/os_workers.rb']",2,e7c9781b388d6cbb51eea5e12d0e92cfe5afdb3a,keystone_workers," # # Since we have merged keystone admin and keystone public into a single # keystone instance, we need doubled workers to have the same number # of workers, to avoid performance degradation. # Facter.add(:os_workers_keystone) do has_weight 100 setcode do processors = Facter.value('processorcount') [ [ processors.to_i, 4 ].max, 24 ].min end end",,49,0
openstack%2Fcloudkitty-specs~master~Iee69e7f5eecc7b017efeb98ee16f609f59ec8243,openstack/cloudkitty-specs,master,Iee69e7f5eecc7b017efeb98ee16f609f59ec8243,Spec: Monasca fetcher,MERGED,2019-10-08 08:53:34.000000000,2020-01-31 09:57:21.000000000,2020-01-31 09:53:58.000000000,"[{'_account_id': 22348}, {'_account_id': 23060}, {'_account_id': 29503}]","[{'number': 1, 'created': '2019-10-08 08:53:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty-specs/commit/87799045e1d354abb43580c1aaab7b7c1c5b839e', 'message': 'Spec: Monasca fetcher\n\nSee monasca_fethcer.rst for details.\n\nChange-Id: Iee69e7f5eecc7b017efeb98ee16f609f59ec8243\nStory: 2006675\nTask: 36950\n'}, {'number': 2, 'created': '2019-10-08 14:47:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty-specs/commit/c4ec49c6c04631ecd0be52db61bac90ec1b8516a', 'message': 'Spec: Monasca fetcher\n\nSee monasca_fetcher.rst for details.\n\nChange-Id: Iee69e7f5eecc7b017efeb98ee16f609f59ec8243\nStory: 2006675\nTask: 36950\n'}, {'number': 3, 'created': '2019-12-17 09:21:30.000000000', 'files': ['specs/ussuri/monasca_fetcher.rst'], 'web_link': 'https://opendev.org/openstack/cloudkitty-specs/commit/fadfba941c2b883909d1198b68fdfb03abb10f97', 'message': 'Spec: Monasca fetcher\n\nSee monasca_fetcher.rst for details.\n\nChange-Id: Iee69e7f5eecc7b017efeb98ee16f609f59ec8243\nStory: 2006675\nTask: 36950\n'}]",7,687248,fadfba941c2b883909d1198b68fdfb03abb10f97,14,3,3,30960,,,0,"Spec: Monasca fetcher

See monasca_fetcher.rst for details.

Change-Id: Iee69e7f5eecc7b017efeb98ee16f609f59ec8243
Story: 2006675
Task: 36950
",git fetch https://review.opendev.org/openstack/cloudkitty-specs refs/changes/48/687248/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/ussuri/monasca_fethcer.rst'],1,87799045e1d354abb43580c1aaab7b7c1c5b839e,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================= Cloudkitty monasca fetcher implementation ========================================= https://storyboard.openstack.org/#!/story/2006675 Monasca is already supported in cloudkitty through its collector. However, cloudkitty lacks a dedicated fetcher for monasca, relying instead on other fetchers. Problem Description =================== No scope discovery is avalaible when using the monasca collector. This forces users to use the keystone fetcher and assign the 'rating' role to every project where cloudkitty is needed. Proposed Change =============== Implementing a new fetcher dedicated to monasca using python-monascaclient's existing codebase / python API. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- The fetcher will use the same authentication mechanisims as the current monasca collector (keystone for authentication and python-monascaclient for monasca interactions), and won't introduce any new dependency. Thus, the new fetcher shouldn't have any security impact. Notifications Impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: qanglade/qanglade Other contributors: lukapeschke/peschk_l Work Items ---------- * Implement a cloudkitty monasca scope fetcher Dependencies ============ None new Testing ======= Regular unit tests will be included. Documentation Impact ==================== Documentation of the new fetcher will be added, mostly covering configuration of the fetcher. References ========== None. ",,118,0
openstack%2Fbifrost~master~I0b93c0e0b348f8bfa18f3a17941cbd7c8771da87,openstack/bifrost,master,I0b93c0e0b348f8bfa18f3a17941cbd7c8771da87,Revise the testing environment documentation,MERGED,2020-01-30 10:43:51.000000000,2020-01-31 09:45:03.000000000,2020-01-31 09:40:56.000000000,"[{'_account_id': 6618}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-01-30 10:43:51.000000000', 'files': ['doc/source/contributor/testenv.rst', 'doc/source/user/howto.rst'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/6d90609f6c6f47612003697c05ed66a4d2455516', 'message': 'Revise the testing environment documentation\n\n* Stop mentioning the removed agent_ssh driver\n* The CSV format is deprecated and no longer used\n* Provide correct links instead of ""above"" (which is no longer above).\n\nChange-Id: I0b93c0e0b348f8bfa18f3a17941cbd7c8771da87\n'}]",0,704958,6d90609f6c6f47612003697c05ed66a4d2455516,8,3,1,10239,,,0,"Revise the testing environment documentation

* Stop mentioning the removed agent_ssh driver
* The CSV format is deprecated and no longer used
* Provide correct links instead of ""above"" (which is no longer above).

Change-Id: I0b93c0e0b348f8bfa18f3a17941cbd7c8771da87
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/58/704958/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributor/testenv.rst', 'doc/source/user/howto.rst']",2,6d90609f6c6f47612003697c05ed66a4d2455516,docs," ""ipmi_address"": ""192.168.122.1"", ""ipmi_username"": ""admin"", ""ipmi_password"": ""pa$$w0rd"" ""driver"": ""ipmi"",.. _enroll: .. _deploy: "," ""ssh_port"": 22, ""ssh_username"": ""ironic"", ""ssh_virt_type"": ""virsh"", ""ssh_address"": ""192.168.122.1"", ""ssh_key_filename"": ""/home/ironic/.ssh/id_rsa"" ""driver"": ""agent_ssh"",",17,17
openstack%2Fbifrost~master~I4596bfb1d2c6fab47e501dc1a5f013877a3c3b87,openstack/bifrost,master,I4596bfb1d2c6fab47e501dc1a5f013877a3c3b87,Disable inspection power-off,MERGED,2020-01-27 23:49:19.000000000,2020-01-31 09:42:42.000000000,2020-01-31 09:40:55.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-01-27 23:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/1dd4cc102d5dc1fd75471706deeb8a36d3f2dc8d', 'message': 'Disable inspection power-off\n\nThis will enable inspection scenarios to operate the fast track\nbehavior.\n\nChange-Id: I4596bfb1d2c6fab47e501dc1a5f013877a3c3b87\n'}, {'number': 2, 'created': '2020-01-29 23:42:33.000000000', 'files': ['playbooks/roles/bifrost-ironic-install/templates/ironic.conf.j2', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'playbooks/roles/bifrost-ironic-install/templates/ironic-inspector.conf.j2', 'releasenotes/notes/inspector-no-longer-powers-off-796801e809184eee.yaml', 'playbooks/roles/bifrost-ironic-install/README.md'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/e522ab0fe71b8a2104ef4372d9652ed944af51bf', 'message': 'Disable inspection power-off\n\nThis will enable inspection scenarios to operate the fast track\nbehavior.\n\nChange-Id: I4596bfb1d2c6fab47e501dc1a5f013877a3c3b87\n'}]",5,704468,e522ab0fe71b8a2104ef4372d9652ed944af51bf,13,4,2,11655,,,0,"Disable inspection power-off

This will enable inspection scenarios to operate the fast track
behavior.

Change-Id: I4596bfb1d2c6fab47e501dc1a5f013877a3c3b87
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/68/704468/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'playbooks/roles/bifrost-ironic-install/templates/ironic-inspector.conf.j2', 'releasenotes/notes/inspector-no-longer-powers-off-796801e809184eee.yaml', 'playbooks/roles/bifrost-ironic-install/README.md']",4,1dd4cc102d5dc1fd75471706deeb8a36d3f2dc8d,704468,inspector_power_off_after_inspection: Boolean setting governing the behavior of ironic-inspector's processing. The default is to not power-off machines effectively enabling the Inspection to Deployment without the need to reboot the physical machine. ,,25,0
openstack%2Ftripleo-common~stable%2Ftrain~Iada9fb49881c8edc9c6ede46a939d1853204f896,openstack/tripleo-common,stable/train,Iada9fb49881c8edc9c6ede46a939d1853204f896,Make healthchecks more strict,MERGED,2020-01-28 18:18:38.000000000,2020-01-31 09:18:20.000000000,2020-01-30 09:27:16.000000000,"[{'_account_id': 3153}, {'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-28 18:18:38.000000000', 'files': ['healthcheck/common.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/dddf584505bb24c53ba9d5fd92396695dc7a540c', 'message': 'Make healthchecks more strict\n\nIt was discovered that healthchecks aren\'t really reliable because they\naren\'t strict enough.\n\nThe current patch adds the ""standard"" options in order to ensure we\nactually catch errors soon enough in order to return the actual state of\nthe checked element.\n\nIt also requires a small change for the healthcheck_port() function,\nsince the ""piping"" returned a 141 code instead of 0 due SIGPIPE being\nsent at some point[1].\n\nIt also depends on two other changes, in order to ensure we won\'t get\nany ""sudo"" issues inside the checks (here again, healthcheck_port is\ntricky).\n\n[1] https://stackoverflow.com/questions/19120263/why-exit-code-141-with-grep-q\n    http://www.tldp.org/LDP/lpg/node20.html\n\nDepends-On: https://review.opendev.org/703818\nDepends-On: https://review.opendev.org/703816\nChange-Id: Iada9fb49881c8edc9c6ede46a939d1853204f896\nCloses-Bug: #1860556\nRelated: https://bugzilla.redhat.com/show_bug.cgi?id=1794044\n(cherry picked from commit ba02b0a23582b286b775fd129e3a09970862755b)\n'}]",0,704651,dddf584505bb24c53ba9d5fd92396695dc7a540c,17,5,1,28223,,,0,"Make healthchecks more strict

It was discovered that healthchecks aren't really reliable because they
aren't strict enough.

The current patch adds the ""standard"" options in order to ensure we
actually catch errors soon enough in order to return the actual state of
the checked element.

It also requires a small change for the healthcheck_port() function,
since the ""piping"" returned a 141 code instead of 0 due SIGPIPE being
sent at some point[1].

It also depends on two other changes, in order to ensure we won't get
any ""sudo"" issues inside the checks (here again, healthcheck_port is
tricky).

[1] https://stackoverflow.com/questions/19120263/why-exit-code-141-with-grep-q
    http://www.tldp.org/LDP/lpg/node20.html

Depends-On: https://review.opendev.org/703818
Depends-On: https://review.opendev.org/703816
Change-Id: Iada9fb49881c8edc9c6ede46a939d1853204f896
Closes-Bug: #1860556
Related: https://bugzilla.redhat.com/show_bug.cgi?id=1794044
(cherry picked from commit ba02b0a23582b286b775fd129e3a09970862755b)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/51/704651/1 && git format-patch -1 --stdout FETCH_HEAD,['healthcheck/common.sh'],1,dddf584505bb24c53ba9d5fd92396695dc7a540c,healthchecks/strict-pipefail-stable/train,"set -eo pipefail # https://bugs.launchpad.net/tripleo/+bug/1860556 # do ot use ""-q"" option for grep, since it returns 141 for some reason with # set -o pipefail. # See https://stackoverflow.com/questions/19120263/why-exit-code-141-with-grep-q (ss -ntuap; sudo -u $puser ss -ntuap) | sort -u | grep -E "":($ports).*,pid=($pids),"">/dev/null"," (ss -ntuap; sudo -u $puser ss -ntuap) | sort -u | grep -qE "":($ports).*,pid=($pids),""",6,1
openstack%2Ftripleo-common~master~Iada9fb49881c8edc9c6ede46a939d1853204f896,openstack/tripleo-common,master,Iada9fb49881c8edc9c6ede46a939d1853204f896,Make healthchecks more strict,MERGED,2020-01-22 15:28:05.000000000,2020-01-31 09:15:56.000000000,2020-01-28 18:00:50.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 11090}, {'_account_id': 14985}, {'_account_id': 17823}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-22 15:28:05.000000000', 'files': ['healthcheck/common.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ba02b0a23582b286b775fd129e3a09970862755b', 'message': 'Make healthchecks more strict\n\nIt was discovered that healthchecks aren\'t really reliable because they\naren\'t strict enough.\n\nThe current patch adds the ""standard"" options in order to ensure we\nactually catch errors soon enough in order to return the actual state of\nthe checked element.\n\nIt also requires a small change for the healthcheck_port() function,\nsince the ""piping"" returned a 141 code instead of 0 due SIGPIPE being\nsent at some point[1].\n\nIt also depends on two other changes, in order to ensure we won\'t get\nany ""sudo"" issues inside the checks (here again, healthcheck_port is\ntricky).\n\n[1] https://stackoverflow.com/questions/19120263/why-exit-code-141-with-grep-q\n    http://www.tldp.org/LDP/lpg/node20.html\n\nDepends-On: https://review.opendev.org/703818\nDepends-On: https://review.opendev.org/703816\nChange-Id: Iada9fb49881c8edc9c6ede46a939d1853204f896\nCloses-Bug: #1860556\nRelated: https://bugzilla.redhat.com/show_bug.cgi?id=1794044\n'}]",3,703819,ba02b0a23582b286b775fd129e3a09970862755b,20,9,1,28223,,,0,"Make healthchecks more strict

It was discovered that healthchecks aren't really reliable because they
aren't strict enough.

The current patch adds the ""standard"" options in order to ensure we
actually catch errors soon enough in order to return the actual state of
the checked element.

It also requires a small change for the healthcheck_port() function,
since the ""piping"" returned a 141 code instead of 0 due SIGPIPE being
sent at some point[1].

It also depends on two other changes, in order to ensure we won't get
any ""sudo"" issues inside the checks (here again, healthcheck_port is
tricky).

[1] https://stackoverflow.com/questions/19120263/why-exit-code-141-with-grep-q
    http://www.tldp.org/LDP/lpg/node20.html

Depends-On: https://review.opendev.org/703818
Depends-On: https://review.opendev.org/703816
Change-Id: Iada9fb49881c8edc9c6ede46a939d1853204f896
Closes-Bug: #1860556
Related: https://bugzilla.redhat.com/show_bug.cgi?id=1794044
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/19/703819/1 && git format-patch -1 --stdout FETCH_HEAD,['healthcheck/common.sh'],1,ba02b0a23582b286b775fd129e3a09970862755b,healthchecks/strict-pipefail,"set -eo pipefail # https://bugs.launchpad.net/tripleo/+bug/1860556 # do ot use ""-q"" option for grep, since it returns 141 for some reason with # set -o pipefail. # See https://stackoverflow.com/questions/19120263/why-exit-code-141-with-grep-q (ss -ntuap; sudo -u $puser ss -ntuap) | sort -u | grep -E "":($ports).*,pid=($pids),"">/dev/null"," (ss -ntuap; sudo -u $puser ss -ntuap) | sort -u | grep -qE "":($ports).*,pid=($pids),""",6,1
openstack%2Fcharm-hacluster~master~Id9167534e8933312c561a6acba40399bca437706,openstack/charm-hacluster,master,Id9167534e8933312c561a6acba40399bca437706,Stop HA services accross units for series upgrade,MERGED,2020-01-16 14:45:53.000000000,2020-01-31 08:17:31.000000000,2020-01-31 08:17:31.000000000,"[{'_account_id': 12549}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 14:45:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/699fbb0fdf34f5149d0b3db691d9f219291c5001', 'message': ""Stop HA services accross units for series upgrade\n\nStop HA services accross all units of an application when doing a\nseries upgrade to avoid the situation where the cluster has some\nnodes on LTS N-1 and some on LTS N.\n\n1) In the 'pre-series-upgrade' send a notification to peers informing\n   them that the unit is doing a series upgrade and to which Ubuntu\n   version.\n2) Peers receive notification. If they are on a later Ubuntu version\n   than the one in the notification then they do nothing. Otherwise\n   they shutdown corosync and pacemaker and add an entry to the local\n   kv store with waiting-unit-upgrade=True.\n3) In the 'post-series-upgrade' hook the notification is removed from\n   the peer relation. waiting-unit-upgrade is set to False and\n   corosync and pacemaker are started.\n\nThe result of this is that when the first unit in the cluster starts\na series upgrade all cluster services are shutdown across all units.\nThey then rejoin the cluster one at a time when they have been\nupgraded to the new version.\n\nI added the waiting-unit-upgrade key to deal with the situation where\nthe first node clears the notification after it has successfully\nupgraded, with out the waiting-unit-upgrade the peers would not know\nthey were in a mixed Ubuntu version cluster.\n\nChange-Id: Id9167534e8933312c561a6acba40399bca437706\nCloses-Bug: 1859150\n""}, {'number': 2, 'created': '2020-01-17 09:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/8789862df42fcdbe399b9e5d7319284b29a1d239', 'message': ""Stop HA services accross units for series upgrade\n\nStop HA services accross all units of an application when doing a\nseries upgrade to avoid the situation where the cluster has some\nnodes on LTS N-1 and some on LTS N.\n\n1) In the 'pre-series-upgrade' send a notification to peers informing\n   them that the unit is doing a series upgrade and to which Ubuntu\n   version.\n2) Peers receive notification. If they are on a later Ubuntu version\n   than the one in the notification then they do nothing. Otherwise\n   they shutdown corosync and pacemaker and add an entry to the local\n   kv store with waiting-unit-upgrade=True.\n3) In the 'post-series-upgrade' hook the notification is removed from\n   the peer relation. waiting-unit-upgrade is set to False and\n   corosync and pacemaker are started.\n\nThe result of this is that when the first unit in the cluster starts\na series upgrade all cluster services are shutdown across all units.\nThey then rejoin the cluster one at a time when they have been\nupgraded to the new version.\n\nI added the waiting-unit-upgrade key to deal with the situation where\nthe first node clears the notification after it has successfully\nupgraded, with out the waiting-unit-upgrade the peers would not know\nthey were in a mixed Ubuntu version cluster.\n\nChange-Id: Id9167534e8933312c561a6acba40399bca437706\nCloses-Bug: 1859150\n""}, {'number': 3, 'created': '2020-01-17 10:35:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/ac7f36e5d82fcae5e73b35c397a513c971ff4959', 'message': ""Stop HA services accross units for series upgrade\n\nStop HA services accross all units of an application when doing a\nseries upgrade to avoid the situation where the cluster has some\nnodes on LTS N-1 and some on LTS N.\n\n1) In the 'pre-series-upgrade' send a notification to peers informing\n   them that the unit is doing a series upgrade and to which Ubuntu\n   version.\n2) Peers receive notification. If they are on a later Ubuntu version\n   than the one in the notification then they do nothing. Otherwise\n   they shutdown corosync and pacemaker and add an entry to the local\n   kv store with waiting-unit-upgrade=True.\n3) In the 'post-series-upgrade' hook the notification is removed from\n   the peer relation. waiting-unit-upgrade is set to False and\n   corosync and pacemaker are started.\n\nThe result of this is that when the first unit in the cluster starts\na series upgrade all cluster services are shutdown across all units.\nThey then rejoin the cluster one at a time when they have been\nupgraded to the new version.\n\nI added the waiting-unit-upgrade key to deal with the situation where\nthe first node clears the notification after it has successfully\nupgraded, with out the waiting-unit-upgrade the peers would not know\nthey were in a mixed Ubuntu version cluster.\n\nChange-Id: Id9167534e8933312c561a6acba40399bca437706\nCloses-Bug: 1859150\n""}, {'number': 4, 'created': '2020-01-30 19:43:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/ba16ace8c178b1e37388cb36ab37f3ccc6dce35b', 'message': ""Stop HA services accross units for series upgrade\n\nStop HA services accross all units of an application when doing a\nseries upgrade to avoid the situation where the cluster has some\nnodes on LTS N-1 and some on LTS N.\n\n1) In the 'pre-series-upgrade' send a notification to peers informing\n   them that the unit is doing a series upgrade and to which Ubuntu\n   version.\n2) Peers receive notification. If they are on a later Ubuntu version\n   than the one in the notification then they do nothing. Otherwise\n   they shutdown corosync and pacemaker and add an entry to the local\n   kv store with waiting-unit-upgrade=True.\n3) In the 'post-series-upgrade' hook the notification is removed from\n   the peer relation. waiting-unit-upgrade is set to False and\n   corosync and pacemaker are started.\n\nThe result of this is that when the first unit in the cluster starts\na series upgrade all cluster services are shutdown across all units.\nThey then rejoin the cluster one at a time when they have been\nupgraded to the new version.\n\nI added the waiting-unit-upgrade key to deal with the situation where\nthe first node clears the notification after it has successfully\nupgraded, with out the waiting-unit-upgrade the peers would not know\nthey were in a mixed Ubuntu version cluster.\n\nChange-Id: Id9167534e8933312c561a6acba40399bca437706\nCloses-Bug: 1859150\n""}, {'number': 5, 'created': '2020-01-31 07:16:26.000000000', 'files': ['hooks/hooks.py', 'hooks/utils.py', 'tests/tests.yaml', 'unit_tests/test_hacluster_utils.py', 'unit_tests/test_hacluster_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/d3512ef320e298142bfe9a3c3e96f342ab9a4cc6', 'message': ""Stop HA services accross units for series upgrade\n\nStop HA services accross all units of an application when doing a\nseries upgrade to avoid the situation where the cluster has some\nnodes on LTS N-1 and some on LTS N.\n\n1) In the 'pre-series-upgrade' send a notification to peers informing\n   them that the unit is doing a series upgrade and to which Ubuntu\n   version.\n2) Peers receive notification. If they are on a later Ubuntu version\n   than the one in the notification then they do nothing. Otherwise\n   they shutdown corosync and pacemaker and add an entry to the local\n   kv store with waiting-unit-upgrade=True.\n3) In the 'post-series-upgrade' hook the notification is removed from\n   the peer relation. waiting-unit-upgrade is set to False and\n   corosync and pacemaker are started.\n\nThe result of this is that when the first unit in the cluster starts\na series upgrade all cluster services are shutdown across all units.\nThey then rejoin the cluster one at a time when they have been\nupgraded to the new version.\n\nI added the waiting-unit-upgrade key to deal with the situation where\nthe first node clears the notification after it has successfully\nupgraded, with out the waiting-unit-upgrade the peers would not know\nthey were in a mixed Ubuntu version cluster.\n\nChange-Id: Id9167534e8933312c561a6acba40399bca437706\nCloses-Bug: 1859150\n""}]",9,702880,d3512ef320e298142bfe9a3c3e96f342ab9a4cc6,32,5,5,12549,,,0,"Stop HA services accross units for series upgrade

Stop HA services accross all units of an application when doing a
series upgrade to avoid the situation where the cluster has some
nodes on LTS N-1 and some on LTS N.

1) In the 'pre-series-upgrade' send a notification to peers informing
   them that the unit is doing a series upgrade and to which Ubuntu
   version.
2) Peers receive notification. If they are on a later Ubuntu version
   than the one in the notification then they do nothing. Otherwise
   they shutdown corosync and pacemaker and add an entry to the local
   kv store with waiting-unit-upgrade=True.
3) In the 'post-series-upgrade' hook the notification is removed from
   the peer relation. waiting-unit-upgrade is set to False and
   corosync and pacemaker are started.

The result of this is that when the first unit in the cluster starts
a series upgrade all cluster services are shutdown across all units.
They then rejoin the cluster one at a time when they have been
upgraded to the new version.

I added the waiting-unit-upgrade key to deal with the situation where
the first node clears the notification after it has successfully
upgraded, with out the waiting-unit-upgrade the peers would not know
they were in a mixed Ubuntu version cluster.

Change-Id: Id9167534e8933312c561a6acba40399bca437706
Closes-Bug: 1859150
",git fetch https://review.opendev.org/openstack/charm-hacluster refs/changes/80/702880/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/hooks.py', 'hooks/utils.py', 'unit_tests/test_hacluster_utils.py', 'unit_tests/test_hacluster_hooks.py']",4,699fbb0fdf34f5149d0b3db691d9f219291c5001,bug/1859150," @mock.patch.object(hooks, 'ha_relation_changed') @mock.patch.object(hooks, 'is_waiting_unit_upgrade_set') @mock.patch.object(hooks, 'set_waiting_unit_upgrade') @mock.patch.object(hooks, 'disable_ha_services') @mock.patch.object(hooks, 'get_series_upgrade_notifications') @mock.patch.object(hooks, 'lsb_release') def test_hanode_relation_changed(self, lsb_release, get_series_upgrade_notifications, disable_ha_services, set_waiting_unit_upgrade, is_waiting_unit_upgrade_set, ha_relation_changed): lsb_release.return_value = { 'DISTRIB_CODENAME': 'trusty'} get_series_upgrade_notifications.return_value = { 'unit1': 'xenial'} is_waiting_unit_upgrade_set.return_value = True hooks.hanode_relation_changed() disable_ha_services.assert_called_once_with() set_waiting_unit_upgrade.assert_called_once_with() self.assertFalse(ha_relation_changed.called) @mock.patch.object(hooks, 'ha_relation_changed') @mock.patch.object(hooks, 'is_waiting_unit_upgrade_set') @mock.patch.object(hooks, 'set_waiting_unit_upgrade') @mock.patch.object(hooks, 'disable_ha_services') @mock.patch.object(hooks, 'get_series_upgrade_notifications') @mock.patch.object(hooks, 'lsb_release') def test_hanode_relation_changed_no_up(self, lsb_release, get_series_upgrade_notifications, disable_ha_services, set_waiting_unit_upgrade, is_waiting_unit_upgrade_set, ha_relation_changed): lsb_release.return_value = { 'DISTRIB_CODENAME': 'trusty'} get_series_upgrade_notifications.return_value = {} is_waiting_unit_upgrade_set.return_value = False hooks.hanode_relation_changed() ha_relation_changed.assert_called_once_with() @mock.patch.object(hooks, 'set_unit_upgrading') @mock.patch.object(hooks, 'is_unit_paused_set') @mock.patch.object(hooks, 'pause_unit') @mock.patch.object(hooks, 'notify_peers_of_series_upgrade') def test_series_upgrade_prepare(self, notify_peers_of_series_upgrade, pause_unit, is_unit_paused_set, set_unit_upgrading): is_unit_paused_set.return_value = False hooks.series_upgrade_prepare() set_unit_upgrading.assert_called_once_with() pause_unit.assert_called_once_with() notify_peers_of_series_upgrade.assert_called_once_with() @mock.patch.object(hooks, 'clear_unit_paused') @mock.patch.object(hooks, 'clear_unit_upgrading') @mock.patch.object(hooks, 'config_changed') @mock.patch.object(hooks, 'enable_ha_services') @mock.patch.object(hooks, 'resume_unit') @mock.patch.object(hooks, 'clear_series_upgrade_notification') @mock.patch.object(hooks, 'clear_waiting_unit_upgrade') def test_series_upgrade_complete(self, clear_waiting_unit_upgrade, clear_series_upgrade_notification, resume_unit, enable_ha_services, config_changed, clear_unit_upgrading, clear_unit_paused): hooks.series_upgrade_complete() clear_waiting_unit_upgrade.assert_called_once_with() clear_series_upgrade_notification.assert_called_once_with() resume_unit.assert_called_once_with() enable_ha_services.assert_called_once_with() config_changed.assert_called_once_with() clear_unit_upgrading.assert_called_once_with() clear_unit_paused.assert_called_once_with() ",,354,2
openstack%2Ftripleo-heat-templates~master~I3aa774c06d91a3b67726fad0d0ca409cda5b78b9,openstack/tripleo-heat-templates,master,I3aa774c06d91a3b67726fad0d0ca409cda5b78b9,Create qemu user/group on controller,MERGED,2020-01-27 10:57:54.000000000,2020-01-31 07:56:31.000000000,2020-01-30 02:55:14.000000000,"[{'_account_id': 3153}, {'_account_id': 9592}, {'_account_id': 12393}, {'_account_id': 14250}, {'_account_id': 14985}, {'_account_id': 16643}, {'_account_id': 17216}, {'_account_id': 20172}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}, {'_account_id': 30133}, {'_account_id': 30921}]","[{'number': 1, 'created': '2020-01-27 10:57:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/45610c4fbb7d9d2e4035d72c42406ff946e0a1ec', 'message': 'Create qemu user/group on controller\n\nDeployment is failing with error [1] because theowner/group\nof the TLS generated certificate and key were set to \'qemu\'.\nThis user and group exist on compute nodes, but not on controller.\n[1] Error: Could not find group qemu""\n\nThis patch adds \'qemu\' user/group on controller node to\nresolve the issue.\n\nChange-Id: I3aa774c06d91a3b67726fad0d0ca409cda5b78b9\nCloses-Bug: #1860971\n'}, {'number': 2, 'created': '2020-01-27 15:21:26.000000000', 'files': ['deployment/nova/nova-vnc-proxy-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b8c6154e7afda5525be00189afde15dac649a7b2', 'message': 'Create qemu user/group on controller\n\nDeployment is failing with error [1] because the owner/group\nof the TLS generated certificate and key were set to \'qemu\'.\nThis user and group exist on compute nodes, but not on controller.\n[1] Error: Could not find group qemu""\n\nThis patch adds \'qemu\' user/group on controller node to\nresolve the issue as this user is required to retrieve the cert,\nused by the VNC proxy, the same way as on the compute nodes.\n\nChange-Id: I3aa774c06d91a3b67726fad0d0ca409cda5b78b9\nCloses-Bug: #1860971\n'}]",0,704303,b8c6154e7afda5525be00189afde15dac649a7b2,30,14,2,20733,,,0,"Create qemu user/group on controller

Deployment is failing with error [1] because the owner/group
of the TLS generated certificate and key were set to 'qemu'.
This user and group exist on compute nodes, but not on controller.
[1] Error: Could not find group qemu""

This patch adds 'qemu' user/group on controller node to
resolve the issue as this user is required to retrieve the cert,
used by the VNC proxy, the same way as on the compute nodes.

Change-Id: I3aa774c06d91a3b67726fad0d0ca409cda5b78b9
Closes-Bug: #1860971
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/03/704303/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/nova/nova-api-container-puppet.yaml'],1,45610c4fbb7d9d2e4035d72c42406ff946e0a1ec,1860971," host_prep_tasks: list_concat: - {get_attr: [NovaApiLogging, host_prep_tasks]} - - name: ensure qemu group is present on the host group: name: qemu gid: 107 state: present - name: ensure qemu user is present on the host user: name: qemu uid: 107 group: qemu state: present shell: /sbin/nologin comment: qemu user"," host_prep_tasks: {get_attr: [NovaApiLogging, host_prep_tasks]}",16,1
openstack%2Fproject-config~master~Ib1ed516df24ee113322f791bbbeab6286d34967e,openstack/project-config,master,Ib1ed516df24ee113322f791bbbeab6286d34967e,Artifact to AFS publishing - don't use archive flag,MERGED,2020-01-31 06:25:30.000000000,2020-01-31 07:35:06.000000000,2020-01-31 07:28:07.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-31 06:25:30.000000000', 'files': ['playbooks/publish/openstack-artifacts-with-afs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/89e400b98e1198529b459931532fa590402dcf80', 'message': ""Artifact to AFS publishing - don't use archive flag\n\nThe -a flag to rsync tries to maintain owner and group permissions\nwhich doesn't work copying to AFS.\n\nThis sets the flags to the same as the upload-afs role at [1]\n\nhttps://opendev.org/zuul/zuul-jobs/src/commit/fc27907b987fc7d4adfa5ca07f3801d589e3b344/roles/upload-afs/library/zuul_afs.py#L78\n\nChange-Id: Ib1ed516df24ee113322f791bbbeab6286d34967e\n""}]",0,705159,89e400b98e1198529b459931532fa590402dcf80,7,2,1,7118,,,0,"Artifact to AFS publishing - don't use archive flag

The -a flag to rsync tries to maintain owner and group permissions
which doesn't work copying to AFS.

This sets the flags to the same as the upload-afs role at [1]

https://opendev.org/zuul/zuul-jobs/src/commit/fc27907b987fc7d4adfa5ca07f3801d589e3b344/roles/upload-afs/library/zuul_afs.py#L78

Change-Id: Ib1ed516df24ee113322f791bbbeab6286d34967e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/59/705159/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/publish/openstack-artifacts-with-afs.yaml'],1,89e400b98e1198529b459931532fa590402dcf80,static-services, # can't set group permissions on AFS; see upload-afs role archive: false perms: true times: true recursive: true rsync_opts: - '--safe-links' - '--delete-after',,8,0
openstack%2Fcharm-percona-cluster~master~I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f,openstack/charm-percona-cluster,master,I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f,Notify clients of series upgrade,MERGED,2020-01-29 06:32:37.000000000,2020-01-31 07:24:07.000000000,2020-01-31 07:24:07.000000000,"[{'_account_id': 12549}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 06:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/fdd65995b816fd9f488fa7240dedf4854eac4d07', 'message': 'Notify clients of series upgrade\n\nWhen the percona cluster is undergoing a series upgrade, clients\nshould suspend db activity in their hooks (like db migrations).\n\nThis change sents a notification of upgrade down the shared-db\nrelation which clients can then react to.\n\nChange-Id: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f\n'}, {'number': 2, 'created': '2020-01-29 12:56:29.000000000', 'files': ['tests/tests.yaml', 'charmhelpers/contrib/openstack/utils.py', 'actions/actions.py', 'charmhelpers/contrib/hahelpers/cluster.py', 'unit_tests/test_percona_hooks.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/hardening/audits/apt.py', 'unit_tests/test_actions.py', 'charmhelpers/contrib/database/mysql.py', 'hooks/percona_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/8443c165f9c5e4d043cba20b790a3407979f104f', 'message': 'Notify clients of series upgrade\n\nWhen the percona cluster is undergoing a series upgrade, clients\nshould suspend db activity in their hooks (like db migrations).\n\nThis change sents a notification of upgrade down the shared-db\nrelation which clients can then react to.\n\nChange-Id: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f\n'}]",0,704730,8443c165f9c5e4d043cba20b790a3407979f104f,14,4,2,12549,,,0,"Notify clients of series upgrade

When the percona cluster is undergoing a series upgrade, clients
should suspend db activity in their hooks (like db migrations).

This change sents a notification of upgrade down the shared-db
relation which clients can then react to.

Change-Id: I5d8ed7d3935db5568c50f8d585e37a4d0cc6914f
",git fetch https://review.opendev.org/openstack/charm-percona-cluster refs/changes/30/704730/1 && git format-patch -1 --stdout FETCH_HEAD,"['actions/actions.py', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/contrib/openstack/utils.py', 'unit_tests/test_percona_hooks.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/hardening/audits/apt.py', 'unit_tests/test_actions.py', 'charmhelpers/contrib/database/mysql.py', 'hooks/percona_hooks.py']",9,fdd65995b816fd9f488fa7240dedf4854eac4d07,notify-clients-maitenace," DB_SERIES_UPGRADING_KEY, for r_id in relation_ids('shared-db'): relation_set( relation_id=r_id, relation_settings={DB_SERIES_UPGRADING_KEY: True}) if not leader_get('cluster_series_upgrading'): for r_id in relation_ids('shared-db'): relation_set( relation_id=r_id, relation_settings={DB_SERIES_UPGRADING_KEY: None})",,216,4
openstack%2Fglance~master~Ieecfb11928f74a504b35172a2c96d3a8cba057c0,openstack/glance,master,Ieecfb11928f74a504b35172a2c96d3a8cba057c0,fix properties' missing underline for VirtCPUTopology,MERGED,2019-09-04 04:04:06.000000000,2020-01-31 06:20:05.000000000,2020-01-28 05:31:28.000000000,"[{'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 9008}, {'_account_id': 9303}, {'_account_id': 21757}, {'_account_id': 22348}, {'_account_id': 24849}, {'_account_id': 27594}, {'_account_id': 28367}]","[{'number': 1, 'created': '2019-09-04 04:04:06.000000000', 'files': ['etc/metadefs/compute-vcputopology.json'], 'web_link': 'https://opendev.org/openstack/glance/commit/da277c583a2b9a311c4ba66c5856e501944e11d8', 'message': ""fix properties' missing underline for VirtCPUTopology\n\nAccording to the docs:\nhttps://opendev.org/openstack/nova-specs/src/branch/master/specs/juno/implemented/virt-driver-vcpu-topology.rst,\ncpu_maxsockets, cpu_maxcores, cpu_maxthreads should be cpu_max_sockets, cpu_max_cores, cpu_max_threads.\n\nChange-Id: Ieecfb11928f74a504b35172a2c96d3a8cba057c0\nSigned-off-by: Ning Yao <yaoning@unitedstack.com>\n""}]",0,679895,da277c583a2b9a311c4ba66c5856e501944e11d8,12,9,1,24849,,,0,"fix properties' missing underline for VirtCPUTopology

According to the docs:
https://opendev.org/openstack/nova-specs/src/branch/master/specs/juno/implemented/virt-driver-vcpu-topology.rst,
cpu_maxsockets, cpu_maxcores, cpu_maxthreads should be cpu_max_sockets, cpu_max_cores, cpu_max_threads.

Change-Id: Ieecfb11928f74a504b35172a2c96d3a8cba057c0
Signed-off-by: Ning Yao <yaoning@unitedstack.com>
",git fetch https://review.opendev.org/openstack/glance refs/changes/95/679895/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/metadefs/compute-vcputopology.json'],1,da277c583a2b9a311c4ba66c5856e501944e11d8,," ""cpu_max_sockets"": { ""cpu_max_cores"": { ""cpu_max_threads"": {"," ""cpu_maxsockets"": { ""cpu_maxcores"": { ""cpu_maxthreads"": {",3,3
openstack%2Fproject-config~master~Iea71bb8e583daa31ab2dcbe08b9a84cb3ba0863f,openstack/project-config,master,Iea71bb8e583daa31ab2dcbe08b9a84cb3ba0863f,Artifact publishing to AFS - don't use upload-afs,MERGED,2020-01-31 03:58:47.000000000,2020-01-31 06:08:59.000000000,2020-01-31 06:00:09.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-31 03:58:47.000000000', 'files': ['playbooks/publish/openstack-artifacts-with-afs.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c7225ad04285375625ed17c7efd295016beae9aa', 'message': ""Artifact publishing to AFS - don't use upload-afs\n\nThe upload-afs role has a range of features for publishing\ndocumentation trees that we don't need -- we just want a straight copy\nof the artifacts/ directory to the output location.  Just use a\nhard-coded synchronize: call.\n\nChange-Id: Iea71bb8e583daa31ab2dcbe08b9a84cb3ba0863f\n""}]",0,705156,c7225ad04285375625ed17c7efd295016beae9aa,8,2,1,7118,,,0,"Artifact publishing to AFS - don't use upload-afs

The upload-afs role has a range of features for publishing
documentation trees that we don't need -- we just want a straight copy
of the artifacts/ directory to the output location.  Just use a
hard-coded synchronize: call.

Change-Id: Iea71bb8e583daa31ab2dcbe08b9a84cb3ba0863f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/56/705156/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/publish/openstack-artifacts-with-afs.yaml', 'zuul.d/jobs.yaml']",2,c7225ad04285375625ed17c7efd295016beae9aa,static-services,," vars: afs_source: ""{{ zuul.executor.work_root }}/artifacts"" afs_target: ""/afs/.openstack.org/project/tarballs.opendev.org/{{ zuul.project.name }}""",8,6
openstack%2Fswift~master~I60d4ad62c7d14ed15e114ed95102a2368c48f9f4,openstack/swift,master,I60d4ad62c7d14ed15e114ed95102a2368c48f9f4,Authors/changelog for swift 2.24.0,MERGED,2020-01-28 01:10:32.000000000,2020-01-31 05:59:02.000000000,2020-01-31 05:57:24.000000000,"[{'_account_id': 7233}, {'_account_id': 9625}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-28 01:10:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2d589bc44f6afb5fc94135ef70f92fa5f116d36f', 'message': 'Authors/changelog for swift 2.24.0\n\nChange-Id: I60d4ad62c7d14ed15e114ed95102a2368c48f9f4\n'}, {'number': 2, 'created': '2020-01-29 04:56:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5ca0ed031094f5947e4e4555b358da46962e066a', 'message': 'Authors/changelog for swift 2.24.0\n\nChange-Id: I60d4ad62c7d14ed15e114ed95102a2368c48f9f4\n'}, {'number': 3, 'created': '2020-01-31 00:17:52.000000000', 'files': ['CHANGELOG', 'releasenotes/notes/2_24_0_release-1ca244cc959922fc.yaml', 'AUTHORS'], 'web_link': 'https://opendev.org/openstack/swift/commit/5cd854b783ce80356ec62e709f0817cbe699c8cd', 'message': 'Authors/changelog for swift 2.24.0\n\nChange-Id: I60d4ad62c7d14ed15e114ed95102a2368c48f9f4\n'}]",4,704481,5cd854b783ce80356ec62e709f0817cbe699c8cd,17,4,3,15343,,,0,"Authors/changelog for swift 2.24.0

Change-Id: I60d4ad62c7d14ed15e114ed95102a2368c48f9f4
",git fetch https://review.opendev.org/openstack/swift refs/changes/81/704481/1 && git format-patch -1 --stdout FETCH_HEAD,"['CHANGELOG', 'releasenotes/notes/2_24_0_release-1ca244cc959922fc.yaml', 'AUTHORS']",3,2d589bc44f6afb5fc94135ef70f92fa5f116d36f,704481,Adrien Pensart (adrien.pensart@corp.ovh.com)Chris Smart (chris.smart@humanservices.gov.au)SeongSoo Cho (ppiyakk2@printf.kr),,155,0
openstack%2Fdevstack~master~Ia2b7e2e33d784560443131e2965f520b361a54e3,openstack/devstack,master,Ia2b7e2e33d784560443131e2965f520b361a54e3,Switch to python3 for memory_peak service,MERGED,2020-01-24 05:49:25.000000000,2020-01-31 05:58:32.000000000,2020-01-31 05:57:23.000000000,"[{'_account_id': 1131}, {'_account_id': 5196}, {'_account_id': 6873}, {'_account_id': 7118}, {'_account_id': 8556}, {'_account_id': 8655}, {'_account_id': 11952}, {'_account_id': 11975}, {'_account_id': 13252}, {'_account_id': 14070}, {'_account_id': 19118}, {'_account_id': 22348}, {'_account_id': 27329}, {'_account_id': 27978}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-24 05:49:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/9508a816d574ecb0bc8049d235ea7a11a4a21a0a', 'message': 'Use python3 command in memory_tracker.sh by default\n\nChange-Id: Ia2b7e2e33d784560443131e2965f520b361a54e3\n'}, {'number': 2, 'created': '2020-01-24 08:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/5b41aa57db5bab984ea9b49f06304579ef7a590b', 'message': 'Use python3 command in memory_tracker.sh by default\n\nCloses-bug: #1860753\nChange-Id: Ia2b7e2e33d784560443131e2965f520b361a54e3\n'}, {'number': 3, 'created': '2020-01-24 08:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/001795bfa90b8a24e7daa56d07fa2d360b6de7d0', 'message': 'Use python3 command in memory_tracker.sh by default\n\nCloses-Bug: #1860753\nChange-Id: Ia2b7e2e33d784560443131e2965f520b361a54e3\n'}, {'number': 4, 'created': '2020-01-24 09:06:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/989645bcd01dd1430473dce2a81c8930cc4bba70', 'message': 'Use python3 command in memory_tracker.sh by default\n\nCloses-Bug: #1860753\nChange-Id: Ia2b7e2e33d784560443131e2965f520b361a54e3\n'}, {'number': 5, 'created': '2020-01-24 09:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4a2c835438fa75c1fcba5a48f35e6f23fea5c657', 'message': 'Use python3 command in memory_tracker.sh by default\n\nCloses-Bug: #1860753\nChange-Id: Ia2b7e2e33d784560443131e2965f520b361a54e3\n'}, {'number': 6, 'created': '2020-01-24 09:20:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/9a654022da15054086c017d4ebe81c44fd436fb9', 'message': 'Use python3 command in memory_tracker.sh by default\n\nCloses-Bug: #1860753\nChange-Id: Ia2b7e2e33d784560443131e2965f520b361a54e3\n'}, {'number': 7, 'created': '2020-01-24 09:25:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/b7e34ed57d3abc09dec17f7492d835b3160423ab', 'message': ""Exports PYTHON variable to systemd unit files\n\nWhen starting 'memory_peak' service PYTHON environment variable is not\nset causing to use python command for executing 'tools/mlock_report.py'\nscript instead of the one chosed by DevStack.\n\nThis fixes this by passing PYTHON variable when generating systemd unit\nfiles. It also set python3 as default interpreter for memory_peak\nservice when PYTHON variable is not defined.\n\nCloses-Bug: #1860753\nChange-Id: Ia2b7e2e33d784560443131e2965f520b361a54e3\n""}, {'number': 8, 'created': '2020-01-24 09:26:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d96fa76c809fc7f72ff31211d6b3e80e9236e109', 'message': ""Exports PYTHON variable to systemd unit files\n\nWhen starting 'memory_peak' service PYTHON environment variable is not\nset causing to use python command for executing 'tools/mlock_report.py'\nscript instead of the one chosed by DevStack.\n\nThis fixes this by passing PYTHON variable when generating systemd unit\nfiles. It also set python3 as default interpreter for memory_peak\nservice when PYTHON variable is not defined.\n\nCloses-Bug: #1860753\nChange-Id: Ia2b7e2e33d784560443131e2965f520b361a54e3\n""}, {'number': 9, 'created': '2020-01-24 10:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/8cb65ac8889d9678791afa0e2b5f22ac2a03a752', 'message': ""Exports PYTHON variable to systemd unit files\n\nWhen starting 'memory_peak' service PYTHON environment variable is not\nset causing to use python command for executing 'tools/mlock_report.py'\nscript instead of the one chosed by DevStack.\n\nThis fixes this by passing PYTHON variable when generating systemd unit\nfiles.\n\nCloses-Bug: #1860753\nChange-Id: Ia2b7e2e33d784560443131e2965f520b361a54e3\n""}, {'number': 10, 'created': '2020-01-27 08:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/70ebf4b35ab9ae29128ced37b36835a86b342620', 'message': ""Exports PYTHON variable to systemd unit files\n\nWhen starting 'memory_peak' service PYTHON environment variable is not\nset causing to use python command for executing 'tools/mlock_report.py'\nscript instead of the one chosed by DevStack.\n\nThis fixes this by passing PYTHON variable when generating systemd unit\nfiles.\n\nCloses-Bug: #1860753\nChange-Id: Ia2b7e2e33d784560443131e2965f520b361a54e3\n""}, {'number': 11, 'created': '2020-01-28 16:25:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/1e66187e5e76682a50f39fc20f3bf4bb2f6d96b8', 'message': ""Switch to python3 for memory_peak service\n\nWhen starting 'memory_peak' service is using python command instead of\npython3, while psutil (required package) is most probably being\ninstalled into the python3 environment (as we are dropping python2.7\nsupport).\n\nCloses-Bug: #1860753\nChange-Id: Ia2b7e2e33d784560443131e2965f520b361a54e3\n""}, {'number': 12, 'created': '2020-01-28 19:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/28909424916a761ad316ddbda7db1bea405ddf57', 'message': ""Switch to python3 for memory_peak service\n\nWhen starting 'memory_peak' service is using python command instead of\npython3, while psutil (required package) is most probably being\ninstalled into the python3 environment (as we are dropping python2.7\nsupport).\n\nCloses-Bug: #1860753\nChange-Id: Ia2b7e2e33d784560443131e2965f520b361a54e3\n""}, {'number': 13, 'created': '2020-01-30 12:35:34.000000000', 'files': ['tools/mlock_report.py', 'tools/memory_tracker.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/3555b48ff45a109e6456923d597fa174084387ab', 'message': ""Switch to python3 for memory_peak service\n\nWhen starting 'memory_peak' service is using python command instead of\npython3, while psutil (required package) is most probably being\ninstalled into the python3 environment (as we are dropping python2.7\nsupport).\n\nCloses-Bug: #1860753\nChange-Id: Ia2b7e2e33d784560443131e2965f520b361a54e3\n""}]",18,704104,3555b48ff45a109e6456923d597fa174084387ab,55,15,13,27329,,,0,"Switch to python3 for memory_peak service

When starting 'memory_peak' service is using python command instead of
python3, while psutil (required package) is most probably being
installed into the python3 environment (as we are dropping python2.7
support).

Closes-Bug: #1860753
Change-Id: Ia2b7e2e33d784560443131e2965f520b361a54e3
",git fetch https://review.opendev.org/openstack/devstack refs/changes/04/704104/6 && git format-patch -1 --stdout FETCH_HEAD,"['tools/mlock_report.py', 'tools/memory_tracker.sh']",2,9508a816d574ecb0bc8049d235ea7a11a4a21a0a,bug/1860753,PYTHON=${PYTHON:-python3},PYTHON=${PYTHON:-python},2,2
openstack%2Fdevstack~master~Ib7bb8b0a3dcf747bcc06da1a2fb17fa9d8808484,openstack/devstack,master,Ib7bb8b0a3dcf747bcc06da1a2fb17fa9d8808484,Add -r option when removing egg-info files/folders,MERGED,2020-01-30 13:41:16.000000000,2020-01-31 05:57:27.000000000,2020-01-31 05:56:07.000000000,"[{'_account_id': 4146}, {'_account_id': 7118}, {'_account_id': 8042}, {'_account_id': 8556}, {'_account_id': 13252}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-30 13:41:16.000000000', 'files': ['tools/fixup_stuff.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7611d3dfd2e1f68bf11027756fd5b217d5ae9640', 'message': ""Add -r option when removing egg-info files/folders\n\nWe are hitting this error:\n+ tools/fixup_stuff.sh:fixup_ubuntu:82 :\n    sudo rm -f /usr/lib/python3/dist-packages/httplib2-0.11.3.egg-info\nrm: cannot remove\n    '/usr/lib/python3/dist-packages/httplib2-0.11.3.egg-info': Is a directory\n\nThis patch adds the -r option to allow removing folders.\n\nChange-Id: Ib7bb8b0a3dcf747bcc06da1a2fb17fa9d8808484\n""}]",0,705005,7611d3dfd2e1f68bf11027756fd5b217d5ae9640,12,8,1,20775,,,0,"Add -r option when removing egg-info files/folders

We are hitting this error:
+ tools/fixup_stuff.sh:fixup_ubuntu:82 :
    sudo rm -f /usr/lib/python3/dist-packages/httplib2-0.11.3.egg-info
rm: cannot remove
    '/usr/lib/python3/dist-packages/httplib2-0.11.3.egg-info': Is a directory

This patch adds the -r option to allow removing folders.

Change-Id: Ib7bb8b0a3dcf747bcc06da1a2fb17fa9d8808484
",git fetch https://review.opendev.org/openstack/devstack refs/changes/05/705005/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/fixup_stuff.sh'],1,7611d3dfd2e1f68bf11027756fd5b217d5ae9640,, sudo rm -rf /usr/lib/python3/dist-packages/httplib2-*.egg-info sudo rm -rf /usr/lib/python3/dist-packages/pyasn1_modules-*.egg-info sudo rm -rf /usr/lib/python3/dist-packages/PyYAML-*.egg-info, sudo rm -f /usr/lib/python3/dist-packages/httplib2-*.egg-info sudo rm -f /usr/lib/python3/dist-packages/pyasn1_modules-*.egg-info sudo rm -f /usr/lib/python3/dist-packages/PyYAML-*.egg-info,3,3
openstack%2Fzaqar~master~I149c8fe7ef4b6628f910943587ab4302cc371441,openstack/zaqar,master,I149c8fe7ef4b6628f910943587ab4302cc371441,Fix exception mishandling,MERGED,2019-05-29 22:17:31.000000000,2020-01-31 05:29:51.000000000,2020-01-31 05:28:22.000000000,"[{'_account_id': 4257}, {'_account_id': 8846}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-05-29 22:17:31.000000000', 'files': ['zaqar/storage/redis/utils.py', 'zaqar/transport/wsgi/v2_0/stats.py', 'zaqar/common/api/utils.py', 'zaqar/common/cli.py', 'zaqar/transport/wsgi/v2_0/health.py', 'zaqar/storage/mongodb/topic_messages.py', 'zaqar/transport/wsgi/v2_0/messages.py', 'zaqar/storage/mongodb/pools.py', 'zaqar/storage/mongodb/topics.py', 'zaqar/transport/wsgi/v1_1/flavors.py', 'zaqar/transport/wsgi/v2_0/topic_purge.py', 'zaqar/transport/wsgi/v2_0/subscriptions.py', 'zaqar/storage/swift/driver.py', 'zaqar/transport/wsgi/v1_0/messages.py', 'zaqar/storage/utils.py', 'zaqar/transport/wsgi/v1_1/claims.py', 'zaqar/transport/wsgi/v1_0/queues.py', 'zaqar/transport/wsgi/v2_0/pools.py', 'zaqar/storage/mongodb/utils.py', 'zaqar/transport/wsgi/v1_1/stats.py', 'zaqar/transport/wsgi/v2_0/queues.py', 'zaqar/transport/wsgi/v2_0/topic_stats.py', 'zaqar/storage/sqlalchemy/utils.py', 'zaqar/storage/mongodb/queues.py', 'zaqar/transport/wsgi/v1_0/metadata.py', 'zaqar/transport/wsgi/v1_1/pools.py', 'zaqar/transport/wsgi/v2_0/flavors.py', 'zaqar/transport/wsgi/v1_1/health.py', 'zaqar/transport/wsgi/v2_0/topic.py', 'zaqar/transport/wsgi/v1_0/stats.py', 'zaqar/storage/base.py', 'zaqar/transport/wsgi/v1_1/messages.py', 'zaqar/bootstrap.py', 'zaqar/api/v2/endpoints.py', 'zaqar/transport/wsgi/v1_1/queues.py', 'zaqar/transport/wsgi/driver.py', 'zaqar/transport/wsgi/utils.py', 'zaqar/transport/wsgi/v1_0/pools.py', 'zaqar/storage/mongodb/messages.py', 'zaqar/transport/wsgi/v1_0/claims.py', 'zaqar/transport/wsgi/v2_0/claims.py', 'zaqar/transport/wsgi/v2_0/purge.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/e135e439350390c8ee3d5bd8478799acbcb7673a', 'message': 'Fix exception mishandling\n\nThere were a lot of instances of exceptions being raised or logged\nincorrectly.\n\nWhen reraising an exception, ""raise"" should be called, not ""raise ex"".\nThe second form will cause the original traceback to be modified to the\nnew location.\n\nLOG.exception is the same as LOG.error with the additional behavior of\nlogging any exception that is in the current scope. Therefore, doing\nsomething like ""LOG.exception(ex)"" is redundant and causes the exception\nmessage to be logged twice. Logging should be done with some sort of\ntextual message without the exception object.\n\nChange-Id: I149c8fe7ef4b6628f910943587ab4302cc371441\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",3,662103,e135e439350390c8ee3d5bd8478799acbcb7673a,11,4,1,11904,,,0,"Fix exception mishandling

There were a lot of instances of exceptions being raised or logged
incorrectly.

When reraising an exception, ""raise"" should be called, not ""raise ex"".
The second form will cause the original traceback to be modified to the
new location.

LOG.exception is the same as LOG.error with the additional behavior of
logging any exception that is in the current scope. Therefore, doing
something like ""LOG.exception(ex)"" is redundant and causes the exception
message to be logged twice. Logging should be done with some sort of
textual message without the exception object.

Change-Id: I149c8fe7ef4b6628f910943587ab4302cc371441
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/03/662103/1 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/storage/redis/utils.py', 'zaqar/transport/wsgi/v2_0/stats.py', 'zaqar/common/api/utils.py', 'zaqar/common/cli.py', 'zaqar/transport/wsgi/v2_0/health.py', 'zaqar/storage/mongodb/topic_messages.py', 'zaqar/transport/wsgi/v2_0/messages.py', 'zaqar/storage/mongodb/pools.py', 'zaqar/storage/mongodb/topics.py', 'zaqar/transport/wsgi/v1_1/flavors.py', 'zaqar/transport/wsgi/v2_0/topic_purge.py', 'zaqar/transport/wsgi/v2_0/subscriptions.py', 'zaqar/storage/swift/driver.py', 'zaqar/transport/wsgi/v1_0/messages.py', 'zaqar/storage/utils.py', 'zaqar/transport/wsgi/v1_1/claims.py', 'zaqar/transport/wsgi/v1_0/queues.py', 'zaqar/transport/wsgi/v2_0/pools.py', 'zaqar/storage/mongodb/utils.py', 'zaqar/transport/wsgi/v1_1/stats.py', 'zaqar/transport/wsgi/v2_0/queues.py', 'zaqar/transport/wsgi/v2_0/topic_stats.py', 'zaqar/storage/sqlalchemy/utils.py', 'zaqar/storage/mongodb/queues.py', 'zaqar/transport/wsgi/v1_0/metadata.py', 'zaqar/transport/wsgi/v1_1/pools.py', 'zaqar/transport/wsgi/v2_0/flavors.py', 'zaqar/transport/wsgi/v1_1/health.py', 'zaqar/transport/wsgi/v2_0/topic.py', 'zaqar/transport/wsgi/v1_0/stats.py', 'zaqar/storage/base.py', 'zaqar/transport/wsgi/v1_1/messages.py', 'zaqar/bootstrap.py', 'zaqar/api/v2/endpoints.py', 'zaqar/transport/wsgi/v1_1/queues.py', 'zaqar/transport/wsgi/driver.py', 'zaqar/transport/wsgi/utils.py', 'zaqar/transport/wsgi/v1_0/pools.py', 'zaqar/storage/mongodb/messages.py', 'zaqar/transport/wsgi/v1_0/claims.py', 'zaqar/transport/wsgi/v2_0/claims.py', 'zaqar/transport/wsgi/v2_0/purge.py']",42,e135e439350390c8ee3d5bd8478799acbcb7673a,cleanup, except Exception: LOG.exception(description), except Exception as ex: LOG.exception(ex),231,241
openstack%2Fcinder-specs~master~Id6cc95b39e8ab0d295624a6ea743de9113b09753,openstack/cinder-specs,master,Id6cc95b39e8ab0d295624a6ea743de9113b09753,Add backup id to volume's metadata,MERGED,2020-01-03 02:16:14.000000000,2020-01-31 05:06:59.000000000,2020-01-30 22:17:17.000000000,"[{'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 26490}, {'_account_id': 27190}, {'_account_id': 27615}, {'_account_id': 30092}, {'_account_id': 30407}]","[{'number': 1, 'created': '2020-01-03 02:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/c2658100ff1694b18b9f17224d865d4411bb4a39', 'message': 'Add backup_id to table volumes;\nWhen the backup restore chooses to create a new volume, write backup_id to it\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n'}, {'number': 2, 'created': '2020-01-03 06:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/47848bc149cdbff08128f33f73eaee18a3b70eb2', 'message': ""Add backup_id field to volumes;\nWhen the backup restore chooses to create a new volume, record 'backup_id' in it\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 3, 'created': '2020-01-03 10:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/6ace01508768c0959f183debfee3e1b5caca8a78', 'message': ""Add backup_id field to volumes;\n\nWhen the backup restore chooses to create a new volume, record 'backup_id' in it\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 4, 'created': '2020-01-03 15:33:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/efc7d3a9827cc77470a8226a38819c99b41fb23c', 'message': ""Add backup_id field to volumes\n\nWhen the backup restore chooses to create a new volume,\nrecord 'backup_id' in it\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 5, 'created': '2020-01-06 00:58:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/ccae0d78ca015626b427300b3b7c9d171b6bc81f', 'message': ""Add backup_id field to volumes\n\nWhen the backup restore chooses to create a new volume,\nrecord 'backup_id' in it\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 6, 'created': '2020-01-06 11:04:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/954b94a5191e2cd9a139c7630c7c13348f95101c', 'message': ""Add backup_id field to volumes\n\nWhen the backup restore chooses to create a new volume,\nrecord 'backup_id' in it\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 7, 'created': '2020-01-07 02:42:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/2397a861b6b525c3c4c159a8ce73d03968ee0e28', 'message': ""Add backup_id field to volumes\n\nWhen the backup restore chooses to create a new volume,\nrecord 'backup_id' in it\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 8, 'created': '2020-01-09 10:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/9fec1519640318168d4a506f04c27a564e473330', 'message': ""Add backup_id field to volumes\n\nWhen the backup restore chooses to create a new volume,\nrecord 'backup_id' in it\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 9, 'created': '2020-01-09 11:31:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/708bb2250fcc090d64860632f4f512bd172a62f3', 'message': ""Add backup_id field to volumes\n\nWhen the backup restore chooses to create a new volume,\nrecord 'backup_id' in it\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 10, 'created': '2020-01-16 02:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/997d72ea4d91900a1e38d1f76c58fd90718b1d63', 'message': ""Add backup id to volume's medadata\n\nWhen the backup restore chooses to create a new volume,\nrecord 'backup_id' in it\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 11, 'created': '2020-01-16 02:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/94f08e9d0b34640302ea62cedef07ddaab83806d', 'message': ""Add backup id to volume's metadata\n\nWhen the backup restore chooses to create a new volume,\nrecord 'backup_id' in it\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 12, 'created': '2020-01-16 08:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/2fbe0f28cf6c007a01d0f20347a9aefa8c518652', 'message': ""Add backup id to volume's metadata\n\nWhen the backup restore chooses to create a new volume,\nrecord 'backup_id' in it\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 13, 'created': '2020-01-16 08:26:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/1f6b68076423210756c068b0ecdceee0db5ed3c2', 'message': ""Add backup id to volume's metadata\n\nWhen the backup restore chooses to create a new volume,\nrecord 'backup_id' in it\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 14, 'created': '2020-01-19 01:23:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/e183a7d520cde5221b302059c9f8145ad663bfaf', 'message': ""Add backup id to volume's metadata\n\nWhen the backup restore chooses to create a new volume,\nrecord 'backup_id' in it\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 15, 'created': '2020-01-19 01:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/c57f4eff4da59348ac543ca299029cae357ddc8e', 'message': ""Add backup id to volume's metadata\n\nWhen the backup restore chooses to create a new volume,\nrecord 'backup_id' in it\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 16, 'created': '2020-01-21 01:12:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/6e79ad7b8523ce2f5c8d0261a57498051a172516', 'message': ""Add backup id to volume's metadata\n\nWhen the backup restore chooses to create a new volume,\nrecord 'backup_id' in it\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 17, 'created': '2020-01-29 07:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/7fd6228c98048e7fd8b56c16e4366dc3f61e55d4', 'message': ""Add backup id to volume's metadata\n\nWhen the backup restore chooses to create a new volume,\nrecord 'backup_id' in it\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 18, 'created': '2020-01-29 07:13:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/8e5cfb0363a81fa8ca7fc6e622b666059a214310', 'message': ""Add backup id to volume's metadata\n\nWhen the backup restore chooses to create a new volume,\nrecord 'backup_id' in it\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 19, 'created': '2020-01-29 13:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/557e1fdf08dc6c8b84be50018ff61815fd67a77a', 'message': ""Add backup id to volume's metadata\n\nWhen the backup restore chooses to create a new volume,\nrecord 'src_backup_id' in it\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 20, 'created': '2020-01-29 13:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/649804778eaded41b19d2344abf5b6ada5ce8b50', 'message': ""Add backup id to volume's metadata\n\nWhen the backup restore chooses to create a new volume,\nrecord 'src_backup_id' in the volume metadata.\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 21, 'created': '2020-01-29 15:16:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/1d29e87e9f44af056c76533779eb646d55862919', 'message': ""Add backup id to volume's metadata\n\nWhen the backup restore chooses to create a new volume,\nrecord 'src_backup_id' in the volume metadata.\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}, {'number': 22, 'created': '2020-01-30 04:49:25.000000000', 'files': ['specs/ussuri/add_backup_id_to_volume.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/0275b38aa48f7583498dc0f1e6e9430e5fd87081', 'message': ""Add backup id to volume's metadata\n\nWhen the backup restore chooses to create a new volume,\nrecord 'src_backup_id' in the volume metadata.\n\nImplements: blueprint add-volume-backup-id\n\nChange-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753\n""}]",69,700977,0275b38aa48f7583498dc0f1e6e9430e5fd87081,88,13,22,30092,,,0,"Add backup id to volume's metadata

When the backup restore chooses to create a new volume,
record 'src_backup_id' in the volume metadata.

Implements: blueprint add-volume-backup-id

Change-Id: Id6cc95b39e8ab0d295624a6ea743de9113b09753
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/77/700977/15 && git format-patch -1 --stdout FETCH_HEAD,['specs/untargeted/add_backup_id_to_volume.rst'],1,c2658100ff1694b18b9f17224d865d4411bb4a39,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================= Add backup id to volumes ============================= https://blueprints.launchpad.net/cinder/+spec/add-volume-backup-id Problem description =================== Select to create a new volume when the backup is restored, the backup_id is not save to the volumes table Users want to know which backup this volume was created from. Now we can know which snapshot, volume was created from, but there is no backup id record Use Cases ========= 1. Users wants to know which backup this volume was created from. Proposed change =============== * Add the fileld ""backup_id"" to the table volumes, mark which backup the volume from * Add the new properties ``backup_id`` to the Object Volumes, and return to the user, let user know where the volume is from throuth the api `` GET /v3/{project_id}/volumes/detail `` * Add the new properties ``backup_id`` to cinder show response Vendor-specific changes ----------------------- None Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- The rest API look like this in v3: .. code-block:: console GET /v3/{project_id}/volumes/detail .. code-block:: python { ""volumes"": [{ ""backup_id"": ""cb49b381-9012-40cb-b8ee-80c19a4801b5"" }] } Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- None Work Items ---------- * Add ``backup_id`` field to the ``volumes`` table * Writes the backup ID value in the backup recovery new volume process * Add ``backup_id`` field to related API. * Implement changes for python-cinderclient to support list transfer with ``--detail``. * Update related transfer api doc. Dependencies ============ None Testing ======= * Add related unittest * Add related functional test * Add tempest tests Documentation Impact ==================== None References ========== None ",,119,0
openstack%2Fopenstack-helm-infra~master~Ifc988002711d34186975988abb33ecd8a9a2fba4,openstack/openstack-helm-infra,master,Ifc988002711d34186975988abb33ecd8a9a2fba4,Add ability to add rally cleanup script,MERGED,2019-09-21 05:58:29.000000000,2020-01-31 03:31:25.000000000,2020-01-31 03:29:00.000000000,"[{'_account_id': 8749}, {'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 24780}]","[{'number': 1, 'created': '2019-09-21 05:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a643d78e43420d8a9cac19afe2907155dc0d2861', 'message': 'DNM: Add ability to add rally cleanup script\n\nThis patch set adds a way to specify clean up scripts for rally tests\nto clean up orphaned resources in the event of rally test failure.\n\nChange-Id: Ifc988002711d34186975988abb33ecd8a9a2fba4\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 2, 'created': '2019-09-21 23:24:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9130fc260c2bb69cc36335aadf33376b89de3be1', 'message': 'DNM: Add ability to add rally cleanup script\n\nThis patch set adds a way to specify clean up scripts for rally tests\nto clean up orphaned resources in the event of rally test failure.\n\nChange-Id: Ifc988002711d34186975988abb33ecd8a9a2fba4\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 3, 'created': '2019-09-23 01:01:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/104c04345b9fc8d900f2e5dd36793e4029d2c3d6', 'message': '[RFC] Add ability to add rally cleanup script\n\nThis patch set adds a way to specify clean up scripts for rally tests\nto clean up orphaned resources in the event of rally test failure.\n\nChange-Id: Ifc988002711d34186975988abb33ecd8a9a2fba4\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 4, 'created': '2020-01-17 19:48:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/884d789286d3f3c32aad7ada3ae670d1c63c47f5', 'message': 'Add ability to add rally cleanup script\n\nThis patch set provides a way to specify clean up scripts for rally tests\nto clean up orphaned resources in the event of rally test failures.\n\nChange-Id: Ifc988002711d34186975988abb33ecd8a9a2fba4\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 5, 'created': '2020-01-30 21:44:49.000000000', 'files': ['helm-toolkit/templates/scripts/_rally_test.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a6b1bd293dbc836be878b76e76b889920ffcf335', 'message': 'Add ability to add rally cleanup script\n\nThis patch set provides a way to specify clean up scripts for rally tests\nto clean up orphaned resources in the event of rally test failures.\n\nChange-Id: Ifc988002711d34186975988abb33ecd8a9a2fba4\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}]",0,683759,a6b1bd293dbc836be878b76e76b889920ffcf335,23,7,5,20466,,,0,"Add ability to add rally cleanup script

This patch set provides a way to specify clean up scripts for rally tests
to clean up orphaned resources in the event of rally test failures.

Change-Id: Ifc988002711d34186975988abb33ecd8a9a2fba4
Signed-off-by: Tin Lam <tin@irrational.io>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/59/683759/1 && git format-patch -1 --stdout FETCH_HEAD,['helm-toolkit/templates/scripts/_rally_test.sh.tpl'],1,a643d78e43420d8a9cac19afe2907155dc0d2861,rally-tests-cleanup,": ""${RALLY_CLEANUP:=""true""}"" if [ ""x$RALLY_CLEANUP"" == ""xtrue"" ]; then{{ $rallyTests.clean_up | default """" | indent 4 }}",": ""${AUTO_REMOVE_USER:=""true""}"" if [ ""x$AUTO_REMOVE_USER"" == ""xtrue"" ]; then",3,2
openstack%2Fopenstack-helm~master~Id9e8d6d6dda46559be3909763644ad1740bd6e3d,openstack/openstack-helm,master,Id9e8d6d6dda46559be3909763644ad1740bd6e3d,Change default image for glance_metadefs_load,MERGED,2020-01-27 19:22:50.000000000,2020-01-31 03:18:15.000000000,2020-01-31 03:16:36.000000000,"[{'_account_id': 8863}, {'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-27 19:22:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/3f5c27f2da397574a9f6f0e343688be23611c869', 'message': 'Change default image for glance_metadefs_loads\n\nChange-Id: Id9e8d6d6dda46559be3909763644ad1740bd6e3d\n'}, {'number': 2, 'created': '2020-01-27 19:23:49.000000000', 'files': ['glance/values_overrides/rocky-ubuntu_xenial.yaml', 'glance/values_overrides/rocky-opensuse_15.yaml', 'glance/values_overrides/ocata-ubuntu_xenial.yaml', 'glance/values_overrides/rocky-ubuntu_bionic.yaml', 'glance/values.yaml', 'glance/values_overrides/pike-ubuntu_xenial.yaml', 'glance/values_overrides/queens-ubuntu_xenial.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/f14906276a955e448c8702b8bb464ca08c882daf', 'message': 'Change default image for glance_metadefs_load\n\nChange-Id: Id9e8d6d6dda46559be3909763644ad1740bd6e3d\n'}]",0,704398,f14906276a955e448c8702b8bb464ca08c882daf,12,5,2,8863,,,0,"Change default image for glance_metadefs_load

Change-Id: Id9e8d6d6dda46559be3909763644ad1740bd6e3d
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/98/704398/2 && git format-patch -1 --stdout FETCH_HEAD,"['glance/values_overrides/rocky-ubuntu_xenial.yaml', 'glance/values_overrides/rocky-opensuse_15.yaml', 'glance/values_overrides/ocata-ubuntu_xenial.yaml', 'glance/values_overrides/rocky-ubuntu_bionic.yaml', 'glance/values.yaml', 'glance/values_overrides/pike-ubuntu_xenial.yaml', 'glance/values_overrides/queens-ubuntu_xenial.yaml']",7,3f5c27f2da397574a9f6f0e343688be23611c869,," glance_metadefs_load: ""docker.io/openstackhelm/glance:queens-ubuntu_xenial""",,7,1
openstack%2Fproject-config~master~Id197d01af5b9839107f2e9c69ed1b2b695541425,openstack/project-config,master,Id197d01af5b9839107f2e9c69ed1b2b695541425,openstack-artifacts-with-afs: fix typo,MERGED,2020-01-31 02:53:20.000000000,2020-01-31 03:12:59.000000000,2020-01-31 03:10:54.000000000,"[{'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-31 02:53:20.000000000', 'files': ['playbooks/publish/openstack-artifacts-with-afs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0c9523f5da656a809ceae79be1366eab5852edbc', 'message': 'openstack-artifacts-with-afs: fix typo\n\nChange-Id: Id197d01af5b9839107f2e9c69ed1b2b695541425\n'}]",0,705149,0c9523f5da656a809ceae79be1366eab5852edbc,7,2,1,7118,,,0,"openstack-artifacts-with-afs: fix typo

Change-Id: Id197d01af5b9839107f2e9c69ed1b2b695541425
",git fetch https://review.opendev.org/openstack/project-config refs/changes/49/705149/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/publish/openstack-artifacts-with-afs.yaml'],1,0c9523f5da656a809ceae79be1366eab5852edbc,static-services, name: destroy-afs-token, name: destory-afs-token,1,1
openstack%2Fproject-config~master~Ie867178a7ab86f97da14eccc90f86dce06b78406,openstack/project-config,master,Ie867178a7ab86f97da14eccc90f86dce06b78406,Artificat to AFS testing - crete artifact on localhost,MERGED,2020-01-31 02:30:45.000000000,2020-01-31 02:52:15.000000000,2020-01-31 02:48:25.000000000,"[{'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-31 02:30:45.000000000', 'files': ['playbooks/publish/openstack-artifacts-with-afs-test.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e46f7ae94531df20ec49f74a31b1a250f78c0f45', 'message': 'Artificat to AFS testing - crete artifact on localhost\n\nThis only needs to happen on the executor\n\nChange-Id: Ie867178a7ab86f97da14eccc90f86dce06b78406\n'}]",0,705145,e46f7ae94531df20ec49f74a31b1a250f78c0f45,7,2,1,7118,,,0,"Artificat to AFS testing - crete artifact on localhost

This only needs to happen on the executor

Change-Id: Ie867178a7ab86f97da14eccc90f86dce06b78406
",git fetch https://review.opendev.org/openstack/project-config refs/changes/45/705145/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/publish/openstack-artifacts-with-afs-test.yaml'],1,e46f7ae94531df20ec49f74a31b1a250f78c0f45,static-services, dest: '{{ zuul.executor.work_root }}/artifacts/afs-copy-test/{{ zuul.change }}.txt' delegate_to: localhost, dest: '{{ zuul.executor.work_root }}/artifacts/afs-copy-test/{{ zuul.change }}.txt',2,1
openstack%2Fopenstack-helm-infra~master~Iaaef308075cf4ffbd0e822548749c89c76ee9374,openstack/openstack-helm-infra,master,Iaaef308075cf4ffbd0e822548749c89c76ee9374,[Gate] Feature gate,ABANDONED,2020-01-07 22:17:48.000000000,2020-01-31 02:51:20.000000000,,"[{'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 27772}, {'_account_id': 30777}]","[{'number': 1, 'created': '2020-01-07 22:17:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/42e80384a67ffb5b0b91ff5f8962c5710e05c9b2', 'message': '[Gate] Feature gate\n\nMove the feature gate parameters from script to jobs yaml.\n\nChange-Id: Iaaef308075cf4ffbd0e822548749c89c76ee9374\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 2, 'created': '2020-01-08 03:59:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6d2ee4ad82755a53de149b54a537ba636cd2e15f', 'message': '[Gate] Feature gate\n\nMove the feature gate parameters from script to jobs yaml.\n\nChange-Id: Iaaef308075cf4ffbd0e822548749c89c76ee9374\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 3, 'created': '2020-01-08 04:05:37.000000000', 'files': ['tools/deployment/osh-infra-monitoring/050-prometheus.sh', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1f3eb16723653cf13bb5a7f046857e9e9b47009d', 'message': '[Gate] Feature gate\n\nMove the feature gate parameters from the loading script(s) to\nthe Zuul job YAML.\n\nChange-Id: Iaaef308075cf4ffbd0e822548749c89c76ee9374\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}]",4,701466,1f3eb16723653cf13bb5a7f046857e9e9b47009d,14,6,3,20466,,,0,"[Gate] Feature gate

Move the feature gate parameters from the loading script(s) to
the Zuul job YAML.

Change-Id: Iaaef308075cf4ffbd0e822548749c89c76ee9374
Signed-off-by: Tin Lam <tin@irrational.io>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/66/701466/3 && git format-patch -1 --stdout FETCH_HEAD,"['tools/deployment/osh-infra-monitoring/050-prometheus.sh', 'zuul.d/jobs.yaml']",2,42e80384a67ffb5b0b91ff5f8962c5710e05c9b2,feature-gate," osh_params: container_distro_name: ubuntu container_distro_version: bionic feature_gates: alertmanager,ceph,elasticsearch,kubernetes,nodes,openstack,postgresql osh_params: container_distro_name: ubuntu container_distro_version: bionic feature_gates: alertmanager,ceph,elasticsearch,kubernetes,nodes,openstack,postgresql osh_params: container_distro_name: ubuntu container_distro_version: bionic feature_gates: alertmanager,ceph,elasticsearch,kubernetes,nodes,openstack,postgresql osh_params: container_distro_name: ubuntu container_distro_version: bionic feature_gates: alertmanager,ceph,elasticsearch,kubernetes,nodes,openstack,postgresql",,16,2
openstack%2Fmistral-dashboard~master~Ia3ff24c76fd54b6fd3931bf63c91c6f5c69381f3,openstack/mistral-dashboard,master,Ia3ff24c76fd54b6fd3931bf63c91c6f5c69381f3,Add pagination for objects in mistral,NEW,2019-09-11 12:13:49.000000000,2020-01-31 02:45:25.000000000,,"[{'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 28691}, {'_account_id': 30755}]","[{'number': 1, 'created': '2019-09-11 12:13:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-dashboard/commit/588ad430d8492103e0ee6d5b250db85f1ab30ef8', 'message': 'Add pagination for objects in mistral\n\nCurrently, If we use horizon to show action executions or task\nexecutions, ... We will receive so many result of actions, ...\nreturned.\nSo, I think we need do pagination for them.\n\nChange-Id: Ia3ff24c76fd54b6fd3931bf63c91c6f5c69381f3\n'}, {'number': 2, 'created': '2019-09-16 04:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-dashboard/commit/6aa1238cf8cf770c452e70598eebe887e8092f6d', 'message': 'Add pagination for objects in mistral\n\nCurrently, If we use horizon to show action executions or task\nexecutions, ... We will receive so many result of actions, ...\nreturned.\nSo, I think we need do pagination for them.\n\nChange-Id: Ia3ff24c76fd54b6fd3931bf63c91c6f5c69381f3\n'}, {'number': 3, 'created': '2019-10-02 09:25:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-dashboard/commit/ec90909af82d826bc27ec11d504cefd4d695da13', 'message': 'Add pagination for objects in mistral\n\nCurrently, If we use horizon to show action executions or task\nexecutions, ... We will receive so many result of actions, ...\nreturned.\nSo, I think we need do pagination for them.\n\nChange-Id: Ia3ff24c76fd54b6fd3931bf63c91c6f5c69381f3\n'}, {'number': 4, 'created': '2020-01-05 08:58:17.000000000', 'files': ['mistraldashboard/workbooks/views.py', 'mistraldashboard/action_executions/views.py', 'mistraldashboard/cron_triggers/views.py', 'mistraldashboard/tasks/views.py', 'mistraldashboard/workflows/views.py'], 'web_link': 'https://opendev.org/openstack/mistral-dashboard/commit/66532255fe6e2f35b114a881014abe0798da1b94', 'message': 'Add pagination for objects in mistral\n\nCurrently, If we use horizon to show action executions or task\nexecutions, ... We will receive so many result of actions, ...\nreturned.\nSo, I think we need do pagination for them.\n\nChange-Id: Ia3ff24c76fd54b6fd3931bf63c91c6f5c69381f3\n'}]",2,681453,66532255fe6e2f35b114a881014abe0798da1b94,11,4,4,28691,,,0,"Add pagination for objects in mistral

Currently, If we use horizon to show action executions or task
executions, ... We will receive so many result of actions, ...
returned.
So, I think we need do pagination for them.

Change-Id: Ia3ff24c76fd54b6fd3931bf63c91c6f5c69381f3
",git fetch https://review.opendev.org/openstack/mistral-dashboard refs/changes/53/681453/4 && git format-patch -1 --stdout FETCH_HEAD,"['mistraldashboard/workbooks/views.py', 'mistraldashboard/action_executions/views.py', 'mistraldashboard/cron_triggers/views.py', 'mistraldashboard/tasks/views.py', 'mistraldashboard/workflows/views.py']",5,588ad430d8492103e0ee6d5b250db85f1ab30ef8,pagination-objects," def has_prev_data(self, table): return self._prev def has_more_data(self, table): return self._more def get_data(self): workflows = [] prev_marker = self.request.GET.get( workflows_tables.WorkflowsTable._meta.prev_pagination_param, None ) if prev_marker is not None: sort_dir = 'asc' marker = prev_marker else: sort_dir = 'desc' marker = self.request.GET.get( workflows_tables.WorkflowsTable._meta.pagination_param, None ) try: workflows, self._more, self._prev = api.pagination_list( entity=""workflows"", request=self.request, marker=marker, sort_keys='name', sort_dirs=sort_dir, paginate=True, reversed_order=True ) if prev_marker is not None: workflows = sorted( workflows, key=lambda action: getattr( action, 'name' ), reverse=False ) except Exception as e: self._prev = False self._more = False msg = _('Unable to retrieve workflows list: %s') % str(e) exceptions.handle(self.request, msg) return workflows", def get_data(self): return api.workflow_list(self.request),240,7
openstack%2Fnova~stable%2Fstein~I0322d872bdff68936033a6f5a54e8296a6fb3434,openstack/nova,stable/stein,I0322d872bdff68936033a6f5a54e8296a6fb3434,Block rebuild when NUMA topology changed,MERGED,2020-01-16 19:59:44.000000000,2020-01-31 02:36:44.000000000,2020-01-31 02:34:40.000000000,"[{'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-01-16 19:59:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/061e25015a93c345e39b7b340ad166c378d072ee', 'message': ""Block rebuild when NUMA topology changed\n\nIf the image change during a rebuild it's possible for the request\nNUMA topology to change. As a rebuild uses a noop claim in the\nresource tracker the NUMA topology will not be updated as part of\na rebuild.\n\nIf the NUMA constraints do not change, a rebuild will continue as normal.\nIf the new constraints conflict with the existing NUMA constraints of the\ninstance the rebuild will be rejected without altering the status of the\ninstance.\n\nThis change introduces an API check to block rebuild when the NUMA\nrequirements for the new image do not match the existing NUMA constraints.\nThis is in line with the previous check introduced to prevent the rebuild of\nvolume-backed instances which similarly are not supported.\n\nThis change adds functional tests to assert the expected behaviour of\nrebuilding NUMA instances with new images. This change also asserts that\nin place rebuilds of numa instances is currently not supported.\n\nModifications:\n\tnova/tests/functional/libvirt/test_numa_servers.py\n\nNOTE(stephenfin): The new tests added in 'test_numa_servers.py' had to\nbe modified to use the old-style '_wait_for_state_change' function,\nsince change I80cdc0a33ec27b1389130c22f9c3a8ff69f6b1a0 isn't present on\n'stable/train' and it's too large and invasive to justify backporting.\nIn addition, a 'super()' call had to be updated to use the Python 2\ncompatible 'super(ClassName, self)' style.\n\nNOTE(sean-k-mooney): due to the lack of\nIcacda8484c9ede1a0ddf0831bc457b83b1dd6931 the Fake HostInfo objects\ncreated in the functional tests where updated to use the NUMAHostInfo\nclass.\n\nCloses-Bug: #1763766\nPartial-implements: blueprint inplace-rebuild-of-numa-instances\nChange-Id: I0322d872bdff68936033a6f5a54e8296a6fb3434\n(cherry picked from commit 6f5358ac1992b17b7f3f99d9a32290e0d4740dae)\n(cherry picked from commit 745de99063bf77704a7f0610fe9e3647257eaa50)\n""}, {'number': 2, 'created': '2020-01-20 15:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/67ee8e3861aa9c618130cbe2a15e39b2bfcbc4cc', 'message': ""Block rebuild when NUMA topology changed\n\nIf the image change during a rebuild it's possible for the request\nNUMA topology to change. As a rebuild uses a noop claim in the\nresource tracker the NUMA topology will not be updated as part of\na rebuild.\n\nIf the NUMA constraints do not change, a rebuild will continue as normal.\nIf the new constraints conflict with the existing NUMA constraints of the\ninstance the rebuild will be rejected without altering the status of the\ninstance.\n\nThis change introduces an API check to block rebuild when the NUMA\nrequirements for the new image do not match the existing NUMA constraints.\nThis is in line with the previous check introduced to prevent the rebuild of\nvolume-backed instances which similarly are not supported.\n\nThis change adds functional tests to assert the expected behaviour of\nrebuilding NUMA instances with new images. This change also asserts that\nin place rebuilds of numa instances is currently not supported.\n\nModifications:\n\tnova/tests/functional/libvirt/test_numa_servers.py\n\nNOTE(sean-k-mooney): due to the lack of\nIfcda7336d56c9b623720ee018ec5697740986273 the Fake HostInfo objects\ncreated in the functional tests where updated to use the NUMAHostInfo\nclass. Prior to Ifcda7336d56c9b623720ee018ec5697740986273 the\nFake HostInfo class did not construct a numa toplogy from the kwargs\nand instead only set a numa topology if if it was passed in during\nconstruction. In older release the initalistation of the numa\ntopology form kwargs was a feature of NUMAHostInfo.\n\nCloses-Bug: #1763766\nPartial-implements: blueprint inplace-rebuild-of-numa-instances\nChange-Id: I0322d872bdff68936033a6f5a54e8296a6fb3434\n(cherry picked from commit 6f5358ac1992b17b7f3f99d9a32290e0d4740dae)\n(cherry picked from commit 745de99063bf77704a7f0610fe9e3647257eaa50)\n""}, {'number': 3, 'created': '2020-01-22 15:06:25.000000000', 'files': ['nova/exception.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/functional/integrated_helpers.py', 'releasenotes/notes/numa-rebuild-b75f9a1966f576ea.yaml', 'nova/tests/functional/libvirt/test_numa_servers.py', 'nova/compute/api.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9f57d16f38f0290718e3ba78393d064746f7e527', 'message': ""Block rebuild when NUMA topology changed\n\nIf the image change during a rebuild it's possible for the request\nNUMA topology to change. As a rebuild uses a noop claim in the\nresource tracker the NUMA topology will not be updated as part of\na rebuild.\n\nIf the NUMA constraints do not change, a rebuild will continue as normal.\nIf the new constraints conflict with the existing NUMA constraints of the\ninstance the rebuild will be rejected without altering the status of the\ninstance.\n\nThis change introduces an API check to block rebuild when the NUMA\nrequirements for the new image do not match the existing NUMA constraints.\nThis is in line with the previous check introduced to prevent the rebuild of\nvolume-backed instances which similarly are not supported.\n\nThis change adds functional tests to assert the expected behaviour of\nrebuilding NUMA instances with new images. This change also asserts that\nin place rebuilds of numa instances is currently not supported.\n\nConflicts:\n    nova/api/openstack/compute/servers.py\n    nova/tests/functional/libvirt/test_numa_servers.py\n\nNOTE(sean-k-mooney): due to the lack of\nIfcda7336d56c9b623720ee018ec5697740986273 the Fake HostInfo objects\ncreated in the functional tests were updated to use the NUMAHostInfo\nclass. Prior to Ifcda7336d56c9b623720ee018ec5697740986273 the\nFake HostInfo class did not construct a numa topology from the kwargs\nand instead only set a numa topology if it was passed in during\nconstruction. In older release the initialization of the numa\ntopology from kwargs was a feature of NUMAHostInfo.\nThe servers.py conflicts are due to a lack of\nI5576fa2a67d2771614266022428b4a95487ab6d5 in Stein.\n\nCloses-Bug: #1763766\nPartial-implements: blueprint inplace-rebuild-of-numa-instances\nChange-Id: I0322d872bdff68936033a6f5a54e8296a6fb3434\n(cherry picked from commit 6f5358ac1992b17b7f3f99d9a32290e0d4740dae)\n(cherry picked from commit 745de99063bf77704a7f0610fe9e3647257eaa50)\n""}]",17,702972,9f57d16f38f0290718e3ba78393d064746f7e527,50,8,3,11604,,,0,"Block rebuild when NUMA topology changed

If the image change during a rebuild it's possible for the request
NUMA topology to change. As a rebuild uses a noop claim in the
resource tracker the NUMA topology will not be updated as part of
a rebuild.

If the NUMA constraints do not change, a rebuild will continue as normal.
If the new constraints conflict with the existing NUMA constraints of the
instance the rebuild will be rejected without altering the status of the
instance.

This change introduces an API check to block rebuild when the NUMA
requirements for the new image do not match the existing NUMA constraints.
This is in line with the previous check introduced to prevent the rebuild of
volume-backed instances which similarly are not supported.

This change adds functional tests to assert the expected behaviour of
rebuilding NUMA instances with new images. This change also asserts that
in place rebuilds of numa instances is currently not supported.

Conflicts:
    nova/api/openstack/compute/servers.py
    nova/tests/functional/libvirt/test_numa_servers.py

NOTE(sean-k-mooney): due to the lack of
Ifcda7336d56c9b623720ee018ec5697740986273 the Fake HostInfo objects
created in the functional tests were updated to use the NUMAHostInfo
class. Prior to Ifcda7336d56c9b623720ee018ec5697740986273 the
Fake HostInfo class did not construct a numa topology from the kwargs
and instead only set a numa topology if it was passed in during
construction. In older release the initialization of the numa
topology from kwargs was a feature of NUMAHostInfo.
The servers.py conflicts are due to a lack of
I5576fa2a67d2771614266022428b4a95487ab6d5 in Stein.

Closes-Bug: #1763766
Partial-implements: blueprint inplace-rebuild-of-numa-instances
Change-Id: I0322d872bdff68936033a6f5a54e8296a6fb3434
(cherry picked from commit 6f5358ac1992b17b7f3f99d9a32290e0d4740dae)
(cherry picked from commit 745de99063bf77704a7f0610fe9e3647257eaa50)
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/702972/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/functional/integrated_helpers.py', 'releasenotes/notes/numa-rebuild-b75f9a1966f576ea.yaml', 'nova/tests/functional/libvirt/test_numa_servers.py', 'nova/compute/api.py', 'nova/api/openstack/compute/servers.py']",7,061e25015a93c345e39b7b340ad166c378d072ee,bug/1763766," exception.ImageNUMATopologyRebuildConflict,",,320,4
openstack%2Fzun~master~I9e4b51821f71768f52898290ced69d3849805415,openstack/zun,master,I9e4b51821f71768f52898290ced69d3849805415,Refactor container driver,MERGED,2020-01-19 20:11:34.000000000,2020-01-31 02:32:11.000000000,2020-01-31 02:30:47.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-19 20:11:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/0722f048aca035478c3a14ef4c8c72a773cc9750', 'message': 'Refactor container driver\n\nIntroduce a BaseDriver class that is the base class of all drivers.\n\nChange-Id: I9e4b51821f71768f52898290ced69d3849805415\n'}, {'number': 2, 'created': '2020-01-19 20:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/af1bc2de02d04482519d8d29cc7425bc9fe4e3cb', 'message': 'Refactor container driver\n\nIntroduce a BaseDriver class that is the base class of all drivers.\n\nChange-Id: I9e4b51821f71768f52898290ced69d3849805415\n'}, {'number': 3, 'created': '2020-01-19 23:56:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/d42a6ddb2664dba8819ece2aa4e9821b9672dfd7', 'message': 'Refactor container driver\n\nIntroduce a BaseDriver class that is the base class of all drivers.\n\nChange-Id: I9e4b51821f71768f52898290ced69d3849805415\n'}, {'number': 4, 'created': '2020-01-25 19:13:26.000000000', 'files': ['zun/tests/unit/container/fake_driver.py', 'zun/container/docker/driver.py', 'zun/container/driver.py', 'zun/tests/unit/container/docker/test_docker_driver.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/83dbf2d5c4f2f607aa2134ceb492ead8c30c72dd', 'message': 'Refactor container driver\n\nIntroduce a BaseDriver class that is the base class of all drivers.\n\nChange-Id: I9e4b51821f71768f52898290ced69d3849805415\n'}]",0,703303,83dbf2d5c4f2f607aa2134ceb492ead8c30c72dd,12,2,4,11536,,,0,"Refactor container driver

Introduce a BaseDriver class that is the base class of all drivers.

Change-Id: I9e4b51821f71768f52898290ced69d3849805415
",git fetch https://review.opendev.org/openstack/zun refs/changes/03/703303/4 && git format-patch -1 --stdout FETCH_HEAD,"['zun/container/docker/driver.py', 'zun/tests/unit/container/fake_driver.py', 'zun/container/driver.py', 'zun/tests/unit/container/docker/test_docker_driver.py']",4,0722f048aca035478c3a14ef4c8c72a773cc9750,, @mock.patch('zun.container.docker.driver.DockerDriver' '.get_host_mem'), @mock.patch('zun.container.driver.ContainerDriver.get_host_mem'),110,105
openstack%2Ftripleo-validations~stable%2Fqueens~I535618b726db49505c3ba56c12daf99201111ac8,openstack/tripleo-validations,stable/queens,I535618b726db49505c3ba56c12daf99201111ac8,Fix default ceph-ansible repo,MERGED,2020-01-30 08:43:49.000000000,2020-01-31 02:31:48.000000000,2020-01-31 02:31:47.000000000,"[{'_account_id': 6796}, {'_account_id': 11491}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 25402}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-30 08:43:49.000000000', 'files': ['validations/ceph-ansible-installed.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/df05c075d4eb580968d4d208ca1d7013111efafa', 'message': 'Fix default ceph-ansible repo\n\nQueens comes with ceph luminous, so this patch\njust fix the default repo variable.\n\nChange-Id: I535618b726db49505c3ba56c12daf99201111ac8\n'}]",4,704941,df05c075d4eb580968d4d208ca1d7013111efafa,13,6,1,25402,,,0,"Fix default ceph-ansible repo

Queens comes with ceph luminous, so this patch
just fix the default repo variable.

Change-Id: I535618b726db49505c3ba56c12daf99201111ac8
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/41/704941/1 && git format-patch -1 --stdout FETCH_HEAD,['validations/ceph-ansible-installed.yaml'],1,df05c075d4eb580968d4d208ca1d7013111efafa,," ceph_ansible_repo: ""centos-ceph-luminous"""," ceph_ansible_repo: ""centos-ceph-nautilus""",1,1
openstack%2Ftripleo-validations~stable%2Frocky~Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5,openstack/tripleo-validations,stable/rocky,Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5,Sync 'validations/ceph-ansible-installed.yaml' with the new role,MERGED,2020-01-23 07:03:25.000000000,2020-01-31 02:31:48.000000000,2020-01-31 02:31:48.000000000,"[{'_account_id': 11491}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 25402}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-23 07:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/13b8894be0d6f19b13359b6f0de4e8a941a50b41', 'message': ""Add an additional validation to check ceph-ansible repository\n\nIn order to address the ceph-ansible potential cross-shipping,\nthis change adds an extra task to validate the repository that\nshould be used to install ceph-ansible in the undercloud.\nIf ceph-ansible is not installed or the repo doesn't match the\nspecified one, this validation raise an error.\n\nChange-Id: Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5\nCloses-Bug: 1857460\n(cherry picked from commit 329f740d109b87105eac36fade70c69c15781a38)\n""}, {'number': 2, 'created': '2020-01-24 15:52:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/79a7a61a2d9d2be3e26beedf96fe6d23a37dd7dc', 'message': ""Sync 'validations/ceph-ansible-installed.yaml' with the new role\n\nCloses-Bug: 1857460\nChange-Id: Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5\n(cherry picked from commit 716a3083232ca137ed617ada73f49a6fe5a6869b)\n""}, {'number': 3, 'created': '2020-01-30 11:16:38.000000000', 'files': ['validations/ceph-ansible-installed.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/1bdafd5281bd0a2b48551690590711c0d75149fe', 'message': ""Sync 'validations/ceph-ansible-installed.yaml' with the new role\n\nCloses-Bug: 1857460\nChange-Id: Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5\n(cherry picked from commit 716a3083232ca137ed617ada73f49a6fe5a6869b)\n""}]",1,703926,1bdafd5281bd0a2b48551690590711c0d75149fe,21,5,3,25402,,,0,"Sync 'validations/ceph-ansible-installed.yaml' with the new role

Closes-Bug: 1857460
Change-Id: Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5
(cherry picked from commit 716a3083232ca137ed617ada73f49a6fe5a6869b)
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/26/703926/1 && git format-patch -1 --stdout FETCH_HEAD,['validations/ceph-ansible-installed.yaml'],1,13b8894be0d6f19b13359b6f0de4e8a941a50b41,sync_validations," fail_without_ceph_ansible: false ceph_ansible_repo: ""centos-ceph-luminous"" - ceph_ansible_installed.stdout.find('is not installed') != -1 - fail_without_ceph_ansible|default(false)|bool - name: Get ceph-ansible repository shell: ""yum info ceph-ansible | awk '/From repo/ {print $4}'"" register: repo changed_when: False - name: Fail if ceph-ansible doesn't belong to the specified repo fail: msg: ""Make sure ceph-ansible package is installed from {{ ceph_ansible_repo }}"" when: - (repo.stdout | length == 0 or repo.stdout != ""{{ ceph_ansible_repo }}"") - fail_without_ceph_ansible|default(false)|bool",,16,0
openstack%2Ftripleo-heat-templates~stable%2Fstein~Id309e812f7dc8d66bd4912fce282ce72350fcbf8,openstack/tripleo-heat-templates,stable/stein,Id309e812f7dc8d66bd4912fce282ce72350fcbf8,Fix keepalived logging on disk,MERGED,2020-01-30 03:05:40.000000000,2020-01-31 02:31:46.000000000,2020-01-31 02:31:46.000000000,"[{'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-30 03:05:40.000000000', 'files': ['deployment/keepalived/keepalived-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/53364fd7a1cfee3e9272f7e7f7880819bfe204f2', 'message': ""Fix keepalived logging on disk\n\nThere are no logs under /var/log/containers/keepalived even though we\nexplicitly try to capture logs on file for the keepalived container:\n\n [root@undercloud-0 ~]# podman exec -it keepalived sh -c 'ps -ax'\n    PID TTY STAT TIME COMMAND\n      1 ? Ss 0:00 dumb-init --single-child -- /usr/local/bin/kolla_start\n      8 ? S 0:00 /usr/sbin/keepalived -nldD | tee -a /var/log/keepalived.log\n     12 ? S 2:18 /usr/sbin/keepalived -nldD | tee -a /var/log/keepalived.log\n\nThe reason this is broken is that 'tee' is not passed to a shell but\nends up being an ignored argument of keepalived. Notice how there is no\nshell process and also no tee process in the container above.\n\nTo fix that we need to pass the proper commands to a shell. This is done\nin a special way like we did for the haproxy container so that kolla\ndoes not mangle quotes and spaces.\n\nAfter this fix we correctly see that the container logs on disk:\n[root@undercloud-0 container-puppet]# ls -l /var/log/containers/keepalived/\n-rw-r--r--. 1 root root 17483 Jan 28 15:55 keepalived.log\n\nWhile we're at it we remove the usage of tee. It makes no sense to\nlog both on file and on stdout/stderr.\n\nCo-Authored-By: Damien Ciabrini <dciabrin@redhat.com>\n\nChange-Id: Id309e812f7dc8d66bd4912fce282ce72350fcbf8\nCloses-Bug: #1861169\n(cherry picked from commit 547a510f63e9e7aa2cd41e050c94fc7077fb86f4)\n""}]",0,704918,53364fd7a1cfee3e9272f7e7f7880819bfe204f2,7,4,1,3153,,,0,"Fix keepalived logging on disk

There are no logs under /var/log/containers/keepalived even though we
explicitly try to capture logs on file for the keepalived container:

 [root@undercloud-0 ~]# podman exec -it keepalived sh -c 'ps -ax'
    PID TTY STAT TIME COMMAND
      1 ? Ss 0:00 dumb-init --single-child -- /usr/local/bin/kolla_start
      8 ? S 0:00 /usr/sbin/keepalived -nldD | tee -a /var/log/keepalived.log
     12 ? S 2:18 /usr/sbin/keepalived -nldD | tee -a /var/log/keepalived.log

The reason this is broken is that 'tee' is not passed to a shell but
ends up being an ignored argument of keepalived. Notice how there is no
shell process and also no tee process in the container above.

To fix that we need to pass the proper commands to a shell. This is done
in a special way like we did for the haproxy container so that kolla
does not mangle quotes and spaces.

After this fix we correctly see that the container logs on disk:
[root@undercloud-0 container-puppet]# ls -l /var/log/containers/keepalived/
-rw-r--r--. 1 root root 17483 Jan 28 15:55 keepalived.log

While we're at it we remove the usage of tee. It makes no sense to
log both on file and on stdout/stderr.

Co-Authored-By: Damien Ciabrini <dciabrin@redhat.com>

Change-Id: Id309e812f7dc8d66bd4912fce282ce72350fcbf8
Closes-Bug: #1861169
(cherry picked from commit 547a510f63e9e7aa2cd41e050c94fc7077fb86f4)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/18/704918/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/keepalived/keepalived-container-puppet.yaml'],1,53364fd7a1cfee3e9272f7e7f7880819bfe204f2,fix_keepalived_log-stable/stein," command: ""/bin/bash -c $* -- eval exec /usr/sbin/keepalived -nldD &>>/var/log/keepalived.log""", command: /usr/sbin/keepalived -nldD | tee -a /var/log/keepalived.log,1,1
openstack%2Fproject-config~master~Ic08543cd586cb00eda8fcd507e2de49aa69fd19c,openstack/project-config,master,Ic08543cd586cb00eda8fcd507e2de49aa69fd19c,Artifact to AFS testing - remove newrev,MERGED,2020-01-31 02:10:54.000000000,2020-01-31 02:29:50.000000000,2020-01-31 02:26:29.000000000,"[{'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-31 02:10:54.000000000', 'files': ['playbooks/publish/openstack-artifacts-with-afs-test.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3928d4828dba627b2d97fe3b52625ecc8c4aed93', 'message': ""Artifact to AFS testing - remove newrev\n\nAvoid\n\n The error was: 'dict object' has no attribute 'newrev'\n\nby using just zuul.change\n\nChange-Id: Ic08543cd586cb00eda8fcd507e2de49aa69fd19c\n""}]",0,705144,3928d4828dba627b2d97fe3b52625ecc8c4aed93,7,2,1,7118,,,0,"Artifact to AFS testing - remove newrev

Avoid

 The error was: 'dict object' has no attribute 'newrev'

by using just zuul.change

Change-Id: Ic08543cd586cb00eda8fcd507e2de49aa69fd19c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/44/705144/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/publish/openstack-artifacts-with-afs-test.yaml'],1,3928d4828dba627b2d97fe3b52625ecc8c4aed93,static-services, dest: '{{ zuul.executor.work_root }}/artifacts/afs-copy-test/{{ zuul.change }}.txt', dest: '{{ zuul.executor.work_root }}/artifacts/afs-copy-test/{{ zuul.newrev }}',1,1
openstack%2Fcookbook-openstack-dns~master~Ibeb6f0d43313478eff1054552df48f96c7ec589d,openstack/cookbook-openstack-dns,master,Ibeb6f0d43313478eff1054552df48f96c7ec589d,Add missing ChefSpec tests and other various fixes,MERGED,2020-01-25 23:55:01.000000000,2020-01-31 02:11:53.000000000,2020-01-31 02:11:53.000000000,"[{'_account_id': 13252}, {'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-25 23:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dns/commit/a3a2f30069f14f386f15c29c20f112aad6a1ab48', 'message': ""Add named recipe and other various fixes\n\nThis cookbook wasn't completely functional unfortunately and this\nprovides various fixes to get it there. One primary issue was that there\nwas no named server running so this patch adds a recipe for setting up\nnamed. This recipe is useful as an example but might not be ideal for\nproduction setups.\n\nWe probably should move the dashboard recipe to the openstack-dashboad\ncookbook in another patch since we have fwaas and lbaas there as well.\n\nOther changes include:\n- Add missing cookbooks required for openstack-chef CI\n- Add missing openstack-network dependency needed for the neutron_int\n  recipe\n- Add missing mdns, producer and worker services for RHEL platform\n- Ensure all servers start as well as be enabled\n- Move rndc.key to named recipe and also have it in the\n  /etc/{named,bind} directory. This is to work around a permission issue\n  on Ubuntu platforms\n- Add *ALL* missing ChefSpec tests\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: Ibeb6f0d43313478eff1054552df48f96c7ec589d\n""}, {'number': 2, 'created': '2020-01-28 19:16:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dns/commit/2169b542cea7d230402975873c44e96b9634b339', 'message': 'Add missing ChefSpec tests and other various fixes\n\nWe probably should move the dashboard recipe to the openstack-dashboad\ncookbook in another patch since we have fwaas and lbaas there as well.\n\nOther changes include:\n- Add missing cookbooks required for openstack-chef CI\n- Add missing openstack-network dependency needed for the neutron_int\n  recipe\n- Add missing mdns, producer and worker services for RHEL platform\n- Ensure all servers start as well as be enabled\n- Add rndc_key attribute for setting the path of the rndc.key\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: Ibeb6f0d43313478eff1054552df48f96c7ec589d\n'}, {'number': 3, 'created': '2020-01-28 19:45:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dns/commit/fbbc6413ada014a9f9968af6f9503e6d4e111c06', 'message': 'Add missing ChefSpec tests and other various fixes\n\nWe probably should move the dashboard recipe to the openstack-dashboad\ncookbook in another patch since we have fwaas and lbaas there as well.\n\nOther changes include:\n- Add missing cookbooks required for openstack-chef CI\n- Add missing openstack-network dependency needed for the neutron_int\n  recipe\n- Add missing mdns, producer and worker services for RHEL platform\n- Ensure all servers start as well as be enabled\n- Add rndc_key attribute for setting the path of the rndc.key\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: Ibeb6f0d43313478eff1054552df48f96c7ec589d\n'}, {'number': 4, 'created': '2020-01-30 21:15:12.000000000', 'files': ['recipes/central.rb', 'recipes/worker.rb', 'spec/common_spec.rb', 'README.rst', 'spec/api-rhel_spec.rb', 'spec/producer_spec.rb', 'spec/api_spec.rb', 'recipes/api.rb', 'Berksfile', 'spec/neutron_int_spec.rb', 'recipes/mdns.rb', 'spec/worker-rhel_spec.rb', 'spec/mdns_spec.rb', 'spec/central-rhel_spec.rb', 'attributes/default.rb', 'spec/identity_registration_spec.rb', 'recipes/producer.rb', 'spec/sink-rhel_spec.rb', 'spec/mdns-rhel_spec.rb', 'spec/central_spec.rb', 'spec/common-rhel_spec.rb', 'spec/dashboard_spec.rb', 'spec/default_spec.rb', 'spec/worker_spec.rb', 'templates/default/pools.yaml.erb', 'spec/sink_spec.rb', 'recipes/sink.rb', 'spec/spec_helper.rb', 'spec/producer-rhel_spec.rb', 'templates/default/named.designate.erb', 'metadata.rb', 'recipes/common.rb', 'recipes/default.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dns/commit/9a5b6fe6d77ab556dde123e8c3920ce0e0ba63b9', 'message': 'Add missing ChefSpec tests and other various fixes\n\nWe probably should move the dashboard recipe to the openstack-dashboad\ncookbook in another patch since we have fwaas and lbaas there as well.\n\nOther changes include:\n- Add missing cookbooks required for openstack-chef CI\n- Add missing openstack-network dependency needed for the neutron_int\n  recipe\n- Add missing mdns, producer and worker services for RHEL platform\n- Ensure all servers start as well as be enabled\n- Add rndc_key attribute for setting the path of the rndc.key\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: Ibeb6f0d43313478eff1054552df48f96c7ec589d\n'}]",7,704236,9a5b6fe6d77ab556dde123e8c3920ce0e0ba63b9,31,3,4,21961,,,0,"Add missing ChefSpec tests and other various fixes

We probably should move the dashboard recipe to the openstack-dashboad
cookbook in another patch since we have fwaas and lbaas there as well.

Other changes include:
- Add missing cookbooks required for openstack-chef CI
- Add missing openstack-network dependency needed for the neutron_int
  recipe
- Add missing mdns, producer and worker services for RHEL platform
- Ensure all servers start as well as be enabled
- Add rndc_key attribute for setting the path of the rndc.key

Depends-On: https://review.opendev.org/702772
Change-Id: Ibeb6f0d43313478eff1054552df48f96c7ec589d
",git fetch https://review.opendev.org/openstack/cookbook-openstack-dns refs/changes/36/704236/1 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/central.rb', 'recipes/worker.rb', 'spec/common_spec.rb', 'README.rst', 'spec/api-rhel_spec.rb', 'spec/producer_spec.rb', 'spec/api_spec.rb', 'recipes/api.rb', 'Berksfile', 'spec/neutron_int_spec.rb', 'spec/named-rhel_spec.rb', 'recipes/mdns.rb', 'spec/worker-rhel_spec.rb', 'spec/mdns_spec.rb', 'spec/central-rhel_spec.rb', 'attributes/default.rb', 'spec/identity_registration_spec.rb', 'recipes/producer.rb', 'spec/sink-rhel_spec.rb', 'spec/mdns-rhel_spec.rb', 'spec/central_spec.rb', 'spec/named_spec.rb', 'spec/common-rhel_spec.rb', 'spec/dashboard_spec.rb', 'recipes/named.rb', 'spec/default_spec.rb', 'spec/worker_spec.rb', 'templates/default/pools.yaml.erb', 'spec/sink_spec.rb', 'recipes/sink.rb', 'spec/spec_helper.rb', 'spec/producer-rhel_spec.rb', 'templates/default/named.designate.erb', 'metadata.rb', 'recipes/common.rb', 'recipes/default.rb']",36,a3a2f30069f14f386f15c29c20f112aad6a1ab48,named-setup,,,972,39
openstack%2Fcookbook-openstack-ops-messaging~master~Ife1b939c1fac0fc90c30e1d2a425d568ea7e7fd3,openstack/cookbook-openstack-ops-messaging,master,Ife1b939c1fac0fc90c30e1d2a425d568ea7e7fd3,Set Berksfile to use ruby solver,MERGED,2020-01-24 01:18:15.000000000,2020-01-31 02:11:52.000000000,2020-01-31 02:11:52.000000000,"[{'_account_id': 13252}, {'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-24 01:18:15.000000000', 'files': ['Berksfile'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-messaging/commit/b5ebaa6fa97aa578f252b1d479a53f0b507675f5', 'message': 'Set Berksfile to use ruby solver\n\nThis provides much better debugging output.\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: Ife1b939c1fac0fc90c30e1d2a425d568ea7e7fd3\n'}]",0,704097,b5ebaa6fa97aa578f252b1d479a53f0b507675f5,10,3,1,21961,,,0,"Set Berksfile to use ruby solver

This provides much better debugging output.

Depends-On: https://review.opendev.org/702772
Change-Id: Ife1b939c1fac0fc90c30e1d2a425d568ea7e7fd3
",git fetch https://review.opendev.org/openstack/cookbook-openstack-ops-messaging refs/changes/97/704097/1 && git format-patch -1 --stdout FETCH_HEAD,['Berksfile'],1,b5ebaa6fa97aa578f252b1d479a53f0b507675f5,berksfile-solver,"solver :ruby, :required ",,2,0
openstack%2Fcookbook-openstack-ops-database~master~I1a738e6f951b12b54bbc2eaf61d5b01ab70a1203,openstack/cookbook-openstack-ops-database,master,I1a738e6f951b12b54bbc2eaf61d5b01ab70a1203,Set Berksfile to use ruby solver,MERGED,2020-01-24 00:50:25.000000000,2020-01-31 02:11:52.000000000,2020-01-31 02:11:51.000000000,"[{'_account_id': 13252}, {'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-24 00:50:25.000000000', 'files': ['Berksfile'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-ops-database/commit/ceccaadf8a71f5087e111a2456f017aa86880e59', 'message': 'Set Berksfile to use ruby solver\n\nThis provides much better debugging output.\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: I1a738e6f951b12b54bbc2eaf61d5b01ab70a1203\n'}]",0,704095,ceccaadf8a71f5087e111a2456f017aa86880e59,9,3,1,21961,,,0,"Set Berksfile to use ruby solver

This provides much better debugging output.

Depends-On: https://review.opendev.org/702772
Change-Id: I1a738e6f951b12b54bbc2eaf61d5b01ab70a1203
",git fetch https://review.opendev.org/openstack/cookbook-openstack-ops-database refs/changes/95/704095/1 && git format-patch -1 --stdout FETCH_HEAD,['Berksfile'],1,ceccaadf8a71f5087e111a2456f017aa86880e59,berksfile-solver,"solver :ruby, :required ",,2,0
openstack%2Fcookbook-openstack-orchestration~master~I381af7639cc0d0a834c391b1b12f26ef7300bb4d,openstack/cookbook-openstack-orchestration,master,I381af7639cc0d0a834c391b1b12f26ef7300bb4d,Include missing cookbooks in Berksfile,MERGED,2020-01-24 00:37:40.000000000,2020-01-31 02:11:51.000000000,2020-01-31 02:11:51.000000000,"[{'_account_id': 13252}, {'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-24 00:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-orchestration/commit/68f8ab2275c139c60445d78ea95902905a22e660', 'message': 'Include missing cookbooks in Berksfile\n\nThis is for individual cookbook integration testing.\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: I381af7639cc0d0a834c391b1b12f26ef7300bb4d\n'}, {'number': 2, 'created': '2020-01-24 00:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-orchestration/commit/e7d0f3b607a8f6e6eb9f3f4904408a7a0b0d4396', 'message': 'Include missing cookbooks in Berksfile\n\nThis is for individual cookbook integration testing.\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: I381af7639cc0d0a834c391b1b12f26ef7300bb4d\n'}, {'number': 3, 'created': '2020-01-30 21:10:38.000000000', 'files': ['Berksfile'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-orchestration/commit/dbf60084f5bdb80e46da75eff59121fb61821bb9', 'message': 'Include missing cookbooks in Berksfile\n\nThis is for individual cookbook integration testing.\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: I381af7639cc0d0a834c391b1b12f26ef7300bb4d\n'}]",0,704094,dbf60084f5bdb80e46da75eff59121fb61821bb9,10,3,3,21961,,,0,"Include missing cookbooks in Berksfile

This is for individual cookbook integration testing.

Depends-On: https://review.opendev.org/702772
Change-Id: I381af7639cc0d0a834c391b1b12f26ef7300bb4d
",git fetch https://review.opendev.org/openstack/cookbook-openstack-orchestration refs/changes/94/704094/1 && git format-patch -1 --stdout FETCH_HEAD,['Berksfile'],1,68f8ab2275c139c60445d78ea95902905a22e660,berksvendor-by-cookbook,"solver :ruby, :required %w( client -common -identity -image -integration-test -ops-database -ops-messaging ).each do |cookbook|",%w(-common -identity client).each do |cookbook|,11,1
openstack%2Fcookbook-openstack-common~master~I32f254e78817a06ac061cfaaf2ab40559bee9a46,openstack/cookbook-openstack-common,master,I32f254e78817a06ac061cfaaf2ab40559bee9a46,Set Berksfile to use ruby solver,MERGED,2020-01-23 23:23:48.000000000,2020-01-31 02:11:50.000000000,2020-01-31 02:11:50.000000000,"[{'_account_id': 13252}, {'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 23:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/98de0be1157eb142c305cf0a7f2315a4f8b7548e', 'message': 'DNM: test new openstack-chef patch\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: I32f254e78817a06ac061cfaaf2ab40559bee9a46\n'}, {'number': 2, 'created': '2020-01-24 00:51:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/211db1c975d60572ef778a09b9eaa7ebe7985c19', 'message': 'Set Berksfile to use ruby solver\n\nThis provides much better debugging output.\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: I32f254e78817a06ac061cfaaf2ab40559bee9a46\n'}, {'number': 3, 'created': '2020-01-30 21:09:46.000000000', 'files': ['Berksfile'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/51716cb6ff1c7aac4bbf96615adf3a5baadcd1a7', 'message': 'Set Berksfile to use ruby solver\n\nThis provides much better debugging output.\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: I32f254e78817a06ac061cfaaf2ab40559bee9a46\n'}]",0,704087,51716cb6ff1c7aac4bbf96615adf3a5baadcd1a7,15,3,3,21961,,,0,"Set Berksfile to use ruby solver

This provides much better debugging output.

Depends-On: https://review.opendev.org/702772
Change-Id: I32f254e78817a06ac061cfaaf2ab40559bee9a46
",git fetch https://review.opendev.org/openstack/cookbook-openstack-common refs/changes/87/704087/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,98de0be1157eb142c305cf0a7f2315a4f8b7548e,berksvendor-by-cookbook,,,1,0
openstack%2Fproject-config~master~I91c58786fb866b734d1dfdec061586f43ca7f2d2,openstack/project-config,master,I91c58786fb866b734d1dfdec061586f43ca7f2d2,Artificat to AFS testing - fix test job,MERGED,2020-01-31 01:43:24.000000000,2020-01-31 02:07:19.000000000,2020-01-31 02:03:37.000000000,"[{'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-31 01:43:24.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/199ed5038962d37dae57b960f47c73ad243501bf', 'message': 'Artificat to AFS testing - fix test job\n\nUse the run phase for placing the dummy file.\n\nChange-Id: I91c58786fb866b734d1dfdec061586f43ca7f2d2\n'}]",0,705142,199ed5038962d37dae57b960f47c73ad243501bf,7,2,1,7118,,,0,"Artificat to AFS testing - fix test job

Use the run phase for placing the dummy file.

Change-Id: I91c58786fb866b734d1dfdec061586f43ca7f2d2
",git fetch https://review.opendev.org/openstack/project-config refs/changes/42/705142/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,199ed5038962d37dae57b960f47c73ad243501bf,static-services, run: playbooks/publish/openstack-artifacts-with-afs-test.yaml, pre-run: playbooks/publish/openstack-artifacts-with-afs-test.yaml,1,1
openstack%2Fkolla~master~I210d9fddd6948dab1feb5abf59a50bce86f21f0f,openstack/kolla,master,I210d9fddd6948dab1feb5abf59a50bce86f21f0f,CentOS 8: Remove shellinabox from ironic-conductor,MERGED,2020-01-29 14:19:12.000000000,2020-01-31 02:07:03.000000000,2020-01-31 02:05:38.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-29 14:19:12.000000000', 'files': ['kolla/image/build.py', 'docker/ironic/ironic-conductor/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/397651ec4b5b93a55d0b8b8f69dfb37dd85cfc8d', 'message': 'CentOS 8: Remove shellinabox from ironic-conductor\n\nshellinabox is used by ironic-conductor to provide a browser-based shell\nto access the consoles of nodes. It is not used by all console drivers,\nand is not used in the integration with nova serial consoles.\n\nThe package was previously installed from EPEL7, but is not currently\nprovided by EPEL8.\n\nThis change removes the package to allow the ironic-conductor image to\nbuild.\n\nChange-Id: I210d9fddd6948dab1feb5abf59a50bce86f21f0f\nPartially-Implements: blueprint centos-rhel-8\n'}]",0,704813,397651ec4b5b93a55d0b8b8f69dfb37dd85cfc8d,17,5,1,14826,,,0,"CentOS 8: Remove shellinabox from ironic-conductor

shellinabox is used by ironic-conductor to provide a browser-based shell
to access the consoles of nodes. It is not used by all console drivers,
and is not used in the integration with nova serial consoles.

The package was previously installed from EPEL7, but is not currently
provided by EPEL8.

This change removes the package to allow the ironic-conductor image to
build.

Change-Id: I210d9fddd6948dab1feb5abf59a50bce86f21f0f
Partially-Implements: blueprint centos-rhel-8
",git fetch https://review.opendev.org/openstack/kolla refs/changes/13/704813/1 && git format-patch -1 --stdout FETCH_HEAD,"['kolla/image/build.py', 'docker/ironic/ironic-conductor/Dockerfile.j2']",2,397651ec4b5b93a55d0b8b8f69dfb37dd85cfc8d,bp/centos-rhel-8," # FIXME(mgoddard): Removed shellinabox which is not currently provided # by EPEL8. 'shellinabox', # FIXME(mgoddard): Removed shellinabox which is not currently provided # by EPEL8. 'shellinabox',"," 'shellinabox', 'shellinabox',",6,3
openstack%2Faodh~master~Id2e9dbe600ff72e827171e51ccdec88a5e1cdc00,openstack/aodh,master,Id2e9dbe600ff72e827171e51ccdec88a5e1cdc00,Documentation about quota management,MERGED,2020-01-31 00:49:13.000000000,2020-01-31 02:06:35.000000000,2020-01-31 02:03:35.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-31 00:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/94ddf85ef924c9ad9ccd5ffacf09e3eea33dfa6e', 'message': 'Documentation about quota management\n\nChange-Id: Id2e9dbe600ff72e827171e51ccdec88a5e1cdc00\n'}, {'number': 2, 'created': '2020-01-31 01:03:33.000000000', 'files': ['doc/source/admin/index.rst', 'doc/source/admin/resource-quota.rst'], 'web_link': 'https://opendev.org/openstack/aodh/commit/6e5c918fc7760bc6a4a915c1f668458652054a1b', 'message': 'Documentation about quota management\n\nChange-Id: Id2e9dbe600ff72e827171e51ccdec88a5e1cdc00\n'}]",0,705140,6e5c918fc7760bc6a4a915c1f668458652054a1b,9,2,2,6732,,,0,"Documentation about quota management

Change-Id: Id2e9dbe600ff72e827171e51ccdec88a5e1cdc00
",git fetch https://review.opendev.org/openstack/aodh refs/changes/40/705140/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/resource-quota.rst'],1,94ddf85ef924c9ad9ccd5ffacf09e3eea33dfa6e,quota-doc,".. Copyright (c) 2020 Catalyst Cloud Limited Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. ========================= Resource Quota Management ========================= The amount of resources(e.g. alarms) that could be created by each OpenStack project is controlled by quota. The default resource quota for each project is set in Aodh config file as follows unless changed by the cloud administrator via Quota API. .. code-block:: ini [api] user_alarm_quota = -1 project_alarm_quota = -1 alarm_max_actions = -1 user_alarm_quota The default alarm quota for an openstack user, default is unlimited. Sometimes the alarm creation request satisfies the project quota but fails the user quota. project_alarm_quota The default alarm quota for an openstack project, default is unlimited. The cloud administrator can change project quota using Quota API, see examples below. alarm_max_actions The maximum number of alarm actions could be created per alarm, default is unlimited. Quota API --------- Aodh Quota API is aiming for multi-tenancy support. By default, only the admin user is able to change the resource quota for projects as defined by the default policy rule 'telemetry:update_quotas'. User alarm quota and alarm action quota are not supported in Quota API. An HTTP request example using ``httpie`` command: .. code-block:: console cat <<EOF | http post v2/quotas X-Auth-Token:$token { ""project_id"": ""8aecc55977714e898281c24260747d78"", ""quotas"": [ { ""resource"": ""alarms"", ""limit"": 30 } ] } EOF",,68,0
openstack%2Faodh~master~I1af381f357b0d80f68e3ead16e158428b7a14555,openstack/aodh,master,I1af381f357b0d80f68e3ead16e158428b7a14555,Improve the quota check,MERGED,2020-01-30 22:57:11.000000000,2020-01-31 02:05:08.000000000,2020-01-31 02:03:34.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-30 22:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/99b0b9b1b83589421e34b599162c883b8c2b6c53', 'message': 'Improve the quota check\n\n- Check alarm quota by considering the quota setting in DB.\n- Add more unit tests for quota API.\n\nChange-Id: I1af381f357b0d80f68e3ead16e158428b7a14555\n'}, {'number': 2, 'created': '2020-01-31 00:19:43.000000000', 'files': ['aodh/api/controllers/v2/alarms.py', 'aodh/tests/functional/api/v2/test_alarm_scenarios.py', 'aodh/api/controllers/v2/quotas.py', 'aodh/tests/functional/api/v2/test_quotas.py'], 'web_link': 'https://opendev.org/openstack/aodh/commit/90a7c6eab2c897bb613bb3aa489f4c075370138a', 'message': 'Improve the quota check\n\n- Check alarm quota by considering the quota setting in DB.\n- Add more unit tests for quota API.\n\nChange-Id: I1af381f357b0d80f68e3ead16e158428b7a14555\n'}]",0,705130,90a7c6eab2c897bb613bb3aa489f4c075370138a,9,2,2,6732,,,0,"Improve the quota check

- Check alarm quota by considering the quota setting in DB.
- Add more unit tests for quota API.

Change-Id: I1af381f357b0d80f68e3ead16e158428b7a14555
",git fetch https://review.opendev.org/openstack/aodh refs/changes/30/705130/1 && git format-patch -1 --stdout FETCH_HEAD,"['aodh/api/controllers/v2/alarms.py', 'aodh/tests/functional/api/v2/test_alarm_scenarios.py', 'aodh/api/controllers/v2/quotas.py', 'aodh/tests/functional/api/v2/test_quotas.py']",4,99b0b9b1b83589421e34b599162c883b8c2b6c53,check-quota," def test_post_quotas_no_limit_failed(self): auth_headers = copy.copy(self.auth_headers) auth_headers['X-Roles'] = 'admin' resp = self.post_json( '/quotas', { ""project_id"": self.project, ""quotas"": [ { ""resource"": ""alarms"" } ] }, headers=auth_headers, expect_errors=True, status=400 ) self.assertIn('Mandatory field missing', resp.json['error_message']['faultstring']) def test_post_quotas_no_resource_failed(self): auth_headers = copy.copy(self.auth_headers) auth_headers['X-Roles'] = 'admin' resp = self.post_json( '/quotas', { ""project_id"": self.project, ""quotas"": [ { ""limit"": 1 } ] }, headers=auth_headers, expect_errors=True, status=400 ) self.assertIn('Mandatory field missing', resp.json['error_message']['faultstring']) def test_post_quotas_wrong_limit_failed(self): auth_headers = copy.copy(self.auth_headers) auth_headers['X-Roles'] = 'admin' resp = self.post_json( '/quotas', { ""project_id"": self.project, ""quotas"": [ { ""resource"": ""alarms"", ""limit"": -5 } ] }, headers=auth_headers, expect_errors=True, status=400 ) self.assertIn('Value should be greater or equal to -1', resp.json['error_message']['faultstring']) def test_post_quotas_unsupported_resource_failed(self): auth_headers = copy.copy(self.auth_headers) auth_headers['X-Roles'] = 'admin' resp = self.post_json( '/quotas', { ""project_id"": self.project, ""quotas"": [ { ""resource"": ""other_resource"", ""limit"": 1 } ] }, headers=auth_headers, expect_errors=True, status=400 ) self.assertIn('Value should be one of', resp.json['error_message']['faultstring'])",,211,24
openstack%2Fcookbook-openstackclient~master~I58e1e50abc2b6d5847cc08d022a303f2993db8d8,openstack/cookbook-openstackclient,master,I58e1e50abc2b6d5847cc08d022a303f2993db8d8,Include missing cookbooks in Berksfile,MERGED,2020-01-23 23:20:06.000000000,2020-01-31 01:56:15.000000000,2020-01-31 01:56:15.000000000,"[{'_account_id': 13252}, {'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 23:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstackclient/commit/31bd22121b7d711a128e673f90280077db31ed67', 'message': 'Include missing cookbooks in Berksfile\n\nThis is for individual cookbook integration testing.\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: I58e1e50abc2b6d5847cc08d022a303f2993db8d8\n'}, {'number': 2, 'created': '2020-01-30 21:06:25.000000000', 'files': ['Berksfile'], 'web_link': 'https://opendev.org/openstack/cookbook-openstackclient/commit/cac2e5ba29593ded2656362ed286710c1c208fbf', 'message': 'Include missing cookbooks in Berksfile\n\nThis is for individual cookbook integration testing.\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: I58e1e50abc2b6d5847cc08d022a303f2993db8d8\n'}]",0,704086,cac2e5ba29593ded2656362ed286710c1c208fbf,17,3,2,21961,,,0,"Include missing cookbooks in Berksfile

This is for individual cookbook integration testing.

Depends-On: https://review.opendev.org/702772
Change-Id: I58e1e50abc2b6d5847cc08d022a303f2993db8d8
",git fetch https://review.opendev.org/openstack/cookbook-openstackclient refs/changes/86/704086/1 && git format-patch -1 --stdout FETCH_HEAD,['Berksfile'],1,31bd22121b7d711a128e673f90280077db31ed67,berksvendor-by-cookbook,"%w( -common -identity -image -integration-test -network -ops-database -ops-messaging ).each do |cookbook| if Dir.exist?(""../cookbook-openstack#{cookbook}"") cookbook ""openstack#{cookbook}"", path: ""../cookbook-openstack#{cookbook}"" else cookbook ""openstack#{cookbook}"", git: ""https://opendev.org/openstack/cookbook-openstack#{cookbook}"" end end ",,16,0
openstack%2Fcookbook-openstack-network~master~Ib986e8df102ae3dcfff8f378c9b2f01f57eef102,openstack/cookbook-openstack-network,master,Ib986e8df102ae3dcfff8f378c9b2f01f57eef102,Include missing cookbooks in Berksfile,MERGED,2020-01-23 23:07:15.000000000,2020-01-31 01:56:15.000000000,2020-01-31 01:56:15.000000000,"[{'_account_id': 13252}, {'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 23:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/988bab7478b99caa71dcfd1dbb1379a198a489b7', 'message': 'Include missing cookbooks in Berksfile\n\nThis is for individual cookbook integration testing.\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: Ib986e8df102ae3dcfff8f378c9b2f01f57eef102\n'}, {'number': 2, 'created': '2020-01-30 21:05:26.000000000', 'files': ['Berksfile'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/95e7167f78e8da4d64ec18833e417da3978067b9', 'message': 'Include missing cookbooks in Berksfile\n\nThis is for individual cookbook integration testing.\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: Ib986e8df102ae3dcfff8f378c9b2f01f57eef102\n'}]",0,704082,95e7167f78e8da4d64ec18833e417da3978067b9,13,3,2,21961,,,0,"Include missing cookbooks in Berksfile

This is for individual cookbook integration testing.

Depends-On: https://review.opendev.org/702772
Change-Id: Ib986e8df102ae3dcfff8f378c9b2f01f57eef102
",git fetch https://review.opendev.org/openstack/cookbook-openstack-network refs/changes/82/704082/1 && git format-patch -1 --stdout FETCH_HEAD,['Berksfile'],1,988bab7478b99caa71dcfd1dbb1379a198a489b7,berksvendor-by-cookbook,%w( client -common -identity -image -integration-test -ops-database -ops-messaging ).each do |cookbook|,%w(-common -identity client).each do |cookbook|,9,1
openstack%2Fcookbook-openstack-image~master~I868ec493b31b95aaff417a924bbec8206011def7,openstack/cookbook-openstack-image,master,I868ec493b31b95aaff417a924bbec8206011def7,Include missing cookbooks in Berksfile,MERGED,2020-01-23 23:03:34.000000000,2020-01-31 01:55:37.000000000,2020-01-31 01:55:36.000000000,"[{'_account_id': 13252}, {'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 23:03:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/cbb4c6f765b3a98b16abe4690a6ae2cad6855255', 'message': 'Include missing cookbooks in Berksfile for individual cookbook integration testing\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: I868ec493b31b95aaff417a924bbec8206011def7\n'}, {'number': 2, 'created': '2020-01-23 23:06:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/ea33cbd2f21d2e3860f99ddc431eaefa10640180', 'message': 'Include missing cookbooks in Berksfile\n\nThis is for individual cookbook integration testing.\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: I868ec493b31b95aaff417a924bbec8206011def7\n'}, {'number': 3, 'created': '2020-01-30 19:23:55.000000000', 'files': ['Berksfile'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/900ea5b749f70a2dfa575c18cdfdf16312b6197d', 'message': 'Include missing cookbooks in Berksfile\n\nThis is for individual cookbook integration testing.\n\nDepends-On: https://review.opendev.org/702772\nChange-Id: I868ec493b31b95aaff417a924bbec8206011def7\n'}]",0,704081,900ea5b749f70a2dfa575c18cdfdf16312b6197d,14,3,3,21961,,,0,"Include missing cookbooks in Berksfile

This is for individual cookbook integration testing.

Depends-On: https://review.opendev.org/702772
Change-Id: I868ec493b31b95aaff417a924bbec8206011def7
",git fetch https://review.opendev.org/openstack/cookbook-openstack-image refs/changes/81/704081/1 && git format-patch -1 --stdout FETCH_HEAD,['Berksfile'],1,cbb4c6f765b3a98b16abe4690a6ae2cad6855255,berksvendor-by-cookbook,%w( client -common -identity -integration-test -ops-database -ops-messaging ).each do |cookbook|,%w(client -common -identity).each do |cookbook|,8,1
openstack%2Fpython-neutronclient~stable%2Ftrain~I4737d4bc4fa116f45e2361eba93f48feae0161a4,openstack/python-neutronclient,stable/train,I4737d4bc4fa116f45e2361eba93f48feae0161a4,Fix pep8 errors with hacking 2.0.0,MERGED,2020-01-29 16:34:58.000000000,2020-01-31 01:38:05.000000000,2020-01-31 01:36:47.000000000,"[{'_account_id': 841}, {'_account_id': 4694}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 16:34:58.000000000', 'files': ['neutronclient/tests/unit/qos/test_cli20_rule.py', 'neutronclient/tests/unit/osc/v2/logging/test_network_log.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/33ae5ad4e17fa4b38b5b7b0892d4ea8de2532361', 'message': 'Fix pep8 errors with hacking 2.0.0\n\nChange-Id: I4737d4bc4fa116f45e2361eba93f48feae0161a4\n(cherry picked from commit 91fb009706526ed8d36ca8f2cf57f1763a9af520)\n'}]",0,704839,33ae5ad4e17fa4b38b5b7b0892d4ea8de2532361,9,4,1,1131,,,0,"Fix pep8 errors with hacking 2.0.0

Change-Id: I4737d4bc4fa116f45e2361eba93f48feae0161a4
(cherry picked from commit 91fb009706526ed8d36ca8f2cf57f1763a9af520)
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/39/704839/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/tests/unit/qos/test_cli20_rule.py', 'neutronclient/tests/unit/osc/v2/logging/test_network_log.py']",2,33ae5ad4e17fa4b38b5b7b0892d4ea8de2532361,fix-pep8-stable/train," ""loggable_resources"": [{""type"": RES_TYPE_SG}, {""type"": RES_TYPE_FWG}]"," ""loggable_resources"": [{""type"": RES_TYPE_SG, ""type"": RES_TYPE_FWG}]",5,5
openstack%2Fcookbook-openstack-telemetry~master~Ie7e6d792a764314775c40d4489cfba05d5c483ce,openstack/cookbook-openstack-telemetry,master,Ie7e6d792a764314775c40d4489cfba05d5c483ce,Update to apache2 ~> 8.0 cookbook,MERGED,2020-01-14 19:43:17.000000000,2020-01-31 01:28:50.000000000,2020-01-31 01:28:50.000000000,"[{'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-14 19:43:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-telemetry/commit/419b7229ca46894d12ff123937db639240221883', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove collector recipe as this service has been deprecated upstream.\n- Add openstack-ceilometer-notification package for RHEL in\n  agent_notification_packages as it was missing.\n- Fix gnocchi-api_wsgi_and aodh-api_wsgi_file file on RHEL\n- Remove openstack-aodh package in aodh_packages for RHEL as it does not\n  exist\n- Clean up arrays in attributes using %w(foo) instead of ['foo']\n- Set group for upgrade scripts so it can read files properly on RHEL\n- Add missing ChefSpec tests for aodh\n\nChange-Id: Ie7e6d792a764314775c40d4489cfba05d5c483ce\n""}, {'number': 2, 'created': '2020-01-15 19:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-telemetry/commit/f923b1e7e7cf1c7eab7019b29246d87b541b482c', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove collector recipe as this service has been deprecated upstream.\n- Add openstack-ceilometer-notification package for RHEL in\n  agent_notification_packages as it was missing.\n- Fix gnocchi-api_wsgi_and aodh-api_wsgi_file file on RHEL\n- Remove openstack-aodh package in aodh_packages for RHEL as it does not\n  exist\n- Clean up arrays in attributes using %w(foo) instead of ['foo']\n- Set group for upgrade scripts so it can read files properly on RHEL\n- Add missing ChefSpec tests for aodh\n\nChange-Id: Ie7e6d792a764314775c40d4489cfba05d5c483ce\n""}, {'number': 3, 'created': '2020-01-24 00:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-telemetry/commit/6b0b927d4a30f04299c15597f75bb3cf8e3711ef', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove collector recipe as this service has been deprecated upstream.\n- Add openstack-ceilometer-notification package for RHEL in\n  agent_notification_packages as it was missing.\n- Fix gnocchi-api_wsgi_and aodh-api_wsgi_file file on RHEL\n- Remove openstack-aodh package in aodh_packages for RHEL as it does not\n  exist\n- Clean up arrays in attributes using %w(foo) instead of ['foo']\n- Set group for upgrade scripts so it can read files properly on RHEL\n- Add missing ChefSpec tests for aodh\n- Include additional cookbooks in Berksfile required for CI\n\nDepends-On: https://review.opendev.org/702772\nDepends-On: https://review.opendev.org/701824\nChange-Id: Ie7e6d792a764314775c40d4489cfba05d5c483ce\n""}, {'number': 4, 'created': '2020-01-30 17:32:03.000000000', 'files': ['spec/aodh-rhel_spec.rb', 'README.rst', 'spec/common-rhel_spec.rb', 'Berksfile', 'recipes/aodh.rb', 'recipes/collector.rb', 'templates/wsgi-template.conf.erb', 'spec/gnocchi_configure-rhel_spec.rb', 'spec/spec_helper.rb', 'attributes/default.rb', 'spec/aodh_spec.rb', 'spec/collector_spec.rb', 'spec/gnocchi_configure_spec.rb', 'spec/collector-rhel_spec.rb', 'recipes/gnocchi_configure.rb', 'metadata.rb', 'recipes/common.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-telemetry/commit/111d3621a9cc4eb4bbe51f885fc7351c92d41229', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove collector recipe as this service has been deprecated upstream.\n- Add openstack-ceilometer-notification package for RHEL in\n  agent_notification_packages as it was missing.\n- Fix gnocchi-api_wsgi_and aodh-api_wsgi_file file on RHEL\n- Remove openstack-aodh package in aodh_packages for RHEL as it does not\n  exist\n- Clean up arrays in attributes using %w(foo) instead of ['foo']\n- Set group for upgrade scripts so it can read files properly on RHEL\n- Add missing ChefSpec tests for aodh\n- Include additional cookbooks in Berksfile required for CI\n\nDepends-On: https://review.opendev.org/702772\nDepends-On: https://review.opendev.org/701824\nChange-Id: Ie7e6d792a764314775c40d4489cfba05d5c483ce\n""}]",0,702508,111d3621a9cc4eb4bbe51f885fc7351c92d41229,14,2,4,21961,,,0,"Update to apache2 ~> 8.0 cookbook

This brings us up to date with the latest apache2 cookbook which
included a major refactor in 6.0.0 removing all of the definitions and
recipe with proper resources. Instead of using the apache2_default_site
resource, directly use a template and then enable the config file using
the apache2_site resource. This gives us the most flexibility.

Additional fixes:
- Install mod_wsgi as a package on RHEL since there is no built-in
  resource for it.
- Remove hack for restarting apache.
- Convert web_app to template and subscribe to restarting apache.
- Remove resources to restore SELinux contexts since this taken care of
  by Chef now automatically.
- Don't set SELinux to permissive on RHEL (I tested this works properly
  with it set to enforcing).
- Remove collector recipe as this service has been deprecated upstream.
- Add openstack-ceilometer-notification package for RHEL in
  agent_notification_packages as it was missing.
- Fix gnocchi-api_wsgi_and aodh-api_wsgi_file file on RHEL
- Remove openstack-aodh package in aodh_packages for RHEL as it does not
  exist
- Clean up arrays in attributes using %w(foo) instead of ['foo']
- Set group for upgrade scripts so it can read files properly on RHEL
- Add missing ChefSpec tests for aodh
- Include additional cookbooks in Berksfile required for CI

Depends-On: https://review.opendev.org/702772
Depends-On: https://review.opendev.org/701824
Change-Id: Ie7e6d792a764314775c40d4489cfba05d5c483ce
",git fetch https://review.opendev.org/openstack/cookbook-openstack-telemetry refs/changes/08/702508/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/aodh-rhel_spec.rb', 'spec/common-rhel_spec.rb', 'recipes/aodh.rb', 'recipes/collector.rb', 'templates/wsgi-template.conf.erb', 'spec/gnocchi_configure-rhel_spec.rb', 'spec/spec_helper.rb', 'attributes/default.rb', 'spec/aodh_spec.rb', 'spec/collector_spec.rb', 'spec/gnocchi_configure_spec.rb', 'spec/collector-rhel_spec.rb', 'recipes/gnocchi_configure.rb', 'metadata.rb', 'recipes/common.rb']",15,419b7229ca46894d12ff123937db639240221883,apache2-refactor," include Apache2::Cookbook::Helpersdirectory ""#{lock_dir}/ceilometer"" do# service['apache2'] is defined in the apache2_default_install resource # but other resources are currently unable to reference it. To work # around this issue, define the following helper in your cookbook: service 'apache2' do extend Apache2::Cookbook::Helpers service_name lazy { apache_platform_service_name } supports restart: true, status: true, reload: true action :nothing end ","directory ""#{node['apache']['run_dir']}/ceilometer"" do",536,327
openstack%2Fcookbook-openstack-bare-metal~master~I198e2c211630e190bf2a992b3dc6b6c5afaf54e8,openstack/cookbook-openstack-bare-metal,master,I198e2c211630e190bf2a992b3dc6b6c5afaf54e8,Update to apache2 ~> 8.0 cookbook,MERGED,2020-01-15 02:09:19.000000000,2020-01-31 01:28:49.000000000,2020-01-31 01:28:49.000000000,"[{'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 02:09:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-bare-metal/commit/6482e945b6975ac8605d1b84eb8338ea1d64f708', 'message': 'Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove erroneous restart for ironic-api service on packages\n- Properly set service password and auth URL\n- Improve tests for ironic.conf\n- Add missing apache2 depend\n- Add missing api RHEL ChefSpec tests\n\nChange-Id: I198e2c211630e190bf2a992b3dc6b6c5afaf54e8\n'}, {'number': 2, 'created': '2020-01-15 19:18:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-bare-metal/commit/6dd2773637a23eb882cd5eb48101241b96694d27', 'message': 'Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove erroneous restart for ironic-api service on packages\n- Properly set service password and auth URL\n- Improve tests for ironic.conf\n- Add missing apache2 depend\n- Add missing api RHEL ChefSpec tests\n\nChange-Id: I198e2c211630e190bf2a992b3dc6b6c5afaf54e8\n'}, {'number': 3, 'created': '2020-01-23 23:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-bare-metal/commit/25224e910b4f7812cbeb207922f667908549a63e', 'message': 'Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove erroneous restart for ironic-api service on packages\n- Properly set service password and auth URL\n- Improve tests for ironic.conf\n- Add missing apache2 depend\n- Add missing api RHEL ChefSpec tests\n- Include additional cookbooks in Berksfile required for CI\n\nDepends-On: https://review.opendev.org/702772\nDepends-On: https://review.opendev.org/701824\nChange-Id: I198e2c211630e190bf2a992b3dc6b6c5afaf54e8\n'}, {'number': 4, 'created': '2020-01-30 19:23:03.000000000', 'files': ['spec/spec_helper.rb', 'README.rst', 'spec/api-rhel_spec.rb', 'attributes/default.rb', 'spec/ironic-common_spec.rb', 'spec/api_spec.rb', 'recipes/api.rb', 'metadata.rb', 'recipes/ironic-common.rb', 'Berksfile', 'templates/default/wsgi-template.conf.erb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-bare-metal/commit/b643c5f620fbf5aa3f9d398cfcd4f3e69ef6008f', 'message': 'Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove erroneous restart for ironic-api service on packages\n- Properly set service password and auth URL\n- Improve tests for ironic.conf\n- Add missing apache2 depend\n- Add missing api RHEL ChefSpec tests\n- Include additional cookbooks in Berksfile required for CI\n\nDepends-On: https://review.opendev.org/702772\nDepends-On: https://review.opendev.org/701824\nChange-Id: I198e2c211630e190bf2a992b3dc6b6c5afaf54e8\n'}]",0,702568,b643c5f620fbf5aa3f9d398cfcd4f3e69ef6008f,16,2,4,21961,,,0,"Update to apache2 ~> 8.0 cookbook

This brings us up to date with the latest apache2 cookbook which
included a major refactor in 6.0.0 removing all of the definitions and
recipe with proper resources. Instead of using the apache2_default_site
resource, directly use a template and then enable the config file using
the apache2_site resource. This gives us the most flexibility.

Additional fixes:
- Install mod_wsgi as a package on RHEL since there is no built-in
  resource for it.
- Convert web_app to template and subscribe to restarting apache.
- Remove erroneous restart for ironic-api service on packages
- Properly set service password and auth URL
- Improve tests for ironic.conf
- Add missing apache2 depend
- Add missing api RHEL ChefSpec tests
- Include additional cookbooks in Berksfile required for CI

Depends-On: https://review.opendev.org/702772
Depends-On: https://review.opendev.org/701824
Change-Id: I198e2c211630e190bf2a992b3dc6b6c5afaf54e8
",git fetch https://review.opendev.org/openstack/cookbook-openstack-bare-metal refs/changes/68/702568/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/spec_helper.rb', 'README.rst', 'spec/api-rhel_spec.rb', 'attributes/default.rb', 'spec/ironic-common_spec.rb', 'spec/api_spec.rb', 'recipes/api.rb', 'metadata.rb', 'recipes/ironic-common.rb', 'templates/default/wsgi-template.conf.erb']",10,6482e945b6975ac8605d1b84eb8338ea1d64f708,apache2-refactor,<VirtualHost <%= @server_host %>:<%= @server_port %>> WSGIDaemonProcess <%= @daemon_process %> processes=2 threads=10 user=<%= @user %> group=<%= @group %> display-name=%{GROUP} WSGIProcessGroup <%= @daemon_process %> WSGIScriptAlias / <%= @server_entry %> ErrorLog <%= @log_dir %>/<%= @daemon_process %>_error.log CustomLog <%= @log_dir %>/<%= @daemon_process %>_access.log combined <% if node['openstack']['bare_metal']['ssl']['enabled'] -%> SSLCertificateFile <%= node['openstack']['bare_metal']['ssl']['certfile'] %> SSLCertificateKeyFile <%= node['openstack']['bare_metal']['ssl']['keyfile'] %> SSLCACertificatePath <%= node['openstack']['bare_metal']['ssl']['ca_certs_path'] %> <% unless node['openstack']['bare_metal']['ssl']['chainfile'].empty? %> SSLCertificateChainFile <%= node['openstack']['bare_metal']['ssl']['chainfile'] %> SSLProtocol <%= node['openstack']['bare_metal']['ssl']['protocol'] %> <% unless node['openstack']['bare_metal']['ssl']['ciphers'].empty? -%> SSLCipherSuite <%= node['openstack']['bare_metal']['ssl']['ciphers'] %><% if node['openstack']['bare_metal']['ssl']['cert_required'] -%>WSGISocketPrefix <%= @run_dir -%>,"Listen <%= @params[:server_host] %>:<%= @params[:server_port] %> <VirtualHost <%= @params[:server_host] %>:<%= @params[:server_port] %>> WSGIDaemonProcess <%= @params[:daemon_process] %> processes=2 threads=10 user=<%= @params[:user] %> group=<%= @params[:group] %> display-name=%{GROUP} WSGIProcessGroup <%= @params[:daemon_process] %> WSGIScriptAlias / <%= @params[:server_entry] %> ErrorLog <%= @params[:log_dir] %>/<%= @params[:daemon_process] %>_error.log CustomLog <%= @params[:log_dir] %>/<%= @params[:daemon_process] %>_access.log combined <% if [true, 'true', 'True'].include?(@params[:log_debug]) -%> LogLevel debug <% end -%> <% if @params[:use_ssl] -%> SSLCertificateFile <%= @params[:cert_file] %> SSLCertificateKeyFile <%= @params[:key_file] %> SSLCACertificatePath <%= @params[:ca_certs_path] %> <% if @params[:chain_file] %> SSLCertificateChainFile <%= @params[:chain_file] %> SSLProtocol <%= @params[:protocol] %> <% if @params[:ciphers] -%> SSLCipherSuite <%= @params[:ciphers] %><% if @params[:cert_required] -%>WSGISocketPrefix <%= @params[:run_dir] -%> ",275,51
openstack%2Fcookbook-openstack-dashboard~master~Ib82595c27f03a7b456d5d5bfecc466f5ac199a5c,openstack/cookbook-openstack-dashboard,master,Ib82595c27f03a7b456d5d5bfecc466f5ac199a5c,Update to apache2 ~> 8.0 cookbook,MERGED,2020-01-14 17:24:22.000000000,2020-01-31 01:28:49.000000000,2020-01-31 01:28:49.000000000,"[{'_account_id': 13252}, {'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-14 17:24:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/b990fde50fd46041e1d4bf566a761bd5d74fc7d2', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Remove or replace references to node['apache'] attributes\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n\nChange-Id: Ib82595c27f03a7b456d5d5bfecc466f5ac199a5c\n""}, {'number': 2, 'created': '2020-01-15 19:19:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/b180150a51608bdcd8e58a67a9cc32c35dcc160b', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Remove or replace references to node['apache'] attributes\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n\nChange-Id: Ib82595c27f03a7b456d5d5bfecc466f5ac199a5c\n""}, {'number': 3, 'created': '2020-01-24 00:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/62b744bf3149528f35085f27bd0125b609a89dca', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Remove or replace references to node['apache'] attributes\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Include additional cookbooks in Berksfile required for CI\n\nDepends-On: https://review.opendev.org/702772\nDepends-On: https://review.opendev.org/701824\nChange-Id: Ib82595c27f03a7b456d5d5bfecc466f5ac199a5c\n""}, {'number': 4, 'created': '2020-01-24 00:39:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/1b8c11349924410302bc157d70e27d23917f81d5', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Remove or replace references to node['apache'] attributes\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Include additional cookbooks in Berksfile required for CI\n\nDepends-On: https://review.opendev.org/702772\nDepends-On: https://review.opendev.org/701824\nChange-Id: Ib82595c27f03a7b456d5d5bfecc466f5ac199a5c\n""}, {'number': 5, 'created': '2020-01-24 00:48:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/8153ffe4bfc22c7cafe4a5bf7436e02ec2334ba1', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Remove or replace references to node['apache'] attributes\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Include additional cookbooks in Berksfile required for CI\n\nDepends-On: https://review.opendev.org/702772\nDepends-On: https://review.opendev.org/701824\nChange-Id: Ib82595c27f03a7b456d5d5bfecc466f5ac199a5c\n""}, {'number': 6, 'created': '2020-01-30 17:30:37.000000000', 'files': ['recipes/neutron-lbaas-dashboard.rb', 'README.rst', 'spec/apache2-server-redhat_spec.rb', 'spec/neutron-lbaas-dashboard_spec.rb', 'spec/horizon-redhat_spec.rb', 'templates/default/dash-site.erb', 'Berksfile', 'spec/apache2-server_spec.rb', 'spec/neutron-fwaas-dashboard_spec.rb', 'spec/horizon_spec.rb', 'spec/spec_helper.rb', 'attributes/default.rb', 'recipes/apache2-server.rb', 'metadata.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-dashboard/commit/4e4bed1eedcec978ba9fc1cba18066c423dd502e', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Remove or replace references to node['apache'] attributes\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Include additional cookbooks in Berksfile required for CI\n\nDepends-On: https://review.opendev.org/702772\nDepends-On: https://review.opendev.org/701824\nChange-Id: Ib82595c27f03a7b456d5d5bfecc466f5ac199a5c\n""}]",3,702489,4e4bed1eedcec978ba9fc1cba18066c423dd502e,22,3,6,21961,,,0,"Update to apache2 ~> 8.0 cookbook

This brings us up to date with the latest apache2 cookbook which
included a major refactor in 6.0.0 removing all of the definitions and
recipe with proper resources. Instead of using the apache2_default_site
resource, directly use a template and then enable the config file using
the apache2_site resource. This gives us the most flexibility.

Additional fixes:
- Remove or replace references to node['apache'] attributes
- Install mod_wsgi as a package on RHEL since there is no built-in
  resource for it.
- Don't set SELinux to permissive on RHEL (I tested this works properly
  with it set to enforcing).
- Remove hack for restarting apache.
- Convert web_app to template and subscribe to restarting apache.
- Remove resources to restore SELinux contexts since this taken care of
  by Chef now automatically.
- Include additional cookbooks in Berksfile required for CI

Depends-On: https://review.opendev.org/702772
Depends-On: https://review.opendev.org/701824
Change-Id: Ib82595c27f03a7b456d5d5bfecc466f5ac199a5c
",git fetch https://review.opendev.org/openstack/cookbook-openstack-dashboard refs/changes/89/702489/1 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/neutron-lbaas-dashboard.rb', 'README.rst', 'spec/apache2-server-redhat_spec.rb', 'spec/neutron-lbaas-dashboard_spec.rb', 'spec/horizon-redhat_spec.rb', 'templates/default/dash-site.erb', 'spec/apache2-server_spec.rb', 'spec/neutron-fwaas-dashboard_spec.rb', 'spec/horizon_spec.rb', 'spec/spec_helper.rb', 'attributes/default.rb', 'recipes/apache2-server.rb', 'metadata.rb']",13,b990fde50fd46041e1d4bf566a761bd5d74fc7d2,apache2-refactor,"depends 'apache2', '~> 8.0'","depends 'apache2', '5.0.1'",163,216
openstack%2Fcookbook-openstack-compute~master~Ib404ab6bfcae3340fd7f0f924539ca6c445b55cf,openstack/cookbook-openstack-compute,master,Ib404ab6bfcae3340fd7f0f924539ca6c445b55cf,Update to apache2 ~> 8.0 cookbook,MERGED,2020-01-15 00:02:50.000000000,2020-01-31 01:28:48.000000000,2020-01-31 01:28:48.000000000,"[{'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 00:02:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/c5deb2e3da5359a830497ca67fe4361377a045a7', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Fix resource ordering in placement_api\n- Improve ChefSpec tests\n- Add missing placement_api RHEL tests\n- Fix issues with chain file and cipher suite in in wsgi template\n\nChange-Id: Ib404ab6bfcae3340fd7f0f924539ca6c445b55cf\n""}, {'number': 2, 'created': '2020-01-15 19:18:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/f11f84595e041f5bc6e2a32851ad6a860ff06045', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Fix resource ordering in placement_api\n- Improve ChefSpec tests\n- Add missing placement_api RHEL tests\n- Fix issues with chain file and cipher suite in in wsgi template\n\nChange-Id: Ib404ab6bfcae3340fd7f0f924539ca6c445b55cf\n""}, {'number': 3, 'created': '2020-01-15 21:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/6fd210520571a7dae1ad5cfcbeed8c1c2a852429', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Fix resource ordering in placement_api\n- Improve ChefSpec tests\n- Add missing placement_api RHEL tests\n- Fix issues with chain file and cipher suite in in wsgi template\n\nChange-Id: Ib404ab6bfcae3340fd7f0f924539ca6c445b55cf\n""}, {'number': 4, 'created': '2020-01-23 23:12:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/353d0e60fd3ffe5cf08dfd2ca498e37c1697159d', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Fix resource ordering in placement_api\n- Improve ChefSpec tests\n- Add missing placement_api RHEL tests\n- Fix issues with chain file and cipher suite in in wsgi template\n- Include additional cookbooks in Berksfile required for CI\n\nDepends-On: https://review.opendev.org/702772\nDepends-On: https://review.opendev.org/701824\nChange-Id: Ib404ab6bfcae3340fd7f0f924539ca6c445b55cf\n""}, {'number': 5, 'created': '2020-01-30 19:22:24.000000000', 'files': ['spec/placement_api-redhat_spec.rb', 'spec/api-metadata_spec.rb', 'spec/api-os-compute-redhat_spec.rb', 'README.rst', 'spec/api-metadata-redhat_spec.rb', 'recipes/api-os-compute.rb', 'Berksfile', 'spec/placement_api_spec.rb', 'recipes/api-metadata.rb', 'spec/api-os-compute_spec.rb', 'recipes/placement_api.rb', 'spec/spec_helper.rb', 'attributes/default.rb', 'metadata.rb', 'recipes/nova-common.rb', 'templates/default/wsgi-template.conf.erb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/868900d090dcce91a37bf72ff2cb43a88ffa9171', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nAdditional fixes:\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Fix resource ordering in placement_api\n- Improve ChefSpec tests\n- Add missing placement_api RHEL tests\n- Fix issues with chain file and cipher suite in in wsgi template\n- Include additional cookbooks in Berksfile required for CI\n\nDepends-On: https://review.opendev.org/702772\nDepends-On: https://review.opendev.org/701824\nChange-Id: Ib404ab6bfcae3340fd7f0f924539ca6c445b55cf\n""}]",0,702558,868900d090dcce91a37bf72ff2cb43a88ffa9171,20,2,5,21961,,,0,"Update to apache2 ~> 8.0 cookbook

This brings us up to date with the latest apache2 cookbook which
included a major refactor in 6.0.0 removing all of the definitions and
recipe with proper resources. Instead of using the apache2_default_site
resource, directly use a template and then enable the config file using
the apache2_site resource. This gives us the most flexibility.

Additional fixes:
- Install mod_wsgi as a package on RHEL since there is no built-in
  resource for it.
- Don't set SELinux to permissive on RHEL (I tested this works properly
  with it set to enforcing).
- Remove hack for restarting apache.
- Convert web_app to template and subscribe to restarting apache.
- Remove resources to restore SELinux contexts since this taken care of
  by Chef now automatically.
- Fix resource ordering in placement_api
- Improve ChefSpec tests
- Add missing placement_api RHEL tests
- Fix issues with chain file and cipher suite in in wsgi template
- Include additional cookbooks in Berksfile required for CI

Depends-On: https://review.opendev.org/702772
Depends-On: https://review.opendev.org/701824
Change-Id: Ib404ab6bfcae3340fd7f0f924539ca6c445b55cf
",git fetch https://review.opendev.org/openstack/cookbook-openstack-compute refs/changes/58/702558/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/placement_api-redhat_spec.rb', 'spec/api-metadata_spec.rb', 'spec/api-os-compute-redhat_spec.rb', 'spec/api-metadata-redhat_spec.rb', 'recipes/api-os-compute.rb', 'spec/placement_api_spec.rb', 'recipes/api-metadata.rb', 'spec/api-os-compute_spec.rb', 'recipes/placement_api.rb', 'spec/spec_helper.rb', 'attributes/default.rb', 'metadata.rb', 'recipes/nova-common.rb', 'templates/default/wsgi-template.conf.erb']",14,c5deb2e3da5359a830497ca67fe4361377a045a7,apache2-refactor,<VirtualHost <%= @server_host %>:<%= @server_port %>> WSGIDaemonProcess <%= @daemon_process %> processes=2 threads=10 user=<%= @user %> group=<%= @group %> display-name=%{GROUP} WSGIProcessGroup <%= @daemon_process %> WSGIScriptAlias / <%= @server_entry %> ErrorLog <%= @log_dir %>/<%= @daemon_process %>_error.log CustomLog <%= @log_dir %>/<%= @daemon_process %>_access.log combined <% if @use_ssl -%> SSLCertificateFile <%= @cert_file %> SSLCertificateKeyFile <%= @key_file %> SSLCACertificatePath <%= @ca_certs_path %> <% unless @chain_file.empty? %> SSLCertificateChainFile <%= @chain_file %> SSLProtocol <%= @protocol %> <% unless @ciphers.empty? -%> SSLCipherSuite <%= @ciphers %><% if @cert_required -%>WSGISocketPrefix <%= @run_dir -%>,"Listen <%= @params[:server_host] %>:<%= @params[:server_port] %> <VirtualHost <%= @params[:server_host] %>:<%= @params[:server_port] %>> WSGIDaemonProcess <%= @params[:daemon_process] %> processes=2 threads=10 user=<%= @params[:user] %> group=<%= @params[:group] %> display-name=%{GROUP} WSGIProcessGroup <%= @params[:daemon_process] %> WSGIScriptAlias / <%= @params[:server_entry] %> ErrorLog <%= @params[:log_dir] %>/<%= @params[:daemon_process] %>_error.log CustomLog <%= @params[:log_dir] %>/<%= @params[:daemon_process] %>_access.log combined <% if [true, 'true', 'True'].include?(@params[:log_debug]) -%> LogLevel debug <% end -%> <% if @params[:use_ssl] -%> SSLCertificateFile <%= @params[:cert_file] %> SSLCertificateKeyFile <%= @params[:key_file] %> SSLCACertificatePath <%= @params[:ca_certs_path] %> <% if @params[:chain_file] %> SSLCertificateChainFile <%= @params[:chain_file] %> SSLProtocol <%= @params[:protocol] %> <% if @params[:ciphers] -%> SSLCipherSuite <%= @params[:ciphers] %><% if @params[:cert_required] -%>WSGISocketPrefix <%= @params[:run_dir] -%> ",577,303
openstack%2Fcinder~stable%2Frocky~I0c26c400f08d91c8c125c69e06e4c90302bcdbb1,openstack/cinder,stable/rocky,I0c26c400f08d91c8c125c69e06e4c90302bcdbb1,Increase cpu limit for image conversion,MERGED,2019-12-03 15:14:15.000000000,2020-01-31 01:14:14.000000000,2019-12-05 20:51:36.000000000,"[{'_account_id': 7198}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12369}, {'_account_id': 18883}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-12-03 15:14:15.000000000', 'files': ['cinder/image/image_utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ce951a3b586bc51a77422c3079637198f14ecb44', 'message': 'Increase cpu limit for image conversion\n\nThe 8 second timeout is not always sufficient for\nlarge images.\n\nBump to 30s, which matches what Nova currently\nuses for this same limit.\n\nChange-Id: I0c26c400f08d91c8c125c69e06e4c90302bcdbb1\nCloses-Bug: #1705340\n(cherry picked from commit 3566c5145ad676c7eb5952807f3ef1c44c142b74)\n(cherry picked from commit fa6f7d3d319647bee17ebc9a390ae26c14f3650f)\n(cherry picked from commit 186fb25d049a2136eb71f9fece81903450b22890)\n'}]",0,697110,ce951a3b586bc51a77422c3079637198f14ecb44,29,17,1,4523,,,0,"Increase cpu limit for image conversion

The 8 second timeout is not always sufficient for
large images.

Bump to 30s, which matches what Nova currently
uses for this same limit.

Change-Id: I0c26c400f08d91c8c125c69e06e4c90302bcdbb1
Closes-Bug: #1705340
(cherry picked from commit 3566c5145ad676c7eb5952807f3ef1c44c142b74)
(cherry picked from commit fa6f7d3d319647bee17ebc9a390ae26c14f3650f)
(cherry picked from commit 186fb25d049a2136eb71f9fece81903450b22890)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/10/697110/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/image/image_utils.py'],1,ce951a3b586bc51a77422c3079637198f14ecb44,," cpu_time=30,"," cpu_time=8,",1,1
openstack%2Fcookbook-openstack-block-storage~master~I289091f54750dd5068e98fd4f4853880f4b72c6c,openstack/cookbook-openstack-block-storage,master,I289091f54750dd5068e98fd4f4853880f4b72c6c,Update to apache2 ~> 8.0 cookbook,MERGED,2020-01-10 18:58:47.000000000,2020-01-31 00:58:54.000000000,2020-01-31 00:58:54.000000000,"[{'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-10 18:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/47b490b6b78f97aab8900404d6a1b3d305e80240', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nOther changes:\n- Remove selinux for depends as it's not being referenced anywhere in\n  the cookbook\n- Included more ChefSpec tests for api recipe\n- Update WSGI template\n\nChange-Id: I289091f54750dd5068e98fd4f4853880f4b72c6c\n""}, {'number': 2, 'created': '2020-01-15 19:17:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/adc9e5e7bb2b707470b48a0bc1a534a438664cd9', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nOther changes:\n- Remove selinux for depends as it's not being referenced anywhere in\n  the cookbook\n- Included more ChefSpec tests for api recipe\n- Update WSGI template\n\nChange-Id: I289091f54750dd5068e98fd4f4853880f4b72c6c\n""}, {'number': 3, 'created': '2020-01-23 23:18:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/6e611aafc0420f6aad67b5f689583b6e9634d0a3', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nOther changes:\n- Remove selinux for depends as it's not being referenced anywhere in\n  the cookbook\n- Included more ChefSpec tests for api recipe\n- Update WSGI template\n- Include additional cookbooks in Berksfile required for CI\n\nDepends-On: https://review.opendev.org/702772\nDepends-On: https://review.opendev.org/701824\nChange-Id: I289091f54750dd5068e98fd4f4853880f4b72c6c\n""}, {'number': 4, 'created': '2020-01-30 17:29:16.000000000', 'files': ['spec/spec_helper.rb', 'README.rst', 'recipes/cinder-common.rb', 'attributes/default.rb', 'spec/api_spec.rb', 'spec/api-redhat_spec.rb', 'recipes/api.rb', 'metadata.rb', 'Berksfile', 'templates/default/wsgi-template.conf.erb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-block-storage/commit/873b58d13bcb4551347e2e31fb0597eab3b7d6b0', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\nOther changes:\n- Remove selinux for depends as it's not being referenced anywhere in\n  the cookbook\n- Included more ChefSpec tests for api recipe\n- Update WSGI template\n- Include additional cookbooks in Berksfile required for CI\n\nDepends-On: https://review.opendev.org/702772\nDepends-On: https://review.opendev.org/701824\nChange-Id: I289091f54750dd5068e98fd4f4853880f4b72c6c\n""}]",0,702027,873b58d13bcb4551347e2e31fb0597eab3b7d6b0,18,2,4,21961,,,0,"Update to apache2 ~> 8.0 cookbook

This brings us up to date with the latest apache2 cookbook which
included a major refactor in 6.0.0 removing all of the definitions and
recipe with proper resources. Instead of using the apache2_default_site
resource, directly use a template and then enable the config file using
the apache2_site resource. This gives us the most flexibility.

Other changes:
- Remove selinux for depends as it's not being referenced anywhere in
  the cookbook
- Included more ChefSpec tests for api recipe
- Update WSGI template
- Include additional cookbooks in Berksfile required for CI

Depends-On: https://review.opendev.org/702772
Depends-On: https://review.opendev.org/701824
Change-Id: I289091f54750dd5068e98fd4f4853880f4b72c6c
",git fetch https://review.opendev.org/openstack/cookbook-openstack-block-storage refs/changes/27/702027/3 && git format-patch -1 --stdout FETCH_HEAD,"['spec/spec_helper.rb', 'README.rst', 'recipes/cinder-common.rb', 'attributes/default.rb', 'spec/api_spec.rb', 'spec/api-redhat_spec.rb', 'recipes/api.rb', 'metadata.rb', 'templates/default/wsgi-template.conf.erb']",9,47b490b6b78f97aab8900404d6a1b3d305e80240,apache2-refactor,<VirtualHost <%= @server_host %>:<%= @server_port %>> WSGIDaemonProcess <%= @daemon_process %> processes=2 threads=10 user=<%= @user %> group=<%= @group %> display-name=%{GROUP} WSGIProcessGroup <%= @daemon_process %> WSGIScriptAlias / <%= @server_entry %> ErrorLog <%= @log_dir %>/<%= @daemon_process %>_error.log CustomLog <%= @log_dir %>/<%= @daemon_process %>_access.log combined <% if node['openstack']['block-storage']['ssl']['enabled'] -%> SSLCertificateFile <%= node['openstack']['block-storage']['ssl']['certfile'] %> SSLCertificateKeyFile <%= node['openstack']['block-storage']['ssl']['keyfile'] %> SSLCACertificatePath <%= node['openstack']['block-storage']['ssl']['ca_certs_path'] %> <% unless node['openstack']['block-storage']['ssl']['chainfile'].empty? %> SSLCertificateChainFile <%= node['openstack']['block-storage']['ssl']['chainfile'] %> SSLProtocol <%= node['openstack']['block-storage']['ssl']['protocol'] %> <% unless node['openstack']['block-storage']['ssl']['ciphers'].empty? -%> SSLCipherSuite <%= node['openstack']['block-storage']['ssl']['ciphers'] %><% if node['openstack']['block-storage']['ssl']['cert_required'] -%>WSGISocketPrefix <%= @run_dir -%>,"Listen <%= @params[:server_host] %>:<%= @params[:server_port] %> <VirtualHost <%= @params[:server_host] %>:<%= @params[:server_port] %>> WSGIDaemonProcess <%= @params[:daemon_process] %> processes=2 threads=10 user=<%= @params[:user] %> group=<%= @params[:group] %> display-name=%{GROUP} WSGIProcessGroup <%= @params[:daemon_process] %> WSGIScriptAlias / <%= @params[:server_entry] %> ErrorLog <%= @params[:log_dir] %>/<%= @params[:daemon_process] %>_error.log CustomLog <%= @params[:log_dir] %>/<%= @params[:daemon_process] %>_access.log combined <% if [true, 'true', 'True'].include?(@params[:log_debug]) -%> LogLevel debug <% end -%> <% if @params[:use_ssl] -%> SSLCertificateFile <%= @params[:cert_file] %> SSLCertificateKeyFile <%= @params[:key_file] %> SSLCACertificatePath <%= @params[:ca_certs_path] %> <% if @params[:chain_file] %> SSLCertificateChainFile <%= @params[:chain_file] %> SSLProtocol <%= @params[:protocol] %> <% if @params[:ciphers] -%> SSLCipherSuite <%= @params[:ciphers] %><% if @params[:cert_required] -%>WSGISocketPrefix <%= @params[:run_dir] -%> ",214,98
openstack%2Fcookbook-openstack-identity~master~I717247217523e89251e4c0bead0c1a0d114ade2a,openstack/cookbook-openstack-identity,master,I717247217523e89251e4c0bead0c1a0d114ade2a,Update to apache2 ~> 8.0 cookbook,MERGED,2020-01-09 19:55:18.000000000,2020-01-31 00:30:37.000000000,2020-01-31 00:30:37.000000000,"[{'_account_id': 13252}, {'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-09 19:55:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/398d4a99ad086a7e57d95ee503d15ba809d001a5', 'message': ""WIP: Update to apache2 ~> 8.0.2 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Remove unused references to log_debug in wsgi template\n- Add missing WSGISocketPrefix to wsgi template\n\nChange-Id: I717247217523e89251e4c0bead0c1a0d114ade2a\n""}, {'number': 2, 'created': '2020-01-10 00:05:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/3fe8c6dc9d6b47e652e9c0c850060f57222be2b3', 'message': ""WIP: Update to apache2 ~> 8.0.2 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Remove unused references to log_debug in wsgi template\n- Add missing WSGISocketPrefix to wsgi template\n\nChange-Id: I717247217523e89251e4c0bead0c1a0d114ade2a\n""}, {'number': 3, 'created': '2020-01-10 17:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/31280a2db425f4c3a68de3d1d32565961ec11e74', 'message': ""WIP: Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Remove unused references to log_debug in wsgi template\n- Add missing WSGISocketPrefix to wsgi template\n\nChange-Id: I717247217523e89251e4c0bead0c1a0d114ade2a\n""}, {'number': 4, 'created': '2020-01-14 19:52:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/0298d35a2e4fd7806edabad9b033d7c4fe284df5', 'message': ""WIP: Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Remove unused references to log_debug in wsgi template\n- Add missing WSGISocketPrefix to wsgi template\n\nDepends-On: https://review.opendev.org/702027\nDepends-On: https://review.opendev.org/702489\nDepends-On: https://review.opendev.org/702508\n\nChange-Id: I717247217523e89251e4c0bead0c1a0d114ade2a\n""}, {'number': 5, 'created': '2020-01-15 18:12:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/d1ea51ff9a6774aa551dba2bb86e0fbac7361aef', 'message': ""WIP: Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Remove unused references to log_debug in wsgi template\n- Add missing WSGISocketPrefix to wsgi template\n- Additional tests for keystone.conf and identity.conf\n- Remove unused ldap section tests as we no longer have attributes for it\n\nDepends-On: https://review.opendev.org/702027\nDepends-On: https://review.opendev.org/702489\nDepends-On: https://review.opendev.org/702508\nDepends-On: https://review.opendev.org/702558\nDepends-On: https://review.opendev.org/702568\n\nChange-Id: I717247217523e89251e4c0bead0c1a0d114ade2a\n""}, {'number': 6, 'created': '2020-01-15 18:13:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/a387ee5e6c3dd9156c6f00ec69ad3a1933871b07', 'message': ""WIP: Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Remove unused references to log_debug in wsgi template\n- Add missing WSGISocketPrefix to wsgi template\n- Additional tests for keystone.conf and identity.conf\n- Remove unused ldap section tests as we no longer have attributes for it\n\nDepends-On: https://review.opendev.org/702027\nDepends-On: https://review.opendev.org/702489\nDepends-On: https://review.opendev.org/702508\nDepends-On: https://review.opendev.org/702558\nDepends-On: https://review.opendev.org/702568\n\nChange-Id: I717247217523e89251e4c0bead0c1a0d114ade2a\n""}, {'number': 7, 'created': '2020-01-15 23:29:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/a02bf4976456a8a0612008b92840d72e9059aa67', 'message': ""WIP: Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Remove unused references to log_debug in wsgi template\n- Add missing WSGISocketPrefix to wsgi template\n- Additional tests for keystone.conf and identity.conf\n- Remove unused ldap section tests as we no longer have attributes for it\n\nDepends-On: https://review.opendev.org/702772\n\nChange-Id: I717247217523e89251e4c0bead0c1a0d114ade2a\n""}, {'number': 8, 'created': '2020-01-15 23:34:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/149ace738d4a87ce3bdbcfd3efb9f57b34151e40', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Remove unused references to log_debug in wsgi template\n- Add missing WSGISocketPrefix to wsgi template\n- Additional tests for keystone.conf and identity.conf\n- Remove unused ldap section tests as we no longer have attributes for it\n\nDepends-On: https://review.opendev.org/702772\n\nChange-Id: I717247217523e89251e4c0bead0c1a0d114ade2a\n""}, {'number': 9, 'created': '2020-01-23 21:38:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/8a46382d6e0fc5c6ab56271df8d29ad89e889337', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Remove unused references to log_debug in wsgi template\n- Add missing WSGISocketPrefix to wsgi template\n- Additional tests for keystone.conf and identity.conf\n- Remove unused ldap section tests as we no longer have attributes for it\n- Include additional cookbooks in Berksfile required for CI\n\nDepends-On: https://review.opendev.org/702772\n\nChange-Id: I717247217523e89251e4c0bead0c1a0d114ade2a\n""}, {'number': 10, 'created': '2020-01-30 17:15:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/72088f495e272c08dc70847c10135db96f1bfd17', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Remove unused references to log_debug in wsgi template\n- Add missing WSGISocketPrefix to wsgi template\n- Additional tests for keystone.conf and identity.conf\n- Remove unused ldap section tests as we no longer have attributes for it\n- Include additional cookbooks in Berksfile required for CI\n\nDepends-On: https://review.opendev.org/702772\n\nChange-Id: I717247217523e89251e4c0bead0c1a0d114ade2a\n""}, {'number': 11, 'created': '2020-01-30 17:23:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/48cdd503bfc03523cbd2ecfb71d60d820d33f1d3', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Remove unused references to log_debug in wsgi template\n- Add missing WSGISocketPrefix to wsgi template\n- Additional tests for keystone.conf and identity.conf\n- Remove unused ldap section tests as we no longer have attributes for it\n- Include additional cookbooks in Berksfile required for CI\n\nDepends-On: https://review.opendev.org/702772\n\nChange-Id: I717247217523e89251e4c0bead0c1a0d114ade2a\n""}, {'number': 12, 'created': '2020-01-30 17:28:29.000000000', 'files': ['recipes/server-apache.rb', 'spec/server-apache_spec.rb', 'README.rst', 'attributes/default.rb', 'spec/server-apache-redhat_spec.rb', 'metadata.rb', 'Berksfile', 'templates/default/wsgi-keystone.conf.erb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/453ab3bb95bb6a3c23f70352eea5529d88dacaec', 'message': ""Update to apache2 ~> 8.0 cookbook\n\nThis brings us up to date with the latest apache2 cookbook which\nincluded a major refactor in 6.0.0 removing all of the definitions and\nrecipe with proper resources. Instead of using the apache2_default_site\nresource, directly use a template and then enable the config file using\nthe apache2_site resource. This gives us the most flexibility.\n\n- Install mod_wsgi as a package on RHEL since there is no built-in\n  resource for it.\n- Don't set SELinux to permissive on RHEL (I tested this works properly\n  with it set to enforcing).\n- Remove hack for restarting apache.\n- Convert web_app to template and subscribe to restarting apache.\n- Remove resources to restore SELinux contexts since this taken care of\n  by Chef now automatically.\n- Remove unused references to log_debug in wsgi template\n- Add missing WSGISocketPrefix to wsgi template\n- Additional tests for keystone.conf and identity.conf\n- Remove unused ldap section tests as we no longer have attributes for it\n- Include additional cookbooks in Berksfile required for CI\n\nDepends-On: https://review.opendev.org/702772\n\nChange-Id: I717247217523e89251e4c0bead0c1a0d114ade2a\n""}]",3,701824,453ab3bb95bb6a3c23f70352eea5529d88dacaec,42,3,12,21961,,,0,"Update to apache2 ~> 8.0 cookbook

This brings us up to date with the latest apache2 cookbook which
included a major refactor in 6.0.0 removing all of the definitions and
recipe with proper resources. Instead of using the apache2_default_site
resource, directly use a template and then enable the config file using
the apache2_site resource. This gives us the most flexibility.

- Install mod_wsgi as a package on RHEL since there is no built-in
  resource for it.
- Don't set SELinux to permissive on RHEL (I tested this works properly
  with it set to enforcing).
- Remove hack for restarting apache.
- Convert web_app to template and subscribe to restarting apache.
- Remove resources to restore SELinux contexts since this taken care of
  by Chef now automatically.
- Remove unused references to log_debug in wsgi template
- Add missing WSGISocketPrefix to wsgi template
- Additional tests for keystone.conf and identity.conf
- Remove unused ldap section tests as we no longer have attributes for it
- Include additional cookbooks in Berksfile required for CI

Depends-On: https://review.opendev.org/702772

Change-Id: I717247217523e89251e4c0bead0c1a0d114ade2a
",git fetch https://review.opendev.org/openstack/cookbook-openstack-identity refs/changes/24/701824/8 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/server-apache.rb', 'spec/server-apache_spec.rb', 'attributes/default.rb', 'metadata.rb', 'templates/default/wsgi-keystone.conf.erb']",5,398d4a99ad086a7e57d95ee503d15ba809d001a5,apache2-refactor,<VirtualHost <%= @server_host %>:<%= @server_port %>> WSGIDaemonProcess identity processes=5 threads=1 user=<%= @user %> group=<%= @group %> display-name=%{GROUP} WSGIScriptAlias / <%= @server_entry %> ErrorLog <%= @log_dir %>/identity.log CustomLog <%= @log_dir %>/identity_access.log combined <% if node['openstack']['identity']['ssl']['enabled'] -%> SSLCertificateFile <%= node['openstack']['identity']['ssl']['certfile'] %> SSLCertificateKeyFile <%= node['openstack']['identity']['ssl']['keyfile'] %> SSLCACertificatePath <%= node['openstack']['identity']['ssl']['ca_certs_path'] %> <% if node['openstack']['identity']['ssl']['chainfile'] %> SSLCertificateChainFile <%= node['openstack']['identity']['ssl']['chainfile'] %> SSLProtocol <%= node['openstack']['identity']['ssl']['protocol'] %> <% if node['openstack']['identity']['ssl']['ciphers'] -%> SSLCipherSuite <%= node['openstack']['identity']['ssl']['ciphers'] %> <% if node['openstack']['identity']['ssl']['cert_required'] -%> WSGISocketPrefix <%= @run_dir %>,"<VirtualHost <%= @params[:server_host] %>:<%= @params[:server_port] %>> WSGIDaemonProcess identity processes=5 threads=1 user=<%= @params[:user] %> group=<%= @params[:group] %> display-name=%{GROUP} WSGIScriptAlias / <%= @params[:server_entry] %> ErrorLog <%= @params[:log_dir] %>/identity.log CustomLog <%= @params[:log_dir] %>/identity_access.log combined <% if [true, 'true', 'True'].include?(@params[:log_debug]) -%> LogLevel debug <% end -%> <% if @params[:use_ssl] -%> SSLCertificateFile <%= @params[:cert_file] %> SSLCertificateKeyFile <%= @params[:key_file] %> SSLCACertificatePath <%= @params[:ca_certs_path] %> <% if @params[:chain_file] %> SSLCertificateChainFile <%= @params[:chain_file] %> SSLProtocol <%= @params[:protocol] %> <% if @params[:ciphers] -%> SSLCipherSuite <%= @params[:ciphers] %> <% if @params[:cert_required] -%>",119,172
openstack%2Fproject-config~master~Ied96194e1904fee232e144a4e89ec8ba2252e42e,openstack/project-config,master,Ied96194e1904fee232e144a4e89ec8ba2252e42e,Testing publishing artifacts to AFS,MERGED,2020-01-30 03:58:13.000000000,2020-01-31 00:29:45.000000000,2020-01-31 00:28:38.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-30 03:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2e160a3b2c0b08eea85577aa77c4b29ed3f9ab79', 'message': 'Also publish artifacts to AFS\n\nThis is part of our efforts to get tarball publishing onto AFS volumes\n[1].  In the current artifact publishing job, add the roles to also\nupload to output to /afs/.openstack.org/project/tarballs.opendev.org.\nThis is intended to be canonical location, long term, but for now we\nare testing this in parallel.\n\n[1] https://docs.opendev.org/opendev/infra-specs/latest/specs/retire-static.html\n\nChange-Id: Ied96194e1904fee232e144a4e89ec8ba2252e42e\n'}, {'number': 2, 'created': '2020-01-30 04:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5ecff521960c79374488dc3bab58018dc6cdccd2', 'message': 'Also publish artifacts to AFS\n\nThis is part of our efforts to get tarball publishing onto AFS volumes\n[1].  In the current artifact publishing job, add the roles to also\nupload to output to /afs/.openstack.org/project/tarballs.opendev.org.\nThis is intended to be canonical location, long term, but for now we\nare testing this in parallel.\n\n[1] https://docs.opendev.org/opendev/infra-specs/latest/specs/retire-static.html\n\nChange-Id: Ied96194e1904fee232e144a4e89ec8ba2252e42e\n'}, {'number': 3, 'created': '2020-01-30 23:47:01.000000000', 'files': ['zuul.d/secrets.yaml', 'playbooks/publish/openstack-artifacts-with-afs.yaml', 'zuul.d/projects.yaml', 'playbooks/publish/openstack-artifacts-with-afs-test.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/675bb510f1a3491bf14a6ded17faa5083395aeb9', 'message': 'Testing publishing artifacts to AFS\n\nThis is part of our efforts to get tarball publishing onto AFS volumes\n[1].\n\nTest a new artifact publishing job that puts output at\n/afs/.openstack.org/project/tarballs.opendev.org.  This is intended to\nreplace the existing publishing job when it is working.\n\n[1] https://docs.opendev.org/opendev/infra-specs/latest/specs/retire-static.html\n\nChange-Id: Ied96194e1904fee232e144a4e89ec8ba2252e42e\n'}]",5,704921,675bb510f1a3491bf14a6ded17faa5083395aeb9,16,4,3,7118,,,0,"Testing publishing artifacts to AFS

This is part of our efforts to get tarball publishing onto AFS volumes
[1].

Test a new artifact publishing job that puts output at
/afs/.openstack.org/project/tarballs.opendev.org.  This is intended to
replace the existing publishing job when it is working.

[1] https://docs.opendev.org/opendev/infra-specs/latest/specs/retire-static.html

Change-Id: Ied96194e1904fee232e144a4e89ec8ba2252e42e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/21/704921/2 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/secrets.yaml', 'zuul.d/jobs.yaml', 'playbooks/publish/openstack-artifacts.yaml']",3,2e160a3b2c0b08eea85577aa77c4b29ed3f9ab79,static-services," # NOTE(ianw) 2020-01-30 : we are moving tarballs to publish to an AFS # volume. For now we do this in parallel, initially ignore errors to # debug things as we go. - hosts: localhost tasks: - block: - name: Create AFS token include_role: name: create-afs-token - name: Upload to AFS include_role: name: upload-afs - name: Destroy AFS token include_role: name: destory-afs-token when: zuul_success | bool ignore_errors: yes",,33,0
openstack%2Fneutron~stable%2Fstein~If0adb7ca4e254f5b19375b471679bcc18e0c7790,openstack/neutron,stable/stein,If0adb7ca4e254f5b19375b471679bcc18e0c7790,Remove one of iptables_hybrid jobs,MERGED,2020-01-29 13:23:14.000000000,2020-01-31 00:29:39.000000000,2020-01-31 00:26:16.000000000,"[{'_account_id': 1131}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 30491}, {'_account_id': 31245}]","[{'number': 1, 'created': '2020-01-29 13:23:14.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e40492d0dcf4481548483e08ce9874016013e650', 'message': 'Remove one of iptables_hybrid jobs\n\nIn check queue there were 2 iptables_hybrid jobs. One was run on Ubuntu\nand one on Fedora.\nDuring the Shanghai PTG we agreed to remove one of those jobs and left\nonly one of them to be run in both check and gate queues.\n\nThis commit removes iptables_hybrid job based on Fedora image.\n\nFedora jobs also make less sense for stable branches (and it was\nnon-voting in this branch)\n\nConflicts:\n\t.zuul.yaml\n\tdoc/source/contributor/testing/ci_scenario_jobs.rst\n\nChange-Id: If0adb7ca4e254f5b19375b471679bcc18e0c7790\n(cherry picked from commit a2fdf8aa72859be748918d56c819736b9ae048c2)\n'}]",0,704800,e40492d0dcf4481548483e08ce9874016013e650,21,7,1,21798,,,0,"Remove one of iptables_hybrid jobs

In check queue there were 2 iptables_hybrid jobs. One was run on Ubuntu
and one on Fedora.
During the Shanghai PTG we agreed to remove one of those jobs and left
only one of them to be run in both check and gate queues.

This commit removes iptables_hybrid job based on Fedora image.

Fedora jobs also make less sense for stable branches (and it was
non-voting in this branch)

Conflicts:
	.zuul.yaml
	doc/source/contributor/testing/ci_scenario_jobs.rst

Change-Id: If0adb7ca4e254f5b19375b471679bcc18e0c7790
(cherry picked from commit a2fdf8aa72859be748918d56c819736b9ae048c2)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/00/704800/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,e40492d0dcf4481548483e08ce9874016013e650,remove-iptables-hybrid-job,, - neutron-tempest-iptables_hybrid-fedora name: neutron-tempest-iptables_hybrid-fedora parent: neutron-tempest-iptables_hybrid nodeset: devstack-single-node-fedora-latest irrelevant-files: *tempest-irrelevant-files voting: false - job:,0,8
openstack%2Fneutron-tempest-plugin~master~Ib94518597bdf3d9f3049643d3242db632769de6b,openstack/neutron-tempest-plugin,master,Ib94518597bdf3d9f3049643d3242db632769de6b,Adding pattern to check_remote_connectivity function,MERGED,2020-01-30 08:43:48.000000000,2020-01-31 00:26:18.000000000,2020-01-31 00:26:18.000000000,"[{'_account_id': 10068}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 18894}, {'_account_id': 19118}, {'_account_id': 22348}, {'_account_id': 29350}, {'_account_id': 31291}]","[{'number': 1, 'created': '2020-01-30 08:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/f571dbbf34e0e98b25a5973d603932922f13dfb8', 'message': 'Adding pattern to check_remote_connectivity function\n\nPing messages sent by this function will include a pattern of bytes\nthat are repeated until message size is completed.\nInput format required is a string with hex digits\n\nChange-Id: Ib94518597bdf3d9f3049643d3242db632769de6b\n'}, {'number': 2, 'created': '2020-01-30 10:53:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/fb0aadc9a8a528ccb4187a3984bc65ef017fa6f4', 'message': 'Adding pattern to check_remote_connectivity function\n\nPing messages sent by this function will include a pattern of bytes\nthat are repeated until message size is completed.\nInput format required is a string with hex digits.\n\nThis is useful when these messages are captured, in order to identify\nand differentiate clearly messages from different tests.\nIt can be used to validate that traffic routing is not affected by\npacket data as well.\n\nChange-Id: Ib94518597bdf3d9f3049643d3242db632769de6b\n'}, {'number': 3, 'created': '2020-01-30 11:15:30.000000000', 'files': ['neutron_tempest_plugin/scenario/base.py'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/f2b60545a585169f4d17653c024320f499cc8026', 'message': 'Adding pattern to check_remote_connectivity function\n\nPing messages sent by this function will include a pattern of bytes\nthat are repeated until message size is completed.\nInput format required is a string with hex digits.\n\nThis is useful when these messages are captured, in order to identify\nand differentiate clearly messages from different tests.\nIt can be used to validate that traffic routing is not affected by\npacket data as well.\n\nCloses-Bug: #1861397\n\nChange-Id: Ib94518597bdf3d9f3049643d3242db632769de6b\n'}]",2,704940,f2b60545a585169f4d17653c024320f499cc8026,16,8,3,31291,,,0,"Adding pattern to check_remote_connectivity function

Ping messages sent by this function will include a pattern of bytes
that are repeated until message size is completed.
Input format required is a string with hex digits.

This is useful when these messages are captured, in order to identify
and differentiate clearly messages from different tests.
It can be used to validate that traffic routing is not affected by
packet data as well.

Closes-Bug: #1861397

Change-Id: Ib94518597bdf3d9f3049643d3242db632769de6b
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/40/704940/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron_tempest_plugin/scenario/base.py'],1,f571dbbf34e0e98b25a5973d603932922f13dfb8,," timeout=None, pattern=None): :param pattern: hex digits included in ICMP messages fragmentation=True, pattern=None): if pattern: cmd += ' -p {pattern}'.format(pattern=pattern) fragmentation=fragmentation, pattern=pattern) ping_count=CONF.validation.ping_count, pattern=pattern): timeout=timeout, pattern=pattern))", timeout=None): fragmentation=True): fragmentation=fragmentation) ping_count=CONF.validation.ping_count): timeout=timeout)),10,5
openstack%2Fopenstack-chef~master~Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e,openstack/openstack-chef,master,Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e,Refactor integration tests,MERGED,2020-01-15 23:07:44.000000000,2020-01-31 00:00:37.000000000,2020-01-30 23:58:22.000000000,"[{'_account_id': 13252}, {'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 23:07:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/d41d7700bbdc9a3bc673dc6124345cdd390dc9d0', 'message': ""Use Berksfile from cookbook that's being tested for integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with gerrit without getting into depends-on hell.\n\nIn addition, print out the command that run_command is going to run to\nhelp with debugging.\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 2, 'created': '2020-01-15 23:14:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/f0c34032ddf4f34bb1ecbdb0fa33b64ceac02cf4', 'message': ""Use Berksfile from cookbook that's being tested for integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with gerrit without getting into depends-on hell.\n\nIn addition, print out the command that run_command is going to run to\nhelp with debugging.\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 3, 'created': '2020-01-15 23:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/e647c6be331ef39904a5b8c1514fe996c703d0f8', 'message': ""Use Berksfile from cookbook that's being tested for integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with gerrit without getting into depends-on hell.\n\nIn addition, print out the command that run_command is going to run to\nhelp with debugging.\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 4, 'created': '2020-01-15 23:41:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/3f0cfd676adb843db61bb0b348ee32faac05512d', 'message': ""Use Berksfile from cookbook that's being tested for integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with gerrit without getting into depends-on hell.\n\nIn addition, print out the command that run_command is going to run to\nhelp with debugging.\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 5, 'created': '2020-01-15 23:56:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/5d8760c3673519a77dee0969d6d4831232625cdf', 'message': ""Use Berksfile from cookbook that's being tested for integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with gerrit without getting into depends-on hell.\n\nIn addition, print out the command that run_command is going to run to\nhelp with debugging.\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 6, 'created': '2020-01-16 00:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/4e0bd7a2f109eae60a0d24a7f83786c2c3f3b6e5', 'message': ""Use Berksfile from cookbook that's being tested for integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with gerrit without getting into depends-on hell.\n\nIn addition, print out the command that run_command is going to run to\nhelp with debugging.\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 7, 'created': '2020-01-23 19:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/2b44ea07f253433b8ec07976910b332298a029ef', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n- Runs Tempest\n\nThe minimal suite excludes running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. However they are included\nin all other suites for test-kitchen except for the default (allinone)\nsuite.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 8, 'created': '2020-01-23 20:12:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/6b7907da3e973f66567d00124be265ebb8db690a', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n- Runs Tempest\n\nThe minimal suite excludes running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. However they are included\nin all other suites for test-kitchen except for the default (allinone)\nsuite.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 9, 'created': '2020-01-23 20:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/95f524f4adbc6cca5698041bee1376d44bf5463f', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n- Runs Tempest\n\nThe minimal suite excludes running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. However they are included\nin all other suites for test-kitchen except for the default (allinone)\nsuite.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 10, 'created': '2020-01-23 22:42:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/4e16f84629a6378bd8211ba8786cf417d5dc72fd', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n- Runs Tempest\n\nThe minimal suite excludes running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. However they are included\nin all other suites for test-kitchen except for the default (allinone)\nsuite.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 11, 'created': '2020-01-23 23:33:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/ae280b8dbf1f752171ccf03368c06d5c3612a692', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n- Runs Tempest\n\nThe minimal suite excludes running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. However they are included\nin all other suites for test-kitchen except for the default (allinone)\nsuite.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 12, 'created': '2020-01-24 00:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/6da6d2363b4bd7c6e5d161a49ffd85c6450acd39', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n- Runs Tempest\n\nThe minimal suite excludes running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. However they are included\nin all other suites for test-kitchen except for the default (allinone)\nsuite.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 13, 'created': '2020-01-24 01:28:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/1d76077a0362ef3b0df2b4a073ef40f432138ff7', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n- Runs Tempest\n\nThe minimal suite excludes running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. However they are included\nin all other suites for test-kitchen except for the default (allinone)\nsuite.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 14, 'created': '2020-01-24 20:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/b160280f7eee41958f995bbece974cffcea908cc', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n\nThe all suites exclude running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. It's recommended to run\ntempest manually when using test-kitchen.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 15, 'created': '2020-01-27 19:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/18c2a0b07f401aedc42ee9291db1cc3525ae16eb', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n\nThe all suites exclude running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. It's recommended to run\ntempest manually when using test-kitchen.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 16, 'created': '2020-01-27 20:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/aec783e6b863737405a0f20d38034256150053c7', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n\nThe all suites exclude running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. It's recommended to run\ntempest manually when using test-kitchen.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 17, 'created': '2020-01-27 20:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/dfff3a7784b106e2dd7618d47205beded5da517f', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n\nThe all suites exclude running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. It's recommended to run\ntempest manually when using test-kitchen.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 18, 'created': '2020-01-27 21:18:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/6836d14b06404c0b9fb4ae5350131135a455f761', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n\nThe all suites exclude running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. It's recommended to run\ntempest manually when using test-kitchen.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 19, 'created': '2020-01-27 21:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/ba4c72e63153eb3e8073c52ba29ad4d603e19107', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n\nThe all suites exclude running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. It's recommended to run\ntempest manually when using test-kitchen.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 20, 'created': '2020-01-28 01:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/2e22d6128fb6e713b8349c48480b632b837e81fa', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n\nThe all suites exclude running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. It's recommended to run\ntempest manually when using test-kitchen.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 21, 'created': '2020-01-28 01:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/c5bc165f69bc6e56e8e4a84ef6224609c07a3b41', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n\nThe all suites exclude running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. It's recommended to run\ntempest manually when using test-kitchen.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 22, 'created': '2020-01-28 19:11:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/23feda9a8ee59ff8cf34acea25dcf4e6f9884923', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n\nThe all suites exclude running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. It's recommended to run\ntempest manually when using test-kitchen.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 23, 'created': '2020-01-30 01:12:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/f6426b3b4b7f737a6b674e6f8a15c9aa712924d6', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\nI've also added minimal non-voting jobs for both platforms so we can\ncatch any issue we might have missed downstream.\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n\nThe all suites exclude running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. It's recommended to run\ntempest manually when using test-kitchen.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 24, 'created': '2020-01-30 01:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/c02f63b23269c11fb25e8d52f9d8211ce70afdda', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\nI've also added minimal non-voting jobs for both platforms so we can\ncatch any issue we might have missed downstream.\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n\nThe all suites exclude running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. It's recommended to run\ntempest manually when using test-kitchen.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 25, 'created': '2020-01-30 01:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/73038cd6b3cf1d36296cf5b0e231deaa65f162fe', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\nI've also added minimal non-voting jobs for both platforms so we can\ncatch any issue we might have missed downstream.\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n\nThe all suites exclude running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. It's recommended to run\ntempest manually when using test-kitchen.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 26, 'created': '2020-01-30 06:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/9ed75250eef848a3e2afff8334f999ab3594536f', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\nI've also added minimal non-voting jobs for both platforms so we can\ncatch any issue we might have missed downstream.\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n\nThe all suites exclude running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. It's recommended to run\ntempest manually when using test-kitchen.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n- Use OSUOSL for EPEL mirror to work around public mirror issues\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 27, 'created': '2020-01-30 16:07:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/0d05f8ecf64f6d46b4838e814813f4038c462bc0', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\nI've also added minimal non-voting jobs for both platforms so we can\ncatch any issue we might have missed downstream.\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n\nThe all suites exclude running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. It's recommended to run\ntempest manually when using test-kitchen.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n- Use OSUOSL for EPEL mirror to work around public mirror issues\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}, {'number': 28, 'created': '2020-01-30 18:10:50.000000000', 'files': ['test/integration/minimal/inspec/image_spec.rb', 'test/integration/network/inspec/identity_spec.rb', 'test/integration/orchestration/inspec/identity_spec.rb', 'data_bags/service_passwords/openstack-telemetry_metric.json', 'test/integration/block-storage/inspec/block_storage_spec.rb', 'playbooks/minimal.yaml', 'test/integration/minimal/inspec/common_spec.rb', 'Berksfile', 'roles/bare_metal_test.json', 'roles/compute_test.json', 'roles/ops_messaging.json', 'test/integration/bare-metal/inspec/bare_metal_spec.rb', 'test/integration/bare-metal/inspec/ops_database_spec.rb', 'test/integration/image/inspec/image_spec.rb', 'environments/integration.json', 'roles/integration_test.json', '.kitchen.yml', 'test/integration/dashboard/inspec/identity_spec.rb', 'roles/minimal_test.json', 'test/integration/dashboard/inspec/ops_messaging_spec.rb', 'test/integration/orchestration/inspec/ops_database_spec.rb', 'test/integration/identity/inspec/ops_database_spec.rb', 'data_bags/service_passwords/openstack-aodh.json', 'test/integration/image/inspec/ops_messaging_spec.rb', 'roles/network.json', 'roles/identity.json', 'roles/telemetry.json', 'roles/image.json', 'roles/common.json', 'roles/image_test.json', 'test/integration/compute/inspec/identity_spec.rb', 'roles/dns_test.json', 'playbooks/integration.yaml', 'roles/orchestration_test.json', 'test/integration/helpers/tempest_spec.rb', 'Rakefile', '.zuul.yaml', 'roles/ops_messaging_test.json', 'test/integration/network/inspec/network_spec.rb', 'test/integration/openstackclient/inspec/ops_messaging_spec.rb', 'test/integration/dashboard/inspec/dashboard_spec.rb', 'test/integration/dns/inspec/dns_spec.rb', 'test/integration/bare-metal/inspec/identity_spec.rb', 'test/integration/telemetry/inspec/ops_messaging_spec.rb', 'data_bags/secrets/designate_rndc.json', 'test/integration/bare-metal/inspec/ops_messaging_spec.rb', 'test/integration/compute/inspec/ops_messaging_spec.rb', 'roles/bare_metal.json', 'test/integration/minimal/inspec/block_storage_spec.rb', 'roles/openstackclient_test.json', 'test/integration/telemetry/inspec/telemetry_spec.rb', 'README.rst', 'test/integration/block-storage/inspec/ops_database_spec.rb', 'roles/orchestration.json', 'test/integration/block-storage/inspec/ops_messaging_spec.rb', 'test/integration/identity/inspec/identity_spec.rb', 'test/integration/common/inspec/common_spec.rb', 'test/integration/openstackclient/inspec/ops_database_spec.rb', 'roles/telemetry_test.json', 'roles/compute.json', 'test/integration/compute/inspec/network_spec.rb', 'test/integration/minimal/inspec/ops_messaging_spec.rb', 'test/integration/block-storage/inspec/identity_spec.rb', 'test/integration/identity/inspec/ops_messaging_spec.rb', 'test/integration/orchestration/inspec/orchestration_spec.rb', 'test/integration/ops-database/inspec/ops_database_spec.rb', 'roles/dashboard_test.json', 'test/integration/openstackclient/inspec/identity_spec.rb', 'roles/network_test.json', 'test/integration/image/inspec/ops_database_spec.rb', 'test/integration/compute/inspec/compute_spec.rb', 'test/integration/orchestration/inspec/ops_messaging_spec.rb', 'roles/dns.json', 'roles/minimal.json', 'test/integration/dns/inspec/ops_database_spec.rb', 'test/integration/minimal/inspec/compute_spec.rb', 'test/integration/minimal/inspec/network_spec.rb', 'roles/ops_database_test.json', 'roles/ops_database.json', 'data_bags/db_passwords/aodh.json', 'roles/openstackclient.json', 'test/integration/compute/inspec/ops_database_spec.rb', 'test/integration/image/inspec/identity_spec.rb', 'test/integration/dns/inspec/identity_spec.rb', 'test/integration/dns/inspec/ops_messaging_spec.rb', 'roles/block_storage.json', 'roles/block_storage_test.json', 'test/integration/minimal/inspec/ops_database_spec.rb', 'test/integration/telemetry/inspec/identity_spec.rb', 'roles/common_test.json', 'roles/dashboard.json', 'test/integration/ops-messaging/inspec/ops_messaging_spec.rb', 'roles/identity_test.json', 'test/integration/dashboard/inspec/ops_database_spec.rb', 'test/integration/telemetry/inspec/ops_database_spec.rb', 'test/integration/minimal/inspec/identity_spec.rb', 'test/integration/network/inspec/ops_database_spec.rb', 'roles/allinone.json', 'test/integration/network/inspec/ops_messaging_spec.rb'], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/cbc1b9bcf4f4eac569fb8cb9d38f9493094b9479', 'message': ""Refactor integration tests\n\nThis changes the logic so that we use the Berksfile in the cookbook\nwe're doing changes in instead of what's included in openstack-chef.\nThis should allow us to properly deal with cookbook dependencies in a\nsaner fashion with Gerrit without getting into depends-on hell.\n\nThis also required refactoring the Rakefile and roles used in Gerrit and\ntest-kitchen. Each cookbook now has their own role and test role which\nincludes specific Tempest configuration settings. This will require\nupdates in most cookbooks' Berksfile to include missing cookbook\ndependencies such as ops-database, ops-messaging and integration-test.\n\nOther major changes includes migrating to using InSpec for integration\ntesting instead of relying on simple commands included in the Rakefile.\nI have replaced most of what was included in _run_basic_queries as\nInSpec tests which also improves our coverage overall. Currently the\nInSpec coverage is fairly basic and should probably include additional\ntests, but in general it covers the following:\n\nI've also added minimal non-voting jobs for both platforms so we can\ncatch any issue we might have missed downstream.\n\n- Services are enabled and running\n- Basic commands return sane output\n- Openstack users, services and endpoints are correct\n\nThe all suites exclude running Tempest due to the fact that InSpec\ndoesn't have the ability to change the command timeout beyond 600\nseconds [1] which is an issue I've run into. It's recommended to run\ntempest manually when using test-kitchen.\n\nNOTE: I haven't made any updates to the multi-node test-kitchen\nenvironment in this patch and will plan on doing that later. I don't\nbelieve this will break anything there.\n\nOther various minor changes include:\n\n- Replaced bare-metal cookbook with block-storage in minimal role\n- Print out the command that run_command is going to run to help with\n  debugging.\n- Use different public_ip so that it doesn't interfere with people using\n  10.0.0.0/24 locally (like me!).\n- Add forwarded port to access Horizon\n- Switch to using Chef 15 with test-kitchen\n- Include log files from additional services that we were missing\n- Add missing databag for aodh and telemetry_metric\n- Include a real rndc key in the databag to assist with testing\n- Use OSUOSL for EPEL mirror to work around public mirror issues\n\n[1] https://github.com/inspec/inspec/issues/1675\n\nDepends-On: https://review.opendev.org/703882\n\nChange-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e\n""}]",1,702772,cbc1b9bcf4f4eac569fb8cb9d38f9493094b9479,53,3,28,21961,,,0,"Refactor integration tests

This changes the logic so that we use the Berksfile in the cookbook
we're doing changes in instead of what's included in openstack-chef.
This should allow us to properly deal with cookbook dependencies in a
saner fashion with Gerrit without getting into depends-on hell.

This also required refactoring the Rakefile and roles used in Gerrit and
test-kitchen. Each cookbook now has their own role and test role which
includes specific Tempest configuration settings. This will require
updates in most cookbooks' Berksfile to include missing cookbook
dependencies such as ops-database, ops-messaging and integration-test.

Other major changes includes migrating to using InSpec for integration
testing instead of relying on simple commands included in the Rakefile.
I have replaced most of what was included in _run_basic_queries as
InSpec tests which also improves our coverage overall. Currently the
InSpec coverage is fairly basic and should probably include additional
tests, but in general it covers the following:

I've also added minimal non-voting jobs for both platforms so we can
catch any issue we might have missed downstream.

- Services are enabled and running
- Basic commands return sane output
- Openstack users, services and endpoints are correct

The all suites exclude running Tempest due to the fact that InSpec
doesn't have the ability to change the command timeout beyond 600
seconds [1] which is an issue I've run into. It's recommended to run
tempest manually when using test-kitchen.

NOTE: I haven't made any updates to the multi-node test-kitchen
environment in this patch and will plan on doing that later. I don't
believe this will break anything there.

Other various minor changes include:

- Replaced bare-metal cookbook with block-storage in minimal role
- Print out the command that run_command is going to run to help with
  debugging.
- Use different public_ip so that it doesn't interfere with people using
  10.0.0.0/24 locally (like me!).
- Add forwarded port to access Horizon
- Switch to using Chef 15 with test-kitchen
- Include log files from additional services that we were missing
- Add missing databag for aodh and telemetry_metric
- Include a real rndc key in the databag to assist with testing
- Use OSUOSL for EPEL mirror to work around public mirror issues

[1] https://github.com/inspec/inspec/issues/1675

Depends-On: https://review.opendev.org/703882

Change-Id: Idebc87ebb6acad7d0af222fb9025fefcb9bf5a1e
",git fetch https://review.opendev.org/openstack/openstack-chef refs/changes/72/702772/5 && git format-patch -1 --stdout FETCH_HEAD,"['Rakefile', 'playbooks/integration.yaml']",2,d41d7700bbdc9a3bc673dc6124345cdd390dc9d0,berksvendor-by-cookbook, PROJECT_DIR: '{{ zuul.project.src_dir }}',,5,1
openstack%2Ftripleo-heat-templates~stable%2Frocky~I20d35affba9da511ed4a9566013868146d3fbf4c,openstack/tripleo-heat-templates,stable/rocky,I20d35affba9da511ed4a9566013868146d3fbf4c,Add SSHD composable service to Networker role definition,MERGED,2020-01-29 22:05:19.000000000,2020-01-30 23:48:41.000000000,2020-01-30 23:48:41.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27092}]","[{'number': 1, 'created': '2020-01-29 22:05:19.000000000', 'files': ['roles/Networker.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0b474e1733eaf118aa88caea42a4a68406cdb81a', 'message': 'Add SSHD composable service to Networker role definition\n\nThe composable service OS::TripleO::Services::Sshd is\nenabled by default in the overcloud but it is not included\nin the default Networker.yaml role definition.\n\nCloses-Bug: #1861343\nChange-Id: I20d35affba9da511ed4a9566013868146d3fbf4c\n(cherry picked from commit 37ea3303700eba9e8d73f45c2e0999c5d39e1132)\n'}]",0,704893,0b474e1733eaf118aa88caea42a4a68406cdb81a,7,4,1,14985,,,0,"Add SSHD composable service to Networker role definition

The composable service OS::TripleO::Services::Sshd is
enabled by default in the overcloud but it is not included
in the default Networker.yaml role definition.

Closes-Bug: #1861343
Change-Id: I20d35affba9da511ed4a9566013868146d3fbf4c
(cherry picked from commit 37ea3303700eba9e8d73f45c2e0999c5d39e1132)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/93/704893/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/Networker.yaml'],1,0b474e1733eaf118aa88caea42a4a68406cdb81a,bug/1861343, - OS::TripleO::Services::Sshd,,1,0
openstack%2Fwhitebox-tempest-plugin~master~If2fc9c808ca4310ff1e62f156797a44a18246b10,openstack/whitebox-tempest-plugin,master,If2fc9c808ca4310ff1e62f156797a44a18246b10,Add SSH tunneling gateway port parameter,MERGED,2020-01-27 19:22:57.000000000,2020-01-30 23:13:09.000000000,2020-01-30 23:13:09.000000000,"[{'_account_id': 8864}, {'_account_id': 22348}, {'_account_id': 27478}, {'_account_id': 31033}]","[{'number': 1, 'created': '2020-01-27 19:22:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/529c6e1606a7c4c13f9d7aae7e572c8fbb41dc5b', 'message': ""Add SSH tunneling gateway port parameter\n\nAdding SSH gateway port number (defaults to 3306 for devstack job)\nto enable tripleo, RHOS jobs in addition to devstack. With existing\ncode, the jobs for tripleo/RHOS fail as they don't listen on 3306 on\nboth ends\n\nChange-Id: If2fc9c808ca4310ff1e62f156797a44a18246b10\n""}, {'number': 2, 'created': '2020-01-30 18:03:17.000000000', 'files': ['whitebox_tempest_plugin/services/clients.py', 'whitebox_tempest_plugin/config.py'], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/d6bc80732696985013973210e5ae7e3fcd0e0f04', 'message': ""Add SSH tunneling gateway port parameter\n\nAdding SSH gateway port number (defaults to 3306 for devstack job)\nto enable tripleo, RHOS jobs in addition to devstack. With existing\ncode, the jobs for tripleo/RHOS fail as they don't listen on 3306 on\nboth ends\n\nChange-Id: If2fc9c808ca4310ff1e62f156797a44a18246b10\n""}]",2,704399,d6bc80732696985013973210e5ae7e3fcd0e0f04,19,4,2,27478,,,0,"Add SSH tunneling gateway port parameter

Adding SSH gateway port number (defaults to 3306 for devstack job)
to enable tripleo, RHOS jobs in addition to devstack. With existing
code, the jobs for tripleo/RHOS fail as they don't listen on 3306 on
both ends

Change-Id: If2fc9c808ca4310ff1e62f156797a44a18246b10
",git fetch https://review.opendev.org/openstack/whitebox-tempest-plugin refs/changes/99/704399/1 && git format-patch -1 --stdout FETCH_HEAD,"['whitebox_tempest_plugin/services/clients.py', 'whitebox_tempest_plugin/config.py']",2,529c6e1606a7c4c13f9d7aae7e572c8fbb41dc5b,ssh-port," help=""Name of the Nova db to use for connection""), cfg.IntOpt( 'ssh_gateway_port', default=3306, help=""SSH port forwarding gateway number"")"," help=""Name of the Nova db to use for connection"")",7,2
openstack%2Fcookbook-openstack-integration-test~master~I0eb2247f163132ef343bbcf6f4cc80326b9704d9,openstack/cookbook-openstack-integration-test,master,I0eb2247f163132ef343bbcf6f4cc80326b9704d9,Adjustments for per-cookbook testing,MERGED,2020-01-22 22:14:54.000000000,2020-01-30 23:12:14.000000000,2020-01-30 23:12:14.000000000,"[{'_account_id': 13252}, {'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-22 22:14:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-integration-test/commit/6e5976940ed1be80ca81a9c1312501e430502ad9', 'message': ""Adjustments for per-cookbook testing\n\nThis provides some updates so that this cookbook can be run for\nindividual cookbooks depending on whether or not various services are\nenabled or not. This is useful if you're wanting to test just keystone,\nand don't need glance or nova just to do that.\n\nSome other changes:\n\n- Update catalog_type for volume to 'volumev3' which matches what we\n  provide (We may want to change this back to 'volume' at some point).\n- Create orchestration recipe to assist with testing heat.\n- Remove unused cookbook dependencies for block-storage and identity.\n  This should get pulled in automatically with how we setup the test\n  environment in openstack-chef.\n\nChange-Id: I0eb2247f163132ef343bbcf6f4cc80326b9704d9\n""}, {'number': 2, 'created': '2020-01-23 17:48:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-integration-test/commit/4cbfabd2a81d762f47a3ad3c324a15ad509ceac1', 'message': ""Adjustments for per-cookbook testing\n\nThis provides some updates so that this cookbook can be run for\nindividual cookbooks depending on whether or not various services are\nenabled or not. This is useful if you're wanting to test just keystone,\nand don't need glance or nova just to do that.\n\nSome other changes:\n\n- Update catalog_type for volume to 'volumev3' which matches what we\n  provide (We may want to change this back to 'volume' at some point).\n- Create orchestration recipe to assist with testing heat.\n- Remove unused cookbook dependencies for block-storage and identity.\n  This should get pulled in automatically with how we setup the test\n  environment in openstack-chef.\n- Blacklist\n  tempest.api.compute.servers.test_create_server.ServersTestBootFromVolume\n  test from running due to an issue with our cinder environment.\n\nChange-Id: I0eb2247f163132ef343bbcf6f4cc80326b9704d9\n""}, {'number': 3, 'created': '2020-01-23 19:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-integration-test/commit/e306a8fbe2bb3aeb6af66e9863d4f66d45e70444', 'message': ""Adjustments for per-cookbook testing\n\nThis provides some updates so that this cookbook can be run for\nindividual cookbooks depending on whether or not various services are\nenabled or not. This is useful if you're wanting to test just keystone,\nand don't need glance or nova just to do that.\n\nSome other changes:\n\n- Update catalog_type for volume to 'volumev3' which matches what we\n  provide (We may want to change this back to 'volume' at some point).\n- Create orchestration recipe to assist with testing heat.\n- Remove unused cookbook dependencies for block-storage and identity.\n  This should get pulled in automatically with how we setup the test\n  environment in openstack-chef.\n- Blacklist\n  tempest.api.compute.servers.test_create_server.ServersTestBootFromVolume\n  test from running due to an issue with our cinder environment.\n\nChange-Id: I0eb2247f163132ef343bbcf6f4cc80326b9704d9\n""}, {'number': 4, 'created': '2020-01-23 21:32:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-integration-test/commit/4560e0666b52ba5284a879a148e08cfd816ce3a2', 'message': ""Adjustments for per-cookbook testing\n\nThis provides some updates so that this cookbook can be run for\nindividual cookbooks depending on whether or not various services are\nenabled or not. This is useful if you're wanting to test just keystone,\nand don't need glance or nova just to do that.\n\nSome other changes:\n\n- Update catalog_type for volume to 'volumev3' which matches what we\n  provide (We may want to change this back to 'volume' at some point).\n- Create orchestration recipe to assist with testing heat.\n- Remove unused cookbook dependencies for compute, block-storage and\n  identity. These should get pulled in automatically with how we setup\n  the test environment in openstack-chef.\n- Blacklist\n  tempest.api.compute.servers.test_create_server.ServersTestBootFromVolume\n  test from running due to an issue with our cinder environment.\n\nChange-Id: I0eb2247f163132ef343bbcf6f4cc80326b9704d9\n""}, {'number': 5, 'created': '2020-01-27 18:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-integration-test/commit/0262ac795f60d778790d82ead069620b39d39a80', 'message': ""Adjustments for per-cookbook testing\n\nThis provides some updates so that this cookbook can be run for\nindividual cookbooks depending on whether or not various services are\nenabled or not. This is useful if you're wanting to test just keystone,\nand don't need glance or nova just to do that.\n\nSome other changes:\n\n- Update catalog_type for volume to 'volumev3' which matches what we\n  provide (We may want to change this back to 'volume' at some point).\n- Create orchestration recipe to assist with testing heat.\n- Create dns recipe to assist with testing designate.\n- Remove unused cookbook dependencies for compute, block-storage and\n  identity. These should get pulled in automatically with how we setup\n  the test environment in openstack-chef.\n- Blacklist\n  tempest.api.compute.servers.test_create_server.ServersTestBootFromVolume\n  test from running due to an issue with our cinder environment.\n\nChange-Id: I0eb2247f163132ef343bbcf6f4cc80326b9704d9\n""}, {'number': 6, 'created': '2020-01-28 02:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-integration-test/commit/d9d7b11b08495f2d22b23ce7e56e670c1e0286b8', 'message': ""Adjustments for per-cookbook testing\n\nThis provides some updates so that this cookbook can be run for\nindividual cookbooks depending on whether or not various services are\nenabled or not. This is useful if you're wanting to test just keystone,\nand don't need glance or nova just to do that.\n\nSome other changes:\n\n- Update catalog_type for volume to 'volumev3' which matches what we\n  provide (We may want to change this back to 'volume' at some point).\n- Create orchestration recipe to assist with testing heat.\n- Create dns recipe to assist with testing designate.\n- Remove unused cookbook dependencies for compute, block-storage and\n  identity. These should get pulled in automatically with how we setup\n  the test environment in openstack-chef.\n- Blacklist\n  tempest.api.compute.servers.test_create_server.ServersTestBootFromVolume\n  test from running due to an issue with our cinder environment.\n\nChange-Id: I0eb2247f163132ef343bbcf6f4cc80326b9704d9\n""}, {'number': 7, 'created': '2020-01-28 19:09:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-integration-test/commit/ecd76ee5fd909929bcb0d0908a2da1b7527de064', 'message': ""Adjustments for per-cookbook testing\n\nThis provides some updates so that this cookbook can be run for\nindividual cookbooks depending on whether or not various services are\nenabled or not. This is useful if you're wanting to test just keystone,\nand don't need glance or nova just to do that.\n\nSome other changes:\n\n- Update catalog_type for volume to 'volumev3' which matches what we\n  provide (We may want to change this back to 'volume' at some point).\n- Create orchestration recipe to assist with testing heat.\n- Create dns recipe to assist with testing designate.\n- Remove unused cookbook dependencies for compute, block-storage and\n  identity. These should get pulled in automatically with how we setup\n  the test environment in openstack-chef.\n- Blacklist\n  tempest.api.compute.servers.test_create_server.ServersTestBootFromVolume\n  test from running due to an issue with our cinder environment.\n\nChange-Id: I0eb2247f163132ef343bbcf6f4cc80326b9704d9\n""}, {'number': 8, 'created': '2020-01-30 00:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-integration-test/commit/f0e4e1f3ccdf1e90b576a24408c4c874639ea775', 'message': ""Adjustments for per-cookbook testing\n\nThis provides some updates so that this cookbook can be run for\nindividual cookbooks depending on whether or not various services are\nenabled or not. This is useful if you're wanting to test just keystone,\nand don't need glance or nova just to do that.\n\nSome other changes:\n\n- Update catalog_type for volume to 'volumev3' which matches what we\n  provide (We may want to change this back to 'volume' at some point).\n- Create orchestration recipe to assist with testing heat.\n- Create dns recipe to assist with testing designate.\n- Remove unused cookbook dependencies for compute, block-storage and\n  identity. These should get pulled in automatically with how we setup\n  the test environment in openstack-chef.\n- Blacklist\n  tempest.api.compute.servers.test_create_server.ServersTestBootFromVolume\n  test from running due to an issue with our cinder environment.\n\nChange-Id: I0eb2247f163132ef343bbcf6f4cc80326b9704d9\n""}, {'number': 9, 'created': '2020-01-30 01:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-integration-test/commit/8a36ac65922fa18370f0e8d3d9c3d7705d35cdd6', 'message': ""Adjustments for per-cookbook testing\n\nThis provides some updates so that this cookbook can be run for\nindividual cookbooks depending on whether or not various services are\nenabled or not. This is useful if you're wanting to test just keystone,\nand don't need glance or nova just to do that.\n\nSome other changes:\n\n- Update catalog_type for volume to 'volumev3' which matches what we\n  provide (We may want to change this back to 'volume' at some point).\n- Create orchestration recipe to assist with testing heat.\n- Create dns recipe to assist with testing designate.\n- Remove unused cookbook dependencies for compute, block-storage and\n  identity. These should get pulled in automatically with how we setup\n  the test environment in openstack-chef.\n- Blacklist\n  tempest.api.compute.servers.test_create_server.ServersTestBootFromVolume\n  test from running due to an issue with our cinder environment.\n\nChange-Id: I0eb2247f163132ef343bbcf6f4cc80326b9704d9\n""}, {'number': 10, 'created': '2020-01-30 05:59:47.000000000', 'files': ['templates/default/tempest-blacklist.erb', 'README.rst', 'spec/setup_spec.rb', 'spec/dns-rhel_spec.rb', 'Berksfile', 'spec/dns_spec.rb', 'attributes/tempest_conf.rb', 'templates/default/tempest.sh.erb', 'recipes/dns.rb', 'spec/spec_helper.rb', 'recipes/setup.rb', 'attributes/default.rb', 'templates/default/named.designate.erb', 'recipes/orchestration.rb', 'spec/orchestration_spec.rb', 'metadata.rb', 'files/default/heat.yml'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-integration-test/commit/3b3e8721fea0dc7a6fb581099f14246fd2d7a253', 'message': ""Adjustments for per-cookbook testing\n\nThis provides some updates so that this cookbook can be run for\nindividual cookbooks depending on whether or not various services are\nenabled or not. This is useful if you're wanting to test just keystone,\nand don't need glance or nova just to do that.\n\nSome other changes:\n\n- Update catalog_type for volume to 'volumev3' which matches what we\n  provide (We may want to change this back to 'volume' at some point).\n- Create orchestration recipe to assist with testing heat.\n- Create dns recipe to assist with testing designate.\n- Remove unused cookbook dependencies for compute, block-storage and\n  identity. These should get pulled in automatically with how we setup\n  the test environment in openstack-chef.\n- Blacklist\n  tempest.api.compute.servers.test_create_server.ServersTestBootFromVolume\n  test from running due to an issue with our cinder environment.\n\nChange-Id: I0eb2247f163132ef343bbcf6f4cc80326b9704d9\n""}]",6,703882,3b3e8721fea0dc7a6fb581099f14246fd2d7a253,28,3,10,21961,,,0,"Adjustments for per-cookbook testing

This provides some updates so that this cookbook can be run for
individual cookbooks depending on whether or not various services are
enabled or not. This is useful if you're wanting to test just keystone,
and don't need glance or nova just to do that.

Some other changes:

- Update catalog_type for volume to 'volumev3' which matches what we
  provide (We may want to change this back to 'volume' at some point).
- Create orchestration recipe to assist with testing heat.
- Create dns recipe to assist with testing designate.
- Remove unused cookbook dependencies for compute, block-storage and
  identity. These should get pulled in automatically with how we setup
  the test environment in openstack-chef.
- Blacklist
  tempest.api.compute.servers.test_create_server.ServersTestBootFromVolume
  test from running due to an issue with our cinder environment.

Change-Id: I0eb2247f163132ef343bbcf6f4cc80326b9704d9
",git fetch https://review.opendev.org/openstack/cookbook-openstack-integration-test refs/changes/82/703882/9 && git format-patch -1 --stdout FETCH_HEAD,"['attributes/tempest_conf.rb', 'README.rst', 'recipes/setup.rb', 'spec/setup_spec.rb', 'recipes/orchestration.rb', 'spec/orchestration_spec.rb', 'metadata.rb', 'files/default/heat.yml']",8,6e5976940ed1be80ca81a9c1312501e430502ad9,refactor-testing,heat_template_version: rocky description: Simple template to deploy a single compute instance resources: private_net: type: OS::Neutron::Net properties: name: private private_subnet: type: OS::Neutron::Subnet properties: name: private-subnet network_id: { get_resource: private_net } cidr: 10.0.99.0/24 allocation_pools: - start: 10.0.99.10 end: 10.0.99.100 my_instance: type: OS::Nova::Server properties: key_name: heat_key image: cirros flavor: m1.small networks: - network: { get_resource: private_net } ,,117,6
openstack%2Fswift~master~I90682de945f48707a1a30d52ee5b2e5fb848d87c,openstack/swift,master,I90682de945f48707a1a30d52ee5b2e5fb848d87c,"Use six.moves.urllib.parse.{,un}quote",ABANDONED,2018-12-01 20:53:01.000000000,2020-01-30 22:55:37.000000000,,"[{'_account_id': 597}, {'_account_id': 8122}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-01 20:53:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ebbe6a544e80d3fb4388c67f0f685ba96a72bb1c', 'message': 'Use six.moves.urllib.parse.{,un}quote\n\nChange-Id: I90682de945f48707a1a30d52ee5b2e5fb848d87c\n'}, {'number': 2, 'created': '2018-12-01 22:10:44.000000000', 'files': ['swift/common/middleware/s3api/controllers/s3_acl.py', 'test/unit/common/middleware/s3api/test_s3api.py', 'test/functional/s3api/test_object.py', 'test/unit/common/middleware/s3api/test_multi_upload.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/80fc7147f42fa6e5318f68eb00a89c2f2379b510', 'message': 'Use six.moves.urllib.parse.{,un}quote\n\nChange-Id: I90682de945f48707a1a30d52ee5b2e5fb848d87c\n'}]",0,621376,80fc7147f42fa6e5318f68eb00a89c2f2379b510,7,3,2,8122,,,0,"Use six.moves.urllib.parse.{,un}quote

Change-Id: I90682de945f48707a1a30d52ee5b2e5fb848d87c
",git fetch https://review.opendev.org/openstack/swift refs/changes/76/621376/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/s3api/controllers/s3_acl.py', 'test/unit/common/middleware/s3api/test_s3api.py', 'test/functional/s3api/test_object.py', 'test/unit/common/middleware/s3api/test_multi_upload.py']",4,ebbe6a544e80d3fb4388c67f0f685ba96a72bb1c,py3-urllib,from six.moves.urllib.parse import quote,from urllib import quote,4,4
openstack%2Ftripleo-operator-ansible~master~I79be50ce14648efdc2b1cbba56cba5c98cc2fc3a,openstack/tripleo-operator-ansible,master,I79be50ce14648efdc2b1cbba56cba5c98cc2fc3a,Add overcloud status role,MERGED,2020-01-21 22:09:06.000000000,2020-01-30 22:55:29.000000000,2020-01-30 22:55:29.000000000,"[{'_account_id': 3153}, {'_account_id': 10969}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-21 22:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/2fbfd345f2394b70bd482cc72751ba25693f42b4', 'message': 'Add overcloud status role\n\nAdds tripleo_overcloud_status role that can be used to collect the\novercloud deployment status.\n\nChange-Id: I79be50ce14648efdc2b1cbba56cba5c98cc2fc3a\n'}, {'number': 2, 'created': '2020-01-21 22:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/4dc7005d889929b1d965c55d9331b02d2d8bb50f', 'message': 'Add overcloud status role\n\nAdds tripleo_overcloud_status role that can be used to collect the\novercloud deployment status.\n\nChange-Id: I79be50ce14648efdc2b1cbba56cba5c98cc2fc3a\n'}, {'number': 3, 'created': '2020-01-29 15:51:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/52b642100e983bdd5d5e46a7ab9f59d0c03af856', 'message': 'Add overcloud status role\n\nAdds tripleo_overcloud_status role that can be used to collect the\novercloud deployment status.\n\nChange-Id: I79be50ce14648efdc2b1cbba56cba5c98cc2fc3a\n'}, {'number': 4, 'created': '2020-01-29 16:17:13.000000000', 'files': ['roles/tripleo_overcloud_status/tasks/main.yml', 'roles/tripleo_overcloud_status/meta/main.yml', 'roles/tripleo_overcloud_status/defaults/main.yml', 'roles/tripleo_overcloud_status/README.md', 'roles/tripleo_overcloud_status/tests/test.yml', 'roles/tripleo_overcloud_status/tests/inventory'], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/b379c6672913a728e372201bf76f4c8ec89c9d59', 'message': 'Add overcloud status role\n\nAdds tripleo_overcloud_status role that can be used to collect the\novercloud deployment status.\n\nChange-Id: I79be50ce14648efdc2b1cbba56cba5c98cc2fc3a\n'}]",0,703700,b379c6672913a728e372201bf76f4c8ec89c9d59,14,3,4,14985,,,0,"Add overcloud status role

Adds tripleo_overcloud_status role that can be used to collect the
overcloud deployment status.

Change-Id: I79be50ce14648efdc2b1cbba56cba5c98cc2fc3a
",git fetch https://review.opendev.org/openstack/tripleo-operator-ansible refs/changes/00/703700/4 && git format-patch -1 --stdout FETCH_HEAD,"['roles/tripleo_overcloud_status/tasks/main.yml', 'roles/tripleo_overcloud_status/meta/main.yml', 'roles/tripleo_overcloud_status/defaults/main.yml', 'roles/tripleo_overcloud_status/README.md', 'roles/tripleo_overcloud_status/tests/test.yml', 'roles/tripleo_overcloud_status/tests/inventory']",6,2fbfd345f2394b70bd482cc72751ba25693f42b4,tripleo-overcloud-status,localhost ,,126,0
openstack%2Fproject-config~master~Ic16cc7d5e82a59b4e70829a9dade0035fe81a85e,openstack/project-config,master,Ic16cc7d5e82a59b4e70829a9dade0035fe81a85e,Move governance-uc jobs in-tree,MERGED,2020-01-29 08:52:28.000000000,2020-01-30 22:44:41.000000000,2020-01-30 22:44:41.000000000,"[{'_account_id': 5263}, {'_account_id': 7118}, {'_account_id': 8181}, {'_account_id': 15993}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 08:52:28.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3a775533c58adf43f5599a6307ed5b8df210247d', 'message': ""Move governance-uc jobs in-tree\n\nLet's have all jobs together in-tree.\n\nDepends-On: https://review.opendev.org/704746\nChange-Id: Ic16cc7d5e82a59b4e70829a9dade0035fe81a85e\n""}]",0,704747,3a775533c58adf43f5599a6307ed5b8df210247d,10,5,1,6547,,,0,"Move governance-uc jobs in-tree

Let's have all jobs together in-tree.

Depends-On: https://review.opendev.org/704746
Change-Id: Ic16cc7d5e82a59b4e70829a9dade0035fe81a85e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/47/704747/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,3a775533c58adf43f5599a6307ed5b8df210247d,static-services,, name: openstack/governance-uc promote: jobs: - promote-governance-uc - project:,0,6
openstack%2Foctavia~master~I81f76afc7e3fa6f190c30f33198197cb627cce26,openstack/octavia,master,I81f76afc7e3fa6f190c30f33198197cb627cce26,Fix unit test when run on CentOS 7,MERGED,2019-12-09 09:05:34.000000000,2020-01-30 22:37:54.000000000,2020-01-30 22:35:59.000000000,"[{'_account_id': 1131}, {'_account_id': 6469}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 29244}]","[{'number': 1, 'created': '2019-12-09 09:05:34.000000000', 'files': ['octavia/tests/unit/amphorae/backends/agent/api_server/test_osutils.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/f5eeb513b50295bbd9d03b64f031bdeda57927a8', 'message': ""Fix unit test when run on CentOS 7\n\nFix unit test test_cmd_get_version_of_installed_package_mapped when run\non a CentOS 7 system.\n\n   testtools.matchers._impl.MismatchError: !=:\n   reference = 'rpm -q --queryformat %{VERSION} haproxy'\n   actual    = 'rpm -q --queryformat %{VERSION} haproxy18'\n\nChange-Id: I81f76afc7e3fa6f190c30f33198197cb627cce26\n""}]",1,697958,f5eeb513b50295bbd9d03b64f031bdeda57927a8,11,6,1,6469,,,0,"Fix unit test when run on CentOS 7

Fix unit test test_cmd_get_version_of_installed_package_mapped when run
on a CentOS 7 system.

   testtools.matchers._impl.MismatchError: !=:
   reference = 'rpm -q --queryformat %{VERSION} haproxy'
   actual    = 'rpm -q --queryformat %{VERSION} haproxy18'

Change-Id: I81f76afc7e3fa6f190c30f33198197cb627cce26
",git fetch https://review.opendev.org/openstack/octavia refs/changes/58/697958/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia/tests/unit/amphorae/backends/agent/api_server/test_osutils.py'],1,f5eeb513b50295bbd9d03b64f031bdeda57927a8,," with mock.patch('distro.version', return_value='8'): self.centos_os_util = osutils.BaseOS.get_os_util()", self.centos_os_util = osutils.BaseOS.get_os_util(),2,1
openstack%2Fgovernance-uc~master~I1ea8efe0ca7042a32f697ddf9c1fc1ac1f7fa163,openstack/governance-uc,master,I1ea8efe0ca7042a32f697ddf9c1fc1ac1f7fa163,Import publishing job,MERGED,2020-01-29 08:51:10.000000000,2020-01-30 22:12:33.000000000,2020-01-30 22:10:10.000000000,"[{'_account_id': 2033}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 8181}, {'_account_id': 15993}, {'_account_id': 22348}, {'_account_id': 24100}, {'_account_id': 30855}]","[{'number': 1, 'created': '2020-01-29 08:51:10.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/governance-uc/commit/24c934d82ffd45e218047b26b548108af3fa1990', 'message': ""Import publishing job\n\nLet's have all jobs together in this repo, so import the promote job to\npublish the content.\n\nChange-Id: I1ea8efe0ca7042a32f697ddf9c1fc1ac1f7fa163\n""}]",0,704746,24c934d82ffd45e218047b26b548108af3fa1990,13,9,1,6547,,,0,"Import publishing job

Let's have all jobs together in this repo, so import the promote job to
publish the content.

Change-Id: I1ea8efe0ca7042a32f697ddf9c1fc1ac1f7fa163
",git fetch https://review.opendev.org/openstack/governance-uc refs/changes/46/704746/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,24c934d82ffd45e218047b26b548108af3fa1990,static-services, promote: jobs: - promote-governance-uc,,3,0
openstack%2Fdevstack~stable%2Fpike~I076a2ce374b8b0c5965c7bd6886821c3159cbc62,openstack/devstack,stable/pike,I076a2ce374b8b0c5965c7bd6886821c3159cbc62,Replace gerrit style Tempest ref to tag for TEMPEST_BRANCH,ABANDONED,2020-01-30 19:36:17.000000000,2020-01-30 21:37:54.000000000,,"[{'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-30 19:36:17.000000000', 'files': ['stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a8de496d7cf0566b13274446e0238ee05036fe88', 'message': 'Replace gerrit style Tempest ref to tag for TEMPEST_BRANCH\n\nWe used the gerrit style ref of Tempest to pin the Tempest\nfor stable branch. With Ic777e4b56c4932dde135ac909cb5c6f4a7d5cc78\nwe can direcrtly use the tag name.\n\nChange-Id: I076a2ce374b8b0c5965c7bd6886821c3159cbc62\n'}]",0,705099,a8de496d7cf0566b13274446e0238ee05036fe88,4,2,1,8556,,,0,"Replace gerrit style Tempest ref to tag for TEMPEST_BRANCH

We used the gerrit style ref of Tempest to pin the Tempest
for stable branch. With Ic777e4b56c4932dde135ac909cb5c6f4a7d5cc78
we can direcrtly use the tag name.

Change-Id: I076a2ce374b8b0c5965c7bd6886821c3159cbc62
",git fetch https://review.opendev.org/openstack/devstack refs/changes/99/705099/1 && git format-patch -1 --stdout FETCH_HEAD,['stackrc'],1,a8de496d7cf0566b13274446e0238ee05036fe88,tempest-tag1,TEMPEST_REPO=${TEMPEST_REPO:-${GIT_BASE}/openstack/tempest.git} # Use Tempest tag 21.0.0 which is Pike supported version.TEMPEST_BRANCH=${TEMPEST_BRANCH:-21.0.0},TEMPEST_REPO=${TEMPEST_REPO:-https://review.opendev.org/openstack/tempest} # Use Tempest commit (for tag 21.0.0) which is Pike supported version.# https://github.com/openstack/tempest/commit/abd07b42ca01319c2e289dc60e0449069e2889df TEMPEST_BRANCH=${TEMPEST_BRANCH:-refs/changes/99/670699/4},3,4
openstack%2Fcharm-neutron-openvswitch~master~I4848a3246d3450540acb8d2f479dfa2e7767be60,openstack/charm-neutron-openvswitch,master,I4848a3246d3450540acb8d2f479dfa2e7767be60,Make ovs_use_veth a config option,MERGED,2020-01-07 23:24:34.000000000,2020-01-30 21:35:47.000000000,2020-01-30 21:35:47.000000000,"[{'_account_id': 935}, {'_account_id': 11805}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-07 23:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/4b8ff67485959354777b022a00849a49e01429c5', 'message': 'Make ovs_use_veth a config option\n\nThis was originally fixed in commit 7578326 but this caused problems. It\nwas subsequently reverted in commit 6d2e9ee.\n\nThis change is a compromise making the option configurable.\n\nChange-Id: I4848a3246d3450540acb8d2f479dfa2e7767be60\nCloses-Bug: #1831935\n'}, {'number': 2, 'created': '2020-01-08 01:00:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/ed758092e1bc83cb9164581c4afba6434ddf2e0c', 'message': 'Make ovs_use_veth a config option\n\nThis was originally fixed in commit 7578326 but this caused problems. It\nwas subsequently reverted in commit 6d2e9ee.\n\nThis change is a compromise making the option configurable.\n\nChange-Id: I4848a3246d3450540acb8d2f479dfa2e7767be60\nCloses-Bug: #1831935\n'}, {'number': 3, 'created': '2020-01-08 15:51:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/8cb54e8a70dc11b6ffcc202b4bc363697f0ca1b0', 'message': 'Make ovs_use_veth a config option\n\nThis was originally fixed in commit 7578326 but this caused problems. It\nwas subsequently reverted in commit 6d2e9ee.\n\nThis change is a compromise making the option configurable.\n\nChange-Id: I4848a3246d3450540acb8d2f479dfa2e7767be60\nCloses-Bug: #1831935\n'}, {'number': 4, 'created': '2020-01-15 00:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/7b66e6e2416f889569486c070626f26d4421ae28', 'message': 'Make ovs_use_veth a config option\n\nThis was originally fixed in commit 7578326 but this caused problems. It\nwas subsequently reverted in commit 6d2e9ee.\n\nThis change is a compromise making the option configurable and throwing\nan exception if there is conflicting configuration.\n\nChange-Id: I4848a3246d3450540acb8d2f479dfa2e7767be60\nCloses-Bug: #1831935\n'}, {'number': 5, 'created': '2020-01-25 00:36:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/1d2a6d8e24244612185cd1121df7eccb7ad374aa', 'message': 'Make ovs_use_veth a config option\n\nThis was originally fixed in commit 7578326 but this caused problems. It\nwas subsequently reverted in commit 6d2e9ee.\n\nThis change uses a common DHCPAgentContext and takes care to check for a\npre-existing setting in the dhcp_agent.ini. Only allowing a config\nchange if there is no pre-existing setting.\n\nPartial-Bug: #1831935\n\nChange-Id: I4848a3246d3450540acb8d2f479dfa2e7767be60\n'}, {'number': 6, 'created': '2020-01-25 00:38:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/61882b58434b792c1a102f7bd92bdd1f9f053e7f', 'message': 'Make ovs_use_veth a config option\n\nThis was originally fixed in commit 7578326 but this caused problems. It\nwas subsequently reverted in commit 6d2e9ee.\n\nThis change uses a common DHCPAgentContext and takes care to check for a\npre-existing setting in the dhcp_agent.ini. Only allowing a config\nchange if there is no pre-existing setting.\n\nPlease review and merge charm-helpers PR:\nhttps://github.com/juju/charm-helpers/pull/422\n\nPartial-Bug: #1831935\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/157\nChange-Id: I4848a3246d3450540acb8d2f479dfa2e7767be60\n'}, {'number': 7, 'created': '2020-01-25 03:18:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/0804d1fc866121cad673a41300a214475b7aa1c6', 'message': 'Make ovs_use_veth a config option\n\nThis was originally fixed in commit 7578326 but this caused problems. It\nwas subsequently reverted in commit 6d2e9ee.\n\nThis change uses a common DHCPAgentContext and takes care to check for a\npre-existing setting in the dhcp_agent.ini. Only allowing a config\nchange if there is no pre-existing setting.\n\nPlease review and merge charm-helpers PR:\nhttps://github.com/juju/charm-helpers/pull/422\n\nPartial-Bug: #1831935\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/157\nChange-Id: I4848a3246d3450540acb8d2f479dfa2e7767be60\n'}, {'number': 8, 'created': '2020-01-29 23:50:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/33fba86178f1e62a3e2ec5c2ffd66bbfc4f76f49', 'message': 'Make ovs_use_veth a config option\n\nThis was originally fixed in commit 7578326 but this caused problems. It\nwas subsequently reverted in commit 6d2e9ee.\n\nThis change uses a common DHCPAgentContext and takes care to check for a\npre-existing setting in the dhcp_agent.ini. Only allowing a config\nchange if there is no pre-existing setting.\n\nPlease review and merge charm-helpers PR:\nhttps://github.com/juju/charm-helpers/pull/422\n\nPartial-Bug: #1831935\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/157\nChange-Id: I4848a3246d3450540acb8d2f479dfa2e7767be60\n'}, {'number': 9, 'created': '2020-01-30 00:39:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/98523bb7c6bee8e0d1e44ea987d37af0bee83269', 'message': 'Make ovs_use_veth a config option\n\nThis was originally fixed in commit 7578326 but this caused problems. It\nwas subsequently reverted in commit 6d2e9ee.\n\nThis change uses a common DHCPAgentContext and takes care to check for a\npre-existing setting in the dhcp_agent.ini. Only allowing a config\nchange if there is no pre-existing setting.\n\nPlease review and merge charm-helpers PR:\nhttps://github.com/juju/charm-helpers/pull/422\n\nPartial-Bug: #1831935\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/157\nChange-Id: I4848a3246d3450540acb8d2f479dfa2e7767be60\n'}, {'number': 10, 'created': '2020-01-30 15:51:03.000000000', 'files': ['templates/icehouse/dhcp_agent.ini', 'unit_tests/test_neutron_ovs_utils.py', 'templates/mitaka/dhcp_agent.ini', 'tests/tests.yaml', 'unit_tests/test_neutron_ovs_context.py', 'templates/ocata/dhcp_agent.ini', 'hooks/neutron_ovs_utils.py', 'hooks/neutron_ovs_context.py', 'tests/bundles/disco_stein.yaml', 'config.yaml', 'hooks/charmhelpers/contrib/openstack/context.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/4075af6a1154246c9653549763e470bb74e7500f', 'message': 'Make ovs_use_veth a config option\n\nThis was originally fixed in commit 7578326 but this caused problems. It\nwas subsequently reverted in commit 6d2e9ee.\n\nThis change uses a common DHCPAgentContext and takes care to check for a\npre-existing setting in the dhcp_agent.ini. Only allowing a config\nchange if there is no pre-existing setting.\n\nPlease review and merge charm-helpers PR:\nhttps://github.com/juju/charm-helpers/pull/422\n\nPartial-Bug: #1831935\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/157\nChange-Id: I4848a3246d3450540acb8d2f479dfa2e7767be60\n'}]",2,701476,4075af6a1154246c9653549763e470bb74e7500f,42,7,10,20805,,,0,"Make ovs_use_veth a config option

This was originally fixed in commit 7578326 but this caused problems. It
was subsequently reverted in commit 6d2e9ee.

This change uses a common DHCPAgentContext and takes care to check for a
pre-existing setting in the dhcp_agent.ini. Only allowing a config
change if there is no pre-existing setting.

Please review and merge charm-helpers PR:
https://github.com/juju/charm-helpers/pull/422

Partial-Bug: #1831935

func-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/157
Change-Id: I4848a3246d3450540acb8d2f479dfa2e7767be60
",git fetch https://review.opendev.org/openstack/charm-neutron-openvswitch refs/changes/76/701476/6 && git format-patch -1 --stdout FETCH_HEAD,"['templates/mitaka/dhcp_agent.ini', 'templates/ocata/dhcp_agent.ini', 'config.yaml']",3,4b8ff67485959354777b022a00849a49e01429c5,bug/1831935, ovs-use-veth: type: boolean default: True description: | This option has the dhcp agent use a veth OVS interface. Support kernels with limited namespace support. i.e. Trusty.,,8,2
openstack%2Fdevstack~stable%2Fqueens~I4d841ab143bb7b100aca432539a9400c8cd60347,openstack/devstack,stable/queens,I4d841ab143bb7b100aca432539a9400c8cd60347,Replace gerrit style Tempest ref to tag for TEMPEST_BRANCH,ABANDONED,2020-01-30 19:25:23.000000000,2020-01-30 21:33:44.000000000,,"[{'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-30 19:25:23.000000000', 'files': ['stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/5445f21c0b9819d1764ddda8145c3c6bc8dc0a31', 'message': 'Replace gerrit style Tempest ref to tag for TEMPEST_BRANCH\n\nWe used the gerrit style ref of Tempest to pin the Tempest\nfor stable branch. With Ic777e4b56c4932dde135ac909cb5c6f4a7d5cc78\nwe can direcrtly use the tag name.\n\nChange-Id: I4d841ab143bb7b100aca432539a9400c8cd60347\n'}]",0,705096,5445f21c0b9819d1764ddda8145c3c6bc8dc0a31,4,2,1,8556,,,0,"Replace gerrit style Tempest ref to tag for TEMPEST_BRANCH

We used the gerrit style ref of Tempest to pin the Tempest
for stable branch. With Ic777e4b56c4932dde135ac909cb5c6f4a7d5cc78
we can direcrtly use the tag name.

Change-Id: I4d841ab143bb7b100aca432539a9400c8cd60347
",git fetch https://review.opendev.org/openstack/devstack refs/changes/96/705096/1 && git format-patch -1 --stdout FETCH_HEAD,['stackrc'],1,5445f21c0b9819d1764ddda8145c3c6bc8dc0a31,tempest-tag,TEMPEST_REPO=${TEMPEST_REPO:-${GIT_BASE}/openstack/tempest.git}TEMPEST_BRANCH=${TEMPEST_BRANCH:-21.0.0},TEMPEST_REPO=${TEMPEST_REPO:-https://review.opendev.org/openstack/tempest}# https://github.com/openstack/tempest/commit/abd07b42ca01319c2e289dc60e0449069e2889df TEMPEST_BRANCH=${TEMPEST_BRANCH:-refs/changes/99/670699/1},2,3
openstack%2Fdevstack~master~Icb52e66d9af5dba12d2599cec8e9407b3c5e13bd,openstack/devstack,master,Icb52e66d9af5dba12d2599cec8e9407b3c5e13bd,Fix pip uncap fallout for nova and barbican(Fix2),ABANDONED,2020-01-28 19:40:09.000000000,2020-01-30 21:23:36.000000000,,"[{'_account_id': 7160}, {'_account_id': 7973}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-28 19:40:09.000000000', 'files': ['tools/fixup_stuff.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/1c6a5974d072edf20ad5ef839cb04c9756a2d8ad', 'message': 'Fix pip uncap fallout for nova and barbican(Fix2)\n\nNeed to make PyYAML overridable on Ubuntu, we have\nremove old installation for not only bionic\nbut for xenial too. The review https://review.opendev.org/703735\nwas fixing it only for bionic distro.\n\nDepends-On: https://review.opendev.org/703735\nChange-Id: Icb52e66d9af5dba12d2599cec8e9407b3c5e13bd\n'}]",0,704670,1c6a5974d072edf20ad5ef839cb04c9756a2d8ad,4,4,1,10379,,,0,"Fix pip uncap fallout for nova and barbican(Fix2)

Need to make PyYAML overridable on Ubuntu, we have
remove old installation for not only bionic
but for xenial too. The review https://review.opendev.org/703735
was fixing it only for bionic distro.

Depends-On: https://review.opendev.org/703735
Change-Id: Icb52e66d9af5dba12d2599cec8e9407b3c5e13bd
",git fetch https://review.opendev.org/openstack/devstack refs/changes/70/704670/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/fixup_stuff.sh'],1,1c6a5974d072edf20ad5ef839cb04c9756a2d8ad,fix-nova2," # Since pip10, pip will refuse to uninstall files from packages # that were created with distutils (rather than more modern # setuptools). This is because it technically doesn't have a # manifest of what to remove. However, in most cases, simply # overwriting works. So this hacks around those packages that # have been dragged in by some other system dependency sudo rm -f /usr/lib/python3/dist-packages/PyYAML-*.egg-info "," # Since pip10, pip will refuse to uninstall files from packages # that were created with distutils (rather than more modern # setuptools). This is because it technically doesn't have a # manifest of what to remove. However, in most cases, simply # overwriting works. So this hacks around those packages that # have been dragged in by some other system dependency sudo rm -f /usr/lib/python3/dist-packages/PyYAML-*.egg-info",9,8
openstack%2Ftripleo-heat-templates~stable%2Ftrain~Id309e812f7dc8d66bd4912fce282ce72350fcbf8,openstack/tripleo-heat-templates,stable/train,Id309e812f7dc8d66bd4912fce282ce72350fcbf8,Fix keepalived logging on disk,MERGED,2020-01-30 03:05:23.000000000,2020-01-30 20:44:26.000000000,2020-01-30 20:44:26.000000000,"[{'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-30 03:05:23.000000000', 'files': ['deployment/keepalived/keepalived-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a5e278ea9ec1b272268c43758d203b01206ea0ab', 'message': ""Fix keepalived logging on disk\n\nThere are no logs under /var/log/containers/keepalived even though we\nexplicitly try to capture logs on file for the keepalived container:\n\n [root@undercloud-0 ~]# podman exec -it keepalived sh -c 'ps -ax'\n    PID TTY STAT TIME COMMAND\n      1 ? Ss 0:00 dumb-init --single-child -- /usr/local/bin/kolla_start\n      8 ? S 0:00 /usr/sbin/keepalived -nldD | tee -a /var/log/keepalived.log\n     12 ? S 2:18 /usr/sbin/keepalived -nldD | tee -a /var/log/keepalived.log\n\nThe reason this is broken is that 'tee' is not passed to a shell but\nends up being an ignored argument of keepalived. Notice how there is no\nshell process and also no tee process in the container above.\n\nTo fix that we need to pass the proper commands to a shell. This is done\nin a special way like we did for the haproxy container so that kolla\ndoes not mangle quotes and spaces.\n\nAfter this fix we correctly see that the container logs on disk:\n[root@undercloud-0 container-puppet]# ls -l /var/log/containers/keepalived/\n-rw-r--r--. 1 root root 17483 Jan 28 15:55 keepalived.log\n\nWhile we're at it we remove the usage of tee. It makes no sense to\nlog both on file and on stdout/stderr.\n\nCo-Authored-By: Damien Ciabrini <dciabrin@redhat.com>\n\nChange-Id: Id309e812f7dc8d66bd4912fce282ce72350fcbf8\nCloses-Bug: #1861169\n(cherry picked from commit 547a510f63e9e7aa2cd41e050c94fc7077fb86f4)\n""}]",0,704917,a5e278ea9ec1b272268c43758d203b01206ea0ab,13,3,1,3153,,,0,"Fix keepalived logging on disk

There are no logs under /var/log/containers/keepalived even though we
explicitly try to capture logs on file for the keepalived container:

 [root@undercloud-0 ~]# podman exec -it keepalived sh -c 'ps -ax'
    PID TTY STAT TIME COMMAND
      1 ? Ss 0:00 dumb-init --single-child -- /usr/local/bin/kolla_start
      8 ? S 0:00 /usr/sbin/keepalived -nldD | tee -a /var/log/keepalived.log
     12 ? S 2:18 /usr/sbin/keepalived -nldD | tee -a /var/log/keepalived.log

The reason this is broken is that 'tee' is not passed to a shell but
ends up being an ignored argument of keepalived. Notice how there is no
shell process and also no tee process in the container above.

To fix that we need to pass the proper commands to a shell. This is done
in a special way like we did for the haproxy container so that kolla
does not mangle quotes and spaces.

After this fix we correctly see that the container logs on disk:
[root@undercloud-0 container-puppet]# ls -l /var/log/containers/keepalived/
-rw-r--r--. 1 root root 17483 Jan 28 15:55 keepalived.log

While we're at it we remove the usage of tee. It makes no sense to
log both on file and on stdout/stderr.

Co-Authored-By: Damien Ciabrini <dciabrin@redhat.com>

Change-Id: Id309e812f7dc8d66bd4912fce282ce72350fcbf8
Closes-Bug: #1861169
(cherry picked from commit 547a510f63e9e7aa2cd41e050c94fc7077fb86f4)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/17/704917/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/keepalived/keepalived-container-puppet.yaml'],1,a5e278ea9ec1b272268c43758d203b01206ea0ab,fix_keepalived_log-stable/train," command: ""/bin/bash -c $* -- eval exec /usr/sbin/keepalived -nldD &>>/var/log/keepalived.log""", command: /usr/sbin/keepalived -nldD | tee -a /var/log/keepalived.log,1,1
openstack%2Fopenstack-helm-addons~master~Ied86a3d137d6cff206eecbff5c33b7c0d50f90fb,openstack/openstack-helm-addons,master,Ied86a3d137d6cff206eecbff5c33b7c0d50f90fb,Refactored ranger-agent-test pod,MERGED,2019-12-03 23:57:45.000000000,2020-01-30 20:42:15.000000000,2020-01-30 20:42:15.000000000,"[{'_account_id': 18524}, {'_account_id': 19391}, {'_account_id': 20466}, {'_account_id': 21111}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 24999}, {'_account_id': 29585}]","[{'number': 1, 'created': '2019-12-03 23:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/aa6698cc370d547a70a0f27265bf0c8d55f7218e', 'message': 'Added get token parameters for ranger-agent test pod\n\nChange-Id: Ied86a3d137d6cff206eecbff5c33b7c0d50f90fb\n'}, {'number': 2, 'created': '2019-12-04 20:24:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/2dccaab6701e67a1ad1db62cb899b966eeeb907c', 'message': 'Added get token for ranger-agent-test pod\n\nChange-Id: Ied86a3d137d6cff206eecbff5c33b7c0d50f90fb\n'}, {'number': 3, 'created': '2019-12-05 00:08:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/5a1cfe9e5782c46ca91c7ae748a22f724de85e5c', 'message': 'Added get token for ranger-agent-test pod\n\nChange-Id: Ied86a3d137d6cff206eecbff5c33b7c0d50f90fb\n'}, {'number': 4, 'created': '2019-12-05 02:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/67de163151f692df7ff92bdf9f944c7ab90d4bda', 'message': 'Added get token for ranger-agent-test pod\n\nChange-Id: Ied86a3d137d6cff206eecbff5c33b7c0d50f90fb\n'}, {'number': 5, 'created': '2019-12-20 00:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/becbabcb92a764b5b258a0b64a79a939a5852cac', 'message': 'Added get token for ranger-agent-test pod\n\nChange-Id: Ied86a3d137d6cff206eecbff5c33b7c0d50f90fb\n'}, {'number': 6, 'created': '2020-01-09 23:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/91ff5ca6d1134acc189096a734385567d77fc7fb', 'message': 'Added get token for ranger-agent-test pod\n\nChange-Id: Ied86a3d137d6cff206eecbff5c33b7c0d50f90fb\n'}, {'number': 7, 'created': '2020-01-14 00:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/ce675860ca7f6b9d1833324e53fb7fc003fdb140', 'message': 'Added get token for ranger-agent-test pod\n\nChange-Id: Ied86a3d137d6cff206eecbff5c33b7c0d50f90fb\n'}, {'number': 8, 'created': '2020-01-28 23:28:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/09fdca36a5d8eef06fc35b5b5b9fb5e796bce36f', 'message': 'Added get token for ranger-agent-test pod\n\nChange-Id: Ied86a3d137d6cff206eecbff5c33b7c0d50f90fb\n'}, {'number': 9, 'created': '2020-01-29 17:46:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/45edb53569d03c0ba71c271cbcd6c45e81273ce0', 'message': 'Refactored ranger-agent-test pod\n\nThis patch refactor ranger-agent-test pod to use python\nmodule. It also fixes incompatible issue with the old\nscript that failed pod test with updated ranger-agent pod.\n\nChange-Id: Ied86a3d137d6cff206eecbff5c33b7c0d50f90fb\n'}, {'number': 10, 'created': '2020-01-29 18:11:13.000000000', 'files': ['ranger-agent/templates/bin/_ranger-agent-test.py.tpl', 'ranger-agent/templates/pod-test.yaml', 'ranger-agent/templates/configmap-bin.yaml', 'ranger-agent/templates/bin/_ranger-agent-test.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/cb8c4a9f072cbdc2c78f3e06da7c1f7bacba09cb', 'message': 'Refactored ranger-agent-test pod\n\nThis patch refactor ranger-agent-test pod to use python\nmodule. It also fixes incompatible issue with the old\nscript that failed pod test with updated ranger-agent pod.\n\nChange-Id: Ied86a3d137d6cff206eecbff5c33b7c0d50f90fb\n'}]",10,697202,cb8c4a9f072cbdc2c78f3e06da7c1f7bacba09cb,34,8,10,19391,,,0,"Refactored ranger-agent-test pod

This patch refactor ranger-agent-test pod to use python
module. It also fixes incompatible issue with the old
script that failed pod test with updated ranger-agent pod.

Change-Id: Ied86a3d137d6cff206eecbff5c33b7c0d50f90fb
",git fetch https://review.opendev.org/openstack/openstack-helm-addons refs/changes/02/697202/8 && git format-patch -1 --stdout FETCH_HEAD,"['ranger-agent/templates/pod-test.yaml', 'ranger-agent/templates/bin/_ranger-agent-test.sh.tpl']",2,aa6698cc370d547a70a0f27265bf0c8d55f7218e,,"# Get Token auth_url=""${AUTH_URL}"" username=""${USERNAME}"" password=""${PASSWORD}"" project_name=""${PROJECT_NAME}"" user_domain_name=""${USER_DOMAIN_NAME}"" project_domain_name=""${PROJECT_DOMAIN_NAME}"" token_url=""http_proxy=\""\"" https_proxy=\""\"" curl -s -i -X POST ""${auth_url}""/auth/tokens -H \""Content-Type: application/json\"" -H \""User-Agent: python-keystoneclient\"" -d '{ \""auth\"": {\""identity\"": {\""methods\"": [\""password\""],\""password\"": {\""user\"": {\""name\"": \""""${username}""\"",\""domain\"": { \""id\"": \""""${user_domain_name}""\"" },\""password\"": \""""${password}""\""}}},\""scope\"": {\""project\"": {\""name\"": \""""${project_name}""\"",\""domain\"": { \""id\"": \""""${project_domain_name}""\"" }}}}}'"" TOKEN=$(eval ${token_url} | awk '/X-Subject-Token/ {print $2}') retry=5 until [ $n -gt $retry ] msg=""$(curl -i -X POST -d ""${PAYLOAD}"" $url --header ""X-AUTH-TOKEN:$TOKEN"")"" if [ $n -eq $retry ]; then let n=n+1"," until [ $n -ge 5 ] msg=""$(curl -i -X POST -d ""${PAYLOAD}"" $url --header ""Content-type:application/json"")"" if [ ""$n"" == ""5"" ]; then n=$[$n+1]",30,4
openstack%2Fswift~master~Idf6c492d554a3ac3d38bd9dfc9c89494cae82bb1,openstack/swift,master,Idf6c492d554a3ac3d38bd9dfc9c89494cae82bb1,Add py38 unit test job,MERGED,2019-10-18 22:15:22.000000000,2020-01-30 20:39:14.000000000,2020-01-30 20:32:51.000000000,"[{'_account_id': 1179}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-18 22:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bd938772f5737e13464414db0fcd12d8cb5c22fe', 'message': 'Add py38 unit test job\n\nDepends-On: https://review.opendev.org/#/c/688594/\nChange-Id: Idf6c492d554a3ac3d38bd9dfc9c89494cae82bb1\n'}, {'number': 2, 'created': '2019-11-12 19:37:00.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/swift/commit/da5b94914302128c20b8ae9e3a2752a02ff29e73', 'message': 'Add py38 unit test job\n\nDepends-On: https://review.opendev.org/#/c/688594/\nChange-Id: Idf6c492d554a3ac3d38bd9dfc9c89494cae82bb1\n'}]",0,689599,da5b94914302128c20b8ae9e3a2752a02ff29e73,14,3,2,15343,,,0,"Add py38 unit test job

Depends-On: https://review.opendev.org/#/c/688594/
Change-Id: Idf6c492d554a3ac3d38bd9dfc9c89494cae82bb1
",git fetch https://review.opendev.org/openstack/swift refs/changes/99/689599/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,bd938772f5737e13464414db0fcd12d8cb5c22fe,689599, name: swift-tox-py38 parent: swift-tox-base nodeset: ubuntu-bionic description: | Run unit-tests for swift under cPython version 3.8. Uses tox with the ``py38`` environment. It sets TMPDIR to an XFS mount point created via tools/test-setup.sh. vars: tox_envlist: py38 bindep_profile: test py38 python_version: 3.8 tox_environment: NOSE_COVER_HTML: 1 NOSE_COVER_HTML_DIR: '{toxinidir}/cover' post-run: tools/playbooks/common/cover-post.yaml - job: - swift-tox-py38: irrelevant-files: - ^(api-ref|doc|releasenotes)/.*$ - ^test/(functional|probe)/.*$ - swift-tox-py38,,24,0
openstack%2Fswift~master~Id91fdd19f226e9ec0d9c702d40d041c385c52b88,openstack/swift,master,Id91fdd19f226e9ec0d9c702d40d041c385c52b88,py38: cgi lost some names,MERGED,2019-10-15 01:35:15.000000000,2020-01-30 20:36:30.000000000,2020-01-30 20:32:49.000000000,"[{'_account_id': 1179}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 01:35:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9d06c4d44f33bfcceb4ea7732e6bd32794666219', 'message': 'py38: cgi lost some names\n\nChange-Id: Id91fdd19f226e9ec0d9c702d40d041c385c52b88\n'}, {'number': 2, 'created': '2020-01-22 19:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/102146f394dfe861553cd376d08841ae6eda1281', 'message': 'py38: cgi lost some names\n\nChange-Id: Id91fdd19f226e9ec0d9c702d40d041c385c52b88\n'}, {'number': 3, 'created': '2020-01-22 20:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0efeb2b9a53106877edfe1e28a00575a9626e73e', 'message': 'py38: cgi lost some names\n\nChange-Id: Id91fdd19f226e9ec0d9c702d40d041c385c52b88\n'}, {'number': 4, 'created': '2020-01-23 00:51:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8756717cf0fdffc006e218ddeb651e3a57169fbd', 'message': 'py38: cgi lost some names\n\nDrive-by: always use quote=True; it basically never hurts.\n\nChange-Id: Id91fdd19f226e9ec0d9c702d40d041c385c52b88\n'}, {'number': 5, 'created': '2020-01-29 20:12:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d12c381f9b0b4184e1144a7866db13664d9f0055', 'message': 'py38: cgi lost some names\n\nDrive-by: always use quote=True; it basically never hurts.\n\nChange-Id: Id91fdd19f226e9ec0d9c702d40d041c385c52b88\n'}, {'number': 6, 'created': '2020-01-29 20:57:03.000000000', 'files': ['swift/common/middleware/staticweb.py', 'test/unit/common/middleware/s3api/test_bucket.py', 'swift/common/middleware/x_profile/html_viewer.py', 'swift/common/request_helpers.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/e3ee6ce31aed8d24fefdd20900d20688a12bb55d', 'message': 'py38: cgi lost some names\n\nDrive-by: always use quote=True; it basically never hurts.\n\nChange-Id: Id91fdd19f226e9ec0d9c702d40d041c385c52b88\n'}]",2,688594,e3ee6ce31aed8d24fefdd20900d20688a12bb55d,19,3,6,15343,,,0,"py38: cgi lost some names

Drive-by: always use quote=True; it basically never hurts.

Change-Id: Id91fdd19f226e9ec0d9c702d40d041c385c52b88
",git fetch https://review.opendev.org/openstack/swift refs/changes/94/688594/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/staticweb.py', 'swift/__init__.py', 'test/unit/common/middleware/s3api/test_bucket.py', 'swift/common/middleware/x_profile/html_viewer.py']",4,9d06c4d44f33bfcceb4ea7732e6bd32794666219,688594,"from six.moves import html_escape l = html_escape(line, quote=None) nfls = html_escape(stats.func_std_string(func)) html.append(""Exception:"" + str(ex))","import cgi l = cgi.escape(line, quote=None) nfls = cgi.escape(stats.func_std_string(func)) html.append(""Exception:"" % str(ex))",30,21
openstack%2Fdevstack~master~Ic777e4b56c4932dde135ac909cb5c6f4a7d5cc78,openstack/devstack,master,Ic777e4b56c4932dde135ac909cb5c6f4a7d5cc78,Support TEMPEST_BRANCH with tag name,MERGED,2020-01-29 21:46:39.000000000,2020-01-30 20:34:25.000000000,2020-01-30 20:32:48.000000000,"[{'_account_id': 4146}, {'_account_id': 5196}, {'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-29 21:46:39.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/e1c0406d10380f6ad3620fa9e12df8499a1010ac', 'message': 'Support TEMPEST_BRANCH with tag name\n\nTEMPEST_BRANCH which is mostly set as master so\nthat Tempest master is run to test the env. With\nstable branch going to EM state and Tempest master\nmight not work due to incompatibility of code or\nrequirements. In that case we pin the Tempest so that\nolder Tempest can be used for their testing.\n\nTill now for ocata, pike and, queens we used the gerrit style\nref to pin the Tempest which is not preferred way. We should be\nable to use the tag name on TEMPEST_BRANCH.\n\nThis commit explicitly checkout the tag set in TEMPEST_BRANCH\nas git_clone does not checkout the tag directly until RECLONE\nis true or tempest dir does not exist.\n\nAfter this stable branch or job can set the tag directly with name.\nFor exmaple: TEMPEST_BRANCH=23.0.0.\n\nChange-Id: Ic777e4b56c4932dde135ac909cb5c6f4a7d5cc78\n'}]",0,704891,e1c0406d10380f6ad3620fa9e12df8499a1010ac,15,5,1,8556,,,0,"Support TEMPEST_BRANCH with tag name

TEMPEST_BRANCH which is mostly set as master so
that Tempest master is run to test the env. With
stable branch going to EM state and Tempest master
might not work due to incompatibility of code or
requirements. In that case we pin the Tempest so that
older Tempest can be used for their testing.

Till now for ocata, pike and, queens we used the gerrit style
ref to pin the Tempest which is not preferred way. We should be
able to use the tag name on TEMPEST_BRANCH.

This commit explicitly checkout the tag set in TEMPEST_BRANCH
as git_clone does not checkout the tag directly until RECLONE
is true or tempest dir does not exist.

After this stable branch or job can set the tag directly with name.
For exmaple: TEMPEST_BRANCH=23.0.0.

Change-Id: Ic777e4b56c4932dde135ac909cb5c6f4a7d5cc78
",git fetch https://review.opendev.org/openstack/devstack refs/changes/91/704891/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,e1c0406d10380f6ad3620fa9e12df8499a1010ac,, # NOTE(gmann): checkout the TEMPEST_BRANCH in case TEMPEST_BRANCH # is tag name not master. git_clone would not checkout tag because # TEMPEST_DIR already exist until RECLONE is true. git checkout $TEMPEST_BRANCH ,,5,0
openstack%2Fopenstack-helm~master~I9a117bcddf84d996f10c5cd7a5ee8895f7333012,openstack/openstack-helm,master,I9a117bcddf84d996f10c5cd7a5ee8895f7333012,WIP - Headless Services - Cinder,ABANDONED,2020-01-22 03:45:34.000000000,2020-01-30 20:22:51.000000000,,"[{'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-22 03:45:34.000000000', 'files': ['cinder/values.yaml', 'cinder/templates/service-api.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/c1c956336d27d40db7ee0ddc1ed56bc9a5886a8f', 'message': 'WIP - Headless Services - Cinder\n\nChange-Id: I9a117bcddf84d996f10c5cd7a5ee8895f7333012\n'}]",0,703721,c1c956336d27d40db7ee0ddc1ed56bc9a5886a8f,5,2,1,21420,,,0,"WIP - Headless Services - Cinder

Change-Id: I9a117bcddf84d996f10c5cd7a5ee8895f7333012
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/21/703721/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/values.yaml', 'cinder/templates/service-api.yaml']",2,c1c956336d27d40db7ee0ddc1ed56bc9a5886a8f,headless-serv, clusterIP: None,,3,0
openstack%2Fkolla~master~Iaf5b68ff6d944ae730ca0b1d5832172c106a6c08,openstack/kolla,master,Iaf5b68ff6d944ae730ca0b1d5832172c106a6c08,CentOS 8: Update packages in images,MERGED,2019-12-17 13:44:17.000000000,2020-01-30 20:15:03.000000000,2020-01-30 20:13:03.000000000,"[{'_account_id': 8175}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23181}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-12-17 13:44:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/29cfdffaac0b2e4d5eaa82a36bd05e84214d7f25', 'message': ""CentOS 8: Update packages in images\n\n* Some further changes for python2 vs python3 packages\n* Allow rabbitmq 3.7.*, since a newer erlang is available\n* Don't install scsi-target-utils on CentOS 8, it is no longer available\n\nChange-Id: Iaf5b68ff6d944ae730ca0b1d5832172c106a6c08\n""}, {'number': 2, 'created': '2019-12-21 14:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/d125951c9006b252ed64afba4ace64fe6e1212cc', 'message': ""CentOS 8: Update packages in images\n\n* Some further changes for python2 vs python3 packages\n* Allow rabbitmq 3.7.*, since a newer erlang is available\n* Don't install scsi-target-utils on CentOS 8, it is no longer available\n\nChange-Id: Iaf5b68ff6d944ae730ca0b1d5832172c106a6c08\n""}, {'number': 3, 'created': '2020-01-07 09:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/11ea6ec9c5cde2d608fb3ac8e343018b1198b6ba', 'message': ""CentOS 8: Update packages in images\n\n* Some further changes for python2 vs python3 packages\n* Allow rabbitmq 3.7.*, since a newer erlang is available\n* Don't install scsi-target-utils on CentOS 8, it is no longer available\n\nChange-Id: Iaf5b68ff6d944ae730ca0b1d5832172c106a6c08\n""}, {'number': 4, 'created': '2020-01-08 09:35:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/fe839c8cc6dd77fc9a215407bbf717ac1c38a08b', 'message': ""CentOS 8: Update packages in images\n\n* Some further changes for python2 vs python3 packages\n* Allow rabbitmq 3.7.*, since a newer erlang is available\n* Don't install scsi-target-utils on CentOS 8, it is no longer available\n\nChange-Id: Iaf5b68ff6d944ae730ca0b1d5832172c106a6c08\n""}, {'number': 5, 'created': '2020-01-09 15:00:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/a53cbe66a82f69aba1c0d75a19265e7d1c8133d7', 'message': ""CentOS 8: Update packages in images\n\n* Some further changes for python2 vs python3 packages\n* Allow rabbitmq 3.7.*, since a newer erlang is available\n* Don't install scsi-target-utils on CentOS 8, it is no longer available\n* Mark some more images buildable for CentOS 8\n\nChange-Id: Iaf5b68ff6d944ae730ca0b1d5832172c106a6c08\n""}, {'number': 6, 'created': '2020-01-09 16:55:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b809beb8ed70313b05ff104105d5c4417d65e4c9', 'message': ""CentOS 8: Update packages in images\n\n* Some further changes for python2 vs python3 packages\n* Allow rabbitmq 3.7.*, since a newer erlang is available\n* Don't install scsi-target-utils on CentOS 8, it is no longer available\n* Mark some more images buildable for CentOS 8\n\nChange-Id: Iaf5b68ff6d944ae730ca0b1d5832172c106a6c08\n""}, {'number': 7, 'created': '2020-01-09 18:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/e58f64e9857bbda91e75e3fb94a85110e23bdb8c', 'message': ""CentOS 8: Update packages in images\n\n* Some further changes for python2 vs python3 packages\n* Allow rabbitmq 3.7.*, since a newer erlang is available\n* Don't install scsi-target-utils on CentOS 8, it is no longer available\n* Mark some more images buildable for CentOS 8\n\nChange-Id: Iaf5b68ff6d944ae730ca0b1d5832172c106a6c08\n""}, {'number': 8, 'created': '2020-01-09 19:39:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/7680a6552fb4f5278aa2e11dac07ddb3f14c56b7', 'message': ""CentOS 8: Update packages in images\n\n* Some further changes for python2 vs python3 packages\n* Allow rabbitmq 3.7.*, since a newer erlang is available\n* Don't install scsi-target-utils on CentOS 8, it is no longer available\n* Mark some more images buildable for CentOS 8\n\nChange-Id: Iaf5b68ff6d944ae730ca0b1d5832172c106a6c08\nPartially-Implements: blueprint centos-rhel-8\nPartially-Implements: blueprint centos-rhel-python-3\n""}, {'number': 9, 'created': '2020-01-10 14:11:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/d1304acb318454ddf0410d3f41d2c4f2d00b2c3d', 'message': 'CentOS 8: Update packages in images\n\n* Some further changes for python2 vs python3 packages\n* Allow rabbitmq 3.7.*, since a newer erlang is available\n* Switch from qemu-img-ev to qemu-img on CentOS 8\n* bridge-utils no longer available on CentOS 8\n* libvirt-daemon-driver-lxc no longer available on CentOS 8\n* Mark some more images buildable for CentOS 8\n\nChange-Id: Iaf5b68ff6d944ae730ca0b1d5832172c106a6c08\nPartially-Implements: blueprint centos-rhel-8\nPartially-Implements: blueprint centos-rhel-python-3\n'}, {'number': 10, 'created': '2020-01-29 11:42:40.000000000', 'files': ['kolla/template/methods.py', 'docker/nova/nova-libvirt/Dockerfile.j2', 'docker/neutron/neutron-linuxbridge-agent/Dockerfile.j2', 'docker/rabbitmq/Dockerfile.j2', 'kolla/template/repos.yaml', 'tests/templates/template_overrides.j2', 'docker/kolla-toolbox/Dockerfile.j2', 'docker/glance/glance-api/Dockerfile.j2', 'kolla/image/build.py', 'docker/nova/nova-spicehtml5proxy/Dockerfile.j2', 'docker/cinder/cinder-volume/Dockerfile.j2', 'docker/keystone/keystone-base/Dockerfile.j2', 'docker/nova/nova-compute/Dockerfile.j2', 'docker/cinder/cinder-base/Dockerfile.j2', 'docker/neutron/neutron-base/Dockerfile.j2', 'docker/kuryr/kuryr-libnetwork/Dockerfile.j2', 'docker/ceilometer/ceilometer-compute/Dockerfile.j2', 'docker/ironic/ironic-conductor/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/4b4e26262b9e03190c639481fb60a8f4f92c532a', 'message': 'CentOS 8: Update packages in images\n\n* Some further changes for python2 vs python3 packages\n* Allow rabbitmq 3.7.*, since a newer erlang is available\n* Switch from qemu-img-ev to qemu-img on CentOS 8\n* bridge-utils no longer available on CentOS 8\n* libvirt-daemon-driver-lxc no longer available on CentOS 8\n* Mark some more images buildable for CentOS 8\n\nChange-Id: Iaf5b68ff6d944ae730ca0b1d5832172c106a6c08\nPartially-Implements: blueprint centos-rhel-8\nPartially-Implements: blueprint centos-rhel-python-3\n'}]",10,699414,4b4e26262b9e03190c639481fb60a8f4f92c532a,73,7,10,14826,,,0,"CentOS 8: Update packages in images

* Some further changes for python2 vs python3 packages
* Allow rabbitmq 3.7.*, since a newer erlang is available
* Switch from qemu-img-ev to qemu-img on CentOS 8
* bridge-utils no longer available on CentOS 8
* libvirt-daemon-driver-lxc no longer available on CentOS 8
* Mark some more images buildable for CentOS 8

Change-Id: Iaf5b68ff6d944ae730ca0b1d5832172c106a6c08
Partially-Implements: blueprint centos-rhel-8
Partially-Implements: blueprint centos-rhel-python-3
",git fetch https://review.opendev.org/openstack/kolla refs/changes/14/699414/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/nova/nova-spicehtml5proxy/Dockerfile.j2', 'docker/cinder/cinder-volume/Dockerfile.j2', 'docker/keystone/keystone-base/Dockerfile.j2', 'docker/neutron/neutron-base/Dockerfile.j2', 'docker/kuryr/kuryr-libnetwork/Dockerfile.j2', 'docker/neutron/neutron-linuxbridge-agent/Dockerfile.j2', 'docker/rabbitmq/Dockerfile.j2', 'docker/kolla-toolbox/Dockerfile.j2', 'docker/ceilometer/ceilometer-compute/Dockerfile.j2']",9,29cfdffaac0b2e4d5eaa82a36bd05e84214d7f25,bp/centos-rhel-8, {% if distro_python_version.startswith('3') %} {% set ceilometer_compute_packages = [ 'python3-libvirt' ] %} {% else %} {% set ceilometer_compute_packages = [ 'libvirt-python' ] %} {% endif %}, {% set ceilometer_compute_packages = [ 'libvirt-python' ] %},78,14
openstack%2Fneutron~stable%2Ftrain~If0adb7ca4e254f5b19375b471679bcc18e0c7790,openstack/neutron,stable/train,If0adb7ca4e254f5b19375b471679bcc18e0c7790,Remove one of iptables_hybrid jobs,MERGED,2020-01-29 13:08:59.000000000,2020-01-30 20:04:23.000000000,2020-01-30 20:00:23.000000000,"[{'_account_id': 1131}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 30491}, {'_account_id': 31245}]","[{'number': 1, 'created': '2020-01-29 13:08:59.000000000', 'files': ['.zuul.yaml', 'doc/source/contributor/testing/ci_scenario_jobs.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c36f1fc29283084d59e9c2d2cc609b44a21fd415', 'message': 'Remove one of iptables_hybrid jobs\n\nIn check queue there were 2 iptables_hybrid jobs. One was run on Ubuntu\nand one on Fedora.\nDuring the Shanghai PTG we agreed to remove one of those jobs and left\nonly one of them to be run in both check and gate queues.\n\nThis commit removes iptables_hybrid job based on Fedora image.\n\nFedora jobs also make less sense for stable branches\n\nChange-Id: If0adb7ca4e254f5b19375b471679bcc18e0c7790\n(cherry picked from commit a2fdf8aa72859be748918d56c819736b9ae048c2)\n'}]",0,704796,c36f1fc29283084d59e9c2d2cc609b44a21fd415,29,7,1,21798,,,0,"Remove one of iptables_hybrid jobs

In check queue there were 2 iptables_hybrid jobs. One was run on Ubuntu
and one on Fedora.
During the Shanghai PTG we agreed to remove one of those jobs and left
only one of them to be run in both check and gate queues.

This commit removes iptables_hybrid job based on Fedora image.

Fedora jobs also make less sense for stable branches

Change-Id: If0adb7ca4e254f5b19375b471679bcc18e0c7790
(cherry picked from commit a2fdf8aa72859be748918d56c819736b9ae048c2)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/96/704796/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'doc/source/contributor/testing/ci_scenario_jobs.rst']",2,c36f1fc29283084d59e9c2d2cc609b44a21fd415,remove-iptables-hybrid-job-stable/train,, |neutron-tempest-iptables_hybrid-fedora |tempest.api (without slow tests) | 3.6 | 1 | openvswitch | iptables_hybrid | legacy | False | False | True | No | | |tempest.scenario | | | | | | | | | | | |(only tests related to | | | | | | | | | | | |Neutron and Nova) | | | | | | | | | | +----------------------------------------------+----------------------------------+---------+-------+-------------+-----------------+----------+-------+--------+------------+-------------+,0,12
openstack%2Fneutron-tempest-plugin~master~I39ca6474068d2e169dff1b81d2a0c71a8361c01f,openstack/neutron-tempest-plugin,master,I39ca6474068d2e169dff1b81d2a0c71a8361c01f,Use different CIDRs for private and public subnets,MERGED,2020-01-29 10:12:23.000000000,2020-01-30 20:00:25.000000000,2020-01-30 20:00:25.000000000,"[{'_account_id': 1131}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 16688}, {'_account_id': 18894}, {'_account_id': 19118}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 29088}, {'_account_id': 31450}]","[{'number': 1, 'created': '2020-01-29 10:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/318fc9bde5c114ea96e79d5c69795f4a63f9278d', 'message': '[neutron-dvr-NetworkConnectivity]Change net ip pool in test_connectivity_dvr_and_no_dvr_routers_in_same_subnet\n\n Change ip pool to avoid conflict with external network pool\n\nChange-Id: I39ca6474068d2e169dff1b81d2a0c71a8361c01f\n'}, {'number': 2, 'created': '2020-01-29 16:36:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/3edb5eba3878aaf797ebda7042d1f9a27da147aa', 'message': 'Use different CIDRs for private and public subnets\n\nIn test ""test_connectivity_dvr_and_no_dvr_routers_in_same_subnet"", as\nreported in the bug, the public IP (floating IP) and the private IP\nare in the same CIDR. This breaks the isolation between networks.\n\nCo-Authored-By: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\n\nCloses-Bug: #1861282\n\nChange-Id: I39ca6474068d2e169dff1b81d2a0c71a8361c01f\n'}, {'number': 3, 'created': '2020-01-29 18:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/db6c88449db171098c4385cb57318ee16420527c', 'message': 'Use different CIDRs for private and public subnets\n\nIn test ""test_connectivity_dvr_and_no_dvr_routers_in_same_subnet"", as\nreported in the bug, the public IP (floating IP) and the private IP\nare in the same CIDR. This breaks the isolation between networks.\n\nCo-Authored-By: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\n\nCloses-Bug: #1861282\n\nChange-Id: I39ca6474068d2e169dff1b81d2a0c71a8361c01f\n'}, {'number': 4, 'created': '2020-01-30 11:08:19.000000000', 'files': ['neutron_tempest_plugin/common/ip.py', 'neutron_tempest_plugin/scenario/test_connectivity.py'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/3e1921b48ad485669b3ab42002d08eb49f34f468', 'message': 'Use different CIDRs for private and public subnets\n\nIn test ""test_connectivity_dvr_and_no_dvr_routers_in_same_subnet"", as\nreported in the bug, the public IP (floating IP) and the private IP\nare in the same CIDR. This breaks the isolation between networks.\n\nCo-Authored-By: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\n\nCloses-Bug: #1861282\n\nChange-Id: I39ca6474068d2e169dff1b81d2a0c71a8361c01f\n'}]",9,704768,3e1921b48ad485669b3ab42002d08eb49f34f468,26,10,4,29088,,,0,"Use different CIDRs for private and public subnets

In test ""test_connectivity_dvr_and_no_dvr_routers_in_same_subnet"", as
reported in the bug, the public IP (floating IP) and the private IP
are in the same CIDR. This breaks the isolation between networks.

Co-Authored-By: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>

Closes-Bug: #1861282

Change-Id: I39ca6474068d2e169dff1b81d2a0c71a8361c01f
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/68/704768/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron_tempest_plugin/scenario/test_connectivity.py'],1,318fc9bde5c114ea96e79d5c69795f4a63f9278d,bug/1861282," | 10.1.0.1 | | 10.1.0.x | | 10.1.0.0/24 | 10.1.0.1 - is subnet's gateway IP address, 10.1.0.x - is any other IP address taken from subnet's range Test ensures that both 10.1.0.1 and 10.1.0.x IP addresses are network, cidr=""10.1.0.0/24"", gateway=""10.1.0.1"") sshclient, '10.1.0.1', ping_count=10)"," | 10.0.0.1 | | 10.0.0.x | | 10.0.0.0/24 | 10.0.0.1 - is subnet's gateway IP address, 10.0.0.x - is any other IP address taken from subnet's range Test ensures that both 10.0.0.1 and 10.0.0.x IP addresses are network, cidr=""10.0.0.0/24"", gateway=""10.0.0.1"") sshclient, '10.0.0.1', ping_count=10)",7,7
openstack%2Fkolla~master~Ice120e8001fd9e8bb37ca4f2df26259cf798ee0e,openstack/kolla,master,Ice120e8001fd9e8bb37ca4f2df26259cf798ee0e,CentOS 8: disable repo_gpgcheck for grafana image,MERGED,2020-01-30 12:49:57.000000000,2020-01-30 19:43:19.000000000,2020-01-30 19:41:05.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23181}, {'_account_id': 24072}, {'_account_id': 30491}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-30 12:49:57.000000000', 'files': ['docker/base/grafana.repo'], 'web_link': 'https://opendev.org/openstack/kolla/commit/05e2c43d6627a705e7f96be1eb5225c88f1c8e13', 'message': ""CentOS 8: disable repo_gpgcheck for grafana image\n\nDNF does not seem to accept keys imported by rpm --import for signing a\nrepo (as opposed to packages). This causes it to prompt during package\ninstall, which does not work without a terminal in the build container.\n\nWe have gpgcheck=1 for the grafana repo, so packages are at least\nsigned. We don't have repo_gpgcheck elsewhere, so it seems reasonable to\ndisable it for grafana.\n\nChange-Id: Ice120e8001fd9e8bb37ca4f2df26259cf798ee0e\nPartially-Implements: blueprint centos-rhel-8\n""}]",0,704999,05e2c43d6627a705e7f96be1eb5225c88f1c8e13,16,7,1,14826,,,0,"CentOS 8: disable repo_gpgcheck for grafana image

DNF does not seem to accept keys imported by rpm --import for signing a
repo (as opposed to packages). This causes it to prompt during package
install, which does not work without a terminal in the build container.

We have gpgcheck=1 for the grafana repo, so packages are at least
signed. We don't have repo_gpgcheck elsewhere, so it seems reasonable to
disable it for grafana.

Change-Id: Ice120e8001fd9e8bb37ca4f2df26259cf798ee0e
Partially-Implements: blueprint centos-rhel-8
",git fetch https://review.opendev.org/openstack/kolla refs/changes/99/704999/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/base/grafana.repo'],1,05e2c43d6627a705e7f96be1eb5225c88f1c8e13,bp/centos-rhel-8,,repo_gpgcheck=1,0,1
openstack%2Fnova~stable%2Fstein~I14637d788205408dcf9a007d7727358c03033dcd,openstack/nova,stable/stein,I14637d788205408dcf9a007d7727358c03033dcd,Remove 'test_cold_migrate_with_physnet_fails' test,MERGED,2020-01-16 19:59:44.000000000,2020-01-30 19:25:19.000000000,2020-01-30 19:22:17.000000000,"[{'_account_id': 10135}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-01-16 19:59:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5dd76d59e2ffe681129e51c3a51dd42a26662cdc', 'message': 'Remove \'test_cold_migrate_with_physnet_fails\' test\n\nThis never actually worked. What we wanted to do was test a setup where\nwe had two hosts, one with the necessary configuration needed for a\nspecific request and one without, and attempt to cold migrate the\ninstance from the former to the latter resulting in a fail. However,\nbecause it\'s not possible to use different configuration for different\nhosts, we were attempting to ""break"" the configuration on one host.\nUnfortunately, the driver correctly detects this broken behavior,\nresulting in an error message like so:\n\n  ERROR [nova.compute.manager] Error updating resources for node test_compute1.\n  Traceback (most recent call last):\n    File ""nova/compute/manager.py"", line 8524, in _update_available_resource_for_node\n      startup=startup)\n    File ""nova/compute/resource_tracker.py"", line 867, in update_available_resource\n      resources = self.driver.get_available_resource(nodename)\n    File ""nova/virt/libvirt/driver.py"", line 7907, in get_available_resource\n      numa_topology = self._get_host_numa_topology()\n    File ""nova/virt/libvirt/driver.py"", line 7057, in _get_host_numa_topology\n      physnet_affinities = _get_physnet_numa_affinity()\n    File ""nova/virt/libvirt/driver.py"", line 7039, in _get_physnet_numa_affinity\n      raise exception.InvalidNetworkNUMAAffinity(reason=msg)\n  InvalidNetworkNUMAAffinity: Invalid NUMA network affinity configured: node 1 for\n  physnet foo is not present in host affinity set {0: set([])}\n\nThere isn\'t really an alternative. We can\'t configure compute nodes\nseparately so that\'s ruled out and the virt driver will correctly detect\nany other attempts to break the configuration. Since the test never\nactually worked, the correct thing to do seems to be to remove it.\n\nNOTE(stephenfin): This was backported to make the backport of change\nI0322d872bdff68936033a6f5a54e8296a6fb3434 cleaner, but it also applies\nhere.\n\nChange-Id: I14637d788205408dcf9a007d7727358c03033dcd\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n(cherry picked from commit a4ca0b531cb3eabdeee6aab925220067ebd81172)\n(cherry picked from commit 8b766d14cf979cd994d52db71267b93aacee42e8)\n'}, {'number': 2, 'created': '2020-01-22 15:06:25.000000000', 'files': ['nova/tests/functional/libvirt/test_numa_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d41afc72761a13d86a99968add1418c1e80a91ee', 'message': 'Remove \'test_cold_migrate_with_physnet_fails\' test\n\nThis never actually worked. What we wanted to do was test a setup where\nwe had two hosts, one with the necessary configuration needed for a\nspecific request and one without, and attempt to cold migrate the\ninstance from the former to the latter resulting in a fail. However,\nbecause it\'s not possible to use different configuration for different\nhosts, we were attempting to ""break"" the configuration on one host.\nUnfortunately, the driver correctly detects this broken behavior,\nresulting in an error message like so:\n\n  ERROR [nova.compute.manager] Error updating resources for node test_compute1.\n  Traceback (most recent call last):\n    File ""nova/compute/manager.py"", line 8524, in _update_available_resource_for_node\n      startup=startup)\n    File ""nova/compute/resource_tracker.py"", line 867, in update_available_resource\n      resources = self.driver.get_available_resource(nodename)\n    File ""nova/virt/libvirt/driver.py"", line 7907, in get_available_resource\n      numa_topology = self._get_host_numa_topology()\n    File ""nova/virt/libvirt/driver.py"", line 7057, in _get_host_numa_topology\n      physnet_affinities = _get_physnet_numa_affinity()\n    File ""nova/virt/libvirt/driver.py"", line 7039, in _get_physnet_numa_affinity\n      raise exception.InvalidNetworkNUMAAffinity(reason=msg)\n  InvalidNetworkNUMAAffinity: Invalid NUMA network affinity configured: node 1 for\n  physnet foo is not present in host affinity set {0: set([])}\n\nThere isn\'t really an alternative. We can\'t configure compute nodes\nseparately so that\'s ruled out and the virt driver will correctly detect\nany other attempts to break the configuration. Since the test never\nactually worked, the correct thing to do seems to be to remove it.\n\nNOTE(stephenfin): This was backported to make the backport of change\nI0322d872bdff68936033a6f5a54e8296a6fb3434 cleaner, but it also applies\nhere.\n\nConflicts:\n    nova/tests/functional/libvirt/test_numa_servers.py\n\nNOTE(sean-k-mooney): Ifcda7336d56c9b623720ee018ec5697740986273\nand I7bf4d0e14024e608cea6e20d25a2bcc9ab8af7aa are not present on stien\nand result in the conflict in test_numa_servers.py\n\nChange-Id: I14637d788205408dcf9a007d7727358c03033dcd\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n(cherry picked from commit a4ca0b531cb3eabdeee6aab925220067ebd81172)\n(cherry picked from commit 8b766d14cf979cd994d52db71267b93aacee42e8)\n'}]",1,702971,d41afc72761a13d86a99968add1418c1e80a91ee,32,7,2,11604,,,0,"Remove 'test_cold_migrate_with_physnet_fails' test

This never actually worked. What we wanted to do was test a setup where
we had two hosts, one with the necessary configuration needed for a
specific request and one without, and attempt to cold migrate the
instance from the former to the latter resulting in a fail. However,
because it's not possible to use different configuration for different
hosts, we were attempting to ""break"" the configuration on one host.
Unfortunately, the driver correctly detects this broken behavior,
resulting in an error message like so:

  ERROR [nova.compute.manager] Error updating resources for node test_compute1.
  Traceback (most recent call last):
    File ""nova/compute/manager.py"", line 8524, in _update_available_resource_for_node
      startup=startup)
    File ""nova/compute/resource_tracker.py"", line 867, in update_available_resource
      resources = self.driver.get_available_resource(nodename)
    File ""nova/virt/libvirt/driver.py"", line 7907, in get_available_resource
      numa_topology = self._get_host_numa_topology()
    File ""nova/virt/libvirt/driver.py"", line 7057, in _get_host_numa_topology
      physnet_affinities = _get_physnet_numa_affinity()
    File ""nova/virt/libvirt/driver.py"", line 7039, in _get_physnet_numa_affinity
      raise exception.InvalidNetworkNUMAAffinity(reason=msg)
  InvalidNetworkNUMAAffinity: Invalid NUMA network affinity configured: node 1 for
  physnet foo is not present in host affinity set {0: set([])}

There isn't really an alternative. We can't configure compute nodes
separately so that's ruled out and the virt driver will correctly detect
any other attempts to break the configuration. Since the test never
actually worked, the correct thing to do seems to be to remove it.

NOTE(stephenfin): This was backported to make the backport of change
I0322d872bdff68936033a6f5a54e8296a6fb3434 cleaner, but it also applies
here.

Conflicts:
    nova/tests/functional/libvirt/test_numa_servers.py

NOTE(sean-k-mooney): Ifcda7336d56c9b623720ee018ec5697740986273
and I7bf4d0e14024e608cea6e20d25a2bcc9ab8af7aa are not present on stien
and result in the conflict in test_numa_servers.py

Change-Id: I14637d788205408dcf9a007d7727358c03033dcd
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
(cherry picked from commit a4ca0b531cb3eabdeee6aab925220067ebd81172)
(cherry picked from commit 8b766d14cf979cd994d52db71267b93aacee42e8)
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/702971/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/libvirt/test_numa_servers.py'],1,5dd76d59e2ffe681129e51c3a51dd42a26662cdc,bug/1763766,," def test_cold_migrate_with_physnet_fails(self): host_infos = [ # host 1 has room on both nodes fakelibvirt.NUMAHostInfo(cpu_nodes=2, cpu_sockets=1, cpu_cores=2, cpu_threads=2, kB_mem=15740000), # host 2 has no second node, where the desired physnet is # reported to be attached fakelibvirt.NUMAHostInfo(cpu_nodes=1, cpu_sockets=1, cpu_cores=1, cpu_threads=1, kB_mem=15740000), ] # Start services self.computes = {} for host in ['test_compute0', 'test_compute1']: host_info = host_infos.pop(0) fake_connection = self._get_connection(host_info=host_info) fake_connection.getHostname = lambda: host # This is fun. Firstly we need to do a global'ish mock so we can # actually start the service. with mock.patch('nova.virt.libvirt.host.Host.get_connection', return_value=fake_connection): compute = self.start_service('compute', host=host) # Once that's done, we need to do some tweaks to each individual # compute ""service"" to make sure they return unique objects compute.driver._host.get_connection = lambda: fake_connection self.computes[host] = compute # Create server extra_spec = {'hw:numa_nodes': '1'} flavor_id = self._create_flavor(extra_spec=extra_spec) networks = [ {'uuid': base.LibvirtNeutronFixture.network_1['id']}, ] good_server = self._build_server(flavor_id) good_server['networks'] = networks post = {'server': good_server} created_server = self.api.post_server(post) server = self._wait_for_state_change(created_server, 'BUILD') self.assertEqual('ACTIVE', server['status']) # TODO(stephenfin): The mock of 'migrate_disk_and_power_off' should # probably be less...dumb with mock.patch('nova.virt.libvirt.driver.LibvirtDriver' '.migrate_disk_and_power_off', return_value='{}'): ex = self.assertRaises(client.OpenStackApiException, self.api.post_server_action, server['id'], {'migrate': None}) self.assertEqual(400, ex.response.status_code) self.assertIn('No valid host', six.text_type(ex))",0,58
openstack%2Fpuppet-neutron~master~I682e22d56d65ec160a09780f6780467b1c8718ba,openstack/puppet-neutron,master,I682e22d56d65ec160a09780f6780467b1c8718ba,Remove neutron::agents::metadata::metadata_ip,MERGED,2020-01-28 14:17:57.000000000,2020-01-30 19:21:46.000000000,2020-01-30 19:20:14.000000000,"[{'_account_id': 3153}, {'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-28 14:17:57.000000000', 'files': ['manifests/agents/metadata.pp', 'releasenotes/notes/remove-nova-metadata-ip-9948a0907e0ec8a6.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/e3c8f1423ba2f40b6f1e44cc082fddaebf17b439', 'message': 'Remove neutron::agents::metadata::metadata_ip\n\nDeprecated in favor of metadata_host.\n\nChange-Id: I682e22d56d65ec160a09780f6780467b1c8718ba\n'}]",0,704579,e3c8f1423ba2f40b6f1e44cc082fddaebf17b439,9,4,1,16137,,,0,"Remove neutron::agents::metadata::metadata_ip

Deprecated in favor of metadata_host.

Change-Id: I682e22d56d65ec160a09780f6780467b1c8718ba
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/79/704579/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/agents/metadata.pp', 'releasenotes/notes/remove-nova-metadata-ip-9948a0907e0ec8a6.yaml']",2,e3c8f1423ba2f40b6f1e44cc082fddaebf17b439,,--- upgrade: - | The deprecated parameter neutron::agents::metadata::metadata_ip is removed. Please use the neutron::agents::metadata::metadata_host parameter. ,,5,11
openstack%2Fnova~master~I30aae6128d30fdfeab7b5c73c12d70b86fe03fc3,openstack/nova,master,I30aae6128d30fdfeab7b5c73c12d70b86fe03fc3,"Revert ""Skip cpu comparison on AArch64""",ABANDONED,2020-01-21 12:17:58.000000000,2020-01-30 19:16:28.000000000,,"[{'_account_id': 4690}, {'_account_id': 6062}, {'_account_id': 6962}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 11604}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22076}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 23950}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-01-21 12:17:58.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b22d754b835f0d9de8521580d9be7209db59b20b', 'message': 'Revert ""Skip cpu comparison on AArch64""\n\nThis reverts commit 4bb54ae86981d186e41dcc325d171ab951beb7b6.\n\nChange-Id: I30aae6128d30fdfeab7b5c73c12d70b86fe03fc3\n'}]",0,703596,b22d754b835f0d9de8521580d9be7209db59b20b,12,22,1,11604,,,0,"Revert ""Skip cpu comparison on AArch64""

This reverts commit 4bb54ae86981d186e41dcc325d171ab951beb7b6.

Change-Id: I30aae6128d30fdfeab7b5c73c12d70b86fe03fc3
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/703596/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,b22d754b835f0d9de8521580d9be7209db59b20b,bug_1756118,,"_fake_cpu_info_aarch64 = { ""arch"": fields.Architecture.AARCH64, ""model"": ""test_model"", ""vendor"": ""test_vendor"", ""topology"": { ""sockets"": 1, ""cores"": 8, ""threads"": 16 }, ""features"": [""feature1"", ""feature2""] } @mock.patch.object(nova.virt.libvirt, 'config') def test_compare_cpu_aarch64_skip_comparison(self, mock_vconfig, mock_compare): instance = objects.Instance(**self.test_instance) skip_comparison_exc = fakelibvirt.make_libvirtError( fakelibvirt.libvirtError, 'Host CPU compatibility check does not make ' 'sense on AArch64; skip CPU comparison') mock_compare.side_effect = skip_comparison_exc conn = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) ret = conn._compare_cpu(None, jsonutils.dumps(_fake_cpu_info_aarch64), instance) self.assertIsNone(ret) @mock.patch.object(host.Host, 'compare_cpu')",0,32
openstack%2Fmistral~master~I3df3ab96342c456429e20a905615b90bcb94818d,openstack/mistral,master,I3df3ab96342c456429e20a905615b90bcb94818d,Initialize profiler for scheduler threads,MERGED,2020-01-30 09:00:28.000000000,2020-01-30 19:12:53.000000000,2020-01-30 19:11:02.000000000,"[{'_account_id': 7700}, {'_account_id': 9712}, {'_account_id': 15895}, {'_account_id': 19134}, {'_account_id': 21970}, {'_account_id': 22348}, {'_account_id': 29124}]","[{'number': 1, 'created': '2020-01-30 09:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/b50739be46da618f295b1925557227298012229e', 'message': ""Initialize profiler for scheduler threads\n\n* It turns out that osprofiler wasn't initialized properly for\n  threads in which scheduler runs its jobs. So profiling simply\n  didn't work for this threads and lots of important info didn't\n  get to the profiler log. This patch fixes it.\n* Other minor style fixes according to the Mistral coding guidelines.\n\nChange-Id: I3df3ab96342c456429e20a905615b90bcb94818d\n""}, {'number': 2, 'created': '2020-01-30 09:27:35.000000000', 'files': ['mistral/expressions/yaql_expression.py', 'mistral/tests/unit/expressions/test_yaql_expression.py', 'mistral/services/legacy_scheduler.py', 'mistral/utils/expression_utils.py', 'mistral/scheduler/default_scheduler.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/511be4f98f27eacda8755ceb4cce360ffbb66b4c', 'message': ""Initialize profiler for scheduler threads\n\n* It turns out that osprofiler wasn't initialized properly for\n  threads in which scheduler runs its jobs. So profiling simply\n  didn't work for this threads and lots of important info didn't\n  get to the profiler log. This patch fixes it.\n* When evaluating a YAQL expression, sometimes we get a huge result\n  value that we always put into the debug log. In practice, it doesn't\n  make much sense and, moreover, it utilizes lots of CPU and disk\n  space. It's better shrink it to some reasonable size that would\n  allow to make necessary analysis, if needed.\n* Other minor style fixes according to the Mistral coding guidelines.\n\nChange-Id: I3df3ab96342c456429e20a905615b90bcb94818d\n""}]",0,704943,511be4f98f27eacda8755ceb4cce360ffbb66b4c,14,7,2,8731,,,0,"Initialize profiler for scheduler threads

* It turns out that osprofiler wasn't initialized properly for
  threads in which scheduler runs its jobs. So profiling simply
  didn't work for this threads and lots of important info didn't
  get to the profiler log. This patch fixes it.
* When evaluating a YAQL expression, sometimes we get a huge result
  value that we always put into the debug log. In practice, it doesn't
  make much sense and, moreover, it utilizes lots of CPU and disk
  space. It's better shrink it to some reasonable size that would
  allow to make necessary analysis, if needed.
* Other minor style fixes according to the Mistral coding guidelines.

Change-Id: I3df3ab96342c456429e20a905615b90bcb94818d
",git fetch https://review.opendev.org/openstack/mistral refs/changes/43/704943/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/expressions/yaql_expression.py', 'mistral/tests/unit/expressions/test_yaql_expression.py', 'mistral/services/legacy_scheduler.py', 'mistral/utils/expression_utils.py', 'mistral/scheduler/default_scheduler.py']",5,b50739be46da618f295b1925557227298012229e,improve_performance,from osprofiler import profiler # Scheduler runs jobs in an separate thread that's neither related # to an RPC nor a REST request processing thread. So we need to # initialize a profiler specifically for this thread. if cfg.CONF.profiler.enabled: profiler.init(cfg.CONF.profiler.hmac_keys) ,,79,38
openstack%2Ftempest~master~I3b318935c7da9b5d2de94cde6a90d24e91df8dc3,openstack/tempest,master,I3b318935c7da9b5d2de94cde6a90d24e91df8dc3,Tempest coverage for volume retype and attach,ABANDONED,2019-04-16 05:11:04.000000000,2020-01-30 19:05:53.000000000,,"[{'_account_id': 4523}, {'_account_id': 11904}, {'_account_id': 12033}, {'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2019-04-16 05:11:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9f6c8f3ebf0031a0b65189a8afde807d77d4588c', 'message': 'Tempest coverage for volume retype and attach\n\nCurrently, we have test for retype volumes with\nmigrations. However, it would be nice if we perform\na cinder retype and then attempts to attach the\nvolume to an instance.\n\nChange-Id: I3b318935c7da9b5d2de94cde6a90d24e91df8dc3\n'}, {'number': 2, 'created': '2019-04-16 15:04:53.000000000', 'files': ['tempest/scenario/test_volume_migrate_attached.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/64af73c71d5f77fc5e7a4a91ee71672f63c4996d', 'message': 'Tempest coverage for volume retype and attach\n\nCurrently, we have test for retype volumes with\nmigrations. However, it would be nice if we perform\na cinder retype and then attempts to attach the\nvolume to an instance.\n\nChange-Id: I3b318935c7da9b5d2de94cde6a90d24e91df8dc3\n'}]",0,652823,64af73c71d5f77fc5e7a4a91ee71672f63c4996d,12,6,2,20813,,,0,"Tempest coverage for volume retype and attach

Currently, we have test for retype volumes with
migrations. However, it would be nice if we perform
a cinder retype and then attempts to attach the
volume to an instance.

Change-Id: I3b318935c7da9b5d2de94cde6a90d24e91df8dc3
",git fetch https://review.opendev.org/openstack/tempest refs/changes/23/652823/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_volume_migrate_attached.py'],1,9f6c8f3ebf0031a0b65189a8afde807d77d4588c,," def __attach_detach_volume_to_instance(self, volume_id): # Create a server server = self.create_server() # Volume is attached and detached successfully from an instance self.volumes_client.attach_volume(volume_id, instance_uuid=server['id'], mountpoint='/dev/%s' % CONF.compute.volume_device_name) waiters.wait_for_volume_resource_status(self.volumes_client, volume_id, 'in-use') self.volumes_client.detach_volume(volume_id) waiters.wait_for_volume_resource_status(self.volumes_client, volume_id, 'available') @decorators.attr(type='slow') @decorators.idempotent_id('deadd2c2-beef-4dce-98be-f86765ff311b') @utils.services('compute', 'volume') def test_volume_retype_w_migations_attach_detach(self): LOG.info(""Creating keypair and security group"") keypair = self.create_keypair() security_group = self._create_security_group() # create volume types LOG.info(""Creating Volume types"") source_type, dest_type = self._create_volume_types() # create an instance from volume LOG.info(""Booting instance from volume"") volume_origin = self.create_volume(imageRef=CONF.compute.image_ref, volume_type=source_type) instance = self._boot_instance_from_volume(volume_origin['id'], keypair, security_group) # write content to volume on instance LOG.info(""Setting timestamp in instance %s"", instance['id']) ip_instance = self.get_server_ip(instance) timestamp = self.create_timestamp(ip_instance, private_key=keypair['private_key'], server=instance) # retype volume with migration from backend #1 to backend #2 LOG.info(""Retyping Volume %s to new type %s"", volume_origin['id'], dest_type) self._volume_retype_with_migration(volume_origin['id'], dest_type) # check the content of written file LOG.info(""Getting timestamp in postmigrated instance %s"", instance['id']) timestamp2 = self.get_timestamp(ip_instance, private_key=keypair['private_key'], server=instance) self.assertEqual(timestamp, timestamp2) # Attach and detach volume to instance self.__attach_detach_volume_to_instance(volume_origin['id'])",,57,0
openstack%2Foslo.log~master~If6d6357501dfdff5a5edb53f24104e216607ea00,openstack/oslo.log,master,If6d6357501dfdff5a5edb53f24104e216607ea00,Drop python 2.7 support and testing,MERGED,2019-12-27 08:16:00.000000000,2020-01-30 18:52:51.000000000,2020-01-30 18:48:14.000000000,"[{'_account_id': 8556}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27621}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-12-27 08:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/30efd57b8bb47ac03b99ddd2923899316afff5bb', 'message': 'Drop python 2.7 support and testing\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: If6d6357501dfdff5a5edb53f24104e216607ea00\n'}, {'number': 2, 'created': '2020-01-30 11:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/151c02a1dc6e50a9a4f595ca4bdc0fa03087fd86', 'message': 'Drop python 2.7 support and testing\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: If6d6357501dfdff5a5edb53f24104e216607ea00\n'}, {'number': 3, 'created': '2020-01-30 11:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/ed147b3821d7410410d56b1d71e80b0ad70fa361', 'message': 'Drop python 2.7 support and testing\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: If6d6357501dfdff5a5edb53f24104e216607ea00\nSem-Ver: api-break\n'}, {'number': 4, 'created': '2020-01-30 15:15:55.000000000', 'files': ['releasenotes/notes/drop-python27-support-0fe4909a5468feb3.yaml', '.zuul.yaml', 'doc/requirements.txt', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/2dd526d1ed0f1f886fff0c2edfc2929dc6f58d1b', 'message': 'Drop python 2.7 support and testing\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: If6d6357501dfdff5a5edb53f24104e216607ea00\nSem-Ver: api-break\n'}]",3,700689,2dd526d1ed0f1f886fff0c2edfc2929dc6f58d1b,21,5,4,27822,,,0,"Drop python 2.7 support and testing

Ussuri Communtiy-wide goal:
https://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html

Change-Id: If6d6357501dfdff5a5edb53f24104e216607ea00
Sem-Ver: api-break
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/89/700689/2 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'setup.cfg', 'tox.ini']",3,30efd57b8bb47ac03b99ddd2923899316afff5bb,drop-py27-support,"envlist = py36,py37,pep8basepython = python3","envlist = py27,py36,py37,pep8basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3",2,12
openstack%2Foslo.service~master~I255de2a755b7783f20925d8ca4de6e34e5aee36b,openstack/oslo.service,master,I255de2a755b7783f20925d8ca4de6e34e5aee36b,tox: Trivial cleanup,MERGED,2019-12-20 10:12:25.000000000,2020-01-30 18:50:28.000000000,2020-01-30 18:46:43.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-12-20 10:12:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/00173467f31169b2668df93859ce3b7c299ce9ec', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: I255de2a755b7783f20925d8ca4de6e34e5aee36b\n""}, {'number': 2, 'created': '2020-01-08 19:11:33.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/98955871361c024305f82d08756daf920f79f361', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: I255de2a755b7783f20925d8ca4de6e34e5aee36b\n""}]",1,700144,98955871361c024305f82d08756daf920f79f361,17,3,2,28522,,,0,"tox: Trivial cleanup

Move 'basepython' to the top-level 'testenv'.
Use the default 'install_command'

https://tox.readthedocs.io/en/latest/config.html#conf-install_command

Change-Id: I255de2a755b7783f20925d8ca4de6e34e5aee36b
",git fetch https://review.opendev.org/openstack/oslo.service refs/changes/44/700144/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,00173467f31169b2668df93859ce3b7c299ce9ec,base_python,basepython = python3,install_command = pip install {opts} {packages}basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,1,9
openstack%2Ftripleo-heat-templates~stable%2Fqueens~Idd22c7b4403bb63c06d2ba714d851a976e830108,openstack/tripleo-heat-templates,stable/queens,Idd22c7b4403bb63c06d2ba714d851a976e830108,Run update without yum update to apply hotfixes.,MERGED,2020-01-29 08:35:52.000000000,2020-01-30 18:35:01.000000000,2020-01-30 18:35:01.000000000,"[{'_account_id': 3153}, {'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-29 08:35:52.000000000', 'files': ['puppet/services/tripleo-packages.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b75796900441bd0a24e60bcc982c890897027b56', 'message': 'Run update without yum update to apply hotfixes.\n\nAdd a new option to skip the yum update of all packages.\n\nChange-Id: Idd22c7b4403bb63c06d2ba714d851a976e830108\n(cherry picked from commit da3bf441aa49608698a4eb6c64793d8689e52a48)\n'}]",0,704743,b75796900441bd0a24e60bcc982c890897027b56,11,6,1,31245,,,0,"Run update without yum update to apply hotfixes.

Add a new option to skip the yum update of all packages.

Change-Id: Idd22c7b4403bb63c06d2ba714d851a976e830108
(cherry picked from commit da3bf441aa49608698a4eb6c64793d8689e52a48)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/43/704743/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/tripleo-packages.yaml'],1,b75796900441bd0a24e60bcc982c890897027b56,queens," SkipPackageUpdate: default: 'false' description: Set to true to skip the update all packages type: boolean - name: Set boolean skip_package_update set_fact: skip_package_update: {get_param: SkipPackageUpdate} - name: Update all packages when: - step|int == 3 - not skip_package_update|bool yum: name: '*' state: latest exclude: ceph*,librados*,librbd*,libcephfs*,librgw*,python-rados*,python-rbd*,python-cephfs*,python-rgw*,rbd-mirror - name: Set boolean skip_package_update set_fact: skip_package_update: {get_param: SkipPackageUpdate} when: - step|int == 3 - not skip_package_update|bool yum: name: '*' state: latest update_cache: yes"," - name: Update all but Ceph packages when: step|int == 3 yum: name=* state=latest exclude=ceph*,librados*,librbd*,libcephfs*,librgw*,python-rados*,python-rbd*,python-cephfs*,python-rgw*,rbd-mirror yum: name=* state=latest update_cache=yes when: step == ""3""",26,5
openstack%2Fcharm-neutron-gateway~master~Ia01c637b0837a4e594d16f6565c605460ad3f922,openstack/charm-neutron-gateway,master,Ia01c637b0837a4e594d16f6565c605460ad3f922,Make ovs_use_veth a config option,MERGED,2020-01-27 23:04:50.000000000,2020-01-30 18:17:08.000000000,2020-01-30 18:17:08.000000000,"[{'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-27 23:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/1e5a34133ad2ea2150838ec554fb7bf8d663040e', 'message': 'Make ovs_use_veth a config option\n\nThis change uses a common DHCPAgentContext and takes care to check for a\npre-existing setting in the dhcp_agent.ini. Only allowing a config\nchange if there is no pre-existing setting.\n\nPlease review and merge charm-helpers PR:\nhttps://github.com/juju/charm-helpers/pull/422\n\nPartial-Bug: #1831935\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/157\nChange-Id: Ia01c637b0837a4e594d16f6565c605460ad3f922\n'}, {'number': 2, 'created': '2020-01-28 00:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/6675cb1cbe2183d2ab663ccdec112ed98baae13d', 'message': 'Make ovs_use_veth a config option\n\nThis change uses a common DHCPAgentContext and takes care to check for a\npre-existing setting in the dhcp_agent.ini. Only allowing a config\nchange if there is no pre-existing setting.\n\nPlease review and merge charm-helpers PR:\nhttps://github.com/juju/charm-helpers/pull/422\n\nPartial-Bug: #1831935\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/157\nChange-Id: Ia01c637b0837a4e594d16f6565c605460ad3f922\n'}, {'number': 3, 'created': '2020-01-29 23:49:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/77871648bf088b041cc051d2d970f5a09573720a', 'message': 'Make ovs_use_veth a config option\n\nThis change uses a common DHCPAgentContext and takes care to check for a\npre-existing setting in the dhcp_agent.ini. Only allowing a config\nchange if there is no pre-existing setting.\n\nPlease review and merge charm-helpers PR:\nhttps://github.com/juju/charm-helpers/pull/422\n\nPartial-Bug: #1831935\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/157\nChange-Id: Ia01c637b0837a4e594d16f6565c605460ad3f922\n'}, {'number': 4, 'created': '2020-01-30 00:39:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/1cbf0e49043343b73292a425ab0b4afa68660f81', 'message': 'Make ovs_use_veth a config option\n\nThis change uses a common DHCPAgentContext and takes care to check for a\npre-existing setting in the dhcp_agent.ini. Only allowing a config\nchange if there is no pre-existing setting.\n\nPlease review and merge charm-helpers PR:\nhttps://github.com/juju/charm-helpers/pull/422\n\nPartial-Bug: #1831935\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/157\nChange-Id: Ia01c637b0837a4e594d16f6565c605460ad3f922\n'}, {'number': 5, 'created': '2020-01-30 02:24:50.000000000', 'files': ['templates/icehouse/dhcp_agent.ini', 'templates/mitaka/dhcp_agent.ini', 'tests/bundles/xenial-ocata.yaml', 'unit_tests/test_neutron_contexts.py', 'config.yaml', 'tests/bundles/eoan-train.yaml', 'tests/bundles/xenial-mitaka.yaml', 'hooks/charmhelpers/contrib/openstack/context.py', 'tests/bundles/xenial-queens.yaml', 'hooks/neutron_utils.py', 'tests/bundles/bionic-stein.yaml', 'tests/bundles/xenial-pike.yaml', 'tests/bundles/bionic-rocky.yaml', 'tests/bundles/bionic-train.yaml', 'tests/bundles/trusty-mitaka.yaml', 'hooks/neutron_contexts.py', 'templates/ocata/dhcp_agent.ini', 'tests/bundles/bionic-queens.yaml'], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/a03fe36fa65b710b6cd8059b870c44204f3e3856', 'message': 'Make ovs_use_veth a config option\n\nThis change uses a common DHCPAgentContext and takes care to check for a\npre-existing setting in the dhcp_agent.ini. Only allowing a config\nchange if there is no pre-existing setting.\n\nPlease review and merge charm-helpers PR:\nhttps://github.com/juju/charm-helpers/pull/422\n\nPartial-Bug: #1831935\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/157\nChange-Id: Ia01c637b0837a4e594d16f6565c605460ad3f922\n'}]",2,704462,a03fe36fa65b710b6cd8059b870c44204f3e3856,26,5,5,20805,,,0,"Make ovs_use_veth a config option

This change uses a common DHCPAgentContext and takes care to check for a
pre-existing setting in the dhcp_agent.ini. Only allowing a config
change if there is no pre-existing setting.

Please review and merge charm-helpers PR:
https://github.com/juju/charm-helpers/pull/422

Partial-Bug: #1831935

func-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/157
Change-Id: Ia01c637b0837a4e594d16f6565c605460ad3f922
",git fetch https://review.opendev.org/openstack/charm-neutron-gateway refs/changes/62/704462/5 && git format-patch -1 --stdout FETCH_HEAD,"['templates/icehouse/dhcp_agent.ini', 'templates/mitaka/dhcp_agent.ini', 'tests/bundles/bionic-train.yaml', 'hooks/neutron_contexts.py', 'templates/ocata/dhcp_agent.ini', 'unit_tests/test_neutron_contexts.py', 'config.yaml', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/neutron_utils.py']",9,1e5a34133ad2ea2150838ec554fb7bf8d663040e,bug/1831935," validate_ovs_use_veth, DHCPAgentContext, 'hook_contexts': [DHCPAgentContext()], 'hook_contexts': [DHCPAgentContext()], DHCPAgentContext(), return validate_ovs_use_veth()"," 'hook_contexts': [NeutronGatewayContext()], 'hook_contexts': [NeutronGatewayContext()],",141,68
openstack%2Fkeystone~stable%2Fstein~Iddc364d8c934b6e54d1e8c75b8b159faadbf865d,openstack/keystone,stable/stein,Iddc364d8c934b6e54d1e8c75b8b159faadbf865d,Ensure bootstrap handles multiple roles with the same name,MERGED,2019-12-18 18:46:54.000000000,2020-01-30 18:15:04.000000000,2020-01-30 18:11:39.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 9954}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-18 18:46:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2c047f1a580c5dd05ac23902ccde2ae28dbd14e9', 'message': ""Ensure bootstrap handles multiple roles with the same name\n\nThe bootstrap logic doesn't take into consideration multiple roles\nwith the same name. If bootstrap is unable to determine which role to\nuse and accidentally uses a domain-specific role with the same name\nas a default role, bootstrap will fail in unexpected ways.\n\nConflicts:\n      keystone/tests/unit/test_cli.py\n\n      This change conflicted with another test that was added in later\n      releases. The resolution was to not include the additional test,\n      which isn't related to this change anyway.\n\nCloses-Bug: 1856881\nChange-Id: Iddc364d8c934b6e54d1e8c75b8b159faadbf865d\n(cherry picked from commit 0552bf9804adea7ab9b9b8b9485fd6cbff598260)\n""}, {'number': 2, 'created': '2020-01-09 13:54:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ba014fd189025df9c7632cb31c58f5027a8336ed', 'message': ""Ensure bootstrap handles multiple roles with the same name\n\nThe bootstrap logic doesn't take into consideration multiple roles\nwith the same name. If bootstrap is unable to determine which role to\nuse and accidentally uses a domain-specific role with the same name\nas a default role, bootstrap will fail in unexpected ways.\n\nConflicts:\n      keystone/tests/unit/test_cli.py\n\n      This change conflicted with another test that was added in later\n      releases. The resolution was to not include the additional test,\n      which isn't related to this change anyway.\n\nCloses-Bug: 1856881\nChange-Id: Iddc364d8c934b6e54d1e8c75b8b159faadbf865d\n(cherry picked from commit 25cf359e5fb914b855922121f20e23bd14626b8e)\n""}, {'number': 3, 'created': '2020-01-29 17:39:28.000000000', 'files': ['releasenotes/notes/bug-1856881-277103af343187f1.yaml', 'keystone/cmd/bootstrap.py', 'keystone/tests/unit/test_cli.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/1ba238e49195890c0232554005d4efa670467694', 'message': ""Ensure bootstrap handles multiple roles with the same name\n\nThe bootstrap logic doesn't take into consideration multiple roles\nwith the same name. If bootstrap is unable to determine which role to\nuse and accidentally uses a domain-specific role with the same name\nas a default role, bootstrap will fail in unexpected ways.\n\nConflicts:\n      keystone/tests/unit/test_cli.py\n      Conflict exists because stable/stein doesn't have\n      https://review.opendev.org/#/c/675228/ but it's unrelated to this\n      specific bug fix.\n\nCloses-Bug: 1856881\nChange-Id: Iddc364d8c934b6e54d1e8c75b8b159faadbf865d\n(cherry picked from commit 25cf359e5fb914b855922121f20e23bd14626b8e)\n(cherry picked from commit 51ff7be731450c183b3e3eb6d34493e986cc2635)\n""}]",7,699834,1ba238e49195890c0232554005d4efa670467694,28,5,3,5046,,,0,"Ensure bootstrap handles multiple roles with the same name

The bootstrap logic doesn't take into consideration multiple roles
with the same name. If bootstrap is unable to determine which role to
use and accidentally uses a domain-specific role with the same name
as a default role, bootstrap will fail in unexpected ways.

Conflicts:
      keystone/tests/unit/test_cli.py
      Conflict exists because stable/stein doesn't have
      https://review.opendev.org/#/c/675228/ but it's unrelated to this
      specific bug fix.

Closes-Bug: 1856881
Change-Id: Iddc364d8c934b6e54d1e8c75b8b159faadbf865d
(cherry picked from commit 25cf359e5fb914b855922121f20e23bd14626b8e)
(cherry picked from commit 51ff7be731450c183b3e3eb6d34493e986cc2635)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/34/699834/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/cmd/bootstrap.py', 'keystone/tests/unit/test_cli.py']",2,2c047f1a580c5dd05ac23902ccde2ae28dbd14e9,," def test_bootstrap_with_ambiguous_role_names(self): # bootstrap system to create the default admin role self._do_test_bootstrap(self.bootstrap) # create a domain-specific roles that share the same names as the # default roles created by keystone-manage bootstrap domain = {'id': uuid.uuid4().hex, 'name': uuid.uuid4().hex} domain = PROVIDERS.resource_api.create_domain(domain['id'], domain) domain_roles = {} for name in ['admin', 'member', 'reader']: domain_role = { 'domain_id': domain['id'], 'id': uuid.uuid4().hex, 'name': name } domain_roles[name] = PROVIDERS.role_api.create_role( domain_role['id'], domain_role ) # ensure subsequent bootstrap attempts don't fail because of # ambiguity self._do_test_bootstrap(self.bootstrap) # clean up the role so we don't hit it again on the next run PROVIDERS.role_api.delete_role(domain_role['id'])",,33,1
openstack%2Fpython-tripleoclient~master~I13b69838aeae619dee392b52bf4cc0ab29aabe21,openstack/python-tripleoclient,master,I13b69838aeae619dee392b52bf4cc0ab29aabe21,"Revert ""Remove panko""",ABANDONED,2020-01-30 17:37:25.000000000,2020-01-30 17:38:20.000000000,,"[{'_account_id': 3153}, {'_account_id': 8449}, {'_account_id': 11082}, {'_account_id': 11491}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-30 17:37:25.000000000', 'files': ['tripleoclient/config/standalone.py', 'tripleoclient/v1/undercloud_config.py', 'releasenotes/notes/remove-panko-deprecated-in-train-0444baa3ba4688f1.yaml'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/5aae1a0a219db59597dc8e620aa36eab995fcdac', 'message': 'Revert ""Remove panko""\n\nThis reverts commit 2241528f4fd154e1f64bdeb0748c07c810ee8314.\n\nChange-Id: I13b69838aeae619dee392b52bf4cc0ab29aabe21\n'}]",0,705072,5aae1a0a219db59597dc8e620aa36eab995fcdac,3,7,1,30357,,,0,"Revert ""Remove panko""

This reverts commit 2241528f4fd154e1f64bdeb0748c07c810ee8314.

Change-Id: I13b69838aeae619dee392b52bf4cc0ab29aabe21
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/72/705072/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/config/standalone.py', 'tripleoclient/v1/undercloud_config.py', 'releasenotes/notes/remove-panko-deprecated-in-train-0444baa3ba4688f1.yaml']",3,5aae1a0a219db59597dc8e620aa36eab995fcdac,master-remove-panko,,"--- deprecations: - | Panko which is part of the telemetry services has been deprecated in Train. From now on, it is not deployed anymore in the Undercloud if the telemetry has been enabled during the installation. ",2,7
openstack%2Fpython-tripleoclient~master~I8849fda5c6a209913be79b668cbdb5e11dce1514,openstack/python-tripleoclient,master,I8849fda5c6a209913be79b668cbdb5e11dce1514,Remove panko,MERGED,2019-09-16 07:57:25.000000000,2020-01-30 17:37:25.000000000,2019-09-16 18:25:12.000000000,"[{'_account_id': 3153}, {'_account_id': 8449}, {'_account_id': 11082}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 30357}]","[{'number': 1, 'created': '2019-09-16 07:57:25.000000000', 'files': ['tripleoclient/config/standalone.py', 'tripleoclient/v1/undercloud_config.py', 'releasenotes/notes/remove-panko-deprecated-in-train-0444baa3ba4688f1.yaml'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/2241528f4fd154e1f64bdeb0748c07c810ee8314', 'message': 'Remove panko\n\nThis patch removes panko which has been deprecated in Train\n\nChange-Id: I8849fda5c6a209913be79b668cbdb5e11dce1514\nSigned-off-by: Gael Chamoulaud <gchamoul@redhat.com>\n'}]",0,682290,2241528f4fd154e1f64bdeb0748c07c810ee8314,10,7,1,11491,,,0,"Remove panko

This patch removes panko which has been deprecated in Train

Change-Id: I8849fda5c6a209913be79b668cbdb5e11dce1514
Signed-off-by: Gael Chamoulaud <gchamoul@redhat.com>
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/90/682290/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/config/standalone.py', 'tripleoclient/v1/undercloud_config.py', 'releasenotes/notes/remove-panko-deprecated-in-train-0444baa3ba4688f1.yaml']",3,2241528f4fd154e1f64bdeb0748c07c810ee8314,master-remove-panko,"--- deprecations: - | Panko which is part of the telemetry services has been deprecated in Train. From now on, it is not deployed anymore in the Undercloud if the telemetry has been enabled during the installation. ",,7,2
openstack%2Fdevstack~stable%2Fqueens~Id4861830c46867b313a5a705fc4722ac13471777,openstack/devstack,stable/queens,Id4861830c46867b313a5a705fc4722ac13471777,Use Tempest v21.0.0 for Queens testing instead of master,MERGED,2020-01-21 19:27:32.000000000,2020-01-30 17:35:57.000000000,2020-01-24 16:59:09.000000000,"[{'_account_id': 1131}, {'_account_id': 7118}, {'_account_id': 8556}, {'_account_id': 11975}, {'_account_id': 13252}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-21 19:27:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/8584d6689c288863ff33bc254856993fd13bba2b', 'message': ""Use Tempest v23.0.0 for Queens testing instead of master\n\nTempest and master and neutron-tempest-plugin queens tag is not\ncompatible for stable/queens testing.\nMore details on https://bugs.launchpad.net/tempest/+bug/1859988\n\nAlso py2 drop will start required the python 3.6 version for Tempest\nmaster tests.\n\nBecause stable/queens is EM, let's pin the Tempest for its tesing\ninstead of putting more effort to make Tempest master run-able.\n\nTempest 23.0.0 is supported Tag for Queens so let's use that for Queens\ntesting instead of Tempest master.\n\nRelated-Bug: 1859988\n\n[1] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: Id4861830c46867b313a5a705fc4722ac13471777\n""}, {'number': 2, 'created': '2020-01-21 19:34:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/482bc75a9772e182aa25ff0f817464329e9a6968', 'message': ""Use Tempest v23.0.0 for Queens testing instead of master\n\nTempest and master and neutron-tempest-plugin queens tag is not\ncompatible for stable/queens testing.\nMore details on https://bugs.launchpad.net/tempest/+bug/1859988\n\nAlso py2 drop will start required the python 3.6 version for Tempest\nmaster tests.\n\nBecause stable/queens is EM, let's pin the Tempest for its tesing\ninstead of putting more effort to make Tempest master run-able.\n\nTempest 23.0.0 is supported Tag for Queens so let's use that for Queens\ntesting instead of Tempest master.\n\nRelated-Bug: 1859988\n\n[1] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: Id4861830c46867b313a5a705fc4722ac13471777\n""}, {'number': 3, 'created': '2020-01-22 21:56:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c17100b5cd10a1efb62875206d9d970d1c578520', 'message': ""Use Tempest v23.0.0 for Queens testing instead of master\n\nTempest and master and neutron-tempest-plugin queens tag is not\ncompatible for stable/queens testing.\nMore details on https://bugs.launchpad.net/tempest/+bug/1859988\n\nAlso py2 drop will start required the python 3.6 version for Tempest\nmaster tests.\n\nBecause stable/queens is EM, let's pin the Tempest for its tesing\ninstead of putting more effort to make Tempest master run-able.\n\nTempest 23.0.0 is supported Tag for Queens so let's use that for Queens\ntesting instead of Tempest master.\n\nRelated-Bug: 1859988\n\n[1] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: Id4861830c46867b313a5a705fc4722ac13471777\n""}, {'number': 4, 'created': '2020-01-23 00:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/da804586d1accefe5ba9cd835361eaebc5d1c0c5', 'message': ""Use Tempest v18.0.0 for Queens testing instead of master\n\nTempest and master and neutron-tempest-plugin queens tag is not\ncompatible for stable/queens testing.\nMore details on https://bugs.launchpad.net/tempest/+bug/1859988\n\nAlso py2 drop will start required the python 3.6 version for Tempest\nmaster tests.\n\nBecause stable/queens is EM, let's pin the Tempest for its tesing\ninstead of putting more effort to make Tempest master run-able.\n\nTempest 18.0.0 is supported Tag for Queens so let's use that for Queens\ntesting instead of Tempest master.\n\nCloses-Bug: 1859988\n\n[1] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: Id4861830c46867b313a5a705fc4722ac13471777\n""}, {'number': 5, 'created': '2020-01-23 15:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/b4f8a8ec056caa1a79866f7a5f0f8ed3fe36ada3', 'message': ""Use Tempest v19.0.0 for Queens testing instead of master\n\nTempest and master and neutron-tempest-plugin queens tag is not\ncompatible for stable/queens testing.\nMore details on https://bugs.launchpad.net/tempest/+bug/1859988\n\nAlso py2 drop will start required the python 3.6 version for Tempest\nmaster tests.\n\nBecause stable/queens is EM, let's pin the Tempest for its tesing\ninstead of putting more effort to make Tempest master run-able.\n\nTempest 19.0.0 is supported Tag for Queens so let's use that for Queens\ntesting instead of Tempest master.\n\nCloses-Bug: 1859988\n\n[1] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: Id4861830c46867b313a5a705fc4722ac13471777\n""}, {'number': 6, 'created': '2020-01-23 15:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4c7678d2bb7ccee630ded545f94cd645bfc22bc7', 'message': ""Use Tempest v19.0.0 for Queens testing instead of master\n\nTempest and master and neutron-tempest-plugin queens tag is not\ncompatible for stable/queens testing.\nMore details on https://bugs.launchpad.net/tempest/+bug/1859988\n\nAlso py2 drop will start required the python 3.6 version for Tempest\nmaster tests.\n\nBecause stable/queens is EM, let's pin the Tempest for its tesing\ninstead of putting more effort to make Tempest master run-able.\n\nTempest 19.0.0 is supported Tag for Queens so let's use that for Queens\ntesting instead of Tempest master.\n\nCloses-Bug: 1859988\n\n[1] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: Id4861830c46867b313a5a705fc4722ac13471777\n""}, {'number': 7, 'created': '2020-01-23 21:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/9bd9abae8f2d7fdd2d469e7638a514a2d8466a13', 'message': ""Use Tempest v21.0.0 for Queens testing instead of master\n\nTempest and master and neutron-tempest-plugin queens tag is not\ncompatible for stable/queens testing.\nMore details on https://bugs.launchpad.net/tempest/+bug/1859988\n\nAlso py2 drop will start required the python 3.6 version for Tempest\nmaster tests.\n\nBecause stable/queens is EM, let's pin the Tempest for its tesing\ninstead of putting more effort to make Tempest master run-able.\n\nTempest 21.0.0 is supported Tag for Queens so let's use that for Queens\ntesting instead of Tempest master.\n\nCloses-Bug: 1859988\n\n[1] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: Id4861830c46867b313a5a705fc4722ac13471777\n""}, {'number': 8, 'created': '2020-01-23 22:55:09.000000000', 'files': ['tests/test_refs.sh', 'lib/tempest', 'stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/4014fb8c5237701164b1422292aa611ad8fc741e', 'message': ""Use Tempest v21.0.0 for Queens testing instead of master\n\nTempest and master and neutron-tempest-plugin queens tag is not\ncompatible for stable/queens testing.\nMore details on https://bugs.launchpad.net/tempest/+bug/1859988\n\nAlso py2 drop will start required the python 3.6 version for Tempest\nmaster tests.\n\nBecause stable/queens is EM, let's pin the Tempest for its tesing\ninstead of putting more effort to make Tempest master run-able.\n\nTempest 21.0.0 is supported Tag for Queens so let's use that for Queens\ntesting instead of Tempest master.\n\nCloses-Bug: 1859988\n\n[1] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: Id4861830c46867b313a5a705fc4722ac13471777\n""}]",6,703679,4014fb8c5237701164b1422292aa611ad8fc741e,35,8,8,8556,,,0,"Use Tempest v21.0.0 for Queens testing instead of master

Tempest and master and neutron-tempest-plugin queens tag is not
compatible for stable/queens testing.
More details on https://bugs.launchpad.net/tempest/+bug/1859988

Also py2 drop will start required the python 3.6 version for Tempest
master tests.

Because stable/queens is EM, let's pin the Tempest for its tesing
instead of putting more effort to make Tempest master run-able.

Tempest 21.0.0 is supported Tag for Queens so let's use that for Queens
testing instead of Tempest master.

Closes-Bug: 1859988

[1] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html

Change-Id: Id4861830c46867b313a5a705fc4722ac13471777
",git fetch https://review.opendev.org/openstack/devstack refs/changes/79/703679/4 && git format-patch -1 --stdout FETCH_HEAD,['stackrc'],1,8584d6689c288863ff33bc254856993fd13bba2b,bug/1859988,TEMPEST_REPO=${TEMPEST_REPO:-https://review.opendev.org/openstack/tempest} # Use Tempest commit (for tag 23.0.0) which is Queens supported version. # https://docs.openstack.org/releasenotes/tempest/v23.0.0.html # https://github.com/openstack/tempest/commit/fd328a4f2165a60eb8b7585ec1af3145939383c3 TEMPEST_BRANCH=${TEMPEST_BRANCH:-refs/changes/55/703255/1},TEMPEST_REPO=${TEMPEST_REPO:-${GIT_BASE}/openstack/tempest.git} TEMPEST_BRANCH=${TEMPEST_BRANCH:-$BRANCHLESS_TARGET_BRANCH},5,2
openstack%2Fironic~stable%2Ftrain~I4f2cecdc0af366364b18232dbd8ea4ffdd3165d2,openstack/ironic,stable/train,I4f2cecdc0af366364b18232dbd8ea4ffdd3165d2,Don't require root partition when installing a whole disk image,MERGED,2020-01-27 16:53:01.000000000,2020-01-30 17:28:25.000000000,2020-01-30 17:25:45.000000000,"[{'_account_id': 6618}, {'_account_id': 10118}, {'_account_id': 19339}, {'_account_id': 21909}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-01-27 16:53:01.000000000', 'files': ['ironic/tests/unit/drivers/modules/test_agent_base_vendor.py', 'releasenotes/notes/whole-disk-scsi-install-bootloader-f7e791d82da476ca.yaml', 'ironic/drivers/modules/agent_base_vendor.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/8f61636eb90a712c74d7d73dc159b2e8702f930e', 'message': ""Don't require root partition when installing a whole disk image\n\nWith the change to find the bootloader on disk (https://review.opendev.org/#/c/696914/)\ninstall_bootloader should now be invoked when doing an iscsi_deploy even if the root\npartition cannot be found.\n\nDepends-On: I7167e71e5d2352a045565289b200e5530d0ba11d\nChange-Id: I4f2cecdc0af366364b18232dbd8ea4ffdd3165d2\n(cherry picked from commit d614d86eef0db7fd9784f4d81a3369841c5a9eb3)\n""}]",0,704357,8f61636eb90a712c74d7d73dc159b2e8702f930e,10,6,1,15519,,,0,"Don't require root partition when installing a whole disk image

With the change to find the bootloader on disk (https://review.opendev.org/#/c/696914/)
install_bootloader should now be invoked when doing an iscsi_deploy even if the root
partition cannot be found.

Depends-On: I7167e71e5d2352a045565289b200e5530d0ba11d
Change-Id: I4f2cecdc0af366364b18232dbd8ea4ffdd3165d2
(cherry picked from commit d614d86eef0db7fd9784f4d81a3369841c5a9eb3)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/57/704357/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/drivers/modules/test_agent_base_vendor.py', 'releasenotes/notes/whole-disk-scsi-install-bootloader-f7e791d82da476ca.yaml', 'ironic/drivers/modules/agent_base_vendor.py']",3,8f61636eb90a712c74d7d73dc159b2e8702f930e,whole-disk-install-bootloader-stable/train,"from ironic.drivers.modules import boot_mode_utils # For whole disk images it is not necessary that the root_uuid # be provided since the bootloaders on the disk will be used if (software_raid or (root_uuid and not whole_disk_image) or (whole_disk_image and boot_mode_utils.get_boot_mode(node) == 'uefi')): if not whole_disk_image: msg = (_(""Failed to install a bootloader when "" ""deploying node %(node)s. Error: %(error)s"") % {'node': node.uuid, 'error': result['command_error']}) log_and_raise_deployment_error(task, msg) else: # Its possible the install will fail if the IPA image # has not been updated, log this and continue LOG.info('Could not install bootloader for whole disk ' 'image for node %(node)s, Error: %(error)s""', {'node': node.uuid, 'error': result['command_error']}) return"," if software_raid or (root_uuid and not whole_disk_image): msg = (_(""Failed to install a bootloader when "" ""deploying node %(node)s. Error: %(error)s"") % {'node': node.uuid, 'error': result['command_error']}) log_and_raise_deployment_error(task, msg)",52,6
openstack%2Fnova~master~I40e515cd4ddc85cd1dba613c2b5c0505e35df295,openstack/nova,master,I40e515cd4ddc85cd1dba613c2b5c0505e35df295,zuul: Remove unnecessary 'USE_PYTHON3',MERGED,2019-11-21 09:34:14.000000000,2020-01-30 17:13:36.000000000,2020-01-30 17:09:07.000000000,"[{'_account_id': 8556}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 11604}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-21 09:34:14.000000000', 'files': ['doc/source/contributor/testing/eventlet-profiling.rst', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/4a876df468b5b2dce4439398a32db4541ed277a1', 'message': ""zuul: Remove unnecessary 'USE_PYTHON3'\n\nThe DevStack change to switch to Python 3 by default [1] has now landed,\nwhich means we no longer need to override this in our zuul\nconfiguration. Remove the relevant entries.\n\n[1] https://review.opendev.org/#/c/649097/\n\nChange-Id: I40e515cd4ddc85cd1dba613c2b5c0505e35df295\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",0,695380,4a876df468b5b2dce4439398a32db4541ed277a1,22,12,1,15334,,,0,"zuul: Remove unnecessary 'USE_PYTHON3'

The DevStack change to switch to Python 3 by default [1] has now landed,
which means we no longer need to override this in our zuul
configuration. Remove the relevant entries.

[1] https://review.opendev.org/#/c/649097/

Change-Id: I40e515cd4ddc85cd1dba613c2b5c0505e35df295
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/695380/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributor/testing/eventlet-profiling.rst', '.zuul.yaml']",2,4a876df468b5b2dce4439398a32db4541ed277a1,drop-py27-support,,# TODO(stephenfin): Remove 'USE_PYTHON3' once [1] or similar merges # # [1] https://review.opendev.org/#/c/649097/ # USE_PYTHON3: True USE_PYTHON3: True USE_PYTHON3: True USE_PYTHON3: True USE_PYTHON3: True USE_PYTHON3: True USE_PYTHON3: True,0,12
openstack%2Fcinder~master~Ib28b6a2867469e73307482827d9e336b10a58432,openstack/cinder,master,Ib28b6a2867469e73307482827d9e336b10a58432,RBD: catch argument exceptions when configuring multiattach,MERGED,2019-11-14 18:35:09.000000000,2020-01-30 17:10:29.000000000,2020-01-24 08:49:10.000000000,"[{'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 5997}, {'_account_id': 9008}, {'_account_id': 9236}, {'_account_id': 9535}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 20813}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}, {'_account_id': 30688}]","[{'number': 1, 'created': '2019-11-14 18:35:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a1958dd3d2e07633a9b5000df35bba41ede20489', 'message': 'RBD: catch argument exceptions when configuring multiattach\n\nIf an expected flag is already in the desired state, rbd will raise an\nInvalidArgument exception.  This is okay, however not catching this will\nresult in volume operation errors.\n\nChange-Id: Ib28b6a2867469e73307482827d9e336b10a58432\nCloses-Bug: #1852628\n'}, {'number': 2, 'created': '2019-12-03 17:58:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b0987abcf56a76d8eb072ed2231a39e8b66712fe', 'message': 'RBD: catch argument exceptions when configuring multiattach\n\nIf an expected flag is already in the desired state, rbd will raise an\nInvalidArgument exception.  This is okay, however not catching this will\nresult in volume operation errors.\n\nChange-Id: Ib28b6a2867469e73307482827d9e336b10a58432\nCloses-Bug: #1852628\n'}, {'number': 3, 'created': '2020-01-07 20:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3e057db79bd95ba53671f92c74df79c4a08e791c', 'message': 'RBD: catch argument exceptions when configuring multiattach\n\nIf an expected flag is already in the desired state, rbd will raise an\nInvalidArgument exception.  This is okay, however not catching this will\nresult in volume operation errors.\n\nCo-Author: Eric Harney <eharney@redhat.com>\nChange-Id: Ib28b6a2867469e73307482827d9e336b10a58432\nCloses-Bug: #1852628\n'}, {'number': 4, 'created': '2020-01-08 14:17:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d8f6572d3d2ce5cc7a9d6cc17fefae9042b3d4cd', 'message': 'RBD: catch argument exceptions when configuring multiattach\n\nIf an expected flag is already in the desired state, rbd will raise an\nInvalidArgument exception.  This is okay, however not catching this will\nresult in volume operation errors.\n\nCo-Author: Eric Harney <eharney@redhat.com>\nChange-Id: Ib28b6a2867469e73307482827d9e336b10a58432\nCloses-Bug: #1852628\n'}, {'number': 5, 'created': '2020-01-09 21:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6df7a3da89b9984c4a6e7552c932708c5808aee2', 'message': 'RBD: catch argument exceptions when configuring multiattach\n\nIf an expected flag is already in the desired state, RBD will raise an\nInvalidArgument exception.  This is okay, however not catching this will\nresult in volume operation errors.\n\nCo-Author: Eric Harney <eharney@redhat.com>\nChange-Id: Ib28b6a2867469e73307482827d9e336b10a58432\nCloses-Bug: #1852628\n'}, {'number': 6, 'created': '2020-01-18 09:08:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1e2d73be2ac52e967ecf3de7c1d3c08273f58740', 'message': 'RBD: catch argument exceptions when configuring multiattach\n\nIf an expected flag is already in the desired state, RBD will raise an\nInvalidArgument exception.  This is okay, however not catching this will\nresult in volume operation errors.\n\nCo-Author: Eric Harney <eharney@redhat.com>\nChange-Id: Ib28b6a2867469e73307482827d9e336b10a58432\nCloses-Bug: #1852628\n'}, {'number': 7, 'created': '2020-01-20 18:49:51.000000000', 'files': ['releasenotes/notes/rbd-multiattach-exceptions-43066312f3b527f5.yaml', 'cinder/volume/drivers/rbd.py', 'cinder/tests/unit/volume/drivers/test_rbd.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9bc67c8978faba9e879bf377652d2679e143d992', 'message': 'RBD: catch argument exceptions when configuring multiattach\n\nIf an expected flag is already in the desired state, RBD will raise an\nInvalidArgument exception.  This is okay, however not catching this will\nresult in volume operation errors.\n\nCo-Author: Eric Harney <eharney@redhat.com>\nChange-Id: Ib28b6a2867469e73307482827d9e336b10a58432\nCloses-Bug: #1852628\n'}]",35,694379,9bc67c8978faba9e879bf377652d2679e143d992,248,42,7,9236,,,0,"RBD: catch argument exceptions when configuring multiattach

If an expected flag is already in the desired state, RBD will raise an
InvalidArgument exception.  This is okay, however not catching this will
result in volume operation errors.

Co-Author: Eric Harney <eharney@redhat.com>
Change-Id: Ib28b6a2867469e73307482827d9e336b10a58432
Closes-Bug: #1852628
",git fetch https://review.opendev.org/openstack/cinder refs/changes/79/694379/7 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/rbd.py'],1,a1958dd3d2e07633a9b5000df35bba41ede20489,," # Order matters here, iteration takes feature dependencies into # account. multipath_feature_exclusions = { ""journaling"": self.rbd.RBD_FEATURE_JOURNALING, ""fast diff"": self.rbd.RBD_FEATURE_FAST_DIFF, ""object map"": self.rbd.RBD_FEATURE_OBJECT_MAP, ""exclusive lock"": self.rbd.RBD_FEATURE_EXCLUSIVE_LOCK, } for name, value in multipath_feature_exclusions.items(): if image_features & value: try: image.update_features(value, False) except self.rbd.InvalidArgument: LOG.info(""enable multiattach: skipping already "" ""unset multiattach feature: %s"", name) # Order matters here, iteration takes feature dependencies into # account. multipath_feature_exclusions = { ""exclusive lock"": self.rbd.RBD_FEATURE_EXCLUSIVE_LOCK, ""object map"": self.rbd.RBD_FEATURE_OBJECT_MAP, ""fast diff"": self.rbd.RBD_FEATURE_FAST_DIFF, ""journaling"": self.rbd.RBD_FEATURE_JOURNALING, } for name, value in multipath_feature_exclusions.items(): if image_features & value: try: image.update_features(value, True) except self.rbd.InvalidArgument: LOG.info(""disable multiattach: skipping already "" ""set multiattach feature: %s"", name)"," multipath_feature_exclusions = [ self.rbd.RBD_FEATURE_JOURNALING, self.rbd.RBD_FEATURE_FAST_DIFF, self.rbd.RBD_FEATURE_OBJECT_MAP, self.rbd.RBD_FEATURE_EXCLUSIVE_LOCK, ] for feature in multipath_feature_exclusions: if image_features & feature: image.update_features(feature, False) multipath_feature_exclusions = [ self.rbd.RBD_FEATURE_EXCLUSIVE_LOCK, self.rbd.RBD_FEATURE_OBJECT_MAP, self.rbd.RBD_FEATURE_FAST_DIFF, self.rbd.RBD_FEATURE_JOURNALING, ] for feature in multipath_feature_exclusions: if image_features & feature: image.update_features(feature, True)",32,18
openstack%2Fos-vif~master~Iaebd42af6d5b8e3165cf10e269addae0ff3665fb,openstack/os-vif,master,Iaebd42af6d5b8e3165cf10e269addae0ff3665fb,[OVS] VLAN tag should be set in the Port register,MERGED,2020-01-20 11:42:41.000000000,2020-01-30 16:59:16.000000000,2020-01-30 16:54:27.000000000,"[{'_account_id': 9732}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-20 11:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/9ebf146c4789daf4318f7275757691e65e865553', 'message': '[OVS] VLAN tag should be set in the Port register\n\nIn OVS, the VLAN tag for a device is set in the Port register,\nnot the Interface [1][2]. Method ""BaseOVS.create_ovs_vif_port""\nshould implement it.\n\n[1] http://docs.openvswitch.org/en/latest/faq/configuration/\n[2] https://github.com/openstack/neutron/blob/1d354f75776fca6bf12beae70f7e3206459c84c4/neutron/agent/common/ovs_lib.py#L346-L347\n\nChange-Id: Iaebd42af6d5b8e3165cf10e269addae0ff3665fb\nCloses-Bug: #1860329\n'}, {'number': 2, 'created': '2020-01-30 12:19:51.000000000', 'files': ['vif_plug_ovs/tests/functional/ovsdb/test_ovsdb_lib.py', 'vif_plug_ovs/ovsdb/ovsdb_lib.py', 'vif_plug_ovs/tests/unit/ovsdb/test_ovsdb_lib.py'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/d5b61d10655b3b7a9d32378b5f7bcdb06479e15d', 'message': '[OVS] VLAN tag should be set in the Port register\n\nIn OVS, the VLAN tag for a device is set in the Port register,\nnot the Interface [1][2]. Method ""BaseOVS.create_ovs_vif_port""\nshould implement it.\n\n[1] http://docs.openvswitch.org/en/latest/faq/configuration/\n[2] https://github.com/openstack/neutron/blob/1d354f75776fca6bf12beae70f7e3206459c84c4/neutron/agent/common/ovs_lib.py#L346-L347\n\nChange-Id: Iaebd42af6d5b8e3165cf10e269addae0ff3665fb\nCloses-Bug: #1860329\n'}]",0,703373,d5b61d10655b3b7a9d32378b5f7bcdb06479e15d,15,4,2,16688,,,0,"[OVS] VLAN tag should be set in the Port register

In OVS, the VLAN tag for a device is set in the Port register,
not the Interface [1][2]. Method ""BaseOVS.create_ovs_vif_port""
should implement it.

[1] http://docs.openvswitch.org/en/latest/faq/configuration/
[2] https://github.com/openstack/neutron/blob/1d354f75776fca6bf12beae70f7e3206459c84c4/neutron/agent/common/ovs_lib.py#L346-L347

Change-Id: Iaebd42af6d5b8e3165cf10e269addae0ff3665fb
Closes-Bug: #1860329
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/73/703373/2 && git format-patch -1 --stdout FETCH_HEAD,"['vif_plug_ovs/tests/functional/ovsdb/test_ovsdb_lib.py', 'vif_plug_ovs/ovsdb/ovsdb_lib.py', 'vif_plug_ovs/tests/unit/ovsdb/test_ovsdb_lib.py']",3,9ebf146c4789daf4318f7275757691e65e865553,bug/1860329," vhost_server_path=vhost_server_path, tag=4000) [mock.call('Port', device, ('tag', 4000)), mock.call('Interface', device, *values)])"," vhost_server_path=vhost_server_path) [mock.call('Interface', device, *values)])",20,12
openstack%2Fcharm-layer-openstack~master~Ic9cdc2f470e4c7e1f6fc17a4d6246ca79fc48bd7,openstack/charm-layer-openstack,master,Ic9cdc2f470e4c7e1f6fc17a4d6246ca79fc48bd7,Ensure that concrete charm class is found for default handlers,MERGED,2020-01-30 14:04:06.000000000,2020-01-30 16:48:05.000000000,2020-01-30 16:48:05.000000000,"[{'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}, {'_account_id': 31420}]","[{'number': 1, 'created': '2020-01-30 14:04:06.000000000', 'files': ['reactive/layer_openstack.py'], 'web_link': 'https://opendev.org/openstack/charm-layer-openstack/commit/30166f783535ae9f974e8cf93d66bae8f9a01d7e', 'message': ""Ensure that concrete charm class is found for default handlers\n\nWhen debugging a charm uprade issue with ovn_chassis, it was noticed\nthat the upgrade hook failed as the concrete charm class wasn't\nfound and instantiated.  This patchset ensures that the concrete charm\nclass is found and thus can be instantiated.\n\nChange-Id: Ic9cdc2f470e4c7e1f6fc17a4d6246ca79fc48bd7\n""}]",0,705017,30166f783535ae9f974e8cf93d66bae8f9a01d7e,8,4,1,20870,,,0,"Ensure that concrete charm class is found for default handlers

When debugging a charm uprade issue with ovn_chassis, it was noticed
that the upgrade hook failed as the concrete charm class wasn't
found and instantiated.  This patchset ensures that the concrete charm
class is found and thus can be instantiated.

Change-Id: Ic9cdc2f470e4c7e1f6fc17a4d6246ca79fc48bd7
",git fetch https://review.opendev.org/openstack/charm-layer-openstack refs/changes/17/705017/1 && git format-patch -1 --stdout FETCH_HEAD,['reactive/layer_openstack.py'],1,30166f783535ae9f974e8cf93d66bae8f9a01d7e,ensure-charm-class-found-for-default-handlers,import charms_openstack.buscharms_openstack.bus.discover() ,,4,0
openstack%2Fopenstack-helm-infra~master~I1eb54d9ec70cebe89c5d92e06b387a5ef358ef00,openstack/openstack-helm-infra,master,I1eb54d9ec70cebe89c5d92e06b387a5ef358ef00,"WIP: Ubuntu 18.04, disable systemd-resolved",ABANDONED,2020-01-28 07:27:15.000000000,2020-01-30 16:45:45.000000000,,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23928}, {'_account_id': 27715}, {'_account_id': 27772}, {'_account_id': 28618}, {'_account_id': 28664}, {'_account_id': 31415}]","[{'number': 1, 'created': '2020-01-28 07:27:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8bf7003ddc064329d026ff7ca8034e29889151b8', 'message': ""Ubuntu 18.04, disable systemd-resolved\n\nUpdated k8s deploy script to disable systemd-resolved service for ubuntu bionic.\nThis to avoid interference between the system-resolved's local dns cache stub\nand the coredns, both running on port 53.\nThis solution will rely on the static /etc/resolv.conf file for name resolution,\ninstead of using the systemd-resolved service and its local stub dns.\n\nChange-Id: I1eb54d9ec70cebe89c5d92e06b387a5ef358ef00\n""}, {'number': 2, 'created': '2020-01-28 21:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/46f8d5991e17ce72baa63a2b339087e7b8891637', 'message': ""Ubuntu 18.04, disable systemd-resolved\n\nUpdated k8s deploy script to disable systemd-resolved service for ubuntu bionic.\nThis to avoid interference between the system-resolved's local dns cache stub\nand the coredns, both running on port 53.\nThis solution will rely on the static /etc/resolv.conf file for name resolution,\ninstead of using the systemd-resolved service and its local stub dns.\n\nChange-Id: I1eb54d9ec70cebe89c5d92e06b387a5ef358ef00\n""}, {'number': 3, 'created': '2020-01-29 19:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/373b230b36421ff4d09e3798216c83197fa032cd', 'message': ""Ubuntu 18.04, disable systemd-resolved\n\nUpdated k8s deploy script to disable systemd-resolved service for ubuntu bionic.\nThis to avoid interference between the system-resolved's local dns cache stub\nand the coredns, both running on port 53.\nThis solution will rely on the static /etc/resolv.conf file for name resolution,\ninstead of using the systemd-resolved service and its local stub dns.\n\nChange-Id: I1eb54d9ec70cebe89c5d92e06b387a5ef358ef00\n""}, {'number': 4, 'created': '2020-01-29 21:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/90563b602d2c2ebdb4a0f41e2ed901807a5a0190', 'message': ""WIP: Ubuntu 18.04, disable systemd-resolved\n\nUpdated k8s deploy script to disable systemd-resolved service for ubuntu bionic.\nThis to avoid interference between the system-resolved's local dns cache stub\nand the coredns, both running on port 53.\nThis solution will rely on the static /etc/resolv.conf file for name resolution,\ninstead of using the systemd-resolved service and its local stub dns.\n\nChange-Id: I1eb54d9ec70cebe89c5d92e06b387a5ef358ef00\n""}, {'number': 5, 'created': '2020-01-29 22:20:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/fcfda1fc3c498accd38bd029a6656638a369653b', 'message': ""WIP: Ubuntu 18.04, disable systemd-resolved\n\nUpdated k8s deploy script to disable systemd-resolved service for ubuntu bionic.\nThis to avoid interference between the system-resolved's local dns cache stub\nand the coredns, both running on port 53.\nThis solution will rely on the static /etc/resolv.conf file for name resolution,\ninstead of using the systemd-resolved service and its local stub dns.\n\nChange-Id: I1eb54d9ec70cebe89c5d92e06b387a5ef358ef00\n""}, {'number': 6, 'created': '2020-01-30 00:41:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/360fc6750554ca46f6aafa2a68b2d66a4e6f537d', 'message': ""WIP: Ubuntu 18.04, disable systemd-resolved\n\nUpdated k8s deploy script to disable systemd-resolved service for ubuntu bionic.\nThis to avoid interference between the system-resolved's local dns cache stub\nand the coredns, both running on port 53.\nThis solution will rely on the static /etc/resolv.conf file for name resolution,\ninstead of using the systemd-resolved service and its local stub dns.\n\nChange-Id: I1eb54d9ec70cebe89c5d92e06b387a5ef358ef00\n""}, {'number': 7, 'created': '2020-01-30 00:56:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b2d5ac66bfe1ec586790cd00b33203e4f6c2ea30', 'message': ""WIP: Ubuntu 18.04, disable systemd-resolved\n\nUpdated k8s deploy script to disable systemd-resolved service for ubuntu bionic.\nThis to avoid interference between the system-resolved's local dns cache stub\nand the coredns, both running on port 53.\nThis solution will rely on the static /etc/resolv.conf file for name resolution,\ninstead of using the systemd-resolved service and its local stub dns.\n\nChange-Id: I1eb54d9ec70cebe89c5d92e06b387a5ef358ef00\n""}, {'number': 8, 'created': '2020-01-30 10:47:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/386e4c36a9449fd204d8a1076bea2a1cd9109f71', 'message': ""WIP: Ubuntu 18.04, disable systemd-resolved\n\nUpdated k8s deploy script to disable systemd-resolved service for ubuntu bionic.\nThis to avoid interference between the system-resolved's local dns cache stub\nand the coredns, both running on port 53.\nThis solution will rely on the static /etc/resolv.conf file for name resolution,\ninstead of using the systemd-resolved service and its local stub dns.\n\nChange-Id: I1eb54d9ec70cebe89c5d92e06b387a5ef358ef00\n""}, {'number': 9, 'created': '2020-01-30 15:23:55.000000000', 'files': ['tools/deployment/common/005-deploy-k8s.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/053dcde8e5f4e85ca25712ba827ea2f9e504760d', 'message': ""WIP: Ubuntu 18.04, disable systemd-resolved\n\nUpdated k8s deploy script to disable systemd-resolved service for ubuntu bionic.\nThis to avoid interference between the system-resolved's local dns cache stub\nand the coredns, both running on port 53.\nThis solution will rely on the static /etc/resolv.conf file for name resolution,\ninstead of using the systemd-resolved service and its local stub dns.\n\nChange-Id: I1eb54d9ec70cebe89c5d92e06b387a5ef358ef00\n""}]",8,704501,053dcde8e5f4e85ca25712ba827ea2f9e504760d,32,10,9,28664,,,0,"WIP: Ubuntu 18.04, disable systemd-resolved

Updated k8s deploy script to disable systemd-resolved service for ubuntu bionic.
This to avoid interference between the system-resolved's local dns cache stub
and the coredns, both running on port 53.
This solution will rely on the static /etc/resolv.conf file for name resolution,
instead of using the systemd-resolved service and its local stub dns.

Change-Id: I1eb54d9ec70cebe89c5d92e06b387a5ef358ef00
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/01/704501/7 && git format-patch -1 --stdout FETCH_HEAD,['tools/deployment/common/005-deploy-k8s.sh'],1,8bf7003ddc064329d026ff7ca8034e29889151b8,704501," DISTRO_ID=$(grep 'DISTRIB_ID' /etc/lsb-release | awk -F= '{print $2}') DISTRO_CODENAME=$(grep 'DISTRIB_CODENAME' /etc/lsb-release | awk -F= '{print $2}') # For ubuntu 18.04 bionic, disable systemd-resolved service, to avoid # interference between the coreDns and the local systemd-resolved's # dns stub resolver, both running on port 53. if [[ ""${DISTRO_ID}"" == ""Ubuntu"" && ""${DISTRO_CODENAME}"" == ""bionic"" ]]; then sudo systemctl disable systemd-resolved.service sudo systemctl stop systemd-resolved.service sudo systemctl mask systemd-resolved.service fi ",,12,0
openstack%2Fironic~master~Id849d0967ba168a6e8940d830d62e62ea1f34f29,openstack/ironic,master,Id849d0967ba168a6e8940d830d62e62ea1f34f29,[DNM] test multinode job,ABANDONED,2019-12-12 11:18:31.000000000,2020-01-30 16:24:55.000000000,,"[{'_account_id': 10118}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-12-12 11:18:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1ddf0ab98d0d470d1c3d7e53852f8d257012e9f0', 'message': '[DNM] test multinode job\n\nChange-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29\n'}, {'number': 2, 'created': '2019-12-12 13:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1a2daea3ad68a3b21d5892671bff1e928d142de4', 'message': '[DNM] test multinode job\n\nChange-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29\n'}, {'number': 3, 'created': '2019-12-12 14:01:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4b2ee02722e483c8afe49393914e478f8c1b8084', 'message': '[DNM] test multinode job\n\nChange-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29\n'}, {'number': 4, 'created': '2019-12-12 17:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/11352353e94b845de5d7c3b608e05285efb58f38', 'message': '[DNM] test multinode job\n\nChange-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29\n'}, {'number': 5, 'created': '2019-12-16 11:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b9d7b8320fafcc1f96c860024921560f14cbdace', 'message': '[DNM] test multinode job\n\nChange-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29\n'}, {'number': 6, 'created': '2019-12-17 17:22:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a35b11671594a400b10f0ee2471fcd7227ba9c53', 'message': '[DNM] test multinode job\n\nChange-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29\n'}, {'number': 7, 'created': '2019-12-18 09:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/742148aab33ce6ebb14c614a1df0b8dd3b4ee545', 'message': '[DNM] test multinode job\n\nDepends-On: https://review.opendev.org/699338\n\nChange-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29\n'}, {'number': 8, 'created': '2019-12-18 13:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4962801c74560fa89bc1ad9759400e7fafb1c5a6', 'message': '[DNM] test multinode job\n\nChange-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29\n'}, {'number': 9, 'created': '2019-12-18 16:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/257d6c903262ff9e89a4eb49471c746610110b46', 'message': '[DNM] test multinode job\n\nChange-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29\n'}, {'number': 10, 'created': '2019-12-23 13:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9df4757450379ff8b0cd149a43dd8dc0714c40c1', 'message': '[DNM] test multinode job\n\nChange-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29\n'}, {'number': 11, 'created': '2019-12-24 14:16:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4a46ab8e1586d617b817113ab642c07bf70d0850', 'message': '[DNM] test multinode job\n\nChange-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29\n'}, {'number': 12, 'created': '2019-12-24 14:32:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/640e40e89c88ed1d5afedf228d27c3d5157a2a75', 'message': '[DNM] test multinode job\n\nChange-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29\n'}, {'number': 13, 'created': '2020-01-02 16:29:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/224af75687069c006e614d4d5f83b036c945445a', 'message': '[DNM] test multinode job\n\nChange-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29\n'}, {'number': 14, 'created': '2020-01-02 16:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9f59cee30cc31a392c5d1ea5cfa1687f503cbc46', 'message': '[DNM] test multinode job\n\nChange-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29\n'}, {'number': 15, 'created': '2020-01-02 16:33:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f51073e96f2724b07623bd4d65722b5a3f88398b', 'message': '[DNM] test multinode job\n\nChange-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29\n'}, {'number': 16, 'created': '2020-01-03 09:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6e480aa34dcb3a146ec6ab43d440eebf5849409e', 'message': '[DNM] test multinode job\n\nChange-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29\n'}, {'number': 17, 'created': '2020-01-03 09:28:11.000000000', 'files': ['playbooks/legacy/grenade-dsvm-ironic-multinode-multitenant/run.yaml', 'zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/66ac02d291173bc48c7a11cf40de5d9d1243f5f2', 'message': '[DNM] test multinode job\n\nChange-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29\n'}]",0,698696,66ac02d291173bc48c7a11cf40de5d9d1243f5f2,51,5,17,23851,,,0,"[DNM] test multinode job

Change-Id: Id849d0967ba168a6e8940d830d62e62ea1f34f29
",git fetch https://review.opendev.org/openstack/ironic refs/changes/96/698696/16 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/ironic-jobs.yaml', 'zuul.d/project.yaml']",2,1ddf0ab98d0d470d1c3d7e53852f8d257012e9f0,test-multinode, - ironic-tempest-ipa-wholedisk-direct-tinyipa-multinode - ironic-tempest-ipa-wholedisk-direct-tinyipa-multinode, templates: - check-requirements - openstack-cover-jobs - openstack-lower-constraints-jobs - openstack-python3-ussuri-jobs - periodic-stable-jobs - publish-openstack-docs-pti - release-notes-jobs-python3 - ironic-tox-unit-with-driver-libs-python3 - ironic-standalone - ironic-tempest-functional-python3 - ironic-grenade-dsvm # Temporary disable voting because of end of cycle CI instability. - ironic-grenade-dsvm-multinode-multitenant: voting: false - ironic-tempest-ipa-partition-pxe_ipmitool-tinyipa - ironic-tempest-ipa-partition-redfish-tinyipa - ironic-tempest-ipa-partition-uefi-pxe_ipmitool-tinyipa - ironic-tempest-ipa-wholedisk-direct-tinyipa-multinode: voting: false - ironic-tempest-ipa-wholedisk-bios-agent_ipmitool-tinyipa - ironic-tempest-ipa-wholedisk-bios-agent_ipmitool-tinyipa-indirect - ironic-tempest-ipa-partition-bios-agent_ipmitool-tinyipa-indirect - ironic-tempest-bfv - ironic-tempest-ipa-partition-uefi-pxe-grub2 # Non-voting jobs - ironic-tox-bandit: voting: false - ironic-tempest-ipa-wholedisk-bios-pxe_snmp-tinyipa: voting: false - ironic-inspector-tempest: voting: false - ironic-inspector-tempest-managed: voting: false - ironic-tempest-ipa-wholedisk-bios-ipmi-direct-dib-centos7: voting: false - bifrost-integration-tinyipa-ubuntu-xenial: voting: false - metalsmith-integration-glance-localboot-centos7: voting: false - ironic-tempest-pxe_ipmitool-postgres: voting: false - ironic-tox-unit-with-driver-libs-python3 - ironic-standalone - ironic-tempest-functional-python3 - ironic-grenade-dsvm # removing from voting due to end of cycle gate instability. # - ironic-grenade-dsvm-multinode-multitenant - ironic-tempest-ipa-partition-pxe_ipmitool-tinyipa - ironic-tempest-ipa-partition-redfish-tinyipa - ironic-tempest-ipa-partition-uefi-pxe_ipmitool-tinyipa # removing from voting due to end of cycle gate instability. # - ironic-tempest-ipa-wholedisk-direct-tinyipa-multinode - ironic-tempest-ipa-wholedisk-bios-agent_ipmitool-tinyipa - ironic-tempest-ipa-wholedisk-bios-agent_ipmitool-tinyipa-indirect - ironic-tempest-ipa-partition-bios-agent_ipmitool-tinyipa-indirect - ironic-tempest-bfv - ironic-tempest-ipa-partition-uefi-pxe-grub2 experimental: jobs: - ironic-inspector-tempest-discovery-fast-track: voting: false,3,63
openstack%2Fneutron~stable%2Fstein~Id019fa7649bd1158f9d56e63f8dad108d0ca8c1f,openstack/neutron,stable/stein,Id019fa7649bd1158f9d56e63f8dad108d0ca8c1f,Allow to kill keepalived state change monitor process,MERGED,2020-01-28 15:42:53.000000000,2020-01-30 16:24:38.000000000,2020-01-30 16:21:33.000000000,"[{'_account_id': 4694}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-28 15:42:53.000000000', 'files': ['etc/neutron/rootwrap.d/l3.filters'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f4d05266d21337538a2743a743ee1aa540407ac7', 'message': 'Allow to kill keepalived state change monitor process\n\nUsually Neutron stops neutron-keepalived-state-change-monitor process\ngracefully with SIGTERM.\nBut in case if this will not stop process for some time, Neutron will\ntry to kill this process with SIGKILL (-9).\nThat was causing problem with rootwrap as kill filters for this process\nallowed to send only ""-15"" to it.\nNow it is possible to kill this process with ""-9"" too.\n\nConflicts:\n    etc/neutron/rootwrap.d/l3.filters\n\nChange-Id: Id019fa7649bd1158f9d56e63f8dad108d0ca8c1f\nCloses-bug: #1860326\n(cherry picked from commit d6fccd247f70abc84c8a480138e135717836c7b3)\n'}]",0,704594,f4d05266d21337538a2743a743ee1aa540407ac7,18,6,1,11975,,,0,"Allow to kill keepalived state change monitor process

Usually Neutron stops neutron-keepalived-state-change-monitor process
gracefully with SIGTERM.
But in case if this will not stop process for some time, Neutron will
try to kill this process with SIGKILL (-9).
That was causing problem with rootwrap as kill filters for this process
allowed to send only ""-15"" to it.
Now it is possible to kill this process with ""-9"" too.

Conflicts:
    etc/neutron/rootwrap.d/l3.filters

Change-Id: Id019fa7649bd1158f9d56e63f8dad108d0ca8c1f
Closes-bug: #1860326
(cherry picked from commit d6fccd247f70abc84c8a480138e135717836c7b3)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/94/704594/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/neutron/rootwrap.d/l3.filters'],1,f4d05266d21337538a2743a743ee1aa540407ac7,bug/1860326-stable/stein,"kill_keepalived_monitor_py: KillFilter, root, python, -15, -9 kill_keepalived_monitor_py27: KillFilter, root, python2.7, -15, -9 kill_keepalived_monitor_py3: KillFilter, root, python3, -15, -9 kill_keepalived_monitor_py35: KillFilter, root, python3.5, -15, -9 kill_keepalived_monitor_py36: KillFilter, root, python3.6, -15, -9 kill_keepalived_monitor_py37: KillFilter, root, python3.7, -15, -9kill_keepalived_monitor_platform_py: KillFilter, root, /usr/libexec/platform-python, -15, -9 kill_keepalived_monitor_platform_py36: KillFilter, root, /usr/libexec/platform-python3.6, -15, -9","kill_keepalived_monitor_py: KillFilter, root, python, -15 kill_keepalived_monitor_py27: KillFilter, root, python2.7, -15 kill_keepalived_monitor_py3: KillFilter, root, python3, -15 kill_keepalived_monitor_py35: KillFilter, root, python3.5, -15 kill_keepalived_monitor_py36: KillFilter, root, python3.6, -15 kill_keepalived_monitor_py37: KillFilter, root, python3.7, -15kill_keepalived_monitor_platform_py: KillFilter, root, /usr/libexec/platform-python, -15 kill_keepalived_monitor_platform_py36: KillFilter, root, /usr/libexec/platform-python3.6, -15",8,8
openstack%2Fnova-specs~master~I95b6a3470e78ceaa05d556a9909746fbe89f05f6,openstack/nova-specs,master,I95b6a3470e78ceaa05d556a9909746fbe89f05f6,Address comments on 'flavor-extra-spec-validators' spec,MERGED,2020-01-30 15:48:50.000000000,2020-01-30 16:19:10.000000000,2020-01-30 16:16:02.000000000,"[{'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-30 15:48:50.000000000', 'files': ['specs/ussuri/approved/flavor-extra-spec-validators.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1ea1f660d94000e0d52d85e2ed7d824b06e351ec', 'message': ""Address comments on 'flavor-extra-spec-validators' spec\n\nSome follow-ups.\n\nChange-Id: I95b6a3470e78ceaa05d556a9909746fbe89f05f6\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",0,705047,1ea1f660d94000e0d52d85e2ed7d824b06e351ec,8,2,1,15334,,,0,"Address comments on 'flavor-extra-spec-validators' spec

Some follow-ups.

Change-Id: I95b6a3470e78ceaa05d556a9909746fbe89f05f6
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/47/705047/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/ussuri/approved/flavor-extra-spec-validators.rst'],1,1ea1f660d94000e0d52d85e2ed7d824b06e351ec,bp/flavor-extra-spec-validators," .. note:: In most cases this is already handled by virt drivers, though this does occur much later in the process that what this spec proposes.``flavors/{flavor_id}/os-extra_specs`` API. A microversion will be introduced for this API to avoid breaking existing tools that are inadvertently setting the wrong values. remove from nova. It is also unnecessary because the use of microversions or the ``validation`` query parameter allows users to continue using the older behavior when absolutely necessary. or the ``validation`` query parameter allows users to continue using theWe will add an API microversion to the ``flavors/{flavor_id}/os-extra_specs`` API to return HTTP 400 on invalid flavor extra specs. We will also add support for a ``validation`` query parameter to partially or fully disable this behavior, if necessary."," .. note:: In most cases this is already handled by virt drivers.API behind the :command:`openstack flavor set` command. A microversion will be introduced for this API to avoid breaking existing tools that are inadvertently setting the wrong values. remove from nova. It is also unnecessary since users can use older API microversions if necessary. and/or the ``validation`` query parameter allows users to continue using theWe will add a REST API microversion to the ``POST flavors/{flavor_id}/os-extra_specs`` API to return HTTP 400 invalid flavor extra specs. We will also add support for a ``validation`` query parameter to partially or fully disable this behavior, if necessary.",15,11
openstack%2Fironic-python-agent~master~Ief8b360d11e654d8fae3a04a2a9f8d474a06e167,openstack/ironic-python-agent,master,Ief8b360d11e654d8fae3a04a2a9f8d474a06e167,Skip read-only devices with metadata erase,MERGED,2020-01-29 04:55:04.000000000,2020-01-30 16:19:06.000000000,2020-01-30 16:14:40.000000000,"[{'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 11292}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23851}, {'_account_id': 26340}]","[{'number': 1, 'created': '2020-01-29 04:55:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/1081f2c3e5b0c6b1c5103d961bea56e88a0a6684', 'message': 'Skip read-only devices\n\nHPE ""Virtual Install Devices"" appear as read-only block\ndevices, and may... or may not be visible depending on the\nbios configuration state.\n\nThese devices can no longer be disabled from the bios settings\nso the simplest course of action seem sot be to handle the\nexistence of a read-only device.\n\nChange-Id: Ief8b360d11e654d8fae3a04a2a9f8d474a06e167\nStory: 2007229\nTask: 38502\n'}, {'number': 2, 'created': '2020-01-29 14:32:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/8a25bfc5e82e3cc1f71e5e4c162b5b9232ac268e', 'message': 'Skip read-only devices\n\nHPE ""Virtual Install Devices"" appear as read-only block\ndevices, and may... or may not be visible depending on the\nbios configuration state.\n\nThese devices can no longer be disabled from the bios settings\nso the simplest course of action seem sot be to handle the\nexistence of a read-only device.\n\nChange-Id: Ief8b360d11e654d8fae3a04a2a9f8d474a06e167\nStory: 2007229\nTask: 38502\n'}, {'number': 3, 'created': '2020-01-29 18:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/ff3586c8e41cd8a7f0ec8a4f4bc2a2c6e4fbc956', 'message': 'Skip read-only devices with metadata erase\n\nHPE ""Virtual Install Devices"" appear as read-only block\ndevices, and may... or may not be visible depending on the\nbios configuration state.\n\nThese devices can no longer be disabled from the bios settings\nso the simplest course of action seem sot be to handle the\nexistence of a read-only device.\n\nIn the event of secure erase, this is treated as a hard failure\ncase and a driver_internal_info flag has been added to enable\na future bypass method for knowledgable operators.\n\nChange-Id: Ief8b360d11e654d8fae3a04a2a9f8d474a06e167\nStory: 2007229\nTask: 38502\n'}, {'number': 4, 'created': '2020-01-29 19:41:40.000000000', 'files': ['ironic_python_agent/hardware.py', 'ironic_python_agent/tests/unit/test_hardware.py', 'releasenotes/notes/fix-cleaning-read-only-device-c8a0f4cc2f434d99.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/cd7b2693f873bde72706f8b6ab8c1f21e68f0fd1', 'message': 'Skip read-only devices with metadata erase\n\nHPE ""Virtual Install Devices"" appear as read-only block\ndevices, and may... or may not be visible depending on the\nbios configuration state.\n\nThese devices can no longer be disabled from the bios settings\nso the simplest course of action seems to be that we should\nhandle the existence of a read-only device.\n\nIn the event of secure erase, this is treated as a hard failure\ncase and a driver_internal_info flag has been added to enable\na future bypass method for knowledgable operators.\n\nChange-Id: Ief8b360d11e654d8fae3a04a2a9f8d474a06e167\nStory: 2007229\nTask: 38502\n'}]",22,704725,cd7b2693f873bde72706f8b6ab8c1f21e68f0fd1,38,8,4,11655,,,0,"Skip read-only devices with metadata erase

HPE ""Virtual Install Devices"" appear as read-only block
devices, and may... or may not be visible depending on the
bios configuration state.

These devices can no longer be disabled from the bios settings
so the simplest course of action seems to be that we should
handle the existence of a read-only device.

In the event of secure erase, this is treated as a hard failure
case and a driver_internal_info flag has been added to enable
a future bypass method for knowledgable operators.

Change-Id: Ief8b360d11e654d8fae3a04a2a9f8d474a06e167
Story: 2007229
Task: 38502
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/25/704725/4 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/hardware.py', 'ironic_python_agent/tests/unit/test_hardware.py']",2,1081f2c3e5b0c6b1c5103d961bea56e88a0a6684,704725," def test__is_read_only_device(self): fileobj = mock.mock_open(read_data='1\n') device = hardware.BlockDevice('/dev/sdfake', 'fake', 1024, False) with mock.patch( 'builtins.open', fileobj, create=True) as mock_open: self.assertTrue(self.hardware._is_read_only_device(device)) mock_open.assert_called_once_with( '/sys/block/sdfake/ro', 'r') def test__is_read_only_device_false(self): fileobj = mock.mock_open(read_data='0\n') device = hardware.BlockDevice('/dev/sdfake', 'fake', 1024, False) with mock.patch( 'builtins.open', fileobj, create=True) as mock_open: self.assertFalse(self.hardware._is_read_only_device(device)) mock_open.assert_called_once_with( '/sys/block/sdfake/ro', 'r') def test__is_read_only_device_error(self): device = hardware.BlockDevice('/dev/sdfake', 'fake', 1024, False) with mock.patch( 'builtins.open', side_effect=IOError, autospec=True) as mock_open: self.assertFalse(self.hardware._is_read_only_device(device)) mock_open.assert_called_once_with( '/sys/block/sdfake/ro', 'r') ",,56,0
openstack%2Fkayobe~master~Id7513b245d1b4eac09f717a7f47469fd7bb4d3b5,openstack/kayobe,master,Id7513b245d1b4eac09f717a7f47469fd7bb4d3b5,Update docs building,MERGED,2020-01-30 08:41:07.000000000,2020-01-30 16:00:45.000000000,2020-01-30 15:57:39.000000000,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-30 08:41:07.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/d5a3c74b1628aa77182a57c974d1fabb00b3f1a2', 'message': 'Update docs building\n\n* Use storyboard instead of launchpad since this project uses\n  storyboard. This fixes the ""Report a bug"" link.\n* Remove unneeded configuration bits for doc building, the\n  defaults of openstackdocstheme are fine.\n\nChange-Id: Id7513b245d1b4eac09f717a7f47469fd7bb4d3b5\n'}]",0,704939,d5a3c74b1628aa77182a57c974d1fabb00b3f1a2,9,4,1,6547,,,0,"Update docs building

* Use storyboard instead of launchpad since this project uses
  storyboard. This fixes the ""Report a bug"" link.
* Remove unneeded configuration bits for doc building, the
  defaults of openstackdocstheme are fine.

Change-Id: Id7513b245d1b4eac09f717a7f47469fd7bb4d3b5
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/39/704939/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,d5a3c74b1628aa77182a57c974d1fabb00b3f1a2,storyboard," #'sphinx.ext.autodoc',use_storyboard = True ","from kayobe.version import version_info as kayobe_version import os import sys sys.path.insert(0, os.path.abspath('../..')) 'sphinx.ext.autodoc', # Uncomment this to enable the OpenStack documentation style, adding # oslosphinx to test-requirements.txt. #'oslosphinx',# The version info for the project you're documenting, acts as replacement for # |version| and |release|, also used in various other places throughout the # built documents. # # The short X.Y version. # The full version, including alpha/beta/rc tags. release = kayobe_version.version_string_with_vcs() # The short X.Y version. version = kayobe_version.canonical_version_string() # Must set this variable to include year, month, day, hours, and minutes. html_last_updated_fmt = '%Y-%m-%d %H:%M' # TODO(mgoddard): Change to openstack/kayobe.bug_project = 'kayobe' bug_tag = ''",3,25
openstack%2Fbifrost~stable%2Fstein~I5aaab91f0590c49972e5eb03d1c70559698b2f39,openstack/bifrost,stable/stein,I5aaab91f0590c49972e5eb03d1c70559698b2f39,Check out global requirements when creating test VMs,MERGED,2020-01-29 14:45:33.000000000,2020-01-30 15:54:11.000000000,2020-01-30 15:50:53.000000000,"[{'_account_id': 6618}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 14:45:33.000000000', 'files': ['playbooks/roles/bifrost-create-vm-nodes/tasks/main.yml', 'playbooks/roles/bifrost-create-vm-nodes/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/981a0363223e98d188a20d029f008db139db0536', 'message': 'Check out global requirements when creating test VMs\n\nAs part of the test VM preparation, we need to use upper-constraints.\n\nChange-Id: I5aaab91f0590c49972e5eb03d1c70559698b2f39\n(cherry picked from commit 6da10694af43d9902a13b2e7a1c6e4b587a5ce57)\n'}]",0,704823,981a0363223e98d188a20d029f008db139db0536,7,2,1,10239,,,0,"Check out global requirements when creating test VMs

As part of the test VM preparation, we need to use upper-constraints.

Change-Id: I5aaab91f0590c49972e5eb03d1c70559698b2f39
(cherry picked from commit 6da10694af43d9902a13b2e7a1c6e4b587a5ce57)
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/23/704823/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-create-vm-nodes/tasks/main.yml', 'playbooks/roles/bifrost-create-vm-nodes/defaults/main.yml']",2,981a0363223e98d188a20d029f008db139db0536,," git_branch: master git_root: ""/opt/stack"" reqs_git_url: https://opendev.org/openstack/requirements reqs_git_folder: ""{{ git_root }}/requirements"" reqs_git_branch: ""{{ git_branch }}"" # Conditional variables utilized based on CI or manual testing options. copy_from_local_path: false ci_testing_zuul: false",reqs_git_folder: /opt/stack/requirements,39,1
openstack%2Fkolla~master~I66c93e07fe5c6c143e9cf65c6451e573bbfc51d8,openstack/kolla,master,I66c93e07fe5c6c143e9cf65c6451e573bbfc51d8,CI: Fix tag suffix logic for CentOS 8,MERGED,2020-01-30 12:22:11.000000000,2020-01-30 15:52:29.000000000,2020-01-30 15:48:37.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-30 12:22:11.000000000', 'files': ['tests/templates/kolla-build.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/cde5405b90ca18fcc498afd9cd09a7e7fd68b6f2', 'message': ""CI: Fix tag suffix logic for CentOS 8\n\nOn CentOS, ansible_distribution is 'CentOS' rather than 'centos'.\nOur logic when setting the image tag for publisher jobs is incorrect,\nmeaning that the centos8 publisher publishes images as 'master'\nrather than 'master-centos8'. Since this job only has two images it\nis likely to complete before the CentOS 7 publisher, so hopefully\nimages will not be broken for long.\n\nThis change fixes the issue by using a case-insensitive comparison.\n\nChange-Id: I66c93e07fe5c6c143e9cf65c6451e573bbfc51d8\nPartially-Implements: blueprint centos-rhel-8\n""}]",0,704987,cde5405b90ca18fcc498afd9cd09a7e7fd68b6f2,10,4,1,14826,,,0,"CI: Fix tag suffix logic for CentOS 8

On CentOS, ansible_distribution is 'CentOS' rather than 'centos'.
Our logic when setting the image tag for publisher jobs is incorrect,
meaning that the centos8 publisher publishes images as 'master'
rather than 'master-centos8'. Since this job only has two images it
is likely to complete before the CentOS 7 publisher, so hopefully
images will not be broken for long.

This change fixes the issue by using a case-insensitive comparison.

Change-Id: I66c93e07fe5c6c143e9cf65c6451e573bbfc51d8
Partially-Implements: blueprint centos-rhel-8
",git fetch https://review.opendev.org/openstack/kolla refs/changes/87/704987/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/templates/kolla-build.conf.j2'],1,cde5405b90ca18fcc498afd9cd09a7e7fd68b6f2,bp/centos-rhel-8,{% set tag_suffix = '-centos8' if ansible_distribution | lower == 'centos' and ansible_distribution_major_version == '8' else '' %},{% set tag_suffix = '-centos8' if ansible_distribution == 'centos' and ansible_distribution_major_version == '8' else '' %},1,1
openstack%2Fnova-specs~master~I1b3b74f1fd2af9419f7aa0c79b5dad5b26065b57,openstack/nova-specs,master,I1b3b74f1fd2af9419f7aa0c79b5dad5b26065b57,Re-propose the flavor extra spec validation spec,MERGED,2019-09-17 14:04:22.000000000,2020-01-30 15:51:29.000000000,2020-01-30 15:46:17.000000000,"[{'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 14070}, {'_account_id': 15334}, {'_account_id': 21672}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-17 14:04:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/45e145a1da9e2ae445041d1018dd5d03c144b797', 'message': ""Re-propose the flavor extra spec validation spec\n\nPreviously known as the (rather lengthy)\n'flavor-extra-spec-image-property-validation-extended' spec.\n\nPart of bp flavor-extra-spec-validators\n\nChange-Id: I1b3b74f1fd2af9419f7aa0c79b5dad5b26065b57\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2020-01-29 11:08:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d0b3c4d3b86a6869d802d4ccb50b5c22c89c0a21', 'message': ""Re-propose the flavor extra spec validation spec\n\nPreviously known as the (rather lengthy)\n'flavor-extra-spec-image-property-validation-extended' spec.\n\nPart of bp flavor-extra-spec-validators\n\nChange-Id: I1b3b74f1fd2af9419f7aa0c79b5dad5b26065b57\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 3, 'created': '2020-01-29 11:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/afb4ad2ae4068c8af0467a93e627c6434b7f767a', 'message': ""Re-propose the flavor extra spec validation spec\n\nPreviously known as the (rather lengthy)\n'flavor-extra-spec-image-property-validation-extended' spec.\n\nPart of bp flavor-extra-spec-validators\n\nChange-Id: I1b3b74f1fd2af9419f7aa0c79b5dad5b26065b57\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 4, 'created': '2020-01-30 12:09:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/96b4186a0f801c287ab77ca2390c60c3b9f426a1', 'message': ""Re-propose the flavor extra spec validation spec\n\nPreviously known as the (rather lengthy)\n'flavor-extra-spec-image-property-validation-extended' spec.\n\nPart of bp flavor-extra-spec-validators\n\nChange-Id: I1b3b74f1fd2af9419f7aa0c79b5dad5b26065b57\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 5, 'created': '2020-01-30 12:43:34.000000000', 'files': ['specs/ussuri/approved/flavor-extra-spec-validators.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/90f006e96c2c42d10e1ce8b78d514ec9f15b670b', 'message': ""Re-propose the flavor extra spec validation spec\n\nPreviously known as the (rather lengthy)\n'flavor-extra-spec-image-property-validation-extended' spec.\n\nPart of bp flavor-extra-spec-validators\n\nChange-Id: I1b3b74f1fd2af9419f7aa0c79b5dad5b26065b57\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",105,682655,90f006e96c2c42d10e1ce8b78d514ec9f15b670b,48,7,5,15334,,,0,"Re-propose the flavor extra spec validation spec

Previously known as the (rather lengthy)
'flavor-extra-spec-image-property-validation-extended' spec.

Part of bp flavor-extra-spec-validators

Change-Id: I1b3b74f1fd2af9419f7aa0c79b5dad5b26065b57
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/55/682655/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/ussuri/approved/flavor-extra-spec-validators.rst'],1,45e145a1da9e2ae445041d1018dd5d03c144b797,bp/flavor-extra-spec-validators,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================== Flavor Extra Spec Validator =========================== https://blueprints.launchpad.net/nova/+spec/flavor-extra-spec-validators Introduce a pluggable system to describe and validate flavor extra specs. Problem description =================== Flavor extra specs are one of the Wild West aspects of nova. There are a number of issues we'd like to address: - Lack of documentation for many flavor extra specs [1]_. While, Glance has metadefs [2]_, those are generally out-of-date, incomplete, and not consumable from nova and our user-facing documentation. - No warnings if there is a typo in your extra spec, resulting in different behavior to that expected. - No defined way to do things like deprecate a flavor extra spec, resulting in continued reinvention of the wheel. Use Cases --------- * As a deployer, I'd like to know what flavor extra specs and image metadata properties are available and why I'd want to use them. * As a deployer, I'd like nova to tell me when I've used a flavor extra spec that doesn't exist or has a typo in it. * As a developer, I'd like an easy way to deprecate flavor extra specs, which is something that will only become more common if we do things like move tracking of dedicated CPUs into placement. * As a documentation writer, I'd like to be able to cross-reference the various flavor extra specs and image metadata properties available. Proposed change =============== A flavor extra spec is a key-value pair. For example:: hw:cpu_policy=dedicated Different solutions are needed to validate the *value* part of an extra spec compared to the *key* part. This spec aims to tackle validation of both *key* and *value*, starting with the latter and then moving onto the former. The following are considered out-of-scope for this change: - Enforcement of extra spec dependencies. For example, if extra spec A requires extra spec B be configured first. We will document the dependency but it won't be enforced. - Enforcement of virt driver dependencies. Unfortunately, while flavor extra specs should be generic, this isn't always the case. As above, we will document this dependency but it won't be enforced. - Hard enforcement of key validation. Eventually we will want to track all possible extra spec names and raise a warning or error for errant values, but this is likely to take some time to perfect. In the interim, we will merely log these potentially errant values. This change builds upon `Flavor extra spec image metadata validation <http://specs.openstack.org/openstack/nova-specs/specs/stein/implemented/flavor-extra-spec-image-property-validation.html>`__, which covers some of these issues for us. Value validation ---------------- Value validation is the easier of the two issues to tackle. It will resolve issues like the following in a generic manner:: hw:cpu_policy=deddddicated For a generic extra spec, a definition of a validator will need to contain the following: - Name or *key* of the extra spec, e.g. ``cpu_policy`` for the above example - Namespace of the extra spec, e.g. ``hw`` for the above example - Description of the extra spec - Support status of the extra spec - Valid values; whether it's an integer, a free-form string, a string matching a given regex, an enum, or something else entirely - Virt driver dependencies; this is only for documentation purposes and will not be enforced - Extra spec dependencies; this is only for documentation purposes and will not be enforced For many extra specs namespaces, we propose maintaining the definitions in-tree. To do this, we propose adding a new module, ``nova.api.validation.extra_specs``, which will contain definitions for *flavor validators*. These will be defined using two new base objects, ``BaseValidator`` and ``BaseExtraSpec``. ``BaseValidator`` will be subclassed to represent a namespace while ``BaseExtraSpec`` will be subclassed to represent an individual extra spec. ``BaseExtraSpec`` subclasses will be registered again a namespace. For example: .. code-block:: python class HWValidator(BaseValidator): """"""A validator for the ``hw`` namespace."""""" name = 'hw' description = ( 'Extra specs that modify behavior of the virtual hardware ' 'associated with instances.' ) class CPUPolicy(BaseExtraSpec): """"""A validator for the ``hw:cpu_policy`` extra spec."""""" name = 'cpu_policy' description = ( 'The policy to apply when determining what host CPUs the guest ' 'CPUs can run on. If ``shared`` (default), guest CPUs can be ' 'overallocated but cannot float across host cores. If ' '``dedicated``, guest CPUs cannot be overallocated but are ' 'individually pinned to their own host core.' ) deprecated = True value = { 'type': str, 'description': 'The CPU policy.', 'enum': [ 'dedicated', 'shared' ], } class NUMACPUs(BaseExtraSpec): """"""A validator for the ``hw:numa_cpu.{id}`` extra spec."""""" name = 'numa_cpu.{id}' description = ( 'A mapping of **guest** CPUs to the **guest** NUMA node ' 'identified by ``{id}``. This can be used to provide asymmetric ' 'CPU-NUMA allocation and is necessary where the number of guest ' 'NUMA nodes is is not a factor of the number of guest CPUs.' ) params = [ { 'name': 'id', 'type': int, 'description': 'The ID of the **guest** NUMA node.', }, ] value = { 'type': str, 'description': ( 'The guest CPUs, in the form of a CPU map, to allocate to the ' 'guest NUMA node identified by ``{id}``.' ), 'pattern': r'\d+((-\d+)?(,\^?\d+(-\d+)?)?)*', } register(HWValidator, CPUPolicy) register(HWValdiator, NUMACPUs) While many of the definitions will be maintained in-tree, some namespaces will require special handling as they're owned by external services, e.g. the ``traits`` namespace (owned by os-traits) or the ``accel`` namespace (proposed for use by cyborg). For these, we propose using `stevedore`_ to allow external projects to register custom validators. For example, nova would provide the following: .. code-block:: ini nova.extra_spec_validators = hw = nova.api.validation.extra_specs:HWValidator os = nova.api.validation.extra_specs:OSValidator traits = nova.api.validation.extra_specs:TraitsValidator resources = nova.api.validation.extra_specs:ResourcesValidator custom = nova.validators.extra_specs:NoopValidator * = nova.validators.extra_specs:YAMLValidator Cyborg could extend this by providing something like the following: .. code-block:: ini nova.extra_spec_validators = accel = cyborg.extra_specs_validator:AccelValidator Finally, there are extra specs that are operator defined and therefore will not be known by a consuming service. For these, we propose introducing a schema definition file. This a YAML-formatted file, which describes the flavor extra specs available. The YAML format is chosen as it allows us to define a specification in a declarative manner while avoiding the need to write Python code. The format of this file will nonetheless mirror the format of the Python objects. For example: .. code-block:: yaml --- version: 1.0 metadata: - name: numa_nodes namspace: hw description: > The number of NUMA nodes the instance should have. value: type: integer description: > The number of NUMA nodes the instance should have. - name: numa_cpus.{id} namspace: hw description: > A mapping of **guest** CPUs to the **guest** NUMA node identified by ``{id}``. This can be used to provide asymmetric CPU-NUMA allocation and is necessary where the number of guest NUMA nodes is is not a factor of the number of guest CPUs. parameters: - name: id type: integer description: > The ID of the **guest** NUMA node. value: type: string format: '\d+((-\d+)?(,\^?\d+(-\d+)?)?)*' description: > The guest CPUs, in the form of a CPU map, to allocate to the guest NUMA node identified by ``{id}``. Regardless of the source of the extra spec validator, they will be used by the API behind the :command:`openstack flavor set` command. A microversion will be introduced for this command to avoid breaking existing tools that are inadvertently setting the wrong values. .. _stevedore: https://docs.openstack.org/stevedore/latest Key validation -------------- We also want to be able to catch invalid extra specs themselves. It will resolve issues like the following in a generic manner:: hw:cpu_pollllicy=dedicated This involves maintaining a registry of valid extra specs. Not all extra specs can be known ahead of time and for dynamic extra specs, such as those proposed in `Support filtering by forbidden aggregate membership <http://specs.openstack.org/openstack/nova-specs/specs/stein/approved/negative-aggregate-membership.html>`. For these, we can rely on a custom namespace validator or YAML specification provided by the operator. However, completing this registry both in-tree and out-of-tree is expected to be a complex endeavour and for this reason we won't enforce validation of keys as part of this spec. Other changes ------------- We also propose adding tooling to (a) render reStructuredText documentation from the definitions and (b) convert the definitions into Glance metadata definition files. Both of these tools will live within the nova tree, allowing us to remain the single source of truth for these things. Alternatives ------------ * We could ignore some of the above issues and try to solve others in a piecemeal fashion. This will likely be far more tedious and time consuming as modifications will be needed in far more places. Data model impact ----------------- None. REST API impact --------------- We will add a REST API microversion to the ``POST flavors/{flavor_d}/os-extra_specs`` API to catch invalid flavor extra specs. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- End users will have better documentation for the available flavor extra specs and image metadata properties. Performance Impact ------------------ None. Other deployer impact --------------------- Operators will now need to add new flavor extra specs to the YAML schema file or they will see errors when using the new API microversion. Developer impact ---------------- Developers should now add new flavor extra specs to the ``nova.compute.extra_specs`` module to take advantage of the validation available. Upgrade impact -------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: stephenfinucane Other contributors: None Work Items ---------- 1. Produce extra spec definitions for all in-tree flavor extra specs. 2. Add code to validate this against the image metadata properties and flavor extra specs on instance create, resize and rebuild operations. 3. Add a Sphinx extension to render this spec into documentation and another tool to convert the spec into Glance metadata definitions. 4. Add parser for YAML-formatted definitions and document how operators can and should use this. 5. Add a tool to generate glance-metadef compatible JSON files that can be consumed by the glance metadata definitions catalog API. Dependencies ============ None. Testing ======= Unit tests. Documentation Impact ==================== There will be better docs, through the power of Sphinx. References ========== .. [1] https://docs.openstack.org/image-guide/image-metadata.html#metadata-definition-service .. [2] https://github.com/openstack/glance/blob/18.0.0/etc/metadefs/compute-libvirt.json History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Train - Introduced * - Ussuri - Re-proposed with a simpler name and minor modifications ",,395,0
openstack%2Fpython-heatclient~master~I1404a5b23fd1852be9d04661c2a0ba12c4bb78ec,openstack/python-heatclient,master,I1404a5b23fd1852be9d04661c2a0ba12c4bb78ec,tests: Pre-mox removal cleanup,MERGED,2020-01-30 11:32:06.000000000,2020-01-30 15:41:20.000000000,2020-01-30 15:38:10.000000000,"[{'_account_id': 4257}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-30 11:32:06.000000000', 'files': ['heatclient/tests/unit/test_resources.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/75ed1cedd9c3820134b877008750c4a28e28e2a0', 'message': 'tests: Pre-mox removal cleanup\n\nMove some stuff around in order to make the later migration easier to\nparse.\n\nChange-Id: I1404a5b23fd1852be9d04661c2a0ba12c4bb78ec\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",0,704968,75ed1cedd9c3820134b877008750c4a28e28e2a0,7,2,1,15334,,,0,"tests: Pre-mox removal cleanup

Move some stuff around in order to make the later migration easier to
parse.

Change-Id: I1404a5b23fd1852be9d04661c2a0ba12c4bb78ec
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/68/704968/1 && git format-patch -1 --stdout FETCH_HEAD,['heatclient/tests/unit/test_resources.py'],1,75ed1cedd9c3820134b877008750c4a28e28e2a0,remove-mox,"class FakeAPI(object): """"""Fake API and ensure request url is correct."""""" def __init__(self, expect, key): self.expect = expect self.key = key def get(self, *args, **kwargs): assert ('GET', args[0]) == self.expect def json_request(self, *args, **kwargs): assert args == self.expect ret = self.key and {self.key: []} or {} return {}, {self.key: ret} def raw_request(self, *args, **kwargs): assert args == self.expect return {} def head(self, url, **kwargs): return self.json_request(""HEAD"", url, **kwargs) def post(self, url, **kwargs): return self.json_request(""POST"", url, **kwargs) def put(self, url, **kwargs): return self.json_request(""PUT"", url, **kwargs) def delete(self, url, **kwargs): return self.raw_request(""DELETE"", url, **kwargs) def patch(self, url, **kwargs): return self.json_request(""PATCH"", url, **kwargs) manager = resources.ResourceManager(FakeAPI(expect, key)) def _test_list(self, fields, expect): key = 'resources' class FakeResponse(object): def json(self): return {key: {}} class FakeClient(object): def get(self, *args, **kwargs): assert args[0] == expect return FakeResponse() manager = resources.ResourceManager(FakeClient()) manager.list(**fields) "," class FakeAPI(object): """"""Fake API and ensure request url is correct."""""" def get(self, *args, **kwargs): assert ('GET', args[0]) == expect def json_request(self, *args, **kwargs): assert args == expect ret = key and {key: []} or {} return {}, {key: ret} def raw_request(self, *args, **kwargs): assert args == expect return {} def head(self, url, **kwargs): return self.json_request(""HEAD"", url, **kwargs) def post(self, url, **kwargs): return self.json_request(""POST"", url, **kwargs) def put(self, url, **kwargs): return self.json_request(""PUT"", url, **kwargs) def delete(self, url, **kwargs): return self.raw_request(""DELETE"", url, **kwargs) def patch(self, url, **kwargs): return self.json_request(""PATCH"", url, **kwargs) manager = resources.ResourceManager(FakeAPI()) def _test_list(self, fields, expect): key = 'resources' class FakeResponse(object): def json(self): return {key: {}} class FakeClient(object): def get(self, *args, **kwargs): assert args[0] == expect return FakeResponse() manager = resources.ResourceManager(FakeClient()) manager.list(**fields) ",51,47
openstack%2Fironic-python-agent-builder~master~Idfb8b121a43a0bb74844fd63d5c2507d7b888b15,openstack/ironic-python-agent-builder,master,Idfb8b121a43a0bb74844fd63d5c2507d7b888b15,Fix pip install pkgs with non-ascii characters in filenames,MERGED,2020-01-30 11:11:55.000000000,2020-01-30 15:39:39.000000000,2020-01-30 15:37:59.000000000,"[{'_account_id': 10239}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-01-30 11:11:55.000000000', 'files': ['dib/ironic-python-agent-ramdisk/install.d/ironic-python-agent-ramdisk-source-install/60-ironic-python-agent-ramdisk-install'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/22a12a3a41108bc0684ad9c0436b5de395c0b6e0', 'message': 'Fix pip install pkgs with non-ascii characters in filenames\n\nAs found recently, pip with Python 3.6 and forward has some issues\ninstalling tarballs that contain files with non-ascii characters\nin their names.\nThis is due mainly to the fact that the default locale in the\nsystem is set to C [1].\nAs a workaround, we run the installation of the packages in the\nvirtualenv forcing C.UTF-8 locale.\n\n[1] https://github.com/pypa/pip/issues/7667\n\nChange-Id: Idfb8b121a43a0bb74844fd63d5c2507d7b888b15\n'}]",0,704961,22a12a3a41108bc0684ad9c0436b5de395c0b6e0,10,4,1,23851,,,0,"Fix pip install pkgs with non-ascii characters in filenames

As found recently, pip with Python 3.6 and forward has some issues
installing tarballs that contain files with non-ascii characters
in their names.
This is due mainly to the fact that the default locale in the
system is set to C [1].
As a workaround, we run the installation of the packages in the
virtualenv forcing C.UTF-8 locale.

[1] https://github.com/pypa/pip/issues/7667

Change-Id: Idfb8b121a43a0bb74844fd63d5c2507d7b888b15
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/61/704961/1 && git format-patch -1 --stdout FETCH_HEAD,['dib/ironic-python-agent-ramdisk/install.d/ironic-python-agent-ramdisk-source-install/60-ironic-python-agent-ramdisk-install'],1,22a12a3a41108bc0684ad9c0436b5de395c0b6e0,fix-locale,export LC_ALL=C.UTF-8 ,,2,0
openstack%2Fneutron~master~Ic70f7d282db478c69016ab1c317c5cae786401ce,openstack/neutron,master,Ic70f7d282db478c69016ab1c317c5cae786401ce,Implement tagging during bulk port creation,MERGED,2019-12-30 01:49:25.000000000,2020-01-30 15:30:30.000000000,2020-01-30 15:26:44.000000000,"[{'_account_id': 841}, {'_account_id': 4694}, {'_account_id': 8313}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 15554}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-12-30 01:49:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d7a2ed53806b51f411838df3fed58c1902c50e3', 'message': 'Implement tagging during bulk port creation\n\nThis change proposes a ML2 plugin extension to implement tagging during\nbulk port creation.\n\nChange-Id: Ic70f7d282db478c69016ab1c317c5cae786401ce\nRelated-Bug: #1815933\n'}, {'number': 2, 'created': '2019-12-30 23:16:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6f440694b376673baab884f5d509b20d7ead102f', 'message': 'Implement tagging during bulk port creation\n\nThis change proposes a ML2 plugin extension to implement tagging during\nbulk port creation.\n\nChange-Id: Ic70f7d282db478c69016ab1c317c5cae786401ce\nRelated-Bug: #1815933\n'}, {'number': 3, 'created': '2020-01-02 23:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c6f95d0e2016b3ef76471b598f2076ce5e87d4af', 'message': 'Implement tagging during bulk port creation\n\nThis change proposes a ML2 plugin extension to implement tagging during\nbulk port creation.\n\nChange-Id: Ic70f7d282db478c69016ab1c317c5cae786401ce\nRelated-Bug: #1815933\n'}, {'number': 4, 'created': '2020-01-03 01:36:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c42edbbf0cd659d5be2fbe9b91b93e498a4e64fd', 'message': 'Implement tagging during bulk port creation\n\nThis change proposes a ML2 plugin extension to implement tagging during\nbulk port creation.\n\nChange-Id: Ic70f7d282db478c69016ab1c317c5cae786401ce\nRelated-Bug: #1815933\n'}, {'number': 5, 'created': '2020-01-04 01:28:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9e0f1f2f4a1e061f27825c4a371b4e929513133e', 'message': 'Implement tagging during bulk port creation\n\nThis change proposes a ML2 plugin extension to implement tagging during\nbulk port creation.\n\nChange-Id: Ic70f7d282db478c69016ab1c317c5cae786401ce\nRelated-Bug: #1815933\n'}, {'number': 6, 'created': '2020-01-04 22:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/31839fb315e93b2986322aec2d7effbe6ea220b1', 'message': 'Implement tagging during bulk port creation\n\nThis change proposes a ML2 plugin extension to implement tagging during\nbulk port creation.\n\nChange-Id: Ic70f7d282db478c69016ab1c317c5cae786401ce\nRelated-Bug: #1815933\n'}, {'number': 7, 'created': '2020-01-12 23:36:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/182cc110089ae86154907a3f22144e7721fe6167', 'message': 'Implement tagging during bulk port creation\n\nThis change proposes a ML2 plugin extension to implement tagging during\nbulk port creation.\n\nChange-Id: Ic70f7d282db478c69016ab1c317c5cae786401ce\nRelated-Bug: #1815933\n'}, {'number': 8, 'created': '2020-01-12 23:58:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2396f23a5eddd125b434f96687973b28c15c8c59', 'message': 'Implement tagging during bulk port creation\n\nThis change proposes a ML2 plugin extension to implement tagging during\nbulk port creation.\n\nChange-Id: Ic70f7d282db478c69016ab1c317c5cae786401ce\nRelated-Bug: #1815933\n'}, {'number': 9, 'created': '2020-01-13 18:34:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/66b111cac1572ba8fc315397dd83bae26e4e6b7a', 'message': 'Implement tagging during bulk port creation\n\nThis change proposes a ML2 plugin extension to implement tagging during\nbulk port creation.\n\nChange-Id: Ic70f7d282db478c69016ab1c317c5cae786401ce\nRelated-Bug: #1815933\n'}, {'number': 10, 'created': '2020-01-26 02:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/210372995bd6fb491d583f4360a8985bad37638b', 'message': 'Implement tagging during bulk port creation\n\nThis change proposes a ML2 plugin extension to implement tagging during\nbulk port creation.\n\nChange-Id: Ic70f7d282db478c69016ab1c317c5cae786401ce\nRelated-Bug: #1815933\n'}, {'number': 11, 'created': '2020-01-27 01:03:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b0404375fe77548128c63939b9da59fa8c11b9d6', 'message': 'Implement tagging during bulk port creation\n\nThis change proposes a ML2 plugin extension to implement tagging during\nbulk port creation.\n\nChange-Id: Ic70f7d282db478c69016ab1c317c5cae786401ce\nRelated-Bug: #1815933\n'}, {'number': 12, 'created': '2020-01-27 17:46:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aa741b8dc66ccc0789a4c23b133938fe9b75962b', 'message': 'Implement tagging during bulk port creation\n\nThis change proposes a ML2 plugin extension to implement tagging during\nbulk port creation.\n\nChange-Id: Ic70f7d282db478c69016ab1c317c5cae786401ce\nRelated-Bug: #1815933\n'}, {'number': 13, 'created': '2020-01-29 00:25:00.000000000', 'files': ['neutron/plugins/ml2/extensions/tag_ports_during_bulk_creation.py', 'neutron/tests/contrib/hooks/api_all_extensions', 'neutron/extensions/tag_ports_during_bulk_creation.py', 'neutron/services/tag/tag_plugin.py', 'releasenotes/notes/tag-ports-during-bulk-creation-23161dd39d779e99.yaml', 'neutron/extensions/tagging.py', 'setup.cfg', 'neutron/tests/unit/plugins/ml2/extensions/test_tag_ports_during_bulk_creation.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e22a191f47fe0d1a05cd707a0ad6a1ca637f69d1', 'message': 'Implement tagging during bulk port creation\n\nThis change proposes a ML2 plugin extension to implement tagging during\nbulk port creation.\n\nChange-Id: Ic70f7d282db478c69016ab1c317c5cae786401ce\nRelated-Bug: #1815933\n'}]",21,700755,e22a191f47fe0d1a05cd707a0ad6a1ca637f69d1,82,11,13,4694,,,0,"Implement tagging during bulk port creation

This change proposes a ML2 plugin extension to implement tagging during
bulk port creation.

Change-Id: Ic70f7d282db478c69016ab1c317c5cae786401ce
Related-Bug: #1815933
",git fetch https://review.opendev.org/openstack/neutron refs/changes/55/700755/9 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/extensions/tag_ports_during_bulk_creation.py', 'neutron/extensions/_tag_ports_during_bulk_creation.py']",2,6d7a2ed53806b51f411838df3fed58c1902c50e3,tag-ports-during-bulk-creation,"# Copyright (c) 2019 Verizon Media # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" TODO(mlavalle): This module should be deleted once neutron-lib containing https://review.opendev.org/#/c/700754/ change is released. """""" ALIAS = 'tag-ports-during-bulk-creation' IS_SHIM_EXTENSION = True IS_STANDARD_ATTR_EXTENSION = False NAME = 'Tag Ports During Bulk Creation' DESCRIPTION = 'Allow to tag ports during bulk creation' UPDATED_TIMESTAMP = '2019-12-29T19:00:00-00:00' RESOURCE_ATTRIBUTE_MAP = {} SUB_RESOURCE_ATTRIBUTE_MAP = {} ACTION_MAP = {} REQUIRED_EXTENSIONS = [] OPTIONAL_EXTENSIONS = [] ACTION_STATUS = {} ",,68,0
openstack%2Fopenstack-ansible-os_tempest~stable%2Ftrain~I0f6819ca73dd5a37a21ade150953acfe6e864a89,openstack/openstack-ansible-os_tempest,stable/train,I0f6819ca73dd5a37a21ade150953acfe6e864a89,Use contraints for tempest plugins,ABANDONED,2020-01-21 13:02:16.000000000,2020-01-30 15:28:43.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25023}]","[{'number': 1, 'created': '2020-01-21 13:02:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/94433f2eeb67ed57de09d9c886610e4c7569366c', 'message': 'Use contraints for tempest plugins\n\nChange-Id: I0f6819ca73dd5a37a21ade150953acfe6e864a89\n'}, {'number': 2, 'created': '2020-01-22 14:44:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/8fd265eb102a085e1f6b80bea96ec2d9de28b96f', 'message': 'Use contraints for tempest plugins\n\nChange-Id: I0f6819ca73dd5a37a21ade150953acfe6e864a89\n'}, {'number': 3, 'created': '2020-01-22 20:06:18.000000000', 'files': ['tasks/tempest_install_source.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/f485bc0ad3528779894def8357160e6f988c72d1', 'message': 'Use contraints for tempest plugins\n\nThis patch temporarily defines the u-c file URL to break a circular\ndependancy and should be reverted later.\n\nChange-Id: I0f6819ca73dd5a37a21ade150953acfe6e864a89\n'}]",0,703607,f485bc0ad3528779894def8357160e6f988c72d1,11,3,3,25023,,,0,"Use contraints for tempest plugins

This patch temporarily defines the u-c file URL to break a circular
dependancy and should be reverted later.

Change-Id: I0f6819ca73dd5a37a21ade150953acfe6e864a89
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/07/703607/2 && git format-patch -1 --stdout FETCH_HEAD,['tasks/tempest_install_source.yml'],1,94433f2eeb67ed57de09d9c886610e4c7569366c,, --constraint {{ tempest_upper_constraints_url }},,1,0
openstack%2Fopenstack-ansible~stable%2Ftrain~I7525b6e415727df3f8903f5536403fe123ec834e,openstack/openstack-ansible,stable/train,I7525b6e415727df3f8903f5536403fe123ec834e,Use nova_placement_service_password for placement_service_password,MERGED,2020-01-29 16:40:44.000000000,2020-01-30 15:21:04.000000000,2020-01-30 15:18:48.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2020-01-29 16:40:44.000000000', 'files': ['scripts/upgrade-utilities/deploy-config-changes.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0fef9ba5ac40b4b9531332583ff0dac55d03d391', 'message': ""Use nova_placement_service_password for placement_service_password\n\nDoring migration placement password is being changed, which results in\ntemporary outage. This should minimize downtime of placement during\nit's extraction\n\nChange-Id: I7525b6e415727df3f8903f5536403fe123ec834e\n""}]",0,704842,0fef9ba5ac40b4b9531332583ff0dac55d03d391,8,3,1,28619,,,0,"Use nova_placement_service_password for placement_service_password

Doring migration placement password is being changed, which results in
temporary outage. This should minimize downtime of placement during
it's extraction

Change-Id: I7525b6e415727df3f8903f5536403fe123ec834e
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/42/704842/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/upgrade-utilities/deploy-config-changes.yml'],1,0fef9ba5ac40b4b9531332583ff0dac55d03d391,placement_migration," line: ""{{ item }}{% if (item == 'placement_service_password:') %} {{ nova_placement_service_password }}{% endif %}"""," line: ""{{ item }}""",1,1
openstack%2Fcinder~master~Ica56833a1d9fb9f47b922dbbc6558901bb3a2800,openstack/cinder,master,Ica56833a1d9fb9f47b922dbbc6558901bb3a2800,Support multiple stores of Glance,MERGED,2019-05-28 05:41:25.000000000,2020-01-30 15:18:11.000000000,2020-01-29 00:57:32.000000000,"[{'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 9008}, {'_account_id': 9303}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12988}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 18002}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 20813}, {'_account_id': 21767}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22078}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27336}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}, {'_account_id': 30590}, {'_account_id': 30688}]","[{'number': 1, 'created': '2019-05-28 05:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d4b2a61c0e80d94af0e1087330007bd7e133fd48', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 2, 'created': '2019-08-05 10:34:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5c6167ecf19572c9d46a5a83fe3ad0391e851432', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 3, 'created': '2019-08-07 06:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8ce73d366f13487836996bbeb67e7a383a76ad19', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 4, 'created': '2019-09-05 06:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4951a41f000d478c7371a1f975c811dabf9e6b1d', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 5, 'created': '2019-11-14 06:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/832e1d8d621759a095b04e8c3562d1b2d176d755', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 6, 'created': '2019-11-22 05:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/044ffc21cef4964dc88d7227478cc1b03f68077b', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 7, 'created': '2019-11-25 07:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e2a8a9963b5c1374cfe5640c371ca2235c68db7f', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 8, 'created': '2019-11-25 07:31:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5164b25db251d24f5f34e6b36d45d0b4aa763f00', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 9, 'created': '2019-11-27 09:43:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/60e11bbc65b1cd3feab9dec946a188082dbbee4a', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 10, 'created': '2019-11-28 08:32:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/65297b97a9be7b3186b0b647982fdf668e2fd496', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 11, 'created': '2019-12-03 05:41:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/61b283c99b105360295d0e7d56fb2524995bedca', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 12, 'created': '2019-12-04 05:37:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1fea238f9faa4b76edf7c25237a01652cc86fa12', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 13, 'created': '2019-12-11 08:55:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c81406a51f3b4aa55b36301b8534006cc1a56bb4', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 14, 'created': '2019-12-11 12:52:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ad6fb28fa4dd6aca27b8f62a4ef783215b659240', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 15, 'created': '2019-12-11 13:10:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8afe578dc7f38fb805c9b3fbf2a48660304902a0', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 16, 'created': '2019-12-12 05:30:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/97f2062d785d49e60d2f97921234202f344154e8', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 17, 'created': '2019-12-20 06:28:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7310cb9ac43887128d204d5ffc1964ce946db120', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 18, 'created': '2020-01-10 08:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/89a318d407504c4c46e768047a1ac028af155bb1', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 19, 'created': '2020-01-16 05:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/492482044cb254facf8c4cc864c6f6b06e7ccb2e', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}, {'number': 20, 'created': '2020-01-21 06:03:01.000000000', 'files': ['cinder/tests/unit/volume/drivers/vmware/test_vmware_vmdk.py', 'cinder/volume/manager.py', 'cinder/tests/unit/volume/test_image.py', 'cinder/tests/unit/volume/drivers/vmware/test_fcd.py', 'cinder/api/contrib/types_extra_specs.py', 'cinder/volume/drivers/linstordrv.py', 'cinder/tests/unit/image/fake.py', 'cinder/tests/unit/volume/drivers/test_gpfs.py', 'cinder/tests/unit/api/contrib/test_types_extra_specs.py', 'cinder/tests/unit/volume/drivers/test_spdk.py', 'cinder/exception.py', 'cinder/tests/unit/test_image_utils.py', 'cinder/volume/drivers/lvm.py', 'cinder/volume/drivers/rbd.py', 'cinder/volume/drivers/vmware/fcd.py', 'cinder/volume/drivers/windows/smbfs.py', 'cinder/volume/drivers/ibm/gpfs.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/volume/drivers/windows/iscsi.py', 'cinder/tests/unit/windows/test_iscsi.py', 'cinder/image/glance.py', 'cinder/volume/drivers/dell_emc/vxflexos/driver.py', 'cinder/volume/driver.py', 'cinder/image/image_utils.py', 'cinder/tests/unit/windows/test_smbfs.py', 'cinder/volume/drivers/spdk.py', 'cinder/tests/unit/volume/drivers/test_quobyte.py', 'cinder/volume/drivers/remotefs.py', 'releasenotes/notes/support-glance-multiple-stores-79d11c5344f41446.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/350973f3dddd8e3b1d521238c69a5bd8c8df3fec', 'message': ""Support multiple stores of Glance\n\nGlance now has ability to configure multiple stores at a\ntime. To use this feature in cinder for uploading volume to image, operator\nneed to define a new field named 'image_service:store_id' in the\nvolume-type extra-specs. At a time of volume upload to image request, if\n'image_service:store_id' is present in the associated volume type, then\nimage will be uploaded to specified 'store_id'. The value 'store_id' is\nnothing but store identifier defined in glance-api.conf. If the value\nof 'image_service:store_id' is null or not set in volume-type then the\nimage will be uploaded to default store in glance.\n\nCo-authored-by: Sagar Waghmare <sawaghma@redhat.com>\nCo-authored-by: Abhishek Kekane <akekane@redhat.com>\n\nDocImpact\nImplements: bp support-glance-multiple-backend\n\nChange-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800\n""}]",52,661676,350973f3dddd8e3b1d521238c69a5bd8c8df3fec,955,54,20,9303,,,0,"Support multiple stores of Glance

Glance now has ability to configure multiple stores at a
time. To use this feature in cinder for uploading volume to image, operator
need to define a new field named 'image_service:store_id' in the
volume-type extra-specs. At a time of volume upload to image request, if
'image_service:store_id' is present in the associated volume type, then
image will be uploaded to specified 'store_id'. The value 'store_id' is
nothing but store identifier defined in glance-api.conf. If the value
of 'image_service:store_id' is null or not set in volume-type then the
image will be uploaded to default store in glance.

Co-authored-by: Sagar Waghmare <sawaghma@redhat.com>
Co-authored-by: Abhishek Kekane <akekane@redhat.com>

DocImpact
Implements: bp support-glance-multiple-backend

Change-Id: Ica56833a1d9fb9f47b922dbbc6558901bb3a2800
",git fetch https://review.opendev.org/openstack/cinder refs/changes/76/661676/16 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/rbd.py', 'cinder/volume/manager.py', 'cinder/tests/unit/volume/test_image.py', 'cinder/api/contrib/types_extra_specs.py', 'cinder/image/glance.py', 'cinder/tests/unit/image/fake.py', 'cinder/volume/driver.py', 'cinder/image/image_utils.py', 'cinder/tests/unit/api/contrib/test_types_extra_specs.py', 'cinder/exception.py', 'cinder/tests/unit/test_image_utils.py', 'releasenotes/notes/support-glance-multiple-stores-79d11c5344f41446.yaml', 'cinder/volume/drivers/lvm.py']",13,d4b2a61c0e80d94af0e1087330007bd7e133fd48,bp/support-glance-multiple-backend,"from cinder.volume import volume_types # retrieve store information from extra-specs store_id = volume_types.get_volume_type_extra_specs( volume.volume_type_id, key='image_service:store_id') self.local_path(volume), store_id=store_id)", self.local_path(volume)),181,19
openstack%2Freleases~master~I7017774d3f2776cfe34e17accc7da1b3568d9697,openstack/releases,master,I7017774d3f2776cfe34e17accc7da1b3568d9697,Bump tripleo-ansible to 1.1.0,MERGED,2020-01-30 04:38:10.000000000,2020-01-30 15:10:57.000000000,2020-01-30 15:10:57.000000000,"[{'_account_id': 308}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 11904}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 16708}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-30 04:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/6ebd2c7305a08b917be8109bbf060010c1385c7e', 'message': 'Bump tripleo-ansible to 1.0.1\n\nIt is need for tripleo standalone upgrade.\n\nRelated-Bug: #1861083\n\nChange-Id: I7017774d3f2776cfe34e17accc7da1b3568d9697\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 2, 'created': '2020-01-30 10:40:25.000000000', 'files': ['deliverables/ussuri/tripleo-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/abe954cdf3b98a0474ef0cb8a8d910e894d0bbe9', 'message': 'Bump tripleo-ansible to 1.1.0\n\nIt is need for tripleo standalone upgrade.\n\nRelated-Bug: #1861083\n\nChange-Id: I7017774d3f2776cfe34e17accc7da1b3568d9697\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}]",2,704922,abe954cdf3b98a0474ef0cb8a8d910e894d0bbe9,18,11,2,12393,,,0,"Bump tripleo-ansible to 1.1.0

It is need for tripleo standalone upgrade.

Related-Bug: #1861083

Change-Id: I7017774d3f2776cfe34e17accc7da1b3568d9697
Signed-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/22/704922/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/ussuri/tripleo-ansible.yaml'],1,6ebd2c7305a08b917be8109bbf060010c1385c7e,bumptripleoansible, - version: 1.0.1 projects: - repo: openstack/tripleo-ansible hash: 6f33d53d516e7e6f23cf3111d2e2cc05158faa3a,,4,0
openstack%2Fopenstack-helm-infra~master~Id4ee1dbd5c82dcbe9893f81c3ad3b9e18d1f9509,openstack/openstack-helm-infra,master,Id4ee1dbd5c82dcbe9893f81c3ad3b9e18d1f9509,[ceph-osd] Fix issues with ceph osd init sript,MERGED,2020-01-30 07:24:07.000000000,2020-01-30 15:00:25.000000000,2020-01-30 14:58:20.000000000,"[{'_account_id': 17119}, {'_account_id': 18511}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 29974}]","[{'number': 1, 'created': '2020-01-30 07:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/04b0238b54a0672a24d9f43027d372edbdfcff1e', 'message': '[ceph-osd] Fix issues with ceph osd init sript\n\nThis is to fix the logic to find osd id for wal lvm and also\nto find correct lvm device for osd disk.\n\nChange-Id: Id4ee1dbd5c82dcbe9893f81c3ad3b9e18d1f9509\n'}, {'number': 2, 'created': '2020-01-30 07:27:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6a536ca79600ad8e3473de96dcbf2f7da344655b', 'message': '[ceph-osd] Fix issues with ceph osd init sript\n\nThis is to fix the logic to find osd id for wal lvm and also\nto find correct lvm device for osd disk.\n\nChange-Id: Id4ee1dbd5c82dcbe9893f81c3ad3b9e18d1f9509\n'}, {'number': 3, 'created': '2020-01-30 09:35:44.000000000', 'files': ['ceph-osd/templates/bin/osd/ceph-volume/_init-with-ceph-volume.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/eacf93722136636dcfbd2b68c59b71f071ffc085', 'message': '[ceph-osd] Fix issues with ceph osd init sript\n\nThis is to fix the logic to find osd id for wal lvm and also\nto find correct lvm device for osd disk.\n\nChange-Id: Id4ee1dbd5c82dcbe9893f81c3ad3b9e18d1f9509\n'}]",0,704928,eacf93722136636dcfbd2b68c59b71f071ffc085,18,6,3,28372,,,0,"[ceph-osd] Fix issues with ceph osd init sript

This is to fix the logic to find osd id for wal lvm and also
to find correct lvm device for osd disk.

Change-Id: Id4ee1dbd5c82dcbe9893f81c3ad3b9e18d1f9509
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/28/704928/3 && git format-patch -1 --stdout FETCH_HEAD,['ceph-osd/templates/bin/osd/ceph-volume/_init-with-ceph-volume.sh.tpl'],1,04b0238b54a0672a24d9f43027d372edbdfcff1e,," if dmsetup ls |grep -i ${osd_dev_split}|grep -v db--wal; then WAL_OSD_ID=$(ceph-volume lvm list /dev/ceph-db-wal-${block_wal_string}/ceph-wal-${osd_dev_string} | grep ""osd id"" | awk '{print $3}')"," if dmsetup ls |grep -i ${osd_dev_split}; then WAL_OSD_ID=$(ceph-volume lvm list /dev/ceph-db-wal-${block_db_string}/ceph-db-${osd_dev_string} | grep ""osd id"" | awk '{print $3}')",2,2
openstack%2Ftripleo-quickstart-extras~master~I7764421b0d61556c68a4feff0e2257d1d9bdf895,openstack/tripleo-quickstart-extras,master,I7764421b0d61556c68a4feff0e2257d1d9bdf895,[WIP] Debug package build failures,ABANDONED,2020-01-13 08:29:17.000000000,2020-01-30 14:59:59.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-13 08:29:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d81f7b64398aacbc5fdf080bff997cdbcc6def8c', 'message': 'Debug package build failures\n\nChange-Id: I7764421b0d61556c68a4feff0e2257d1d9bdf895\n'}, {'number': 2, 'created': '2020-01-13 08:35:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e34b55357d7b7ffe5a6c0047f3dbed654b7d21d7', 'message': 'Debug package build failures\n\nChange-Id: I7764421b0d61556c68a4feff0e2257d1d9bdf895\n'}, {'number': 3, 'created': '2020-01-13 09:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/4f0009ea3e01609141a274f69ea5d68219d22a47', 'message': '[WIP] Debug package build failures\n\nChange-Id: I7764421b0d61556c68a4feff0e2257d1d9bdf895\n'}, {'number': 4, 'created': '2020-01-13 09:13:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e0de4422397a9277959f50421cf2661592802979', 'message': '[WIP] Debug package build failures\n\nChange-Id: I7764421b0d61556c68a4feff0e2257d1d9bdf895\n'}, {'number': 5, 'created': '2020-01-13 13:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/391cfde969787de127669878b2bbf6de579fbe08', 'message': '[WIP] Debug package build failures\n\nChange-Id: I7764421b0d61556c68a4feff0e2257d1d9bdf895\n'}, {'number': 6, 'created': '2020-01-14 14:54:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/ca29d47b557f870887530d6c48503ebe1fb75ed0', 'message': '[WIP] Debug package build failures\n\nChange-Id: I7764421b0d61556c68a4feff0e2257d1d9bdf895\n'}, {'number': 7, 'created': '2020-01-14 15:03:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f4f488c2e1c731727b4c0413a4b8e0d391bc3fbe', 'message': '[WIP] Debug package build failures\n\nChange-Id: I7764421b0d61556c68a4feff0e2257d1d9bdf895\n'}, {'number': 8, 'created': '2020-01-14 15:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/3ad4f6fb2aea4068d3a728b733714fa039361b59', 'message': '[WIP] Debug package build failures\n\nChange-Id: I7764421b0d61556c68a4feff0e2257d1d9bdf895\n'}, {'number': 9, 'created': '2020-01-16 07:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/1197369d84e47e8d13c70d161719041c6a889305', 'message': '[WIP] Debug package build failures\n\nChange-Id: I7764421b0d61556c68a4feff0e2257d1d9bdf895\n'}, {'number': 10, 'created': '2020-01-16 07:11:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f91166bccc6c572784d763b14802c7cc25ba84dc', 'message': '[WIP] Debug package build failures\n\nChange-Id: I7764421b0d61556c68a4feff0e2257d1d9bdf895\n'}, {'number': 11, 'created': '2020-01-22 07:58:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/bfe7eed8b87a562abfa0d1531b4de934af8dec7b', 'message': '[WIP] Debug package build failures\n\nChange-Id: I7764421b0d61556c68a4feff0e2257d1d9bdf895\n'}, {'number': 12, 'created': '2020-01-23 08:44:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/1480ee7279a86c5b271de7bea1d85e59d8f51564', 'message': '[WIP] Debug package build failures\n\nChange-Id: I7764421b0d61556c68a4feff0e2257d1d9bdf895\n'}, {'number': 13, 'created': '2020-01-27 11:49:31.000000000', 'files': ['roles/build-test-packages/tasks/dlrn-build.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f244b0b0cbf097ccbeb543a413e6ed0957862ff0', 'message': '[WIP] Debug package build failures\n\nChange-Id: I7764421b0d61556c68a4feff0e2257d1d9bdf895\n'}]",0,702170,f244b0b0cbf097ccbeb543a413e6ed0957862ff0,28,2,13,27329,,,0,"[WIP] Debug package build failures

Change-Id: I7764421b0d61556c68a4feff0e2257d1d9bdf895
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/70/702170/6 && git format-patch -1 --stdout FETCH_HEAD,['roles/build-test-packages/tasks/dlrn-build.yml'],1,d81f7b64398aacbc5fdf080bff997cdbcc6def8c,fix-project-name-mapping, - block: - name: Run DLRN shell: > source {{ build_repo_dir }}/dlrn-venv/bin/activate; set -eox; while true; do dlrn --config-file projects.ini --head-only \ --package-name {{ project_name_mapped.stdout }} \ --local \ --info-repo rdoinfo --dev; result=$? if ! [ $result -eq 2 ]; then exit $result; fi args: chdir: '{{ build_repo_dir }}/DLRN' register: repo_built when: artg_build_one | bool reque: - debug: msg: | WARNING: Unable to build {{ artg_change.project }}: failed building --- STDERR --- {{ repo_built.stderr }} --- STDERR ---, - name: Run DLRN shell: > set +e; source {{ build_repo_dir }}/dlrn-venv/bin/activate; while true; do dlrn --config-file projects.ini --head-only --package-name {{ project_name_mapped.stdout }} --local --info-repo rdoinfo --dev; if [ $? -eq 0 ]; then # SUCCESS break; elif [ $? -eq 1 ]; then # FAILED exit 1; elif [ $? -eq 2 ]; then # RETRY continue; fi; # Unexpected DLRN return code exit $?; done; args: chdir: '{{ build_repo_dir }}/DLRN' register: repo_built when: artg_build_one|bool,26,23
openstack%2Fpython-tripleoclient~master~Ia1a108e77dd50404b78d952c9c9a9c0d534a5d28,openstack/python-tripleoclient,master,Ia1a108e77dd50404b78d952c9c9a9c0d534a5d28,Fix all py27 tests,MERGED,2020-01-29 18:04:56.000000000,2020-01-30 14:51:15.000000000,2020-01-30 09:30:58.000000000,"[{'_account_id': 3153}, {'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-29 18:04:56.000000000', 'files': ['tripleoclient/tests/v1/tripleo/test_tripleo_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6aa5cdd3b02eff76aea9cda9103b2b173339c717', 'message': 'Fix all py27 tests\n\nThis change fixes our py27 tests. The issue was a cascading failure caused\nby a bad mock for sys.stdout.flush which results in general failure when\ncalling system and other builtin functions.\n\nChange-Id: Ia1a108e77dd50404b78d952c9c9a9c0d534a5d28\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}]",0,704859,6aa5cdd3b02eff76aea9cda9103b2b173339c717,11,5,1,7353,,,0,"Fix all py27 tests

This change fixes our py27 tests. The issue was a cascading failure caused
by a bad mock for sys.stdout.flush which results in general failure when
calling system and other builtin functions.

Change-Id: Ia1a108e77dd50404b78d952c9c9a9c0d534a5d28
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/59/704859/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/tests/v1/tripleo/test_tripleo_deploy.py'],1,6aa5cdd3b02eff76aea9cda9103b2b173339c717,fix-py27," def test_download_ansible_playbooks(self, mock_join, mock_stack_config, mock_launch_heat, mock_importInv, createdir_mock): with mock.patch('sys.stdout', autospec=True) as mock_stdout: self.cmd.output_dir = fake_output_dir self.cmd._download_ansible_playbooks(mock_launch_heat, 'undercloud', 'Undercloud') self.assertEqual(mock_stdout.flush.call_count, 2)"," @mock.patch('tripleoclient.v1.tripleo_deploy.sys.stdout.flush') def test_download_ansible_playbooks(self, mock_join, mock_flush, mock_stack_config, mock_launch_heat, mock_importInv, createdir_mock): self.cmd.output_dir = fake_output_dir self.cmd._download_ansible_playbooks(mock_launch_heat, 'undercloud', 'Undercloud') self.assertEqual(mock_flush.call_count, 2)",9,9
openstack%2Fplacement~master~Ia0aa7fc7b7f8e3a14c3e8c3292f042d7ace86bb5,openstack/placement,master,Ia0aa7fc7b7f8e3a14c3e8c3292f042d7ace86bb5,Add prefix '/placement' for listing resource providers,ABANDONED,2020-01-29 13:11:48.000000000,2020-01-30 14:46:00.000000000,,"[{'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}, {'_account_id': 23950}]","[{'number': 1, 'created': '2020-01-29 13:11:48.000000000', 'files': ['api-ref/source/samples/resource_providers/get-resource_providers.json'], 'web_link': 'https://opendev.org/openstack/placement/commit/e52bc789b4be9de529d4d3661e5e87b25526f5e3', 'message': ""Add prefix '/placement' for listing resource providers\n\nChange-Id: Ia0aa7fc7b7f8e3a14c3e8c3292f042d7ace86bb5\nStory: #2007232\nTask: #38508\n""}]",0,704799,e52bc789b4be9de529d4d3661e5e87b25526f5e3,7,4,1,23950,,,0,"Add prefix '/placement' for listing resource providers

Change-Id: Ia0aa7fc7b7f8e3a14c3e8c3292f042d7ace86bb5
Story: #2007232
Task: #38508
",git fetch https://review.opendev.org/openstack/placement refs/changes/99/704799/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/samples/resource_providers/get-resource_providers.json'],1,e52bc789b4be9de529d4d3661e5e87b25526f5e3,bug_2007232," ""href"": ""/placement/resource_providers/99c09379-6e52-4ef8-9a95-b9ce6f68452e"", ""href"": ""/placement/resource_providers/99c09379-6e52-4ef8-9a95-b9ce6f68452e/aggregates"", ""href"": ""/placement/resource_providers/99c09379-6e52-4ef8-9a95-b9ce6f68452e/inventories"", ""href"": ""/placement/resource_providers/99c09379-6e52-4ef8-9a95-b9ce6f68452e/usages"", ""href"": ""/placement/resource_providers/99c09379-6e52-4ef8-9a95-b9ce6f68452e/traits"", ""href"": ""/placement/resource_providers/99c09379-6e52-4ef8-9a95-b9ce6f68452e/allocations"", ""href"": ""/placement/resource_providers/d0b381e9-8761-42de-8e6c-bba99a96d5f5"", ""href"": ""/placement/resource_providers/d0b381e9-8761-42de-8e6c-bba99a96d5f5/aggregates"", ""href"": ""/placement/resource_providers/d0b381e9-8761-42de-8e6c-bba99a96d5f5/inventories"", ""href"": ""/placement/resource_providers/d0b381e9-8761-42de-8e6c-bba99a96d5f5/usages"", ""href"": ""/placement/resource_providers/d0b381e9-8761-42de-8e6c-bba99a96d5f5/traits"", ""href"": ""/placement/resource_providers/d0b381e9-8761-42de-8e6c-bba99a96d5f5/allocations"","," ""href"": ""/resource_providers/99c09379-6e52-4ef8-9a95-b9ce6f68452e"", ""href"": ""/resource_providers/99c09379-6e52-4ef8-9a95-b9ce6f68452e/aggregates"", ""href"": ""/resource_providers/99c09379-6e52-4ef8-9a95-b9ce6f68452e/inventories"", ""href"": ""/resource_providers/99c09379-6e52-4ef8-9a95-b9ce6f68452e/usages"", ""href"": ""/resource_providers/99c09379-6e52-4ef8-9a95-b9ce6f68452e/traits"", ""href"": ""/resource_providers/99c09379-6e52-4ef8-9a95-b9ce6f68452e/allocations"", ""href"": ""/resource_providers/d0b381e9-8761-42de-8e6c-bba99a96d5f5"", ""href"": ""/resource_providers/d0b381e9-8761-42de-8e6c-bba99a96d5f5/aggregates"", ""href"": ""/resource_providers/d0b381e9-8761-42de-8e6c-bba99a96d5f5/inventories"", ""href"": ""/resource_providers/d0b381e9-8761-42de-8e6c-bba99a96d5f5/usages"", ""href"": ""/resource_providers/d0b381e9-8761-42de-8e6c-bba99a96d5f5/traits"", ""href"": ""/resource_providers/d0b381e9-8761-42de-8e6c-bba99a96d5f5/allocations"",",12,12
openstack%2Floci~master~If602d4ccdaa66eed98dc8e9c600137a2f6fbb828,openstack/loci,master,If602d4ccdaa66eed98dc8e9c600137a2f6fbb828,Remove an entry for building project from uc,ABANDONED,2020-01-21 15:50:17.000000000,2020-01-30 14:35:20.000000000,,"[{'_account_id': 8863}, {'_account_id': 17068}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28719}, {'_account_id': 29911}]","[{'number': 1, 'created': '2020-01-21 15:50:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/33f79d966122c07cfbe40cc24c701e54417a7c75', 'message': ""Remove an entry for building project from uc\n\nIn some releases (Stein, Train) uc contains at least an entry for\nhorizon, that breaks build for this component with unsatisfied\nconstraints error. Obviously we don't need this constraint for the\ncomponent we build.\n\nChange-Id: If602d4ccdaa66eed98dc8e9c600137a2f6fbb828\n""}, {'number': 2, 'created': '2020-01-21 17:17:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/f7641c94ed76c37ba3c91e18802f6a7449a40cd9', 'message': ""Remove an entry for building project from uc\n\nIn some releases (Stein, Train) uc contains at least an entry for\nhorizon, that breaks build for this component with unsatisfied\nconstraints error. Obviously we don't need this constraint for the\ncomponent we build.\n\nChange-Id: If602d4ccdaa66eed98dc8e9c600137a2f6fbb828\n""}, {'number': 3, 'created': '2020-01-21 17:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/73776edcf85e6cec445bd8c03d3fd5e437ec1545', 'message': ""Remove an entry for building project from uc\n\nIn some releases (Stein, Train) uc contains at entries for neutron and\nhorizon, that breaks build for these components with unsatisfied\nconstraints error. Obviously we don't need this constraint for the\ncomponent we build.\n\nChange-Id: If602d4ccdaa66eed98dc8e9c600137a2f6fbb828\n""}, {'number': 4, 'created': '2020-01-21 17:22:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/76f4ee52118d01ca413079576c2303dbfb64158f', 'message': ""Remove an entry for building project from uc\n\nIn some releases (Stein, Train) uc contains at entries for neutron and\nhorizon, that breaks build for these components with unsatisfied\nconstraints error. Obviously we don't need this constraint for the\ncomponent we build.\n\nChange-Id: If602d4ccdaa66eed98dc8e9c600137a2f6fbb828\n""}, {'number': 5, 'created': '2020-01-21 17:23:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/d962708a1928da536041a3b9e197a70ba880c350', 'message': ""Remove an entry for building project from uc\n\nIn some releases (Stein, Train) uc contains entries for neutron and\nhorizon, that breaks build for these components with unsatisfied\nconstraints error. Obviously we don't need this constraint for the\ncomponent we build.\n\nChange-Id: If602d4ccdaa66eed98dc8e9c600137a2f6fbb828\n""}, {'number': 6, 'created': '2020-01-21 17:31:33.000000000', 'files': ['scripts/requirements.sh'], 'web_link': 'https://opendev.org/openstack/loci/commit/bf478313c0963bf8d82a091874a1a756258d6626', 'message': ""Remove an entry for building project from uc\n\nIn some releases (Stein, Train) uc contains entries for neutron and\nhorizon, that breaks build for these components with unsatisfied\nconstraints error. Obviously we don't need this constraint for the\ncomponent we build.\n\nChange-Id: If602d4ccdaa66eed98dc8e9c600137a2f6fbb828\n""}]",0,703647,bf478313c0963bf8d82a091874a1a756258d6626,21,7,6,8863,,,0,"Remove an entry for building project from uc

In some releases (Stein, Train) uc contains entries for neutron and
horizon, that breaks build for these components with unsatisfied
constraints error. Obviously we don't need this constraint for the
component we build.

Change-Id: If602d4ccdaa66eed98dc8e9c600137a2f6fbb828
",git fetch https://review.opendev.org/openstack/loci refs/changes/47/703647/4 && git format-patch -1 --stdout FETCH_HEAD,['scripts/requirements.sh'],1,33f79d966122c07cfbe40cc24c701e54417a7c75,,"# Remove entry for current project to avoid unsatisfied constraints error sed -i ""/^${PROJECT}===/d"" /upper-constraints.txt ",,3,0
openstack%2Foslo.context~master~Ie875138bd1b773f460698e1eacc9dab542318e30,openstack/oslo.context,master,Ie875138bd1b773f460698e1eacc9dab542318e30,Drop python 2.7 support and testing,MERGED,2019-12-27 08:12:54.000000000,2020-01-30 14:33:43.000000000,2020-01-30 14:28:40.000000000,"[{'_account_id': 841}, {'_account_id': 8556}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27621}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-12-27 08:12:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.context/commit/489bd05ba069d9aef1794260797c394ecf872cb3', 'message': 'Drop python 2.7 support and testing\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: Ie875138bd1b773f460698e1eacc9dab542318e30\n'}, {'number': 2, 'created': '2020-01-30 11:42:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.context/commit/6b446e4de2ea9acd43a5a057aacb6b1d93088ead', 'message': 'Drop python 2.7 support and testing\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: Ie875138bd1b773f460698e1eacc9dab542318e30\n'}, {'number': 3, 'created': '2020-01-30 11:43:21.000000000', 'files': ['releasenotes/notes/drop-python27-support-b421329839e69d41.yaml', '.zuul.yaml', 'doc/requirements.txt', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.context/commit/3017e180f00d3f7f8f7b2eb9099e601806315dfe', 'message': 'Drop python 2.7 support and testing\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: Ie875138bd1b773f460698e1eacc9dab542318e30\nSem-Ver: api-break\n'}]",3,700688,3017e180f00d3f7f8f7b2eb9099e601806315dfe,18,6,3,27822,,,0,"Drop python 2.7 support and testing

Ussuri Communtiy-wide goal:
https://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html

Change-Id: Ie875138bd1b773f460698e1eacc9dab542318e30
Sem-Ver: api-break
",git fetch https://review.opendev.org/openstack/oslo.context refs/changes/88/700688/2 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'setup.cfg', 'tox.ini']",3,489bd05ba069d9aef1794260797c394ecf872cb3,drop-py27-support,"envlist = py37,pep8","envlist = py27,py37,pep8",1,5
openstack%2Foslo.concurrency~master~I94e709093e01825069b44b6c485e49a81f8f14c1,openstack/oslo.concurrency,master,I94e709093e01825069b44b6c485e49a81f8f14c1,Drop python 2.7 support and testing,MERGED,2019-12-27 08:10:15.000000000,2020-01-30 14:31:05.000000000,2020-01-30 14:26:28.000000000,"[{'_account_id': 8556}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27621}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-12-27 08:10:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/6f2c53b2c7f79cb72eba6389c77c7cccf9a958a3', 'message': 'Drop python 2.7 support and testing\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: I94e709093e01825069b44b6c485e49a81f8f14c1\n'}, {'number': 2, 'created': '2020-01-30 11:37:32.000000000', 'files': ['requirements.txt', 'test-requirements.txt', '.zuul.yaml', 'doc/requirements.txt', 'releasenotes/notes/drop-python27-support-7d837a45dae941bb.yaml', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/cfc27ef4972a99c5787e537b0f85067829517c4c', 'message': 'Drop python 2.7 support and testing\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: I94e709093e01825069b44b6c485e49a81f8f14c1\nSem-Ver: api-break\n'}]",5,700687,cfc27ef4972a99c5787e537b0f85067829517c4c,16,5,2,27822,,,0,"Drop python 2.7 support and testing

Ussuri Communtiy-wide goal:
https://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html

Change-Id: I94e709093e01825069b44b6c485e49a81f8f14c1
Sem-Ver: api-break
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/87/700687/2 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'setup.cfg', 'tox.ini']",3,6f2c53b2c7f79cb72eba6389c77c7cccf9a958a3,drop-py27-support,"envlist = py37,pep8basepython = python3","envlist = py27,py37,pep8[testenv:py27] basepython = python2.7 basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3",2,13
openstack%2Fos-vif~master~I7cd6112b3b35a6971d3d354abae7652344ed1c97,openstack/os-vif,master,I7cd6112b3b35a6971d3d354abae7652344ed1c97,"Revert ""[Follow Up] OVS DPDK port representors support""",MERGED,2020-01-21 18:57:31.000000000,2020-01-30 14:17:11.000000000,2020-01-30 14:10:17.000000000,"[{'_account_id': 9732}, {'_account_id': 11604}, {'_account_id': 12171}, {'_account_id': 15334}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 22948}, {'_account_id': 25241}, {'_account_id': 25733}, {'_account_id': 28714}]","[{'number': 1, 'created': '2020-01-21 18:57:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/e0468865002e7123b99ac72eba009eb193bf9e76', 'message': 'Revert ""[Follow Up] OVS DPDK port representors support""\n\nit seems that relevant OVS patches still did not land [1][2]\ni think we should revert and wait for the patches to merge first then we can go ahead and merge in os-vif with release note that states the exact version.\n\napologies for not blocking the merge in time.\n\n[1] https://patchwork.ozlabs.org/patch/1186896/\n[2] https://patchwork.ozlabs.org/patch/1215075/\n\nThis reverts commit 399e3550886d091dcf022051da578d5a2c219654.\n\nChange-Id: I7cd6112b3b35a6971d3d354abae7652344ed1c97\n'}, {'number': 2, 'created': '2020-01-21 19:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/6ef8fe30d2d8684ecaecc5bef4819173e885e413', 'message': 'Revert ""[Follow Up] OVS DPDK port representors support""\n\nit seems that relevant OVS patches still did not land [1][2].\nI think we should revert and wait for the patches to merge first,\nthen we can go ahead and merge in os-vif with release note that states\nthe exact OVS version required.\n\n[1] https://patchwork.ozlabs.org/patch/1186896/\n[2] https://patchwork.ozlabs.org/patch/1215075/\n\nThis reverts commit 399e3550886d091dcf022051da578d5a2c219654.\n\nChange-Id: I7cd6112b3b35a6971d3d354abae7652344ed1c97\n'}, {'number': 3, 'created': '2020-01-22 14:40:27.000000000', 'files': ['vif_plug_ovs/ovs.py', 'vif_plug_ovs/ovsdb/ovsdb_lib.py', 'vif_plug_ovs/ovsdb/impl_vsctl.py', 'vif_plug_ovs/tests/unit/ovsdb/test_impl_vsctl.py', 'os_vif/tests/unit/test_utils.py', 'os_vif/utils.py', 'vif_plug_ovs/tests/unit/ovsdb/test_ovsdb_lib.py'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/bb5e51309eb05032f31c07c26f5c4d18c31cc087', 'message': 'Revert ""[Follow Up] OVS DPDK port representors support""\n\nit seems that relevant OVS patches still did not land [1][2].\nI think we should revert and wait for the patches to merge first,\nthen we can go ahead and merge in os-vif with release note that states\nthe exact OVS version required.\n\n[1] https://patchwork.ozlabs.org/patch/1186896/\n[2] https://patchwork.ozlabs.org/patch/1215075/\n\nThis reverts commit 399e3550886d091dcf022051da578d5a2c219654.\n\nChange-Id: I7cd6112b3b35a6971d3d354abae7652344ed1c97\n'}]",0,703672,bb5e51309eb05032f31c07c26f5c4d18c31cc087,37,10,3,28714,,,0,"Revert ""[Follow Up] OVS DPDK port representors support""

it seems that relevant OVS patches still did not land [1][2].
I think we should revert and wait for the patches to merge first,
then we can go ahead and merge in os-vif with release note that states
the exact OVS version required.

[1] https://patchwork.ozlabs.org/patch/1186896/
[2] https://patchwork.ozlabs.org/patch/1215075/

This reverts commit 399e3550886d091dcf022051da578d5a2c219654.

Change-Id: I7cd6112b3b35a6971d3d354abae7652344ed1c97
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/72/703672/2 && git format-patch -1 --stdout FETCH_HEAD,"['vif_plug_ovs/ovs.py', 'vif_plug_ovs/ovsdb/ovsdb_lib.py', 'vif_plug_ovs/ovsdb/impl_vsctl.py', 'vif_plug_ovs/tests/unit/ovsdb/test_impl_vsctl.py', 'os_vif/tests/unit/test_utils.py', 'os_vif/utils.py', 'vif_plug_ovs/tests/unit/ovsdb/test_ovsdb_lib.py']",7,e0468865002e7123b99ac72eba009eb193bf9e76,zuulv3," '0000:02:00.1,representor=[0]'})] def test_delete_ovs_vif_port(self, mock_delete_net_dev): def test_delete_ovs_vif_port_no_delete_netdev(self, mock_delete_net_dev): self.br.delete_ovs_vif_port('bridge', 'device', delete_netdev=False)","from os_vif import utils CONF.register_opt(cfg.StrOpt('cleanup_base_mac', default='aa:16:3f:00:00:00'), test_vif_plug_ovs_group) '0000:02:00.1,representor=[0]'}), ('mac', 'ca:fe:ca:fe:ca:fe')] @mock.patch.object(ovsdb_lib.BaseOVS, '_is_dpdk_representor_port', return_value=False) def test_delete_ovs_vif_port(self, mock_is_dpdk_representor_port, mock_delete_net_dev): @mock.patch.object(ovsdb_lib.BaseOVS, '_is_dpdk_representor_port', return_value=False) def test_delete_ovs_vif_port_no_delete_netdev(self, mock_is_dpdk_representor_port, mock_delete_net_dev): self.br.delete_ovs_vif_port('bridge', 'device', delete_netdev=False) @mock.patch.object(linux_net, 'delete_net_dev') @mock.patch.object(utils, 'get_random_mac', return_value='aa:16:3f:00:00:00') @mock.patch.object(ovsdb_lib.BaseOVS, '_is_dpdk_representor_port', return_value=True) def test_delete_ovs_dpdk_representor_port(self, mock_is_dpdk_representor_port, mock_get_random_mac, mock_delete_net_dev): self.br.delete_ovs_vif_port('bridge', 'device') self.mock_del_port.assert_has_calls( [mock.call('device', bridge='bridge', if_exists=True)]) self.mock_db_set.assert_has_calls( [mock.call('Interface', 'device', ('mac', 'aa:16:3f:00:00:00'))]) mock_delete_net_dev.assert_has_calls([mock.call('device')]) mock_get_random_mac.assert_has_calls([mock.call( ['aa', '16', '3f', '00', '00', '00'])]) ",6,134
openstack%2Fos-vif~master~I7965a848d1d682760affd9a03ee7e052a69de57d,openstack/os-vif,master,I7965a848d1d682760affd9a03ee7e052a69de57d,move os-vif-ovs to be a non legacy job.,MERGED,2020-01-08 19:42:20.000000000,2020-01-30 14:15:36.000000000,2020-01-30 14:10:16.000000000,"[{'_account_id': 9732}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-08 19:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/3db185b200c45ab6fe9c8a2babce070dc401c65b', 'message': 'move os-vif-ovs to be a non legacy job.\n\nThis change removes the legacy os-vif-ovs\njob and repelaces it with a native zuul v3\nversion. Both the old and new os-vif-ovs job\ncurrently execute tempest-full but this should\nbe reduced but that is left to a follow up\npatch as this is is intended as a direct refactor.\n\nChange-Id: I7965a848d1d682760affd9a03ee7e052a69de57d\n'}, {'number': 2, 'created': '2020-01-09 11:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/48a506b91c1d7aadcf8b49702e12362465605c2a', 'message': 'move os-vif-ovs to be a non legacy job.\n\nThis change removes the legacy os-vif-ovs\njob and repelaces it with a native zuul v3\nversion. Both the old and new os-vif-ovs job\ncurrently execute tempest-full but this should\nbe reduced but that is left to a follow up\npatch as this is is intended as a direct refactor.\n\nChange-Id: I7965a848d1d682760affd9a03ee7e052a69de57d\n'}, {'number': 3, 'created': '2020-01-22 14:40:27.000000000', 'files': ['.zuul.yaml', 'playbooks/os-vif-ovs/run.yaml', 'playbooks/os-vif-ovs/post.yaml'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/1ed44bd400fc8adb83438083d376658f27205373', 'message': 'move os-vif-ovs to be a non legacy job.\n\nThis change removes the legacy os-vif-ovs\njob and repelaces it with a native zuul v3\nversion. Both the old and new os-vif-ovs job\ncurrently execute tempest-full but this should\nbe reduced but that is left to a follow up\npatch as this is is intended as a direct refactor.\n\nChange-Id: I7965a848d1d682760affd9a03ee7e052a69de57d\n'}]",13,701601,1ed44bd400fc8adb83438083d376658f27205373,18,5,3,11604,,,0,"move os-vif-ovs to be a non legacy job.

This change removes the legacy os-vif-ovs
job and repelaces it with a native zuul v3
version. Both the old and new os-vif-ovs job
currently execute tempest-full but this should
be reduced but that is left to a follow up
patch as this is is intended as a direct refactor.

Change-Id: I7965a848d1d682760affd9a03ee7e052a69de57d
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/01/701601/2 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'playbooks/os-vif-ovs/run.yaml', 'playbooks/os-vif-ovs/post.yaml']",3,3db185b200c45ab6fe9c8a2babce070dc401c65b,zuulv3,,- hosts: primary tasks: - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=/logs/** - --include=*/ - --exclude=* - --prune-empty-dirs ,47,71
openstack%2Ftacker~master~I3bf7be13f69837a0c2b9d62d10b21dce0fd0fe76,openstack/tacker,master,I3bf7be13f69837a0c2b9d62d10b21dce0fd0fe76,Drop python 2.7 support and testing,MERGED,2019-10-31 06:26:58.000000000,2020-01-30 14:12:43.000000000,2020-01-30 14:07:52.000000000,"[{'_account_id': 8556}, {'_account_id': 18955}, {'_account_id': 22348}, {'_account_id': 26222}, {'_account_id': 26463}, {'_account_id': 26588}, {'_account_id': 27180}]","[{'number': 1, 'created': '2019-10-31 06:26:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/120d25534b9c10707197e000bc9416b8ed74ffc3', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nTacker is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I3bf7be13f69837a0c2b9d62d10b21dce0fd0fe76\n'}, {'number': 2, 'created': '2019-11-13 23:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/7a3289a393e7f8b71ae48ddedbe623f19dabd810', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nTacker is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nDepends-On: https://review.opendev.org/#/c/693631/\n\nChange-Id: I3bf7be13f69837a0c2b9d62d10b21dce0fd0fe76\n'}, {'number': 3, 'created': '2019-11-14 12:53:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/359983ca22c5e157b2a0e6fc4c5bc96cacde7dd0', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nTacker is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nDepends-On: https://review.opendev.org/#/c/693631/\n\nChange-Id: I3bf7be13f69837a0c2b9d62d10b21dce0fd0fe76\n'}, {'number': 4, 'created': '2019-11-28 09:42:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/19a0b5a9bfa65b5e696a64cff971402f883dc836', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nTacker is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nDepends-On: https://review.opendev.org/#/c/693631/\n\nChange-Id: I3bf7be13f69837a0c2b9d62d10b21dce0fd0fe76\n'}, {'number': 5, 'created': '2019-12-13 23:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/d80bd4fbd0a6dbd45a47de18886ae5b2c312a9c8', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nTacker is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nDepends-On: https://review.opendev.org/#/c/693631/\n\nChange-Id: I3bf7be13f69837a0c2b9d62d10b21dce0fd0fe76\n'}, {'number': 6, 'created': '2019-12-19 14:29:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/ee170f248302834466afe0f3536a3750643d7c53', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nTacker is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nDepends-On: https://review.opendev.org/#/c/693631/\n\nChange-Id: I3bf7be13f69837a0c2b9d62d10b21dce0fd0fe76\n'}, {'number': 7, 'created': '2019-12-20 08:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/c1103818e6078c0e222789d80ec479a42d52bdb9', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nTacker is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nDepends-On: https://review.opendev.org/#/c/693631/\n\nChange-Id: I3bf7be13f69837a0c2b9d62d10b21dce0fd0fe76\n'}, {'number': 8, 'created': '2020-01-22 06:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/acd284a9a0217fa20660d684450d92a2e078f5ee', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nTacker is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nDepends-On: https://review.opendev.org/#/c/693631/\n\nChange-Id: I3bf7be13f69837a0c2b9d62d10b21dce0fd0fe76\n'}, {'number': 9, 'created': '2020-01-23 07:49:17.000000000', 'files': ['.zuul.yaml', 'releasenotes/notes/drop-py-2-7-8db9ceef15903295.yaml', 'doc/requirements.txt', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tacker/commit/71658dc91098656151e024162a70a51d4b239fb3', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nTacker is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nDepends-On: https://review.opendev.org/#/c/693631/\n\nChange-Id: I3bf7be13f69837a0c2b9d62d10b21dce0fd0fe76\n'}]",5,692269,71658dc91098656151e024162a70a51d4b239fb3,37,7,9,8556,,,0,"Drop python 2.7 support and testing

OpenStack is dropping the py2.7 support in ussuri cycle.

Tacker is ready with python 3 and ok to drop the
python 2.7 support.

Complete discussion & schedule can be found in
- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html
- https://etherpad.openstack.org/p/drop-python2-support

Ussuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/

Depends-On: https://review.opendev.org/#/c/693631/

Change-Id: I3bf7be13f69837a0c2b9d62d10b21dce0fd0fe76
",git fetch https://review.opendev.org/openstack/tacker refs/changes/69/692269/5 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'releasenotes/notes/drop-py-2-7-8db9ceef15903295.yaml', 'setup.cfg', 'tox.ini']",4,120d25534b9c10707197e000bc9416b8ed74ffc3,drop-py27-support,"envlist = py37,py36,pep8,docsbasepython = python3basepython = python3basepython = python3","envlist = py37,py36,py27,pep8,docsbasepython = {env:TACKER_TOX_PYTHON:python2}basepython = python2.7[testenv:debug-py27] basepython = python2.7 commands = oslo_debug_helper {posargs} basepython = python2.7",11,23
openstack%2Ftacker~master~I9f93075402dd5273a4ab045db5cd15bd4dea8582,openstack/tacker,master,I9f93075402dd5273a4ab045db5cd15bd4dea8582,remove upper-constraints.txt from lower-const job,MERGED,2019-12-06 04:24:00.000000000,2020-01-30 14:04:44.000000000,2020-01-30 14:01:47.000000000,"[{'_account_id': 22348}, {'_account_id': 26222}, {'_account_id': 26588}]","[{'number': 1, 'created': '2019-12-06 04:24:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/962e6abd449777f3ab11b02c7c1b2eee58183632', 'message': 'remove upper-constraints.txt from lower-const job\n\nCurrently in lower-constraints job, pip install is issued with both\nupper-constraints.txt by `install_command` in [testenv] and\nlower-constraints.txt by `deps` in [testenv:lower-constraints] so\nlower-constraints job actually tests aginst upper-constraints. We need\nto remove upper-constraints.txt from lower-constraints job.\n\nChange-Id: I9f93075402dd5273a4ab045db5cd15bd4dea8582\n'}, {'number': 2, 'created': '2019-12-06 05:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/95e2203ed2f9ac894682a88379f8de39c01a3f0c', 'message': 'remove upper-constraints.txt from lower-const job\n\nCurrently in lower-constraints job, pip install is issued with both\nupper-constraints.txt by `install_command` in [testenv] and\nlower-constraints.txt by `deps` in [testenv:lower-constraints] so\nlower-constraints job actually tests aginst upper-constraints. We need\nto remove upper-constraints.txt from lower-constraints job.\n\nChange-Id: I9f93075402dd5273a4ab045db5cd15bd4dea8582\n'}, {'number': 3, 'created': '2019-12-09 06:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/ec5532542737db02b6deea72d4789b8e64fc4df9', 'message': 'remove upper-constraints.txt from lower-const job\n\nCurrently in lower-constraints job, pip install is issued with both\nupper-constraints.txt by `install_command` in [testenv] and\nlower-constraints.txt by `deps` in [testenv:lower-constraints] so\nlower-constraints job actually tests aginst upper-constraints. We need\nto remove upper-constraints.txt from lower-constraints job.\n\nAlong with the above, update version of mock, olso_messaging and\nkeystoneatuh1 package in lower-constraints.txt.\n\nChange-Id: I9f93075402dd5273a4ab045db5cd15bd4dea8582\n'}, {'number': 4, 'created': '2019-12-11 02:46:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/2e3429f1f0f477b72e17598d9fdda5ebd86d664c', 'message': 'remove upper-constraints.txt from lower-const job\n\nCurrently in lower-constraints job, pip install is issued with both\nupper-constraints.txt by `install_command` in [testenv] and\nlower-constraints.txt by `deps` in [testenv:lower-constraints] so\nlower-constraints job actually tests aginst upper-constraints. We need\nto remove upper-constraints.txt from lower-constraints job.\n\nAlong with the above, update version of mock, olso_messaging and\nkeystoneatuh1 package in lower-constraints.txt, requirements.txt and\ntest-requirements.txt.\n\nChange-Id: I9f93075402dd5273a4ab045db5cd15bd4dea8582\n'}, {'number': 5, 'created': '2020-01-17 07:45:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/c71939e20092e11dccb601500dc20fc4de288a5a', 'message': 'remove upper-constraints.txt from lower-const job\n\nCurrently in lower-constraints job, pip install is issued with both\nupper-constraints.txt by `install_command` in [testenv] and\nlower-constraints.txt by `deps` in [testenv:lower-constraints] so\nlower-constraints job actually tests aginst upper-constraints. We need\nto remove upper-constraints.txt from lower-constraints job.\n\nAlong with the above, update version of mock, olso_messaging and\nkeystoneatuh1 package in lower-constraints.txt, requirements.txt and\ntest-requirements.txt.\n\nChange-Id: I9f93075402dd5273a4ab045db5cd15bd4dea8582\n'}, {'number': 6, 'created': '2020-01-21 02:32:16.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tacker/commit/8ee4d0d40583dc298d14fd06b3f70194ed17dfe2', 'message': 'remove upper-constraints.txt from lower-const job\n\nCurrently in lower-constraints job, pip install is issued with both\nupper-constraints.txt by `install_command` in [testenv] and\nlower-constraints.txt by `deps` in [testenv:lower-constraints] so\nlower-constraints job actually tests aginst upper-constraints. We need\nto remove upper-constraints.txt from lower-constraints job.\n\nAlong with the above, update version of mock, olso_messaging and\nkeystoneatuh1 package in lower-constraints.txt, requirements.txt and\ntest-requirements.txt.\n\nChange-Id: I9f93075402dd5273a4ab045db5cd15bd4dea8582\n'}]",0,697616,8ee4d0d40583dc298d14fd06b3f70194ed17dfe2,21,3,6,26588,,,0,"remove upper-constraints.txt from lower-const job

Currently in lower-constraints job, pip install is issued with both
upper-constraints.txt by `install_command` in [testenv] and
lower-constraints.txt by `deps` in [testenv:lower-constraints] so
lower-constraints job actually tests aginst upper-constraints. We need
to remove upper-constraints.txt from lower-constraints job.

Along with the above, update version of mock, olso_messaging and
keystoneatuh1 package in lower-constraints.txt, requirements.txt and
test-requirements.txt.

Change-Id: I9f93075402dd5273a4ab045db5cd15bd4dea8582
",git fetch https://review.opendev.org/openstack/tacker refs/changes/16/697616/6 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,962e6abd449777f3ab11b02c7c1b2eee58183632,bug-lower-const,install_command = pip install {opts} {package},,1,0
openstack%2Floci~master~If490aacc6df6198c286a4b316165892452db8ab5,openstack/loci,master,If490aacc6df6198c286a4b316165892452db8ab5,Remove an entry for building project from uc,MERGED,2020-01-27 21:25:10.000000000,2020-01-30 13:51:37.000000000,2020-01-30 13:51:37.000000000,"[{'_account_id': 8863}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28719}]","[{'number': 1, 'created': '2020-01-27 21:25:10.000000000', 'files': ['scripts/fetch_wheels.sh'], 'web_link': 'https://opendev.org/openstack/loci/commit/690c3d7673ff1a48b2ac787505bffaf621d86eba', 'message': ""Remove an entry for building project from uc\n\nIn some releases (Stein, Train, Rocky) uc contains entries for neutron\nand horizon, that breaks build for these components with unsatisfied\nconstraints error. Obviously we don't need this constraint for the\ncomponent we build.\n\nChange-Id: If490aacc6df6198c286a4b316165892452db8ab5\n""}]",0,704433,690c3d7673ff1a48b2ac787505bffaf621d86eba,12,6,1,8863,,,0,"Remove an entry for building project from uc

In some releases (Stein, Train, Rocky) uc contains entries for neutron
and horizon, that breaks build for these components with unsatisfied
constraints error. Obviously we don't need this constraint for the
component we build.

Change-Id: If490aacc6df6198c286a4b316165892452db8ab5
",git fetch https://review.opendev.org/openstack/loci refs/changes/33/704433/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/fetch_wheels.sh'],1,690c3d7673ff1a48b2ac787505bffaf621d86eba,," # Presence of constraint for project we build (in Stein, Train for Horizon and # Neutron) in uc breaks project installation with unsatisfied constraints error # This line ensures that such constraint is absent for any future occurrence sed -i ""/^${PROJECT}===/d"" /tmp/wheels/upper-constraints.txt",,5,0
openstack%2Ftacker~master~I2dfee4967545aba5ea54561dc4910df02b0a9c98,openstack/tacker,master,I2dfee4967545aba5ea54561dc4910df02b0a9c98,Support patch to fix window style line ending,MERGED,2019-12-19 14:29:28.000000000,2020-01-30 13:46:27.000000000,2020-01-30 13:44:39.000000000,"[{'_account_id': 20191}, {'_account_id': 22348}, {'_account_id': 26222}, {'_account_id': 26588}, {'_account_id': 27180}]","[{'number': 1, 'created': '2019-12-19 14:29:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/9683126e318ed680fbc5c51f32805f26dce1b858', 'message': 'This fix Drop python 2.7 support and testing\n\nRemoved windows style line endings.\n\nChange-Id: I2dfee4967545aba5ea54561dc4910df02b0a9c98\n'}, {'number': 2, 'created': '2019-12-20 08:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/c1ffce53a7c37fdd30a3238e10996b6d5a58d40d', 'message': ""Support patch to fix window style line ending\n\nPep8 didn't recognised this error because it was running\non python2. Now tacker is going to support python3 so this\nwindow style line ending should be fixed.\n\nThis patch removed window style line endings.\n\nChange-Id: I2dfee4967545aba5ea54561dc4910df02b0a9c98\n""}, {'number': 3, 'created': '2020-01-23 07:49:17.000000000', 'files': ['tacker/tests/unit/conductor/fakes.py', 'tacker/tests/unit/conductor/conductorrpc/test_vnf_pkgm_rpc.py', 'tacker/policies/__init__.py', 'tacker/tests/unit/objects/test_vnf_package_vnfd.py', 'tacker/tests/unit/vnfm/infra_drivers/openstack/fixture_data/client.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/9dd0823c95ba8614d2b1cd50dbccb8208599bc5b', 'message': ""Support patch to fix window style line ending\n\nPep8 didn't recognised this error because it was running\non python2. Now tacker is going to support python3 so this\nwindow style line ending should be fixed.\n\nThis patch removed window style line endings.\n\nChange-Id: I2dfee4967545aba5ea54561dc4910df02b0a9c98\n""}]",3,699995,9dd0823c95ba8614d2b1cd50dbccb8208599bc5b,16,5,3,26463,,,0,"Support patch to fix window style line ending

Pep8 didn't recognised this error because it was running
on python2. Now tacker is going to support python3 so this
window style line ending should be fixed.

This patch removed window style line endings.

Change-Id: I2dfee4967545aba5ea54561dc4910df02b0a9c98
",git fetch https://review.opendev.org/openstack/tacker refs/changes/95/699995/1 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/tests/unit/conductor/fakes.py', 'tacker/tests/unit/conductor/conductorrpc/test_vnf_pkgm_rpc.py', 'tacker/policies/__init__.py', 'tacker/tests/unit/objects/test_vnf_package_vnfd.py', 'tacker/tests/unit/vnfm/infra_drivers/openstack/fixture_data/client.py']",5,9683126e318ed680fbc5c51f32805f26dce1b858,drop-py27-support,"# Copyright 2019 NTT DATA # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import fixtures from heatclient import client from keystoneauth1 import fixture from keystoneauth1 import loading from keystoneauth1 import session IDENTITY_URL = 'http://identityserver:5000/v3' HEAT_URL = 'http://heat-api' class ClientFixture(fixtures.Fixture): def __init__(self, requests_mock, heat_url=HEAT_URL, identity_url=IDENTITY_URL): super(ClientFixture, self).__init__() self.identity_url = identity_url self.client = None self.token = fixture.V2Token() self.token.set_scope() self.requests_mock = requests_mock self.discovery = fixture.V2Discovery(href=self.identity_url) s = self.token.add_service('orchestration') s.add_endpoint(heat_url) def setUp(self): super(ClientFixture, self).setUp() auth_url = '%s/tokens' % self.identity_url headers = {'X-Content-Type': 'application/json'} self.requests_mock.post(auth_url, json=self.token, headers=headers) self.requests_mock.get(self.identity_url, json=self.discovery, headers=headers) self.client = self.new_client() def new_client(self): self.session = session.Session() loader = loading.get_plugin_loader('password') self.session.auth = loader.load_from_options( auth_url=self.identity_url, username='xx', password='xx') return client.Client(""1"", session=self.session)","# Copyright 2019 NTT DATA # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import fixtures from heatclient import client from keystoneauth1 import fixture from keystoneauth1 import loading from keystoneauth1 import session IDENTITY_URL = 'http://identityserver:5000/v3' HEAT_URL = 'http://heat-api' class ClientFixture(fixtures.Fixture): def __init__(self, requests_mock, heat_url=HEAT_URL, identity_url=IDENTITY_URL): super(ClientFixture, self).__init__() self.identity_url = identity_url self.client = None self.token = fixture.V2Token() self.token.set_scope() self.requests_mock = requests_mock self.discovery = fixture.V2Discovery(href=self.identity_url) s = self.token.add_service('orchestration') s.add_endpoint(heat_url) def setUp(self): super(ClientFixture, self).setUp() auth_url = '%s/tokens' % self.identity_url headers = {'X-Content-Type': 'application/json'} self.requests_mock.post(auth_url, json=self.token, headers=headers) self.requests_mock.get(self.identity_url, json=self.discovery, headers=headers) self.client = self.new_client() def new_client(self): self.session = session.Session() loader = loading.get_plugin_loader('password') self.session.auth = loader.load_from_options( auth_url=self.identity_url, username='xx', password='xx') return client.Client(""1"", session=self.session) ",273,273
openstack%2Fopenstack-zuul-jobs~master~Ieceb107dbb8135345fba8b17af362ea0263e86c1,openstack/openstack-zuul-jobs,master,Ieceb107dbb8135345fba8b17af362ea0263e86c1,Remove legacy bgpvpn jobs,MERGED,2020-01-23 12:58:27.000000000,2020-01-30 13:46:14.000000000,2020-01-30 13:42:14.000000000,"[{'_account_id': 1004}, {'_account_id': 6547}, {'_account_id': 8313}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 12:58:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/1b60aa46e77c1c92b7af57b5b730efbd301afbeb', 'message': 'Remove legacy bgpvpn jobs\n\nThese job definitions are now obsolate, new zuulv3 syntax jobs will be\nnetworking-bgpvpn repository, see dependnecy.\n\nChange-Id: Ieceb107dbb8135345fba8b17af362ea0263e86c1\nDepends-On: https://review.opendev.org/703601\n'}, {'number': 2, 'created': '2020-01-30 09:00:52.000000000', 'files': ['playbooks/legacy/networking-bgpvpn-bagpipe-dsvm-functional/post.yaml', 'playbooks/legacy/networking-bgpvpn-bagpipe-dsvm-install/post.yaml', 'zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/networking-bgpvpn-dsvm-functional/run.yaml', 'playbooks/legacy/networking-bgpvpn-dsvm-install/run.yaml', 'playbooks/legacy/networking-bgpvpn-dsvm-install/post.yaml', 'playbooks/legacy/networking-bgpvpn-bagpipe-dsvm-functional/run.yaml', 'playbooks/legacy/networking-bgpvpn-dsvm-functional/post.yaml', 'playbooks/legacy/networking-bgpvpn-bagpipe-dsvm-install/run.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/8fd314e383f79fa898922338d5a446227090f3b4', 'message': 'Remove legacy bgpvpn jobs\n\nThese job definitions are now obsolate, the jobs\nhave been imported in-tree.\n\nChange-Id: Ieceb107dbb8135345fba8b17af362ea0263e86c1\n'}]",2,703986,8fd314e383f79fa898922338d5a446227090f3b4,20,4,2,8313,,,0,"Remove legacy bgpvpn jobs

These job definitions are now obsolate, the jobs
have been imported in-tree.

Change-Id: Ieceb107dbb8135345fba8b17af362ea0263e86c1
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/86/703986/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/zuul-legacy-jobs.yaml'],1,1b60aa46e77c1c92b7af57b5b730efbd301afbeb,zuulv3,, name: legacy-networking-bgpvpn-bagpipe-dsvm-functional parent: legacy-dsvm-base run: playbooks/legacy/networking-bgpvpn-bagpipe-dsvm-functional/run.yaml post-run: playbooks/legacy/networking-bgpvpn-bagpipe-dsvm-functional/post.yaml timeout: 7800 required-projects: - openstack/devstack-gate - openstack/networking-bagpipe - openstack/networking-bgpvpn - job: name: legacy-networking-bgpvpn-bagpipe-dsvm-install parent: legacy-dsvm-base run: playbooks/legacy/networking-bgpvpn-bagpipe-dsvm-install/run.yaml post-run: playbooks/legacy/networking-bgpvpn-bagpipe-dsvm-install/post.yaml timeout: 7800 required-projects: - openstack/devstack-gate - openstack/networking-bagpipe - openstack/networking-bgpvpn - job: name: legacy-networking-bgpvpn-dsvm-functional parent: legacy-dsvm-base run: playbooks/legacy/networking-bgpvpn-dsvm-functional/run.yaml post-run: playbooks/legacy/networking-bgpvpn-dsvm-functional/post.yaml timeout: 7800 required-projects: - openstack/devstack-gate - openstack/networking-bgpvpn - openstack/neutron - openstack/networking-bagpipe - openstack/networking-odl - openstack/horizon - job: name: legacy-networking-bgpvpn-dsvm-install parent: legacy-dsvm-base run: playbooks/legacy/networking-bgpvpn-dsvm-install/run.yaml post-run: playbooks/legacy/networking-bgpvpn-dsvm-install/post.yaml timeout: 7800 required-projects: - openstack/devstack-gate - openstack/networking-bgpvpn - job:,0,46
openstack%2Ftripleo-validations~stable%2Fqueens~Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5,openstack/tripleo-validations,stable/queens,Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5,Sync 'validations/ceph-ansible-installed.yaml' with the new role,MERGED,2020-01-23 07:09:12.000000000,2020-01-30 13:31:10.000000000,2020-01-27 18:58:57.000000000,"[{'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 11491}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 25402}, {'_account_id': 25877}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-23 07:09:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/d09629cba09b7e20356d1bdb7d107fab9ba5f61b', 'message': ""Add an additional validation to check ceph-ansible repository\n\nIn order to address the ceph-ansible potential cross-shipping,\nthis change adds an extra task to validate the repository that\nshould be used to install ceph-ansible in the undercloud.\nIf ceph-ansible is not installed or the repo doesn't match the\nspecified one, this validation raise an error.\n\nChange-Id: Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5\nCloses-Bug: 1857460\n(cherry picked from commit 329f740d109b87105eac36fade70c69c15781a38)\n""}, {'number': 2, 'created': '2020-01-23 14:39:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/6156d0d7c6d7636118da4036d449e0083e5f4bae', 'message': ""Add an additional validation to check ceph-ansible repository\n\nIn order to address the ceph-ansible potential cross-shipping,\nthis change adds an extra task to validate the repository that\nshould be used to install ceph-ansible in the undercloud.\nIf ceph-ansible is not installed or the repo doesn't match the\nspecified one, this validation raise an error.\n\nDepends-On: https://review.opendev.org/#/c/703999\nChange-Id: Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5\nCloses-Bug: 1857460\n(cherry picked from commit 329f740d109b87105eac36fade70c69c15781a38)\n""}, {'number': 3, 'created': '2020-01-23 15:32:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/9ae183f5a3e31e3016f9c726085b22583899b645', 'message': ""Add an additional validation to check ceph-ansible repository\n\nIn order to address the ceph-ansible potential cross-shipping,\nthis change adds an extra task to validate the repository that\nshould be used to install ceph-ansible in the undercloud.\nIf ceph-ansible is not installed or the repo doesn't match the\nspecified one, this validation raise an error.\n\nDepends-On: https://review.opendev.org/#/c/703999\nChange-Id: Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5\nCloses-Bug: 1857460\n(cherry picked from commit 329f740d109b87105eac36fade70c69c15781a38)\n""}, {'number': 4, 'created': '2020-01-23 15:46:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/37ffc0ba97ae33f20c56044c27e9e2de3722a91f', 'message': ""Add an additional validation to check ceph-ansible repository\n\nIn order to address the ceph-ansible potential cross-shipping,\nthis change adds an extra task to validate the repository that\nshould be used to install ceph-ansible in the undercloud.\nIf ceph-ansible is not installed or the repo doesn't match the\nspecified one, this validation raise an error.\n\nChange-Id: Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5\nCloses-Bug: 1857460\n(cherry picked from commit 329f740d109b87105eac36fade70c69c15781a38)\n""}, {'number': 5, 'created': '2020-01-23 16:00:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/0c8764c4bf1c134c5aa444cdf9866a3bc1d01e70', 'message': ""Add an additional validation to check ceph-ansible repository\n\nIn order to address the ceph-ansible potential cross-shipping,\nthis change adds an extra task to validate the repository that\nshould be used to install ceph-ansible in the undercloud.\nIf ceph-ansible is not installed or the repo doesn't match the\nspecified one, this validation raise an error.\n\nChange-Id: Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5\nCloses-Bug: 1857460\n(cherry picked from commit 329f740d109b87105eac36fade70c69c15781a38)\n""}, {'number': 6, 'created': '2020-01-24 15:59:48.000000000', 'files': ['validations/ceph-ansible-installed.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/1ac55cd6f95f422284ef2bdf3eb62bca15874fe1', 'message': ""Sync 'validations/ceph-ansible-installed.yaml' with the new role\n\nCloses-Bug: 1857460\nChange-Id: Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5\n(cherry picked from commit 716a3083232ca137ed617ada73f49a6fe5a6869b)\n""}]",1,703928,1ac55cd6f95f422284ef2bdf3eb62bca15874fe1,20,9,6,25402,,,0,"Sync 'validations/ceph-ansible-installed.yaml' with the new role

Closes-Bug: 1857460
Change-Id: Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5
(cherry picked from commit 716a3083232ca137ed617ada73f49a6fe5a6869b)
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/28/703928/1 && git format-patch -1 --stdout FETCH_HEAD,['validations/ceph-ansible-installed.yaml'],1,d09629cba09b7e20356d1bdb7d107fab9ba5f61b,sync_validations," fail_without_ceph_ansible: false ceph_ansible_repo: ""centos-ceph-luminous"" - ceph_ansible_installed.stdout.find('is not installed') != -1 - fail_without_ceph_ansible|default(false)|bool - name: Get ceph-ansible repository shell: ""yum info ceph-ansible | awk '/From repo/ {print $4}'"" register: repo changed_when: False - name: Fail if ceph-ansible doesn't belong to the specified repo fail: msg: ""Make sure ceph-ansible package is installed from {{ ceph_ansible_repo }}"" when: - (repo.stdout | length == 0 or repo.stdout != ""{{ ceph_ansible_repo }}"") - fail_without_ceph_ansible|default(false)|bool",,16,0
openstack%2Ftripleo-heat-templates~master~I3683820bf6c547f5151fc4f5c9696e58b50dac75,openstack/tripleo-heat-templates,master,I3683820bf6c547f5151fc4f5c9696e58b50dac75,Remove /run bind-mount from mistral containers,MERGED,2020-01-29 14:05:39.000000000,2020-01-30 13:29:52.000000000,2020-01-30 13:29:51.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 9712}, {'_account_id': 14985}, {'_account_id': 15895}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-29 14:05:39.000000000', 'files': ['deployment/mistral/mistral-executor-container-puppet.yaml', 'deployment/mistral/mistral-event-engine-container-puppet.yaml', 'deployment/mistral/mistral-engine-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2426780600c6d2f610e066111947d0655c325fd9', 'message': ""Remove /run bind-mount from mistral containers\n\nApparently, there isn't any real use for this bind-mount. Removing it\nmight also make things better for the content of audit.log, especially\nif we can avoid exposing DBus socket in the container (sudo does some\nweird things with it).\n\nChange-Id: I3683820bf6c547f5151fc4f5c9696e58b50dac75\nRelated-Bug: #1819461\n""}]",0,704808,2426780600c6d2f610e066111947d0655c325fd9,14,9,1,28223,,,0,"Remove /run bind-mount from mistral containers

Apparently, there isn't any real use for this bind-mount. Removing it
might also make things better for the content of audit.log, especially
if we can avoid exposing DBus socket in the container (sudo does some
weird things with it).

Change-Id: I3683820bf6c547f5151fc4f5c9696e58b50dac75
Related-Bug: #1819461
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/08/704808/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/mistral/mistral-executor-container-puppet.yaml', 'deployment/mistral/mistral-event-engine-container-puppet.yaml', 'deployment/mistral/mistral-engine-container-puppet.yaml']",3,2426780600c6d2f610e066111947d0655c325fd9,mistral/no-run-mount,, - /run:/run,0,3
openstack%2Foslo.i18n~master~I36ef5b39b48e259b51f2bb03caf3443d8969c1e9,openstack/oslo.i18n,master,I36ef5b39b48e259b51f2bb03caf3443d8969c1e9,tox: Trivial cleanup,MERGED,2019-12-20 10:00:00.000000000,2020-01-30 13:26:45.000000000,2020-01-30 13:24:01.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 31245}]","[{'number': 1, 'created': '2019-12-20 10:00:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/dbf03085c45b5c439ddd518679ec3369e53c9b32', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: I36ef5b39b48e259b51f2bb03caf3443d8969c1e9\n""}, {'number': 2, 'created': '2020-01-08 18:38:04.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/70317a0109de134b950baef63179429ca10c8da1', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: I36ef5b39b48e259b51f2bb03caf3443d8969c1e9\n""}]",1,700137,70317a0109de134b950baef63179429ca10c8da1,13,4,2,28522,,,0,"tox: Trivial cleanup

Move 'basepython' to the top-level 'testenv'.
Use the default 'install_command'

https://tox.readthedocs.io/en/latest/config.html#conf-install_command

Change-Id: I36ef5b39b48e259b51f2bb03caf3443d8969c1e9
",git fetch https://review.opendev.org/openstack/oslo.i18n refs/changes/37/700137/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,dbf03085c45b5c439ddd518679ec3369e53c9b32,base_python,basepython = python3,install_command = pip install {opts} {packages}basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,1,7
openstack%2Foslo.middleware~master~I0f7296cfd8586b5b41c7a237561c4d931ee1e3d1,openstack/oslo.middleware,master,I0f7296cfd8586b5b41c7a237561c4d931ee1e3d1,tox: Trivial cleanup,MERGED,2019-12-20 10:05:19.000000000,2020-01-30 13:26:02.000000000,2020-01-30 13:24:32.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-12-20 10:05:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/96ea18ffdc0681be2c8983853264b00fdaac6e1c', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: I0f7296cfd8586b5b41c7a237561c4d931ee1e3d1\n""}, {'number': 2, 'created': '2020-01-08 19:02:26.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/c93f92b611c9186594df20a715c8ea88f6fb9f22', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: I0f7296cfd8586b5b41c7a237561c4d931ee1e3d1\n""}]",2,700139,c93f92b611c9186594df20a715c8ea88f6fb9f22,14,3,2,28522,,,0,"tox: Trivial cleanup

Move 'basepython' to the top-level 'testenv'.
Use the default 'install_command'

https://tox.readthedocs.io/en/latest/config.html#conf-install_command

Change-Id: I0f7296cfd8586b5b41c7a237561c4d931ee1e3d1
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/39/700139/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,96ea18ffdc0681be2c8983853264b00fdaac6e1c,base_python,basepython = python3,install_command = pip install {opts} {packages}basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,1,7
openstack%2Foslo.log~master~I7269b71668b7d37886bdfd02a188cc9d6fd0c958,openstack/oslo.log,master,I7269b71668b7d37886bdfd02a188cc9d6fd0c958,tox: Trivial cleanup,MERGED,2019-12-20 10:03:00.000000000,2020-01-30 13:24:33.000000000,2020-01-30 13:23:03.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27621}, {'_account_id': 27822}, {'_account_id': 31245}]","[{'number': 1, 'created': '2019-12-20 10:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/ea2ca479d95f8e53c2c4290c2c313b6cb0d2b73d', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\n\nChange-Id: I7269b71668b7d37886bdfd02a188cc9d6fd0c958\n""}, {'number': 2, 'created': '2020-01-08 18:33:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/bbd0eb97096cc54659912f38684731a55375cd05', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\n\nChange-Id: I7269b71668b7d37886bdfd02a188cc9d6fd0c958\n""}, {'number': 3, 'created': '2020-01-08 18:34:13.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/d22760ad4924ef56e529bbe6caa173446f2f1bf7', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\n\nChange-Id: I7269b71668b7d37886bdfd02a188cc9d6fd0c958\n""}]",1,700138,d22760ad4924ef56e529bbe6caa173446f2f1bf7,16,5,3,28522,,,0,"tox: Trivial cleanup

Move 'basepython' to the top-level 'testenv'.

Change-Id: I7269b71668b7d37886bdfd02a188cc9d6fd0c958
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/38/700138/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,ea2ca479d95f8e53c2c4290c2c313b6cb0d2b73d,base_python,basepython = python3,basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,1,7
openstack%2Foslo.cache~master~Ia88552f8c379eff0f1f73139c6c3f53e619013fb,openstack/oslo.cache,master,Ia88552f8c379eff0f1f73139c6c3f53e619013fb,tox: Trivial cleanup,MERGED,2019-12-20 09:51:29.000000000,2020-01-30 13:19:25.000000000,2020-01-30 13:17:02.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27621}, {'_account_id': 27822}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-12-20 09:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/f56c296d4d49c74e9d3eb631b3afcc817d150981', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\n\nChange-Id: Ia88552f8c379eff0f1f73139c6c3f53e619013fb\n""}, {'number': 2, 'created': '2020-01-08 18:47:46.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/7316168134dca02fa8ecd53a9ea2c758fdd026c0', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\n\nChange-Id: Ia88552f8c379eff0f1f73139c6c3f53e619013fb\n""}]",6,700132,7316168134dca02fa8ecd53a9ea2c758fdd026c0,18,5,2,28522,,,0,"tox: Trivial cleanup

Move 'basepython' to the top-level 'testenv'.

Change-Id: Ia88552f8c379eff0f1f73139c6c3f53e619013fb
",git fetch https://review.opendev.org/openstack/oslo.cache refs/changes/32/700132/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f56c296d4d49c74e9d3eb631b3afcc817d150981,base_python,basepython = python3basepython = python2.7basepython = python3.5,basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,3,6
openstack%2Foslo.messaging~master~Idef066a2e3b4923789a6b081d5442e931aba4507,openstack/oslo.messaging,master,Idef066a2e3b4923789a6b081d5442e931aba4507,Add support for kafka SSL autentication,MERGED,2019-11-15 10:31:15.000000000,2020-01-30 13:16:40.000000000,2020-01-30 13:14:32.000000000,"[{'_account_id': 15334}, {'_account_id': 20523}, {'_account_id': 22348}, {'_account_id': 27339}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-11-15 10:31:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/3151aba79d1f82aa2212eda4b6154d908a36ab51', 'message': 'Add support for kafka SSL autentication\n\nChange-Id: Idef066a2e3b4923789a6b081d5442e931aba4507\n'}, {'number': 2, 'created': '2020-01-16 12:22:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/49f37afdbf2b4538e540ce4f527ecffdcabf259b', 'message': 'Add support for kafka SSL autentication\n\nChange-Id: Idef066a2e3b4923789a6b081d5442e931aba4507\n'}, {'number': 3, 'created': '2020-01-16 22:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/bb32a5e9c03b7bf832a70414cf299942297ce431', 'message': 'Add support for kafka SSL autentication\n\nChange-Id: Idef066a2e3b4923789a6b081d5442e931aba4507\n'}, {'number': 4, 'created': '2020-01-16 22:27:04.000000000', 'files': ['oslo_messaging/_drivers/impl_kafka.py', 'oslo_messaging/_drivers/kafka_driver/kafka_options.py', 'oslo_messaging/tests/drivers/test_impl_kafka.py', 'releasenotes/notes/add-ssl-support-for-kafka.yaml'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/5a43d4548a8cab82222d8d4d0fddc246a1f1fa32', 'message': 'Add support for kafka SSL autentication\n\nChange-Id: Idef066a2e3b4923789a6b081d5442e931aba4507\n'}]",1,694507,5a43d4548a8cab82222d8d4d0fddc246a1f1fa32,24,5,4,27339,,,0,"Add support for kafka SSL autentication

Change-Id: Idef066a2e3b4923789a6b081d5442e931aba4507
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/07/694507/4 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/_drivers/impl_kafka.py', 'oslo_messaging/_drivers/kafka_driver/kafka_options.py']",2,3151aba79d1f82aa2212eda4b6154d908a36ab51,," ' certificate'), cfg.StrOpt('ssl_client_cert_file', default='', help='Client certificate PEM file used for authentication.'), cfg.StrOpt('ssl_client_key_file', default='', help='Client key PEM file used for authentication.'), cfg.StrOpt('ssl_client_key_password', default='', help='Client key password file used for authentication.')", ' certificate'),23,2
openstack%2Foslo.utils~master~I45981d5e80ab8ea03176ce08e119556fec078a37,openstack/oslo.utils,master,I45981d5e80ab8ea03176ce08e119556fec078a37,tox: Trivial cleanup,MERGED,2019-12-20 10:19:27.000000000,2020-01-30 13:14:54.000000000,2020-01-30 13:12:21.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 28522}, {'_account_id': 31245}]","[{'number': 1, 'created': '2019-12-20 10:19:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/1a02dd8668bb822cf0a0a65ae2d94d26fb6af4aa', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: I45981d5e80ab8ea03176ce08e119556fec078a37\n""}, {'number': 2, 'created': '2020-01-08 18:51:32.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/d8c91bc7d0f12608e33212890bf4f07287b5df37', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: I45981d5e80ab8ea03176ce08e119556fec078a37\n""}]",3,700149,d8c91bc7d0f12608e33212890bf4f07287b5df37,15,5,2,28522,,,0,"tox: Trivial cleanup

Move 'basepython' to the top-level 'testenv'.
Use the default 'install_command'

https://tox.readthedocs.io/en/latest/config.html#conf-install_command

Change-Id: I45981d5e80ab8ea03176ce08e119556fec078a37
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/49/700149/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,1a02dd8668bb822cf0a0a65ae2d94d26fb6af4aa,base_python,basepython = python3,install_command = pip install {opts} {packages}basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,1,8
openstack%2Foslo.config~master~I4957925d96c2eea0f9a2d791feb71b6d3f54a224,openstack/oslo.config,master,I4957925d96c2eea0f9a2d791feb71b6d3f54a224,tox: Trivial cleanup,MERGED,2019-12-20 09:46:39.000000000,2020-01-30 13:14:38.000000000,2020-01-30 13:11:33.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 31245}]","[{'number': 1, 'created': '2019-12-20 09:46:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/36d2e829ba9d8088e67d6dfdc688c0394ea38fb6', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\n\nChange-Id: I4957925d96c2eea0f9a2d791feb71b6d3f54a224\n""}, {'number': 2, 'created': '2020-01-08 19:01:03.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/db72309ae8b155453ce778606d7e9f939ed91c33', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\n\nChange-Id: I4957925d96c2eea0f9a2d791feb71b6d3f54a224\n""}]",1,700130,db72309ae8b155453ce778606d7e9f939ed91c33,13,4,2,28522,,,0,"tox: Trivial cleanup

Move 'basepython' to the top-level 'testenv'.

Change-Id: I4957925d96c2eea0f9a2d791feb71b6d3f54a224
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/30/700130/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,36d2e829ba9d8088e67d6dfdc688c0394ea38fb6,base_python,basepython = python3,basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,1,7
openstack%2Fdesignate~master~Ida918a2d670a69cc8995983d23e5424bd48de8a9,openstack/designate,master,Ida918a2d670a69cc8995983d23e5424bd48de8a9,Fixing services getting stuck on shutdown,MERGED,2019-12-23 08:23:59.000000000,2020-01-30 13:12:18.000000000,2020-01-30 13:09:25.000000000,"[{'_account_id': 8099}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2019-12-23 08:23:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/24df46501f7440ba647d1608334e6482ca7afd95', 'message': '[WIP] Move Heartbeat into base class\n\nChange-Id: Ida918a2d670a69cc8995983d23e5424bd48de8a9\n'}, {'number': 2, 'created': '2019-12-23 08:32:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/257b4054694c751d88a2927b1213bde423322760', 'message': '[WIP] Move Heartbeat into base class\n\nChange-Id: Ida918a2d670a69cc8995983d23e5424bd48de8a9\n'}, {'number': 3, 'created': '2019-12-23 08:57:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/2871ae6ab8b4f382317f0687b5b8496b0136b1cb', 'message': '[WIP] Move Heartbeat into base class\n\nChange-Id: Ida918a2d670a69cc8995983d23e5424bd48de8a9\n'}, {'number': 4, 'created': '2019-12-23 08:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/732817374dd374666156c6d308e1e57fff9b0a62', 'message': '[WIP] Move Heartbeat into base class\n\nChange-Id: Ida918a2d670a69cc8995983d23e5424bd48de8a9\n'}, {'number': 5, 'created': '2019-12-23 09:00:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/e358f7769e5ccf666d53a3435214e8f4b0b22fd6', 'message': '[WIP] Move Heartbeat into base class\n\nChange-Id: Ida918a2d670a69cc8995983d23e5424bd48de8a9\n'}, {'number': 6, 'created': '2019-12-23 09:08:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/e614bf78fc12b0511142abcc77236b09f69cb584', 'message': '[WIP] Move Heartbeat into base class\n\nChange-Id: Ida918a2d670a69cc8995983d23e5424bd48de8a9\n'}, {'number': 7, 'created': '2019-12-23 09:20:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/7f8f22177295335b2bc2ceb404a94de44d119789', 'message': ""Fixing services getting stuck on shutdown\n\nThe new heartbeat code was causing the service to\nnot exit properly. This patch adds a thread group\nspecifically for the heartbeat service, so that\nthere can't be a race condition on shutdown.\n\nChange-Id: Ida918a2d670a69cc8995983d23e5424bd48de8a9\n""}, {'number': 8, 'created': '2019-12-24 23:09:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/76e9382ed081e0f6aaa91b47d0effebaf9c7a2cc', 'message': ""Fixing services getting stuck on shutdown\n\nThe new heartbeat code was causing the service to\nnot exit properly. This patch adds a thread group\nspecifically for the heartbeat service, so that\nthere can't be a race condition on shutdown.\n\nCloses-Bug: #1857476\nChange-Id: Ida918a2d670a69cc8995983d23e5424bd48de8a9\n""}, {'number': 9, 'created': '2019-12-25 00:50:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/b12708de222f711257b5a7216a45a3115a5c3716', 'message': ""Fixing services getting stuck on shutdown\n\nThe new heartbeat code was causing the service to\nnot exit properly. This patch adds a thread group\nspecifically for the heartbeat service, so that\nthere can't be a race condition on shutdown.\n\nCloses-Bug: #1857476\nChange-Id: Ida918a2d670a69cc8995983d23e5424bd48de8a9\n""}, {'number': 10, 'created': '2019-12-25 04:07:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/e0108c88037156febfc6bd56906b547ce961b6f6', 'message': 'Fixing services getting stuck on shutdown\n\nThe new heartbeat code was causing the service to\nnot exit properly. This patch removes the use of a\nthread group for handling heartbeats and replaces\nit with a FixedIntervalLoopingCall instead.\n\nCloses-Bug: #1857476\nChange-Id: Ida918a2d670a69cc8995983d23e5424bd48de8a9\n'}, {'number': 11, 'created': '2019-12-25 04:10:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/a72189548a745afbc3f6b983e28f7c16dc0e8050', 'message': 'Fixing services getting stuck on shutdown\n\nThe new heartbeat code was causing the service to\nnot exit properly. This patch removes the use of a\nthread group for handling heartbeats and replaces\nit with a FixedIntervalLoopingCall instead.\n\nCloses-Bug: #1857476\nChange-Id: Ida918a2d670a69cc8995983d23e5424bd48de8a9\n'}, {'number': 12, 'created': '2019-12-25 04:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/18a2467ca66dbc32b38b6eef32eded852852f633', 'message': 'Fixing services getting stuck on shutdown\n\nThe new heartbeat code was causing the service to\nnot exit properly. This patch removes the use of a\nthread group for handling heartbeats and replaces\nit with a FixedIntervalLoopingCall instead.\n\nCloses-Bug: #1857476\nChange-Id: Ida918a2d670a69cc8995983d23e5424bd48de8a9\n'}, {'number': 13, 'created': '2019-12-29 02:48:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/384d8b875883a564c993255b70b74c51f83c2454', 'message': 'Fixing services getting stuck on shutdown\n\nThe new heartbeat code was causing the service to\nnot exit properly. This patch removes the use of a\nthread group for handling heartbeats and replaces\nit with a FixedIntervalLoopingCall instead.\n\nCloses-Bug: #1857476\nChange-Id: Ida918a2d670a69cc8995983d23e5424bd48de8a9\n'}, {'number': 14, 'created': '2020-01-16 18:54:44.000000000', 'files': ['designate/cmd/worker.py', 'designate/cmd/mdns.py', 'designate/tests/unit/test_heartbeat.py', 'designate/cmd/sink.py', 'designate/service_status.py', 'designate/api/wsgi.py', 'designate/cmd/api.py', 'designate/cmd/central.py', 'designate/service.py', 'designate/cmd/producer.py', 'designate/tests/unit/test_service_status.py', 'designate/cmd/agent.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/136a9f79fafaf94d18b81618943c0f73b38bfdfe', 'message': 'Fixing services getting stuck on shutdown\n\nThe new heartbeat code was causing the service to\nnot exit properly. This patch removes the use of a\nthread group for handling heartbeats and replaces\nit with a FixedIntervalLoopingCall instead.\n\nCloses-Bug: #1857476\nChange-Id: Ida918a2d670a69cc8995983d23e5424bd48de8a9\n'}]",0,700390,136a9f79fafaf94d18b81618943c0f73b38bfdfe,26,3,14,22623,,,0,"Fixing services getting stuck on shutdown

The new heartbeat code was causing the service to
not exit properly. This patch removes the use of a
thread group for handling heartbeats and replaces
it with a FixedIntervalLoopingCall instead.

Closes-Bug: #1857476
Change-Id: Ida918a2d670a69cc8995983d23e5424bd48de8a9
",git fetch https://review.opendev.org/openstack/designate refs/changes/90/700390/13 && git format-patch -1 --stdout FETCH_HEAD,"['designate/cmd/api.py', 'designate/cmd/worker.py', 'designate/cmd/central.py', 'designate/cmd/mdns.py', 'designate/service.py', 'designate/cmd/sink.py', 'designate/cmd/producer.py', 'designate/cmd/agent.py']",8,24df46501f7440ba647d1608334e6482ca7afd95,heartbeat_fix,," heartbeat = service.Heartbeat(server.service_name, server.tg) heartbeat.start()",6,17
openstack%2Fopenstack-ansible-os_keystone~stable%2Ftrain~I92a9237a1f596ed935a0b36db93cda1a65578f56,openstack/openstack-ansible-os_keystone,stable/train,I92a9237a1f596ed935a0b36db93cda1a65578f56,Federated openid support using auth_mod_openidc,ABANDONED,2020-01-30 13:08:50.000000000,2020-01-30 13:11:16.000000000,,[],"[{'number': 1, 'created': '2020-01-30 13:08:50.000000000', 'files': ['templates/keystone.conf.j2', 'tasks/main.yml', 'tasks/keystone_federation_sp_shib_setup.yml', 'releasenotes/notes/mod-auth-openidc-102bd253b677f3fc.yaml', 'templates/keystone-httpd.conf.j2', 'vars/redhat.yml', 'vars/debian.yml', 'defaults/main.yml', 'tasks/keystone_apache.yml', 'vars/suse.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/71a072d376888b87588c5c6c6e1070221ac2c321', 'message': 'Federated openid support using auth_mod_openidc\n\nThis patch adds support for using mod_auth_openidc instead of shibboleth for\nsupporting users who have a preference to use oidc for federation. A new\nvariable to called apache_mod is added to keystone_sp allowing the auth library\nto be selected. If left undefined shibboleth auth module will continue to be\ninstalled by default maintaining backward compatibility.\n\nThis patch does not support simultaneous use of shibboleth and mod_auth_openidc\nprimarily because shib2 depends on libcurl3 but mod_auth_openidc depends on\nlibcurl4 which cannot coexist on Ubuntu. This can be resolved when there is a\nshib3 package available in a future release of Ubuntu.\n\nChange-Id: I92a9237a1f596ed935a0b36db93cda1a65578f56\n'}]",0,705001,71a072d376888b87588c5c6c6e1070221ac2c321,2,0,1,29865,,,0,"Federated openid support using auth_mod_openidc

This patch adds support for using mod_auth_openidc instead of shibboleth for
supporting users who have a preference to use oidc for federation. A new
variable to called apache_mod is added to keystone_sp allowing the auth library
to be selected. If left undefined shibboleth auth module will continue to be
installed by default maintaining backward compatibility.

This patch does not support simultaneous use of shibboleth and mod_auth_openidc
primarily because shib2 depends on libcurl3 but mod_auth_openidc depends on
libcurl4 which cannot coexist on Ubuntu. This can be resolved when there is a
shib3 package available in a future release of Ubuntu.

Change-Id: I92a9237a1f596ed935a0b36db93cda1a65578f56
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/01/705001/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/keystone.conf.j2', 'tasks/main.yml', 'tasks/keystone_federation_sp_shib_setup.yml', 'releasenotes/notes/mod-auth-openidc-102bd253b677f3fc.yaml', 'templates/keystone-httpd.conf.j2', 'vars/redhat.yml', 'vars/debian.yml', 'defaults/main.yml', 'tasks/keystone_apache.yml', 'vars/suse.yml']",10,71a072d376888b87588c5c6c6e1070221ac2c321,," - ""{{ keystone_sp_apache_mod_auth_openidc | ternary('apache2-mod_auth_openidc', 'shibboleth-sp') }}"" state: ""{{ keystone_sp_apache_mod_shib | ternary('present', 'absent') }}"" - name: ""auth_openidc"" state: ""{{ keystone_sp_apache_mod_auth_openidc | ternary('present', 'absent') }}"""," - shibboleth-sp state: ""{{ ( keystone_sp != {} ) | ternary('present', 'absent') }}""",123,29
openstack%2Fnova-specs~master~I288e4a2bd12702a1e7f7ebed544c95eb4a40e641,openstack/nova-specs,master,I288e4a2bd12702a1e7f7ebed544c95eb4a40e641,Non-Admin user can filter their instances by more filters,MERGED,2020-01-09 16:13:28.000000000,2020-01-30 13:08:26.000000000,2020-01-30 13:02:29.000000000,"[{'_account_id': 8556}, {'_account_id': 9708}, {'_account_id': 14070}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 28595}]","[{'number': 1, 'created': '2020-01-09 16:13:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7e666b16e066abada6b583013beed0bc77e6c3b1', 'message': 'Non-admin user can filter their instances by AZs\n\nNova API specification does not allow user to filter their instances by\navailability zone, it is until now considered to a admin-only filter. As AZ\nare an input parameter at VM creation available to any user and it is an\nimportant notion for cloud usage, it should be easy for anyone to filter\nresources on it.\n\nChange-Id: I288e4a2bd12702a1e7f7ebed544c95eb4a40e641\nImplements: blueprint non-admin-filter-instance-by-az\n'}, {'number': 2, 'created': '2020-01-11 14:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a6572a0334f24e7f1a203b5c8db18a3c5c9f7d40', 'message': 'Non-admin user can filter their instances by AZs\n\nNova API specification does not allow user to filter their instances by\navailability zone, it is until now considered to a admin-only filter. As AZ\nare an input parameter at VM creation available to any user and it is an\nimportant notion for cloud usage, it should be easy for anyone to filter\nresources on it.\n\nChange-Id: I288e4a2bd12702a1e7f7ebed544c95eb4a40e641\nImplements: blueprint non-admin-filter-instance-by-az\n'}, {'number': 3, 'created': '2020-01-25 15:29:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1815e848746e81397f41a52c65fd1bae3daffafd', 'message': 'Non-admin user can filter their instances by AZs\n\nMany instances filter are restricted to admin-only users, while the related\nattribute are readable when showing instance detail for non admin users.\n\nIn order to stay coherent, all existing instance filters who are related to a\nfield readable by default to non admin users when showing instance details,\nshould be allowed by default without policy modification.\n\nAPIImpact\n\nChange-Id: I288e4a2bd12702a1e7f7ebed544c95eb4a40e641\nImplements: blueprint non-admin-filter-instance-by-az\n'}, {'number': 4, 'created': '2020-01-25 15:31:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/649afab26e0a14173e0760ee58775c60120477ab', 'message': 'Non-admin user can filter their instances by AZs\n\nMany instances filter are restricted to admin-only users, while the\nrelated attribute are readable when showing instance detail for non\nadmin users.\n\nIn order to stay coherent, all existing instance filters who are\nrelated to a field readable by default to non admin users when showing\ninstance details, should be allowed by default without policy\nmodification.\n\nAPIImpact\n\nChange-Id: I288e4a2bd12702a1e7f7ebed544c95eb4a40e641\nImplements: blueprint non-admin-filter-instance-by-az\n'}, {'number': 5, 'created': '2020-01-30 07:45:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d68dc2883877fd48afecd562fc525022ef66579e', 'message': 'Non-admin user can filter their instances by AZs\n\nMany instances filter are restricted to admin-only users, while the\nrelated attribute are readable when showing instance detail for non\nadmin users.\n\nIn order to stay coherent, all existing instance filters who are\nrelated to a field readable by default to non admin users when showing\ninstance details, should be allowed by default without policy\nmodification.\n\nAPIImpact\n\nChange-Id: I288e4a2bd12702a1e7f7ebed544c95eb4a40e641\nImplements: blueprint non-admin-filter-instance-by-az\n'}, {'number': 6, 'created': '2020-01-30 08:04:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/033f9f01f403fc6f7c99a4de10f166693c1d558a', 'message': 'Non-admin user can filter their instances by AZs\n\nMany instances filter are restricted to admin-only users, while the\nrelated attribute are readable when showing instance detail for non\nadmin users.\n\nIn order to stay coherent, all existing instance filters who are\nrelated to a field readable by default to non admin users when showing\ninstance details, should be allowed by default without policy\nmodification.\n\nAPIImpact\n\nChange-Id: I288e4a2bd12702a1e7f7ebed544c95eb4a40e641\nImplements: blueprint non-admin-filter-instance-by-az\n'}, {'number': 7, 'created': '2020-01-30 09:54:50.000000000', 'files': ['specs/ussuri/approved/non-admin-filter-instance-by-az.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c76d1b3149de83cd8234642e258054d2e19d3ce3', 'message': 'Non-Admin user can filter their instances by more filters\n\nMany instances filter are restricted to admin-only users, while the\nrelated attribute are readable when showing instance detail for non\nadmin users.\n\nIn order to stay coherent, all existing instance filters who are\nrelated to a field readable by default to non admin users when showing\ninstance details, should be allowed by default without policy\nmodification.\n\nAPIImpact\n\nChange-Id: I288e4a2bd12702a1e7f7ebed544c95eb4a40e641\nImplements: blueprint non-admin-filter-instance-by-az\n'}]",35,701763,c76d1b3149de83cd8234642e258054d2e19d3ce3,37,7,7,28595,,,0,"Non-Admin user can filter their instances by more filters

Many instances filter are restricted to admin-only users, while the
related attribute are readable when showing instance detail for non
admin users.

In order to stay coherent, all existing instance filters who are
related to a field readable by default to non admin users when showing
instance details, should be allowed by default without policy
modification.

APIImpact

Change-Id: I288e4a2bd12702a1e7f7ebed544c95eb4a40e641
Implements: blueprint non-admin-filter-instance-by-az
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/63/701763/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/ussuri/approved/non-admin-filter-instance-by-az.rst'],1,7e666b16e066abada6b583013beed0bc77e6c3b1,bp/non-admin-filter-instance-by-az,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================= Non-Admin user can filter their instance by availability zone ============================================================= https://blueprints.launchpad.net/nova/+spec/non-admin-filter-instance-by-az Nova API specification does not allow user to filter their instances by availability zone, it is until now considered to a admin-only filter. As AZ are an input parameter at VM creation available to any user and it is an important notion for cloud usage, it should be easy for anyone to filter resources on it. Problem description =================== Filtering servers by availability_zone are already possible, as it directly available in the database, it is just restricted to admin only context. Use Cases --------- In a multiple availability zone deployment, it is a commonly shared cloud pattern that users create their resources in multiple AZs in order to get resilient in case of failure of one AZ. Dealing with multiple availability zone can lead to complexity for the user, by example in case of cinder usage, you can disable the ``cross_az_attach`` option to restrict volume attachment to be same AZ as the instance. In that configuration, it can be really useful to the customer to be able to filter their instance by AZ, by example in a user interface use-case, to display only instance who can be attached to a given volume. Proposed change =============== Add a new microversion to servers list APIs to enable availability_zone filter for non admin users. As non admin filters are listed in the _get_server_search_options, it will only require to add ``availability_zone`` in that list for the given microversion. Alternatives ------------ Currently the only way to allow non admin users filter their instances by AZ is to edit the nova policy ``os_compute_api:servers:allow_all_filters``, which can be really painful to maintain during upgrades and can cause security issue as you don't want regular user to use filter like the hypervisor or node one. Data model impact ----------------- None REST API impact --------------- A new microversion will be added as we change the behaviour of the API for non admin users, even if we don't add or remove any parameter. List API will no longer ignore query string parameter availability_zone for regular user: GET /servers?availability_zone=az2 GET /servers/detail?availability_zone=az1 Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- Python client may add help to inform users this new filter. Add support for the availability zone filter in python-novaclient for the 'nova list' command. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Upgrade impact -------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Victor Coutellier Feature Liaison --------------- Feature liaison: Liaison Needed Work Items ---------- * Add availability_zone to the non-admin whitelisted instance filter * Add related test * Add support for availability_zone to the 'nova list' operation in novaclient Dependencies ============ None Testing ======= * Add related unittest * Add related functional test Documentation Impact ==================== The nova API documentation will need to be updated to reflect the REST API changes, and adding microversion instructions. References ========== None History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Ussuri - Introduced ",,144,0
openstack%2Foslo.privsep~master~Ic951cc21208e54105cfd42fbd28ce1f2f738cced,openstack/oslo.privsep,master,Ic951cc21208e54105cfd42fbd28ce1f2f738cced,tox: Trivial cleanup,MERGED,2019-12-20 10:08:10.000000000,2020-01-30 13:06:57.000000000,2020-01-30 13:01:47.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 31245}]","[{'number': 1, 'created': '2019-12-20 10:08:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.privsep/commit/1d3fea4e8fbd3845655e44190eb3f3e22b5a51e6', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: Ic951cc21208e54105cfd42fbd28ce1f2f738cced\n""}, {'number': 2, 'created': '2020-01-08 18:55:25.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.privsep/commit/e39c40b62957ce09878381c8845dfdf32e65acea', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: Ic951cc21208e54105cfd42fbd28ce1f2f738cced\n""}]",2,700141,e39c40b62957ce09878381c8845dfdf32e65acea,13,4,2,28522,,,0,"tox: Trivial cleanup

Move 'basepython' to the top-level 'testenv'.
Use the default 'install_command'

https://tox.readthedocs.io/en/latest/config.html#conf-install_command

Change-Id: Ic951cc21208e54105cfd42fbd28ce1f2f738cced
",git fetch https://review.opendev.org/openstack/oslo.privsep refs/changes/41/700141/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,1d3fea4e8fbd3845655e44190eb3f3e22b5a51e6,base_python,basepython = python3,install_command = pip install {opts} {packages}basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,1,7
openstack%2Foslo.policy~master~Iacd257fc6c351582de45476768e3fd1775317d3c,openstack/oslo.policy,master,Iacd257fc6c351582de45476768e3fd1775317d3c,Initialize global config object in cli tools,MERGED,2019-10-23 16:11:46.000000000,2020-01-30 13:06:01.000000000,2020-01-30 13:03:37.000000000,"[{'_account_id': 6928}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-10-23 16:11:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/a2947cea02f46dfa763d5106d6df2686c614e78f', 'message': ""Initialize global config object in oslopolicy-list-redundant\n\nWe need to use the global conf object for this tool so that when the\nprojects initialize the global conf object in their get_enforcer\nfunction it has the necessary cli args registered on it. As a followup\nto this change, we will need to modify each project to parse cli args\nin its call to the conf object so things like --config-file don't get\ndropped. Currently passing --config-file to oslopolicy-list-redundant\nis ineffective because the projects pass an empty cli arg list to\nthe conf object.\n\nChange-Id: Iacd257fc6c351582de45476768e3fd1775317d3c\nCloses-Bug: 1849518\n""}, {'number': 2, 'created': '2019-10-24 21:08:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/1376d2c44dbff1f369924f15f3e7fe8e78641efc', 'message': ""Initialize global config object in cli tools\n\nCurrently, passing --config-file to a tool like oslopolicy-list-redundant\nis ineffective because the projects pass an empty cli arg list to the\nconf object when they initialize it. By registering our cli args on the\nglobal conf object, the projects can safely parse cli args in their\ncall to the conf object so things like --config-file won't be ignored.\nThis didn't work before because oslo.policy recognizes cli args like\n--namespace that aren't recognized by the consuming projects.\n\nThis will require followup changes in each project to stop passing an\nempty cli arg list to the conf object initialization.\n\nChange-Id: Iacd257fc6c351582de45476768e3fd1775317d3c\nCloses-Bug: 1849518\n""}, {'number': 3, 'created': '2020-01-15 16:52:53.000000000', 'files': ['oslo_policy/tests/test_generator.py', 'oslo_policy/generator.py'], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/686aa238f921e8b6dff814d001690e15fa8ccea6', 'message': ""Initialize global config object in cli tools\n\nCurrently, passing --config-file to a tool like oslopolicy-list-redundant\nis ineffective because the projects pass an empty cli arg list to the\nconf object when they initialize it. By registering our cli args on the\nglobal conf object, the projects can safely parse cli args in their\ncall to the conf object so things like --config-file won't be ignored.\nThis didn't work before because oslo.policy recognizes cli args like\n--namespace that aren't recognized by the consuming projects.\n\nThis will require followup changes in each project to stop passing an\nempty cli arg list to the conf object initialization.  In the meantime,\neverything should continue to work as it did before.\n\nChange-Id: Iacd257fc6c351582de45476768e3fd1775317d3c\nCloses-Bug: 1849518\n""}]",0,690628,686aa238f921e8b6dff814d001690e15fa8ccea6,18,4,3,6928,,,0,"Initialize global config object in cli tools

Currently, passing --config-file to a tool like oslopolicy-list-redundant
is ineffective because the projects pass an empty cli arg list to the
conf object when they initialize it. By registering our cli args on the
global conf object, the projects can safely parse cli args in their
call to the conf object so things like --config-file won't be ignored.
This didn't work before because oslo.policy recognizes cli args like
--namespace that aren't recognized by the consuming projects.

This will require followup changes in each project to stop passing an
empty cli arg list to the conf object initialization.  In the meantime,
everything should continue to work as it did before.

Change-Id: Iacd257fc6c351582de45476768e3fd1775317d3c
Closes-Bug: 1849518
",git fetch https://review.opendev.org/openstack/oslo.policy refs/changes/28/690628/2 && git format-patch -1 --stdout FETCH_HEAD,['oslo_policy/generator.py'],1,a2947cea02f46dfa763d5106d6df2686c614e78f,bug/1849518, conf = cfg.CONF, conf = cfg.ConfigOpts(),1,1
openstack%2Foslo.context~master~I0999b102ec9ee41fb1d2a4f3f5d4ebcd5b9307ab,openstack/oslo.context,master,I0999b102ec9ee41fb1d2a4f3f5d4ebcd5b9307ab,tox: Trivial cleanup,MERGED,2019-12-20 09:48:58.000000000,2020-01-30 13:01:14.000000000,2020-01-30 12:58:17.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-12-20 09:48:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.context/commit/21770d358a58913a0db915d66b4204024c942931', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\n\nChange-Id: I0999b102ec9ee41fb1d2a4f3f5d4ebcd5b9307ab\n""}, {'number': 2, 'created': '2020-01-08 19:14:59.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.context/commit/558445c7c75d924018b4f4c78430adaff118b5fe', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\n\nChange-Id: I0999b102ec9ee41fb1d2a4f3f5d4ebcd5b9307ab\n""}]",0,700131,558445c7c75d924018b4f4c78430adaff118b5fe,13,3,2,28522,,,0,"tox: Trivial cleanup

Move 'basepython' to the top-level 'testenv'.

Change-Id: I0999b102ec9ee41fb1d2a4f3f5d4ebcd5b9307ab
",git fetch https://review.opendev.org/openstack/oslo.context refs/changes/31/700131/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,21770d358a58913a0db915d66b4204024c942931,base_python,basepython = python3,basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,1,6
openstack%2Fopenstack-ansible-ceph_client~stable%2Ftrain~I8a86554b6ed2a8f409352a9788cb5539d9067b93,openstack/openstack-ansible-ceph_client,stable/train,I8a86554b6ed2a8f409352a9788cb5539d9067b93,Add ceph packages for CentOS deployment,ABANDONED,2020-01-28 12:45:32.000000000,2020-01-30 12:57:41.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-01-28 12:45:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/d0ba1908503a321c1d2fade1144d621c9b3e6c28', 'message': 'Add ceph packages for CentOS and Debian  deployments\n\nThis patch adds centos py3 packages for symlinking into\npy3 venvs.\n\npyhton3-cephfs libraries should be symlinked into manila venv\nfor manila-share correct operation with cephfs driver.\n\nChange-Id: I8a86554b6ed2a8f409352a9788cb5539d9067b93\n(cherry picked from commit f8f8335c6bdf7aad78d9db9483818ac096d32cea)\n'}, {'number': 2, 'created': '2020-01-28 12:46:13.000000000', 'files': ['vars/redhat-7.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/86ad95641e7e4d95d7a6d23a98fc9548536352fe', 'message': 'Add ceph packages for CentOS deployment\n\nThis patch adds centos py3 packages for symlinking into\npy3 venvs.\n\nChange-Id: I8a86554b6ed2a8f409352a9788cb5539d9067b93\n(cherry picked from commit f8f8335c6bdf7aad78d9db9483818ac096d32cea)\n'}]",0,704555,86ad95641e7e4d95d7a6d23a98fc9548536352fe,4,1,2,28619,,,0,"Add ceph packages for CentOS deployment

This patch adds centos py3 packages for symlinking into
py3 venvs.

Change-Id: I8a86554b6ed2a8f409352a9788cb5539d9067b93
(cherry picked from commit f8f8335c6bdf7aad78d9db9483818ac096d32cea)
",git fetch https://review.opendev.org/openstack/openstack-ansible-ceph_client refs/changes/55/704555/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat-7.yml', 'vars/debian.yml']",2,d0ba1908503a321c1d2fade1144d621c9b3e6c28,py3_ceph-stable/train, - python3-cephfs,,4,0
openstack%2Fmistral~master~I98ef8d60b40c13ffa0a6690841f1e27f092dfdea,openstack/mistral,master,I98ef8d60b40c13ffa0a6690841f1e27f092dfdea,Set tempest configuration to support service api,MERGED,2020-01-27 07:25:21.000000000,2020-01-30 12:40:43.000000000,2020-01-30 12:35:10.000000000,"[{'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9712}, {'_account_id': 15895}, {'_account_id': 19134}, {'_account_id': 21970}, {'_account_id': 22348}, {'_account_id': 29124}]","[{'number': 1, 'created': '2020-01-27 07:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/e44cd5b46e0f2f835ead28df7d1db3d3a5c8d547', 'message': 'Set tempest configuration to support service api\n\nThis config is read by tempest test weather to test\nthe service api that was added in ussuri\n\nDepends-On: https://review.opendev.org/704274\nChange-Id: I98ef8d60b40c13ffa0a6690841f1e27f092dfdea\n'}, {'number': 2, 'created': '2020-01-27 08:50:39.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/mistral/commit/906291d7a97bee1a5de371d003259d0946ed69ff', 'message': 'Set tempest configuration to support service api\n\nThis config is read by tempest test weather to test\nthe service api that was added in ussuri\n\nDepends-On: https://review.opendev.org/704274\nChange-Id: I98ef8d60b40c13ffa0a6690841f1e27f092dfdea\n'}]",0,704275,906291d7a97bee1a5de371d003259d0946ed69ff,15,8,2,19134,,,0,"Set tempest configuration to support service api

This config is read by tempest test weather to test
the service api that was added in ussuri

Depends-On: https://review.opendev.org/704274
Change-Id: I98ef8d60b40c13ffa0a6690841f1e27f092dfdea
",git fetch https://review.opendev.org/openstack/mistral refs/changes/75/704275/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,e44cd5b46e0f2f835ead28df7d1db3d3a5c8d547,tempest,"function configure_tempest_for_mistral { if is_service_enabled tempest; then iniset $TEMPEST_CONFIG mistral serice_api_supported True fi } elif [[ ""$1"" == ""stack"" && ""$2"" == ""test-config"" ]]; then echo_summary ""Configuring Tempest for Mistral"" configure_tempest_for_mistral",,8,0
openstack%2Fmistral~master~I9cc78df13d0f0715538bbdb76c8ccad273bd2033,openstack/mistral,master,I9cc78df13d0f0715538bbdb76c8ccad273bd2033,Fix fake clients in actions,MERGED,2020-01-27 13:18:08.000000000,2020-01-30 12:38:04.000000000,2020-01-30 12:35:09.000000000,"[{'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9712}, {'_account_id': 15895}, {'_account_id': 19134}, {'_account_id': 21970}, {'_account_id': 22348}, {'_account_id': 29124}]","[{'number': 1, 'created': '2020-01-27 13:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/6f0e861a3039689899354d5cd297677a483da1d0', 'message': 'Fix fake clients in actions\n\n* Use inspector_url when creating a fake client for ironic inspector client\n* Add a session and a url for designate fake client\n\nChange-Id: I9cc78df13d0f0715538bbdb76c8ccad273bd2033\n'}, {'number': 2, 'created': '2020-01-27 14:34:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/48a31e0ccc774dc6ccbdd5b6979271f1f214ae1d', 'message': 'Fix fake clients in actions\n\n* Use inspector_url when creating a fake client for ironic inspector client\n* Add a session and a url for designate fake client\n\nChange-Id: I9cc78df13d0f0715538bbdb76c8ccad273bd2033\n'}, {'number': 3, 'created': '2020-01-27 14:51:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/bf14e91f04ec1d802b664d28d3bd0322b4dfa677', 'message': 'Fix fake clients in actions\n\n* Use inspector_url when creating a fake client for ironic inspector client\n* Add a session and a url for designate fake client\n\nChange-Id: I9cc78df13d0f0715538bbdb76c8ccad273bd2033\n'}, {'number': 4, 'created': '2020-01-27 15:35:23.000000000', 'files': ['mistral/tests/unit/actions/openstack/test_generator.py', 'mistral/actions/openstack/actions.py', 'mistral/actions/openstack/mapping.json'], 'web_link': 'https://opendev.org/openstack/mistral/commit/eaf0916e312b872f822410fdb732c1a727445543', 'message': 'Fix fake clients in actions\n\n* Use inspector_url when creating a fake client for ironic inspector client\n* Add a session and a url for designate fake client\n\nChange-Id: I9cc78df13d0f0715538bbdb76c8ccad273bd2033\n'}]",0,704318,eaf0916e312b872f822410fdb732c1a727445543,14,8,4,19134,,,0,"Fix fake clients in actions

* Use inspector_url when creating a fake client for ironic inspector client
* Add a session and a url for designate fake client

Change-Id: I9cc78df13d0f0715538bbdb76c8ccad273bd2033
",git fetch https://review.opendev.org/openstack/mistral refs/changes/18/704318/2 && git format-patch -1 --stdout FETCH_HEAD,['mistral/actions/openstack/actions.py'],1,6f0e861a3039689899354d5cd297677a483da1d0,fake_clients," return cls._get_client_class()( inspector_url='http://127.0.0.1:5050') session = keystone_utils.get_admin_session() return cls._get_client_class()( endpoint_override=""http://127.0.0.1:9001/"", session=session )", return cls._get_client_class()() return cls._get_client_class()(),7,2
openstack%2Fmistral~master~I9cabb519a2c229b5269ae56c339160913322648a,openstack/mistral,master,I9cabb519a2c229b5269ae56c339160913322648a,Fix state change propagation in workflows,NEW,2018-10-04 13:35:05.000000000,2020-01-30 12:33:32.000000000,,"[{'_account_id': 21970}, {'_account_id': 22348}, {'_account_id': 27008}]","[{'number': 1, 'created': '2018-10-04 13:35:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/91517c15e64afeb55b2213f7a636247ad6117143', 'message': 'Fix state change propagation in workflows\n\nThe workflow state may be updated concurrently from many sources,\nthus, if the state update (guarded by state conditions) does\nnot change the state in the DB, then the current state must be\nobtained from the DB and should be used to propagate the changes.\n\nCloses-Bug##1779071\n\nChange-Id: I9cabb519a2c229b5269ae56c339160913322648a\n'}, {'number': 2, 'created': '2018-10-09 09:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/aaf6e74924298f9b5bbcc954ca7714fef94a99ef', 'message': 'Fix state change propagation in workflows\n\nThe workflow state may be updated concurrently from many sources,\nthus, if the state update (guarded by state conditions) does\nnot change the state in the DB, then the current state must be\nobtained from the DB and should be used to propagate the changes.\n\nCloses-Bug: #1779071\nChange-Id: I9cabb519a2c229b5269ae56c339160913322648a\n'}, {'number': 3, 'created': '2018-10-18 11:00:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/cabac805580b06326fbc847209170a31acec591f', 'message': 'Fix state change propagation in workflows\n\nThe workflow state may be updated concurrently from many sources,\nthus, if the state update (guarded by state conditions) does\nnot change the state in the DB, then the current state must be\nobtained from the DB and should be used to propagate the changes.\n\nCloses-Bug: #1779071\nChange-Id: I9cabb519a2c229b5269ae56c339160913322648a\n'}, {'number': 4, 'created': '2020-01-30 09:30:39.000000000', 'files': ['mistral/engine/workflows.py', 'mistral/tests/unit/engine/test_set_state.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/e5f55a545314b5daea759b2926099f2fc502a1d6', 'message': 'Fix state change propagation in workflows\n\nThe workflow state may be updated concurrently from many sources,\nthus, if the state update (guarded by state conditions) does\nnot change the state in the DB, then the current state must be\nobtained from the DB and should be used to propagate the changes.\n\nCloses-Bug: #1779071\nChange-Id: I9cabb519a2c229b5269ae56c339160913322648a\n'}]",8,607960,e5f55a545314b5daea759b2926099f2fc502a1d6,10,3,4,21970,,,0,"Fix state change propagation in workflows

The workflow state may be updated concurrently from many sources,
thus, if the state update (guarded by state conditions) does
not change the state in the DB, then the current state must be
obtained from the DB and should be used to propagate the changes.

Closes-Bug: #1779071
Change-Id: I9cabb519a2c229b5269ae56c339160913322648a
",git fetch https://review.opendev.org/openstack/mistral refs/changes/60/607960/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/engine/workflows.py', 'mistral/tests/unit/engine/test_set_state.py']",2,91517c15e64afeb55b2213f7a636247ad6117143,bug/1779071,"from mistral.workflow import states def test_cancel_set_state(self): wf1_text = """""" version: '2.0' wf1: tasks: task1: workflow: wf2 """""" wf2_text = """""" version: '2.0' wf2: tasks: task1: action: std.noop wait-before: 5 """""" wf_service.create_workflows(wf1_text) wf_service.create_workflows(wf2_text) wf_ex = self.engine.start_workflow('wf1') def wait_for_subworkflow_start(): with db_api.transaction(): task_executions = db_api.get_workflow_execution( wf_ex.id).task_executions if task_executions: if task_executions[0]: return task_executions[0].executions return False self._await( predicate=wait_for_subworkflow_start, delay=0.1, timeout=20, fail_message=""Sub workflow not started in time."" ) with db_api.transaction(): temp_wf_ex = db_api.get_workflow_execution(wf_ex.id) sub_wf_ex = temp_wf_ex.task_executions[0].executions[0] self.await_workflow_success(wf_ex.id) # The state in db is SUCCESS, but wf_ex still contains outdated info. self.assertEqual(states.RUNNING, sub_wf_ex.state) wf = workflows.Workflow(sub_wf_ex) # Trying to change the status of succeed execution. There is no error, # only warning message that state has been changed in db. wf.stop(states.CANCELLED) with db_api.transaction(): wf_ex = db_api.get_workflow_execution(sub_wf_ex.id) self.assertEqual(states.SUCCESS, wf_ex.state)",,67,4
openstack%2Foslo.upgradecheck~master~I7c672f05753886e234430c760f1afc1ed01ff2a3,openstack/oslo.upgradecheck,master,I7c672f05753886e234430c760f1afc1ed01ff2a3,tox: Trivial cleanup,MERGED,2019-12-20 10:16:08.000000000,2020-01-30 12:30:10.000000000,2020-01-30 12:25:43.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27621}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-12-20 10:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.upgradecheck/commit/9672b7803764fe1bb76502aa006667825c421d11', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: I7c672f05753886e234430c760f1afc1ed01ff2a3\n""}, {'number': 2, 'created': '2020-01-08 19:13:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.upgradecheck/commit/88d59b11cfe4229135e9ffcc73a8a4d4ec0b58da', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: I7c672f05753886e234430c760f1afc1ed01ff2a3\n""}, {'number': 3, 'created': '2020-01-16 12:39:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.upgradecheck/commit/1fc931149f28e0a091985c1d3ad5bcaf24edf00e', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: I7c672f05753886e234430c760f1afc1ed01ff2a3\n""}, {'number': 4, 'created': '2020-01-17 16:25:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.upgradecheck/commit/b16151a8fd4ae405efd9228f45d2a878bcba811d', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: I7c672f05753886e234430c760f1afc1ed01ff2a3\n""}, {'number': 5, 'created': '2020-01-30 12:01:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.upgradecheck/commit/3731623056777863bf7339c7a96cc6c03eb2c940', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: I7c672f05753886e234430c760f1afc1ed01ff2a3\n""}, {'number': 6, 'created': '2020-01-30 12:01:47.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.upgradecheck/commit/2837bff516eb283e43ec0795d285b9485dbc4e53', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: I7c672f05753886e234430c760f1afc1ed01ff2a3\n""}]",1,700146,2837bff516eb283e43ec0795d285b9485dbc4e53,27,4,6,28522,,,0,"tox: Trivial cleanup

Move 'basepython' to the top-level 'testenv'.
Use the default 'install_command'

https://tox.readthedocs.io/en/latest/config.html#conf-install_command

Change-Id: I7c672f05753886e234430c760f1afc1ed01ff2a3
",git fetch https://review.opendev.org/openstack/oslo.upgradecheck refs/changes/46/700146/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,9672b7803764fe1bb76502aa006667825c421d11,base_python,basepython = python3,install_command = pip install {opts} {packages}basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,1,6
openstack%2Ftripleo-ansible~master~I53761319a6ef161ac0de7f14f3fdd101d8b647e0,openstack/tripleo-ansible,master,I53761319a6ef161ac0de7f14f3fdd101d8b647e0,DNM: debug ansible ssh_known_host,ABANDONED,2020-01-29 11:36:50.000000000,2020-01-30 12:29:59.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-29 11:36:50.000000000', 'files': ['tripleo_ansible/roles/tripleo_ssh_known_hosts/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/4d9f9c0c00284e53422eae0095333f3e9901bbbd', 'message': 'DNM: debug ansible ssh_known_host\n\nChange-Id: I53761319a6ef161ac0de7f14f3fdd101d8b647e0\n'}]",0,704781,4d9f9c0c00284e53422eae0095333f3e9901bbbd,4,2,1,23811,,,0,"DNM: debug ansible ssh_known_host

Change-Id: I53761319a6ef161ac0de7f14f3fdd101d8b647e0
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/81/704781/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo_ssh_known_hosts/tasks/main.yml'],1,4d9f9c0c00284e53422eae0095333f3e9901bbbd,, {{ '# role_networks = ' ~ role_networks }} {{ '# enabled_networks = ' ~ enabled_networks }} {% if true or network in role_networks %}, {% if network in role_networks %},3,1
openstack%2Foslo.upgradecheck~master~Icd6095a373188f5ef152ec2f1748aa7f826ad8a8,openstack/oslo.upgradecheck,master,Icd6095a373188f5ef152ec2f1748aa7f826ad8a8,Bump Babel to 2.3.4 on lower-constraint,MERGED,2020-01-16 12:39:57.000000000,2020-01-30 12:28:39.000000000,2020-01-30 12:25:42.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-16 12:39:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.upgradecheck/commit/c9b5177c6aff747f95f54a0b0eb054cc7fd4b0bf', 'message': 'Bump Babel to 2.3.4 on lower-constraint\n\nChange-Id: Icd6095a373188f5ef152ec2f1748aa7f826ad8a8\n'}, {'number': 2, 'created': '2020-01-17 16:25:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.upgradecheck/commit/cd8dfa982ca85f9f186b4fd086ae4170c714ca74', 'message': 'Bump Babel to 2.3.4 on lower-constraint\n\nChange-Id: Icd6095a373188f5ef152ec2f1748aa7f826ad8a8\n'}, {'number': 3, 'created': '2020-01-30 12:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.upgradecheck/commit/03837f2b62b5997137c4129fb2d3283cf1b20100', 'message': 'Bump Babel to 2.3.4 on lower-constraint\n\nCI jobs complains about lower constraint who was not aligned so moving\nBabel from 1.3 to 2.3.4\n\nChange-Id: Icd6095a373188f5ef152ec2f1748aa7f826ad8a8\n'}, {'number': 4, 'created': '2020-01-30 12:01:23.000000000', 'files': ['requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/oslo.upgradecheck/commit/1024d00f10e52273c6c021f221191e9b1a9447ae', 'message': 'Bump Babel to 2.3.4 on lower-constraint\n\nCI jobs complained about lower constraint who was not aligned so moving\nBabel from 1.3 to 2.3.4\n\nChange-Id: Icd6095a373188f5ef152ec2f1748aa7f826ad8a8\n'}]",2,702859,1024d00f10e52273c6c021f221191e9b1a9447ae,15,3,4,28522,,,0,"Bump Babel to 2.3.4 on lower-constraint

CI jobs complained about lower constraint who was not aligned so moving
Babel from 1.3 to 2.3.4

Change-Id: Icd6095a373188f5ef152ec2f1748aa7f826ad8a8
",git fetch https://review.opendev.org/openstack/oslo.upgradecheck refs/changes/59/702859/1 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,c9b5177c6aff747f95f54a0b0eb054cc7fd4b0bf,base_python,Babel==2.3.4,Babel==1.3,1,1
openstack%2Ftempest~master~Ia02102b06329385b09a80d572d73ddf21b9e9be6,openstack/tempest,master,Ia02102b06329385b09a80d572d73ddf21b9e9be6,Fix test_subnet_details scenario test case,ABANDONED,2020-01-17 13:13:07.000000000,2020-01-30 12:15:29.000000000,,"[{'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 8367}, {'_account_id': 8556}, {'_account_id': 9732}, {'_account_id': 11975}, {'_account_id': 20190}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2020-01-17 13:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2822dd1be590e67efd0dcc5fedf957fb6357077c', 'message': 'Fix test_subnet_details scenario test case\n\nWhen guest vm has got some additional nameserver configured in\n/etc/resolv.conf, this test was failing as it was expecting there\nonly servers given from Neutron.\n\nNow tempest checks if all expected servers are configured but will\nnot fail if there is more servers there.\n\nChange-Id: Ia02102b06329385b09a80d572d73ddf21b9e9be6\nCloses-Bug: 1860129\n'}, {'number': 2, 'created': '2020-01-19 09:54:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/aa0f82e01f04ac5adff64dce6c8e2ad7907e0fb6', 'message': 'Fix test_subnet_details scenario test case\n\nWhen guest vm has got some additional nameserver configured in\n/etc/resolv.conf, this test was failing as it was expecting there\nonly servers given from Neutron.\n\nNow tempest checks if all expected servers are configured but will\nnot fail if there is more servers there.\n\nChange-Id: Ia02102b06329385b09a80d572d73ddf21b9e9be6\nCloses-Bug: 1860129\n'}, {'number': 3, 'created': '2020-01-20 12:53:32.000000000', 'files': ['tempest/scenario/test_network_basic_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/ca644105e406252573d4605b5f8a0ca79f94aac0', 'message': 'Fix test_subnet_details scenario test case\n\nWhen guest vm has got some additional nameserver configured in\n/etc/resolv.conf, this test was failing as it was expecting there\nonly servers given from Neutron.\n\nNow tempest checks if all expected servers are configured but will\nnot fail if there is more servers there.\n\nChange-Id: Ia02102b06329385b09a80d572d73ddf21b9e9be6\nCloses-Bug: 1860129\n'}]",4,703072,ca644105e406252573d4605b5f8a0ca79f94aac0,40,10,3,11975,,,0,"Fix test_subnet_details scenario test case

When guest vm has got some additional nameserver configured in
/etc/resolv.conf, this test was failing as it was expecting there
only servers given from Neutron.

Now tempest checks if all expected servers are configured but will
not fail if there is more servers there.

Change-Id: Ia02102b06329385b09a80d572d73ddf21b9e9be6
Closes-Bug: 1860129
",git fetch https://review.opendev.org/openstack/tempest refs/changes/72/703072/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_network_basic_ops.py'],1,2822dd1be590e67efd0dcc5fedf957fb6357077c,bug/1860129," expected_servers = [initial_dns_server] actual_servers = ssh_client.get_dns_servers() for dns_server in expected_servers: self.assertIn(dns_server, actual_servers, 'Looking for server: {trgt_serv}. ' 'Retrieved DNS nameservers: {act_serv} ' 'From host: {host}.' .format(host=ssh_client.ssh_client.host, act_serv=actual_servers, trgt_serv=dns_server))"," dns_servers = [initial_dns_server] servers = ssh_client.get_dns_servers() self.assertEqual(set(dns_servers), set(servers), 'Looking for servers: {trgt_serv}. ' 'Retrieved DNS nameservers: {act_serv} ' 'From host: {host}.' .format(host=ssh_client.ssh_client.host, act_serv=servers, trgt_serv=dns_servers))",10,9
openstack%2Fopenstack-ansible-os_tempest~master~I1d447933af5b668c17576a0ed985683a28fa153a,openstack/openstack-ansible-os_tempest,master,I1d447933af5b668c17576a0ed985683a28fa153a,Use contraints for tempest plugins,MERGED,2020-01-23 12:00:28.000000000,2020-01-30 12:03:45.000000000,2020-01-30 12:00:53.000000000,"[{'_account_id': 1004}, {'_account_id': 8367}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-01-23 12:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/44b0e72acbe55970a8c102d0dce7e25dc4b4fac6', 'message': 'Use contraints for tempest plugins\n\nThis patch unifies the master branch with the changes which have\nbeen necessary to unbreak the stable branches in light of py2 support\nbeing removed from tempest and its plugins.\n\nChange-Id: I1d447933af5b668c17576a0ed985683a28fa153a\n'}, {'number': 2, 'created': '2020-01-23 16:19:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/0ce61ea2a9bedfbd0dc1cf0c5e1cc0c3bc26bfd1', 'message': 'Use contraints for tempest plugins\n\nThis patch unifies the master branch with the changes which have\nbeen necessary to unbreak the stable branches in light of py2 support\nbeing removed from tempest and its plugins.\n\nChange-Id: I1d447933af5b668c17576a0ed985683a28fa153a\n'}, {'number': 3, 'created': '2020-01-27 13:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/121c65a7f54f07a5607a2eeff27442978bc784ec', 'message': 'Use contraints for tempest plugins\n\nThis patch unifies the master branch with the changes which have\nbeen necessary to unbreak the stable branches in light of py2 support\nbeing removed from tempest and its plugins.\n\nDepends-On: https://review.opendev.org/704317\nChange-Id: I1d447933af5b668c17576a0ed985683a28fa153a\n'}, {'number': 4, 'created': '2020-01-29 09:04:45.000000000', 'files': ['tasks/tempest_install_source.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/9de0b7a59f150f5ef7bc9f85870edbafeedcbf10', 'message': 'Use contraints for tempest plugins\n\nThis patch unifies the master branch with the changes which have\nbeen necessary to unbreak the stable branches in light of py2 support\nbeing removed from tempest and its plugins.\n\nDepends-On: https://review.opendev.org/704317\nChange-Id: I1d447933af5b668c17576a0ed985683a28fa153a\n'}]",0,703979,9de0b7a59f150f5ef7bc9f85870edbafeedcbf10,29,6,4,25023,,,0,"Use contraints for tempest plugins

This patch unifies the master branch with the changes which have
been necessary to unbreak the stable branches in light of py2 support
being removed from tempest and its plugins.

Depends-On: https://review.opendev.org/704317
Change-Id: I1d447933af5b668c17576a0ed985683a28fa153a
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/79/703979/2 && git format-patch -1 --stdout FETCH_HEAD,['tasks/tempest_install_source.yml'],1,44b0e72acbe55970a8c102d0dce7e25dc4b4fac6,, --constraint {{ tempest_upper_constraints_url }} --constraint {{ tempest_upper_constraints_url }},,2,0
openstack%2Fopenstack-ansible-os_tempest~master~Ic429a505ceab59f05a781edd4045e4493f1271db,openstack/openstack-ansible-os_tempest,master,Ic429a505ceab59f05a781edd4045e4493f1271db,Mark ubuntu distro install as non voting,MERGED,2020-01-29 09:04:45.000000000,2020-01-30 12:03:25.000000000,2020-01-30 11:47:24.000000000,"[{'_account_id': 1004}, {'_account_id': 8367}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-01-29 09:04:45.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/0e17aafba9535d86399d1512f2fc3a6891883283', 'message': 'Mark ubuntu distro install as non voting\n\nChange-Id: Ic429a505ceab59f05a781edd4045e4493f1271db\n'}]",0,704750,0e17aafba9535d86399d1512f2fc3a6891883283,13,6,1,25023,,,0,"Mark ubuntu distro install as non voting

Change-Id: Ic429a505ceab59f05a781edd4045e4493f1271db
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/50/704750/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,0e17aafba9535d86399d1512f2fc3a6891883283,, - openstack-ansible-deploy-aio_distro_metal-ubuntu-bionic: voting: false - openstack-ansible-deploy-aio_distro_metal-ubuntu-bionic: voting: false,,4,0
openstack%2Fkolla~master~Ibbb720390ff17e11249a5aa77163c15c0971209a,openstack/kolla,master,Ibbb720390ff17e11249a5aa77163c15c0971209a,"CentOS 8: base image fixes for RabbitMQ, fluentd & InfluxDB",MERGED,2020-01-29 11:42:40.000000000,2020-01-30 12:01:04.000000000,2020-01-30 11:59:01.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-29 11:42:40.000000000', 'files': ['docker/base/Dockerfile.j2', 'docker/base/td.repo', 'docker/base/rabbitmq_rabbitmq-server.repo'], 'web_link': 'https://opendev.org/openstack/kolla/commit/bdb0dbddbc30215169baaaa263c583e7d3183607', 'message': 'CentOS 8: base image fixes for RabbitMQ, fluentd & InfluxDB\n\n- Fix td-agent repo URL for fluentd. $releasever and $basearch variables\n  were escaped in the repo URL.\n\n- Disable repo_gpgcheck for RabbitMQ. The rabbitmq-server 3.7 packages\n  on packagecloud are not signed, which is why we have gpgcheck=0 for\n  that repo. Previously repo_gpgcheck was set to 1, but this breaks DNF\n  which does not seem to accept keys imported by rpm --import for\n  signing a repo (as opposed to packages). This causes it to prompt\n  during package install, which does not work without a terminal in the\n  build container. This should be temporary as we will upgrade RabbitMQ\n  to 3.8 soon.\n\n- Add InfluxDB repo back to list of repos to disable.\n\nChange-Id: Ibbb720390ff17e11249a5aa77163c15c0971209a\nPartially-Implements: blueprint centos-rhel-8\n'}]",3,704782,bdb0dbddbc30215169baaaa263c583e7d3183607,13,5,1,14826,,,0,"CentOS 8: base image fixes for RabbitMQ, fluentd & InfluxDB

- Fix td-agent repo URL for fluentd. $releasever and $basearch variables
  were escaped in the repo URL.

- Disable repo_gpgcheck for RabbitMQ. The rabbitmq-server 3.7 packages
  on packagecloud are not signed, which is why we have gpgcheck=0 for
  that repo. Previously repo_gpgcheck was set to 1, but this breaks DNF
  which does not seem to accept keys imported by rpm --import for
  signing a repo (as opposed to packages). This causes it to prompt
  during package install, which does not work without a terminal in the
  build container. This should be temporary as we will upgrade RabbitMQ
  to 3.8 soon.

- Add InfluxDB repo back to list of repos to disable.

Change-Id: Ibbb720390ff17e11249a5aa77163c15c0971209a
Partially-Implements: blueprint centos-rhel-8
",git fetch https://review.opendev.org/openstack/kolla refs/changes/82/704782/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/base/Dockerfile.j2', 'docker/base/td.repo', 'docker/base/rabbitmq_rabbitmq-server.repo']",3,bdb0dbddbc30215169baaaa263c583e7d3183607,bp/centos-rhel-8,"# NOTE(mgoddard): rabbitmq-server 3.7 packages are not signed. Previously # repo_gpgcheck was set to 1, but this breaks DNF which does not seem to accept # keys imported by rpm --import for signing a repo (as opposed to packages). # TODO(mgoddard): Set gpgcheck=1 for rabbitmq-server 3.8+",repo_gpgcheck=1,8,8
openstack%2Fopenstack-ansible-haproxy_server~master~I9f69dbb024e2f4aa660c1f5f968ed201dc3423c2,openstack/openstack-ansible-haproxy_server,master,I9f69dbb024e2f4aa660c1f5f968ed201dc3423c2,Enable ip_nonlocal_bind for IPv6 in addition to IPv4,MERGED,2020-01-30 10:20:26.000000000,2020-01-30 11:55:45.000000000,2020-01-30 11:52:50.000000000,"[{'_account_id': 1004}, {'_account_id': 2463}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2020-01-30 10:20:26.000000000', 'files': ['tasks/haproxy_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-haproxy_server/commit/826741f1f1fc9a4ffc2f6af03cd35a70c33fc3ba', 'message': 'Enable ip_nonlocal_bind for IPv6 in addition to IPv4\n\nSet net.ipv6.ip_nonlocal_bind in addition to net.ipv4.ip_nonlocal_bind\nto allow for haproxy to bind to a IPv6 VIP\n\nChange-Id: I9f69dbb024e2f4aa660c1f5f968ed201dc3423c2\n'}]",0,704955,826741f1f1fc9a4ffc2f6af03cd35a70c33fc3ba,9,4,1,23922,,,0,"Enable ip_nonlocal_bind for IPv6 in addition to IPv4

Set net.ipv6.ip_nonlocal_bind in addition to net.ipv4.ip_nonlocal_bind
to allow for haproxy to bind to a IPv6 VIP

Change-Id: I9f69dbb024e2f4aa660c1f5f968ed201dc3423c2
",git fetch https://review.opendev.org/openstack/openstack-ansible-haproxy_server refs/changes/55/704955/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/haproxy_post_install.yml'],1,826741f1f1fc9a4ffc2f6af03cd35a70c33fc3ba,haproxy_v6_nonlocalbind," name: ""{{ item }}"" with_items: - ""net.ipv4.ip_nonlocal_bind"" - ""net.ipv6.ip_nonlocal_bind""", name: net.ipv4.ip_nonlocal_bind,4,1
openstack%2Foslo.policy~master~I70c01ad88344edd2db384da8b24ba0238764a8ec,openstack/oslo.policy,master,I70c01ad88344edd2db384da8b24ba0238764a8ec,Link to the Keystone role documentation,MERGED,2020-01-15 18:05:26.000000000,2020-01-30 11:47:05.000000000,2020-01-30 11:42:39.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27621}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-15 18:05:26.000000000', 'files': ['doc/source/admin/policy-json-file.rst', 'doc/source/admin/policy-yaml-file.rst'], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/30f5df1b8c4f80ef5685882674aa3faf424f22e3', 'message': 'Link to the Keystone role documentation\n\nThe oslo.policy docs on writing custom policy checks use things like\nthe admin role without explaining where it comes from. This change\nadds a link to the Keystone docs that explain which roles are created\nby default and what they provide access to.\n\nChange-Id: I70c01ad88344edd2db384da8b24ba0238764a8ec\n'}]",0,702713,30f5df1b8c4f80ef5685882674aa3faf424f22e3,9,4,1,6928,,,0,"Link to the Keystone role documentation

The oslo.policy docs on writing custom policy checks use things like
the admin role without explaining where it comes from. This change
adds a link to the Keystone docs that explain which roles are created
by default and what they provide access to.

Change-Id: I70c01ad88344edd2db384da8b24ba0238764a8ec
",git fetch https://review.opendev.org/openstack/oslo.policy refs/changes/13/702713/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/policy-json-file.rst', 'doc/source/admin/policy-yaml-file.rst']",2,30f5df1b8c4f80ef5685882674aa3faf424f22e3,link-keystone-docs,".. note:: ``admin`` is a built-in default role in Keystone. For more details and other roles that may be available, see the `Keystone documentation on default roles. <https://docs.openstack.org/keystone/latest/admin/service-api-protection.html>`_ ",,8,0
openstack%2Ftripleo-heat-templates~stable%2Fstein~I448c01a94a2d5f6f12e0dffce32391a22e2643b4,openstack/tripleo-heat-templates,stable/stein,I448c01a94a2d5f6f12e0dffce32391a22e2643b4,Moving tripleo-ci-centos-7-scenario010-standalone to nv,ABANDONED,2019-10-09 13:36:40.000000000,2020-01-30 11:46:38.000000000,,"[{'_account_id': 6469}, {'_account_id': 6816}, {'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-09 13:36:40.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/226404616cd001ffde28bacb95364b044324de56', 'message': 'Moving tripleo-ci-centos-7-scenario010-standalone to nv\n\nMoving tripleo-ci-centos-7-scenario010-standalone to non-voting on stein\nbranch.\n\nChange-Id: I448c01a94a2d5f6f12e0dffce32391a22e2643b4\n'}]",1,687559,226404616cd001ffde28bacb95364b044324de56,11,6,1,8367,,,0,"Moving tripleo-ci-centos-7-scenario010-standalone to nv

Moving tripleo-ci-centos-7-scenario010-standalone to non-voting on stein
branch.

Change-Id: I448c01a94a2d5f6f12e0dffce32391a22e2643b4
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/59/687559/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,226404616cd001ffde28bacb95364b044324de56,scen10-nv, - tripleo-ci-centos-7-scenario010-standalone: voting: false,,2,0
openstack%2Foslo.policy~master~If23d817ab1392b97f1e2d8cfc3ddef2be9d9619c,openstack/oslo.policy,master,If23d817ab1392b97f1e2d8cfc3ddef2be9d9619c,Make HTTP check doc heading more specific,MERGED,2020-01-15 18:05:26.000000000,2020-01-30 11:45:11.000000000,2020-01-30 11:42:39.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27621}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-15 18:05:26.000000000', 'files': ['doc/source/user/plugins.rst'], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/e49b2ae61275eac8219f1a096be0ae9b5aa79f5d', 'message': 'Make HTTP check doc heading more specific\n\nIt was confusing that this was titled ""Writing custom check rules""\nwhen it only discussed HTTP check rules. This makes it more clear\nwhat the document deals with.\n\nChange-Id: If23d817ab1392b97f1e2d8cfc3ddef2be9d9619c\n'}]",0,702712,e49b2ae61275eac8219f1a096be0ae9b5aa79f5d,9,4,1,6928,,,0,"Make HTTP check doc heading more specific

It was confusing that this was titled ""Writing custom check rules""
when it only discussed HTTP check rules. This makes it more clear
what the document deals with.

Change-Id: If23d817ab1392b97f1e2d8cfc3ddef2be9d9619c
",git fetch https://review.opendev.org/openstack/oslo.policy refs/changes/12/702712/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/plugins.rst'],1,e49b2ae61275eac8219f1a096be0ae9b5aa79f5d,link-keystone-docs,======================== Writing HTTP check rules ======================== :lines: 28-64 ,========================== Writing custom check rules ========================== :lines: 28-64,4,4
openstack%2Foslo-specs~master~I792f90f68c1f9f9848445c8ba8f9f7a207806fc5,openstack/oslo-specs,master,I792f90f68c1f9f9848445c8ba8f9f7a207806fc5,tox: Trivial cleanup,MERGED,2019-12-20 10:14:17.000000000,2020-01-30 11:39:41.000000000,2020-01-30 11:37:19.000000000,"[{'_account_id': 6928}, {'_account_id': 11904}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-12-20 10:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/1f8cc2c9d61c4673724160f643890e48c3e1bba7', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: I792f90f68c1f9f9848445c8ba8f9f7a207806fc5\n""}, {'number': 2, 'created': '2020-01-08 19:21:21.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/8344c5ce652f48841b570d7a4673b45442957d46', 'message': ""tox: Trivial cleanup\n\nMove 'basepython' to the top-level 'testenv'.\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: I792f90f68c1f9f9848445c8ba8f9f7a207806fc5\n""}]",4,700145,8344c5ce652f48841b570d7a4673b45442957d46,18,5,2,28522,,,0,"tox: Trivial cleanup

Move 'basepython' to the top-level 'testenv'.
Use the default 'install_command'

https://tox.readthedocs.io/en/latest/config.html#conf-install_command

Change-Id: I792f90f68c1f9f9848445c8ba8f9f7a207806fc5
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/45/700145/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,1f8cc2c9d61c4673724160f643890e48c3e1bba7,base_python,basepython = python3,install_command = pip install -U {opts} {packages}basepython = python3basepython = python3,1,3
openstack%2Fmistral-tempest-plugin~master~I84ddb8a075269dc475fb56e0fc5ecabd28bba1a8,openstack/mistral-tempest-plugin,master,I84ddb8a075269dc475fb56e0fc5ecabd28bba1a8,Skip service api if not supported,MERGED,2020-01-27 07:24:45.000000000,2020-01-30 11:28:20.000000000,2020-01-30 11:28:20.000000000,"[{'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9712}, {'_account_id': 15895}, {'_account_id': 19134}, {'_account_id': 21970}, {'_account_id': 22348}, {'_account_id': 29124}, {'_account_id': 30755}]","[{'number': 1, 'created': '2020-01-27 07:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-tempest-plugin/commit/dba419560dc1420dbafcedf6fa7d694c26d5956f', 'message': ""Skip service api if not supported\n\nThe Service api was fixed and supported only in ussri\nDon't run it if not supported\n\nChange-Id: I84ddb8a075269dc475fb56e0fc5ecabd28bba1a8\n""}, {'number': 2, 'created': '2020-01-27 08:50:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-tempest-plugin/commit/e9b97e04eb7d1dd2ccf92f7c70f4e3872a7938a4', 'message': ""Skip service api if not supported\n\nThe Service api was fixed and supported only in ussri\nDon't run it if not supported\n\nChange-Id: I84ddb8a075269dc475fb56e0fc5ecabd28bba1a8\n""}, {'number': 3, 'created': '2020-01-27 09:35:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-tempest-plugin/commit/7b50d601e4bf45e1be77f6ba8a65b5965ff1327d', 'message': ""Skip service api if not supported\n\nThe Service api was fixed and supported only in ussri\nDon't run it if not supported\n\nChange-Id: I84ddb8a075269dc475fb56e0fc5ecabd28bba1a8\n""}, {'number': 4, 'created': '2020-01-27 11:45:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-tempest-plugin/commit/cbd5f99b0b7ceaa46e3934049b86918909de97f8', 'message': ""Skip service api if not supported\n\nThe Service api was fixed and supported only in ussri\nDon't run it if not supported\n\nChange-Id: I84ddb8a075269dc475fb56e0fc5ecabd28bba1a8\n""}, {'number': 5, 'created': '2020-01-30 07:53:20.000000000', 'files': ['mistral_tempest_tests/tests/api/v2/test_services.py', 'mistral_tempest_tests/plugin.py', 'mistral_tempest_tests/config.py'], 'web_link': 'https://opendev.org/openstack/mistral-tempest-plugin/commit/cc3455b732b32d475f0eef8c3553fef040d9e990', 'message': ""Skip service api if not supported\n\nThe Service api was fixed and supported only in ussri\nDon't run it if not supported\n\nsee: https://review.opendev.org/#/c/700507/\n     https://review.opendev.org/#/c/700517/\n     \nChange-Id: I84ddb8a075269dc475fb56e0fc5ecabd28bba1a8\n""}]",0,704274,cc3455b732b32d475f0eef8c3553fef040d9e990,20,9,5,19134,,,0,"Skip service api if not supported

The Service api was fixed and supported only in ussri
Don't run it if not supported

see: https://review.opendev.org/#/c/700507/
     https://review.opendev.org/#/c/700517/
     
Change-Id: I84ddb8a075269dc475fb56e0fc5ecabd28bba1a8
",git fetch https://review.opendev.org/openstack/mistral-tempest-plugin refs/changes/74/704274/4 && git format-patch -1 --stdout FETCH_HEAD,['mistral_tempest_tests/tests/api/v2/test_services.py'],1,dba419560dc1420dbafcedf6fa7d694c26d5956f,tempest,"import testtools from tempest import configCONF = config.CONF def service_api_supported(): try: return CONF.mistral.serice_api_supported except Exception: return False @testtools.skipUnless(service_api_supported(), 'Service api is not supported')",,14,0
openstack%2Ftripleo-quickstart-extras~master~Ia30a3c07bbffc6d86539514b13aa258bd6eec8d8,openstack/tripleo-quickstart-extras,master,Ia30a3c07bbffc6d86539514b13aa258bd6eec8d8,"update master skip list, nova issues and timeout",MERGED,2020-01-07 17:11:18.000000000,2020-01-30 11:15:47.000000000,2020-01-08 08:19:14.000000000,"[{'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2020-01-07 17:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/41d860659c77daede1d95b20c173295d3911c1e6', 'message': ""update master skip list, nova issues and timeout\n\nWe'll need to update the bugs on this, but\nfor now we need to get fs020 running w/o\ntiming out. clearly there is an issue w/ nova\n\nChange-Id: Ia30a3c07bbffc6d86539514b13aa258bd6eec8d8\n""}, {'number': 2, 'created': '2020-01-07 17:12:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/ba328eca5ca4900885243d770360b991fb5a01f4', 'message': ""update master skip list, nova issues and timeout\n\nWe'll need to update the bugs on this, but\nfor now we need to get fs020 running w/o\ntiming out. clearly there is an issue w/ nova\n\nRelated-Bug: #1858662\nChange-Id: Ia30a3c07bbffc6d86539514b13aa258bd6eec8d8\n""}, {'number': 3, 'created': '2020-01-08 02:00:14.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip_master.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/4a1526f8d48d5da7f812a70e7d2d407f7650380b', 'message': ""update master skip list, nova issues and timeout\n\nWe'll need to update the bugs on this, but\nfor now we need to get fs020 running w/o\ntiming out. clearly there is an issue w/ nova\n\nRelated-Bug: #1858662\nChange-Id: Ia30a3c07bbffc6d86539514b13aa258bd6eec8d8\n""}]",0,701403,4a1526f8d48d5da7f812a70e7d2d407f7650380b,17,5,3,9592,,,0,"update master skip list, nova issues and timeout

We'll need to update the bugs on this, but
for now we need to get fs020 running w/o
timing out. clearly there is an issue w/ nova

Related-Bug: #1858662
Change-Id: Ia30a3c07bbffc6d86539514b13aa258bd6eec8d8
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/03/701403/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_skip_master.yml'],1,41d860659c77daede1d95b20c173295d3911c1e6,, - test: 'tempest.api.compute.admin.test_migrations.MigrationsAdminTest.test_cold_migration' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.admin.test_migrations.MigrationsAdminTest.test_list_migrations_in_flavor_resize_situation' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.admin.test_migrations.MigrationsAdminTest.test_resize_server_revert_deleted_flavor' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_create_server.ServersTestBootFromVolume' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.admin.test_migrations.MigrationsAdminTest.test_revert_cold_migration' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_device_tagging.TaggedAttachmentsTest.test_tagged_attachment' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_delete_server.DeleteServersTestJSON.test_delete_server_while_in_attached_volume' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.admin.test_volumes_negative.VolumesAdminNegativeTest.test_update_attached_volume_with_nonexistent_volume_in_body' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_delete_server.DeleteServersTestJSON.test_delete_server_while_in_verify_resize_state' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.admin.test_volumes_negative.VolumesAdminNegativeTest' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.volumes.test_attach_volume.AttachVolumeTestJSON.test_attach_detach_volume' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_server_rescue_negative.ServerRescueNegativeTestJSON.test_rescued_vm_detach_volume' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_device_tagging.TaggedBootDevicesTest.test_tagged_boot_devices' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.volumes.test_attach_volume.AttachVolumeTestJSON.test_list_get_volume_attachments' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_device_tagging.TaggedBootDevicesTest' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.volumes.test_attach_volume.AttachVolumeTestJSON' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_device_tagging.TaggedBootDevicesTest_v242.test_tagged_boot_devices' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_device_tagging.TaggedBootDevicesTest_v242' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_disk_config.ServerDiskConfigTestJSON.test_resize_server_from_auto_to_manual' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_disk_config.ServerDiskConfigTestJSON.test_resize_server_from_manual_to_auto' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.scenario.test_minimum_basic.TestMinimumBasicScenario.test_minimum_basic_scenario' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_server_actions.ServerActionsTestJSON.test_rebuild_server_with_volume_attached' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_server_actions.ServerActionsTestJSON.test_resize_server_confirm' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_server_actions.ServerActionsTestJSON.test_resize_server_confirm_from_stopped' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_server_actions.ServerActionsTestJSON.test_resize_server_revert' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.scenario.test_shelve_instance.TestShelveInstance.test_shelve_volume_backed_instance' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_server_actions.ServerActionsTestJSON.test_resize_server_revert_with_volume_attached' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_server_actions.ServerActionsTestJSON.test_resize_volume_backed_server_confirm' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.servers.test_server_actions.ServerActionsTestJSON' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.scenario.test_volume_boot_pattern.TestVolumeBootPattern.test_image_defined_boot_from_volume' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.volumes.test_attach_volume.AttachVolumeShelveTestJSON.test_attach_volume_shelved_or_offload_server' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.scenario.test_volume_boot_pattern.TestVolumeBootPattern.test_volume_boot_pattern' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.scenario.test_volume_boot_pattern.TestVolumeBootPattern' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.volumes.test_attach_volume_negative.AttachVolumeNegativeTest.test_attach_attached_volume_to_different_server' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.volumes.test_attach_volume_negative.AttachVolumeNegativeTest.test_attach_attached_volume_to_same_server' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.compute.volumes.test_attach_volume_negative.AttachVolumeNegativeTest.test_delete_attached_volume' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.volume.test_volumes_snapshots.VolumesSnapshotTestJSON.test_snapshot_create_delete_with_volume_in_use' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.api.volume.test_volumes_snapshots.VolumesSnapshotTestJSON.test_snapshot_create_offline_delete_online' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.scenario.test_network_advanced_server_ops.TestNetworkAdvancedServerOps.test_server_connectivity_cold_migration' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.scenario.test_network_advanced_server_ops.TestNetworkAdvancedServerOps.test_server_connectivity_resize' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662' - test: 'tempest.scenario.test_stamp_pattern.TestStampPattern.test_stamp_pattern' reason: 'timeout' lp: 'https://bugs.launchpad.net/tripleo/+bug/1858662',,123,0
openstack%2Fneutron~stable%2Fqueens~Ia1f7807ea695ca216e19e4a563367609efe7c53e,openstack/neutron,stable/queens,Ia1f7807ea695ca216e19e4a563367609efe7c53e,DNM It's just a test of neutron-tempest-plugin jobs,ABANDONED,2019-11-13 15:26:22.000000000,2020-01-30 11:09:05.000000000,,"[{'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-11-13 15:26:22.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0045b12f8d0df315ad5e767a37f3a1d7cc7beed6', 'message': ""DNM It's just a test of neutron-tempest-plugin jobs\n\nDepends-On: https://review.opendev.org/694049/\n\nChange-Id: Ia1f7807ea695ca216e19e4a563367609efe7c53e\n""}]",0,694094,0045b12f8d0df315ad5e767a37f3a1d7cc7beed6,4,2,1,11975,,,0,"DNM It's just a test of neutron-tempest-plugin jobs

Depends-On: https://review.opendev.org/694049/

Change-Id: Ia1f7807ea695ca216e19e4a563367609efe7c53e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/94/694094/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,0045b12f8d0df315ad5e767a37f3a1d7cc7beed6,freeze-neutron-tempest-plugin-version,# NOTE: it's just o test,,1,0
openstack%2Ftripleo-docs~master~I4caf0d4a0108fa4f5e1c87063d77821cf4cf89e0,openstack/tripleo-docs,master,I4caf0d4a0108fa4f5e1c87063d77821cf4cf89e0,Document openstack overcloud admin authorize,MERGED,2020-01-29 21:24:22.000000000,2020-01-30 10:45:47.000000000,2020-01-30 10:43:51.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 21:24:22.000000000', 'files': ['deploy-guide/source/deployment/ansible_config_download.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/ce6e4ba6836eed919bb074bd3a97b50a00ae580e', 'message': 'Document openstack overcloud admin authorize\n\nWhen using the manual config-download steps with --stack-only, the\ntripleo-admin user still needs to be authorized if the default user/key\nis used by tripleo-ansible-inventory.\n\nThis patch adds documentation for openstack overcloud admin authorize\nwhich will authorize the tripleo-admin user.\n\nChange-Id: I4caf0d4a0108fa4f5e1c87063d77821cf4cf89e0\n'}]",0,704887,ce6e4ba6836eed919bb074bd3a97b50a00ae580e,8,3,1,7144,,,0,"Document openstack overcloud admin authorize

When using the manual config-download steps with --stack-only, the
tripleo-admin user still needs to be authorized if the default user/key
is used by tripleo-ansible-inventory.

This patch adds documentation for openstack overcloud admin authorize
which will authorize the tripleo-admin user.

Change-Id: I4caf0d4a0108fa4f5e1c87063d77821cf4cf89e0
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/87/704887/1 && git format-patch -1 --stdout FETCH_HEAD,['deploy-guide/source/deployment/ansible_config_download.rst'],1,ce6e4ba6836eed919bb074bd3a97b50a00ae580e,,".. _`authorized on the overcloud nodes`: Enable tripleo-admin via SSH ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ The tripleo-admin user must be `authorized on the overcloud nodes`_ for use by ``ansible-playbook``, if using the default user set by ``tripleo-ansible-inventory``. Authorizing the tripleo-admin user is done by running the ``openstack overcloud admin authorize`` command:: openstack overcloud admin authorize \ --overcloud-ssh-user heat-admin \ --overcloud-ssh-key ~/.ssh/id_rsa Alternatively, a user and key that are already authorized on the overcloud nodes can be used if that user and key are specified when running ``tripleo-ansible-inventory``. See `Generate an inventory`_. ",,17,0
openstack%2Fbifrost~master~I7cadb268aedde381dc37ef610baac44bb2e8650a,openstack/bifrost,master,I7cadb268aedde381dc37ef610baac44bb2e8650a,Re-arrange documentation for clearer first experience,MERGED,2020-01-28 11:53:00.000000000,2020-01-30 10:44:04.000000000,2020-01-30 00:14:00.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-01-28 11:53:00.000000000', 'files': ['doc/source/contributor/testenv.rst', 'doc/source/contributing.rst', 'doc/source/index.rst', 'doc/source/install/index.rst', 'doc/source/contributor/index.rst', 'doc/source/user/howto.rst'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/42d9b0843196a6711ec214f38efd533bd24fabdf', 'message': 'Re-arrange documentation for clearer first experience\n\n1. Expand the table of contents on the landing page to 3 levels of depth.\n   There is no need to save space there, and an expanded table of contents\n   allows much easier navigation.\n2. Move testing environment information to the new contributor guide instead\n   of being hidden inside of ""How To"".\n3. Move ""Advanced Topics"" category in the installation guide one level up\n   to make it more prominent (and visible in the landing page).\n\nIncludes a small ordering fix in the manual testing on the VMs guide: VM\nconfiguration has to go first.\n\nChange-Id: I7cadb268aedde381dc37ef610baac44bb2e8650a\n'}]",3,704539,42d9b0843196a6711ec214f38efd533bd24fabdf,9,3,1,10239,,,0,"Re-arrange documentation for clearer first experience

1. Expand the table of contents on the landing page to 3 levels of depth.
   There is no need to save space there, and an expanded table of contents
   allows much easier navigation.
2. Move testing environment information to the new contributor guide instead
   of being hidden inside of ""How To"".
3. Move ""Advanced Topics"" category in the installation guide one level up
   to make it more prominent (and visible in the landing page).

Includes a small ordering fix in the manual testing on the VMs guide: VM
configuration has to go first.

Change-Id: I7cadb268aedde381dc37ef610baac44bb2e8650a
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/39/704539/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributor/testenv.rst', 'doc/source/contributing.rst', 'doc/source/index.rst', 'doc/source/contributor/index.rst', 'doc/source/install/index.rst', 'doc/source/user/howto.rst']",6,42d9b0843196a6711ec214f38efd533bd24fabdf,docs,,"Execute local testing ===================== A simple ``scripts/test-bifrost.sh`` script can be utilized to install pre-requisite software packages, Ansible, and then execute the ``test-bifrost-create-vm.yaml`` and ``test-bifrost.yaml`` playbooks in order to provide a single step testing mechanism. ``playbooks/test-bifrost-create-vm.yaml`` creates one or more VMs for testing and saves out a baremetal.json file which is used by ``playbooks/test-bifrost.yaml`` to execute the remaining roles. Two additional roles are invoked by this playbook which enables Ansible to connect to the new nodes by adding them to the inventory, and then logging into the remote machine via the user's ssh host key. Once that has successfully occurred, additional roles will unprovision the host(s) and delete them from ironic. Command:: scripts/test-bifrost.sh Note: - Cleaning mode is explicitly disabled in the ``test-bifrost.yaml`` playbook due to the fact that is an IO-intensive operation that can take a great deal of time. - In order to cap requirements for installation, an ``upper_constraints_file`` setting is defined. This is consuming the ``UPPER_CONSTRAINTS_FILE`` env var by default, to properly integrate with CI systems, and will default to ``/opt/stack/requirements/upper-constraints.txt`` file if not present. Manually test with Virtual Machines =================================== Bifrost supports using virtual machines to emulate the hardware. It is assumed you have an SSH server running on the host machine. The ``agent_ssh`` driver, used by ironic with VM testing, will need to use SSH to control the virtual machines. An SSH key is generated for the ``ironic`` user when testing. The ironic conductor will use this key to connect to the host machine and run virsh commands. #. Set ``testing`` to *true* in the ``playbooks/inventory/group_vars/target`` file. #. You may need to adjust the value for ``ssh_public_key_path``. #. Run the install step, as documented above, however adding ``-e testing=true`` to the Ansible command line. #. Execute the ``ansible-playbook -vvvv -i inventory/target test-bifrost-create-vm.yaml`` command to create a test virtual machine. #. Set the environment variable of ``BIFROST_INVENTORY_SOURCE`` to the path to the JSON file, which by default has been written to /tmp/baremetal.json. #. Run the enrollment step, as documented above, using the CSV file you created in the previous step. #. Run the deployment step, as documented above. ",83,66
openstack%2Fopenstack-doc-tools~master~I4da67ec5ea303ef35d6aac47a5d7ae5ec57aab9b,openstack/openstack-doc-tools,master,I4da67ec5ea303ef35d6aac47a5d7ae5ec57aab9b,Add python-requires >= 3.6,MERGED,2020-01-27 17:28:19.000000000,2020-01-30 10:21:31.000000000,2020-01-30 10:17:02.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-27 17:28:19.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/5888968ec016104f1ea596e8c7388a3e8512bfb3', 'message': 'Add python-requires >= 3.6\n\nAs part of moving to Python 3.6, add a python-requires to clearly state\nit.\n\nChange-Id: I4da67ec5ea303ef35d6aac47a5d7ae5ec57aab9b\n'}]",0,704371,5888968ec016104f1ea596e8c7388a3e8512bfb3,9,2,1,6547,,,0,"Add python-requires >= 3.6

As part of moving to Python 3.6, add a python-requires to clearly state
it.

Change-Id: I4da67ec5ea303ef35d6aac47a5d7ae5ec57aab9b
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/71/704371/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,5888968ec016104f1ea596e8c7388a3e8512bfb3,drop-py27-support,python-requires = >=3.6,,1,0
openstack%2Fopenstack-doc-tools~master~I32d5dc317b821dee4a625506f227a8f5bfaaecfc,openstack/openstack-doc-tools,master,I32d5dc317b821dee4a625506f227a8f5bfaaecfc,Drop python 2.7 support and testing,MERGED,2019-12-27 07:55:46.000000000,2020-01-30 10:20:15.000000000,2020-01-30 10:17:01.000000000,"[{'_account_id': 6547}, {'_account_id': 8556}, {'_account_id': 11904}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-12-27 07:55:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/e2275f2ea4b1369d3934ed5e162d97821b588edd', 'message': 'Drop python 2.7 support and testing\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: I32d5dc317b821dee4a625506f227a8f5bfaaecfc\n'}, {'number': 2, 'created': '2020-01-27 16:03:30.000000000', 'files': ['releasenotes/notes/drop-py2-7-c7fce3322cc66380.yaml', 'requirements.txt', '.zuul.yaml', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/dc37b3569be4dc1ffe4598fd0e42b4141a9b839b', 'message': 'Drop python 2.7 support and testing\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nCo-Authored-By: Andreas Jaeger <aj@suse.com>\nChange-Id: I32d5dc317b821dee4a625506f227a8f5bfaaecfc\n'}]",4,700684,dc37b3569be4dc1ffe4598fd0e42b4141a9b839b,17,6,2,27822,,,0,"Drop python 2.7 support and testing

Ussuri Communtiy-wide goal:
https://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html

Co-Authored-By: Andreas Jaeger <aj@suse.com>
Change-Id: I32d5dc317b821dee4a625506f227a8f5bfaaecfc
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/84/700684/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'setup.cfg', 'tox.ini']",3,e2275f2ea4b1369d3934ed5e162d97821b588edd,drop-py27-support,"envlist = py37,pep8basepython = python3","envlist = py27,py37,pep8basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3",2,10
openstack%2Freleases~master~I726abe1f652270ed5ae2c058d68554b238be0ab1,openstack/releases,master,I726abe1f652270ed5ae2c058d68554b238be0ab1,Remove directly-released infra deliverables,MERGED,2020-01-29 16:40:14.000000000,2020-01-30 10:18:48.000000000,2020-01-30 10:18:48.000000000,"[{'_account_id': 308}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 16:40:14.000000000', 'files': ['deliverables/_independent/python-storyboardclient.yaml', 'deliverables/_independent/diskimage-builder.yaml', 'deliverables/_independent/yaml2ical.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/7f5ec4fc7a5d54137b8a5fbaa466ed80463233df', 'message': ""Remove directly-released infra deliverables\n\nThe Infrastructure/Opendev team releases its software by pushing tags\ndirectly, and not by going through the OpenStack release management team\ntooling. However, some software fell into the cracks and got, at least\nat one point, released through openstack/releases. This change removes\nthe corresponding deliverable files:\n\n- diskimage-builder has an ACL that allows direct releases, and indeed\n  it was released recently without going through the deliverable file.\n  Let's remove it as it is an Infrastructure deliverable.\n\n- Storyboard like other opendev software is released by pushing tags\n  directly. However, python-storyboardclient still used openstack/releases,\n  as there was no ACL to allow for direct tagging. This is fixed in the\n  dependent change, so we can remove the python-storyboard deliverable file.\n\n- yaml2ical is another infrastructure team software. While it could be\n  tagged directly, since its release manager was the same as the Release\n  Management team PTL at that time, it used the convenient release\n  management tooling. Let's remove the file to not continue that mistake.\n\nDepends-On: https://review.opendev.org/704837\nChange-Id: I726abe1f652270ed5ae2c058d68554b238be0ab1\n""}]",0,704841,7f5ec4fc7a5d54137b8a5fbaa466ed80463233df,8,3,1,308,,,0,"Remove directly-released infra deliverables

The Infrastructure/Opendev team releases its software by pushing tags
directly, and not by going through the OpenStack release management team
tooling. However, some software fell into the cracks and got, at least
at one point, released through openstack/releases. This change removes
the corresponding deliverable files:

- diskimage-builder has an ACL that allows direct releases, and indeed
  it was released recently without going through the deliverable file.
  Let's remove it as it is an Infrastructure deliverable.

- Storyboard like other opendev software is released by pushing tags
  directly. However, python-storyboardclient still used openstack/releases,
  as there was no ACL to allow for direct tagging. This is fixed in the
  dependent change, so we can remove the python-storyboard deliverable file.

- yaml2ical is another infrastructure team software. While it could be
  tagged directly, since its release manager was the same as the Release
  Management team PTL at that time, it used the convenient release
  management tooling. Let's remove the file to not continue that mistake.

Depends-On: https://review.opendev.org/704837
Change-Id: I726abe1f652270ed5ae2c058d68554b238be0ab1
",git fetch https://review.opendev.org/openstack/releases refs/changes/41/704841/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/_independent/python-storyboardclient.yaml', 'deliverables/_independent/diskimage-builder.yaml', 'deliverables/_independent/yaml2ical.yaml']",3,7f5ec4fc7a5d54137b8a5fbaa466ed80463233df,remove-infra-deliverables,,--- launchpad: yaml2ical team: Infrastructure type: other release-type: python-pypi releases: - version: 0.1.0 projects: - repo: openstack-infra/yaml2ical hash: 0d18942d98d025b4c30eebca03819736e0dee22f - version: 0.2.0 projects: - repo: openstack-infra/yaml2ical hash: 40f12c0d63de705f7464be5dd7147884e0f1f7d4 - version: 0.3.0 projects: - repo: openstack-infra/yaml2ical hash: 8bc6cf87c5edd4dd3a6252f056f9074818f6d170 - version: 0.4.0 projects: - repo: openstack-infra/yaml2ical hash: ff513f9efe88138f3356412acca9980599e1bbd4 - version: 0.5.0 projects: - repo: openstack-infra/yaml2ical hash: f2ac69f2e34bfe7c7778bf3cec09ee975057e3f4 - version: 0.6.0 projects: - repo: openstack-infra/yaml2ical hash: b14b2fb3cf3d4080c249b0c21b6232160e2af352 - version: 0.6.1 projects: - repo: openstack-infra/yaml2ical hash: 691e5167b0308849fdf4696727d936461933549d - version: 0.7.0 projects: - repo: openstack-infra/yaml2ical hash: 2bc859072ffd3a6687084f98ab356bcaff27c830 - projects: - hash: 6e498abcb6acb8d14809f757abfd85e8ab5b5c1f repo: openstack-infra/yaml2ical version: 0.8.0 - projects: - hash: 0d1125f618c3c9954714e67c2c09827f18990c0d repo: openstack-infra/yaml2ical version: 0.8.1 - projects: - hash: 6a2106440138a53eb288b960a06743d2e57138b1 repo: openstack-infra/yaml2ical version: 0.9.0 - projects: - hash: 02ba0f5a806721529bc185ccb2d1b589f9e4af73 repo: openstack-infra/yaml2ical version: 0.10.0 repository-settings: openstack-infra/yaml2ical: {} ,0,436
openstack%2Freleases~master~Id6739d07622baf66909e2eb08101c332ed7d7ae2,openstack/releases,master,Id6739d07622baf66909e2eb08101c332ed7d7ae2,Release kolla and kolla-ansible stable branches,MERGED,2020-01-29 17:14:40.000000000,2020-01-30 10:12:28.000000000,2020-01-30 10:12:28.000000000,"[{'_account_id': 308}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-29 17:14:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/6dad52e81049d994c3a3e45e76c9e39b44798c41', 'message': 'Release kolla and kolla-ansible stable branches\n\n* Release kolla 7.1.0 for Rocky\n* Release kolla 8.0.1 for Stein\n* Release kolla 9.0.1 for Train\n\n* Release kolla-ansible 7.2.0 for Rocky\n* Release kolla-ansible 8.1.0 for Stein\n* Release kolla-ansible 9.0.1 for Train\n\nChange-Id: Id6739d07622baf66909e2eb08101c332ed7d7ae2\n'}, {'number': 2, 'created': '2020-01-29 17:16:32.000000000', 'files': ['deliverables/train/kolla-ansible.yaml', 'deliverables/rocky/kolla-ansible.yaml', 'deliverables/stein/kolla.yaml', 'deliverables/rocky/kolla.yaml', 'deliverables/stein/kolla-ansible.yaml', 'deliverables/train/kolla.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/a4af6b3c0b74ee16ba4fca56aa010e4bf0ce83a2', 'message': 'Release kolla and kolla-ansible stable branches\n\n* Release kolla 7.1.0 for Rocky\n* Release kolla 8.0.2 for Stein\n* Release kolla 9.0.1 for Train\n\n* Release kolla-ansible 7.2.0 for Rocky\n* Release kolla-ansible 8.1.0 for Stein\n* Release kolla-ansible 9.0.1 for Train\n\nChange-Id: Id6739d07622baf66909e2eb08101c332ed7d7ae2\n'}]",0,704849,a4af6b3c0b74ee16ba4fca56aa010e4bf0ce83a2,10,5,2,14826,,,0,"Release kolla and kolla-ansible stable branches

* Release kolla 7.1.0 for Rocky
* Release kolla 8.0.2 for Stein
* Release kolla 9.0.1 for Train

* Release kolla-ansible 7.2.0 for Rocky
* Release kolla-ansible 8.1.0 for Stein
* Release kolla-ansible 9.0.1 for Train

Change-Id: Id6739d07622baf66909e2eb08101c332ed7d7ae2
",git fetch https://review.opendev.org/openstack/releases refs/changes/49/704849/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/train/kolla-ansible.yaml', 'deliverables/rocky/kolla-ansible.yaml', 'deliverables/stein/kolla.yaml', 'deliverables/rocky/kolla.yaml', 'deliverables/stein/kolla-ansible.yaml', 'deliverables/train/kolla.yaml']",6,6dad52e81049d994c3a3e45e76c9e39b44798c41,, - projects: - repo: openstack/kolla hash: 9b8dbab77f2990036a09ff6146042b4c18dba3a8 version: 9.0.1,,24,0
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I87974e88c38b42e90bc3cd801fcf1deaf268720c,openstack/tripleo-heat-templates,stable/train,I87974e88c38b42e90bc3cd801fcf1deaf268720c,Force facts cache refreshing before upgrade.,MERGED,2020-01-24 11:07:29.000000000,2020-01-30 09:59:40.000000000,2020-01-25 04:54:28.000000000,"[{'_account_id': 6926}, {'_account_id': 8042}, {'_account_id': 11166}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-24 11:07:29.000000000', 'files': ['common/deploy-steps.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f632ea38ac1f5c68d0659d5a8d0fb51bf7844eb4', 'message': ""Force facts cache refreshing before upgrade.\n\nWhen upgrading from Rocky to Stein, an upgrade of the operating system is\nperformed. This upgrade from RHEL7 to RHEL8 implies the removal of the\ndefault /usr/bin/python binary. As the facts cache is enabled, Ansible's\nstrategy does not consider to upgrade facts and therefore we try to run the\nansible playbook using the old python binary when running the upgrade.\nThis fails with the error: /usr/bin/python: No such file or directory.\n\nThis patch makes use of the setup task in combination with gather_facts\nfalse, to ensure that the facts are gathered and refreshed for the\nOvercloud nodes. This way, we make sure that we are using the right\npython binary. As during scale, a similar situation is occuring, this\npatch adds the same logic in scale_playbook.\n\nCloses-Bug: #1856313\nChange-Id: I87974e88c38b42e90bc3cd801fcf1deaf268720c\n(cherry picked from commit 14db20baee3529b223a87e9f73279c6034a47427)\n""}]",0,704138,f632ea38ac1f5c68d0659d5a8d0fb51bf7844eb4,8,6,1,26343,,,0,"Force facts cache refreshing before upgrade.

When upgrading from Rocky to Stein, an upgrade of the operating system is
performed. This upgrade from RHEL7 to RHEL8 implies the removal of the
default /usr/bin/python binary. As the facts cache is enabled, Ansible's
strategy does not consider to upgrade facts and therefore we try to run the
ansible playbook using the old python binary when running the upgrade.
This fails with the error: /usr/bin/python: No such file or directory.

This patch makes use of the setup task in combination with gather_facts
false, to ensure that the facts are gathered and refreshed for the
Overcloud nodes. This way, we make sure that we are using the right
python binary. As during scale, a similar situation is occuring, this
patch adds the same logic in scale_playbook.

Closes-Bug: #1856313
Change-Id: I87974e88c38b42e90bc3cd801fcf1deaf268720c
(cherry picked from commit 14db20baee3529b223a87e9f73279c6034a47427)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/38/704138/1 && git format-patch -1 --stdout FETCH_HEAD,['common/deploy-steps.j2'],1,f632ea38ac1f5c68d0659d5a8d0fb51bf7844eb4,, - hosts: DEPLOY_SOURCE_HOST:DEPLOY_TARGET_HOST gather_facts: no tasks: - name: Force facts refresh before upgrade. setup: - hosts: DEPLOY_SOURCE_HOST:DEPLOY_TARGET_HOST gather_facts: no tasks: - name: Force facts refresh before scale. setup:, - hosts: DEPLOY_SOURCE_HOST gather_facts: yes - hosts: DEPLOY_TARGET_HOST name: Gather facts from overcloud gather_facts: yes tags: always - hosts: DEPLOY_SOURCE_HOST name: Gather facts from undercloud gather_facts: yes become: false tags: - always - facts - hosts: DEPLOY_TARGET_HOST gather_facts: yes,10,16
openstack%2Fpython-tripleoclient~master~Ic2ae04daf81f19afa763c2f6b1c0ae5e6467324b,openstack/python-tripleoclient,master,Ic2ae04daf81f19afa763c2f6b1c0ae5e6467324b,Add kwarg to set an ansible.cfg file,MERGED,2020-01-28 20:52:59.000000000,2020-01-30 09:32:42.000000000,2020-01-30 09:30:57.000000000,"[{'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-28 20:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/d64ae11743ae4ec66e1fc3e451f1c65101b07be6', 'message': 'Add kwarg to set an ansible.cfg file\n\nThis change implements the ability to set the file path for an ansible\nconfiguration file. If no option is provide a default ansible.cfg file\nwill be generated in the artifact path. This default ansible.cfg file\nwill, at this time, contain one tunable which will improve CPU\navailability by reducing the internal polling interval. While most of\nthe ansible configuration is performned though the use of environment\nvariables, not all options have an exposed environment variable or\nplaybook tunable. By having the ability to define an ansible\nconfiguration file, or generate one when needed, we should be able\nto accomodate any configuration required.\n\nChange-Id: Ic2ae04daf81f19afa763c2f6b1c0ae5e6467324b\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 2, 'created': '2020-01-29 04:16:46.000000000', 'files': ['tripleoclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/c57f87870b3422c5782a45fd6740fd0f2ce6c307', 'message': 'Add kwarg to set an ansible.cfg file\n\nThis change implements the ability to set the file path for an ansible\nconfiguration file. If no option is provide a default ansible.cfg file\nwill be generated in the artifact path. This default ansible.cfg file\nwill, at this time, contain one tunable which will improve CPU\navailability by reducing the internal polling interval. While most of\nthe ansible configuration is performned though the use of environment\nvariables, not all options have an exposed environment variable or\nplaybook tunable. By having the ability to define an ansible\nconfiguration file, or generate one when needed, we should be able\nto accomodate any configuration required.\n\nChange-Id: Ic2ae04daf81f19afa763c2f6b1c0ae5e6467324b\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}]",0,704683,c57f87870b3422c5782a45fd6740fd0f2ce6c307,20,5,2,7353,,,0,"Add kwarg to set an ansible.cfg file

This change implements the ability to set the file path for an ansible
configuration file. If no option is provide a default ansible.cfg file
will be generated in the artifact path. This default ansible.cfg file
will, at this time, contain one tunable which will improve CPU
availability by reducing the internal polling interval. While most of
the ansible configuration is performned though the use of environment
variables, not all options have an exposed environment variable or
playbook tunable. By having the ability to define an ansible
configuration file, or generate one when needed, we should be able
to accomodate any configuration required.

Change-Id: Ic2ae04daf81f19afa763c2f6b1c0ae5e6467324b
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/83/704683/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/utils.py'],1,d64ae11743ae4ec66e1fc3e451f1c65101b07be6,scale-2020," extra_env_variables=None, ansible_cfg=None): :param ansible_cfg: Path to an ansible configuration file. One will be generated in the artifact path if this option is None. :type ansible_cfg: String if not 'ANSIBLE_CONFIG' in env and not ansible_cfg: ansible_cfg = os.path.join(ansible_artifact_path, 'ansible.cfg') config = configparser.ConfigParser() config.add_section('defaults') config.set('defaults', 'internal_poll_interval', '0.05') with open(ansible_cfg, 'w') as f: config.write(f) env['ANSIBLE_CONFIG'] = ansible_cfg elif not 'ANSIBLE_CONFIG' in env and ansible_cfg: env['ANSIBLE_CONFIG'] = ansible_cfg ", extra_env_variables=None):,16,1
openstack%2Ftripleo-heat-templates~stable%2Fqueens~I20d35affba9da511ed4a9566013868146d3fbf4c,openstack/tripleo-heat-templates,stable/queens,I20d35affba9da511ed4a9566013868146d3fbf4c,Add SSHD composable service to Networker role definition,MERGED,2020-01-29 22:06:01.000000000,2020-01-30 09:31:00.000000000,2020-01-30 09:30:59.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27092}]","[{'number': 1, 'created': '2020-01-29 22:06:01.000000000', 'files': ['roles/Networker.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4999cbf9dba2a3b8391004f8a1ff258061bc71ee', 'message': 'Add SSHD composable service to Networker role definition\n\nThe composable service OS::TripleO::Services::Sshd is\nenabled by default in the overcloud but it is not included\nin the default Networker.yaml role definition.\n\nCloses-Bug: #1861343\nChange-Id: I20d35affba9da511ed4a9566013868146d3fbf4c\n(cherry picked from commit 37ea3303700eba9e8d73f45c2e0999c5d39e1132)\n'}]",0,704894,4999cbf9dba2a3b8391004f8a1ff258061bc71ee,7,4,1,14985,,,0,"Add SSHD composable service to Networker role definition

The composable service OS::TripleO::Services::Sshd is
enabled by default in the overcloud but it is not included
in the default Networker.yaml role definition.

Closes-Bug: #1861343
Change-Id: I20d35affba9da511ed4a9566013868146d3fbf4c
(cherry picked from commit 37ea3303700eba9e8d73f45c2e0999c5d39e1132)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/94/704894/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/Networker.yaml'],1,4999cbf9dba2a3b8391004f8a1ff258061bc71ee,bug/1861343, - OS::TripleO::Services::Sshd,,1,0
openstack%2Ftripleo-common~stable%2Ftrain~I294910384fc9dd9ca8c7114d08842868909d9e9f,openstack/tripleo-common,stable/train,I294910384fc9dd9ca8c7114d08842868909d9e9f,Raise exception on KeyboardInterrupt,MERGED,2020-01-29 14:33:10.000000000,2020-01-30 09:28:45.000000000,2020-01-30 09:27:14.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-29 14:33:10.000000000', 'files': ['tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/95c117498d5d5caeb8359dc830f748cabc9c7228', 'message': 'Raise exception on KeyboardInterrupt\n\nUsing subprocess with tenacity can lead to issues when a keyboard\ninterrupt occurs because the logic we have will actually trigger a\nretry. This can lead to the inability to stop some of the commands with\na ctrl+c.\n\nChange-Id: I294910384fc9dd9ca8c7114d08842868909d9e9f\nCloses-Bug: #1746724\n(cherry picked from commit 9003b7ac5be6a54aed0b3cd8172c838c413f17f5)\n'}]",0,704815,95c117498d5d5caeb8359dc830f748cabc9c7228,9,3,1,14985,,,0,"Raise exception on KeyboardInterrupt

Using subprocess with tenacity can lead to issues when a keyboard
interrupt occurs because the logic we have will actually trigger a
retry. This can lead to the inability to stop some of the commands with
a ctrl+c.

Change-Id: I294910384fc9dd9ca8c7114d08842868909d9e9f
Closes-Bug: #1746724
(cherry picked from commit 9003b7ac5be6a54aed0b3cd8172c838c413f17f5)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/15/704815/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,95c117498d5d5caeb8359dc830f748cabc9c7228,bug/1746724-stable/train," try: process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out) if process.returncode != 0: raise ImageUploaderException('Error copying image:\n%s\n%s' % (' '.join(cmd), err)) except KeyboardInterrupt: raise Exception('Action interrupted with ctrl+c') try: process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out.decode('utf-8')) if process.returncode != 0: raise ImageUploaderException('Error deleting image:\n%s\n%s' % (' '.join(cmd), err)) except KeyboardInterrupt: raise Exception('Action interrupted with ctrl+c') try: process = subprocess.Popen( cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True, close_fds=True out, err = process.communicate() if process.returncode != 0: error_msg = ( 'Pulling image failed: cmd ""{}"", stdout ""{}"",' ' stderr ""{}""'.format( ' '.join(cmd), out, err ) ) LOG.error(error_msg) raise ImageUploaderException(error_msg) except KeyboardInterrupt: raise Exception('Action interrupted with ctrl+c') try: p = subprocess.Popen(cmd, stdout=subprocess.PIPE) chunk_size = 2 ** 20 while True: data = p.stdout.read(chunk_size) if not data: break calc_digest.update(data) yield data p.wait() if p.returncode != 0: raise ImageUploaderException('Extracting layer failed') except KeyboardInterrupt: raise Exception('Action interrupted with ctrl+c') try: process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out) if process.returncode != 0: LOG.warning('Error deleting image:\n%s\n%s' % (' '.join(cmd), err)) except KeyboardInterrupt: raise Exception('Action interrupted with ctrl+c')"," process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out) if process.returncode != 0: raise ImageUploaderException('Error copying image:\n%s\n%s' % (' '.join(cmd), err)) process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out.decode('utf-8')) if process.returncode != 0: raise ImageUploaderException('Error deleting image:\n%s\n%s' % (' '.join(cmd), err)) process = subprocess.Popen( cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True, close_fds=True ) out, err = process.communicate() if process.returncode != 0: error_msg = ( 'Pulling image failed: cmd ""{}"", stdout ""{}"",' ' stderr ""{}""'.format( ' '.join(cmd), out, err ) LOG.error(error_msg) raise ImageUploaderException(error_msg) p = subprocess.Popen(cmd, stdout=subprocess.PIPE) chunk_size = 2 ** 20 while True: data = p.stdout.read(chunk_size) if not data: break calc_digest.update(data) yield data p.wait() if p.returncode != 0: raise ImageUploaderException('Extracting layer failed') process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out) if process.returncode != 0: LOG.warning('Error deleting image:\n%s\n%s' % (' '.join(cmd), err))",65,49
openstack%2Ftripleo-common~stable%2Fqueens~I294910384fc9dd9ca8c7114d08842868909d9e9f,openstack/tripleo-common,stable/queens,I294910384fc9dd9ca8c7114d08842868909d9e9f,Raise exception on KeyboardInterrupt,MERGED,2020-01-29 14:42:47.000000000,2020-01-30 09:27:15.000000000,2020-01-30 09:27:15.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-29 14:42:47.000000000', 'files': ['tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5a93687ab142575d31952fd7db7132271c5648ac', 'message': 'Raise exception on KeyboardInterrupt\n\nUsing subprocess with tenacity can lead to issues when a keyboard\ninterrupt occurs because the logic we have will actually trigger a\nretry. This can lead to the inability to stop some of the commands with\na ctrl+c.\n\nConflicts:\n    tripleo_common/image/image_uploader.py\n\nChange-Id: I294910384fc9dd9ca8c7114d08842868909d9e9f\nCloses-Bug: #1746724\n(cherry picked from commit 9003b7ac5be6a54aed0b3cd8172c838c413f17f5)\n'}]",0,704819,5a93687ab142575d31952fd7db7132271c5648ac,8,3,1,14985,,,0,"Raise exception on KeyboardInterrupt

Using subprocess with tenacity can lead to issues when a keyboard
interrupt occurs because the logic we have will actually trigger a
retry. This can lead to the inability to stop some of the commands with
a ctrl+c.

Conflicts:
    tripleo_common/image/image_uploader.py

Change-Id: I294910384fc9dd9ca8c7114d08842868909d9e9f
Closes-Bug: #1746724
(cherry picked from commit 9003b7ac5be6a54aed0b3cd8172c838c413f17f5)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/19/704819/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,5a93687ab142575d31952fd7db7132271c5648ac,bug/1746724-stable/queens," try: process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE) out, err = process.communicate() if process.returncode != 0: not_found_msgs = ( 'manifest unknown', # returned by docker.io 'requested access to the resource is denied' ) if any(n in err for n in not_found_msgs): raise ImageNotFoundException('Not found image: %s\n%s' % (image, err)) raise ImageUploaderException('Error inspecting image: %s\n%s' % except KeyboardInterrupt: raise Exception('Action interrupted with ctrl+c')"," process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE) out, err = process.communicate() if process.returncode != 0: not_found_msgs = ( 'manifest unknown', # returned by docker.io 'requested access to the resource is denied' ) if any(n in err for n in not_found_msgs): raise ImageNotFoundException('Not found image: %s\n%s' % raise ImageUploaderException('Error inspecting image: %s\n%s' % (image, err))",16,13
openstack%2Ftripleo-common~stable%2Fstein~I294910384fc9dd9ca8c7114d08842868909d9e9f,openstack/tripleo-common,stable/stein,I294910384fc9dd9ca8c7114d08842868909d9e9f,Raise exception on KeyboardInterrupt,MERGED,2020-01-29 14:33:20.000000000,2020-01-30 09:24:30.000000000,2020-01-30 09:22:46.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-29 14:33:20.000000000', 'files': ['tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3e1c52853bac0627333882626bc06b67934f6329', 'message': 'Raise exception on KeyboardInterrupt\n\nUsing subprocess with tenacity can lead to issues when a keyboard\ninterrupt occurs because the logic we have will actually trigger a\nretry. This can lead to the inability to stop some of the commands with\na ctrl+c.\n\nChange-Id: I294910384fc9dd9ca8c7114d08842868909d9e9f\nCloses-Bug: #1746724\n(cherry picked from commit 9003b7ac5be6a54aed0b3cd8172c838c413f17f5)\n'}]",0,704816,3e1c52853bac0627333882626bc06b67934f6329,9,3,1,14985,,,0,"Raise exception on KeyboardInterrupt

Using subprocess with tenacity can lead to issues when a keyboard
interrupt occurs because the logic we have will actually trigger a
retry. This can lead to the inability to stop some of the commands with
a ctrl+c.

Change-Id: I294910384fc9dd9ca8c7114d08842868909d9e9f
Closes-Bug: #1746724
(cherry picked from commit 9003b7ac5be6a54aed0b3cd8172c838c413f17f5)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/16/704816/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,3e1c52853bac0627333882626bc06b67934f6329,bug/1746724-stable/stein," try: process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out) if process.returncode != 0: raise ImageUploaderException('Error copying image:\n%s\n%s' % (' '.join(cmd), err)) except KeyboardInterrupt: raise Exception('Action interrupted with ctrl+c') try: process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out.decode('utf-8')) if process.returncode != 0: raise ImageUploaderException('Error deleting image:\n%s\n%s' % (' '.join(cmd), err)) except KeyboardInterrupt: raise Exception('Action interrupted with ctrl+c') try: process = subprocess.Popen( cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True, close_fds=True out, err = process.communicate() if process.returncode != 0: error_msg = ( 'Pulling image failed: cmd ""{}"", stdout ""{}"",' ' stderr ""{}""'.format( ' '.join(cmd), out, err ) ) LOG.error(error_msg) raise ImageUploaderException(error_msg) except KeyboardInterrupt: raise Exception('Action interrupted with ctrl+c') try: p = subprocess.Popen(cmd, stdout=subprocess.PIPE) chunk_size = 2 ** 20 while True: data = p.stdout.read(chunk_size) if not data: break calc_digest.update(data) yield data p.wait() if p.returncode != 0: raise ImageUploaderException('Extracting layer failed') except KeyboardInterrupt: raise Exception('Action interrupted with ctrl+c') try: process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out) if process.returncode != 0: LOG.warning('Error deleting image:\n%s\n%s' % (' '.join(cmd), err)) except KeyboardInterrupt: raise Exception('Action interrupted with ctrl+c')"," process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out) if process.returncode != 0: raise ImageUploaderException('Error copying image:\n%s\n%s' % (' '.join(cmd), err)) process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out.decode('utf-8')) if process.returncode != 0: raise ImageUploaderException('Error deleting image:\n%s\n%s' % (' '.join(cmd), err)) process = subprocess.Popen( cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True, close_fds=True ) out, err = process.communicate() if process.returncode != 0: error_msg = ( 'Pulling image failed: cmd ""{}"", stdout ""{}"",' ' stderr ""{}""'.format( ' '.join(cmd), out, err ) LOG.error(error_msg) raise ImageUploaderException(error_msg) p = subprocess.Popen(cmd, stdout=subprocess.PIPE) chunk_size = 2 ** 20 while True: data = p.stdout.read(chunk_size) if not data: break calc_digest.update(data) yield data p.wait() if p.returncode != 0: raise ImageUploaderException('Extracting layer failed') process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out) if process.returncode != 0: LOG.warning('Error deleting image:\n%s\n%s' % (' '.join(cmd), err))",65,49
openstack%2Ftripleo-common~stable%2Frocky~I294910384fc9dd9ca8c7114d08842868909d9e9f,openstack/tripleo-common,stable/rocky,I294910384fc9dd9ca8c7114d08842868909d9e9f,Raise exception on KeyboardInterrupt,MERGED,2020-01-29 14:41:01.000000000,2020-01-30 09:22:45.000000000,2020-01-30 09:22:45.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-29 14:41:01.000000000', 'files': ['tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/af2b1e11cafe4063819098cd78808d865988849a', 'message': 'Raise exception on KeyboardInterrupt\n\nUsing subprocess with tenacity can lead to issues when a keyboard\ninterrupt occurs because the logic we have will actually trigger a\nretry. This can lead to the inability to stop some of the commands with\na ctrl+c.\n\nConflicts:\n    tripleo_common/image/image_uploader.py\n\nChange-Id: I294910384fc9dd9ca8c7114d08842868909d9e9f\nCloses-Bug: #1746724\n(cherry picked from commit 9003b7ac5be6a54aed0b3cd8172c838c413f17f5)\n'}]",0,704817,af2b1e11cafe4063819098cd78808d865988849a,8,3,1,14985,,,0,"Raise exception on KeyboardInterrupt

Using subprocess with tenacity can lead to issues when a keyboard
interrupt occurs because the logic we have will actually trigger a
retry. This can lead to the inability to stop some of the commands with
a ctrl+c.

Conflicts:
    tripleo_common/image/image_uploader.py

Change-Id: I294910384fc9dd9ca8c7114d08842868909d9e9f
Closes-Bug: #1746724
(cherry picked from commit 9003b7ac5be6a54aed0b3cd8172c838c413f17f5)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/17/704817/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,af2b1e11cafe4063819098cd78808d865988849a,bug/1746724-stable/rocky," try: process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE) out, err = process.communicate() if process.returncode != 0: not_found_msgs = ( 'manifest unknown', # returned by docker.io 'requested access to the resource is denied' ) if any(n in err for n in not_found_msgs): raise ImageNotFoundException('Not found image: %s\n%s' % (image, err)) raise ImageUploaderException('Error inspecting image: %s\n%s' % except KeyboardInterrupt: raise Exception('Action interrupted with ctrl+c')"," process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE) out, err = process.communicate() if process.returncode != 0: not_found_msgs = ( 'manifest unknown', # returned by docker.io 'requested access to the resource is denied' ) if any(n in err for n in not_found_msgs): raise ImageNotFoundException('Not found image: %s\n%s' % raise ImageUploaderException('Error inspecting image: %s\n%s' % (image, err))",16,13
openstack%2Fkayobe~master~I020b3fc842f8aafef26e2f2425cd511544484baa,openstack/kayobe,master,I020b3fc842f8aafef26e2f2425cd511544484baa,"Revert ""Use OpenStack Train release""",ABANDONED,2020-01-30 08:34:40.000000000,2020-01-30 09:08:58.000000000,,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 28048}]","[{'number': 1, 'created': '2020-01-30 08:34:40.000000000', 'files': ['ansible/group_vars/all/openstack', 'etc/kayobe/openstack.yml', 'tox.ini', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/1e9463f99e7adf058eaf3f1091e168f683fd6e1d', 'message': 'Revert ""Use OpenStack Train release""\n\n\nThis reverts commit a93b85ba07113a77a6c0db498a59cef3bca15b94.\n\nAs the commit says: ""This commit should be reverted on the\nmaster branch once the Kayobe stable/train branch has been \ncut and RC1 released."" - train was released a long time ago.\n\nChange-Id: I020b3fc842f8aafef26e2f2425cd511544484baa\n'}]",0,704936,1e9463f99e7adf058eaf3f1091e168f683fd6e1d,3,5,1,6547,,,0,"Revert ""Use OpenStack Train release""


This reverts commit a93b85ba07113a77a6c0db498a59cef3bca15b94.

As the commit says: ""This commit should be reverted on the
master branch once the Kayobe stable/train branch has been 
cut and RC1 released."" - train was released a long time ago.

Change-Id: I020b3fc842f8aafef26e2f2425cd511544484baa
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/36/704936/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/group_vars/all/openstack', 'etc/kayobe/openstack.yml', 'tox.ini', 'zuul.d/jobs.yaml']",4,1e9463f99e7adf058eaf3f1091e168f683fd6e1d,stable/train,, # TODO(wszumski): Remove when kayobe stable/train exists. override-checkout: stable/train # TODO(wszumski): Remove when kayobe stable/train exists. override-checkout: stable/train # TODO(wszumski): Remove when kayobe stable/train exists. override-checkout: stable/train,11,17
openstack%2Fopenstack-zuul-jobs~master~I0d0047c8c58cd976c66d8c95f996e0d8b830be18,openstack/openstack-zuul-jobs,master,I0d0047c8c58cd976c66d8c95f996e0d8b830be18,Remove legacy bagpipe jobs,ABANDONED,2020-01-23 13:08:51.000000000,2020-01-30 08:53:39.000000000,,"[{'_account_id': 6547}, {'_account_id': 8313}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 13:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/0fcfcccadcd0336362605d019b500aa6ba89551f', 'message': 'Remove legacy bagpipe jobs\n\nThese job definitions are now obsolate, new zuulv3 syntax jobs will be\nnetworking-bagpipe repository, see dependnecy.\n\nChange-Id: I0d0047c8c58cd976c66d8c95f996e0d8b830be18\nDepends-On: https://review.opendev.org/703949\n'}, {'number': 2, 'created': '2020-01-23 13:17:46.000000000', 'files': ['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/networking-bagpipe-dsvm-fullstack/run.yaml', 'playbooks/legacy/networking-bagpipe-dsvm-fullstack/post.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/0d677608c7df32882ef18414022ae43148f03f9a', 'message': 'Remove legacy bagpipe jobs\n\nThese job definitions are now obsolate, new zuulv3 syntax jobs will be\nnetworking-bagpipe repository, see dependnecy.\n\nChange-Id: I0d0047c8c58cd976c66d8c95f996e0d8b830be18\nDepends-On: https://review.opendev.org/703949\n'}]",0,703987,0d677608c7df32882ef18414022ae43148f03f9a,7,3,2,8313,,,0,"Remove legacy bagpipe jobs

These job definitions are now obsolate, new zuulv3 syntax jobs will be
networking-bagpipe repository, see dependnecy.

Change-Id: I0d0047c8c58cd976c66d8c95f996e0d8b830be18
Depends-On: https://review.opendev.org/703949
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/87/703987/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/zuul-legacy-jobs.yaml'],1,0fcfcccadcd0336362605d019b500aa6ba89551f,zuulv3,, name: legacy-networking-bagpipe-dsvm-fullstack parent: legacy-dsvm-base run: playbooks/legacy/networking-bagpipe-dsvm-fullstack/run.yaml post-run: playbooks/legacy/networking-bagpipe-dsvm-fullstack/post.yaml timeout: 7800 required-projects: - openstack/devstack-gate - openstack/networking-bagpipe - openstack/networking-bgpvpn - openstack/networking-sfc - job:,0,12
openstack%2Fpython-mistralclient~master~I8b4c56277f0f172da712f777c4c856dba6fa0b0b,openstack/python-mistralclient,master,I8b4c56277f0f172da712f777c4c856dba6fa0b0b,Create client for interactive shell,MERGED,2020-01-29 23:53:52.000000000,2020-01-30 08:52:56.000000000,2020-01-30 08:51:29.000000000,"[{'_account_id': 8731}, {'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 23:53:52.000000000', 'files': ['mistralclient/shell.py', 'mistralclient/tests/unit/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/5171cdd63a7731a684f8146997f28136ab3a6483', 'message': ""Create client for interactive shell\n\nThe client allows you to run an interactive mode that doesn't exit\nbetween calls and reuses the client which is handy for end users.\nCurrently the code doesn't actually create a workflow engine client in\nthe interactive mode so all the mistral actions fail. We should create a\nclient if the client doesn't pass any args to the shell because that\nenters interactive mode.\n\nChange-Id: I8b4c56277f0f172da712f777c4c856dba6fa0b0b\nCloses-Bug: #1861357\n""}]",0,704907,5171cdd63a7731a684f8146997f28136ab3a6483,9,3,1,14985,,,0,"Create client for interactive shell

The client allows you to run an interactive mode that doesn't exit
between calls and reuses the client which is handy for end users.
Currently the code doesn't actually create a workflow engine client in
the interactive mode so all the mistral actions fail. We should create a
client if the client doesn't pass any args to the shell because that
enters interactive mode.

Change-Id: I8b4c56277f0f172da712f777c4c856dba6fa0b0b
Closes-Bug: #1861357
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/07/704907/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistralclient/shell.py', 'mistralclient/tests/unit/test_shell.py']",2,5171cdd63a7731a684f8146997f28136ab3a6483,bug/1861357," def test_command_interactive_mode(self, client_mock): self.shell('') self.assertTrue(client_mock.called) params = client_mock.call_args self.assertEqual('', params[1]['mistral_url']) @mock.patch('mistralclient.api.client.client')",,8,2
openstack%2Fkayobe~master~I6006e14df27a180f1438f9eb01b9ebefdddaff72,openstack/kayobe,master,I6006e14df27a180f1438f9eb01b9ebefdddaff72,Use OpenStack Train release,MERGED,2019-11-15 18:05:18.000000000,2020-01-30 08:34:40.000000000,2019-12-12 15:02:34.000000000,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 28048}]","[{'number': 1, 'created': '2019-11-15 18:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/e6c1ce89a690454b145b175b371127968270cc3f', 'message': 'Use OpenStack Train release\n\nSwitch all dependencies to use the OpenStack Train release.\n\nThis commit should be reverted on the master branch once the\nKayobe stable/train branch has been cut and RC1 released.\n\nChange-Id: I6006e14df27a180f1438f9eb01b9ebefdddaff72\n'}, {'number': 2, 'created': '2019-12-06 13:35:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/acc7388f8da1deb5337f050b8659f535b4083230', 'message': 'Use OpenStack Train release\n\nSwitch all dependencies to use the OpenStack Train release.\n\nThis commit should be reverted on the master branch once the\nKayobe stable/train branch has been cut and RC1 released.\n\nChange-Id: I6006e14df27a180f1438f9eb01b9ebefdddaff72\n'}, {'number': 3, 'created': '2019-12-11 16:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/544cd833a1dc23aef824364881c9cd438482af33', 'message': 'Use OpenStack Train release\n\nSwitch all dependencies to use the OpenStack Train release.\n\nThis commit should be reverted on the master branch once the\nKayobe stable/train branch has been cut and RC1 released.\n\nChange-Id: I6006e14df27a180f1438f9eb01b9ebefdddaff72\n'}, {'number': 4, 'created': '2019-12-12 10:56:38.000000000', 'files': ['ansible/group_vars/all/openstack', 'etc/kayobe/openstack.yml', 'tox.ini', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/a93b85ba07113a77a6c0db498a59cef3bca15b94', 'message': 'Use OpenStack Train release\n\nSwitch all dependencies to use the OpenStack Train release.\n\nThis commit should be reverted on the master branch once the\nKayobe stable/train branch has been cut and RC1 released.\n\nChange-Id: I6006e14df27a180f1438f9eb01b9ebefdddaff72\n'}]",3,694616,a93b85ba07113a77a6c0db498a59cef3bca15b94,25,5,4,28048,,,0,"Use OpenStack Train release

Switch all dependencies to use the OpenStack Train release.

This commit should be reverted on the master branch once the
Kayobe stable/train branch has been cut and RC1 released.

Change-Id: I6006e14df27a180f1438f9eb01b9ebefdddaff72
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/16/694616/4 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/group_vars/all/openstack', 'etc/kayobe/openstack.yml', 'tox.ini', 'zuul.d/jobs.yaml']",4,e6c1ce89a690454b145b175b371127968270cc3f,stable/train, # TODO(wszumski): Remove when kayobe stable/train exists. override-checkout: stable/train # TODO(wszumski): Remove when kayobe stable/train exists. override-checkout: stable/train # TODO(wszumski): Remove when kayobe stable/train exists. override-checkout: stable/train,,16,10
openstack%2Fmistral-lib~master~I2ff9881cf074b8d5bc052b1652dbc79b58ac586b,openstack/mistral-lib,master,I2ff9881cf074b8d5bc052b1652dbc79b58ac586b,Drop py2 support and add zuul jobs,MERGED,2020-01-28 09:40:56.000000000,2020-01-30 08:26:06.000000000,2020-01-30 08:22:44.000000000,"[{'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9712}, {'_account_id': 15895}, {'_account_id': 19134}, {'_account_id': 21970}, {'_account_id': 22348}, {'_account_id': 29124}, {'_account_id': 30755}]","[{'number': 1, 'created': '2020-01-28 09:40:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-lib/commit/e3aa0fce7146e7a609e4eed13c10e5fec10b4616', 'message': 'drop py2 zuul jobs\n\nChange-Id: I2ff9881cf074b8d5bc052b1652dbc79b58ac586b\n'}, {'number': 2, 'created': '2020-01-28 09:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-lib/commit/ab8e008093e26876f2afa43e0c7fa9af6dc4a1bf', 'message': 'Drop py2 support\n\nShould be done with a major bump version e.g 2.0.0\n\nChange-Id: I2ff9881cf074b8d5bc052b1652dbc79b58ac586b\n'}, {'number': 3, 'created': '2020-01-28 10:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-lib/commit/3140877298176f40b2623fcd91f8f42faffada2b', 'message': 'Drop py2 support and add zuul jobs\n\nShould be done with a major bump version e.g 2.0.0\nAdd docs and release zuul jobs\n\nChange-Id: I2ff9881cf074b8d5bc052b1652dbc79b58ac586b\n'}, {'number': 4, 'created': '2020-01-28 11:15:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-lib/commit/388e8e22dbb8bb66aa1d27b4b460bbc1a05e99cb', 'message': 'Drop py2 support and add zuul jobs\n\nShould be done with a major bump version e.g 2.0.0\nAdd docs and release zuul jobs\n\nChange-Id: I2ff9881cf074b8d5bc052b1652dbc79b58ac586b\n'}, {'number': 5, 'created': '2020-01-28 11:18:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-lib/commit/3bd1b29b5ca834d9e095b73a3823b3626e79d885', 'message': 'Drop py2 support and add zuul jobs\n\nShould be done with a major bump version e.g 2.0.0\nAdd docs and release zuul jobs\n\nChange-Id: I2ff9881cf074b8d5bc052b1652dbc79b58ac586b\n'}, {'number': 6, 'created': '2020-01-28 11:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-lib/commit/7ba25d23f7fd0b8a3cd991bfb0b875aaffffa13b', 'message': 'Drop py2 support and add zuul jobs\n\nShould be done with a major bump version e.g 2.0.0\nAdd docs and release zuul jobs\n\nChange-Id: I2ff9881cf074b8d5bc052b1652dbc79b58ac586b\n'}, {'number': 7, 'created': '2020-01-28 12:05:36.000000000', 'files': ['releasenotes/source/newton.rst', '.zuul.yaml', 'releasenotes/source/mitaka.rst', 'releasenotes/source/liberty.rst', 'releasenotes/source/index.rst', 'mistral_lib/utils/inspect_utils.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/mistral-lib/commit/1a81f2cdd85b0a48492c9b30fe1461a508e17ebc', 'message': 'Drop py2 support and add zuul jobs\n\nShould be done with a major bump version e.g 2.0.0\nAdd docs and release zuul jobs\n\nChange-Id: I2ff9881cf074b8d5bc052b1652dbc79b58ac586b\n'}]",0,704516,1a81f2cdd85b0a48492c9b30fe1461a508e17ebc,24,9,7,19134,,,0,"Drop py2 support and add zuul jobs

Should be done with a major bump version e.g 2.0.0
Add docs and release zuul jobs

Change-Id: I2ff9881cf074b8d5bc052b1652dbc79b58ac586b
",git fetch https://review.opendev.org/openstack/mistral-lib refs/changes/16/704516/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,e3aa0fce7146e7a609e4eed13c10e5fec10b4616,py3,, - openstack-python-jobs,0,1
openstack%2Ftripleo-ci~master~I9283fb8176a5e2ec7522ec70a35191eca8c9a016,openstack/tripleo-ci,master,I9283fb8176a5e2ec7522ec70a35191eca8c9a016,Disable gzip on main collect-logs config,MERGED,2020-01-29 08:09:01.000000000,2020-01-30 08:24:26.000000000,2020-01-29 16:06:49.000000000,"[{'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-29 08:09:01.000000000', 'files': ['toci-quickstart/config/collect-logs.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6b5298dc9ed13ae40bbc4c87b8c90f26db263017', 'message': 'Disable gzip on main collect-logs config\n\nThat file is used by upstream jobs where we do not want to gzip files.\n\nChange-Id: I9283fb8176a5e2ec7522ec70a35191eca8c9a016\n'}]",0,704738,6b5298dc9ed13ae40bbc4c87b8c90f26db263017,8,4,1,24162,,,0,"Disable gzip on main collect-logs config

That file is used by upstream jobs where we do not want to gzip files.

Change-Id: I9283fb8176a5e2ec7522ec70a35191eca8c9a016
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/38/704738/1 && git format-patch -1 --stdout FETCH_HEAD,['toci-quickstart/config/collect-logs.yml'],1,6b5298dc9ed13ae40bbc4c87b8c90f26db263017,gzip,"# that is used upstream, do not enable gzip there or we would not be able # to load the files in the browser. artcl_gzip: false",artcl_gzip: true,3,1
openstack%2Fkolla~master~Ibb147f12fc5d9f6f30c8e32ad17cd7f9b6febb33,openstack/kolla,master,Ibb147f12fc5d9f6f30c8e32ad17cd7f9b6febb33,Deprecate OpenDaylight,MERGED,2020-01-29 16:34:47.000000000,2020-01-30 08:15:12.000000000,2020-01-30 08:13:23.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-29 16:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/64a1d1a36f0670fce86ec4f877e3c55867f0550b', 'message': 'Deprecate Opendaylight\n\nSince [1] TripleO has stopped supporting Opendaylight deployments.\nKolla-Ansible ODL role also has been removed in [2].\n\n[1]: https://review.opendev.org/638701\n[2]: https://review.opendev.org/694523\n\nChange-Id: Ibb147f12fc5d9f6f30c8e32ad17cd7f9b6febb33\n'}, {'number': 2, 'created': '2020-01-29 16:44:10.000000000', 'files': ['releasenotes/notes/deprecate-opendaylight-58b3e9dbdc359688.yaml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/a68223412e6e3289173adca1af760157b25121c2', 'message': 'Deprecate OpenDaylight\n\nSince [1] TripleO has stopped supporting OpenDaylight deployments.\nKolla-Ansible ODL role also has been removed in [2].\n\n[1]: https://review.opendev.org/638701\n[2]: https://review.opendev.org/694523\n\nChange-Id: Ibb147f12fc5d9f6f30c8e32ad17cd7f9b6febb33\n'}]",0,704838,a68223412e6e3289173adca1af760157b25121c2,10,5,2,22629,,,0,"Deprecate OpenDaylight

Since [1] TripleO has stopped supporting OpenDaylight deployments.
Kolla-Ansible ODL role also has been removed in [2].

[1]: https://review.opendev.org/638701
[2]: https://review.opendev.org/694523

Change-Id: Ibb147f12fc5d9f6f30c8e32ad17cd7f9b6febb33
",git fetch https://review.opendev.org/openstack/kolla refs/changes/38/704838/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/deprecate-opendaylight-58b3e9dbdc359688.yaml'],1,64a1d1a36f0670fce86ec4f877e3c55867f0550b,,--- deprecations: - | The Opendaylight (``opendaylight``) image is deprecated and will be removed. It is not used by any Kolla downstream projects. ,,5,0
openstack%2Ftripleo-validations~master~I88724e66679498ff8492f507fba84b76a7142bc8,openstack/tripleo-validations,master,I88724e66679498ff8492f507fba84b76a7142bc8,"molecule-xfs_check_ftypefailure (non-voting), remove from gate",MERGED,2020-01-24 15:15:14.000000000,2020-01-30 07:49:37.000000000,2020-01-30 07:49:37.000000000,"[{'_account_id': 9592}, {'_account_id': 11491}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-24 15:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/606162fa5d59949ccf9fb4c1096e0e5f721d5bb4', 'message': 'molecule-xfs_check_ftypefailure (non-voting), remove from gate\n\nnon-voting job, should not be the gate\n\nChange-Id: I88724e66679498ff8492f507fba84b76a7142bc8\n'}, {'number': 2, 'created': '2020-01-29 16:47:20.000000000', 'files': ['zuul.d/molecule.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/d8246e9af9a7986efc1e343a8fb76efcbc9e8e45', 'message': 'molecule-xfs_check_ftypefailure (non-voting), remove from gate\n\nnon-voting job, should not be the gate\n\nChange-Id: I88724e66679498ff8492f507fba84b76a7142bc8\n'}]",0,704164,d8246e9af9a7986efc1e343a8fb76efcbc9e8e45,13,4,2,9592,,,0,"molecule-xfs_check_ftypefailure (non-voting), remove from gate

non-voting job, should not be the gate

Change-Id: I88724e66679498ff8492f507fba84b76a7142bc8
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/64/704164/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/molecule.yaml'],1,606162fa5d59949ccf9fb4c1096e0e5f721d5bb4,,, - tripleo-validations-centos-7-molecule-xfs-check-ftype,0,1
openstack%2Ftripleo-heat-templates~stable%2Fstein~I8e4c675925cdae292c25a1e86b904fd7f618633f,openstack/tripleo-heat-templates,stable/stein,I8e4c675925cdae292c25a1e86b904fd7f618633f,Remove dracut-config-generic package,MERGED,2020-01-29 14:54:40.000000000,2020-01-30 07:40:13.000000000,2020-01-30 07:40:13.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2020-01-29 14:54:40.000000000', 'files': ['deployment/kernel/kernel-baremetal-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f98b9c51ce362001c5091f19d405b7d74e70a9ca', 'message': ""Remove dracut-config-generic package\n\nIn LP#1830574, we introduce the dracut command to include necessary\nfile into initramfs. However, dracut in RHEL or CentOS doesn't include\nsysctl.conf or other specific module related confs at an installation\nof new kernel if dracut-config-generic package exists on the system.\n\nWe should remove the package to allow creating a host-specific initramfs\nat an installation of new kernel.\n\nChange-Id: I8e4c675925cdae292c25a1e86b904fd7f618633f\nCloses-bug: #1857493\nCo-Authored-By: Keigo Noha <knoha@redhat.com>\n""}]",0,704825,f98b9c51ce362001c5091f19d405b7d74e70a9ca,9,4,1,31245,,,0,"Remove dracut-config-generic package

In LP#1830574, we introduce the dracut command to include necessary
file into initramfs. However, dracut in RHEL or CentOS doesn't include
sysctl.conf or other specific module related confs at an installation
of new kernel if dracut-config-generic package exists on the system.

We should remove the package to allow creating a host-specific initramfs
at an installation of new kernel.

Change-Id: I8e4c675925cdae292c25a1e86b904fd7f618633f
Closes-bug: #1857493
Co-Authored-By: Keigo Noha <knoha@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/25/704825/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/kernel/kernel-baremetal-puppet.yaml'],1,f98b9c51ce362001c5091f19d405b7d74e70a9ca,stein, host_prep_tasks: - name: Remove dracut-config-generic yum: name: 'dracut-config-generic' state: absent,,5,0
openstack%2Ftripleo-heat-templates~stable%2Ftrain~Ic8225af65c409b6a32d4bb2def370c7c802147fa,openstack/tripleo-heat-templates,stable/train,Ic8225af65c409b6a32d4bb2def370c7c802147fa,Check to make sure compute service is deployed before scale down,MERGED,2020-01-25 15:09:11.000000000,2020-01-30 07:40:11.000000000,2020-01-30 07:40:11.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 16845}, {'_account_id': 17216}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-25 15:09:11.000000000', 'files': ['deployment/nova/nova-compute-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/557c0c358f9b9eacc74f1bfe169af7cfa2c18cd0', 'message': 'Check to make sure compute service is deployed before scale down\n\nCurrently during a node scale down using openstack overcloud\nnode delete, we assume the that nova-compute is enabled on the\nnode and is working as expected. However, the node scale down\nfails in cases where the node being scaled is not correctly\nbehaving as a compute node (nova containers not running/reporting\nto the overcloud). This patch includes a check to only disable\nand stop nova services if they are running. We ran into this\nscenario when we wanted to scale down a node that did not cleanly\ndeploy as a compute node due to failure in step 5 in a large scale\nenvironment.\n\nChange-Id: Ic8225af65c409b6a32d4bb2def370c7c802147fa\nCo-Authored-By: Luke Short <ekultails@gmail.com>\nCloses-Bug: #1860694\nSigned-off-by: Sai Sindhur Malleni <smalleni@redhat.com>\n(cherry picked from commit 119769384f944e20b0f11c86ed68c5ffeb8385c5)\n'}]",0,704220,557c0c358f9b9eacc74f1bfe169af7cfa2c18cd0,14,6,1,17216,,,0,"Check to make sure compute service is deployed before scale down

Currently during a node scale down using openstack overcloud
node delete, we assume the that nova-compute is enabled on the
node and is working as expected. However, the node scale down
fails in cases where the node being scaled is not correctly
behaving as a compute node (nova containers not running/reporting
to the overcloud). This patch includes a check to only disable
and stop nova services if they are running. We ran into this
scenario when we wanted to scale down a node that did not cleanly
deploy as a compute node due to failure in step 5 in a large scale
environment.

Change-Id: Ic8225af65c409b6a32d4bb2def370c7c802147fa
Co-Authored-By: Luke Short <ekultails@gmail.com>
Closes-Bug: #1860694
Signed-off-by: Sai Sindhur Malleni <smalleni@redhat.com>
(cherry picked from commit 119769384f944e20b0f11c86ed68c5ffeb8385c5)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/20/704220/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/nova/nova-compute-container-puppet.yaml'],1,557c0c358f9b9eacc74f1bfe169af7cfa2c18cd0,compute_scale-stable/train, - name: Disable nova services when: - (nova_compute_service | length) == 1 block: - name: Disable nova-compute service command: openstack compute service set {{ nova_compute_service[0].Host }} nova-compute --disable delegate_to: localhost check_mode: no when: - not is_additional_cell|bool - name: Stop nova-compute healthcheck container service: name: tripleo_nova_compute_healthcheck state: stopped enabled: no become: true - name: Stop nova-compute container service: name: tripleo_nova_compute state: stopped enabled: no become: true - name: Delete nova-compute service command: openstack compute service delete {{ nova_compute_service[0].ID }} delegate_to: localhost check_mode: no, - name: Disable nova-compute service command: openstack compute service set {{ nova_compute_service[0].Host }} nova-compute --disable delegate_to: localhost check_mode: no when: - (nova_compute_service | length) <= 1 - not is_additional_cell|bool - name: Stop nova-compute healthcheck container service: name: tripleo_nova_compute_healthcheck state: stopped enabled: no become: true - name: Stop nova-compute container service: name: tripleo_nova_compute state: stopped enabled: no become: true - name: Delete nova-compute service command: openstack compute service delete {{ nova_compute_service[0].ID }} delegate_to: localhost check_mode: no when: - (nova_compute_service | length) <= 1,25,24
openstack%2Fcharm-neutron-api~master~Ie6f117f47a8189c8e30224f7200d8976cdec9605,openstack/charm-neutron-api,master,Ie6f117f47a8189c8e30224f7200d8976cdec9605,"When resuming, exclude haproxy",MERGED,2020-01-23 16:39:34.000000000,2020-01-30 07:00:59.000000000,2020-01-30 07:00:59.000000000,"[{'_account_id': 12549}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 16:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/acb595ca3c912c4d7c653e388d9b7a7354c387e2', 'message': 'When resuming, exclude haproxy\n\nWhen resuming services exclude those managed by hacluster, in\nthis case haproxy. If pacemaker lacks quorum it may shut haproxy\ndown which will cause this charm to error.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: Ie6f117f47a8189c8e30224f7200d8976cdec9605\n'}, {'number': 2, 'created': '2020-01-29 18:52:15.000000000', 'files': ['hooks/charmhelpers/contrib/hahelpers/cluster.py', 'hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/fetch/ubuntu_apt_pkg.py', 'hooks/neutron_api_utils.py', 'unit_tests/test_neutron_api_utils.py', 'hooks/charmhelpers/contrib/hardening/audits/apt.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/1b978ffd78353a5c67a5edfe4a8939c747979feb', 'message': 'When resuming, exclude haproxy\n\nWhen resuming services exclude those managed by hacluster, in\nthis case haproxy. If pacemaker lacks quorum it may shut haproxy\ndown which will cause this charm to error.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: Ie6f117f47a8189c8e30224f7200d8976cdec9605\n'}]",0,704027,1b978ffd78353a5c67a5edfe4a8939c747979feb,14,4,2,12549,,,0,"When resuming, exclude haproxy

When resuming services exclude those managed by hacluster, in
this case haproxy. If pacemaker lacks quorum it may shut haproxy
down which will cause this charm to error.

Charmhelper sync included to bring in required
get_managed_services_and_ports method.

Change-Id: Ie6f117f47a8189c8e30224f7200d8976cdec9605
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/27/704027/2 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/charmhelpers/contrib/openstack/policyd.py', 'hooks/charmhelpers/contrib/hahelpers/cluster.py', 'hooks/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/charmhelpers/contrib/charmsupport/nrpe.py', 'hooks/neutron_api_utils.py', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/charmhelpers/contrib/openstack/ha/utils.py', 'unit_tests/test_neutron_api_utils.py', 'hooks/charmhelpers/contrib/hardening/audits/apt.py', 'hooks/charmhelpers/fetch/ubuntu.py', 'hooks/charmhelpers/contrib/openstack/vaultlocker.py', 'hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/fetch/ubuntu_apt_pkg.py', 'hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/charmhelpers/contrib/openstack/templates/section-placement', 'hooks/charmhelpers/contrib/openstack/audits/openstack_security_guide.py', 'hooks/charmhelpers/core/hookenv.py', 'hooks/charmhelpers/contrib/openstack/amulet/utils.py']",18,acb595ca3c912c4d7c653e388d9b7a7354c387e2,exclude-haproxy-from-status," 'bionic_ussuri', 'focal_ussuri',",,657,160
openstack%2Ftripleo-heat-templates~master~I1043d66586d22b26adf66145879d1a64a25f54a0,openstack/tripleo-heat-templates,master,I1043d66586d22b26adf66145879d1a64a25f54a0,Ensure Ceph dependencies are installed in pre-provisioned nodes,MERGED,2019-12-11 08:11:55.000000000,2020-01-30 06:47:42.000000000,2019-12-28 13:38:54.000000000,"[{'_account_id': 3153}, {'_account_id': 11491}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-12-11 08:11:55.000000000', 'files': ['deployment/ceph-ansible/ceph-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bcebf3996908eb72114bf27343ba6d74425d67f8', 'message': 'Ensure Ceph dependencies are installed in pre-provisioned nodes\n\nThis change adds an in-flight validation to make sure all the\nspecified Ceph dependencies are installed.\nIf a package is not installed in the overcloud, then fail the\ndeployment using the message from the validations frame work.\n\nDepends-on: https://review.opendev.org/#/c/697453\nChange-Id: I1043d66586d22b26adf66145879d1a64a25f54a0\n'}]",0,698417,bcebf3996908eb72114bf27343ba6d74425d67f8,30,7,1,25402,,,0,"Ensure Ceph dependencies are installed in pre-provisioned nodes

This change adds an in-flight validation to make sure all the
specified Ceph dependencies are installed.
If a package is not installed in the overcloud, then fail the
deployment using the message from the validations frame work.

Depends-on: https://review.opendev.org/#/c/697453
Change-Id: I1043d66586d22b26adf66145879d1a64a25f54a0
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/17/698417/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/ceph-ansible/ceph-base.yaml'],1,bcebf3996908eb72114bf27343ba6d74425d67f8,ceph_deps_inflight_validations," - name: Check if Ceph dependencies are installed import_role: role: ceph tasks_from: ceph-dependencies-installed tags: - opendev-validation - opendev-validation-ceph vars: fail_without_deps: true packages: lvm2 tripleo_delegate_to: ""{{ groups['overcloud'] | default([]) }}""",,11,0
openstack%2Fneutron~master~I75713e0e3924ad4c9177e7c9b04c58882e292dc0,openstack/neutron,master,I75713e0e3924ad4c9177e7c9b04c58882e292dc0,"Add ""qos_network_policy_id"" to port definition",MERGED,2019-11-06 19:52:00.000000000,2020-01-30 06:20:06.000000000,2020-01-30 06:13:09.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 18051}, {'_account_id': 22348}, {'_account_id': 24791}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-11-06 19:52:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/00182ba26b880d04a7df386b27ea5202ac8a3eda', 'message': '[WIP] Add ""qos_network_policy_id"" to port definition\n\nAdded ""qos_network_policy_id"" key to port dictionary.\n\nDepends-On: https://review.opendev.org/#/c/693234/\nChange-Id: I75713e0e3924ad4c9177e7c9b04c58882e292dc0\nCloses-Bug: #1851362\n'}, {'number': 2, 'created': '2020-01-09 17:26:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/17660e990eba5762f234543e01b4a98944313ae6', 'message': 'Add ""qos_network_policy_id"" to port definition\n\nAdded ""qos_network_policy_id"" key to port dictionary.\n\nChange-Id: I75713e0e3924ad4c9177e7c9b04c58882e292dc0\nCloses-Bug: #1851362\n'}, {'number': 3, 'created': '2020-01-14 19:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e87e28889a3cbf2376beb2d4f1d063e5e8af2616', 'message': 'Add ""qos_network_policy_id"" to port definition\n\nAdded ""qos_network_policy_id"" key to port dictionary.\n\nChange-Id: I75713e0e3924ad4c9177e7c9b04c58882e292dc0\nCloses-Bug: #1851362\n'}, {'number': 4, 'created': '2020-01-17 17:57:11.000000000', 'files': ['neutron/services/qos/qos_plugin.py', 'neutron/tests/unit/core_extensions/test_qos.py', 'neutron/extensions/qos_port_network_policy.py', 'neutron/core_extensions/qos.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f2b52b5e8f2579cac2e9cd3844ed3e75d18cd06d', 'message': 'Add ""qos_network_policy_id"" to port definition\n\nAdded ""qos_network_policy_id"" key to port dictionary.\n\nChange-Id: I75713e0e3924ad4c9177e7c9b04c58882e292dc0\nCloses-Bug: #1851362\n'}]",3,693244,f2b52b5e8f2579cac2e9cd3844ed3e75d18cd06d,82,11,4,16688,,,0,"Add ""qos_network_policy_id"" to port definition

Added ""qos_network_policy_id"" key to port dictionary.

Change-Id: I75713e0e3924ad4c9177e7c9b04c58882e292dc0
Closes-Bug: #1851362
",git fetch https://review.opendev.org/openstack/neutron refs/changes/44/693244/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/core_extensions/qos.py'],1,00182ba26b880d04a7df386b27ea5202ac8a3eda,bug/1851362, retval = {qos_consts.QOS_POLICY_ID: qos_policy_id} if resource_type == base.PORT: network_binding = resource.get('qos_network_policy_binding') qos_net_policy_id = (network_binding['policy_id'] if network_binding else None) retval[qos_consts.QOS_NETWORK_POLICY_ID] = qos_net_policy_id return retval, return {qos_consts.QOS_POLICY_ID: qos_policy_id},7,1
openstack%2Fneutron~master~I6abecfbde525279fbfd4b9e27e0d1803311a7f96,openstack/neutron,master,I6abecfbde525279fbfd4b9e27e0d1803311a7f96,Pass result dict to extensions by create port bulk,MERGED,2020-01-26 02:23:50.000000000,2020-01-30 06:16:59.000000000,2020-01-30 06:13:06.000000000,"[{'_account_id': 4694}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 15554}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 24791}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-26 02:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/444d77a1c65f97800f6bc0dc3421ad59ef6c44fb', 'message': 'Pass result dict to extension drivers from create port bulk\n\nPass result dict to extension drivers from create port bulk\n\nChange-Id: I6abecfbde525279fbfd4b9e27e0d1803311a7f96\n'}, {'number': 2, 'created': '2020-01-26 18:24:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3757202998395f4d0e17bbfebfe5479715328c2f', 'message': 'Pass result dict to extensions by create port bulk\n\nThe create ports in bulk code in the ML2 plugin is passing to the\nextension drivers a DB object for each port created. Per the ML2\nextension drivers API deinition in [0], what should be passed instead is\nthe result dictionary of each created port. This change fixes the\nmismatch.\n\n[0] https://github.com/openstack/neutron-lib/blob/478502b3dfb8c3ff66318169377251826563a398/neutron_lib/plugins/ml2/api.py#L1142\n\nChange-Id: I6abecfbde525279fbfd4b9e27e0d1803311a7f96\n'}, {'number': 3, 'created': '2020-01-26 18:26:57.000000000', 'files': ['neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2e316157edd412d747e8533746c0974cab7dfde0', 'message': 'Pass result dict to extensions by create port bulk\n\nThe create ports in bulk code in the ML2 plugin is passing to the\nextension drivers a DB object for each port created. Per the ML2\nextension drivers API definition in [0], what should be passed instead\nis the result dictionary of each created port. This change fixes the\nmismatch.\n\n[0] https://github.com/openstack/neutron-lib/blob/478502b3dfb8c3ff66318169377251826563a398/neutron_lib/plugins/ml2/api.py#L1142\n\nChange-Id: I6abecfbde525279fbfd4b9e27e0d1803311a7f96\n'}]",2,704240,2e316157edd412d747e8533746c0974cab7dfde0,43,10,3,4694,,,0,"Pass result dict to extensions by create port bulk

The create ports in bulk code in the ML2 plugin is passing to the
extension drivers a DB object for each port created. Per the ML2
extension drivers API definition in [0], what should be passed instead
is the result dictionary of each created port. This change fixes the
mismatch.

[0] https://github.com/openstack/neutron-lib/blob/478502b3dfb8c3ff66318169377251826563a398/neutron_lib/plugins/ml2/api.py#L1142

Change-Id: I6abecfbde525279fbfd4b9e27e0d1803311a7f96
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/704240/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/plugin.py'],1,444d77a1c65f97800f6bc0dc3421ad59ef6c44fb,fix-create-port-bulk-db-object, port_dict), db_port_obj),1,1
openstack%2Fdevstack~stable%2Ftrain~I1cdb7e4a209872f1620be556b7278879a4b86df5,openstack/devstack,stable/train,I1cdb7e4a209872f1620be556b7278879a4b86df5,"Revert ""install LIBS_FROM_GIT using python 2 and 3 where appropriate""",MERGED,2020-01-28 12:09:06.000000000,2020-01-30 06:16:20.000000000,2020-01-30 06:13:11.000000000,"[{'_account_id': 4146}, {'_account_id': 7118}, {'_account_id': 8556}, {'_account_id': 10459}, {'_account_id': 12988}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-28 12:09:06.000000000', 'files': ['inc/python'], 'web_link': 'https://opendev.org/openstack/devstack/commit/1ed5bde039e7a8b2a0bc8c2fec362f1382f840fb', 'message': 'Revert ""install LIBS_FROM_GIT using python 2 and 3 where appropriate""\n\nAll the OpenStack projects should be able to run under Python 3 now so\nthe fallback installation of the Python 2 libraries should not be\nneeded any longer. This also avoids the problem of script files\ninstalled by the libraries sometimes being overwritten by the Python 2\nversion leading to incorrect execution later, as discussed in\nhttp://lists.openstack.org/pipermail/openstack-discuss/2019-September/009226.html\n\nThis reverts commit a2eb89417fbb6d61526b1819cbe3d0a60537eedd.\n\nChange-Id: I1cdb7e4a209872f1620be556b7278879a4b86df5\n(cherry picked from commit 16bccbcea410ce426f83b5086424080b5bfaf925)\n'}]",0,704543,1ed5bde039e7a8b2a0bc8c2fec362f1382f840fb,15,8,1,10459,,,0,"Revert ""install LIBS_FROM_GIT using python 2 and 3 where appropriate""

All the OpenStack projects should be able to run under Python 3 now so
the fallback installation of the Python 2 libraries should not be
needed any longer. This also avoids the problem of script files
installed by the libraries sometimes being overwritten by the Python 2
version leading to incorrect execution later, as discussed in
http://lists.openstack.org/pipermail/openstack-discuss/2019-September/009226.html

This reverts commit a2eb89417fbb6d61526b1819cbe3d0a60537eedd.

Change-Id: I1cdb7e4a209872f1620be556b7278879a4b86df5
(cherry picked from commit 16bccbcea410ce426f83b5086424080b5bfaf925)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/43/704543/1 && git format-patch -1 --stdout FETCH_HEAD,['inc/python'],1,1ed5bde039e7a8b2a0bc8c2fec362f1382f840fb,,," if python3_enabled; then # Turn off Python 3 mode and install the package again, # forcing a Python 2 installation. This ensures that all libs # being used for development are installed under both versions # of Python. echo ""Installing $name again without Python 3 enabled"" USE_PYTHON3=False setup_develop $bindep $dir USE_PYTHON3=True fi",0,10
openstack%2Fneutron~stable%2Fstein~I09114712582d2d38d14cf1683b87a8ce3a8e8c3c,openstack/neutron,stable/stein,I09114712582d2d38d14cf1683b87a8ce3a8e8c3c,List SG rules which belongs to tenant's SG,MERGED,2019-10-15 13:56:35.000000000,2020-01-30 06:15:33.000000000,2020-01-30 06:10:36.000000000,"[{'_account_id': 4694}, {'_account_id': 8313}, {'_account_id': 9732}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-10-15 13:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f763e11a40c57aa6cf9bd3b30fbebbfe971cb9df', 'message': ""List SG rules which belongs to tenant's SG\n\nIn case when user's security group contains rules created e.g.\nby admin, and such rules has got admin's tenant as tenant_id,\nowner of security group should be able to see those rules.\nSome time ago this was addressed for request:\n\nGET /v2.0/security-groups/<sec_group_id>\n\nBut it is also required to behave in same way for\n\nGET /v2.0/security-group-rules\n\nSo this patch fixes this behaviour for listing of security\ngroup rules.\nTo achieve that this patch also adds new policy rule:\nADMIN_OWNER_OR_SG_OWNER which is similar to already existing\nADMIN_OWNER_OR_NETWORK_OWNER used e.g. for listing or creating\nports.\n\nChange-Id: I09114712582d2d38d14cf1683b87a8ce3a8e8c3c\nCloses-Bug: #1824248\n""}, {'number': 2, 'created': '2019-12-04 20:34:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1c649b11e3cf37c8f5cc9661d1e06ed4a412b6af', 'message': ""List SG rules which belongs to tenant's SG\n\nIn case when user's security group contains rules created e.g.\nby admin, and such rules has got admin's tenant as tenant_id,\nowner of security group should be able to see those rules.\nSome time ago this was addressed for request:\n\nGET /v2.0/security-groups/<sec_group_id>\n\nBut it is also required to behave in same way for\n\nGET /v2.0/security-group-rules\n\nSo this patch fixes this behaviour for listing of security\ngroup rules.\nTo achieve that this patch also adds new policy rule:\nADMIN_OWNER_OR_SG_OWNER which is similar to already existing\nADMIN_OWNER_OR_NETWORK_OWNER used e.g. for listing or creating\nports.\n\nChange-Id: I09114712582d2d38d14cf1683b87a8ce3a8e8c3c\nCloses-Bug: #1824248\n""}, {'number': 3, 'created': '2019-12-04 20:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bb22d9eef6f95aea2bce14a18f57fedafbde2672', 'message': ""List SG rules which belongs to tenant's SG\n\nIn case when user's security group contains rules created e.g.\nby admin, and such rules has got admin's tenant as tenant_id,\nowner of security group should be able to see those rules.\nSome time ago this was addressed for request:\n\nGET /v2.0/security-groups/<sec_group_id>\n\nBut it is also required to behave in same way for\n\nGET /v2.0/security-group-rules\n\nSo this patch fixes this behaviour for listing of security\ngroup rules.\nTo achieve that this patch also adds new policy rule:\nADMIN_OWNER_OR_SG_OWNER which is similar to already existing\nADMIN_OWNER_OR_NETWORK_OWNER used e.g. for listing or creating\nports.\n\nChange-Id: I09114712582d2d38d14cf1683b87a8ce3a8e8c3c\nCloses-Bug: #1824248\n""}, {'number': 4, 'created': '2020-01-16 08:57:07.000000000', 'files': ['releasenotes/notes/show-all-security-group-rules-for-security-group-owner-6635dd3e4c6ab5ee.yaml', 'neutron/db/securitygroups_db.py', 'neutron/policy.py', 'neutron/conf/policies/security_group.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/47890e9b85826951387fedb57ab474bd20ab1c3b', 'message': ""List SG rules which belongs to tenant's SG\n\nIn case when user's security group contains rules created e.g.\nby admin, and such rules has got admin's tenant as tenant_id,\nowner of security group should be able to see those rules.\nSome time ago this was addressed for request:\n\nGET /v2.0/security-groups/<sec_group_id>\n\nBut it is also required to behave in same way for\n\nGET /v2.0/security-group-rules\n\nSo this patch fixes this behaviour for listing of security\ngroup rules.\nTo achieve that this patch also adds new policy rule:\nADMIN_OWNER_OR_SG_OWNER which is similar to already existing\nADMIN_OWNER_OR_NETWORK_OWNER used e.g. for listing or creating\nports.\n\nChange-Id: I09114712582d2d38d14cf1683b87a8ce3a8e8c3c\nCloses-Bug: #1824248\n(cherry picked from commit b898d2e3c08b50e576ee849fbe8614c66f360c62)\n""}]",2,688716,47890e9b85826951387fedb57ab474bd20ab1c3b,37,8,4,11975,,,0,"List SG rules which belongs to tenant's SG

In case when user's security group contains rules created e.g.
by admin, and such rules has got admin's tenant as tenant_id,
owner of security group should be able to see those rules.
Some time ago this was addressed for request:

GET /v2.0/security-groups/<sec_group_id>

But it is also required to behave in same way for

GET /v2.0/security-group-rules

So this patch fixes this behaviour for listing of security
group rules.
To achieve that this patch also adds new policy rule:
ADMIN_OWNER_OR_SG_OWNER which is similar to already existing
ADMIN_OWNER_OR_NETWORK_OWNER used e.g. for listing or creating
ports.

Change-Id: I09114712582d2d38d14cf1683b87a8ce3a8e8c3c
Closes-Bug: #1824248
(cherry picked from commit b898d2e3c08b50e576ee849fbe8614c66f360c62)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/16/688716/4 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/show-all-security-group-rules-for-security-group-owner-6635dd3e4c6ab5ee.yaml', 'neutron/db/securitygroups_db.py', 'neutron/policy.py', 'neutron/conf/policies/security_group.py']",4,f763e11a40c57aa6cf9bd3b30fbebbfe971cb9df,bug/1824248-stable/train-stable/stein,"RULE_ADMIN_OR_SG_OWNER = 'rule:admin_or_sg_owner' RULE_ADMIN_OWNER_OR_SG_OWNER = 'rule:admin_owner_or_sg_owner' policy.RuleDefault( 'admin_or_sg_owner', base.policy_or('rule:context_is_admin', 'tenant_id:%(security_group:tenant_id)s'), description='Rule for admin or security group owner access'), policy.RuleDefault( 'admin_owner_or_sg_owner', base.policy_or('rule:owner', RULE_ADMIN_OR_SG_OWNER), description=('Rule for resource owner, ' 'admin or security group owner access')), RULE_ADMIN_OWNER_OR_SG_OWNER,"," base.RULE_ADMIN_OR_OWNER,",35,4
openstack%2Fkeystone~stable%2Ftrain~Ie0c0b48d240b118f7b491d164e5c1a203ebb31e8,openstack/keystone,stable/train,Ie0c0b48d240b118f7b491d164e5c1a203ebb31e8,Remove legacy protection tests,MERGED,2019-10-09 17:49:50.000000000,2020-01-30 06:14:16.000000000,2020-01-30 06:10:41.000000000,"[{'_account_id': 5046}, {'_account_id': 6873}, {'_account_id': 8482}, {'_account_id': 9954}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-09 17:49:50.000000000', 'files': ['keystone/tests/unit/test_v3_protection.py', 'keystone/tests/unit/test_v3_auth.py', 'keystone/tests/protection/v3/test_tokens.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/4752cd3fa4492f740bcb55f2efcb813865771bc5', 'message': ""Remove legacy protection tests\n\nThis commit removes a bunch of tests that were originally written to\ntest the policy.v3cloudsample.json policy file. Now that we've\nimplemented system-scope, default roles, and removed the\npolicy.v3cloudsample.json policy file, we can remove these tests.\n\nThis commit also ports some token revocation tests over to the\nprotection test suite so we have full coverage from\nTestTokenRevokeSelfAndAdmin.\n\nChange-Id: Ie0c0b48d240b118f7b491d164e5c1a203ebb31e8\n(cherry picked from commit 5f5f10630c7d2a5600f9efc0950a1f20b17a0d8c)\n""}]",0,687640,4752cd3fa4492f740bcb55f2efcb813865771bc5,14,5,1,5046,,,0,"Remove legacy protection tests

This commit removes a bunch of tests that were originally written to
test the policy.v3cloudsample.json policy file. Now that we've
implemented system-scope, default roles, and removed the
policy.v3cloudsample.json policy file, we can remove these tests.

This commit also ports some token revocation tests over to the
protection test suite so we have full coverage from
TestTokenRevokeSelfAndAdmin.

Change-Id: Ie0c0b48d240b118f7b491d164e5c1a203ebb31e8
(cherry picked from commit 5f5f10630c7d2a5600f9efc0950a1f20b17a0d8c)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/40/687640/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/test_v3_protection.py', 'keystone/tests/unit/test_v3_auth.py', 'keystone/tests/protection/v3/test_tokens.py']",3,4752cd3fa4492f740bcb55f2efcb813865771bc5,," def test_user_can_revoke_their_own_tokens(self): with self.test_client() as c: self.headers['X-Subject-Token'] = self.token_id c.delete('/v3/auth/tokens', headers=self.headers) def test_user_cannot_revoke_system_scoped_token(self): user = unit.new_user_ref(domain_id=CONF.identity.default_domain_id) user['id'] = PROVIDERS.identity_api.create_user(user)['id'] PROVIDERS.assignment_api.create_system_grant_for_user( user['id'], self.bootstrapper.reader_role_id ) system_auth = self.build_authentication_request( user_id=user['id'], password=user['password'], system=True ) with self.test_client() as c: r = c.post('/v3/auth/tokens', json=system_auth) system_token = r.headers['X-Subject-Token'] with self.test_client() as c: self.headers['X-Subject-Token'] = system_token c.delete( '/v3/auth/tokens', headers=self.headers, expected_status_code=http_client.FORBIDDEN ) def test_user_cannot_revoke_domain_scoped_token(self): domain = PROVIDERS.resource_api.create_domain( uuid.uuid4().hex, unit.new_domain_ref() ) user = unit.new_user_ref(domain_id=domain['id']) user['id'] = PROVIDERS.identity_api.create_user(user)['id'] PROVIDERS.assignment_api.create_grant( self.bootstrapper.reader_role_id, user_id=user['id'], domain_id=domain['id'] ) domain_auth = self.build_authentication_request( user_id=user['id'], password=user['password'], domain_id=domain['id'] ) with self.test_client() as c: r = c.post('/v3/auth/tokens', json=domain_auth) domain_token = r.headers['X-Subject-Token'] with self.test_client() as c: self.headers['X-Subject-Token'] = domain_token c.delete( '/v3/auth/tokens', headers=self.headers, expected_status_code=http_client.FORBIDDEN ) def test_user_cannot_revoke_project_scoped_token(self): project = PROVIDERS.resource_api.create_project( uuid.uuid4().hex, unit.new_project_ref(domain_id=CONF.identity.default_domain_id) ) user = unit.new_user_ref(domain_id=CONF.identity.default_domain_id) user['id'] = PROVIDERS.identity_api.create_user(user)['id'] PROVIDERS.assignment_api.create_grant( self.bootstrapper.reader_role_id, user_id=user['id'], project_id=project['id'] ) project_auth = self.build_authentication_request( user_id=user['id'], password=user['password'], project_id=project['id'] ) with self.test_client() as c: r = c.post('/v3/auth/tokens', json=project_auth) project_token = r.headers['X-Subject-Token'] with self.test_client() as c: self.headers['X-Subject-Token'] = project_token c.delete( '/v3/auth/tokens', headers=self.headers, expected_status_code=http_client.FORBIDDEN ) ", pass,88,1670
openstack%2Fneutron-tempest-plugin~master~Ibe83390402675bb7e7d3cc4909a8097de4b0f836,openstack/neutron-tempest-plugin,master,Ibe83390402675bb7e7d3cc4909a8097de4b0f836,Add debugging information in case of SSH connection error,MERGED,2020-01-16 16:02:48.000000000,2020-01-30 06:10:40.000000000,2020-01-30 06:10:39.000000000,"[{'_account_id': 4694}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 16:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/3895c9f6bf07815acf309697b9814fdde23d5ce8', 'message': 'Add debugging information in case of SSH connection error\n\nIn case of SSH error, new debugging information is added to the log:\n- The local routing table\n- The local ARP table\n\nChange-Id: Ibe83390402675bb7e7d3cc4909a8097de4b0f836\nRelated-Bug: #1858642\n'}, {'number': 2, 'created': '2020-01-28 14:38:02.000000000', 'files': ['neutron_tempest_plugin/common/ip.py', 'neutron_tempest_plugin/scenario/base.py'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/4849f00e7eb7f0da8a62f7f697e27770d9b89ec3', 'message': 'Add debugging information in case of SSH connection error\n\nIn case of SSH error, new debugging information is added to the log:\n- The local routing table\n- The local ARP table\n\nChange-Id: Ibe83390402675bb7e7d3cc4909a8097de4b0f836\nRelated-Bug: #1858642\n'}]",0,702903,4849f00e7eb7f0da8a62f7f697e27770d9b89ec3,21,4,2,16688,,,0,"Add debugging information in case of SSH connection error

In case of SSH error, new debugging information is added to the log:
- The local routing table
- The local ARP table

Change-Id: Ibe83390402675bb7e7d3cc4909a8097de4b0f836
Related-Bug: #1858642
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/03/702903/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_tempest_plugin/common/ip.py', 'neutron_tempest_plugin/scenario/base.py']",2,3895c9f6bf07815acf309697b9814fdde23d5ce8,bug/1858642,"from neutron_tempest_plugin.common import ip as ip_utils self._log_local_network_status() def _log_local_network_status(self): local_routes = ip_utils.IPCommand().list_routes() LOG.debug('Local routes:\n%s', '\n'.join(str(r) for r in local_routes)) arp_table = ip_utils.arp_table() LOG.debug('Local ARP table:\n%s', '\n'.join(str(r) for r in arp_table)) ",,42,0
openstack%2Ffreezer~master~I661e9cdaf33e89bdb905d1f34a001f3853c4c366,openstack/freezer,master,I661e9cdaf33e89bdb905d1f34a001f3853c4c366,Remove six usage from freezer package,MERGED,2020-01-22 11:54:29.000000000,2020-01-30 05:52:16.000000000,2020-01-30 05:50:53.000000000,"[{'_account_id': 21069}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-22 11:54:29.000000000', 'files': ['freezer/tests/integration/common.py', 'freezer/engine/rsync/pyrsync.py', 'freezer/utils/checksum.py', 'freezer/tests/unit/utils/test_checksum.py', 'freezer/engine/engine.py', 'freezer/utils/config.py', 'freezer/storage/physical.py', 'freezer/tests/unit/engines/rsync/test_pyrsync.py', 'freezer/tests/unit/utils/test_config.py', 'freezer/utils/utils.py', 'lower-constraints.txt', 'freezer/engine/rsyncv2/rsyncv2.py', 'freezer/storage/fslike.py', 'freezer/storage/multiple.py', 'freezer/utils/streaming.py', 'requirements.txt', 'freezer/job.py', 'freezer/mode/mode.py', 'freezer/engine/rsync/rsync.py', 'freezer/scheduler/scheduler_job.py', 'freezer/lib/pep3143daemon/daemon.py', 'freezer/storage/base.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/02e435f0ed1aede7a2da68cf99d315e9551b642d', 'message': ""Remove six usage from freezer package\n\nWe don't support Python 2 anymore so we don't need this\ncompatibility library.\n\nThis patch remove six usage.\n\nChange-Id: I661e9cdaf33e89bdb905d1f34a001f3853c4c366\n""}]",0,703779,02e435f0ed1aede7a2da68cf99d315e9551b642d,9,2,1,21069,,,0,"Remove six usage from freezer package

We don't support Python 2 anymore so we don't need this
compatibility library.

This patch remove six usage.

Change-Id: I661e9cdaf33e89bdb905d1f34a001f3853c4c366
",git fetch https://review.opendev.org/openstack/freezer refs/changes/79/703779/1 && git format-patch -1 --stdout FETCH_HEAD,"['freezer/tests/integration/common.py', 'freezer/engine/rsync/pyrsync.py', 'freezer/utils/checksum.py', 'freezer/tests/unit/utils/test_checksum.py', 'freezer/engine/engine.py', 'freezer/utils/config.py', 'freezer/storage/physical.py', 'freezer/tests/unit/engines/rsync/test_pyrsync.py', 'freezer/tests/unit/utils/test_config.py', 'freezer/utils/utils.py', 'lower-constraints.txt', 'freezer/engine/rsyncv2/rsyncv2.py', 'freezer/storage/fslike.py', 'freezer/storage/multiple.py', 'freezer/utils/streaming.py', 'requirements.txt', 'freezer/job.py', 'freezer/mode/mode.py', 'freezer/engine/rsync/rsync.py', 'freezer/scheduler/scheduler_job.py', 'freezer/lib/pep3143daemon/daemon.py', 'freezer/storage/base.py']",22,02e435f0ed1aede7a2da68cf99d315e9551b642d,,class Storage(metaclass=abc.ABCMeta):,import six@six.add_metaclass(abc.ABCMeta) class Storage(object):,41,81
openstack%2Fopenstack-helm-infra~master~I90f0c3fd5d1e1b835326b1c690582990f7ca15cb,openstack/openstack-helm-infra,master,I90f0c3fd5d1e1b835326b1c690582990f7ca15cb,[ceph-osd] Fix to check osd disk name instead of  disk path,MERGED,2020-01-30 01:42:32.000000000,2020-01-30 05:42:19.000000000,2020-01-30 05:40:45.000000000,"[{'_account_id': 8898}, {'_account_id': 17119}, {'_account_id': 18511}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23928}, {'_account_id': 26686}, {'_account_id': 29974}]","[{'number': 1, 'created': '2020-01-30 01:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/decadee25ab04bb5b24e208b573b23954796ae4f', 'message': '[ceph-osd] Fix to check osd disk name instead of  disk path\n\nThis is to fix the logic to use osd device name instaed of whole disk path\nwhile osd initilizing.\n\nChange-Id: I90f0c3fd5d1e1b835326b1c690582990f7ca15cb\n'}, {'number': 2, 'created': '2020-01-30 02:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/49346e03ced896b1e819baee2bbf3471a7b36f4e', 'message': '[ceph-osd] Fix to check osd disk name instead of  disk path\n\nThis is to fix the logic to use osd device name instaed of whole disk path\nwhile osd initilizing.\n\nChange-Id: I90f0c3fd5d1e1b835326b1c690582990f7ca15cb\n'}, {'number': 3, 'created': '2020-01-30 02:49:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/753959569e06f21ddb1c7de6f6abb4158994104f', 'message': '[ceph-osd] Fix to check osd disk name instead of  disk path\n\nThis is to fix the logic to use osd device name instaed of whole disk path\nwhile osd initilizing.\nalso correct the ceph osd ls command to use correct keyring.\n\nChange-Id: I90f0c3fd5d1e1b835326b1c690582990f7ca15cb\n'}, {'number': 4, 'created': '2020-01-30 03:31:35.000000000', 'files': ['ceph-osd/templates/bin/osd/ceph-volume/_init-with-ceph-volume.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/63e43d98b772d885d7aa4f775dd4adb7049b4682', 'message': '[ceph-osd] Fix to check osd disk name instead of  disk path\n\nThis is to fix the logic to use osd device name instaed of whole disk path\nwhile osd initilizing.\nalso correct the ceph osd ls command to use correct keyring.\n\nChange-Id: I90f0c3fd5d1e1b835326b1c690582990f7ca15cb\n'}]",2,704915,63e43d98b772d885d7aa4f775dd4adb7049b4682,20,8,4,28372,,,0,"[ceph-osd] Fix to check osd disk name instead of  disk path

This is to fix the logic to use osd device name instaed of whole disk path
while osd initilizing.
also correct the ceph osd ls command to use correct keyring.

Change-Id: I90f0c3fd5d1e1b835326b1c690582990f7ca15cb
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/15/704915/4 && git format-patch -1 --stdout FETCH_HEAD,['ceph-osd/templates/bin/osd/ceph-volume/_init-with-ceph-volume.sh.tpl'],1,decadee25ab04bb5b24e208b573b23954796ae4f,," osd_dev_split=$(echo ${OSD_DEVICE} | awk -F ""/"" '{print $3}') if dmsetup ls |grep -i ${osd_dev_split}; then", if dmsetup ls |grep -i ${OSD_DEVICE}; then,2,1
openstack%2Ffreezer-tempest-plugin~master~I025c12a265de4e3fdfad67c9e570c3110869acd6,openstack/freezer-tempest-plugin,master,I025c12a265de4e3fdfad67c9e570c3110869acd6,[ussuri][goal] Drop python 2.7 support and testing,MERGED,2020-01-23 22:13:29.000000000,2020-01-30 05:37:30.000000000,2020-01-30 05:37:29.000000000,"[{'_account_id': 21069}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 22:13:29.000000000', 'files': ['test-requirements.txt', 'releasenotes/notes/drop-py-2-7-b64b230b4ad22d82.yaml', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/freezer-tempest-plugin/commit/3d8fcb471020d3407671067ac2b043e44b269ff0', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nfreezer-tempest-plugin is ready with python 3 and ok to drop the\npython 2.7 support.\n\nRemoving the USE_PYTHON3=True from base job so that it can\nkeep running  on py3 for < ussuri branches.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: I025c12a265de4e3fdfad67c9e570c3110869acd6\n'}]",0,704074,3d8fcb471020d3407671067ac2b043e44b269ff0,6,2,1,8556,,,0,"[ussuri][goal] Drop python 2.7 support and testing

OpenStack is dropping the py2.7 support in ussuri cycle.

freezer-tempest-plugin is ready with python 3 and ok to drop the
python 2.7 support.

Removing the USE_PYTHON3=True from base job so that it can
keep running  on py3 for < ussuri branches.

Complete discussion & schedule can be found in
- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html
- https://etherpad.openstack.org/p/drop-python2-support

Ussuri Communtiy-wide goal:
https://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html

Change-Id: I025c12a265de4e3fdfad67c9e570c3110869acd6
",git fetch https://review.opendev.org/openstack/freezer-tempest-plugin refs/changes/74/704074/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'releasenotes/notes/drop-py-2-7-b64b230b4ad22d82.yaml', 'setup.cfg', 'tox.ini']",4,3d8fcb471020d3407671067ac2b043e44b269ff0,drop-py27-support,minversion = 3.1.1ignore_basepython_conflict = Truebasepython = python3,minversion = 2.0basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,12,11
openstack%2Faodh~master~I9258ae4801edbc5289d890fe2e060964a73b216c,openstack/aodh,master,I9258ae4801edbc5289d890fe2e060964a73b216c,Support quota API,MERGED,2020-01-29 09:09:49.000000000,2020-01-30 05:28:54.000000000,2020-01-30 05:27:39.000000000,"[{'_account_id': 6732}, {'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 09:09:49.000000000', 'files': ['aodh/tests/base.py', 'aodh/api/rbac.py', 'aodh/api/policies.py', 'aodh/tests/functional/api/v2/test_quotas.py', 'aodh/api/controllers/v2/root.py', 'aodh/storage/sqlalchemy/alembic/versions/007_add_quota_table.py', 'aodh/api/controllers/v2/base.py', 'aodh/api/controllers/v2/alarms.py', 'aodh/storage/models.py', 'aodh/storage/sqlalchemy/models.py', 'aodh/api/controllers/v2/quotas.py', 'aodh/storage/impl_sqlalchemy.py', 'aodh/storage/base.py'], 'web_link': 'https://opendev.org/openstack/aodh/commit/223178716e784aa1e65c656dc639a18ddf4fba9f', 'message': 'Support quota API\n\nCurrently Aodh only supports global quota for projects and users, we\nneed quota API to manage quotas per project.\n\nThe new quota API only supports project quotas as the same with other\nopenstack services.\n\nBy default, only admin user can update the quota.\n\nTODO(in subsequent patches):\n- Check quota from DB when creating resources\n- Doc\n- Release note\n- openstack CLI support\n\nChange-Id: I9258ae4801edbc5289d890fe2e060964a73b216c\n'}]",0,704751,223178716e784aa1e65c656dc639a18ddf4fba9f,7,3,1,6732,,,0,"Support quota API

Currently Aodh only supports global quota for projects and users, we
need quota API to manage quotas per project.

The new quota API only supports project quotas as the same with other
openstack services.

By default, only admin user can update the quota.

TODO(in subsequent patches):
- Check quota from DB when creating resources
- Doc
- Release note
- openstack CLI support

Change-Id: I9258ae4801edbc5289d890fe2e060964a73b216c
",git fetch https://review.opendev.org/openstack/aodh refs/changes/51/704751/1 && git format-patch -1 --stdout FETCH_HEAD,"['aodh/tests/base.py', 'aodh/api/rbac.py', 'aodh/api/policies.py', 'aodh/tests/functional/api/v2/test_quotas.py', 'aodh/api/controllers/v2/root.py', 'aodh/storage/sqlalchemy/alembic/versions/007_add_quota_table.py', 'aodh/api/controllers/v2/base.py', 'aodh/api/controllers/v2/alarms.py', 'aodh/storage/models.py', 'aodh/storage/sqlalchemy/models.py', 'aodh/api/controllers/v2/quotas.py', 'aodh/storage/impl_sqlalchemy.py', 'aodh/storage/base.py']",13,223178716e784aa1e65c656dc639a18ddf4fba9f,quota-api," @staticmethod def get_quotas(project_id): """"""Get resource quota for the given project."""""" raise aodh.NotImplementedError('Getting resource quota not ' 'implemented') @staticmethod def set_quotas(project_id, quotas): """"""Set resource quota for the given user."""""" raise aodh.NotImplementedError('Setting resource quota not ' 'implemented')",,359,11
openstack%2Frpm-packaging~master~I69f2ffdc60c96690167776783b182ad9afc17b94,openstack/rpm-packaging,master,I69f2ffdc60c96690167776783b182ad9afc17b94,stackviz: convert to python3,MERGED,2020-01-16 18:35:32.000000000,2020-01-30 05:23:15.000000000,2020-01-30 05:23:15.000000000,"[{'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-16 18:35:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/23b92cdbda809ac0e3b96a368dd01ce62c9838ba', 'message': 'stackviz: convert to python3\n\nAlso enable unit tests.\n\nChange-Id: I69f2ffdc60c96690167776783b182ad9afc17b94\n'}, {'number': 2, 'created': '2020-01-17 11:55:30.000000000', 'files': ['openstack/stackviz/stackviz.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/fa8cc044ea6a20ff0eaf08faa8f93ca462cf0bbd', 'message': 'stackviz: convert to python3\n\nAlso enable unit tests.\n\nChange-Id: I69f2ffdc60c96690167776783b182ad9afc17b94\n'}]",0,702953,fa8cc044ea6a20ff0eaf08faa8f93ca462cf0bbd,15,5,2,13294,,,0,"stackviz: convert to python3

Also enable unit tests.

Change-Id: I69f2ffdc60c96690167776783b182ad9afc17b94
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/53/702953/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/stackviz/stackviz.spec.j2'],1,23b92cdbda809ac0e3b96a368dd01ce62c9838ba,remove-python2,%global with_tests 1BuildRequires: {{ py3('devel') }} BuildRequires: {{ py3('oslotest') }} BuildRequires: {{ py3('python-subunit') }} BuildRequires: {{ py3('stestr') }} BuildRequires: {{ py3('testrepository') }} BuildRequires: {{ py3('testtools') }}Requires: {{ py3('subunit2sql') }}BuildRequires: {{ py3('docutils') }}%package -n {{ py2name(py_versions='py3') }} Summary: Visualization utility Requires: {{ py3('six') }} Requires: {{ py3('python-subunit') }} Requires: {{ py3('testrepository') }} Requires: {{ py3('testtools') }} %if 0%{?rdo} Requires: {{ py3('subunit2sql') }} %endif %description -n {{ py2name(py_versions='py3') }} %{common_desc} This package contains the Python 3.x module. BuildRequires: {{ py3('Sphinx') }} BuildRequires: {{ py3('openstackdocstheme') }}%{py3_build}PBR_VERSION={{ upstream_version }} %sphinx_build -b html doc/source doc/build/html%{py3_install}python3 -m stestr.cli run %files -n {{ py2name(py_versions='py3') }}%{_bindir}/stackviz-export %{python3_sitelib}/stackviz %{python3_sitelib}/stackviz-*.egg-info,"%global with_tests 0BuildRequires: {{ py2pkg('devel', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('python-subunit', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('testrepository', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('testtools', py_versions=['py2', 'py3']) }} Requires: {{ py2pkg('python-subunit') }} Requires: {{ py2pkg('testrepository') }} Requires: {{ py2pkg('testtools') }}BuildRequires: {{ py2pkg('subunit2sql') }} Requires: {{ py2pkg('subunit2sql') }}BuildRequires: {{ py2pkg('docutils', py_versions=['py2', 'py3']) }}%if 0%{?suse_version} Requires(post): update-alternatives Requires(postun): update-alternatives %else # on RDO, update-alternatives is in chkconfig Requires(post): chkconfig Requires(postun): chkconfig %endif %python_subpackagesBuildRequires: {{ py2pkg('Sphinx') }} BuildRequires: {{ py2pkg('openstackdocstheme') }}# Remove bundled egg-info rm -rf %{module}.egg-info%{python_build}PBR_VERSION={{ upstream_version }} sphinx-build -b html doc/source doc/build/html%{python_install} %python_clone -a %{buildroot}%{_bindir}/stackviz-export %{__python2} setup.py test%post %python_install_alternative stackviz-export %postun %python_uninstall_alternative stackviz-export %files %{python_files}%python_alternative %{_bindir}/stackviz-export %{python_sitelib}/stackviz %{python_sitelib}/stackviz-*.egg-info",34,39
openstack%2Fzun~master~I55ca8d25990570f64c62542df683ca90d6ba9c0e,openstack/zun,master,I55ca8d25990570f64c62542df683ca90d6ba9c0e,Move volume-related code to base container driver,MERGED,2020-01-19 05:27:33.000000000,2020-01-30 04:42:35.000000000,2020-01-30 04:40:51.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-19 05:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/bed4d0d2232ceae55101d3355ca5d59100f8f982', 'message': '[WIP] Cleanup container driver interface\n\nChange-Id: I55ca8d25990570f64c62542df683ca90d6ba9c0e\n'}, {'number': 2, 'created': '2020-01-19 16:33:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/7a4e8b8955686fe3e1e8c3fbda3c6816937b64d6', 'message': 'Cleanup container driver interface\n\nChange-Id: I55ca8d25990570f64c62542df683ca90d6ba9c0e\n'}, {'number': 3, 'created': '2020-01-19 17:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/6c6e299e17997a65c6a73a40cc96b9ea2e10efb5', 'message': 'Cleanup container driver interface\n\nChange-Id: I55ca8d25990570f64c62542df683ca90d6ba9c0e\n'}, {'number': 4, 'created': '2020-01-19 17:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/5e2c7f68eec2acd36a69161a93aca6553f5467b8', 'message': 'Cleanup container driver interface\n\nChange-Id: I55ca8d25990570f64c62542df683ca90d6ba9c0e\n'}, {'number': 5, 'created': '2020-01-19 17:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/dd1b8417be90c24c29626b88812cb9d9db1e7467', 'message': 'Cleanup container driver interface\n\nChange-Id: I55ca8d25990570f64c62542df683ca90d6ba9c0e\n'}, {'number': 6, 'created': '2020-01-19 18:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/14fb6130ee6037b0d74dfb2f94076346df2f5aea', 'message': 'Cleanup container driver interface\n\nChange-Id: I55ca8d25990570f64c62542df683ca90d6ba9c0e\n'}, {'number': 7, 'created': '2020-01-19 19:41:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/bf5cd1c8027ef422eeade4b263dc5d3bc9c3f4f9', 'message': 'Move volume-related code to base container driver\n\nThe goal is to be able to re-use the code if we introduce\na second container driver.\n\nChange-Id: I55ca8d25990570f64c62542df683ca90d6ba9c0e\n'}, {'number': 8, 'created': '2020-01-19 19:44:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/236144012521656c2e59e2d9d9caf8f653f3142c', 'message': 'Move volume-related code to base container driver\n\nThe goal is to be able to re-use the code if we introduce\na second container driver.\n\nChange-Id: I55ca8d25990570f64c62542df683ca90d6ba9c0e\n'}, {'number': 9, 'created': '2020-01-19 23:56:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/536d1ab939a32249c4e4a1ca92f21cac16185c5f', 'message': 'Move volume-related code to base container driver\n\nThe goal is to be able to re-use the code if we introduce\na second container driver.\n\nChange-Id: I55ca8d25990570f64c62542df683ca90d6ba9c0e\n'}, {'number': 10, 'created': '2020-01-25 19:13:26.000000000', 'files': ['zun/container/docker/driver.py', 'zun/container/driver.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/46a2d314aba04094683feb2f0852647a56424ec4', 'message': 'Move volume-related code to base container driver\n\nThe goal is to be able to re-use the code if we introduce\na second container driver.\n\nChange-Id: I55ca8d25990570f64c62542df683ca90d6ba9c0e\n'}]",0,703275,46a2d314aba04094683feb2f0852647a56424ec4,22,2,10,11536,,,0,"Move volume-related code to base container driver

The goal is to be able to re-use the code if we introduce
a second container driver.

Change-Id: I55ca8d25990570f64c62542df683ca90d6ba9c0e
",git fetch https://review.opendev.org/openstack/zun refs/changes/75/703275/4 && git format-patch -1 --stdout FETCH_HEAD,"['zun/container/docker/driver.py', 'zun/tests/unit/container/fake_driver.py', 'zun/container/driver.py', 'zun/tests/unit/container/docker/test_docker_driver.py']",4,bed4d0d2232ceae55101d3355ca5d59100f8f982,,," def test_get_container_name(self): mock_container = mock.MagicMock( uuid='ea8e2a25-2901-438d-8157-de7ffd68d051') result_container_name = self.driver.get_container_name( mock_container) self.assertEqual( result_container_name, '%sea8e2a25-2901-438d-8157-de7ffd68d051' % consts.NAME_PREFIX) ",39,54
openstack%2Fneutron~stable%2Fqueens~Id019fa7649bd1158f9d56e63f8dad108d0ca8c1f,openstack/neutron,stable/queens,Id019fa7649bd1158f9d56e63f8dad108d0ca8c1f,Allow to kill keepalived state change monitor process,MERGED,2020-01-28 15:47:24.000000000,2020-01-30 04:20:04.000000000,2020-01-30 04:20:04.000000000,"[{'_account_id': 4694}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-28 15:47:24.000000000', 'files': ['etc/neutron/rootwrap.d/l3.filters'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e6c419b42c1b8c8902bedb02b791c4a2f4ea053b', 'message': 'Allow to kill keepalived state change monitor process\n\nUsually Neutron stops neutron-keepalived-state-change-monitor process\ngracefully with SIGTERM.\nBut in case if this will not stop process for some time, Neutron will\ntry to kill this process with SIGKILL (-9).\nThat was causing problem with rootwrap as kill filters for this process\nallowed to send only ""-15"" to it.\nNow it is possible to kill this process with ""-9"" too.\n\nConflicts:\n    etc/neutron/rootwrap.d/l3.filters\n\nChange-Id: Id019fa7649bd1158f9d56e63f8dad108d0ca8c1f\nCloses-bug: #1860326\n(cherry picked from commit d6fccd247f70abc84c8a480138e135717836c7b3)\n(cherry picked from commit f4d05266d21337538a2743a743ee1aa540407ac7)\n'}]",0,704597,e6c419b42c1b8c8902bedb02b791c4a2f4ea053b,9,5,1,11975,,,0,"Allow to kill keepalived state change monitor process

Usually Neutron stops neutron-keepalived-state-change-monitor process
gracefully with SIGTERM.
But in case if this will not stop process for some time, Neutron will
try to kill this process with SIGKILL (-9).
That was causing problem with rootwrap as kill filters for this process
allowed to send only ""-15"" to it.
Now it is possible to kill this process with ""-9"" too.

Conflicts:
    etc/neutron/rootwrap.d/l3.filters

Change-Id: Id019fa7649bd1158f9d56e63f8dad108d0ca8c1f
Closes-bug: #1860326
(cherry picked from commit d6fccd247f70abc84c8a480138e135717836c7b3)
(cherry picked from commit f4d05266d21337538a2743a743ee1aa540407ac7)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/97/704597/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/neutron/rootwrap.d/l3.filters'],1,e6c419b42c1b8c8902bedb02b791c4a2f4ea053b,bug/1860326-stable/queens,"kill_keepalived_monitor_py: KillFilter, root, python, -15, -9 kill_keepalived_monitor_py27: KillFilter, root, python2.7, -15, -9 kill_keepalived_monitor_py3: KillFilter, root, python3, -15, -9 kill_keepalived_monitor_py35: KillFilter, root, python3.5, -15, -9 kill_keepalived_monitor_py36: KillFilter, root, python3.6, -15, -9 kill_keepalived_monitor_py37: KillFilter, root, python3.7, -15, -9","kill_keepalived_monitor_py: KillFilter, root, python, -15 kill_keepalived_monitor_py27: KillFilter, root, python2.7, -15 kill_keepalived_monitor_py3: KillFilter, root, python3, -15 kill_keepalived_monitor_py35: KillFilter, root, python3.5, -15 kill_keepalived_monitor_py36: KillFilter, root, python3.6, -15 kill_keepalived_monitor_py37: KillFilter, root, python3.7, -15",6,6
openstack%2Fneutron~stable%2Fqueens~I10e3619d5f3600ea97ed695321bb691dece3181f,openstack/neutron,stable/queens,I10e3619d5f3600ea97ed695321bb691dece3181f,Add retries to update trunk port,MERGED,2020-01-14 08:16:43.000000000,2020-01-30 04:20:01.000000000,2020-01-30 04:20:01.000000000,"[{'_account_id': 4694}, {'_account_id': 8556}, {'_account_id': 9732}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-14 08:16:43.000000000', 'files': ['neutron/services/trunk/rpc/server.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7a1e79e90b09e5d39d65c4f8da49fcf3af7e2c63', 'message': 'Add retries to update trunk port\n\nIn [1] retry of trunk update was added to avoid StaleDataError\nexceptions to fail to set trunk port or subports to ACTIVE state.\nBut it was only partial fix for the issue descibed in related bug\nand from [2] we know that it still can happen on high load systems\nfrom time to time.\nSo I was checking this issue and reported bug again and I found out\nthat retry was added only in _process_trunk_subport_bindings()\nmethod. But StaleDataError can be raised also in other cases where\nthe same trunk is updated, e.g. in update_trunk_status() method.\n\nSo this commit adds same retry mechanism to all trunk.update() actions\nin services.trunk.rpc.server module.\n\n[1] https://review.opendev.org/#/c/662236/\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=1733197\n\nConflicts:\n    neutron/services/trunk/rpc/server.py\n\nChange-Id: I10e3619d5f3600ea97ed695321bb691dece3181f\nPartial-Bug: #1828375\n(cherry picked from commit ade35a233edb5c9489cc3a68ae00672fb328f63d)\n'}]",0,702366,7a1e79e90b09e5d39d65c4f8da49fcf3af7e2c63,28,7,1,11975,,,0,"Add retries to update trunk port

In [1] retry of trunk update was added to avoid StaleDataError
exceptions to fail to set trunk port or subports to ACTIVE state.
But it was only partial fix for the issue descibed in related bug
and from [2] we know that it still can happen on high load systems
from time to time.
So I was checking this issue and reported bug again and I found out
that retry was added only in _process_trunk_subport_bindings()
method. But StaleDataError can be raised also in other cases where
the same trunk is updated, e.g. in update_trunk_status() method.

So this commit adds same retry mechanism to all trunk.update() actions
in services.trunk.rpc.server module.

[1] https://review.opendev.org/#/c/662236/
[2] https://bugzilla.redhat.com/show_bug.cgi?id=1733197

Conflicts:
    neutron/services/trunk/rpc/server.py

Change-Id: I10e3619d5f3600ea97ed695321bb691dece3181f
Partial-Bug: #1828375
(cherry picked from commit ade35a233edb5c9489cc3a68ae00672fb328f63d)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/66/702366/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/trunk/rpc/server.py'],1,7a1e79e90b09e5d39d65c4f8da49fcf3af7e2c63,bug/1828375-stable/queens," def _safe_update_trunk(self, trunk, **kwargs): trunk.update(**kwargs) def update_trunk_status(self, context, trunk_id, status): """"""Update the trunk status to reflect outcome of data plane wiring."""""" with db_api.autonested_transaction(context.session): trunk = trunk_objects.Trunk.get_object(context, id=trunk_id) if trunk: self._safe_update_trunk(trunk, status=status) def _process_trunk_subport_bindings(self, context, trunk, port_ids): """"""Process port bindings for subports on the given trunk."""""" updated_ports = [] trunk_port_id = trunk.port_id trunk_port = self.core_plugin.get_port(context, trunk_port_id) trunk_host = trunk_port.get(portbindings.HOST_ID) # NOTE(status_police) Set the trunk in BUILD state before # processing subport bindings. The trunk will stay in BUILD # state until an attempt has been made to bind all subports # passed here and the agent acknowledges the operation was # successful. self._safe_update_trunk( trunk, status=trunk_consts.BUILD_STATUS) self._safe_update_trunk( trunk, status=trunk_consts.ERROR_STATUS) self._safe_update_trunk( trunk, status=trunk_consts.DEGRADED_STATUS)"," def update_trunk_status(self, context, trunk_id, status): """"""Update the trunk status to reflect outcome of data plane wiring."""""" with db_api.autonested_transaction(context.session): trunk = trunk_objects.Trunk.get_object(context, id=trunk_id) if trunk: trunk.update(status=status) def _process_trunk_subport_bindings(self, context, trunk, port_ids): """"""Process port bindings for subports on the given trunk."""""" updated_ports = [] trunk_port_id = trunk.port_id trunk_port = self.core_plugin.get_port(context, trunk_port_id) trunk_host = trunk_port.get(portbindings.HOST_ID) # NOTE(status_police) Set the trunk in BUILD state before # processing subport bindings. The trunk will stay in BUILD # state until an attempt has been made to bind all subports # passed here and the agent acknowledges the operation was # successful. trunk.update(status=trunk_consts.BUILD_STATUS) trunk.update(status=trunk_consts.ERROR_STATUS) trunk.update(status=trunk_consts.DEGRADED_STATUS)",28,22
openstack%2Ftripleo-common~stable%2Fstein~Icef88c3ae33fe4516b3cadd64240cc882434e690,openstack/tripleo-common,stable/stein,Icef88c3ae33fe4516b3cadd64240cc882434e690,Clarify introspection failed attempt log message,MERGED,2020-01-27 15:51:00.000000000,2020-01-30 02:56:55.000000000,2020-01-30 02:55:11.000000000,"[{'_account_id': 3153}, {'_account_id': 4571}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2020-01-27 15:51:00.000000000', 'files': ['workbooks/baremetal.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3c0865de9ce5d338e95c2802b7152eb9be17bf42', 'message': 'Clarify introspection failed attempt log message\n\nThis change clarifies that an introspect attempt failed, implying that\na future attempt might succeed.\n\nThis is part of a fix for transient failures when calling\nironic-inspector leading to logging indicating introspection failed\nwhen it actually succeeded.\n\nThe layout of the message is also changed slightly to make Kibana\nsearches for failures easier.\n\nChange-Id: Icef88c3ae33fe4516b3cadd64240cc882434e690\nPartial-Bug: #1854399\n(cherry picked from commit 7e1f2ce788a3d569f24b061f768b87db1e1683bb)\n'}]",0,704341,3c0865de9ce5d338e95c2802b7152eb9be17bf42,9,5,1,21909,,,0,"Clarify introspection failed attempt log message

This change clarifies that an introspect attempt failed, implying that
a future attempt might succeed.

This is part of a fix for transient failures when calling
ironic-inspector leading to logging indicating introspection failed
when it actually succeeded.

The layout of the message is also changed slightly to make Kibana
searches for failures easier.

Change-Id: Icef88c3ae33fe4516b3cadd64240cc882434e690
Partial-Bug: #1854399
(cherry picked from commit 7e1f2ce788a3d569f24b061f768b87db1e1683bb)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/41/704341/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/baremetal.yaml'],1,3c0865de9ce5d338e95c2802b7152eb9be17bf42,bug/1854399-stable/stein," message: <% ""Introspection of node completed:{0}. Status:{1}. Errors:{2}"".format($.introspected_node.uuid, $.status, $.introspected_node.error) %> message: <% ""Introspection of node attempt failed:{0}."".format($.node_uuid) %>"," message: <% ""Introspection of node {0} completed. Status:{1}. Errors:{2}"".format($.introspected_node.uuid, $.status, $.introspected_node.error) %> message: <% ""Introspection of node {0} failed."".format($.node_uuid) %>",2,2
openstack%2Fpython-tripleoclient~stable%2Ftrain~Ic0864c5cd8f5ad196e76b3cea45f95662121a582,openstack/python-tripleoclient,stable/train,Ic0864c5cd8f5ad196e76b3cea45f95662121a582,Enforce 0600 permissions on private SSH key file.,MERGED,2020-01-22 14:48:12.000000000,2020-01-30 02:56:46.000000000,2020-01-30 02:55:10.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2020-01-22 14:48:12.000000000', 'files': ['tripleoclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/bd2a37734010ee89535930fe85faad27661555f5', 'message': 'Enforce 0600 permissions on private SSH key file.\n\nChange-Id: Ic0864c5cd8f5ad196e76b3cea45f95662121a582\nCloses-Bug: #1859244\nSigned-off-by: Luke Short <ekultails@gmail.com>\n(cherry picked from commit 3d06657c90e32c17b6ff7ae0e672e6a2050764fc)\n'}]",0,703808,bd2a37734010ee89535930fe85faad27661555f5,12,5,1,25877,,,0,"Enforce 0600 permissions on private SSH key file.

Change-Id: Ic0864c5cd8f5ad196e76b3cea45f95662121a582
Closes-Bug: #1859244
Signed-off-by: Luke Short <ekultails@gmail.com>
(cherry picked from commit 3d06657c90e32c17b6ff7ae0e672e6a2050764fc)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/08/703808/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/utils.py'],1,bd2a37734010ee89535930fe85faad27661555f5,," os.chmod(key, 0o600)",,1,0
openstack%2Ftripleo-common~stable%2Ftrain~Icef88c3ae33fe4516b3cadd64240cc882434e690,openstack/tripleo-common,stable/train,Icef88c3ae33fe4516b3cadd64240cc882434e690,Clarify introspection failed attempt log message,MERGED,2020-01-27 15:50:37.000000000,2020-01-30 02:56:44.000000000,2020-01-30 02:55:09.000000000,"[{'_account_id': 3153}, {'_account_id': 4571}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2020-01-27 15:50:37.000000000', 'files': ['workbooks/baremetal.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8b1b9dbd20709e225a0d3556e57a79e2f0bc6984', 'message': 'Clarify introspection failed attempt log message\n\nThis change clarifies that an introspect attempt failed, implying that\na future attempt might succeed.\n\nThis is part of a fix for transient failures when calling\nironic-inspector leading to logging indicating introspection failed\nwhen it actually succeeded.\n\nThe layout of the message is also changed slightly to make Kibana\nsearches for failures easier.\n\nChange-Id: Icef88c3ae33fe4516b3cadd64240cc882434e690\nPartial-Bug: #1854399\n(cherry picked from commit 7e1f2ce788a3d569f24b061f768b87db1e1683bb)\n'}]",0,704340,8b1b9dbd20709e225a0d3556e57a79e2f0bc6984,12,6,1,21909,,,0,"Clarify introspection failed attempt log message

This change clarifies that an introspect attempt failed, implying that
a future attempt might succeed.

This is part of a fix for transient failures when calling
ironic-inspector leading to logging indicating introspection failed
when it actually succeeded.

The layout of the message is also changed slightly to make Kibana
searches for failures easier.

Change-Id: Icef88c3ae33fe4516b3cadd64240cc882434e690
Partial-Bug: #1854399
(cherry picked from commit 7e1f2ce788a3d569f24b061f768b87db1e1683bb)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/40/704340/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/baremetal.yaml'],1,8b1b9dbd20709e225a0d3556e57a79e2f0bc6984,bug/1854399-stable/train," message: <% ""Introspection of node completed:{0}. Status:{1}. Errors:{2}"".format($.introspected_node.uuid, $.status, $.introspected_node.error) %> message: <% ""Introspection of node attempt failed:{0}."".format($.node_uuid) %>"," message: <% ""Introspection of node {0} completed. Status:{1}. Errors:{2}"".format($.introspected_node.uuid, $.status, $.introspected_node.error) %> message: <% ""Introspection of node {0} failed."".format($.node_uuid) %>",2,2
openstack%2Ftripleo-ansible~stable%2Ftrain~I92113589b98d7c1f9c05e1ea0938a03d95b7dd15,openstack/tripleo-ansible,stable/train,I92113589b98d7c1f9c05e1ea0938a03d95b7dd15,Add action plugin for all_nodes data,MERGED,2020-01-29 20:37:50.000000000,2020-01-30 02:38:24.000000000,2020-01-30 02:38:23.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-29 20:37:50.000000000', 'files': ['tripleo_ansible/ansible_plugins/action/tripleo_all_nodes_data.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/456425f37a6739a0ef3ee3dcfdc86dda10e51407', 'message': 'Add action plugin for all_nodes data\n\nThis patch adds an action plugin to render the all_nodes group_vars for\nthe overcloud. This plugin will produce the same json structure as the\nall_nodes.j2 template in the tripleo-heiradata role. Once\ndeploy_steps_playbook.yaml is migrated over to use the new action\nplugin, the all_nodes.j2 template can be removed.\n\nAt scale, the template was taking an unusual amount of time to render.\nSwitching to native python with the action plugin results in improved\nperformance. In a 150 node environment, using the action plugin dropped\nthe render time from 7 minutes to 30 seconds.\n\nUsing an action plugin will also allow more easier unit testing (to be\nforthcoming), and also add the opportunity to use debug statements to\nshow errors.\n\nChange-Id: I92113589b98d7c1f9c05e1ea0938a03d95b7dd15\n(cherry picked from commit 918452da7f456d32afa7b3cc000aa28bd96e7bb8)\n'}]",0,704883,456425f37a6739a0ef3ee3dcfdc86dda10e51407,7,3,1,7144,,,0,"Add action plugin for all_nodes data

This patch adds an action plugin to render the all_nodes group_vars for
the overcloud. This plugin will produce the same json structure as the
all_nodes.j2 template in the tripleo-heiradata role. Once
deploy_steps_playbook.yaml is migrated over to use the new action
plugin, the all_nodes.j2 template can be removed.

At scale, the template was taking an unusual amount of time to render.
Switching to native python with the action plugin results in improved
performance. In a 150 node environment, using the action plugin dropped
the render time from 7 minutes to 30 seconds.

Using an action plugin will also allow more easier unit testing (to be
forthcoming), and also add the opportunity to use debug statements to
show errors.

Change-Id: I92113589b98d7c1f9c05e1ea0938a03d95b7dd15
(cherry picked from commit 918452da7f456d32afa7b3cc000aa28bd96e7bb8)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/83/704883/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/ansible_plugins/action/tripleo_all_nodes_data.py'],1,456425f37a6739a0ef3ee3dcfdc86dda10e51407,,"# Copyright 2020 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. DOCUMENTATION = """""" --- module: tripleo_all_nodes_data author: - James Slagle (@slagle) <jslagle@redhat.com> version_added: '2.8' short_description: Renders the all_nodes data for TripleO as group_vars notes: [] description: - This module renders the all_nodes data for TripleO as group_vars which are then available on overcloud nodes. options: forks: description: - The number of forks to spawn in parallel to compute the data for each service. Defaults to the forks set for ansible. required: False """""" EXAMPLES = """""" - name: Render all_nodes data tripleo_all_nodes_data: """""" import json from multiprocessing import Manager, Process import os import traceback from ansible.errors import AnsibleError from ansible.plugins.action import ActionBase from ansible.plugins.filter import ipaddr from ansible.utils.display import Display DISPLAY = Display() class ActionModule(ActionBase): """"""Renders the all_nodes data for TripleO as group_vars"""""" def compute_service(self, service, all_nodes): DISPLAY.vv(""Processing {}"".format(service)) # <service>_enabled: true all_nodes[service + '_enabled'] = True # <service>_node_ips: <list of ips> DISPLAY.vv("" Computing data for {}_node_ips"".format(service)) service_network = self.service_net_map.get( service + '_network', 'ctlplane') service_hosts = self.groups.get(service, []) service_node_ips = list( map(lambda host: self.h_vars[host][service_network + '_ip'], service_hosts)) for extra_node_ip in self.all_nodes_extra_map_data.get( service + '_node_ips', []): if extra_node_ip not in service_node_ips: service_node_ips.append(extra_node_ip) all_nodes[service + '_node_ips'] = service_node_ips if self.nova_additional_cell: # <service>_cell_node_names: <list of hostnames> v = service_network + '_hostname' service_cell_node_names = \ list(map(lambda host: self.h_vars[host][v], service_hosts)) all_nodes[service + '_cell_node_names'] = \ service_cell_node_names else: # <service>_node_names: <list of hostnames> DISPLAY.vv("" Computing data for {}_node_names"".format(service)) v = service_network + '_hostname' service_node_names = \ list(map(lambda host: self.h_vars[host][v], service_hosts)) for extra_node_name in self.all_nodes_extra_map_data.get( service + '_node_names', []): if extra_node_name not in service_node_names: service_node_names.append(extra_node_name) all_nodes[service + '_node_names'] = service_node_names # <service>_short_node_names: <list of hostnames> DISPLAY.vv("" Computing data for {}_short_node_names"".format(service)) service_short_node_names = \ list(map(lambda host: self.h_vars[host]['inventory_hostname'], service_hosts)) for extra_short_node_name in self.all_nodes_extra_map_data.get( service + '_short_node_names', []): if extra_short_node_name not in service_node_names: service_short_node_names.append(extra_short_node_name) all_nodes[service + '_short_node_names'] = \ service_short_node_names # <service>_short_bootstrap_node_name: hostname DISPLAY.vv("" Computing data for {}_short_bootstrap_node_name"".format(service)) if self.all_nodes_extra_map_data.get( service + '_short_bootstrap_node_name', None): v = service + '_short_bootstrap_node_name' service_hosts += self.all_nodes_extra_map_data[v] service_hosts.sort() if service_hosts: all_nodes[service + '_short_bootstrap_node_name'] = \ service_hosts[0] # <service>_bootstrap_node_ip: hostname DISPLAY.vv("" Computing data for {}_short_bootstrap_node_ip"".format(service)) if self.all_nodes_extra_map_data.get( service + '_bootstrap_node_ip', None): v = service + '_bootstrap_node_ip' service_bootstrap_node_ips = \ service_node_ips + self.all_nodes_extra_map_data[v] else: service_bootstrap_node_ips = service_node_ips if service_bootstrap_node_ips: all_nodes[service + '_bootstrap_node_ip'] = \ service_bootstrap_node_ips[0] def process_services(self, enabled_services, all_nodes, forks): # This breaks up the enabled_services list into smaller lists with # length equal to the number of forks. enabled_services_length = len(enabled_services) for i in range(0, enabled_services_length, forks): # It would be nice to be able to use multiprocessing.Pool here, # however, that resulted in many pickle errors. # For each smaller list, spawn a process to compute each service in # that chunk. end = i + forks if end > enabled_services_length: end = enabled_services_length processes = [Process(target=self.compute_service, args=(enabled_services[x], all_nodes)) for x in range(i, end)] [p.start() for p in processes] [p.join() for p in processes] [p.terminate() for p in processes] def compute_all_nodes(self, all_nodes, task_vars): DISPLAY.vv(""Starting compute and render for all_nodes data"") # Internal Ansible objects for inventory and variables inventory = self._task.get_variable_manager()._inventory self.groups = inventory.get_groups_dict() # host_vars self.h_vars = self._task.get_variable_manager().get_vars()['hostvars'] # Needed tripleo variables for convenience self.service_net_map = task_vars['service_net_map'] self.nova_additional_cell = task_vars['nova_additional_cell'] self.all_nodes_extra_map_data = task_vars['all_nodes_extra_map_data'] net_vip_map = task_vars['net_vip_map'] enabled_services = task_vars['enabled_services'] primary_role_name = task_vars['primary_role_name'] enabled_services += self.all_nodes_extra_map_data.get( 'enabled_services', []) # make enabled_services unique enabled_services = list(set(enabled_services)) all_nodes['enabled_services'] = enabled_services forks = self._task.args.get('forks', task_vars['ansible_forks']) DISPLAY.vv(""forks set to {}"".format(forks)) self.process_services(enabled_services, all_nodes, forks) # <service>: service_network DISPLAY.vv(""Computing data for service_net_map"") for key, value in self.service_net_map.items(): all_nodes[key] = value # all values from all_nodes_extra_map_data when nova_additional_cell if self.nova_additional_cell: for key, value in self.all_nodes_extra_map_data.items(): all_nodes[key] = value # redis_vip: ip DISPLAY.vv(""Computing data for redis_vip"") if 'redis' in enabled_services or self.nova_additional_cell: if 'redis_vip' in self.all_nodes_extra_map_data: all_nodes['redis_vip'] = self.all_nodes_extra_map_data['redis_vip'] elif 'redis' in net_vip_map: all_nodes['redis_vip'] = net_vip_map['redis'] # ovn_dbs_vip: ip DISPLAY.vv(""Computing data for ovn_dbs_vip"") if 'ovn_dbs' in enabled_services or self.nova_additional_cell: if 'ovn_dbs_vip' in self.all_nodes_extra_map_data: all_nodes['ovn_dbs_vip'] = \ self.all_nodes_extra_map_data['ovn_dbs_vip'] elif 'ovn_dbs' in net_vip_map: all_nodes['ovn_dbs_vip'] = net_vip_map['ovn_dbs'] DISPLAY.vv(""Computing data for top level vars"") all_nodes['deploy_identifier'] = task_vars['deploy_identifier'] all_nodes['stack_action'] = task_vars['stack_action'] all_nodes['stack_update_type'] = task_vars['stack_update_type'] all_nodes['container_cli'] = task_vars['container_cli'] # controller_node_<ips/names> # note that these are supposed to be strings, not lists DISPLAY.vv(""Computing data for controller node ips/names"") primary_hosts = self.groups.get(primary_role_name, []) all_nodes['controller_node_ips'] = \ ','.join(list(map(lambda host: self.h_vars[host]['ctlplane_ip'], primary_hosts))) all_nodes['controller_node_names'] = \ ','.join(list(map(lambda host: self.h_vars[host]['inventory_hostname'], primary_hosts))) DISPLAY.vv(""Done"") def run(self, tmp=None, task_vars=None): """"""Renders the all_nodes data for TripleO as group_vars"""""" manager = Manager() all_nodes = manager.dict() try: self.compute_all_nodes(all_nodes, task_vars) all_nodes = dict(all_nodes) all_nodes_path = os.path.join(task_vars['playbook_dir'], 'group_vars', 'overcloud.json') with open(all_nodes_path, 'w') as f: DISPLAY.vv(""Rendering all_nodes to {}"".format(all_nodes_path)) json.dump(all_nodes, f, sort_keys=True, indent=4) except Exception as e: DISPLAY.error(traceback.format_exc()) raise AnsibleError(str(e)) finally: manager.shutdown() # multiprocessing can hang the plugin exit if there are still # references to the Manager() object. Even though we have called # .shutdown(), clean up all_nodes just to be safe. all_nodes = None DISPLAY.vv(""returning"") return dict(all_nodes=all_nodes) ",,253,0
openstack%2Ftripleo-ansible~master~I688541e5817075f779898a1aedea9daa57a63414,openstack/tripleo-ansible,master,I688541e5817075f779898a1aedea9daa57a63414,Update molecule test jobs for new role name,MERGED,2020-01-29 19:30:24.000000000,2020-01-30 02:38:24.000000000,2020-01-30 02:38:24.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2020-01-29 19:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/6f7da254bf0f5e06cb7547c95f20a412ec12eb53', 'message': ""Update molecule test jobs for new role name\n\nThis change updates all of the molecule test jobs to ensure that all of the\nnew role names are no longer using the hyphen'd names, which are currently\nsymlinks.\n\nChange-Id: I688541e5817075f779898a1aedea9daa57a63414\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 2, 'created': '2020-01-29 19:32:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/a506375508ec5bc96a8dc4fd2a200c0a57eb81bb', 'message': ""Update molecule test jobs for new role name\n\nThis change updates all of the molecule test jobs to ensure that all of the\nnew role names are no longer using the hyphen'd names, which are currently\nsymlinks.\n\nChange-Id: I688541e5817075f779898a1aedea9daa57a63414\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 3, 'created': '2020-01-29 19:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/339da562862893762695458cbc424a0acec2afac', 'message': ""Update molecule test jobs for new role name\n\nThis change updates all of the molecule test jobs to ensure that all of the\nnew role names are no longer using the hyphen'd names, which are currently\nsymlinks.\n\nChange-Id: I688541e5817075f779898a1aedea9daa57a63414\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 4, 'created': '2020-01-29 19:45:51.000000000', 'files': ['zuul.d/molecule.yaml', 'zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/801ee3b4c9e0ccaee265c5ea0f4cb3188d09b9e7', 'message': ""Update molecule test jobs for new role name\n\nThis change updates all of the molecule test jobs to ensure that all of the\nnew role names are no longer using the hyphen'd names, which are currently\nsymlinks.\n\nChange-Id: I688541e5817075f779898a1aedea9daa57a63414\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}]",5,704875,801ee3b4c9e0ccaee265c5ea0f4cb3188d09b9e7,15,5,4,7353,,,0,"Update molecule test jobs for new role name

This change updates all of the molecule test jobs to ensure that all of the
new role names are no longer using the hyphen'd names, which are currently
symlinks.

Change-Id: I688541e5817075f779898a1aedea9daa57a63414
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/75/704875/2 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/molecule.yaml', 'zuul.d/layout.yaml']",2,6f7da254bf0f5e06cb7547c95f20a412ec12eb53,, - ^tripleo_ansible/roles/tripleo_ceph_**/.* - ^tripleo_ansible/roles/tripleo_hieradata/.* - ^tripleo_ansible/roles/tripleo_upgrade_hiera/.* - ^tripleo_ansible/roles/tripleo_hieradata/.* - ^tripleo_ansible/roles/tripleo_upgrade_hiera/.* - ^tripleo_ansible/roles/tripleo_create_admin/.* - ^tripleo_ansible/roles/tripleo_hieradata/.* - ^tripleo_ansible/roles/tripleo_upgrade_hiera/.* - ^tripleo_ansible/roles/tripleo_ceph_**/.* - ^tripleo_ansible/roles/tripleo_hieradata/.* - ^tripleo_ansible/roles/tripleo_upgrade_hiera/.*, - ^tripleo_ansible/roles/tripleo-ceph-*/.* - ^tripleo_ansible/roles/tripleo-hieradata/.* - ^tripleo_ansible/roles/tripleo-upgrade-hiera/.* - ^tripleo_ansible/roles/tripleo-hieradata/.* - ^tripleo_ansible/roles/tripleo-upgrade-hiera/.* - ^tripleo_ansible/roles/tripleo-create-admin/.* - ^tripleo_ansible/roles/tripleo-hieradata/.* - ^tripleo_ansible/roles/tripleo-upgrade-hiera/.* - ^tripleo_ansible/roles/tripleo-ceph-*/.* - ^tripleo_ansible/roles/tripleo-hieradata/.* - ^tripleo_ansible/roles/tripleo-upgrade-hiera/.*,186,186
openstack%2Fneutron~master~I5f00cb5432c397fb2a8a4921df3e162df6e1aff7,openstack/neutron,master,I5f00cb5432c397fb2a8a4921df3e162df6e1aff7,"Add ""ovn"" as official tag used on Neutron's Launchpad",MERGED,2020-01-28 15:25:09.000000000,2020-01-30 02:31:46.000000000,2020-01-30 02:29:33.000000000,"[{'_account_id': 4694}, {'_account_id': 6773}, {'_account_id': 8655}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-28 15:25:09.000000000', 'files': ['doc/source/contributor/policies/bugs.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6ff46fb44b9999cad99f2a76eaaccfc20e03f60b', 'message': 'Add ""ovn"" as official tag used on Neutron\'s Launchpad\n\nIt also adds Lucas and Jakub as people to contact for OVN related bugs.\n\nChange-Id: I5f00cb5432c397fb2a8a4921df3e162df6e1aff7\nRelated-Blueprint: neutron-ovn-merge\n'}]",0,704591,6ff46fb44b9999cad99f2a76eaaccfc20e03f60b,12,7,1,11975,,,0,"Add ""ovn"" as official tag used on Neutron's Launchpad

It also adds Lucas and Jakub as people to contact for OVN related bugs.

Change-Id: I5f00cb5432c397fb2a8a4921df3e162df6e1aff7
Related-Blueprint: neutron-ovn-merge
",git fetch https://review.opendev.org/openstack/neutron refs/changes/91/704591/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/policies/bugs.rst'],1,6ff46fb44b9999cad99f2a76eaaccfc20e03f60b,bp/neutron-ovn-merge,| ovn_ | A bug affecting ML2/OVN | Jakub Libosvar/ | | | | Lucas Alvares Gomes | +-------------------------------+-----------------------------------------+--------------------------+.. _ovn: OVN +++ * `OVN - All bugs <https://bugs.launchpad.net/neutron/+bugs?field.tag=ovn>`_ * `OVN - In progress <https://bugs.launchpad.net/neutron/+bugs?field.status%3Alist=INPROGRESS&field.tag=ovn>`_ ,,11,0
openstack%2Fcinder~master~Ic57c1562617da849ada82cefb0acb30f07eee690,openstack/cinder,master,Ic57c1562617da849ada82cefb0acb30f07eee690,Refactor README links,MERGED,2019-09-02 05:29:58.000000000,2020-01-30 02:28:03.000000000,2020-01-22 11:44:36.000000000,"[{'_account_id': 5997}, {'_account_id': 9732}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25678}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}, {'_account_id': 30688}]","[{'number': 1, 'created': '2019-09-02 05:29:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d13e26b867205e70464d4f26857866d3eebc74ba', 'message': 'Refactor README links\n\nChange-Id: Ic57c1562617da849ada82cefb0acb30f07eee690\n'}, {'number': 2, 'created': '2020-01-21 06:36:41.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/90927c495f2ba6395bc890dafdd7f308846f80cf', 'message': 'Refactor README links\n\nChange-Id: Ic57c1562617da849ada82cefb0acb30f07eee690\n'}]",2,679594,90927c495f2ba6395bc890dafdd7f308846f80cf,46,28,2,27615,,,0,"Refactor README links

Change-Id: Ic57c1562617da849ada82cefb0acb30f07eee690
",git fetch https://review.opendev.org/openstack/cinder refs/changes/94/679594/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,d13e26b867205e70464d4f26857866d3eebc74ba,cinder_specs_link,* `Wiki <https://wiki.openstack.org/Cinder/>`__ * `Developer Docs <https://docs.openstack.org/cinder/latest/>`__ * `Blueprints <https://blueprints.launchpad.net/cinder/>`__ * `Release notes <https://docs.openstack.org/releasenotes/cinder/>`__ * `Design specifications <https://specs.openstack.org/openstack/cinder-specs/>`__You can raise bugs here `Launchpad <https://bugs.launchpad.net/cinder>`__`Python Cinderclient <https://opendev.org/openstack/python-cinderclient>`__,* Wiki: https://wiki.openstack.org/Cinder * Developer docs: https://docs.openstack.org/cinder/latest/ * Blueprints: https://blueprints.launchpad.net/cinder * Release notes: https://docs.openstack.org/releasenotes/cinder/ * Design specifications: https://specs.openstack.org/openstack/cinder-specs/You can raise bugs here https://bugs.launchpad.net/cinderhttps://opendev.org/openstack/python-cinderclient,7,7
openstack%2Ftripleo-specs~master~I9274dc4384fa4589f874f39379876afab158b0f3,openstack/tripleo-specs,master,I9274dc4384fa4589f874f39379876afab158b0f3,Global Galera Database,ABANDONED,2018-09-06 21:21:48.000000000,2020-01-30 01:40:42.000000000,,"[{'_account_id': 2218}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 10873}, {'_account_id': 11816}, {'_account_id': 12314}, {'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23811}]","[{'number': 1, 'created': '2018-09-06 21:21:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/8c8e195139064e6a8db66b087eba12a431c8feff', 'message': 'Global Galera Database\n\nSupport deploying a second Galera database to the overcloud which shares\nnodes with other overclouds.\n\nChange-Id: I9274dc4384fa4589f874f39379876afab158b0f3\n'}, {'number': 2, 'created': '2018-09-24 19:13:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/60d5d2237fc96de94a0a73e5f4d873731f11a4de', 'message': 'Global Galera Database\n\nSupport deploying a second Galera database to the overcloud which shares\nnodes with other overclouds.\n\nChange-Id: I9274dc4384fa4589f874f39379876afab158b0f3\n'}, {'number': 3, 'created': '2018-09-26 18:29:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/7d523dd43159a6c4e7a6da62e6a49e407daf1043', 'message': 'Global Galera Database\n\nSupport deploying a second Galera database to the overcloud which shares\nnodes with other overclouds.\n\nChange-Id: I9274dc4384fa4589f874f39379876afab158b0f3\n'}, {'number': 4, 'created': '2018-10-11 15:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/b4cd902beab374dc9af72a379ec3c963e6d76a0c', 'message': 'Global Galera Database\n\nSupport deploying a second Galera database to the overcloud which shares\nnodes with other overclouds.\n\nImplements: blueprint global-database\nChange-Id: I9274dc4384fa4589f874f39379876afab158b0f3\n'}, {'number': 5, 'created': '2018-11-02 17:21:05.000000000', 'files': ['specs/stein/global-database.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/ea3245145561fbee2ed4ecdfbb761f8e56e33b79', 'message': 'Global Galera Database\n\nSupport deploying a second Galera database to the overcloud which shares\nnodes with other overclouds.\n\nImplements: blueprint global-database\nChange-Id: I9274dc4384fa4589f874f39379876afab158b0f3\n'}]",41,600555,ea3245145561fbee2ed4ecdfbb761f8e56e33b79,54,11,5,11816,,,0,"Global Galera Database

Support deploying a second Galera database to the overcloud which shares
nodes with other overclouds.

Implements: blueprint global-database
Change-Id: I9274dc4384fa4589f874f39379876afab158b0f3
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/55/600555/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/stein/global-database.rst'],1,8c8e195139064e6a8db66b087eba12a431c8feff,global_database,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================= Global Galera Database ======================= https://blueprints.launchpad.net/tripleo/+spec/global-database Support deploying a second Galera database to the overcloud which shares nodes with other overclouds. Problem Description =================== Certain Openstack services, most prominently Keystone with region support, can benefit from being able to share database state with that of other overclouds, the so called ""shared database"" strategy of producing a multi-site configuration. A multi-node Galera database can coordinate its state with that of remote nodes from other overclouds, however TripleO does not support this yet. Proposed Change =============== Overview -------- TripleO's directives to install and configure a Galera database will be enhanced to support the installation and configuration of a second Galera database per controller, referred to as the ""global"" database. The existing Galera database will be referred to as the ""local"" database. The ""global"" database acts identically in all ways to the ""local"" database, except that its Galera cluster address includes additional node addresses, corresponding to Galera nodes installed by other TripleO installers. The phase where TripleO configures Galera to be managed and bootstrapped under Pacemaker will be altered for the ""global"" database to use an enhanced version of the Galera resource agent [1] which can accommodate bootstrapping or joining an existing cluster in coordination with other Pacemaker instances. An individual Pacemaker cluster can run its immediate ""global"" Galera nodes and consider them to be in ""master"" state without all other remote Galera nodes necessarily being online as of yet (Galera itself has no issue with this). When the ""global"" database nodes are installed, any number of Openstack database-driven services will include configuration options so that they target the ""global"" database as the destination for their tables and data, rather than the ""local"" database. As database manage commands are idempotent, whether or not the schema structure for a given database already exists should allow the initial database setup steps to proceed successfully. For upgrades, the approach will rely upon N+1 rolling schema upgrade capability that is present within the existing openstack services intended for this (Keystone; not sure if Glance supports rolling DB upgrades however). Global Galera Database ---------------------- For the initial deployment of a particular overcloud, the existing overcloud is built out in a manner virtually identical to how it is today. The one difference from a stock overcloud is that a second Galera service will be deployed on the overcloud, referred to as the ""global"" galera cluster. This second Galera service, like the primary ""local"" Galera service, consists of multiple Galera nodes running on controllers. The communication channel for these nodes however is not on the ""internalapi"" network, and is instead on a network that can be routed to the other overclouds, such as the ""external"" network, or perhaps a new network added to TripleO's existing set of configured networks. The ""global"" Galera service will be provided with an accompanying VIP managed by Pacemaker as well as a new service configuration in HAProxy. Services that are configured to use the ""global"" database are directed to connect to this new galera cluster using the new VIP/HAProxy configuration. Global Galera Runs as Multi-Master ----------------------------------- One implication of having a large Galera cluster stretched across multiple overclouds is that the services which use this database will likely be communicating with multiple Galera nodes simultaneously, using Galera's normal ""multi-master"" capability. In TripleO, we have for a long time configured HAProxy for Galera in such a way that Openstack services route all of their database traffic to exactly one Galera node at a time, while the other nodes (usually two out of a three-controller setup) remain inactive essentially as hot standbys. The rationale for this was based on the fact that legacy Openstack services made use of MySQL features that did not scale well across Galera nodes, namely the use of ""SELECT..FOR UPDATE"", a pessismistic locking directive that is unsupported by Galera. When a lock set up in this way would fail to promote a writeset (e.g. data from a transaction) to other Galera nodes, the transaction would fail with an error, and the corresponding Openstack service often did not have a robust retry mechanism in order to accomodate this smoothly, and even if it did, it still raised the issue of performance degradation. In modern Openstack, the use of ""SELECT..FOR UPDATE"" is gone, and services now feature mature and robust retry mechanisms for the case where two conflicting Galera writesets produce a losing transaction. Additionally, for the intended service of Keystone, now that Keystone uses Fernet tokens, it has an extremely low rate of writes, and as it uses extensive caching it also has a low read rate as well. It is not anticipated that either using Galera in true multi-master state, or the fact that writesets need to be transmitted to significantly more Galera nodes which are remote, will produce any performance issue for such a service. Note that Galera does not introduce any additional latency vs. plain vanilla MySQL for read operations, only for writes, regardless of the number of nodes in use. ""Global"" Galera Resource Agent ------------------------------- When the multi-overcloud environment runs, the only service that has any ongoing knowledge of other overcloud nodes is Galera itself, as well as the Pacemaker resource agent that is used for Galera. A modified resource agent is proposed at [1] which allows Galera nodes spread among multiple overclouds/Pacemaker clusters to participate within a single Galera cluster across all of them. Each overcloud continues to run its own HA/Pacemaker cluster that is fully local to that overcloud. In order to achieve the effect of a set of Galera nodes that can communicate with Galera nodes in other environments, while still maintaining individual per-overcloud Pacemaker/HA management, the Pacemaker/Galera resource agent will be modified such that when it seeks to bootstrap the cluster and locate all participating nodes, an additional map of ""remote"" Galera nodes is passed into its configuration, which are known to be managed by other Pacemaker clusters. To understand how this is possible, note that the modern version of the Galera resource agent tracks everything it needs to know about other Galera nodes using pacemaker attribute and status commands. To the extent that it runs ""mysql"" commands directly, these are run only against the local MySQL instance which corresponds to that resource agent, running alongside it within the same container. The job of the Galera resource agent is then to start and stop this MySQL instance, while communicating to the parent Pacemaker process the status of the node. The only complexity to this is that when it starts the MySQL process, it needs to know whether or not a cluster is already formed, and if not, if its local node will receive the ``--wsrep-new- cluster`` flag or not, which indicates whether or not this node is the ""bootstrap"" node of the Galera cluster. To the extent that the Galera resource agent is more complicated than a simple start/stop script, it has literally just ""one job"", to figure out if that flag should be set, or not. The current Galera resource agent publishes information about its own MySQL service using pacemaker attribute commands for its local Pacemaker service. It learns about other nodes only by inspecting these attributes using those same commands. The commands used are the ""crm_attribute"", ""crm_mon"" and ""crm_master"" commands. In order to allow the resource agent to coordinate with Galera nodes in other overclouds, the initial proof of concept uses ssh to run the same commands remotely on other clusters, but it only runs read-only commands (note that ssh is not strictly required; a simple read-only xinetd service can be used as well). The resource agent will then start its local nodes using the additional information of a possible bootstrap node of a remote cluster as part of its decision whether or not it needs to set the bootstrap flag locally. This architecture takes advantage of the relatively simplistic nature of the Galera resource agent, as well as Pacemaker, in that Pacemaker has no knowledge, given an individual Galera node, of what kinds of dependencies that Galera node has upon any other node or service - only the resource agent cares about this detail. To the extent the resource agent cares about this, it only cares to know which node is a good choice to be the initial ""bootstrap"" node, when Galera first starts up. If the resource agent can decide that there is already a bootstrap node remote to the local Pacemaker cluster, it simply starts up its local Galera nodes without specifying any of them as the bootstrap. Deploy One Overcloud at a Time ------------------------------ The TripleO deployment process will remain oriented towards deploying one Overcloud at a time, using individual underclouds for each overcloud. This allows both for little to no architectural changes in Tripleo, as well as allowing operators to continue to deploy individual overclouds within deployment phases mostly independent of each other. The initial assumption for this feature is that the Overclouds are to be deployed as ""global""-enabled with specific services targeted to the ""global"" database at initial deployment time, although it is not necessary that this ""global"" database is already running; TripleO will be able to initiate the ""global"" database from scratch. There are also strategies by which an existing local-only TripleO overcloud can be migrated to make use of a ""global"" database, however that is outside of the scope of this blueprint for now. Configuration ------------- The level of operator-level configuration in order to deploy a ""global"" database is expected to consist of: * Directives stating that a ""global"" database is in fact to be present, which will be installed at the software and configurational level in the identical manner in which the ""local"" database currently is set up. * Directives which list out the network hostnames of additional Galera nodes from other overclouds, which may or may not be online as of yet, which will become part of the ""wsrep_cluster_address"" of the global Galera cluster. * Directives which state which Openstack services should participate within the ""global"" database, rather than the ""local"" one, for example Keystone and Glance. * A directive which states if this particular TripleO environment is the ""first"" one to be installed, which will serve as a hint to the resource agent that it should be able to bootstrap the Galera cluster without the other overcloud nodes present. In the ideal case, a TripleO installer should be able to deploy as part of a larger ""global"" Galera cluster whether or not other participating clusters are already present, and should not require any configurational changes going forward other overclouds that are to be deployed subsequently are online. Meaning, supposing an operator is to install three overclouds amongst a total of nine controller machines, and there are to be nine Galera nodes within the ""global"" database. The set of all nine hostnames should be known up front and configured as given within each TripleO environment. The first overcloud to deploy should be able to bootstrap its local three Galera nodes without waiting for the other six to be available. A special flag in the TripleO configuration will indicate that the resource agent should bootstrap these Galera nodes as though they are the only nodes present (however, the Galera nodes themselves can still be configured with the full list of nine hostnames). When that overcloud is up and running, the second overcloud can then install in the same manner; when its global database is started, its Pacemaker resource agent will detect that a Galera cluster is already bootstrapped, and its three nodes will start and join the cluster normally. Then the same process is repeated for the last overcloud. Alternatively, the operator could in theory deploy all three overclouds from each individual undercloud in any sequence, and each installer could reach the point at which global Galera is to be bootstrapped at which point they would wait for all other Galera nodes to be available. While this scenario is interesting, it's not clear that it would actually be practical as it requires two or more independently deploying overclouds to be running within roughly similar timeframes, which may not be generally feasible. Upgrades -------- The approach for upgrades is intended to make use of the N+1 rolling upgrade feature that is becoming common within Openstack services, including Keystone. For review, the architecture of rolling upgrades includes that the database is migrated in two distinct phases, the ""expand"" and ""contract"" phases. In ""expand"", new schema elements are added to the database, such as new columns and tables. The consuming application is capable in some way of communicating with this expanded database in terms of the non-expanded schema, as it has not yet been upgraded. Then the consuming application can be upgraded to the new version, one Python process at a time, where they each move from communicating with the expanded database in terms of the non-expanded version, to the expanded version, meaning they start reading and writing with the new columns and tables and no longer using the legacy structures. Then in ""contract"", after the legacy structures are no longer in use, they can be dropped, typically as the first stage of the *next* version. In order for the database to be compatible with two versions of the application simultaneously during ""expand"", either the application itself is written in some agnostic way of communicating with each (e.g. Nova) or database triggers are used to synchronize amongst the two versions (e.g. Keystone). Keystone's architecture here is described at [2]. Taking advantage of online database upgrades, the process for upgrading multiple coordinating overclouds looks very much like that of upgrading an individual overcloud. An upgrade for a three-overcloud environment where Keystone is using the global database would look like: 1. All overclouds are up-to-date at version S. The previous version would have been ""R"". 2. Operator runs upgrade on overcloud 1 from S to T. 3. The upgrade may want to begin by running ""keystone-manage db_sync --contract"" to remove database structures that correspond to the previous version, if present, in this case ""R"". Or alternatively it may require that the operator has manually run ""--contract"" at least once since the last upgrade. 4. overcloud 1's keystone updater runs database manage on the ""global"" database, using ""keystone-manage db_sync --expand"" so that it makes use of online upgrades. This modifies its database schema to suit the transition between S and T and installs triggers which will coordinate data writes between the S and T versions of the schema. The updater can then run ""keystone-manage db_sync --migrate"" to perform data migrations so that initial data is populated into the ""T"" version of the schema. 5. The keystone services on each of overcloud 1, 2, and 3 continue to communicate with the database normally, talking to it in terms of the ""S"" version of the schema. As data is written by these processes in terms of ""S"", it is automatically copied by the triggers to suit the ""T"" version of the schema. 6. overcloud 1's keystone services are upgraded, which now communicate with the database in terms of the ""T"" schema. Data written in terms of ""T"" is automatically copied by the triggers to suit the ""S"" version of the schema. 7. At the same time, overclouds 2 and 3 continue to communicate with that same schema, however they communicate with it in terms of the ""S"" schema as they are still software version ""S"". 8. The operator then runs upgrades on overcloud 2 and 3 so that all consuming services now communicate with the database in terms of ""T"". 9. Elements of the database that correspond only to ""S"" are now obsolete, and can be removed at any time running ""keystone-manage db_sync --contract"" just once on any individual controller. Alternatives ------------ An alternative to using a common database instance across services is to build services that themselves know how to replicate to each other, such as, Keystone services which can communicate, merge, and resolve conflicts for new changes with other remote Keystone services at the API level (Keystone-to-Keystone Federation). Security Impact --------------- * security of the network in which the galera nodes are ""stretched"", Galera can use SSL + SSL rsync replication * issues of passwords shared across overclouds in Keystone Other End User Impact --------------------- Only Operators will do this. Performance Impact ------------------ Minimal performance impact is expected as the Galera database is available locally as it was before. Other Deployer Impact --------------------- Developer Impact ---------------- Discuss things that will affect other developers working on OpenStack. Implementation ============== Assignee(s) ----------- Primary assignee: zzzeek - Mike Bayer Other contributors: <launchpad-id or None> Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ The modified Pacemaker resource agent in [1]. This resource agent would be merged into ClusterLabs upstream and be part of the Pacemaker install deployed within Galera containers as well as on controllers. Participating services must support rolling database upgrades. Testing ======= Please discuss how the change will be tested. Is this untestable in CI given current limitations (specific hardware / software configurations available)? If so, are there mitigation plans (3rd party testing, gate enhancements, etc). Documentation Impact ==================== What is the impact on the docs? Don't repeat details discussed above, but please reference them here. References ========== [1] Proposed Pacemaker resource agent: https://github.com/ClusterLabs/resource-agents/pull/1141 [2] Keystone's N+1 upgrades: https://docs.openstack.org/keystone/pike/admin/identity-upgrading.html#upgrading-without-downtime [3] A fully working proof of concept: this POC uses Ansible and Infrared to deploy ten virtual hosts with two underclouds to allow for two overclouds, then patches TripleO to deploy a second Galera database using the above modified resource agent and point Keystone towards this new database. It currently deploys the ""global"" databases independently and then merges them together in a second step, using SQL scripts to merge the two Keystone databases together. https://github.com/zzzeek/stretch_cluster ",,412,0
openstack%2Fswift~master~Ifd9fbac032825bae1c8f5edd88c5d692a0b2cef1,openstack/swift,master,Ifd9fbac032825bae1c8f5edd88c5d692a0b2cef1,Bump up ceph tests timeout,MERGED,2020-01-22 17:44:44.000000000,2020-01-30 01:14:45.000000000,2020-01-30 01:11:38.000000000,"[{'_account_id': 7233}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-22 17:44:44.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/swift/commit/cd78ee983d0ae0cebdb27327b6ea7950308d0dbf', 'message': ""Bump up ceph tests timeout\n\nLooking at the last few hundred runs, we've had ~8% TIMEOUTs, and the\naverage time is already 21 minutes. Let's give it an extra 10 minutes,\nsee if the TIMEOUT rate comes down.\n\nChange-Id: Ifd9fbac032825bae1c8f5edd88c5d692a0b2cef1\n""}]",2,703848,cd78ee983d0ae0cebdb27327b6ea7950308d0dbf,16,3,1,15343,,,0,"Bump up ceph tests timeout

Looking at the last few hundred runs, we've had ~8% TIMEOUTs, and the
average time is already 21 minutes. Let's give it an extra 10 minutes,
see if the TIMEOUT rate comes down.

Change-Id: Ifd9fbac032825bae1c8f5edd88c5d692a0b2cef1
",git fetch https://review.opendev.org/openstack/swift refs/changes/48/703848/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,cd78ee983d0ae0cebdb27327b6ea7950308d0dbf,, timeout: 2400,,1,0
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I466afb53bee498c6f265ecf613fe34a736c6b92e,openstack/tripleo-heat-templates,stable/train,I466afb53bee498c6f265ecf613fe34a736c6b92e,Raise Heat API WSGI timeout to 600s,ABANDONED,2020-01-29 20:29:29.000000000,2020-01-30 00:39:20.000000000,,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-29 20:29:29.000000000', 'files': ['deployment/heat/heat-base-puppet.yaml', 'releasenotes/notes/heat-api-wsgi-timeout-600-640058f1ae18232c.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0e7d706de9e6ba5532336ecd560b550e7d5a4b72', 'message': ""Raise Heat API WSGI timeout to 600s\n\nThe HAProxy and Heat's rpc_response_timeout are already set to 10\nminutes, so the WSGI timeout should be as well. Otherwise, raising the\nother timeouts doesn't really do any good.\n\nSome requests to the Heat API when running config-download can take\nlonger than 60 seconds, particularly at scale (> 100 nodes).\n\nChange-Id: I466afb53bee498c6f265ecf613fe34a736c6b92e\nCloses-Bug: #1860475\n(cherry picked from commit acf208609e85fd87c76403b15884de385e9766d7)\n""}]",0,704881,0e7d706de9e6ba5532336ecd560b550e7d5a4b72,7,3,1,7144,,,0,"Raise Heat API WSGI timeout to 600s

The HAProxy and Heat's rpc_response_timeout are already set to 10
minutes, so the WSGI timeout should be as well. Otherwise, raising the
other timeouts doesn't really do any good.

Some requests to the Heat API when running config-download can take
longer than 60 seconds, particularly at scale (> 100 nodes).

Change-Id: I466afb53bee498c6f265ecf613fe34a736c6b92e
Closes-Bug: #1860475
(cherry picked from commit acf208609e85fd87c76403b15884de385e9766d7)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/81/704881/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/heat/heat-base-puppet.yaml', 'releasenotes/notes/heat-api-wsgi-timeout-600-640058f1ae18232c.yaml']",2,0e7d706de9e6ba5532336ecd560b550e7d5a4b72,,"--- fixes: - The WSGI timeout for Heat API is now set to 600 seconds to match the HAProxy timeout and the RPC response timeout. Previously, it was set to 60 seconds, which resulted in API requests timing out. ",,6,0
openstack%2Fbifrost~stable%2Ftrain~I5aaab91f0590c49972e5eb03d1c70559698b2f39,openstack/bifrost,stable/train,I5aaab91f0590c49972e5eb03d1c70559698b2f39,Check out global requirements when creating test VMs,MERGED,2020-01-29 14:44:35.000000000,2020-01-30 00:15:25.000000000,2020-01-30 00:13:59.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 14:44:35.000000000', 'files': ['playbooks/roles/bifrost-create-vm-nodes/tasks/main.yml', 'playbooks/roles/bifrost-create-vm-nodes/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/a418620c57e068c1edbd800f87d04137a43423e5', 'message': 'Check out global requirements when creating test VMs\n\nAs part of the test VM preparation, we need to use upper-constraints.\n\nChange-Id: I5aaab91f0590c49972e5eb03d1c70559698b2f39\n(cherry picked from commit 6da10694af43d9902a13b2e7a1c6e4b587a5ce57)\n'}]",0,704822,a418620c57e068c1edbd800f87d04137a43423e5,7,2,1,10239,,,0,"Check out global requirements when creating test VMs

As part of the test VM preparation, we need to use upper-constraints.

Change-Id: I5aaab91f0590c49972e5eb03d1c70559698b2f39
(cherry picked from commit 6da10694af43d9902a13b2e7a1c6e4b587a5ce57)
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/22/704822/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-create-vm-nodes/tasks/main.yml', 'playbooks/roles/bifrost-create-vm-nodes/defaults/main.yml']",2,a418620c57e068c1edbd800f87d04137a43423e5,," git_branch: master git_root: ""/opt/stack"" reqs_git_url: https://opendev.org/openstack/requirements reqs_git_folder: ""{{ git_root }}/requirements"" reqs_git_branch: ""{{ git_branch }}"" # Conditional variables utilized based on CI or manual testing options. copy_from_local_path: false ci_testing_zuul: false",reqs_git_folder: /opt/stack/requirements,39,1
openstack%2Fdevstack~master~Ic4f70f839765e67394509cc543560aac7f50e287,openstack/devstack,master,Ic4f70f839765e67394509cc543560aac7f50e287,Remove conflicting packages in Ubuntu,MERGED,2020-01-27 15:01:48.000000000,2020-01-30 00:02:38.000000000,2020-01-30 00:01:06.000000000,"[{'_account_id': 1131}, {'_account_id': 4146}, {'_account_id': 7118}, {'_account_id': 8556}, {'_account_id': 13252}, {'_account_id': 16222}, {'_account_id': 17042}, {'_account_id': 22348}, {'_account_id': 24791}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-27 15:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f6400b95497c2ec97d3dd7ee21ab09862e5ca571', 'message': 'Remove conflicting packages in Ubuntu\n\nFollowing packages conflict with pip installed versions:\n* httplib2\n* pyasn1-modules\n\nChange-Id: Ic4f70f839765e67394509cc543560aac7f50e287\n'}, {'number': 2, 'created': '2020-01-27 16:12:10.000000000', 'files': ['tools/fixup_stuff.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/e727dd56821231677e398133a3f991dcc3931ff4', 'message': 'Remove conflicting packages in Ubuntu\n\nFollowing packages conflict with pip installed versions:\n* httplib2\n* pyasn1-modules\n\nChange-Id: Ic4f70f839765e67394509cc543560aac7f50e287\n'}]",2,704336,e727dd56821231677e398133a3f991dcc3931ff4,21,10,2,16222,,,0,"Remove conflicting packages in Ubuntu

Following packages conflict with pip installed versions:
* httplib2
* pyasn1-modules

Change-Id: Ic4f70f839765e67394509cc543560aac7f50e287
",git fetch https://review.opendev.org/openstack/devstack refs/changes/36/704336/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/fixup_stuff.sh'],1,f6400b95497c2ec97d3dd7ee21ab09862e5ca571,, sudo apt-get -y remove python3-httplib2 sudo apt-get -y remove python3-pyasn1-modules,,2,0
openstack%2Fdesignate~master~I0161bc82878ca936c3b0d9e9f9624be81fad21db,openstack/designate,master,I0161bc82878ca936c3b0d9e9f9624be81fad21db,Drop use of USE_SYSTEMD var in devstack plugin,MERGED,2020-01-27 14:17:33.000000000,2020-01-29 23:31:53.000000000,2020-01-29 23:30:01.000000000,"[{'_account_id': 8099}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2020-01-27 14:17:33.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/designate/commit/d0731c03f5d996717daca149c4b0e3bf0aa8214e', 'message': ""Drop use of USE_SYSTEMD var in devstack plugin\n\nThe USE_SYSTEMD variable is to be dropped from devstack[0], as running\nwith systemd is the only option now. Drop it's usage in our plugin.\n\n[0] https://review.opendev.org/703734\n\nChange-Id: I0161bc82878ca936c3b0d9e9f9624be81fad21db\n""}]",0,704327,d0731c03f5d996717daca149c4b0e3bf0aa8214e,8,3,1,13252,,,0,"Drop use of USE_SYSTEMD var in devstack plugin

The USE_SYSTEMD variable is to be dropped from devstack[0], as running
with systemd is the only option now. Drop it's usage in our plugin.

[0] https://review.opendev.org/703734

Change-Id: I0161bc82878ca936c3b0d9e9f9624be81fad21db
",git fetch https://review.opendev.org/openstack/designate refs/changes/27/704327/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,d0731c03f5d996717daca149c4b0e3bf0aa8214e,fix-ds, setup_systemd_logging $DESIGNATE_CONF," if [ ""$USE_SYSTEMD"" != ""False"" ]; then setup_systemd_logging $DESIGNATE_CONF fi # Format logging if [ ""$LOG_COLOR"" == ""True"" ] && [ ""$USE_SYSTEMD"" == ""False"" ]; then setup_colorized_logging $DESIGNATE_CONF DEFAULT fi",1,8
openstack%2Ftripleo-ansible~master~I0796695271ec7863bb23e5bc292876e1e845e0fe,openstack/tripleo-ansible,master,I0796695271ec7863bb23e5bc292876e1e845e0fe,tripleo_container_manage: skip shutdown.yml if not necessary,MERGED,2020-01-29 17:31:37.000000000,2020-01-29 23:25:10.000000000,2020-01-29 23:25:10.000000000,"[{'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-29 17:31:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/10f53a143d5c2fb52267ee5d68f4b37712e9b0e7', 'message': ""tripleo_container_manage: skip shutdown.yml if not necessary\n\nIf the tripleo-container-shutdown.preset is already in place, we don't need to\nexecute the shutdown.yml playbook.\n\nIt'll avoid the repeat of these tasks at every step; and therefore save\ntime.\n\nChange-Id: I0796695271ec7863bb23e5bc292876e1e845e0fe\n""}, {'number': 2, 'created': '2020-01-29 17:32:54.000000000', 'files': ['tripleo_ansible/roles/tripleo_container_manage/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/e37bdf179347f620deb5afa206bfe838e7eaf03b', 'message': ""tripleo_container_manage: skip shutdown.yml if not necessary\n\nIf the tripleo-container-shutdown.preset is already in place, we don't need to\nexecute the shutdown.yml playbook.\n\nIt'll avoid the repeat of these tasks at every step; and therefore save\ntime.\n\nChange-Id: I0796695271ec7863bb23e5bc292876e1e845e0fe\n""}]",0,704852,e37bdf179347f620deb5afa206bfe838e7eaf03b,9,4,2,3153,,,0,"tripleo_container_manage: skip shutdown.yml if not necessary

If the tripleo-container-shutdown.preset is already in place, we don't need to
execute the shutdown.yml playbook.

It'll avoid the repeat of these tasks at every step; and therefore save
time.

Change-Id: I0796695271ec7863bb23e5bc292876e1e845e0fe
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/52/704852/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo_container_manage/tasks/main.yml'],1,10f53a143d5c2fb52267ee5d68f4b37712e9b0e7,optim, - name: Check if /usr/lib/systemd/system-preset/91-tripleo-container-shutdown.preset exists stat: path: /usr/lib/systemd/system-preset/91-tripleo-container-shutdown.preset register: tripleo_container_shutdown when: - tripleo_container_shutdown.stat.exists,,6,0
openstack%2Fdesignate~master~I7265c525f1091012011ba12d65e9669a826ab979,openstack/designate,master,I7265c525f1091012011ba12d65e9669a826ab979,Drop setcap on python binary,MERGED,2020-01-29 15:37:29.000000000,2020-01-29 23:24:10.000000000,2020-01-29 23:22:36.000000000,"[{'_account_id': 8099}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2020-01-29 15:37:29.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/designate/commit/3770b006d0c442461a23008d382bd7bd103584ae', 'message': ""Drop setcap on python binary\n\nThis is a bit of a security issue, also we don't seem to need it anymore\nsince we have long switched to running under python3 and the setcap\ndoesn't have any effect anyway. It will also break deployments once we\ndrop installing python2 completely, so just remove it now.\n\nChange-Id: I7265c525f1091012011ba12d65e9669a826ab979\n""}]",0,704827,3770b006d0c442461a23008d382bd7bd103584ae,8,3,1,13252,,,0,"Drop setcap on python binary

This is a bit of a security issue, also we don't seem to need it anymore
since we have long switched to running under python3 and the setcap
doesn't have any effect anyway. It will also break deployments once we
drop installing python2 completely, so just remove it now.

Change-Id: I7265c525f1091012011ba12d65e9669a826ab979
",git fetch https://review.opendev.org/openstack/designate refs/changes/27/704827/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,3770b006d0c442461a23008d382bd7bd103584ae,fix-for-py3, if is_fedora; then install_package bind-utils," # Some Designate Backends require mdns be bound to port 53, make that # doable. sudo setcap 'cap_net_bind_service=+ep' $(readlink -f /usr/bin/python) if is_ubuntu; then install_package libcap2-bin elif is_fedora; then install_package libcap bind-utils",2,9
openstack%2Fneutron-lib~master~I898633cd360cd9619f5e9a87acb718e01e99b647,openstack/neutron-lib,master,I898633cd360cd9619f5e9a87acb718e01e99b647,[Api-Ref][Docs] Change dns_assignment parameter to be list,MERGED,2020-01-28 09:42:03.000000000,2020-01-29 23:21:43.000000000,2020-01-29 23:18:28.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 22348}, {'_account_id': 24245}]","[{'number': 1, 'created': '2020-01-28 09:42:03.000000000', 'files': ['api-ref/source/v2/samples/ports/port-create-response.json', 'api-ref/source/v2/samples/ports/ports-bulk-create-response.json', 'api-ref/source/v2/samples/ports/port-update-response.json', 'api-ref/source/v2/samples/ports/port-bind-update-response.json', 'api-ref/source/v2/samples/ports/port-bind-create-response.json', 'api-ref/source/v2/samples/ports/ports-bind-list-response.json', 'api-ref/source/v2/samples/ports/ports-list-response.json', 'api-ref/source/v2/samples/ports/port-bind-show-response.json', 'api-ref/source/v2/samples/ports/port-show-response.json'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/fe653c2047b268797b83e2be198fcd5ca8e7b8b3', 'message': ""[Api-Ref][Docs] Change dns_assignment parameter to be list\n\nIn api-ref dns_assignment parameter was listed as dict but in fact it\nis list of dicts.\nThis patch fixes api-ref to reflect what is actually in neutron's code.\n\nChange-Id: I898633cd360cd9619f5e9a87acb718e01e99b647\nCloses-Bug: #1861027\n""}]",0,704517,fe653c2047b268797b83e2be198fcd5ca8e7b8b3,9,4,1,11975,,,0,"[Api-Ref][Docs] Change dns_assignment parameter to be list

In api-ref dns_assignment parameter was listed as dict but in fact it
is list of dicts.
This patch fixes api-ref to reflect what is actually in neutron's code.

Change-Id: I898633cd360cd9619f5e9a87acb718e01e99b647
Closes-Bug: #1861027
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/17/704517/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/v2/samples/ports/port-create-response.json', 'api-ref/source/v2/samples/ports/ports-bulk-create-response.json', 'api-ref/source/v2/samples/ports/port-update-response.json', 'api-ref/source/v2/samples/ports/port-bind-update-response.json', 'api-ref/source/v2/samples/ports/port-bind-create-response.json', 'api-ref/source/v2/samples/ports/ports-bind-list-response.json', 'api-ref/source/v2/samples/ports/port-bind-show-response.json', 'api-ref/source/v2/samples/ports/port-show-response.json', 'api-ref/source/v2/samples/ports/ports-list-response.json']",9,fe653c2047b268797b83e2be198fcd5ca8e7b8b3,bug/1861027," ""dns_assignment"": [ { ""hostname"": ""myport"", ""ip_address"": ""172.24.4.2"", ""fqdn"": ""myport.my-domain.org"" } ], ""dns_assignment"": [ { ""hostname"": ""myport2"", ""ip_address"": ""10.0.0.1"", ""fqdn"": ""myport2.my-domain.org"" } ],"," ""dns_assignment"": { ""hostname"": ""myport"", ""ip_address"": ""172.24.4.2"", ""fqdn"": ""myport.my-domain.org"" }, ""dns_assignment"": { ""hostname"": ""myport2"", ""ip_address"": ""10.0.0.1"", ""fqdn"": ""myport2.my-domain.org"" },",71,51
openstack%2Fopenstack-helm-infra~master~I68e1d4c8c1ade39f856c69333585dfcba3ea35ab,openstack/openstack-helm-infra,master,I68e1d4c8c1ade39f856c69333585dfcba3ea35ab,[ceph-osd] Wait for devices to initialize the osd,MERGED,2020-01-29 19:20:53.000000000,2020-01-29 23:08:37.000000000,2020-01-29 23:06:17.000000000,"[{'_account_id': 11934}, {'_account_id': 18511}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 29974}, {'_account_id': 30777}]","[{'number': 1, 'created': '2020-01-29 19:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f7e1b0a95c90804838c8cfbafede1c58d1ce8600', 'message': '[wip][ceph-osd]  wait for devices to intilize the osd\n\nThis is wait for all the osd devices before intilizing .\n\nChange-Id: I68e1d4c8c1ade39f856c69333585dfcba3ea35ab\n'}, {'number': 2, 'created': '2020-01-29 19:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bb76b811eb2c3ec6d45ff90496e8070a0722728a', 'message': '[ceph-osd] Wait for devices to intilize the osd\n\nThis is wait for all the osd devices before intilizing and also\nadd few checks to make sure disk is used or not .\n\nChange-Id: I68e1d4c8c1ade39f856c69333585dfcba3ea35ab\n'}, {'number': 3, 'created': '2020-01-29 19:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2b82fbe62118630bb34f0cf979471411092b1fa5', 'message': '[ceph-osd] Wait for devices to intilize the osd\n\nThis is wait for all the osd devices before intilizing and also\nadd few checks to make sure disk is used or not .\n\nChange-Id: I68e1d4c8c1ade39f856c69333585dfcba3ea35ab\n'}, {'number': 4, 'created': '2020-01-29 19:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e68b1f24f19049e5c66ed2891f10d708f42d3825', 'message': '[ceph-osd] Wait for devices to intilize the osd\n\nThis is to wait for all the osd devices before intilizing and also\nto add few more checks to make sure disk is used or not .\n\nChange-Id: I68e1d4c8c1ade39f856c69333585dfcba3ea35ab\n'}, {'number': 5, 'created': '2020-01-29 19:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e21e20e299faa3e88eec8c369fa3039df8a34720', 'message': '[ceph-osd] Wait for devices to intilize the osd\n\nThis is to wait for all the osd devices before intilizing and also\nto add few more checks to make sure disk is used or not .\n\nChange-Id: I68e1d4c8c1ade39f856c69333585dfcba3ea35ab\n'}, {'number': 6, 'created': '2020-01-29 20:31:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/0952aa43d3a4295b6a577ca76f3cba873ec4cfca', 'message': '[ceph-osd] Wait for devices to intialize the osd\n\nThis is to wait for all the osd devices before intializing and also\nto add few more checks to make sure disk is used or not .\n\nChange-Id: I68e1d4c8c1ade39f856c69333585dfcba3ea35ab\n'}, {'number': 7, 'created': '2020-01-29 20:34:33.000000000', 'files': ['ceph-osd/templates/bin/osd/ceph-volume/_init-with-ceph-volume.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9a18198fca2c1c1d4a0a029bfbce384594d148ad', 'message': '[ceph-osd] Wait for devices to initialize the osd\n\nThis is to wait for all the osd devices before initializing and also\nto add few more checks to make sure disk is used or not .\n\nChange-Id: I68e1d4c8c1ade39f856c69333585dfcba3ea35ab\n'}]",13,704874,9a18198fca2c1c1d4a0a029bfbce384594d148ad,23,6,7,28372,,,0,"[ceph-osd] Wait for devices to initialize the osd

This is to wait for all the osd devices before initializing and also
to add few more checks to make sure disk is used or not .

Change-Id: I68e1d4c8c1ade39f856c69333585dfcba3ea35ab
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/74/704874/5 && git format-patch -1 --stdout FETCH_HEAD,['ceph-osd/templates/bin/osd/ceph-volume/_init-with-ceph-volume.sh.tpl'],1,f7e1b0a95c90804838c8cfbafede1c58d1ce8600,," udev_settle if ceph osd ls |grep ${OSD_ID}; then echo ""Running bluestore mode and ${OSD_DEVICE} already bootstrapped"" else echo ""found the wrong osd id which is not belongs to current ceph cluster"" exit 1 fi "," echo ""Running bluestore mode and ${OSD_DEVICE} already bootstrapped""",7,1
openstack%2Fpaunch~stable%2Ftrain~I346c49cb204f273bd7077ca5153412cda9846534,openstack/paunch,stable/train,I346c49cb204f273bd7077ca5153412cda9846534,Do not force remove containers,MERGED,2020-01-28 19:29:46.000000000,2020-01-29 22:56:30.000000000,2020-01-29 22:55:13.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-28 19:29:46.000000000', 'files': ['paunch/tests/test_runner.py', 'paunch/runner.py', 'paunch/tests/test_builder_base.py'], 'web_link': 'https://opendev.org/openstack/paunch/commit/d56765a0aff2f8cf5761a26de86a0ec3a2e5bd0f', 'message': ""Do not force remove containers\n\nPaunch does docker/podman rm -f, when removes containers. It seems it\nreturns too early, having some leftovers (like docker service\nendpoints) behind or pending for it to be removed later, in case of\nbig fat deamons.\n\nLong story short, don't do rm -f and allow it to do its job gracefully\nand without a hurry.\n\nChange-Id: I346c49cb204f273bd7077ca5153412cda9846534\nCloses-Bug: #1860004\nCo-authored-by: Sergii Golovatiuk <sgolovat@redhat.com>\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n(cherry picked from commit 3813fc7f2bd5768248f7c450d707a13c33f19fc3)\n""}]",0,704668,d56765a0aff2f8cf5761a26de86a0ec3a2e5bd0f,8,4,1,25877,,,0,"Do not force remove containers

Paunch does docker/podman rm -f, when removes containers. It seems it
returns too early, having some leftovers (like docker service
endpoints) behind or pending for it to be removed later, in case of
big fat deamons.

Long story short, don't do rm -f and allow it to do its job gracefully
and without a hurry.

Change-Id: I346c49cb204f273bd7077ca5153412cda9846534
Closes-Bug: #1860004
Co-authored-by: Sergii Golovatiuk <sgolovat@redhat.com>
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
(cherry picked from commit 3813fc7f2bd5768248f7c450d707a13c33f19fc3)
",git fetch https://review.opendev.org/openstack/paunch refs/changes/68/704668/1 && git format-patch -1 --stdout FETCH_HEAD,"['paunch/tests/test_runner.py', 'paunch/runner.py', 'paunch/tests/test_builder_base.py']",3,d56765a0aff2f8cf5761a26de86a0ec3a2e5bd0f,," # stop five ('', '', 0), # stop six ('', '', 0), # stop two, changed config data ('', '', 0), mock.call(['docker', 'stop', 'five'], mock.ANY), mock.call(['docker', 'rm', 'five'], mock.ANY), mock.call(['docker', 'stop', 'six'], mock.ANY), mock.call(['docker', 'rm', 'six'], mock.ANY), mock.call(['docker', 'stop', 'two-12345678'], mock.ANY), mock.call(['docker', 'rm', 'two-12345678'], mock.ANY),"," mock.call(['docker', 'rm', '-f', 'five'], mock.ANY), mock.call(['docker', 'rm', '-f', 'six'], mock.ANY), mock.call(['docker', 'rm', '-f', 'two-12345678'], mock.ANY),",15,5
openstack%2Fneutron-specs~master~If937e343484387ecce4a3709bed3ca74cc52b9bc,openstack/neutron-specs,master,If937e343484387ecce4a3709bed3ca74cc52b9bc,Missing caveat in NC DSCP spec,MERGED,2020-01-20 15:45:14.000000000,2020-01-29 22:53:36.000000000,2020-01-29 22:50:39.000000000,"[{'_account_id': 4694}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 18051}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-20 15:45:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/743a970be595ac9a8d9892500436c5336a79e6bf', 'message': 'Missing caveat in NC DSCP spec\n\nadded section explicitly calling out a lock on certain\nvariables in the classification resources to prevent\nupdating.\nThis avoids an issue with the classifications being\nupdated but the classifier having no way to inform its\nconsumers.\n\nChange-Id: If937e343484387ecce4a3709bed3ca74cc52b9bc\n'}, {'number': 2, 'created': '2020-01-22 15:20:45.000000000', 'files': ['specs/ussuri/qos_classifier.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/acc57d57c4adbeddf7b83af7c9684beef28b9304', 'message': 'Missing caveat in NC DSCP spec\n\nadded section explicitly calling out a lock on certain\nvariables in the classification resources to prevent\nupdating.\nThis avoids an issue with the classifications being\nupdated but the classifier having no way to inform its\nconsumers.\n\nChange-Id: If937e343484387ecce4a3709bed3ca74cc52b9bc\n'}]",2,703431,acc57d57c4adbeddf7b83af7c9684beef28b9304,14,6,2,18051,,,0,"Missing caveat in NC DSCP spec

added section explicitly calling out a lock on certain
variables in the classification resources to prevent
updating.
This avoids an issue with the classifications being
updated but the classifier having no way to inform its
consumers.

Change-Id: If937e343484387ecce4a3709bed3ca74cc52b9bc
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/31/703431/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/ussuri/qos_classifier.rst'],1,743a970be595ac9a8d9892500436c5336a79e6bf,,"- As Neutron Classifier is unable to force an update action to it's consumers and as users may be unaware of all the consumers of a classification, the classification ""definition"" and ""type"" fields and the classification group ""classifications"", ""classification_groups"" and ""operator"" fields cannot be updated after creation. ",,6,0
openstack%2Fopenstack-helm~master~I29cc044e0d4f10198c23c7c3e132ab0093f91e21,openstack/openstack-helm,master,I29cc044e0d4f10198c23c7c3e132ab0093f91e21,Fix compute-kit netpol job,MERGED,2020-01-23 14:50:49.000000000,2020-01-29 22:48:20.000000000,2020-01-29 22:46:07.000000000,"[{'_account_id': 17591}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 14:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/a5e882a13ef875bb279cc11b6c1f4d5285c750aa', 'message': 'Fix compute-kit netpol job\n\nThis patch set addresses a failure in the compute-kit network\npolicy failing as some application:nova to application:nova\npods communication is blocked.\n\nChange-Id: I29cc044e0d4f10198c23c7c3e132ab0093f91e21\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 2, 'created': '2020-01-23 16:27:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/309fc5bdcd10619f87597ae2cde2838761dbb961', 'message': 'Fix compute-kit netpol job\n\nThis patch set addresses a failure in the compute-kit network\npolicy failing as some application:nova to application:nova\npods communication is blocked.\n\nChange-Id: I29cc044e0d4f10198c23c7c3e132ab0093f91e21\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 3, 'created': '2020-01-23 18:04:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/015cf79746d3199f56d2fcce0fbfdb0bf910d102', 'message': 'Fix compute-kit netpol job\n\nThis patch set addresses a failure in the compute-kit network\npolicy failing as some application:nova to application:nova\npods communication is blocked.\n\nChange-Id: I29cc044e0d4f10198c23c7c3e132ab0093f91e21\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 4, 'created': '2020-01-23 20:39:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/0b66a4823319cbaeeff01623125fcb29c04c9eb0', 'message': 'Fix compute-kit netpol job\n\nThis patch set addresses a failure in the compute-kit network\npolicy failing as some application:nova to application:nova\npods communication is blocked.\n\nChange-Id: I29cc044e0d4f10198c23c7c3e132ab0093f91e21\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 5, 'created': '2020-01-28 12:24:22.000000000', 'files': ['nova/values_overrides/netpol.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8e72ff763061c3dcb23211fb1e362a280bbdebbc', 'message': 'Fix compute-kit netpol job\n\nThis patch set addresses a failure in the compute-kit network\npolicy failing as some application:nova to application:nova\npods communication is blocked.\n\nChange-Id: I29cc044e0d4f10198c23c7c3e132ab0093f91e21\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}]",0,704002,8e72ff763061c3dcb23211fb1e362a280bbdebbc,16,3,5,20466,,,0,"Fix compute-kit netpol job

This patch set addresses a failure in the compute-kit network
policy failing as some application:nova to application:nova
pods communication is blocked.

Change-Id: I29cc044e0d4f10198c23c7c3e132ab0093f91e21
Signed-off-by: Tin Lam <tin@irrational.io>
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/02/704002/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/values_overrides/netpol.yaml'],1,a5e882a13ef875bb279cc11b6c1f4d5285c750aa,fix/netpol-job, - podSelector: matchLabels: application: nova - to: - podSelector: matchLabels: application: placement - to:,,8,0
openstack%2Fpaunch~stable%2Fqueens~I635e7d53f8aea63c05a2e5565f2a2ab40dcd38f8,openstack/paunch,stable/queens,I635e7d53f8aea63c05a2e5565f2a2ab40dcd38f8,Fix labels to take multiple values,MERGED,2020-01-14 14:01:43.000000000,2020-01-29 22:36:29.000000000,2020-01-29 22:34:54.000000000,"[{'_account_id': 3153}, {'_account_id': 4571}, {'_account_id': 6926}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-14 14:01:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/2d1ed1660deed218f52b35ffb0426b4eaee59fd9', 'message': 'Fix labels to take multiple values\n\nCloses-Bug: #1798362\nChange-Id: I635e7d53f8aea63c05a2e5565f2a2ab40dcd38f8\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n(cherry picked from commit b28914702ae5e83d3e3922e1690acb3ef95a167b)\n'}, {'number': 2, 'created': '2020-01-23 14:09:56.000000000', 'files': ['paunch/cmd.py', 'releasenotes/notes/labels-96a99153cf97c3aa.yaml'], 'web_link': 'https://opendev.org/openstack/paunch/commit/f12e6da460543c8677f256ff93c5b1fecad5f674', 'message': 'Fix labels to take multiple values\n\nCloses-Bug: #1798362\nChange-Id: I635e7d53f8aea63c05a2e5565f2a2ab40dcd38f8\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n(cherry picked from commit b28914702ae5e83d3e3922e1690acb3ef95a167b)\n'}]",0,702435,f12e6da460543c8677f256ff93c5b1fecad5f674,15,7,2,6926,,,0,"Fix labels to take multiple values

Closes-Bug: #1798362
Change-Id: I635e7d53f8aea63c05a2e5565f2a2ab40dcd38f8
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
(cherry picked from commit b28914702ae5e83d3e3922e1690acb3ef95a167b)
",git fetch https://review.opendev.org/openstack/paunch refs/changes/35/702435/2 && git format-patch -1 --stdout FETCH_HEAD,"['paunch/cmd.py', 'releasenotes/notes/labels-96a99153cf97c3aa.yaml']",2,2d1ed1660deed218f52b35ffb0426b4eaee59fd9,1790792_maybe,--- fixes: - | Fixed ``--labels`` can takes multiple values. ,,8,2
openstack%2Fansible-role-tripleo-modify-image~master~I19491a162e5bf6d6517fd343d675aff12bdc9719,openstack/ansible-role-tripleo-modify-image,master,I19491a162e5bf6d6517fd343d675aff12bdc9719,Ensure the yum cache has at most one writer,MERGED,2020-01-27 14:51:49.000000000,2020-01-29 22:32:56.000000000,2020-01-29 22:32:56.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 9592}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-27 14:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-modify-image/commit/34a5194c88e7512151cb97456edec0852c611c0e', 'message': 'Ensure the yum cache has at most one writer\n\nIf the yum cache path exists and already mounted by someone,\ndo not attempt writing to it, use the overlay mode instead.\nThis drastically reduces chances to have multiple writers for the\ncache.\n\nCloses-bug: #1860804\n\nChange-Id: I19491a162e5bf6d6517fd343d675aff12bdc9719\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 2, 'created': '2020-01-27 15:21:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-modify-image/commit/0fd390fcb01fdb56df826beeeee25467191779d6', 'message': 'Ensure the yum cache has at most one writer\n\nIf the yum cache path exists and already mounted by someone,\ndo not attempt writing to it, use the overlay mode instead.\n\nThis still leaves a window of opportunity for another workers to\nRW mount the cache after the ansible check has reported a stale\nfact about there was no other mounts found. To make this window\nas small as possible, modify the buildah command to run that\ncheck as well. If the cache recognized as already mounted by\nthat command, raise to the rescue section and retry. Otherwise,\nexecute the original buildah command.\n\nIf it has to be retried in the rescue block, do not use the yum cache\nfor the maximum data safety and clean (a scratch) cache state reasons.\n\nThis drastically reduces chances to have multiple writers for the\ncache.\n\nCloses-bug: #1860804\n\nChange-Id: I19491a162e5bf6d6517fd343d675aff12bdc9719\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 3, 'created': '2020-01-28 09:06:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-modify-image/commit/45d6373da46cd6e314ac778603cfca742d729d20', 'message': 'Ensure the yum cache has at most one writer\n\nIf the yum cache path exists and already mounted by someone,\ndo not attempt writing to it, use the overlay mode instead.\n\nThis still leaves a window of opportunity for another workers to\nRW mount the cache after the ansible check has reported a stale\nfact about there was no other mounts found. To make this window\nas small as possible, modify the buildah command to run that\ncheck as well. If the cache recognized as already mounted by\nthat command, raise to the rescue section and retry. Otherwise,\nexecute the original buildah command.\n\nIf it has to be retried in the rescue block, do not use the yum cache\nfor the maximum data safety and clean (a scratch) cache state reasons.\n\nThis drastically reduces chances to have multiple writers for the\ncache.\n\nCloses-bug: #1860804\n\nChange-Id: I19491a162e5bf6d6517fd343d675aff12bdc9719\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 4, 'created': '2020-01-28 14:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-modify-image/commit/bcc3abdf2c687b733c4d1fd1e0f9af0c163ea7a5', 'message': 'Ensure the yum cache has at most one writer\n\nIf the yum cache path exists and already mounted by someone,\ndo not attempt writing to it, use the overlay mode instead.\n\nThis still leaves a window of opportunity for another workers to\nRW mount the cache after the ansible check has reported a stale\nfact about there was no other mounts found. But this is unlikely\nto happen.\n\nAlso, if it has to be retried in the rescue block, do not use the yum\ncache for the maximum data safety and clean (a scratch) cache state\nreasons.\n\nThis drastically reduces chances to have multiple writers for the\ncache.\n\nCloses-bug: #1860804\n\nChange-Id: I19491a162e5bf6d6517fd343d675aff12bdc9719\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 5, 'created': '2020-01-29 08:33:17.000000000', 'files': ['tasks/yum_update_buildah.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-modify-image/commit/eff235ee7274f0d4a9c71bf0d971d93fd5e3d339', 'message': 'Ensure the yum cache has at most one writer\n\nIf the yum cache path exists and already mounted by someone,\ndo not attempt writing to it, use the overlay mode instead.\n\nThis still leaves a window of opportunity for another workers to\nRW mount the cache after the ansible check has reported a stale\nfact about there was no other mounts found. But this is unlikely\nto happen.\n\nAlso, if it has to be retried in the rescue block, do not use the yum\ncache for the maximum data safety and clean (a scratch) cache state\nreasons.\n\nThis drastically reduces chances to have multiple writers for the\ncache.\n\nCloses-bug: #1860804\n\nChange-Id: I19491a162e5bf6d6517fd343d675aff12bdc9719\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}]",1,704335,eff235ee7274f0d4a9c71bf0d971d93fd5e3d339,17,8,5,6926,,,0,"Ensure the yum cache has at most one writer

If the yum cache path exists and already mounted by someone,
do not attempt writing to it, use the overlay mode instead.

This still leaves a window of opportunity for another workers to
RW mount the cache after the ansible check has reported a stale
fact about there was no other mounts found. But this is unlikely
to happen.

Also, if it has to be retried in the rescue block, do not use the yum
cache for the maximum data safety and clean (a scratch) cache state
reasons.

This drastically reduces chances to have multiple writers for the
cache.

Closes-bug: #1860804

Change-Id: I19491a162e5bf6d6517fd343d675aff12bdc9719
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-modify-image refs/changes/35/704335/4 && git format-patch -1 --stdout FETCH_HEAD,['tasks/yum_update_buildah.yml'],1,34a5194c88e7512151cb97456edec0852c611c0e,, - name: Check if the cache path has been already mounted command: findmnt -J {{ yum_cache }} register: findmnt_result - findmnt_result.rc != 0,,5,0
openstack%2Fnetworking-ovn~stable%2Fqueens~Idb01ca5a5bd9ba7332832da14c1890f3e4828356,openstack/networking-ovn,stable/queens,Idb01ca5a5bd9ba7332832da14c1890f3e4828356,Add support for virtual port type,ABANDONED,2020-01-29 14:18:34.000000000,2020-01-29 22:24:18.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-01-29 14:18:34.000000000', 'files': ['networking_ovn/common/ovn_client.py', 'networking_ovn/common/utils.py', 'networking_ovn/common/constants.py', 'networking_ovn/ovsdb/ovn_api.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ovsdb/impl_idl_ovn.py', 'networking_ovn/ovsdb/commands.py', 'releasenotes/notes/virtual-ports-fe725a817ce45e6d.yaml', 'networking_ovn/tests/functional/test_mech_driver.py', 'networking_ovn/tests/unit/fakes.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/8cd48ae5300fb6ccbff68078a9ddde39372237d0', 'message': 'Add support for virtual port type\n\nThis patch adds support for ""virtual"" port type following the work in\ncore OVN [0].\n\nCurrently there are two main usages for this type of port:\n\n* Octavia: For creating the logical port for the virtual IP.\n* VRRP [1]\n\nUpon adding an IP address to the allowed_address_pairs field of the\nNeutron\'s port, networking-ovn will look if that IP matches with the IP\nof another existing port in the same network. If so, networking-ovn will\nupdating the matching port accordingly setting its type to ""virtual""\nand adding the required options in the OVN database.\n\nThe patch also accounts for other situations such as:\n\n* Creating the VIP port after the parents (the ones with the IP in the\n  allowed_address_pairs field) are created.\n\n* When updating removing/adding allowed_address_pairs\' the virtual\n  ports are also updated.\n\n* When deleting a parent port the virtual ports are also updated.\n\nThe code removes the type ""virtual"" from a virtual port whenever there\'s\nno parents left (in case of deletion or editing allowed_address_pairs)\nmaking it an ordinary port again.\n\nThe patch also keeps the logic introduced by\n33fd553158a96b4dc40c66acf050fa7f91227dec for version of OVN which does\nnot support the virtual port type (> 2.12) making it backward compatible.\n\n[0]\nhttps://github.com/ovn-org/ovn/commit/054f4c85c413e20d893e10ba053ec52ac15db49c\n[1]\nhttps://docs.catalystcloud.io/tutorials/deploying-highly-available-instances-with-keepalived.html\n\nCloses-Bug: #1840449\nRelated-Bug: #1789686\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n(cherry picked from commit 5e72ea104cba1c30d2de36dbbab6e3d23a075929)\n\nConflicts:\n\tnetworking_ovn/common/ovn_client.py\n\tnetworking_ovn/common/utils.py\n\tnetworking_ovn/ovsdb/commands.py\n\tnetworking_ovn/tests/functional/test_mech_driver.py\n\tnetworking_ovn/tests/unit/fakes.py\n\tnetworking_ovn/tests/unit/ml2/test_mech_driver.py\n\nChange-Id: Idb01ca5a5bd9ba7332832da14c1890f3e4828356\n'}]",0,704812,8cd48ae5300fb6ccbff68078a9ddde39372237d0,3,1,1,6773,,,0,"Add support for virtual port type

This patch adds support for ""virtual"" port type following the work in
core OVN [0].

Currently there are two main usages for this type of port:

* Octavia: For creating the logical port for the virtual IP.
* VRRP [1]

Upon adding an IP address to the allowed_address_pairs field of the
Neutron's port, networking-ovn will look if that IP matches with the IP
of another existing port in the same network. If so, networking-ovn will
updating the matching port accordingly setting its type to ""virtual""
and adding the required options in the OVN database.

The patch also accounts for other situations such as:

* Creating the VIP port after the parents (the ones with the IP in the
  allowed_address_pairs field) are created.

* When updating removing/adding allowed_address_pairs' the virtual
  ports are also updated.

* When deleting a parent port the virtual ports are also updated.

The code removes the type ""virtual"" from a virtual port whenever there's
no parents left (in case of deletion or editing allowed_address_pairs)
making it an ordinary port again.

The patch also keeps the logic introduced by
33fd553158a96b4dc40c66acf050fa7f91227dec for version of OVN which does
not support the virtual port type (> 2.12) making it backward compatible.

[0]
https://github.com/ovn-org/ovn/commit/054f4c85c413e20d893e10ba053ec52ac15db49c
[1]
https://docs.catalystcloud.io/tutorials/deploying-highly-available-instances-with-keepalived.html

Closes-Bug: #1840449
Related-Bug: #1789686
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
(cherry picked from commit 5e72ea104cba1c30d2de36dbbab6e3d23a075929)

Conflicts:
	networking_ovn/common/ovn_client.py
	networking_ovn/common/utils.py
	networking_ovn/ovsdb/commands.py
	networking_ovn/tests/functional/test_mech_driver.py
	networking_ovn/tests/unit/fakes.py
	networking_ovn/tests/unit/ml2/test_mech_driver.py

Change-Id: Idb01ca5a5bd9ba7332832da14c1890f3e4828356
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/12/704812/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/common/ovn_client.py', 'networking_ovn/common/utils.py', 'networking_ovn/common/constants.py', 'networking_ovn/ovsdb/ovn_api.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ovsdb/impl_idl_ovn.py', 'networking_ovn/ovsdb/commands.py', 'releasenotes/notes/virtual-ports-fe725a817ce45e6d.yaml', 'networking_ovn/tests/functional/test_mech_driver.py', 'networking_ovn/tests/unit/fakes.py']",10,8cd48ae5300fb6ccbff68078a9ddde39372237d0,, self.set_lswitch_port_to_virtual_type = mock.Mock() self.unset_lswitch_port_to_virtual_type = mock.Mock() self.ls_get = mock.Mock() self.is_col_present = mock.Mock() self.is_col_present.return_value = False,,586,25
openstack%2Fnetworking-ovn~stable%2Frocky~I7b4211dd1536144e14cc4cc7aa6f1b665e3af9a6,openstack/networking-ovn,stable/rocky,I7b4211dd1536144e14cc4cc7aa6f1b665e3af9a6,Add support for virtual port type,ABANDONED,2020-01-29 13:40:54.000000000,2020-01-29 22:22:44.000000000,,"[{'_account_id': 1131}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 13:40:54.000000000', 'files': ['networking_ovn/common/ovn_client.py', 'networking_ovn/common/utils.py', 'networking_ovn/common/constants.py', 'networking_ovn/ovsdb/ovn_api.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ovsdb/impl_idl_ovn.py', 'networking_ovn/ovsdb/commands.py', 'releasenotes/notes/virtual-ports-fe725a817ce45e6d.yaml', 'networking_ovn/tests/functional/test_mech_driver.py', 'networking_ovn/tests/unit/fakes.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/b841298ddf03240fb191f0d34cb3e15940e126ec', 'message': 'Add support for virtual port type\n\nThis patch adds support for ""virtual"" port type following the work in\ncore OVN [0].\n\nCurrently there are two main usages for this type of port:\n\n* Octavia: For creating the logical port for the virtual IP.\n* VRRP [1]\n\nUpon adding an IP address to the allowed_address_pairs field of the\nNeutron\'s port, networking-ovn will look if that IP matches with the IP\nof another existing port in the same network. If so, networking-ovn will\nupdating the matching port accordingly setting its type to ""virtual""\nand adding the required options in the OVN database.\n\nThe patch also accounts for other situations such as:\n\n* Creating the VIP port after the parents (the ones with the IP in the\n  allowed_address_pairs field) are created.\n\n* When updating removing/adding allowed_address_pairs\' the virtual\n  ports are also updated.\n\n* When deleting a parent port the virtual ports are also updated.\n\nThe code removes the type ""virtual"" from a virtual port whenever there\'s\nno parents left (in case of deletion or editing allowed_address_pairs)\nmaking it an ordinary port again.\n\nThe patch also keeps the logic introduced by\n33fd553158a96b4dc40c66acf050fa7f91227dec for version of OVN which does\nnot support the virtual port type (> 2.12) making it backward compatible.\n\n[0]\nhttps://github.com/ovn-org/ovn/commit/054f4c85c413e20d893e10ba053ec52ac15db49c\n[1]\nhttps://docs.catalystcloud.io/tutorials/deploying-highly-available-instances-with-keepalived.html\n\nCloses-Bug: #1840449\nRelated-Bug: #1789686\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n(cherry picked from commit 5e72ea104cba1c30d2de36dbbab6e3d23a075929)\n\nConflicts:\n\tnetworking_ovn/common/ovn_client.py\n\tnetworking_ovn/tests/functional/test_mech_driver.py\n\tnetworking_ovn/tests/unit/fakes.py\n\tnetworking_ovn/tests/unit/ml2/test_mech_driver.py\n\nChange-Id: I7b4211dd1536144e14cc4cc7aa6f1b665e3af9a6\n'}]",0,704806,b841298ddf03240fb191f0d34cb3e15940e126ec,4,2,1,6773,,,0,"Add support for virtual port type

This patch adds support for ""virtual"" port type following the work in
core OVN [0].

Currently there are two main usages for this type of port:

* Octavia: For creating the logical port for the virtual IP.
* VRRP [1]

Upon adding an IP address to the allowed_address_pairs field of the
Neutron's port, networking-ovn will look if that IP matches with the IP
of another existing port in the same network. If so, networking-ovn will
updating the matching port accordingly setting its type to ""virtual""
and adding the required options in the OVN database.

The patch also accounts for other situations such as:

* Creating the VIP port after the parents (the ones with the IP in the
  allowed_address_pairs field) are created.

* When updating removing/adding allowed_address_pairs' the virtual
  ports are also updated.

* When deleting a parent port the virtual ports are also updated.

The code removes the type ""virtual"" from a virtual port whenever there's
no parents left (in case of deletion or editing allowed_address_pairs)
making it an ordinary port again.

The patch also keeps the logic introduced by
33fd553158a96b4dc40c66acf050fa7f91227dec for version of OVN which does
not support the virtual port type (> 2.12) making it backward compatible.

[0]
https://github.com/ovn-org/ovn/commit/054f4c85c413e20d893e10ba053ec52ac15db49c
[1]
https://docs.catalystcloud.io/tutorials/deploying-highly-available-instances-with-keepalived.html

Closes-Bug: #1840449
Related-Bug: #1789686
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
(cherry picked from commit 5e72ea104cba1c30d2de36dbbab6e3d23a075929)

Conflicts:
	networking_ovn/common/ovn_client.py
	networking_ovn/tests/functional/test_mech_driver.py
	networking_ovn/tests/unit/fakes.py
	networking_ovn/tests/unit/ml2/test_mech_driver.py

Change-Id: I7b4211dd1536144e14cc4cc7aa6f1b665e3af9a6
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/06/704806/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/common/ovn_client.py', 'networking_ovn/common/utils.py', 'networking_ovn/common/constants.py', 'networking_ovn/ovsdb/ovn_api.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ovsdb/impl_idl_ovn.py', 'networking_ovn/ovsdb/commands.py', 'releasenotes/notes/virtual-ports-fe725a817ce45e6d.yaml', 'networking_ovn/tests/functional/test_mech_driver.py', 'networking_ovn/tests/unit/fakes.py']",10,b841298ddf03240fb191f0d34cb3e15940e126ec,, self.set_lswitch_port_to_virtual_type = mock.Mock() self.unset_lswitch_port_to_virtual_type = mock.Mock() self.ls_get = mock.Mock() self.is_col_present = mock.Mock() self.is_col_present.return_value = False,,583,25
openstack%2Fnetworking-ovn~stable%2Fstein~I8077395a8b07fcbae49929556dbd1967c9f5546c,openstack/networking-ovn,stable/stein,I8077395a8b07fcbae49929556dbd1967c9f5546c,Add support for virtual port type,ABANDONED,2020-01-29 13:34:53.000000000,2020-01-29 22:20:22.000000000,,"[{'_account_id': 1131}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 13:34:53.000000000', 'files': ['networking_ovn/common/ovn_client.py', 'networking_ovn/common/utils.py', 'networking_ovn/common/constants.py', 'networking_ovn/ovsdb/ovn_api.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ovsdb/impl_idl_ovn.py', 'networking_ovn/ovsdb/commands.py', 'releasenotes/notes/virtual-ports-fe725a817ce45e6d.yaml', 'networking_ovn/tests/functional/test_mech_driver.py', 'networking_ovn/tests/unit/fakes.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/f476d8dcfa7651c72b26a9490ddd0720537c36ce', 'message': 'Add support for virtual port type\n\nThis patch adds support for ""virtual"" port type following the work in\ncore OVN [0].\n\nCurrently there are two main usages for this type of port:\n\n* Octavia: For creating the logical port for the virtual IP.\n* VRRP [1]\n\nUpon adding an IP address to the allowed_address_pairs field of the\nNeutron\'s port, networking-ovn will look if that IP matches with the IP\nof another existing port in the same network. If so, networking-ovn will\nupdating the matching port accordingly setting its type to ""virtual""\nand adding the required options in the OVN database.\n\nThe patch also accounts for other situations such as:\n\n* Creating the VIP port after the parents (the ones with the IP in the\n  allowed_address_pairs field) are created.\n\n* When updating removing/adding allowed_address_pairs\' the virtual\n  ports are also updated.\n\n* When deleting a parent port the virtual ports are also updated.\n\nThe code removes the type ""virtual"" from a virtual port whenever there\'s\nno parents left (in case of deletion or editing allowed_address_pairs)\nmaking it an ordinary port again.\n\nThe patch also keeps the logic introduced by\n33fd553158a96b4dc40c66acf050fa7f91227dec for version of OVN which does\nnot support the virtual port type (> 2.12) making it backward compatible.\n\n[0]\nhttps://github.com/ovn-org/ovn/commit/054f4c85c413e20d893e10ba053ec52ac15db49c\n[1]\nhttps://docs.catalystcloud.io/tutorials/deploying-highly-available-instances-with-keepalived.html\n\nCloses-Bug: #1840449\nRelated-Bug: #1789686\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n(cherry picked from commit 5e72ea104cba1c30d2de36dbbab6e3d23a075929)\n\nConflicts:\n\tnetworking_ovn/common/ovn_client.py\n\tnetworking_ovn/tests/functional/test_mech_driver.py\n\tnetworking_ovn/tests/unit/ml2/test_mech_driver.py\n\nChange-Id: I8077395a8b07fcbae49929556dbd1967c9f5546c\n'}]",1,704804,f476d8dcfa7651c72b26a9490ddd0720537c36ce,5,2,1,6773,,,0,"Add support for virtual port type

This patch adds support for ""virtual"" port type following the work in
core OVN [0].

Currently there are two main usages for this type of port:

* Octavia: For creating the logical port for the virtual IP.
* VRRP [1]

Upon adding an IP address to the allowed_address_pairs field of the
Neutron's port, networking-ovn will look if that IP matches with the IP
of another existing port in the same network. If so, networking-ovn will
updating the matching port accordingly setting its type to ""virtual""
and adding the required options in the OVN database.

The patch also accounts for other situations such as:

* Creating the VIP port after the parents (the ones with the IP in the
  allowed_address_pairs field) are created.

* When updating removing/adding allowed_address_pairs' the virtual
  ports are also updated.

* When deleting a parent port the virtual ports are also updated.

The code removes the type ""virtual"" from a virtual port whenever there's
no parents left (in case of deletion or editing allowed_address_pairs)
making it an ordinary port again.

The patch also keeps the logic introduced by
33fd553158a96b4dc40c66acf050fa7f91227dec for version of OVN which does
not support the virtual port type (> 2.12) making it backward compatible.

[0]
https://github.com/ovn-org/ovn/commit/054f4c85c413e20d893e10ba053ec52ac15db49c
[1]
https://docs.catalystcloud.io/tutorials/deploying-highly-available-instances-with-keepalived.html

Closes-Bug: #1840449
Related-Bug: #1789686
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
(cherry picked from commit 5e72ea104cba1c30d2de36dbbab6e3d23a075929)

Conflicts:
	networking_ovn/common/ovn_client.py
	networking_ovn/tests/functional/test_mech_driver.py
	networking_ovn/tests/unit/ml2/test_mech_driver.py

Change-Id: I8077395a8b07fcbae49929556dbd1967c9f5546c
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/04/704804/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/common/ovn_client.py', 'networking_ovn/common/utils.py', 'networking_ovn/common/constants.py', 'networking_ovn/ovsdb/ovn_api.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ovsdb/impl_idl_ovn.py', 'networking_ovn/ovsdb/commands.py', 'releasenotes/notes/virtual-ports-fe725a817ce45e6d.yaml', 'networking_ovn/tests/functional/test_mech_driver.py', 'networking_ovn/tests/unit/fakes.py']",10,f476d8dcfa7651c72b26a9490ddd0720537c36ce,, self.set_lswitch_port_to_virtual_type = mock.Mock() self.unset_lswitch_port_to_virtual_type = mock.Mock() self.ls_get = mock.Mock() self.is_col_present = mock.Mock() self.is_col_present.return_value = False,,582,25
openstack%2Fmanila~stable%2Ftrain~Ia61b108ece0817069737980a614cc6c15c1a3507,openstack/manila,stable/train,Ia61b108ece0817069737980a614cc6c15c1a3507,Improve share list speed using lazy='subquery',MERGED,2020-01-29 17:21:27.000000000,2020-01-29 22:18:26.000000000,2020-01-29 21:05:50.000000000,"[{'_account_id': 9003}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 25243}, {'_account_id': 29632}, {'_account_id': 30002}, {'_account_id': 30314}]","[{'number': 1, 'created': '2020-01-29 17:21:27.000000000', 'files': ['manila/db/sqlalchemy/models.py', 'releasenotes/notes/bug-1859785-share-list-speed-6b09e7717624e037.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/f01e48557863a4b6d4e75fe368e0185652aab09f', 'message': 'Improve share list speed using lazy=\'subquery\'\n\nlazy=\'immediate\' leads to each relationship being collected when\nit is accessed. This results in at least three extra queries when\nwe query for all share details. lazy=\'subquery\' collects all data\nwhen the query is executed. In this commit we only changed code for\nimproving the share list with details (""manila list"") speed.\n\nChange-Id: Ia61b108ece0817069737980a614cc6c15c1a3507\nCloses-Bug: #1859785\nCo-authored-by: Johannes Kulik <johannes.kulik@sap.com>\nCo-authored-by: Maurice Escher <maurice.escher@sap.com>\n(cherry picked from commit 54c5667e6b4a37270c4aed64b9a5ebd5f31bfa16)\n'}]",0,704850,f01e48557863a4b6d4e75fe368e0185652aab09f,13,7,1,16643,,,0,"Improve share list speed using lazy='subquery'

lazy='immediate' leads to each relationship being collected when
it is accessed. This results in at least three extra queries when
we query for all share details. lazy='subquery' collects all data
when the query is executed. In this commit we only changed code for
improving the share list with details (""manila list"") speed.

Change-Id: Ia61b108ece0817069737980a614cc6c15c1a3507
Closes-Bug: #1859785
Co-authored-by: Johannes Kulik <johannes.kulik@sap.com>
Co-authored-by: Maurice Escher <maurice.escher@sap.com>
(cherry picked from commit 54c5667e6b4a37270c4aed64b9a5ebd5f31bfa16)
",git fetch https://review.opendev.org/openstack/manila refs/changes/50/704850/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/db/sqlalchemy/models.py', 'releasenotes/notes/bug-1859785-share-list-speed-6b09e7717624e037.yaml']",2,f01e48557863a4b6d4e75fe368e0185652aab09f,bug/1859785-stable/train,--- fixes: - | Improved share list speed using lazy='subquery'. The sqlalchemy models of Share and Share Instance relationships previously had lazy='immediate'. This resulted in at least three extra queries when we queried for all share details. ,,10,3
openstack%2Fswift~stable%2Fstein~I36f0954fd9949d7d1404a0c381b917d1cfb17ec5,openstack/swift,stable/stein,I36f0954fd9949d7d1404a0c381b917d1cfb17ec5,s3api: Better handle 498/429 responses,MERGED,2020-01-28 18:39:59.000000000,2020-01-29 22:14:38.000000000,2020-01-29 22:09:13.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-28 18:39:59.000000000', 'files': ['swift/common/middleware/s3api/s3request.py', 'swift/common/http.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/778767f324e82dd7a075306cf8468aabbbc363b6', 'message': ""s3api: Better handle 498/429 responses\n\nCurrently, they just 500 as an unexpected response status. Much better\nwould be S3's '503 Slow Down' response.\n\nOf course, that's all dependent on where you place ratelimit in your\npipeline -- and we haven't really given clear guidance on that. I'm not\nactually sure you *want* ratelimit to be after s3api and auth... but if\nyou *do*, let's at least handle it gracefully.\n\nChange-Id: I36f0954fd9949d7d1404a0c381b917d1cfb17ec5\nRelated-Bug: 1669888\n(cherry picked from commit f33c061ae92f33ea467c58749d3f15d2b1cc942c)\n""}]",0,704659,778767f324e82dd7a075306cf8468aabbbc363b6,9,2,1,15343,,,0,"s3api: Better handle 498/429 responses

Currently, they just 500 as an unexpected response status. Much better
would be S3's '503 Slow Down' response.

Of course, that's all dependent on where you place ratelimit in your
pipeline -- and we haven't really given clear guidance on that. I'm not
actually sure you *want* ratelimit to be after s3api and auth... but if
you *do*, let's at least handle it gracefully.

Change-Id: I36f0954fd9949d7d1404a0c381b917d1cfb17ec5
Related-Bug: 1669888
(cherry picked from commit f33c061ae92f33ea467c58749d3f15d2b1cc942c)
",git fetch https://review.opendev.org/openstack/swift refs/changes/59/704659/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/s3api/s3request.py', 'swift/common/http.py']",2,778767f324e82dd7a075306cf8468aabbbc363b6,bug/1669888,HTTP_RATE_LIMITED = 498,,5,2
openstack%2Fdesignate~master~Idf29b90d79b7668218ce8a647358983b7deb457a,openstack/designate,master,Idf29b90d79b7668218ce8a647358983b7deb457a,Don't apply setup_colorized_logging when using mod_wsgi,ABANDONED,2019-10-23 06:55:51.000000000,2020-01-29 22:12:40.000000000,,"[{'_account_id': 8099}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-23 06:55:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/8810d3cc36135f96466e695e447df15db25f83e6', 'message': ""Don't apply setup_colorized_logging when using mod_wsgi\n\nChange-Id: Idf29b90d79b7668218ce8a647358983b7deb457a\n""}, {'number': 2, 'created': '2019-12-13 05:51:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/a3ce46b58089c42bd221ae1bf33753fd8c82fb80', 'message': ""Don't apply setup_colorized_logging when using mod_wsgi\n\nChange-Id: Idf29b90d79b7668218ce8a647358983b7deb457a\n""}, {'number': 3, 'created': '2019-12-16 20:03:49.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/designate/commit/2bd3b0a625eae39551c570115d647cef91440b62', 'message': ""Don't apply setup_colorized_logging when using mod_wsgi\n\nChange-Id: Idf29b90d79b7668218ce8a647358983b7deb457a\n""}]",0,690479,2bd3b0a625eae39551c570115d647cef91440b62,9,2,3,22623,,,0,"Don't apply setup_colorized_logging when using mod_wsgi

Change-Id: Idf29b90d79b7668218ce8a647358983b7deb457a
",git fetch https://review.opendev.org/openstack/designate refs/changes/79/690479/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,8810d3cc36135f96466e695e447df15db25f83e6,standard_wsgi," elif [ ""$LOG_COLOR"" == ""True"" ] && [ ""$DESIGNATE_WSGI_MODE"" != ""mod_wsgi"" ]; then"," fi # Format logging if [ ""$LOG_COLOR"" == ""True"" ] && [ ""$USE_SYSTEMD"" == ""False"" ]; then",1,4
openstack%2Fswift~stable%2Fstein~Iadb0a40092b8347eb5c04785cc14d1324cc9396f,openstack/swift,stable/stein,Iadb0a40092b8347eb5c04785cc14d1324cc9396f,s3api: Translate 503 to S3-style 503s,MERGED,2020-01-28 18:39:59.000000000,2020-01-29 22:12:05.000000000,2020-01-29 22:09:12.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-28 18:39:59.000000000', 'files': ['test/unit/common/middleware/s3api/test_obj.py', 'test/unit/common/middleware/s3api/test_bucket.py', 'swift/common/middleware/s3api/s3request.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/12893195d34e029fcdc643e2a91b35cbb899ba06', 'message': 's3api: Translate 503 to S3-style 503s\n\n...instead of logging tracebacks about unexpected status codes.\n\nChange-Id: Iadb0a40092b8347eb5c04785cc14d1324cc9396f\n(cherry picked from commit 7bb7da6d2dc4267f8279170b6d326e81777d3c06)\n'}]",0,704658,12893195d34e029fcdc643e2a91b35cbb899ba06,7,2,1,15343,,,0,"s3api: Translate 503 to S3-style 503s

...instead of logging tracebacks about unexpected status codes.

Change-Id: Iadb0a40092b8347eb5c04785cc14d1324cc9396f
(cherry picked from commit 7bb7da6d2dc4267f8279170b6d326e81777d3c06)
",git fetch https://review.opendev.org/openstack/swift refs/changes/58/704658/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/middleware/s3api/test_obj.py', 'test/unit/common/middleware/s3api/test_bucket.py', 'swift/common/middleware/s3api/s3request.py']",3,12893195d34e029fcdc643e2a91b35cbb899ba06,bug/1669888," HTTP_BAD_REQUEST, HTTP_REQUEST_TIMEOUT, HTTP_SERVICE_UNAVAILABLE, \ is_success BadDigest, AuthorizationHeaderMalformed, \ AuthorizationQueryParametersError, ServiceUnavailable if status == HTTP_SERVICE_UNAVAILABLE: raise ServiceUnavailable()"," HTTP_BAD_REQUEST, HTTP_REQUEST_TIMEOUT, is_success BadDigest, AuthorizationHeaderMalformed, AuthorizationQueryParametersError",28,6
openstack%2Fswift~stable%2Ftrain~I36f0954fd9949d7d1404a0c381b917d1cfb17ec5,openstack/swift,stable/train,I36f0954fd9949d7d1404a0c381b917d1cfb17ec5,s3api: Better handle 498/429 responses,MERGED,2020-01-28 17:57:40.000000000,2020-01-29 22:11:34.000000000,2020-01-29 22:09:11.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-28 17:57:40.000000000', 'files': ['swift/common/middleware/s3api/s3request.py', 'swift/common/http.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/092054da632037cd3632d8a2c85b7d2015998fff', 'message': ""s3api: Better handle 498/429 responses\n\nCurrently, they just 500 as an unexpected response status. Much better\nwould be S3's '503 Slow Down' response.\n\nOf course, that's all dependent on where you place ratelimit in your\npipeline -- and we haven't really given clear guidance on that. I'm not\nactually sure you *want* ratelimit to be after s3api and auth... but if\nyou *do*, let's at least handle it gracefully.\n\nChange-Id: I36f0954fd9949d7d1404a0c381b917d1cfb17ec5\nRelated-Bug: 1669888\n(cherry picked from commit f33c061ae92f33ea467c58749d3f15d2b1cc942c)\n""}]",0,704646,092054da632037cd3632d8a2c85b7d2015998fff,7,2,1,15343,,,0,"s3api: Better handle 498/429 responses

Currently, they just 500 as an unexpected response status. Much better
would be S3's '503 Slow Down' response.

Of course, that's all dependent on where you place ratelimit in your
pipeline -- and we haven't really given clear guidance on that. I'm not
actually sure you *want* ratelimit to be after s3api and auth... but if
you *do*, let's at least handle it gracefully.

Change-Id: I36f0954fd9949d7d1404a0c381b917d1cfb17ec5
Related-Bug: 1669888
(cherry picked from commit f33c061ae92f33ea467c58749d3f15d2b1cc942c)
",git fetch https://review.opendev.org/openstack/swift refs/changes/46/704646/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/s3api/s3request.py', 'swift/common/http.py']",2,092054da632037cd3632d8a2c85b7d2015998fff,bug/1669888,HTTP_RATE_LIMITED = 498,,5,2
openstack%2Fkeystone~stable%2Fstein~Icfce3b14abb55c6fef3de1b314cee22fc8b1d08c,openstack/keystone,stable/stein,Icfce3b14abb55c6fef3de1b314cee22fc8b1d08c,Fix role_assignments role.id filter,MERGED,2020-01-29 05:02:50.000000000,2020-01-29 21:48:03.000000000,2020-01-29 21:45:20.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 05:02:50.000000000', 'files': ['keystone/tests/unit/test_v3_assignment.py', 'keystone/tests/unit/protection/v3/test_assignment.py', 'keystone/tests/unit/test_v3.py', 'keystone/assignment/core.py', 'releasenotes/notes/bug-1858012-584267ada7e33f2c.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/af470fd6394af9758a277f05744dd4544bac09e5', 'message': ""Fix role_assignments role.id filter\n\nWithout this patch, if there are multiple role assignments on the system\nand they are not all the same role, querying for role assignments with\n/v3/role_assignments?role.id={role_id} may leak some role assignments\nthat don't match the role_id, making the returned results incorrect.\nThis patch fixes the issue by using a list comprehension instead of a\nfor loop over a list that was being modified within the loop.\n\nChange-Id: Icfce3b14abb55c6fef3de1b314cee22fc8b1d08c\nCloses-bug: #1858012\n(cherry picked from commit c2d88306621f890a857acd6831ea8bf073f55537)\n(cherry picked from commit 4d413f1eba2d1e6b16ecd57fa27de528dd0f67cb)\n""}]",0,704726,af470fd6394af9758a277f05744dd4544bac09e5,8,3,1,8482,,,0,"Fix role_assignments role.id filter

Without this patch, if there are multiple role assignments on the system
and they are not all the same role, querying for role assignments with
/v3/role_assignments?role.id={role_id} may leak some role assignments
that don't match the role_id, making the returned results incorrect.
This patch fixes the issue by using a list comprehension instead of a
for loop over a list that was being modified within the loop.

Change-Id: Icfce3b14abb55c6fef3de1b314cee22fc8b1d08c
Closes-bug: #1858012
(cherry picked from commit c2d88306621f890a857acd6831ea8bf073f55537)
(cherry picked from commit 4d413f1eba2d1e6b16ecd57fa27de528dd0f67cb)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/26/704726/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/test_v3_assignment.py', 'keystone/tests/unit/protection/v3/test_assignment.py', 'keystone/tests/unit/test_v3.py', 'keystone/assignment/core.py', 'releasenotes/notes/bug-1858012-584267ada7e33f2c.yaml']",5,af470fd6394af9758a277f05744dd4544bac09e5,assignment-role-filtering-stable-stein,--- fixes: - | [`bug 1858012 <https://bugs.launchpad.net/keystone/+bug/1858012>`_] Fixes a bug in the /v3/role_assignments filtering where the `role.id` query parameter didn't properly filter role assignments by role in cases where there were multiple system role assignments. ,,51,7
openstack%2Fopenstack-ansible-os_neutron~stable%2Ftrain~I1492af56e2e389b37cfc0e2818119729cd7ef733,openstack/openstack-ansible-os_neutron,stable/train,I1492af56e2e389b37cfc0e2818119729cd7ef733,Add extra rootwrap filter,MERGED,2020-01-29 12:11:11.000000000,2020-01-29 21:15:51.000000000,2020-01-29 21:14:16.000000000,"[{'_account_id': 22348}, {'_account_id': 28008}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-01-29 12:11:11.000000000', 'files': ['files/rootwrap.d/l3-extra.filters'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/b35e1994ddd01820d25343d4b29df787ffc99f0e', 'message': 'Add extra rootwrap filter\n\nDue to the fact the binary name that we use inside OSA is python2\nand there is no filter for it inside Neutron, killing processes\nfails and migrating routers will result in the old keepalived procs\nnot being killed off.\n\nChange-Id: I1492af56e2e389b37cfc0e2818119729cd7ef733\n'}]",0,704784,b35e1994ddd01820d25343d4b29df787ffc99f0e,10,3,1,1004,,,0,"Add extra rootwrap filter

Due to the fact the binary name that we use inside OSA is python2
and there is no filter for it inside Neutron, killing processes
fails and migrating routers will result in the old keepalived procs
not being killed off.

Change-Id: I1492af56e2e389b37cfc0e2818119729cd7ef733
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/84/704784/1 && git format-patch -1 --stdout FETCH_HEAD,['files/rootwrap.d/l3-extra.filters'],1,b35e1994ddd01820d25343d4b29df787ffc99f0e,,"# NOTE(mnaser): This file exists because we use `python2` for our binaries # and there is no filter upstream for this which means that # killing the keepalived monitors fails on OpenStack-Ansible # environments that run Python2. [Filters] kill_keepalived_monitor_py2: KillFilter, root, python2, -15 ",,7,0
openstack%2Ftripleo-heat-templates~master~I2c8a4a0270c99d76500ac42d90fffdc0475cb995,openstack/tripleo-heat-templates,master,I2c8a4a0270c99d76500ac42d90fffdc0475cb995,Use YAML anchors/aliases to reduce playbook task repetition,MERGED,2020-01-27 21:01:53.000000000,2020-01-29 21:04:51.000000000,2020-01-29 19:46:50.000000000,"[{'_account_id': 6816}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-27 21:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f7acf9e40d352e0b325555b15845c3a9e97f326d', 'message': 'Use YAML anchors/aliases to reduce playbook task repetition\n\nIt would appear that we use many of the same tasks in several\nof the plays. We can use anchors/alaises to reduce this\nrepetition This way we reduce the maintenance burden because\nwe only need to maintain it in one place.\n\nChange-Id: I2c8a4a0270c99d76500ac42d90fffdc0475cb995\n'}, {'number': 2, 'created': '2020-01-27 21:12:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b15087aed179ffa79d009f0b822d86e59c0e7300', 'message': 'Use YAML anchors/aliases to reduce playbook task repetition\n\nIt would appear that we use many of the same tasks in several\nof the plays. We can use anchors/alaises to reduce this\nrepetition This way we reduce the maintenance burden because\nwe only need to maintain it in one place.\n\nChange-Id: I2c8a4a0270c99d76500ac42d90fffdc0475cb995\n'}, {'number': 3, 'created': '2020-01-28 11:19:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b29dd132d23b746d7a9ad6eb6ccd2e18003cb4ac', 'message': 'Use YAML anchors/aliases to reduce playbook task repetition\n\nIt would appear that we use many of the same tasks in several\nof the plays. We can use anchors/alaises to reduce this\nrepetition This way we reduce the maintenance burden because\nwe only need to maintain it in one place.\n\nChange-Id: I2c8a4a0270c99d76500ac42d90fffdc0475cb995\n'}, {'number': 4, 'created': '2020-01-29 09:50:45.000000000', 'files': ['common/deploy-steps.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bc4df9c5a994183c71347691e9eb3633e1c00951', 'message': 'Use YAML anchors/aliases to reduce playbook task repetition\n\nIt would appear that we use many of the same tasks in several\nof the plays. We can use anchors/alaises to reduce this\nrepetition This way we reduce the maintenance burden because\nwe only need to maintain it in one place.\n\nChange-Id: I2c8a4a0270c99d76500ac42d90fffdc0475cb995\n'}]",2,704426,bc4df9c5a994183c71347691e9eb3633e1c00951,19,7,4,6816,,,0,"Use YAML anchors/aliases to reduce playbook task repetition

It would appear that we use many of the same tasks in several
of the plays. We can use anchors/alaises to reduce this
repetition This way we reduce the maintenance burden because
we only need to maintain it in one place.

Change-Id: I2c8a4a0270c99d76500ac42d90fffdc0475cb995
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/26/704426/1 && git format-patch -1 --stdout FETCH_HEAD,['common/deploy-steps.j2'],1,f7acf9e40d352e0b325555b15845c3a9e97f326d,ffwd-upgrade2, - &gather_facts_undercloud hosts: DEPLOY_SOURCE_HOST - &gather_facts_overcloud hosts: DEPLOY_TARGET_HOST - &load_global_variables hosts: all - &render_overcloud_group_vars hosts: DEPLOY_TARGET_HOST - &set_overcloud_group_vars hosts: DEPLOY_TARGET_HOST - *gather_facts_undercloud - *gather_facts_overcloud - *load_global_variables - *render_overcloud_group_vars - *set_overcloud_group_vars - *gather_facts_undercloud - *gather_facts_overcloud - *load_global_variables - *render_overcloud_group_vars - *set_overcloud_group_vars - *gather_facts_undercloud - *gather_facts_overcloud - *load_global_variables - *render_overcloud_group_vars - *set_overcloud_group_vars - <<: *gather_facts_undercloud - <<: *gather_facts_overcloud ignore_unreachable: True - *load_global_variables - *render_overcloud_group_vars - *set_overcloud_group_vars," - hosts: DEPLOY_SOURCE_HOST - hosts: DEPLOY_TARGET_HOST - hosts: all - hosts: DEPLOY_TARGET_HOST - hosts: DEPLOY_TARGET_HOST - hosts: DEPLOY_SOURCE_HOST name: Gather facts from undercloud gather_facts: yes become: false - hosts: DEPLOY_TARGET_HOST name: Gather facts from overcloud gather_facts: yes - hosts: all name: Load global variables gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - include_vars: global_vars.yaml no_log: true - hosts: DEPLOY_TARGET_HOST name: Render all_nodes data as group_vars for overcloud gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - name: Render all_nodes data as group_vars for overcloud delegate_to: localhost become: false run_once: true when: not ansible_check_mode|bool block: - name: Get current user command: whoami register: whoami - name: render all_nodes data as group_vars for overcloud template: src: ""{{ '{{' }} lookup('first_found', lookup('config', 'DEFAULT_ROLES_PATH') | map('regex_replace', '$', '/tripleo-hieradata') | list) ~ '/templates/all_nodes.j2' {{ '}}'}}"" dest: ""{{ '{{' }} playbook_dir {{ '}}' }}/group_vars/overcloud.json"" owner: ""{{ '{{' }} whoami.stdout {{ '}}' }}"" group: ""{{ '{{' }} whoami.stdout {{ '}}' }}"" tags: - facts - hosts: DEPLOY_TARGET_HOST name: Set all_nodes data as group_vars for overcloud gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - name: Set all_nodes data as group_vars for overcloud include_vars: ""{{ '{{ ' }} playbook_dir {{ ' }}' }}/group_vars/overcloud.json"" no_log: true when: not ansible_check_mode|bool tags: - facts - hosts: DEPLOY_SOURCE_HOST:DEPLOY_TARGET_HOST name: Gather facts from undercloud gather_facts: no become: false tags: always tasks: - name: Force facts refresh before upgrade. setup: - hosts: all name: Load global variables gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - include_vars: global_vars.yaml no_log: true - name: ensure we get the right selinux context command: chcon -R -t svirt_sandbox_file_t /var/lib/config-data args: warn: no tags: - always - hosts: DEPLOY_TARGET_HOST name: Render all_nodes data as group_vars for overcloud gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - name: Render all_nodes data as group_vars for overcloud delegate_to: localhost become: false run_once: true when: not ansible_check_mode|bool block: - name: Get current user command: whoami register: whoami - name: render all_nodes data as group_vars for overcloud template: src: ""{{ '{{' }} lookup('first_found', lookup('config', 'DEFAULT_ROLES_PATH') | map('regex_replace', '$', '/tripleo-hieradata') | list) ~ '/templates/all_nodes.j2' {{ '}}'}}"" dest: ""{{ '{{' }} playbook_dir {{ '}}' }}/group_vars/overcloud.json"" owner: ""{{ '{{' }} whoami.stdout {{ '}}' }}"" group: ""{{ '{{' }} whoami.stdout {{ '}}' }}"" tags: - facts - hosts: DEPLOY_TARGET_HOST name: Set all_nodes data as group_vars for overcloud gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - name: Set all_nodes data as group_vars for overcloud include_vars: ""{{ '{{ ' }} playbook_dir {{ ' }}' }}/group_vars/overcloud.json"" no_log: true when: not ansible_check_mode|bool tags: - facts - hosts: DEPLOY_SOURCE_HOST name: Gather facts from undercloud gather_facts: yes become: false tags: - always - facts # facts from overcloud may be needed for external installer inventory - hosts: DEPLOY_TARGET_HOST name: Gather facts from overcloud gather_facts: yes tags: - always - facts - hosts: all name: Load global variables gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - include_vars: global_vars.yaml no_log: true tags: - always - hosts: DEPLOY_TARGET_HOST name: Render all_nodes data as group_vars for overcloud gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - name: Render all_nodes data as group_vars for overcloud delegate_to: localhost become: false run_once: true when: not ansible_check_mode|bool block: - name: Get current user command: whoami register: whoami - name: render all_nodes data as group_vars for overcloud template: src: ""{{ '{{' }} lookup('first_found', lookup('config', 'DEFAULT_ROLES_PATH') | map('regex_replace', '$', '/tripleo-hieradata') | list) ~ '/templates/all_nodes.j2' {{ '}}'}}"" dest: ""{{ '{{' }} playbook_dir {{ '}}' }}/group_vars/overcloud.json"" owner: ""{{ '{{' }} whoami.stdout {{ '}}' }}"" group: ""{{ '{{' }} whoami.stdout {{ '}}' }}"" tags: - facts - hosts: DEPLOY_TARGET_HOST name: Set all_nodes data as group_vars for overcloud gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - name: Set all_nodes data as group_vars for overcloud include_vars: ""{{ '{{ ' }} playbook_dir {{ ' }}' }}/group_vars/overcloud.json"" no_log: true when: not ansible_check_mode|bool tags: - facts - hosts: DEPLOY_SOURCE_HOST:DEPLOY_TARGET_HOST name: Gather facts from overcloud gather_facts: no tags: - always - facts tasks: - name: Force facts refresh before scale. setup: - hosts: all name: Load global variables gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - include_vars: global_vars.yaml no_log: true tags: - always - hosts: DEPLOY_TARGET_HOST name: Render all_nodes data as group_vars for overcloud gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - name: Render all_nodes data as group_vars for overcloud delegate_to: localhost become: false run_once: true when: not ansible_check_mode|bool block: - name: Get current user command: whoami register: whoami - name: render all_nodes data as group_vars for overcloud template: src: ""{{ '{{' }} lookup('first_found', lookup('config', 'DEFAULT_ROLES_PATH') | map('regex_replace', '$', '/tripleo-hieradata') | list) ~ '/templates/all_nodes.j2' {{ '}}'}}"" dest: ""{{ '{{' }} playbook_dir {{ '}}' }}/group_vars/overcloud.json"" owner: ""{{ '{{' }} whoami.stdout {{ '}}' }}"" group: ""{{ '{{' }} whoami.stdout {{ '}}' }}"" tags: - facts - hosts: DEPLOY_TARGET_HOST name: Set all_nodes data as group_vars for overcloud gather_facts: {{ '""{{' }} gather_facts | default(false) {{ '}}""' }} tasks: - name: Set all_nodes data as group_vars for overcloud include_vars: ""{{ '{{ ' }} playbook_dir {{ ' }}' }}/group_vars/overcloud.json"" no_log: true when: not ansible_check_mode|bool tags: - facts",31,202
openstack%2Fproject-config~master~I37572eab88453ffc820b63c95b549cd69c91548c,openstack/project-config,master,I37572eab88453ffc820b63c95b549cd69c91548c,Allow python-storyboardclient direct release,MERGED,2020-01-29 16:33:36.000000000,2020-01-29 20:47:17.000000000,2020-01-29 20:47:17.000000000,"[{'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 16:33:36.000000000', 'files': ['gerrit/acls/opendev/python-storyboardclient.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/066a86007d060540ffe473ad7380caa338b4a106', 'message': 'Allow python-storyboardclient direct release\n\nStoryboard like other opendev software is released by pushing tags\ndirectly, and not by going through the OpenStack release management team\ntooling. However, python-storyboardclient still used openstack/releases,\nas there was no ACL to allow for direct tagging.\n\nThis adds the ability for the (already-existing)\npython-storyboardclient-release group to push tags. The corresponding\ndeliverable file in openstack/releases will be removed.\n\nChange-Id: I37572eab88453ffc820b63c95b549cd69c91548c\n'}]",0,704837,066a86007d060540ffe473ad7380caa338b4a106,7,3,1,308,,,0,"Allow python-storyboardclient direct release

Storyboard like other opendev software is released by pushing tags
directly, and not by going through the OpenStack release management team
tooling. However, python-storyboardclient still used openstack/releases,
as there was no ACL to allow for direct tagging.

This adds the ability for the (already-existing)
python-storyboardclient-release group to push tags. The corresponding
deliverable file in openstack/releases will be removed.

Change-Id: I37572eab88453ffc820b63c95b549cd69c91548c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/37/704837/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/opendev/python-storyboardclient.config'],1,066a86007d060540ffe473ad7380caa338b4a106,opendev-release-acl-fix,"[access ""refs/tags/*""] pushSignedTag = group python-storyboardclient-release ",,3,0
openstack%2Ftripleo-ansible~master~I92113589b98d7c1f9c05e1ea0938a03d95b7dd15,openstack/tripleo-ansible,master,I92113589b98d7c1f9c05e1ea0938a03d95b7dd15,Add action plugin for all_nodes data,MERGED,2020-01-23 17:23:16.000000000,2020-01-29 20:37:50.000000000,2020-01-28 21:28:43.000000000,"[{'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2020-01-23 17:23:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/99873c19935230b7eb6514ce134b3070d3a7fb14', 'message': 'Add action plugin for all_nodes data\n\nThis patch adds an action plugin to render the all_nodes group_vars for\nthe overcloud. This plugin will produce the same json structure as the\nall_nodes.j2 template in the tripleo-heiradata role. Once\ndeploy_steps_playbook.yaml is migrated over to use the new action\nplugin, the all_nodes.j2 template can be removed.\n\nAt scale, the template was taking an unusual amount of time to render.\nSwitching to native python with the action plugin results in improved\nperformance. In a 150 node environment, using the action plugin dropped\nthe render time from 7 minutes to 30 seconds.\n\nChange-Id: I92113589b98d7c1f9c05e1ea0938a03d95b7dd15\n'}, {'number': 2, 'created': '2020-01-23 17:25:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/729c0e74eff1a9bbee8b256c26936c2618b91923', 'message': 'Add action plugin for all_nodes data\n\nThis patch adds an action plugin to render the all_nodes group_vars for\nthe overcloud. This plugin will produce the same json structure as the\nall_nodes.j2 template in the tripleo-heiradata role. Once\ndeploy_steps_playbook.yaml is migrated over to use the new action\nplugin, the all_nodes.j2 template can be removed.\n\nAt scale, the template was taking an unusual amount of time to render.\nSwitching to native python with the action plugin results in improved\nperformance. In a 150 node environment, using the action plugin dropped\nthe render time from 7 minutes to 30 seconds.\n\nUsing an action plugin will also allow more easier unit testing (to be\nforthcoming), and also add the opportunity to use debug statements to\nshow errors.\n\nChange-Id: I92113589b98d7c1f9c05e1ea0938a03d95b7dd15\n'}, {'number': 3, 'created': '2020-01-23 19:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/db5ca650b39b1664b8eb707ac90e6c881e90fc3f', 'message': 'Add action plugin for all_nodes data\n\nThis patch adds an action plugin to render the all_nodes group_vars for\nthe overcloud. This plugin will produce the same json structure as the\nall_nodes.j2 template in the tripleo-heiradata role. Once\ndeploy_steps_playbook.yaml is migrated over to use the new action\nplugin, the all_nodes.j2 template can be removed.\n\nAt scale, the template was taking an unusual amount of time to render.\nSwitching to native python with the action plugin results in improved\nperformance. In a 150 node environment, using the action plugin dropped\nthe render time from 7 minutes to 30 seconds.\n\nUsing an action plugin will also allow more easier unit testing (to be\nforthcoming), and also add the opportunity to use debug statements to\nshow errors.\n\nChange-Id: I92113589b98d7c1f9c05e1ea0938a03d95b7dd15\n'}, {'number': 4, 'created': '2020-01-23 21:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/10184025874b191be8cdb3650642c3342a0e76cb', 'message': 'Add action plugin for all_nodes data\n\nThis patch adds an action plugin to render the all_nodes group_vars for\nthe overcloud. This plugin will produce the same json structure as the\nall_nodes.j2 template in the tripleo-heiradata role. Once\ndeploy_steps_playbook.yaml is migrated over to use the new action\nplugin, the all_nodes.j2 template can be removed.\n\nAt scale, the template was taking an unusual amount of time to render.\nSwitching to native python with the action plugin results in improved\nperformance. In a 150 node environment, using the action plugin dropped\nthe render time from 7 minutes to 30 seconds.\n\nUsing an action plugin will also allow more easier unit testing (to be\nforthcoming), and also add the opportunity to use debug statements to\nshow errors.\n\nChange-Id: I92113589b98d7c1f9c05e1ea0938a03d95b7dd15\n'}, {'number': 5, 'created': '2020-01-24 15:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/97658529130b371993fafd7cf151431b25b3bc61', 'message': 'Add action plugin for all_nodes data\n\nThis patch adds an action plugin to render the all_nodes group_vars for\nthe overcloud. This plugin will produce the same json structure as the\nall_nodes.j2 template in the tripleo-heiradata role. Once\ndeploy_steps_playbook.yaml is migrated over to use the new action\nplugin, the all_nodes.j2 template can be removed.\n\nAt scale, the template was taking an unusual amount of time to render.\nSwitching to native python with the action plugin results in improved\nperformance. In a 150 node environment, using the action plugin dropped\nthe render time from 7 minutes to 30 seconds.\n\nUsing an action plugin will also allow more easier unit testing (to be\nforthcoming), and also add the opportunity to use debug statements to\nshow errors.\n\nChange-Id: I92113589b98d7c1f9c05e1ea0938a03d95b7dd15\n'}, {'number': 6, 'created': '2020-01-24 16:57:51.000000000', 'files': ['tripleo_ansible/ansible_plugins/action/tripleo_all_nodes_data.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/918452da7f456d32afa7b3cc000aa28bd96e7bb8', 'message': 'Add action plugin for all_nodes data\n\nThis patch adds an action plugin to render the all_nodes group_vars for\nthe overcloud. This plugin will produce the same json structure as the\nall_nodes.j2 template in the tripleo-heiradata role. Once\ndeploy_steps_playbook.yaml is migrated over to use the new action\nplugin, the all_nodes.j2 template can be removed.\n\nAt scale, the template was taking an unusual amount of time to render.\nSwitching to native python with the action plugin results in improved\nperformance. In a 150 node environment, using the action plugin dropped\nthe render time from 7 minutes to 30 seconds.\n\nUsing an action plugin will also allow more easier unit testing (to be\nforthcoming), and also add the opportunity to use debug statements to\nshow errors.\n\nChange-Id: I92113589b98d7c1f9c05e1ea0938a03d95b7dd15\n'}]",2,704041,918452da7f456d32afa7b3cc000aa28bd96e7bb8,30,7,6,7144,,,0,"Add action plugin for all_nodes data

This patch adds an action plugin to render the all_nodes group_vars for
the overcloud. This plugin will produce the same json structure as the
all_nodes.j2 template in the tripleo-heiradata role. Once
deploy_steps_playbook.yaml is migrated over to use the new action
plugin, the all_nodes.j2 template can be removed.

At scale, the template was taking an unusual amount of time to render.
Switching to native python with the action plugin results in improved
performance. In a 150 node environment, using the action plugin dropped
the render time from 7 minutes to 30 seconds.

Using an action plugin will also allow more easier unit testing (to be
forthcoming), and also add the opportunity to use debug statements to
show errors.

Change-Id: I92113589b98d7c1f9c05e1ea0938a03d95b7dd15
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/41/704041/6 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/ansible_plugins/action/tripleo_all_nodes_data.py'],1,99873c19935230b7eb6514ce134b3070d3a7fb14,,"# Copyright 2020 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. DOCUMENTATION = """""" --- module: tripleo_all_nodes_data author: - James Slagle (@slagle) <jslagle@redhat.com> version_added: '2.8' short_description: Renders the all_nodes data for TripleO as group_vars notes: [] description: - This module redners the all_nodes data for TripleO as group_vars which are then available on overcloud nodes. options: """""" EXAMPLES = """""" - name: Render all_nodes data tripleo_all_nodes_data: """""" import json import os from ansible.plugins.action import ActionBase from ansible.plugins.filter import ipaddr from ansible.utils.display import Display DISPLAY = Display() class ActionModule(ActionBase): """"""Renders the all_nodes data for TripleO as group_vars"""""" def run(self, tmp=None, task_vars=None): """"""Renders the all_nodes data for TripleO as group_vars"""""" # Internal Ansible objects for inventory and variables inventory = self._task.get_variable_manager()._inventory groups = inventory.get_groups_dict() # host_vars h_vars = self._task.get_variable_manager().get_vars()['hostvars'] # Needed tripleo variables for convenience service_net_map = task_vars['service_net_map'] nova_additional_cell = task_vars['nova_additional_cell'] all_nodes_extra_map_data = task_vars['all_nodes_extra_map_data'] net_vip_map = task_vars['net_vip_map'] enabled_services = task_vars['enabled_services'] primary_role_name = task_vars['primary_role_name'] all_nodes = {} enabled_services += all_nodes_extra_map_data.get('enabled_services', []) # make enabled_services unique enabled_services = list(set(enabled_services)) all_nodes['enabled_services'] = enabled_services for service in enabled_services: DISPLAY.vv(""Computing data for %s"" % service) # <service>_enabled: true all_nodes[service + '_enabled'] = True # <service>_node_ips: <list of ips> DISPLAY.vv("" Computing data for service_node_ips"") service_network = service_net_map.get(service + '_network', 'ctlplane') service_hosts = groups.get(service, []) service_node_ips = list(map(lambda host: h_vars[host][service_network + '_ip'], service_hosts)) for extra_node_ip in all_nodes_extra_map_data.get(service + '_node_ips', []): if extra_node_ip not in service_node_ips: service_node_ips.append(extra_node_ip) all_nodes[service + '_node_ips'] = service_node_ips if nova_additional_cell: # <service>_cell_node_names: <list of hostnames> service_cell_node_names = \ list(map(lambda host: h_vars[host][service_network + '_hostname'], service_hosts)) all_nodes[service + '_cell_node_names'] = service_cell_node_names else: # <service>_node_names: <list of hostnames> DISPLAY.vv("" Computing data for service_node_names"") service_node_names = \ list(map(lambda host: h_vars[host][service_network + '_hostname'], service_hosts)) for extra_node_name in all_nodes_extra_map_data.get(service + '_node_names', []): if extra_node_name not in service_node_names: service_node_names.append(extra_node_name) all_nodes[service + '_node_names'] = service_node_names # <service>_short_node_names: <list of hostnames> DISPLAY.vv("" Computing data for service_short_node_names"") service_short_node_names = \ list(map(lambda host: h_vars[host]['inventory_hostname'], service_hosts)) for extra_short_node_name in all_nodes_extra_map_data.get(service + '_short_node_names', []): if extra_short_node_name not in service_node_names: service_short_node_names.append(extra_short_node_name) all_nodes[service + '_short_node_names'] = service_short_node_names # <service>_short_bootstrap_node_name: hostname DISPLAY.vv("" Computing data for service_short_bootstrap_node_name"") if all_nodes_extra_map_data.get(service + '_short_bootstrap_node_name', None): service_hosts += all_nodes_extra_map_data[service + '_short_bootstrap_node_name'] service_hosts.sort() if service_hosts: all_nodes[service + '_short_bootstrap_node_name'] = service_hosts[0] # <service>_bootstrap_node_ip: hostname DISPLAY.vv("" Computing data for service_short_bootstrap_node_ip"") if all_nodes_extra_map_data.get(service + '_bootstrap_node_ip', None): service_bootstrap_node_ips = service_node_ips + all_nodes_extra_map_data[service + '_bootstrap_node_ip'] else: service_bootstrap_node_ips = service_node_ips if service_bootstrap_node_ips : all_nodes[service + '_bootstrap_node_ip'] = service_bootstrap_node_ips[0] # <service>: service_network DISPLAY.vv(""Computing data for service_net_map"") for key, value in service_net_map.items(): all_nodes[key] = value # all values from all_nodes_extra_map_data when nova_additional_cell if nova_additional_cell: for key, value in all_nodes_extra_map_data.items(): all_nodes[key] = value # redis_vip: ip DISPLAY.vv(""Computing data for redis_vip"") if 'redis' in enabled_services or nova_additional_cell: if 'redis_vip' in all_nodes_extra_map_data: all_nodes['redis_vip'] = all_nodes_extra_map_data['redis_vip'] elif 'redis' in net_vip_map: all_nodes['redis_vip'] = net_vip_map['redis'] # ovn_dbs_vip: ip DISPLAY.vv(""Computing data for ovn_dbs_vip"") if 'ovn_dbs' in enabled_services or nova_additional_cell: if 'ovn_dbs_vip' in all_nodes_extra_map_data: all_nodes['ovn_dbs_vip'] = all_nodes_extra_map_data['ovn_dbs_vip'] elif 'ovn_dbs' in net_vip_map: all_nodes['ovn_dbs_vip'] = net_vip_map['ovn_dbs'] DISPLAY.vv(""Computing data for top level vars"") all_nodes['deploy_identifier'] = task_vars['deploy_identifier'] all_nodes['stack_action'] = task_vars['stack_action'] all_nodes['stack_update_type'] = task_vars['stack_update_type'] all_nodes['container_cli'] = task_vars['container_cli'] # controller_node_<ips/names> # note that these are supposed to be strings, not lists DISPLAY.vv(""Computing data for controller node ips/names"") primary_hosts = groups.get(primary_role_name, []) all_nodes['controller_node_ips'] = ','.join(list(map(lambda host: h_vars[host]['ctlplane_ip'], primary_hosts))) all_nodes['controller_node_names'] = ','.join(list(map(lambda host: h_vars[host]['inventory_hostname'], primary_hosts))) all_nodes_path = os.path.join(task_vars['playbook_dir'], 'group_vars', 'overcloud.json') with open(all_nodes_path, 'w') as f: json.dump(all_nodes, f, sort_keys=True, indent=4) return {} ",,183,0
openstack%2Fopenstack-helm-infra~master~I621325e4a9d27d3ab0d0bc30b4926ea0fa3fd17e,openstack/openstack-helm-infra,master,I621325e4a9d27d3ab0d0bc30b4926ea0fa3fd17e,Update audit user access for Mariadb,MERGED,2020-01-28 17:08:23.000000000,2020-01-29 20:27:02.000000000,2020-01-29 20:23:25.000000000,"[{'_account_id': 16881}, {'_account_id': 17591}, {'_account_id': 18236}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22636}]","[{'number': 1, 'created': '2020-01-28 17:08:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/22a96a22ba0b5b155de6760347fc9abae32d9174', 'message': 'Update audit user access for Mariadb\n\nThe audit user is granted SELECT permission\nfor all Mariadb databases and tables.\n\nChange-Id: I621325e4a9d27d3ab0d0bc30b4926ea0fa3fd17e\n'}, {'number': 2, 'created': '2020-01-28 20:36:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c516d20a86bcfb2c8871f034c5abad74aa3546d6', 'message': 'Update audit user access for Mariadb\n\nThe audit user is granted SELECT permission\nfor all Mariadb databases and tables.\n\nChange-Id: I621325e4a9d27d3ab0d0bc30b4926ea0fa3fd17e\n'}, {'number': 3, 'created': '2020-01-28 23:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9c7b665b498b3ef59e348d7c10b7cecaa8122138', 'message': 'Update audit user access for Mariadb\n\nThe audit user is granted SELECT permission\nfor all Mariadb databases and tables.\n\nChange-Id: I621325e4a9d27d3ab0d0bc30b4926ea0fa3fd17e\n'}, {'number': 4, 'created': '2020-01-29 18:11:45.000000000', 'files': ['mariadb/templates/bin/_start.py.tpl', 'mariadb/templates/statefulset.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/d135e2c964391c9cbf17e15ab55bbfd6c5a32ab9', 'message': 'Update audit user access for Mariadb\n\nThe audit user is granted SELECT permission\nfor all Mariadb databases and tables.\n\nChange-Id: I621325e4a9d27d3ab0d0bc30b4926ea0fa3fd17e\n'}]",1,704635,d135e2c964391c9cbf17e15ab55bbfd6c5a32ab9,21,7,4,18236,,,0,"Update audit user access for Mariadb

The audit user is granted SELECT permission
for all Mariadb databases and tables.

Change-Id: I621325e4a9d27d3ab0d0bc30b4926ea0fa3fd17e
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/35/704635/4 && git format-patch -1 --stdout FETCH_HEAD,['mariadb/templates/bin/_start.py.tpl'],1,22a96a22ba0b5b155de6760347fc9abae32d9174,," ""GRANT SELECT ON *.* TO '{4}'@'%' ;\n"" ""GRANT SELECT ON *.* TO '{4}'@'%' ;\n"""," ""GRANT SELECT ON mysql.user TO '{4}'@'%' ;\n"" ""GRANT SELECT ON mysql.user TO '{4}'@'%' ;\n""",2,2
openstack%2Foctavia~stable%2Fqueens~Ifed862639d3fc3de23ace4c7ceaea1a4eca62749,openstack/octavia,stable/queens,Ifed862639d3fc3de23ace4c7ceaea1a4eca62749,Add listener and pool protocol validation,MERGED,2020-01-11 20:14:11.000000000,2020-01-29 19:54:57.000000000,2020-01-29 19:53:12.000000000,"[{'_account_id': 6469}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 28329}, {'_account_id': 29244}]","[{'number': 1, 'created': '2020-01-11 20:14:11.000000000', 'files': ['api-ref/source/parameters.yaml', 'releasenotes/notes/add-protocol-validation-0f9129a045e372ce.yaml', 'octavia/tests/functional/api/v2/test_l7policy.py', 'octavia/tests/functional/api/v2/base.py', 'api-ref/source/v2/general.inc', 'octavia/tests/functional/api/v2/test_pool.py', 'octavia/common/constants.py', 'octavia/api/v2/controllers/pool.py', 'octavia/api/v2/controllers/l7policy.py', 'octavia/tests/functional/api/v2/test_load_balancer.py', 'octavia/tests/common/constants.py', 'octavia/tests/functional/api/v2/test_listener.py', 'octavia/api/v2/controllers/base.py', 'octavia/api/v2/controllers/listener.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/e3ddec776da4654517a237287c05298a9280e52f', 'message': ""Add listener and pool protocol validation\n\nThe pool and listener can't be combined arbitrarily. We need to add\nsome constraints in protocol side.\n\nStory: 2003500\nTasks: 24777\n\nCo-Authored-By: Carlos Goncalves <cgoncalves@redhat.com>\nChange-Id: Ifed862639d3fc3de23ace4c7ceaea1a4eca62749\n(cherry picked from commit 47e0ef31bcfd34838fac4c619b699edd65e20223)\n(cherry picked from commit 87704d42f42156bbb60138b86e34ea86f84629fe)\n(cherry picked from commit 1f37a73eb96f8115abf9da2243dc84a6ca9ade1d)\n(cherry picked from commit 34545524b6cc194c788172aaf3e565513f2e4d74)\n""}]",0,702102,e3ddec776da4654517a237287c05298a9280e52f,40,6,1,6469,,,0,"Add listener and pool protocol validation

The pool and listener can't be combined arbitrarily. We need to add
some constraints in protocol side.

Story: 2003500
Tasks: 24777

Co-Authored-By: Carlos Goncalves <cgoncalves@redhat.com>
Change-Id: Ifed862639d3fc3de23ace4c7ceaea1a4eca62749
(cherry picked from commit 47e0ef31bcfd34838fac4c619b699edd65e20223)
(cherry picked from commit 87704d42f42156bbb60138b86e34ea86f84629fe)
(cherry picked from commit 1f37a73eb96f8115abf9da2243dc84a6ca9ade1d)
(cherry picked from commit 34545524b6cc194c788172aaf3e565513f2e4d74)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/02/702102/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/parameters.yaml', 'releasenotes/notes/add-protocol-validation-0f9129a045e372ce.yaml', 'octavia/tests/functional/api/v2/test_l7policy.py', 'octavia/tests/functional/api/v2/base.py', 'api-ref/source/v2/general.inc', 'octavia/tests/functional/api/v2/test_pool.py', 'octavia/common/constants.py', 'octavia/api/v2/controllers/pool.py', 'octavia/api/v2/controllers/l7policy.py', 'octavia/tests/functional/api/v2/test_load_balancer.py', 'octavia/tests/common/constants.py', 'octavia/tests/functional/api/v2/test_listener.py', 'octavia/api/v2/controllers/base.py', 'octavia/api/v2/controllers/listener.py']",14,e3ddec776da4654517a237287c05298a9280e52f,," def _validate_pool(self, session, lb_id, pool_id, listener_protocol): self._validate_protocol(listener_protocol, db_pool.protocol) listener_dict['default_pool_id'], listener.protocol) listener_dict['default_pool_id'], listener_dict['protocol']) listener.default_pool_id, db_listener.protocol)"," def _validate_pool(self, session, lb_id, pool_id): listener_dict['default_pool_id']) listener_dict['default_pool_id']) listener.default_pool_id)",396,16
openstack%2Fpython-dracclient~stable%2Ftrain~I9b9ddfe44ff778d061f76b607f5cfa45f981a4fe,openstack/python-dracclient,stable/train,I9b9ddfe44ff778d061f76b607f5cfa45f981a4fe,Fix pointer to upper_constraints.txt,MERGED,2019-11-06 21:48:20.000000000,2020-01-29 19:15:26.000000000,2020-01-29 19:15:26.000000000,"[{'_account_id': 8068}, {'_account_id': 10644}, {'_account_id': 22348}, {'_account_id': 23847}]","[{'number': 1, 'created': '2019-11-06 21:48:20.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-dracclient/commit/895ad93726a7d80a7dec582f43aa6a364efe3e50', 'message': 'Fix pointer to upper_constraints.txt\n\nThis patch corrects the pointer to upper_constraints.txt so that it\nuses the one on the stable/train branch.\n\nChange-Id: I9b9ddfe44ff778d061f76b607f5cfa45f981a4fe\n'}]",0,693259,895ad93726a7d80a7dec582f43aa6a364efe3e50,7,4,1,10250,,,0,"Fix pointer to upper_constraints.txt

This patch corrects the pointer to upper_constraints.txt so that it
uses the one on the stable/train branch.

Change-Id: I9b9ddfe44ff778d061f76b607f5cfa45f981a4fe
",git fetch https://review.opendev.org/openstack/python-dracclient refs/changes/59/693259/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,895ad93726a7d80a7dec582f43aa6a364efe3e50,fix_ref,install_command = pip install -U -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/stable/train/upper-constraints.txt} {opts} {packages} -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/stable/train/upper-constraints.txt},install_command = pip install -U -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt} {opts} {packages} -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt},2,2
openstack%2Fswift~master~I331b6871e5b62f61809338a1abddafe1263e7f02,openstack/swift,master,I331b6871e5b62f61809338a1abddafe1263e7f02,s3api: use native strings in s3api.auth_details access_key,MERGED,2020-01-27 20:13:07.000000000,2020-01-29 19:12:59.000000000,2020-01-29 19:10:20.000000000,"[{'_account_id': 1179}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-27 20:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2966ba27d3ebab4800ef1d629603187d45881133', 'message': 's3api: use native strings in s3api.auth_details access_key\n\nChange-Id: I331b6871e5b62f61809338a1abddafe1263e7f02\n'}, {'number': 2, 'created': '2020-01-27 22:01:07.000000000', 'files': ['swift/common/middleware/s3api/s3request.py', 'test/unit/common/middleware/s3api/test_s3api.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/bd063b678992a710f423a86d392a34237a8379ba', 'message': 's3api: use native strings in s3api.auth_details access_key\n\nChange-Id: I331b6871e5b62f61809338a1abddafe1263e7f02\n'}]",2,704413,bd063b678992a710f423a86d392a34237a8379ba,18,3,2,15343,,,0,"s3api: use native strings in s3api.auth_details access_key

Change-Id: I331b6871e5b62f61809338a1abddafe1263e7f02
",git fetch https://review.opendev.org/openstack/swift refs/changes/13/704413/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/s3api/s3request.py', 'test/unit/common/middleware/s3api/test_s3api.py']",2,2966ba27d3ebab4800ef1d629603187d45881133,," def test_non_ascii_user(self): self.swift.register('HEAD', '/v1/AUTH_test/bucket+segments/' 'object/123456789abcdef', swob.HTTPOk, {}, None) self.swift.register('PUT', '/v1/AUTH_test/bucket+segments/' 'object/123456789abcdef/1', swob.HTTPCreated, {}, None) req = Request.blank('/bucket/object?uploadId=123456789abcdef' '&partNumber=1', environ={'REQUEST_METHOD': 'PUT'}) # NB: WSGI string for a snowman req.headers['Authorization'] = 'AWS test:\xe2\x98\x83:sig' date_header = self.get_date_header() req.headers['Date'] = date_header with mock.patch('swift.common.middleware.s3api.s3request.' 'S3Request.check_signature') as mock_cs: status, headers, body = self.call_s3api(req) _, _, headers = self.swift.calls_with_headers[-1] self.assertEqual(req.environ['s3api.auth_details'], { 'access_key': (u'test:\N{SNOWMAN}'.encode('utf-8') if six.PY2 else u'test:\N{SNOWMAN}'), 'signature': 'sig', 'string_to_sign': b'\n'.join([ b'PUT', b'', b'', date_header.encode('ascii'), b'/bucket/object?partNumber=1&uploadId=123456789abcdef']), 'check_signature': mock_cs}) ",,36,9
openstack%2Fdevstack~stable%2Frocky~I143b5d9b5cbe9a3c3f0d749badf2b6332a753fb5,openstack/devstack,stable/rocky,I143b5d9b5cbe9a3c3f0d749badf2b6332a753fb5,Install python3.6 on ubuntu xenial for Tempest venv,MERGED,2020-01-20 18:18:25.000000000,2020-01-29 18:57:41.000000000,2020-01-27 23:51:45.000000000,"[{'_account_id': 1131}, {'_account_id': 7118}, {'_account_id': 8367}, {'_account_id': 8556}, {'_account_id': 10459}, {'_account_id': 13252}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-20 18:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ec69186f791459bd69beff28a4594321a84e4af8', 'message': 'Install python3.6 on ubuntu xenial for Tempest venv\n\nStable/Rocky and Stable/queens use ubuntu xenial for\ngate which doe not have python3.6 interpretor.\n\nAs OpenStack is droping the python2 support, many dependency\nof Tempest its plugins need py3.6 interpretor.\nFor Example: neutron-lib latest release Bug#1860033.\n\nThis install the python3.6 and make it available for Tempest evenv\nso that Tempest master can keep testing the stable branch.\n\nStein onwards distro has py3.6 so no isuse there.\nCloses-Bug: 1860033\n\nChange-Id: I143b5d9b5cbe9a3c3f0d749badf2b6332a753fb5\n'}, {'number': 2, 'created': '2020-01-20 18:19:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/21a1c6bce35191477b935f2955b48e8a91e88fba', 'message': 'Install python3.6 on ubuntu xenial for Tempest venv\n\nStable/Rocky and Stable/queens use ubuntu xenial for\ngate which doe not have python3.6 interpretor.\n\nAs OpenStack is droping the python2 support, many dependency\nof Tempest its plugins need py3.6 interpretor.\nFor Example: neutron-lib latest release Bug#1860033.\n\nThis install the python3.6 and make it available for Tempest evenv\nso that Tempest master can keep testing the stable branch.\n\nStein onwards distro has py3.6 so no isuse there.\nDepends-On: https://review.opendev.org/#/c/703011/\n\nCloses-Bug: 1860033\n\nChange-Id: I143b5d9b5cbe9a3c3f0d749badf2b6332a753fb5\n'}, {'number': 3, 'created': '2020-01-21 12:57:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/741c50bb5e13e56abd045316dc36dd74f80254ae', 'message': 'Install python3.6 on ubuntu xenial for Tempest venv\n\nStable/Rocky and Stable/Queens use ubuntu xenial for\ngate which does not have python3.6 interpreter.\n\nAs OpenStack is dropping the python2 support, many dependencies\nof Tempest and its plugins need py3.6 interpreter.\nFor Example: neutron-lib latest release Bug#1860033.\n\nThis installs python3.6 and makes it available in Tempest venv\nso that Tempest master can keep testing the stable branch.\n\nStein onwards distro ver (bionic) has py3.6 so no issue there.\n\nDepends-On: https://review.opendev.org/#/c/703011/\nCloses-Bug: 1860033\nCo-authored-by: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\nChange-Id: I143b5d9b5cbe9a3c3f0d749badf2b6332a753fb5\n'}, {'number': 4, 'created': '2020-01-21 15:29:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d067d156efa764acae4a49c5fadaee8655ed6fb8', 'message': 'Install python3.6 on ubuntu xenial for Tempest venv\n\nStable/Rocky and Stable/Queens use ubuntu xenial for\ngate which does not have python3.6 interpreter.\n\nAs OpenStack is dropping the python2 support, many dependencies\nof Tempest and its plugins need py3.6 interpreter.\nFor Example: neutron-lib latest release Bug#1860033.\n\nThis installs python3.6 and makes it available in Tempest venv\nso that Tempest master can keep testing the stable branch.\n\nStein onwards distro ver (bionic) has py3.6 so no issue there.\n\nCloses-Bug: 1860033\nCo-authored-by: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\nChange-Id: I143b5d9b5cbe9a3c3f0d749badf2b6332a753fb5\n'}, {'number': 5, 'created': '2020-01-21 18:56:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/94521815f5d6a9dc3e8855e3f44ccef22ad0ca7d', 'message': 'Install python3.6 on ubuntu xenial for Tempest venv\n\nStable/Rocky and Stable/Queens use ubuntu xenial for\ngate which does not have python3.6 interpreter.\n\nAs OpenStack is dropping the python2 support, many dependencies\nof Tempest and its plugins need py3.6 interpreter.\nFor Example: neutron-lib latest release Bug#1860033.\n\nThis installs python3.6 and makes it available in Tempest venv\nso that Tempest master can keep testing the stable branch.\npy3.6 provided by ppa.\n\nStein onwards distro ver (bionic) has py3.6 so no issue there.\n\nCloses-Bug: 1860033\nCo-authored-by: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\nChange-Id: I143b5d9b5cbe9a3c3f0d749badf2b6332a753fb5\n'}, {'number': 6, 'created': '2020-01-21 20:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/75abdbae00ff035ddbc5baa73cfe4ae54bd8ce32', 'message': 'Install python3.6 on ubuntu xenial for Tempest venv\n\nStable/Rocky and Stable/Queens use ubuntu xenial for\ngate which does not have python3.6 interpreter.\n\nAs OpenStack is dropping the python2 support, many dependencies\nof Tempest and its plugins need py3.6 interpreter.\nFor Example: neutron-lib latest release Bug#1860033.\n\nThis installs python3.6 and makes it available in Tempest venv\nso that Tempest master can keep testing the stable branch.\npy3.6 provided by ppa.\n\nStein onwards distro ver (bionic) has py3.6 so no issue there.\n\nCloses-Bug: 1860033\nCo-authored-by: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\nChange-Id: I143b5d9b5cbe9a3c3f0d749badf2b6332a753fb5\n'}, {'number': 7, 'created': '2020-01-23 22:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2d5105ac3db43aa26dbf805c2e2717db204164fc', 'message': 'Install python3.6 on ubuntu xenial for Tempest venv\n\nStable/Rocky and Stable/Queens use ubuntu xenial for\ngate which does not have python3.6 interpreter.\n\nAs OpenStack is dropping the python2 support, many dependencies\nof Tempest and its plugins need py3.6 interpreter.\nFor Example: neutron-lib latest release Bug#1860033.\n\nThis installs python3.6 and makes it available in Tempest venv\nso that Tempest master can keep testing the stable branch.\npy3.6 provided by ppa.\n\nStein onwards distro ver (bionic) has py3.6 so no issue there.\n\nCloses-Bug: 1860033\nCo-authored-by: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\nChange-Id: I143b5d9b5cbe9a3c3f0d749badf2b6332a753fb5\n'}, {'number': 8, 'created': '2020-01-24 14:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2003dc0829a79cec9fbe651f1f88d09ffd7d520c', 'message': 'Install python3.6 on ubuntu xenial for Tempest venv\n\nStable/Rocky and Stable/Queens use ubuntu xenial for\ngate which does not have python3.6 interpreter.\n\nAs OpenStack is dropping the python2 support, many dependencies\nof Tempest and its plugins need py3.6 interpreter.\nFor Example: neutron-lib latest release Bug#1860033.\n\nThis installs python3.6 and makes it available in Tempest venv\nso that Tempest master can keep testing the stable branch.\npy3.6 provided by ppa.\n\nStein onwards distro ver (bionic) has py3.6 so no issue there.\n\nCloses-Bug: 1860033\nCo-authored-by: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\nChange-Id: I143b5d9b5cbe9a3c3f0d749badf2b6332a753fb5\n'}, {'number': 9, 'created': '2020-01-24 15:06:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4b7c03086be6ac34e772b1f3e833ffd233af5ac6', 'message': 'Install python3.6 on ubuntu xenial for Tempest venv\n\nStable/Rocky and Stable/Queens use ubuntu xenial for\ngate which does not have python3.6 interpreter.\n\nAs OpenStack is dropping the python2 support, many dependencies\nof Tempest and its plugins need py3.6 interpreter.\nFor Example: neutron-lib latest release Bug#1860033.\n\nThis installs python3.6 and makes it available in Tempest venv\nso that Tempest master can keep testing the stable branch.\npy3.6 provided by ppa.\n\nStein onwards distro ver (bionic) has py3.6 so no issue there.\n\nCloses-Bug: 1860033\nCo-authored-by: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\nChange-Id: I143b5d9b5cbe9a3c3f0d749badf2b6332a753fb5\n'}, {'number': 10, 'created': '2020-01-24 18:56:14.000000000', 'files': ['tools/fixup_stuff.sh', 'lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/0b596470c8f7196a5e8e42faaa02db0ecefcf80d', 'message': 'Install python3.6 on ubuntu xenial for Tempest venv\n\nStable/Rocky and Stable/Queens use ubuntu xenial for\ngate which does not have python3.6 interpreter.\n\nAs OpenStack is dropping the python2 support, many dependencies\nof Tempest and its plugins need py3.6 interpreter.\nFor Example: neutron-lib latest release Bug#1860033.\n\nThis installs python3.6 and makes it available in Tempest venv\nso that Tempest master can keep testing the stable branch.\npy3.6 provided by ppa.\n\nStein onwards distro ver (bionic) has py3.6 so no issue there.\n\nCloses-Bug: 1860033\nCo-authored-by: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\nChange-Id: I143b5d9b5cbe9a3c3f0d749badf2b6332a753fb5\n'}]",17,703476,0b596470c8f7196a5e8e42faaa02db0ecefcf80d,75,9,10,8556,,,0,"Install python3.6 on ubuntu xenial for Tempest venv

Stable/Rocky and Stable/Queens use ubuntu xenial for
gate which does not have python3.6 interpreter.

As OpenStack is dropping the python2 support, many dependencies
of Tempest and its plugins need py3.6 interpreter.
For Example: neutron-lib latest release Bug#1860033.

This installs python3.6 and makes it available in Tempest venv
so that Tempest master can keep testing the stable branch.
py3.6 provided by ppa.

Stein onwards distro ver (bionic) has py3.6 so no issue there.

Closes-Bug: 1860033
Co-authored-by: Radosaw Piliszek <radoslaw.piliszek@gmail.com>
Change-Id: I143b5d9b5cbe9a3c3f0d749badf2b6332a753fb5
",git fetch https://review.opendev.org/openstack/devstack refs/changes/76/703476/8 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,ec69186f791459bd69beff28a4594321a84e4af8,bug/1860033," if is_ubuntu; then echo ""Installing python 3.6"" tox -evenv-tempest -- sudo add-apt-repository ppa:deadsnakes/ppa --yes tox -evenv-tempest -- sudo apt-get update tox -evenv-tempest -- sudo apt-get install python3.6 python3.6-dev --yes py3_ver=$(tox -evenv-tempest -- python3 --version) echo Python3 version installed in Tempest venv: $ver fi",,8,0
openstack%2Fdevstack~stable%2Frocky~I6c4ddf06533d097d61d1b31b6c3ce28af8c40f40,openstack/devstack,stable/rocky,I6c4ddf06533d097d61d1b31b6c3ce28af8c40f40,Install python3 on fedora-family distros for Tempest venv,ABANDONED,2020-01-24 19:14:33.000000000,2020-01-29 18:40:13.000000000,,"[{'_account_id': 7118}, {'_account_id': 8556}, {'_account_id': 13252}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26106}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-24 19:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/167ec63456633422788389faef995f3b74bcc04a', 'message': 'Install python3 on fedora-family distros for Tempest venv\n\nFollowup on parent which did the same for Ubuntu Xenial.\n\nChange-Id: I6c4ddf06533d097d61d1b31b6c3ce28af8c40f40\nRelated-bug: #1860033\n'}, {'number': 2, 'created': '2020-01-27 10:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6e082175391338c8f496fd367c9db9bde0669517', 'message': 'Install python3 on fedora-family distros for Tempest venv\n\nFollowup on parent which did the same for Ubuntu Xenial.\n\nChange-Id: I6c4ddf06533d097d61d1b31b6c3ce28af8c40f40\nRelated-bug: #1860033\n'}, {'number': 3, 'created': '2020-01-28 08:20:05.000000000', 'files': ['.zuul.yaml', 'tools/fixup_stuff.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/b120fb9baa8bbda7efa939edee701036addaa82d', 'message': 'Install python3 on fedora-family distros for Tempest venv\n\nFollowup on parent which did the same for Ubuntu Xenial.\n\nThis is mostly to fix CentOS 7.\n\nAs discussed, this also drops the fedora job which is no\nlonger relevant due to the nature of fedora releases.\n\nChange-Id: I6c4ddf06533d097d61d1b31b6c3ce28af8c40f40\nRelated-bug: #1860033\n'}]",3,704188,b120fb9baa8bbda7efa939edee701036addaa82d,23,8,3,30491,,,0,"Install python3 on fedora-family distros for Tempest venv

Followup on parent which did the same for Ubuntu Xenial.

This is mostly to fix CentOS 7.

As discussed, this also drops the fedora job which is no
longer relevant due to the nature of fedora releases.

Change-Id: I6c4ddf06533d097d61d1b31b6c3ce28af8c40f40
Related-bug: #1860033
",git fetch https://review.opendev.org/openstack/devstack refs/changes/88/704188/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/fixup_stuff.sh'],1,167ec63456633422788389faef995f3b74bcc04a,bug/1860033,"# Fedora family with py3 #------------------------- # Install py3 for Tempest function fixup_tempest_on_fedora { # See also fixup_tempest_on_xenial if is_fedora; then echo ""Installing python3 package from repos"" yum_install python3 fi } fixup_tempest_on_fedora",,12,0
openstack%2Fneutron~stable%2Frocky~Ia38a1ef91d025488ab2c43572e773a7f9900ad78,openstack/neutron,stable/rocky,Ia38a1ef91d025488ab2c43572e773a7f9900ad78,DNM: testing,ABANDONED,2020-01-29 17:00:00.000000000,2020-01-29 18:37:14.000000000,,"[{'_account_id': 9732}, {'_account_id': 26622}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-29 17:00:00.000000000', 'files': ['neutron/manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7b5b5f39320dc461d28ec6c1dfb59b63f64af617', 'message': 'DNM: testing\n\nDepends-On: https://review.opendev.org/#/c/704688/\nChange-Id: Ia38a1ef91d025488ab2c43572e773a7f9900ad78\n'}]",0,704846,7b5b5f39320dc461d28ec6c1dfb59b63f64af617,7,3,1,8556,,,0,"DNM: testing

Depends-On: https://review.opendev.org/#/c/704688/
Change-Id: Ia38a1ef91d025488ab2c43572e773a7f9900ad78
",git fetch https://review.opendev.org/openstack/neutron refs/changes/46/704846/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/manager.py'],1,7b5b5f39320dc461d28ec6c1dfb59b63f64af617,," """"""Handle initialization if this is a standalone service."," """"""Handle initialization if this is a standalone service.",1,1
openstack%2Fliberasurecode~master~I50cd7922dfa377ea27f3c9558a8a7268120ec733,openstack/liberasurecode,master,I50cd7922dfa377ea27f3c9558a8a7268120ec733,Fix create_fake_frags_no_meta to use memset to fill frags,MERGED,2020-01-14 20:58:20.000000000,2020-01-29 18:36:43.000000000,2020-01-29 18:36:43.000000000,"[{'_account_id': 11805}, {'_account_id': 15343}, {'_account_id': 16896}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-14 20:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/liberasurecode/commit/c11ff0aa58e79d96100bc92f69b76e25b6668031', 'message': 'Fix strncpy to prevent truncation of source\n\nFix data_len argument in call to create_fake_frags_no_meta to\nensure strncpy copies the string plus the null terminator rather\nthan the string without the null terminator.\n\nChange-Id: I50cd7922dfa377ea27f3c9558a8a7268120ec733\nCloses-Bug: #1859710\n'}, {'number': 2, 'created': '2020-01-15 14:20:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/liberasurecode/commit/2fb87db0be9c4d2ef926053debdc9075048896ed', 'message': ""Fix strncpy to prevent truncation of source\n\nEnsure data_len argument to create_fake_frags_no_meta includes\nstring's null terminator. This ensures strncpy copies the string\nplus the null terminator.\n\nAlso ensure create_buffer null terminates the string it creates.\n\nChange-Id: I50cd7922dfa377ea27f3c9558a8a7268120ec733\nCloses-Bug: #1859710\n""}, {'number': 3, 'created': '2020-01-29 00:35:03.000000000', 'files': ['test/liberasurecode_test.c'], 'web_link': 'https://opendev.org/openstack/liberasurecode/commit/0eb6cd321e312e32b3ad12c34089466eae60cd88', 'message': ""Fix create_fake_frags_no_meta to use memset to fill frags\n\nThese aren't C strings; we shouldn't be using strncpy and friends.\n\nChange-Id: I50cd7922dfa377ea27f3c9558a8a7268120ec733\nCloses-Bug: #1859710\n""}]",0,702530,0eb6cd321e312e32b3ad12c34089466eae60cd88,15,4,3,11805,,,0,"Fix create_fake_frags_no_meta to use memset to fill frags

These aren't C strings; we shouldn't be using strncpy and friends.

Change-Id: I50cd7922dfa377ea27f3c9558a8a7268120ec733
Closes-Bug: #1859710
",git fetch https://review.opendev.org/openstack/liberasurecode refs/changes/30/702530/3 && git format-patch -1 --stdout FETCH_HEAD,['test/liberasurecode_test.c'],1,c11ff0aa58e79d96100bc92f69b76e25b6668031,bug/1859710," "" "", 2);"," "" "", 1);",1,1
openstack%2Fproject-config~master~I56a9bfc7bb7bd0180bcbab842514c77e9081e54e,openstack/project-config,master,I56a9bfc7bb7bd0180bcbab842514c77e9081e54e,Don't require CLA for contributors of Ansible Openstack modules,MERGED,2020-01-28 18:07:08.000000000,2020-01-29 18:01:06.000000000,2020-01-29 18:01:06.000000000,"[{'_account_id': 2}, {'_account_id': 1004}, {'_account_id': 4162}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 7353}, {'_account_id': 10969}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-28 18:07:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2cabdb46515d91f793cf9b10bbf68cb144fd7931', 'message': 'WIP: don\'t require CLA for contributors of Ansible Openstack modules\n\nHistory:\n  - Ansible Openstack modules are moved from Ansible core repo to\n    Openstack SIG repo. Like all other modules will be separated\n    from Ansible core in 2.10 and will go somwhere.\n  - Ansible contributors are confused by moving to Gerrit and\n    because of requirement to sign for CLA.\n\nAs it\'s SIG repo and not part of ""official"" Openstack, can we SKIP\nrequirement of signing of CLA for contributors?\n\nChange-Id: I56a9bfc7bb7bd0180bcbab842514c77e9081e54e\n'}, {'number': 2, 'created': '2020-01-29 09:55:32.000000000', 'files': ['gerrit/acls/openstack/ansible-collections-openstack.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/65bf2b3faafe00b76f8094d27fbcb664e139029a', 'message': 'Don\'t require CLA for contributors of Ansible Openstack modules\n\nHistory:\n  - Ansible Openstack modules are moved from Ansible core repo to\n    Openstack SIG repo. Like all other modules will be separated\n    from Ansible core in 2.10 and will go somwhere.\n  - Ansible contributors are confused by moving to Gerrit and\n    because of requirement to sign for CLA.\n\nAs it\'s SIG repo and not part of ""official"" Openstack, can we SKIP\nrequirement of signing of CLA for contributors?\n\nChange-Id: I56a9bfc7bb7bd0180bcbab842514c77e9081e54e\n'}]",0,704648,65bf2b3faafe00b76f8094d27fbcb664e139029a,13,8,2,10969,,,0,"Don't require CLA for contributors of Ansible Openstack modules

History:
  - Ansible Openstack modules are moved from Ansible core repo to
    Openstack SIG repo. Like all other modules will be separated
    from Ansible core in 2.10 and will go somwhere.
  - Ansible contributors are confused by moving to Gerrit and
    because of requirement to sign for CLA.

As it's SIG repo and not part of ""official"" Openstack, can we SKIP
requirement of signing of CLA for contributors?

Change-Id: I56a9bfc7bb7bd0180bcbab842514c77e9081e54e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/48/704648/2 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/openstack/ansible-collections-openstack.config'],1,2cabdb46515d91f793cf9b10bbf68cb144fd7931,,requireContributorAgreement = false,requireContributorAgreement = true,1,1
openstack%2Ftripleo-quickstart~master~I10554e61b60a56566d21550c078ba0e169c0f0b1,openstack/tripleo-quickstart,master,I10554e61b60a56566d21550c078ba0e169c0f0b1,Adding sslverify on add_repo,MERGED,2020-01-28 14:33:19.000000000,2020-01-29 17:58:29.000000000,2020-01-29 17:56:34.000000000,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-28 14:33:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/45940382e36f80eff57ac403f03ac2a7215a6be0', 'message': 'WIP: Testing sslverify on add_repo\n\nChange-Id: I10554e61b60a56566d21550c078ba0e169c0f0b1\n'}, {'number': 2, 'created': '2020-01-28 15:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/32d2e0a128671637b67955486e4d98222de8cb95', 'message': 'WIP: Testing sslverify on add_repo\n\nChange-Id: I10554e61b60a56566d21550c078ba0e169c0f0b1\n'}, {'number': 3, 'created': '2020-01-28 15:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/757997ab4e439d2323cff04df76cfc3bc5a667e4', 'message': 'WIP: Testing sslverify on add_repo\n\nChange-Id: I10554e61b60a56566d21550c078ba0e169c0f0b1\n'}, {'number': 4, 'created': '2020-01-28 19:36:48.000000000', 'files': ['roles/repo-setup/templates/repo_setup.sh.j2', 'roles/repo-setup/README.md'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/9a8d2034f5cfd22d1a64adb2793ad97dc02cdb17', 'message': 'Adding sslverify on add_repo\n\nThis value defaults to 1 - true.\nBy default the repo will check for a cert if available.\nThe user can override the default on a per repo\nbasis\n\nChange-Id: I10554e61b60a56566d21550c078ba0e169c0f0b1\n'}]",3,704583,9a8d2034f5cfd22d1a64adb2793ad97dc02cdb17,24,7,4,9976,,,0,"Adding sslverify on add_repo

This value defaults to 1 - true.
By default the repo will check for a cert if available.
The user can override the default on a per repo
basis

Change-Id: I10554e61b60a56566d21550c078ba0e169c0f0b1
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/83/704583/4 && git format-patch -1 --stdout FETCH_HEAD,"['roles/repo-setup/templates/repo_setup.sh.j2', 'roles/repo-setup/README.md']",2,45940382e36f80eff57ac403f03ac2a7215a6be0,add-repo-cert, * `repos.sslverify` - whether to use a cert to use repo metadata (default: no),,4,0
openstack%2Freleases~master~Ide4f55f0fe0a3731c169d581dcd74fe2616ea7ae,openstack/releases,master,Ide4f55f0fe0a3731c169d581dcd74fe2616ea7ae,Sahara: (last) point releases from the rocky branch,MERGED,2020-01-27 18:52:41.000000000,2020-01-29 17:37:07.000000000,2020-01-29 17:37:07.000000000,"[{'_account_id': 8932}, {'_account_id': 11904}, {'_account_id': 16708}, {'_account_id': 22348}, {'_account_id': 23078}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-27 18:52:41.000000000', 'files': ['deliverables/rocky/sahara.yaml', 'deliverables/rocky/sahara-image-elements.yaml', 'deliverables/rocky/sahara-dashboard.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/0d9041e568586abbbfacb7d4fc447c0b1568487e', 'message': 'Sahara: (last) point releases from the rocky branch\n\nThe 3 repositories (sahara-dashboard, sahara-image-elements and sahara)\ncontain important updates.\nTwo other repositories contain changes (python-saharaclient, sahara-extra)\nbut those are Zuul changes or non-functional changes (openstack->opendev).\n\nChange-Id: Ide4f55f0fe0a3731c169d581dcd74fe2616ea7ae\n'}]",2,704392,0d9041e568586abbbfacb7d4fc447c0b1568487e,10,6,1,10459,,,0,"Sahara: (last) point releases from the rocky branch

The 3 repositories (sahara-dashboard, sahara-image-elements and sahara)
contain important updates.
Two other repositories contain changes (python-saharaclient, sahara-extra)
but those are Zuul changes or non-functional changes (openstack->opendev).

Change-Id: Ide4f55f0fe0a3731c169d581dcd74fe2616ea7ae
",git fetch https://review.opendev.org/openstack/releases refs/changes/92/704392/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/rocky/sahara.yaml', 'deliverables/rocky/sahara-image-elements.yaml', 'deliverables/rocky/sahara-dashboard.yaml']",3,0d9041e568586abbbfacb7d4fc447c0b1568487e,, - projects: - repo: openstack/sahara-dashboard hash: 51a46eab08704053c9feea430831313740c847ae version: 9.0.2,,12,0
openstack%2Fcharm-mysql-innodb-cluster~master~I446736fd75c48408f738d14a9b34b427c33aba78,openstack/charm-mysql-innodb-cluster,master,I446736fd75c48408f738d14a9b34b427c33aba78,Restore wheelhouse override for charm-helpers,MERGED,2020-01-29 15:39:12.000000000,2020-01-29 17:23:12.000000000,2020-01-29 17:23:12.000000000,"[{'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 15:39:12.000000000', 'files': ['wheelhouse-overrides.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/f7dda1417efa5ca8c524535980f7ed112f4c7b63', 'message': 'Restore wheelhouse override for charm-helpers\n\nChange-Id: I446736fd75c48408f738d14a9b34b427c33aba78\n'}]",0,704828,f7dda1417efa5ca8c524535980f7ed112f4c7b63,8,3,1,20805,,,0,"Restore wheelhouse override for charm-helpers

Change-Id: I446736fd75c48408f738d14a9b34b427c33aba78
",git fetch https://review.opendev.org/openstack/charm-mysql-innodb-cluster refs/changes/28/704828/1 && git format-patch -1 --stdout FETCH_HEAD,"['wheelhouse-overrides.txt', 'tox.ini']",2,f7dda1417efa5ca8c524535980f7ed112f4c7b63,bug/1861234, charm-build --log-level DEBUG --wheelhouse-overrides wheelhouse-overrides.txt -o {toxinidir}/build src {posargs}, charm-build --log-level DEBUG -o {toxinidir}/build src {posargs},2,1
openstack%2Fmanila~master~Ia61b108ece0817069737980a614cc6c15c1a3507,openstack/manila,master,Ia61b108ece0817069737980a614cc6c15c1a3507,Improve share list speed using lazy='subquery',MERGED,2020-01-15 10:31:53.000000000,2020-01-29 17:21:27.000000000,2020-01-29 17:17:46.000000000,"[{'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 16643}, {'_account_id': 18816}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22348}, {'_account_id': 25243}, {'_account_id': 29632}, {'_account_id': 30002}, {'_account_id': 30314}]","[{'number': 1, 'created': '2020-01-15 10:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/697513d2f502270af09d980b05b14442ef6cfc49', 'message': 'Improve share list speed using lazy=\'subquery\'\n\nlazy=\'immediate\' leads to each relationship being collected when\nit is accessed. This results in at least three extra queries when\nwe query for all share details. lazy=\'subquery\' collects all data\nwhen the query is exected. In this commit we only changed code for\nimproving the share list with details (""manila list"") speed.\n\nChange-Id: Ia61b108ece0817069737980a614cc6c15c1a3507\nCloses-Bug: #1859785\nCo-authored-by: Johannes Kulik <johannes.kulik@sap.com>\n'}, {'number': 2, 'created': '2020-01-16 12:13:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/1d2b4a03abf0e31969272a5022ee5a9ad96af4c5', 'message': 'Improve share list speed using lazy=\'subquery\'\n\nlazy=\'immediate\' leads to each relationship being collected when\nit is accessed. This results in at least three extra queries when\nwe query for all share details. lazy=\'subquery\' collects all data\nwhen the query is executed. In this commit we only changed code for\nimproving the share list with details (""manila list"") speed.\n\nChange-Id: Ia61b108ece0817069737980a614cc6c15c1a3507\nCloses-Bug: #1859785\nCo-authored-by: Johannes Kulik <johannes.kulik@sap.com>\n'}, {'number': 3, 'created': '2020-01-29 10:35:56.000000000', 'files': ['manila/db/sqlalchemy/models.py', 'releasenotes/notes/bug-1859785-share-list-speed-6b09e7717624e037.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/54c5667e6b4a37270c4aed64b9a5ebd5f31bfa16', 'message': 'Improve share list speed using lazy=\'subquery\'\n\nlazy=\'immediate\' leads to each relationship being collected when\nit is accessed. This results in at least three extra queries when\nwe query for all share details. lazy=\'subquery\' collects all data\nwhen the query is executed. In this commit we only changed code for\nimproving the share list with details (""manila list"") speed.\n\nChange-Id: Ia61b108ece0817069737980a614cc6c15c1a3507\nCloses-Bug: #1859785\nCo-authored-by: Johannes Kulik <johannes.kulik@sap.com>\nCo-authored-by: Maurice Escher <maurice.escher@sap.com>\n'}]",1,702639,54c5667e6b4a37270c4aed64b9a5ebd5f31bfa16,43,15,3,18816,,,0,"Improve share list speed using lazy='subquery'

lazy='immediate' leads to each relationship being collected when
it is accessed. This results in at least three extra queries when
we query for all share details. lazy='subquery' collects all data
when the query is executed. In this commit we only changed code for
improving the share list with details (""manila list"") speed.

Change-Id: Ia61b108ece0817069737980a614cc6c15c1a3507
Closes-Bug: #1859785
Co-authored-by: Johannes Kulik <johannes.kulik@sap.com>
Co-authored-by: Maurice Escher <maurice.escher@sap.com>
",git fetch https://review.opendev.org/openstack/manila refs/changes/39/702639/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/db/sqlalchemy/models.py'],1,697513d2f502270af09d980b05b14442ef6cfc49,bug/1859785," lazy='subquery', lazy='subquery', lazy='subquery',"," lazy='immediate', lazy='immediate', lazy='immediate',",3,3
openstack%2Fkeystonemiddleware~stable%2Fstein~I5d32d835886360522af21f735c74b2f85036f7f1,openstack/keystonemiddleware,stable/stein,I5d32d835886360522af21f735c74b2f85036f7f1,Blacklist bandit 1.6.0 & cap sphinx for 2.7,ABANDONED,2020-01-08 22:56:10.000000000,2020-01-29 17:10:03.000000000,,"[{'_account_id': 1916}, {'_account_id': 8482}, {'_account_id': 11904}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-08 22:56:10.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/9c9a94c1dacb60d097100ff18ad1a1e7cf6dd657', 'message': 'Blacklist bandit 1.6.0 & cap sphinx for 2.7\n\nThe latest version of bandit has broken directory exclusion,\nso multiple test files are getting flagged. This change\nblocks version 1.6.0 while this issue is fixed for 1.6.1.\n\nThis change also caps sphinx at <2.0.0 for python version 2.7.\n\nChange-Id: I5d32d835886360522af21f735c74b2f85036f7f1\n(cherry picked from commit e93d078958047ebc15159224e2068acdd8e6b768)\n'}]",0,701635,9c9a94c1dacb60d097100ff18ad1a1e7cf6dd657,8,5,1,11904,,,0,"Blacklist bandit 1.6.0 & cap sphinx for 2.7

The latest version of bandit has broken directory exclusion,
so multiple test files are getting flagged. This change
blocks version 1.6.0 while this issue is fixed for 1.6.1.

This change also caps sphinx at <2.0.0 for python version 2.7.

Change-Id: I5d32d835886360522af21f735c74b2f85036f7f1
(cherry picked from commit e93d078958047ebc15159224e2068acdd8e6b768)
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/35/701635/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt']",2,9c9a94c1dacb60d097100ff18ad1a1e7cf6dd657,fix-reqs-stable/stein,"sphinx!=1.6.6,!=1.6.7,>=1.6.2,<2.0.0;python_version=='2.7' # BSD sphinx!=1.6.6,!=1.6.7,>=1.6.2;python_version>='3.4' # BSD","sphinx!=1.6.6,!=1.6.7,>=1.6.2 # BSD",3,2
openstack%2Fcharm-keystone~master~Ib2b1f3dead1dbb613591bdf3903ed56e8c14f45c,openstack/charm-keystone,master,Ib2b1f3dead1dbb613591bdf3903ed56e8c14f45c,Use get_managed_services_and_ports from ch,MERGED,2020-01-23 16:39:35.000000000,2020-01-29 17:07:07.000000000,2020-01-29 17:07:07.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 16:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/15db583bd5ef4625efe2a7eb6e2d9945983d9c42', 'message': 'Use get_managed_services_and_ports from ch\n\nSwitch to using get_managed_services_and_ports from charmhelpers.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: Ib2b1f3dead1dbb613591bdf3903ed56e8c14f45c\n'}, {'number': 2, 'created': '2020-01-29 08:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/2f7f0e50346cd60dafed8ded38c171b818ec59fe', 'message': 'Use get_managed_services_and_ports from ch\n\nSwitch to using get_managed_services_and_ports from charmhelpers.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: Ib2b1f3dead1dbb613591bdf3903ed56e8c14f45c\n'}, {'number': 3, 'created': '2020-01-29 08:02:21.000000000', 'files': ['tests/tests.yaml', 'charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'unit_tests/test_keystone_utils.py', 'charmhelpers/contrib/hardening/audits/apt.py', 'hooks/keystone_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/fca036ba24f1f586b34870ba7565485390f17004', 'message': 'Use get_managed_services_and_ports from ch\n\nSwitch to using get_managed_services_and_ports from charmhelpers.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: Ib2b1f3dead1dbb613591bdf3903ed56e8c14f45c\n'}]",0,704028,fca036ba24f1f586b34870ba7565485390f17004,15,4,3,12549,,,0,"Use get_managed_services_and_ports from ch

Switch to using get_managed_services_and_ports from charmhelpers.

Charmhelper sync included to bring in required
get_managed_services_and_ports method.

Change-Id: Ib2b1f3dead1dbb613591bdf3903ed56e8c14f45c
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/28/704028/2 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/amulet/deployment.py', 'charmhelpers/contrib/openstack/audits/openstack_security_guide.py', 'charmhelpers/core/hookenv.py', 'hooks/keystone_utils.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/ha/utils.py', 'charmhelpers/contrib/openstack/templates/section-placement', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'unit_tests/test_keystone_utils.py', 'charmhelpers/contrib/hardening/audits/apt.py', 'charmhelpers/contrib/openstack/vaultlocker.py', 'charmhelpers/contrib/openstack/policyd.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/charmsupport/nrpe.py']",18,15db583bd5ef4625efe2a7eb6e2d9945983d9c42,use-svc-port-helper-from-ch," def remove_deprecated_check(nrpe, deprecated_services): """""" Remove checks fro deprecated services in list :param nrpe: NRPE object to remove check from :type nrpe: NRPE :param deprecated_services: List of deprecated services that are removed :type deprecated_services: list """""" for dep_svc in deprecated_services: log('Deprecated service: {}'.format(dep_svc)) nrpe.remove_check(shortname=dep_svc)",,629,204
openstack%2Fcharm-swift-proxy~master~Idce188397884521e686c2ea201e671a6557d4bf2,openstack/charm-swift-proxy,master,Idce188397884521e686c2ea201e671a6557d4bf2,Workaround for Juju bug 1860992,MERGED,2020-01-29 10:01:46.000000000,2020-01-29 17:03:14.000000000,2020-01-29 17:03:14.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 10:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/b48e00500d1f31e818c76d75767c7e1691332d66', 'message': 'Workaround for Juju bug 1860992\n\nChange CMR offer names to match application names to workaround\nJuju bug 1860992.\n\nChange-Id: Idce188397884521e686c2ea201e671a6557d4bf2\n'}, {'number': 2, 'created': '2020-01-29 12:48:24.000000000', 'files': ['tests/tests.yaml', 'tests/bundles/overlays/bionic-train-gr-r1.yaml.j2', 'tests/bundles/overlays/bionic-train-gr-r2.yaml.j2'], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/cd872e79e734a65b5283cc201b6c20b3654e4a76', 'message': 'Workaround for Juju bug 1860992\n\nChange CMR offer names to match application names to workaround\nJuju bug 1860992.\n\nChange-Id: Idce188397884521e686c2ea201e671a6557d4bf2\n'}]",0,704763,cd872e79e734a65b5283cc201b6c20b3654e4a76,15,4,2,12549,,,0,"Workaround for Juju bug 1860992

Change CMR offer names to match application names to workaround
Juju bug 1860992.

Change-Id: Idce188397884521e686c2ea201e671a6557d4bf2
",git fetch https://review.opendev.org/openstack/charm-swift-proxy refs/changes/63/704763/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/bundles/overlays/bionic-train-gr-r1.yaml.j2', 'tests/bundles/overlays/bionic-train-gr-r2.yaml.j2']",2,b48e00500d1f31e818c76d75767c7e1691332d66,bug/1860992, url: admin/{{ swift_gr_region1 }}.keystone swift-proxy-region1: url: admin/{{ swift_gr_region1 }}.swift-proxy-region1 swift-storage-region1-zone1: url: admin/{{ swift_gr_region1 }}.swift-storage-region1-zone1 swift-storage-region1-zone2: url: admin/{{ swift_gr_region1 }}.swift-storage-region1-zone2 swift-storage-region1-zone3: url: admin/{{ swift_gr_region1 }}.swift-storage-region1-zone3, url: admin/{{ swift_gr_region1 }}.keystone-offer swift-proxy-region1: url: admin/{{ swift_gr_region1 }}.swift-proxy-region1-offer swift-storage-region1-zone1: url: admin/{{ swift_gr_region1 }}.swift-storage-region1-zone1-offer swift-storage-region1-zone2: url: admin/{{ swift_gr_region1 }}.swift-storage-region1-zone2-offer swift-storage-region1-zone3: url: admin/{{ swift_gr_region1 }}.swift-storage-region1-zone3-offer,10,10
openstack%2Ftempest~master~Id4e9179340a77707fbbc3ced624d41671641ee1d,openstack/tempest,master,Id4e9179340a77707fbbc3ced624d41671641ee1d,"Revert ""Define python3 as basepython for Tempest tox env""",ABANDONED,2020-01-29 09:31:15.000000000,2020-01-29 17:00:39.000000000,,"[{'_account_id': 1131}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 8367}, {'_account_id': 8556}, {'_account_id': 10135}, {'_account_id': 13252}, {'_account_id': 16688}, {'_account_id': 20190}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23186}, {'_account_id': 30491}, {'_account_id': 31239}]","[{'number': 1, 'created': '2020-01-29 09:31:15.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tempest/commit/910d66b671ceabb9fe83c2188c6d4ad0b42817e5', 'message': 'Revert ""Define python3 as basepython for Tempest tox env""\n\nThis reverts commit 1c680fdb728c24a4c9a1507ad8319f0a505cef9c.\n\nRequiring python 3.6 broke distros which provide newer python\nwhich should be fine by design.\n\nChange-Id: Id4e9179340a77707fbbc3ced624d41671641ee1d\nCloses-bug: #1861263\n'}]",0,704755,910d66b671ceabb9fe83c2188c6d4ad0b42817e5,12,14,1,30491,,,0,"Revert ""Define python3 as basepython for Tempest tox env""

This reverts commit 1c680fdb728c24a4c9a1507ad8319f0a505cef9c.

Requiring python 3.6 broke distros which provide newer python
which should be fine by design.

Change-Id: Id4e9179340a77707fbbc3ced624d41671641ee1d
Closes-bug: #1861263
",git fetch https://review.opendev.org/openstack/tempest refs/changes/55/704755/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,910d66b671ceabb9fe83c2188c6d4ad0b42817e5,bug/1860033,minversion = 2.3.1basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,minversion = 3.1.1ignore_basepython_conflict = Truebasepython = python3.6basepython = python3basepython = {[tempestenv]basepython}basepython = {[tempestenv]basepython}basepython = {[tempestenv]basepython}basepython = {[tempestenv]basepython}basepython = {[tempestenv]basepython}basepython = {[tempestenv]basepython}basepython = {[tempestenv]basepython}basepython = {[tempestenv]basepython}basepython = {[tempestenv]basepython}basepython = {[tempestenv]basepython}basepython = {[tempestenv]basepython}basepython = {[tempestenv]basepython}basepython = {[tempestenv]basepython}basepython = {[tempestenv]basepython}basepython = {[tempestenv]basepython}basepython = {[tempestenv]basepython}basepython = {[tempestenv]basepython},9,21
openstack%2Fopenstack-helm-images~master~Iefa4a95362168f3fb947dbe0049e567236c7830c,openstack/openstack-helm-images,master,Iefa4a95362168f3fb947dbe0049e567236c7830c,Nagios elasticsearch plugin fix for the new version of the easticsearch,MERGED,2020-01-28 14:34:56.000000000,2020-01-29 16:58:59.000000000,2020-01-29 16:56:51.000000000,"[{'_account_id': 17591}, {'_account_id': 18295}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 28849}, {'_account_id': 30582}, {'_account_id': 30777}]","[{'number': 1, 'created': '2020-01-28 14:34:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/4ff54f9f7c92aa75d04f3d159c627de6b3c20d52', 'message': 'Nagios elasticsearch plugin fix for the new version of the easticsearch\n\nChange-Id: Iefa4a95362168f3fb947dbe0049e567236c7830c\n'}, {'number': 2, 'created': '2020-01-28 21:21:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/fa3f4131d41290329499e95f67d0f9487c5fb754', 'message': 'Nagios elasticsearch plugin fix for the new version of the easticsearch\n\nThe unncessary conditional check is throwing exceptions.\n\x1b\nChange-Id: Iefa4a95362168f3fb947dbe0049e567236c7830c\n'}, {'number': 3, 'created': '2020-01-29 16:18:23.000000000', 'files': ['nagios/plugins/query_elasticsearch.py'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/f80358d3e92f0b960c7bfc75e637dbc869f26283', 'message': 'Nagios elasticsearch plugin fix for the new version of the easticsearch\n\nThe unncessary conditional check is throwing exceptions.\n\x1b\nChange-Id: Iefa4a95362168f3fb947dbe0049e567236c7830c\n'}]",3,704584,f80358d3e92f0b960c7bfc75e637dbc869f26283,19,7,3,18295,,,0,"Nagios elasticsearch plugin fix for the new version of the easticsearch

The unncessary conditional check is throwing exceptions.

Change-Id: Iefa4a95362168f3fb947dbe0049e567236c7830c
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/84/704584/2 && git format-patch -1 --stdout FETCH_HEAD,['nagios/plugins/query_elasticsearch.py'],1,4ff54f9f7c92aa75d04f3d159c627de6b3c20d52,, elif (not response.json()['hits']):, elif (not response.json()['hits'] or int(response.json()['hits']['total']) < 0):,1,2
openstack%2Fcharm-swift-storage~master~Ia3019c9d8b905b80d5a44691607bb8a9ea20fe9d,openstack/charm-swift-storage,master,Ia3019c9d8b905b80d5a44691607bb8a9ea20fe9d,Workaround for Juju bug 1860992,MERGED,2020-01-29 10:04:38.000000000,2020-01-29 16:52:33.000000000,2020-01-29 16:52:33.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 10:04:38.000000000', 'files': ['tests/bundles/overlays/bionic-train-gr-r1.yaml.j2', 'tests/bundles/overlays/bionic-train-gr-r2.yaml.j2'], 'web_link': 'https://opendev.org/openstack/charm-swift-storage/commit/b8cc274f9a641f0a6df905358e96d5033e493f84', 'message': 'Workaround for Juju bug 1860992\n\nChange CMR offer names to match application names to workaround\nJuju bug 1860992.\n\nChange-Id: Ia3019c9d8b905b80d5a44691607bb8a9ea20fe9d\n'}]",0,704764,b8cc274f9a641f0a6df905358e96d5033e493f84,9,4,1,12549,,,0,"Workaround for Juju bug 1860992

Change CMR offer names to match application names to workaround
Juju bug 1860992.

Change-Id: Ia3019c9d8b905b80d5a44691607bb8a9ea20fe9d
",git fetch https://review.opendev.org/openstack/charm-swift-storage refs/changes/64/704764/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/bundles/overlays/bionic-train-gr-r1.yaml.j2', 'tests/bundles/overlays/bionic-train-gr-r2.yaml.j2']",2,b8cc274f9a641f0a6df905358e96d5033e493f84,bug/1860992, url: admin/{{ swift_gr_region1 }}.keystone swift-proxy-region1: url: admin/{{ swift_gr_region1 }}.swift-proxy-region1 swift-storage-region1-zone1: url: admin/{{ swift_gr_region1 }}.swift-storage-region1-zone1 swift-storage-region1-zone2: url: admin/{{ swift_gr_region1 }}.swift-storage-region1-zone2 swift-storage-region1-zone3: url: admin/{{ swift_gr_region1 }}.swift-storage-region1-zone3, url: admin/{{ swift_gr_region1 }}.keystone-offer swift-proxy-region1: url: admin/{{ swift_gr_region1 }}.swift-proxy-region1-offer swift-storage-region1-zone1: url: admin/{{ swift_gr_region1 }}.swift-storage-region1-zone1-offer swift-storage-region1-zone2: url: admin/{{ swift_gr_region1 }}.swift-storage-region1-zone2-offer swift-storage-region1-zone3: url: admin/{{ swift_gr_region1 }}.swift-storage-region1-zone3-offer,10,10
openstack%2Fkeystone~stable%2Fstein~I9ac523ad7637b1ff1c6c49b75add387ca112f980,openstack/keystone,stable/stein,I9ac523ad7637b1ff1c6c49b75add387ca112f980,Fix werkzeug imports for version 0.15.x,ABANDONED,2019-05-07 16:07:08.000000000,2020-01-29 16:46:15.000000000,,"[{'_account_id': 8482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-05-07 16:07:08.000000000', 'files': ['keystone/server/flask/application.py', 'keystone/server/flask/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/48dfd3c5910328da102788ad019909770806c3db', 'message': 'Fix werkzeug imports for version 0.15.x\n\nVersion 0.15.0 introduced some ""deprecation warning"" that cause a fatal\nerror and break all the unit tests. The new usage is not backwards\ncompatible, so this commit updates the module imports to accomodate both\nversions.\n\nChange-Id: I9ac523ad7637b1ff1c6c49b75add387ca112f980\n(cherry picked from commit de07ad37fc1b4d99176d5e706c0179c7cf939958)\n'}]",0,657632,48dfd3c5910328da102788ad019909770806c3db,4,2,1,24131,,,0,"Fix werkzeug imports for version 0.15.x

Version 0.15.0 introduced some ""deprecation warning"" that cause a fatal
error and break all the unit tests. The new usage is not backwards
compatible, so this commit updates the module imports to accomodate both
versions.

Change-Id: I9ac523ad7637b1ff1c6c49b75add387ca112f980
(cherry picked from commit de07ad37fc1b4d99176d5e706c0179c7cf939958)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/32/657632/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/server/flask/application.py', 'keystone/server/flask/core.py']",2,48dfd3c5910328da102788ad019909770806c3db,fix-werkzeug-for-real-stable/stein, try: # werkzeug 0.15.x from werkzeug.middleware import proxy_fix except ImportError: # werkzeug 0.14.x from werkzeug.contrib import fixers as proxy_fix # Apply werkzeug specific middleware app.wsgi_app = proxy_fix.ProxyFix(app.wsgi_app),from werkzeug.contrib import fixers # Apply werkzeug speficic middleware app.wsgi_app = fixers.ProxyFix(app.wsgi_app),17,5
openstack%2Fkeystone~stable%2Fstein~Iad73e61b50c55cedaf1c78f9437cb84ddd4aa6a9,openstack/keystone,stable/stein,Iad73e61b50c55cedaf1c78f9437cb84ddd4aa6a9,Update UPPER_CONSTRAINTS_FILE for stable/stein,ABANDONED,2019-05-10 11:19:57.000000000,2020-01-29 16:45:09.000000000,,"[{'_account_id': 8482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-05-10 11:19:57.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/50560c6306b7a5cc3481fd8c878c7556ed6918a5', 'message': 'Update UPPER_CONSTRAINTS_FILE for stable/stein\n\nChange-Id: Iad73e61b50c55cedaf1c78f9437cb84ddd4aa6a9\n'}]",0,658337,50560c6306b7a5cc3481fd8c878c7556ed6918a5,4,2,1,30361,,,0,"Update UPPER_CONSTRAINTS_FILE for stable/stein

Change-Id: Iad73e61b50c55cedaf1c78f9437cb84ddd4aa6a9
",git fetch https://review.opendev.org/openstack/keystone refs/changes/37/658337/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,50560c6306b7a5cc3481fd8c878c7556ed6918a5,,deps = -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/stable/stein/upper-constraints.txt}deps = -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/stable/stein/upper-constraints.txt},deps = -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/stein}deps = -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/stein},2,2
openstack%2Fproject-config~master~I8da81b35a79d5c4f8bc8f38d13027ad41e53b0ca,openstack/project-config,master,I8da81b35a79d5c4f8bc8f38d13027ad41e53b0ca,Remove promote-tox-docs-static,MERGED,2020-01-29 08:40:38.000000000,2020-01-29 16:45:07.000000000,2020-01-29 16:45:07.000000000,"[{'_account_id': 1004}, {'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 08:40:38.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ecdb4517509af3e564589c01a29055a3c0f8e44b', 'message': 'Remove promote-tox-docs-static\n\nThis jobs is now not used anymore, remove it and its parent.\n\nDepends-On: https://review.opendev.org/704744\nChange-Id: I8da81b35a79d5c4f8bc8f38d13027ad41e53b0ca\n'}]",0,704745,ecdb4517509af3e564589c01a29055a3c0f8e44b,8,3,1,6547,,,0,"Remove promote-tox-docs-static

This jobs is now not used anymore, remove it and its parent.

Depends-On: https://review.opendev.org/704744
Change-Id: I8da81b35a79d5c4f8bc8f38d13027ad41e53b0ca
",git fetch https://review.opendev.org/openstack/project-config refs/changes/45/704745/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,ecdb4517509af3e564589c01a29055a3c0f8e44b,static-services,," name: base-promote-tox-docs-static parent: opendev-promote-docs-base abstract: true protected: true description: | Base job for jobs that promote content to static.openstack.org. Jobs need to set the variable ``static_target`` for site to publish to. This is a promote job for ``openstack-tox-docs``. run: playbooks/static-docs/promote.yaml vars: download_artifact_job: openstack-tox-docs roles: - zuul: zuul/zuul-jobs - zuul: openstack/openstack-zuul-jobs secrets: - name: fileserver secret: static_ssh_key pass-to-parent: true - job: name: promote-tox-docs-static parent: base-promote-tox-docs-static description: | Promote content to static.openstack.org to /srv/static/{{ zuul.project.short_name }} allowed-projects: - openstack/election final: true vars: static_target: ""{{ zuul.project.short_name }}"" - job:",0,34
openstack%2Fkolla-ansible~master~I0626c93435c989447feb257cd24ddc3af2d05851,openstack/kolla-ansible,master,I0626c93435c989447feb257cd24ddc3af2d05851,doc: fix bullets in external_ceph.rst,MERGED,2020-01-29 15:51:09.000000000,2020-01-29 16:42:02.000000000,2020-01-29 16:38:03.000000000,"[{'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-29 15:51:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e94669df35b1bc4b090b3523173a00ddf6753b8e', 'message': 'doc: fix bullets in external_ceph.rst\n\nBullets under Cinder paragraph were not properly formatted.\n\nChange-Id: I0626c93435c989447feb257cd24ddc3af2d05851\n'}, {'number': 2, 'created': '2020-01-29 16:14:40.000000000', 'files': ['doc/source/reference/storage/external-ceph-guide.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ab797c1ae92626c184cc2c614b2c3c3a3a4646f9', 'message': 'doc: fix bullets in external_ceph.rst\n\nBullets under Cinder paragraph were not properly formatted.\n\nChange-Id: I0626c93435c989447feb257cd24ddc3af2d05851\n'}]",0,704832,ab797c1ae92626c184cc2c614b2c3c3a3a4646f9,9,2,2,22629,,,0,"doc: fix bullets in external_ceph.rst

Bullets under Cinder paragraph were not properly formatted.

Change-Id: I0626c93435c989447feb257cd24ddc3af2d05851
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/32/704832/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/reference/storage/external-ceph-guide.rst'],1,e94669df35b1bc4b090b3523173a00ddf6753b8e,fix_external_ceph_docs,,,2,0
openstack%2Fpython-neutronclient~master~I4737d4bc4fa116f45e2361eba93f48feae0161a4,openstack/python-neutronclient,master,I4737d4bc4fa116f45e2361eba93f48feae0161a4,Fix pep8 errors with hacking 2.0.0,MERGED,2019-12-17 07:39:38.000000000,2020-01-29 16:34:58.000000000,2019-12-19 12:40:33.000000000,"[{'_account_id': 1131}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-17 07:39:38.000000000', 'files': ['neutronclient/tests/unit/qos/test_cli20_rule.py', 'neutronclient/tests/unit/osc/v2/logging/test_network_log.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/91fb009706526ed8d36ca8f2cf57f1763a9af520', 'message': 'Fix pep8 errors with hacking 2.0.0\n\nChange-Id: I4737d4bc4fa116f45e2361eba93f48feae0161a4\n'}]",0,699357,91fb009706526ed8d36ca8f2cf57f1763a9af520,10,4,1,841,,,0,"Fix pep8 errors with hacking 2.0.0

Change-Id: I4737d4bc4fa116f45e2361eba93f48feae0161a4
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/57/699357/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/tests/unit/qos/test_cli20_rule.py', 'neutronclient/tests/unit/osc/v2/logging/test_network_log.py']",2,91fb009706526ed8d36ca8f2cf57f1763a9af520,fix-pep8," ""loggable_resources"": [{""type"": RES_TYPE_SG}, {""type"": RES_TYPE_FWG}]"," ""loggable_resources"": [{""type"": RES_TYPE_SG, ""type"": RES_TYPE_FWG}]",5,5
openstack%2Ftripleo-heat-templates~master~I40a3464c6a133619cb0e7e0e4a38f448d46c7808,openstack/tripleo-heat-templates,master,I40a3464c6a133619cb0e7e0e4a38f448d46c7808,Add CellController to multiple-nics ci template,MERGED,2020-01-28 18:50:15.000000000,2020-01-29 16:17:35.000000000,2020-01-29 16:17:35.000000000,"[{'_account_id': 6926}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 30133}]","[{'number': 1, 'created': '2020-01-28 18:50:15.000000000', 'files': ['ci/environments/network/multiple-nics/network-environment.yaml', 'ci/environments/network/multiple-nics/network-isolation-absolute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5dd32cde00ff671c44737bd9966381187f6b49b1', 'message': 'Add CellController to multiple-nics ci template\n\nTo test multi cell in 3rd party ci we need to update\nthe multiple-nics env files for the CellController role.\n\nChange-Id: I40a3464c6a133619cb0e7e0e4a38f448d46c7808\n'}]",0,704661,5dd32cde00ff671c44737bd9966381187f6b49b1,8,8,1,17216,,,0,"Add CellController to multiple-nics ci template

To test multi cell in 3rd party ci we need to update
the multiple-nics env files for the CellController role.

Change-Id: I40a3464c6a133619cb0e7e0e4a38f448d46c7808
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/61/704661/1 && git format-patch -1 --stdout FETCH_HEAD,"['ci/environments/network/multiple-nics/network-environment.yaml', 'ci/environments/network/multiple-nics/network-isolation-absolute.yaml']",2,5dd32cde00ff671c44737bd9966381187f6b49b1,cellv2, OS::TripleO::CellController::Ports::ExternalPort: /usr/share/openstack-tripleo-heat-templates/network/ports/external.yaml OS::TripleO::CellController::Ports::InternalApiPort: /usr/share/openstack-tripleo-heat-templates/network/ports/internal_api.yaml OS::TripleO::CellController::Ports::StoragePort: /usr/share/openstack-tripleo-heat-templates/network/ports/storage.yaml OS::TripleO::CellController::Ports::StorageMgmtPort: /usr/share/openstack-tripleo-heat-templates/network/ports/storage_mgmt.yaml OS::TripleO::CellController::Ports::TenantPort: /usr/share/openstack-tripleo-heat-templates/network/ports/tenant.yaml,,6,0
openstack%2Felection~master~I9c99a962bdf7237bb367ca7d8f133c4a641400cd,openstack/election,master,I9c99a962bdf7237bb367ca7d8f133c4a641400cd,Remove promote-tox-docs-static,MERGED,2020-01-29 08:39:02.000000000,2020-01-29 16:09:09.000000000,2020-01-29 16:04:50.000000000,"[{'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 08:39:02.000000000', 'files': ['.zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/election/commit/74156002417bf61fd17781b0dade6c1fdf19b65a', 'message': 'Remove promote-tox-docs-static\n\nWe have switched to the new AFS publishing of this repo, so can\nremove the old promote-tox-docs-static and publish only ones.\n\nChange-Id: I9c99a962bdf7237bb367ca7d8f133c4a641400cd\n'}]",0,704744,74156002417bf61fd17781b0dade6c1fdf19b65a,8,2,1,6547,,,0,"Remove promote-tox-docs-static

We have switched to the new AFS publishing of this repo, so can
remove the old promote-tox-docs-static and publish only ones.

Change-Id: I9c99a962bdf7237bb367ca7d8f133c4a641400cd
",git fetch https://review.opendev.org/openstack/election refs/changes/44/704744/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/project.yaml'],1,74156002417bf61fd17781b0dade6c1fdf19b65a,static-services,, - promote-tox-docs-static,0,1
openstack%2Fpython-neutronclient~master~I323b3aceec0a937874eabf770fbc82995202f6d6,openstack/python-neutronclient,master,I323b3aceec0a937874eabf770fbc82995202f6d6,Convert exception to string before passing it in,MERGED,2020-01-07 19:51:07.000000000,2020-01-29 16:07:43.000000000,2020-01-15 21:23:33.000000000,"[{'_account_id': 841}, {'_account_id': 6618}, {'_account_id': 10342}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-07 19:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/fcd7f079ddbc59fcd55c853be2305350b4baf48b', 'message': 'Convert exception to string before passing it in\n\nBefore this change, neutronclient was passing in a raw exception\nas a kwarg to the ConnectionFailed exception. This caused an\nexception to be raised in _safe_decode_dict() due to the exception\nnot being a text type.\n\nNow, we explicitly convert the raw exception to a string before\npassing it as a kwarg.\n\nChange-Id: I323b3aceec0a937874eabf770fbc82995202f6d6\n'}, {'number': 2, 'created': '2020-01-07 23:02:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/ee16723b04d211cf252a3ad153f612298887d837', 'message': 'Convert exception to string before passing it in\n\nBefore this change, neutronclient was passing in a raw exception\nas a kwarg to the ConnectionFailed exception. This caused an\nexception to be raised in _safe_decode_dict() due to the exception\nnot being a text type.\n\nNow, we explicitly convert the raw exception to a string before\npassing it as a kwarg.\n\nChange-Id: I323b3aceec0a937874eabf770fbc82995202f6d6\n'}, {'number': 3, 'created': '2020-01-08 22:08:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/97e56a1427a0621523b0adcaffe79213fad344eb', 'message': 'Convert exception to string before passing it in\n\nBefore this change, neutronclient was passing in a raw exception\nas a kwarg to the ConnectionFailed exception. This caused an\nexception to be raised in _safe_decode_dict() due to the exception\nnot being a text type.\n\nNow, we explicitly convert the raw exception to a string before\npassing it as a kwarg.\n\nChange-Id: I323b3aceec0a937874eabf770fbc82995202f6d6\n'}, {'number': 4, 'created': '2020-01-08 22:09:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/cd6a9e8f37b67c4fdc3818064f3cc7f17b63a14f', 'message': 'Convert exception to string before passing it in\n\nBefore this change, neutronclient was passing in a raw exception\nas a kwarg to the ConnectionFailed exception. This caused an\nexception to be raised in _safe_decode_dict() due to the exception\nnot being a text type.\n\nNow, we explicitly convert the raw exception to a string before\npassing it as a kwarg.\n\nChange-Id: I323b3aceec0a937874eabf770fbc82995202f6d6\n'}, {'number': 5, 'created': '2020-01-09 18:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/1f8057dfe29b450d475e83eb9db62abf67255621', 'message': 'Convert exception to string before passing it in\n\nBefore this change, neutronclient was passing in a raw exception\nas a kwarg to the ConnectionFailed exception. This caused an\nexception to be raised in _safe_decode_dict() due to the exception\nnot being a text type.\n\nNow, we explicitly convert the raw exception to a string before\npassing it as a kwarg.\n\nCloses-bug: 1859068\nChange-Id: I323b3aceec0a937874eabf770fbc82995202f6d6\n'}, {'number': 6, 'created': '2020-01-14 15:33:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/d627cf141685a146c415cbc1c9baf66aadbca371', 'message': 'Convert exception to string before passing it in\n\nBefore this change, neutronclient was passing in a raw exception\nas a kwarg to the ConnectionFailed exception. This caused an\nexception to be raised in _safe_decode_dict() due to the exception\nnot being a text type.\n\nNow, we explicitly convert the raw exception to a string before\npassing it as a kwarg.\n\nCloses-bug: 1859068\nChange-Id: I323b3aceec0a937874eabf770fbc82995202f6d6\n'}, {'number': 7, 'created': '2020-01-14 15:33:30.000000000', 'files': ['neutronclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/946ac3ed2e9e177eb5c56cc74aadbc091b9292ab', 'message': 'Convert exception to string before passing it in\n\nBefore this change, neutronclient was passing in a raw exception\nas a kwarg to the ConnectionFailed exception. This caused an\nexception to be raised in _safe_decode_dict() due to the exception\nnot being a text type.\n\nNow, we explicitly convert the raw exception to a string before\npassing it as a kwarg.\n\nCloses-bug: 1859068\nChange-Id: I323b3aceec0a937874eabf770fbc82995202f6d6\n'}]",6,701444,946ac3ed2e9e177eb5c56cc74aadbc091b9292ab,41,7,7,10342,,,0,"Convert exception to string before passing it in

Before this change, neutronclient was passing in a raw exception
as a kwarg to the ConnectionFailed exception. This caused an
exception to be raised in _safe_decode_dict() due to the exception
not being a text type.

Now, we explicitly convert the raw exception to a string before
passing it as a kwarg.

Closes-bug: 1859068
Change-Id: I323b3aceec0a937874eabf770fbc82995202f6d6
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/44/701444/6 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/client.py'],1,fcd7f079ddbc59fcd55c853be2305350b4baf48b,bug/1859068, raise exceptions.ConnectionFailed(reason=str(e)), raise exceptions.ConnectionFailed(reason=e),1,1
openstack%2Fproject-config~master~Ifc2f8b0023456aa1a27c74bcdf32a93ef9b8f03f,openstack/project-config,master,Ifc2f8b0023456aa1a27c74bcdf32a93ef9b8f03f,Remove static publishing for governance,MERGED,2020-01-29 08:28:41.000000000,2020-01-29 16:07:20.000000000,2020-01-29 16:07:20.000000000,"[{'_account_id': 1004}, {'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 08:28:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/230bec0c70bc3698a10667ba47a27d4a3206a0df', 'message': 'Remove static publishing for governance\n\nWe publish now to AFS and have no need to duplicate publishing anymore,\nremove temporary jobs.\n\nNote that the uc jobs were switched, we keep the AFS one.\n\nChange-Id: Ifc2f8b0023456aa1a27c74bcdf32a93ef9b8f03f\n'}, {'number': 2, 'created': '2020-01-29 08:40:38.000000000', 'files': ['zuul.d/projects.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ae649ddf09c142c79e8012fb7be00fe1878130a4', 'message': 'Remove static publishing for governance\n\nWe publish now to AFS and have no need to duplicate publishing anymore,\nremove temporary jobs.\n\nNote that the uc jobs were switched, we keep the AFS one.\n\nChange-Id: Ifc2f8b0023456aa1a27c74bcdf32a93ef9b8f03f\n'}]",0,704741,ae649ddf09c142c79e8012fb7be00fe1878130a4,9,3,2,6547,,,0,"Remove static publishing for governance

We publish now to AFS and have no need to duplicate publishing anymore,
remove temporary jobs.

Note that the uc jobs were switched, we keep the AFS one.

Change-Id: Ifc2f8b0023456aa1a27c74bcdf32a93ef9b8f03f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/41/704741/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/projects.yaml', 'zuul.d/jobs.yaml']",2,230bec0c70bc3698a10667ba47a27d4a3206a0df,static-services,," name: promote-governance-sigs-static parent: base-promote-tox-docs-static description: | Promote content to static.openstack.org to /srv/static/sigs This job is added for transition of sites, it will be removed soon. final: true allowed-projects: - openstack/governance-sigs vars: static_target: sigs - job: name: promote-governance-tc-static parent: base-promote-tox-docs-static description: | Promote content to static.openstack.org to /srv/static/tc This job is added for transition of sites, it will be removed soon. final: true allowed-projects: - openstack/governance vars: static_target: tc - job: parent: base-promote-tox-docs-static description: | Promote content to static.openstack.org to /srv/static/uc final: true allowed-projects: - openstack/governance-uc vars: static_target: uc - job: name: promote-governance-uc-static This job is added for transition of sites, it will be removed soon. name: promote-governance-website-static parent: base-promote-tox-docs-static description: | Promote content to static.openstack.org to /srv/static/governance This job is added for transition of sites, it will be removed soon. final: true allowed-projects: - openstack/governance-website vars: static_target: governance - job: name: promote-security-static parent: base-promote-tox-docs-static description: | Promote content to static.openstack.org to /srv/static/security This job is added for transition of sites, it will be removed soon. final: true allowed-projects: - openstack/ossa vars: static_target: security - job:",0,97
openstack%2Ftripleo-operator-ansible~master~I44f2172069df2bf788b5b37d2bf70e381983f7a1,openstack/tripleo-operator-ansible,master,I44f2172069df2bf788b5b37d2bf70e381983f7a1,Add overcloud failures role,MERGED,2020-01-21 22:02:55.000000000,2020-01-29 16:02:57.000000000,2020-01-29 16:02:57.000000000,"[{'_account_id': 3153}, {'_account_id': 10969}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-21 22:02:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/546da0d5a7c7378b863514b5c4d455249ef6c7a9', 'message': 'Add overcloud failures role\n\nAdds tripleo_overcloud_failures which can be used to collect the failure\noutput when a deployment fails for an overcloud.\n\nChange-Id: I44f2172069df2bf788b5b37d2bf70e381983f7a1\n'}, {'number': 2, 'created': '2020-01-21 22:10:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/0c7723a6a6b013fd4b5d4b517a1b478a10b620b3', 'message': 'Add overcloud failures role\n\nAdds tripleo_overcloud_failures which can be used to collect the failure\noutput when a deployment fails for an overcloud.\n\nChange-Id: I44f2172069df2bf788b5b37d2bf70e381983f7a1\n'}, {'number': 3, 'created': '2020-01-21 22:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/0447f07a85a42d295c2315fe4cc6460ecdf9beed', 'message': 'Add overcloud failures role\n\nAdds tripleo_overcloud_failures which can be used to collect the failure\noutput when a deployment fails for an overcloud.\n\nChange-Id: I44f2172069df2bf788b5b37d2bf70e381983f7a1\n'}, {'number': 4, 'created': '2020-01-28 19:14:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/52839827b0cfdb96b83a11df9e2a2b22106d5a77', 'message': 'Add overcloud failures role\n\nAdds tripleo_overcloud_failures which can be used to collect the failure\noutput when a deployment fails for an overcloud.\n\nChange-Id: I44f2172069df2bf788b5b37d2bf70e381983f7a1\n'}, {'number': 5, 'created': '2020-01-28 19:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/e65688e1c9750e99bf2016997ccbfe3469318aaf', 'message': 'Add overcloud failures role\n\nAdds tripleo_overcloud_failures which can be used to collect the failure\noutput when a deployment fails for an overcloud.\n\nChange-Id: I44f2172069df2bf788b5b37d2bf70e381983f7a1\n'}, {'number': 6, 'created': '2020-01-28 19:51:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/21b320fb260559321578a31afecdbbb1fd928201', 'message': 'Add overcloud failures role\n\nAdds tripleo_overcloud_failures which can be used to collect the failure\noutput when a deployment fails for an overcloud.\n\nChange-Id: I44f2172069df2bf788b5b37d2bf70e381983f7a1\n'}, {'number': 7, 'created': '2020-01-28 19:54:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/7b691bf20806d7d2af5c774ee58d08b285ca06f0', 'message': 'Add overcloud failures role\n\nAdds tripleo_overcloud_failures which can be used to collect the failure\noutput when a deployment fails for an overcloud.\n\nChange-Id: I44f2172069df2bf788b5b37d2bf70e381983f7a1\n'}, {'number': 8, 'created': '2020-01-28 19:55:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/fbcc22803e756310600a773fa801a9f10cf49381', 'message': 'Add overcloud failures role\n\nAdds tripleo_overcloud_failures which can be used to collect the failure\noutput when a deployment fails for an overcloud.\n\nChange-Id: I44f2172069df2bf788b5b37d2bf70e381983f7a1\n'}, {'number': 9, 'created': '2020-01-28 20:15:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/3c2e3464cd034128dc106752c96999538a85a106', 'message': 'Add overcloud failures role\n\nAdds tripleo_overcloud_failures which can be used to collect the failure\noutput when a deployment fails for an overcloud.\n\nChange-Id: I44f2172069df2bf788b5b37d2bf70e381983f7a1\n'}, {'number': 10, 'created': '2020-01-28 20:36:22.000000000', 'files': ['roles/tripleo_overcloud_failures/tests/test.yml', 'zuul.d/molecule.yaml', 'roles/tripleo_overcloud_failures/molecule/default/molecule.yml', 'roles/tripleo_overcloud_failures/README.md', 'roles/tripleo_overcloud_failures/molecule/default/playbook.yml', 'roles/tripleo_overcloud_failures/meta/main.yml', 'roles/tripleo_overcloud_failures/tasks/main.yml', 'roles/tripleo_overcloud_failures/defaults/main.yml', 'roles/tripleo_overcloud_failures/tests/inventory'], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/bb480ed481979e193369b7c371695925ed37a216', 'message': 'Add overcloud failures role\n\nAdds tripleo_overcloud_failures which can be used to collect the failure\noutput when a deployment fails for an overcloud.\n\nChange-Id: I44f2172069df2bf788b5b37d2bf70e381983f7a1\n'}]",0,703699,bb480ed481979e193369b7c371695925ed37a216,23,3,10,14985,,,0,"Add overcloud failures role

Adds tripleo_overcloud_failures which can be used to collect the failure
output when a deployment fails for an overcloud.

Change-Id: I44f2172069df2bf788b5b37d2bf70e381983f7a1
",git fetch https://review.opendev.org/openstack/tripleo-operator-ansible refs/changes/99/703699/3 && git format-patch -1 --stdout FETCH_HEAD,"['roles/tripleo_overcloud_failures/tests/test.yml', 'roles/tripleo_overcloud_failures/README.md', 'roles/tripleo_overcloud_failures/defaults/main.yml', 'roles/tripleo_overcloud_failures/meta/main.yml', 'roles/tripleo_overcloud_failures/tasks/main.yml', 'roles/tripleo_overcloud_failures/tests/inventory']",6,546da0d5a7c7378b863514b5c4d455249ef6c7a9,tripleo-overcloud-export,localhost ,,126,0
openstack%2Fcharm-neutron-api~master~Idbf0f52efbd9834cb185eede1dbc3375aebbbd53,openstack/charm-neutron-api,master,Idbf0f52efbd9834cb185eede1dbc3375aebbbd53,Sync charm-helpers for Ussuri/Focal release and version details,MERGED,2020-01-17 19:22:23.000000000,2020-01-29 15:50:46.000000000,2020-01-29 15:50:46.000000000,"[{'_account_id': 11805}, {'_account_id': 12549}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-17 19:22:23.000000000', 'files': ['hooks/charmhelpers/contrib/openstack/policyd.py', 'hooks/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/charmhelpers/contrib/charmsupport/nrpe.py', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/charmhelpers/contrib/openstack/ha/utils.py', 'hooks/charmhelpers/fetch/ubuntu.py', 'hooks/charmhelpers/contrib/openstack/vaultlocker.py', 'hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/charmhelpers/contrib/openstack/templates/section-placement', 'hooks/charmhelpers/contrib/openstack/audits/openstack_security_guide.py', 'hooks/charmhelpers/core/hookenv.py', 'hooks/charmhelpers/contrib/openstack/amulet/utils.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/9d630b22a91cf4be9a6a1747fb368ea49d02e09c', 'message': 'Sync charm-helpers for Ussuri/Focal release and version details\n\nChange-Id: Idbf0f52efbd9834cb185eede1dbc3375aebbbd53\n'}]",0,703175,9d630b22a91cf4be9a6a1747fb368ea49d02e09c,28,5,1,11805,,,0,"Sync charm-helpers for Ussuri/Focal release and version details

Change-Id: Idbf0f52efbd9834cb185eede1dbc3375aebbbd53
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/75/703175/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/charmhelpers/contrib/openstack/policyd.py', 'hooks/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/charmhelpers/contrib/charmsupport/nrpe.py', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/charmhelpers/contrib/openstack/ha/utils.py', 'hooks/charmhelpers/fetch/ubuntu.py', 'hooks/charmhelpers/contrib/openstack/vaultlocker.py', 'hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/charmhelpers/contrib/openstack/templates/section-placement', 'hooks/charmhelpers/contrib/openstack/audits/openstack_security_guide.py', 'hooks/charmhelpers/core/hookenv.py', 'hooks/charmhelpers/contrib/openstack/amulet/utils.py']",13,9d630b22a91cf4be9a6a1747fb368ea49d02e09c,batch-update," 'bionic_ussuri', 'focal_ussuri',",,528,151
openstack%2Fkeystone~master~I398b151904c9c5c9d0c3ab4358074e8adcfd1b6c,openstack/keystone,master,I398b151904c9c5c9d0c3ab4358074e8adcfd1b6c,Update OIDC documentation to handle bearer access token flow,MERGED,2019-11-12 12:44:52.000000000,2020-01-29 15:43:43.000000000,2020-01-29 15:40:37.000000000,"[{'_account_id': 8482}, {'_account_id': 16465}, {'_account_id': 22348}, {'_account_id': 28356}, {'_account_id': 29865}, {'_account_id': 30695}]","[{'number': 1, 'created': '2019-11-12 12:44:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f016dbca8e94e066d098845c915cf31ff89ee31e', 'message': 'Update OIDC documentation to handle bearer access token flow\n\nAlso add a section of multiple Identity Providers configuration.\n\nChange-Id: I398b151904c9c5c9d0c3ab4358074e8adcfd1b6c\n'}, {'number': 2, 'created': '2019-11-25 22:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f51b7243699c6258a9e030378cc1a4734ee64b77', 'message': 'Update OIDC documentation to handle bearer access token flow\n\nAlso add a section of multiple Identity Providers configuration.\n\nChange-Id: I398b151904c9c5c9d0c3ab4358074e8adcfd1b6c\n'}, {'number': 3, 'created': '2019-12-26 19:45:37.000000000', 'files': ['doc/source/admin/federation/openidc.inc'], 'web_link': 'https://opendev.org/openstack/keystone/commit/01a8c1fcabcf9d64b48fc1ca4b425aa3ca80c670', 'message': 'Update OIDC documentation to handle bearer access token flow\n\nAlso add a section of multiple Identity Providers configuration.\n\nChange-Id: I398b151904c9c5c9d0c3ab4358074e8adcfd1b6c\n'}]",20,693838,01a8c1fcabcf9d64b48fc1ca4b425aa3ca80c670,21,6,3,30695,,,0,"Update OIDC documentation to handle bearer access token flow

Also add a section of multiple Identity Providers configuration.

Change-Id: I398b151904c9c5c9d0c3ab4358074e8adcfd1b6c
",git fetch https://review.opendev.org/openstack/keystone refs/changes/38/693838/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/federation/openidc.inc'],1,f016dbca8e94e066d098845c915cf31ff89ee31e,upstream/doc/fix-oidc-configuration," OIDCOAuthVerifyJwksUri https://www.googleapis.com/oauth2/v3/certsthe Identity Provider's metadata. ``OIDCOAuthVerifyJwksUri`` is a URL from which the Service Provider will download the public key from the Identity Provider to check if the user's access token is valid or not. ``OIDCRedirectURI`` is a vanity URL that must.. warning:: To add support to Bearer Access Token authentication flow that is used by applications that not adopt the browser flow, such the OpenStack CLI, you will need to change the AuthType from ``openid-connect`` to ``auth-openidc``: Configuring Multiple Identity Providers ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ To configure multiples Identity Providers in your environment you will need to set your OIDC options like the following options: .. code-block:: apache OIDCClaimPrefix ""OIDC-"" OIDCResponseType ""id_token"" OIDCScope ""openid email profile"" OIDCMetadataDir </dir/to/idps-metadata> OIDCCryptoPassphrase <random string> OIDCRedirectURI https://sp.keystone.example.org/v3/OS-FEDERATION/identity_providers/google/protocols/openid/auth OIDCOAuthVerifyCertFiles <kid>#</path/to-cert.pem> <kid2>#</path/to-cert2.pem> <kidN>#</path/to-certN.pem> The ``OIDCOAuthVerifyCertFiles`` is a tuple separated with `space` containing the key-id (kid) of the Issuer's public key and a path to the Issuer certificate. The separator ``#`` is used to split the (``kid``) and the public certificate address .. note:: This configuration is important to avoid the discovery process while using the bearer access token authentication flow. The metadata folder configured in the option ``OIDCMetadataDir`` must have all your Identity Providers configurations, the name of the files will be the name (with path) of the Issuers like: .. code-block:: dir - path-to-metadata | - accounts.google.com.client | - accounts.google.com.conf | - accounts.google.com.provider .. note:: The name of the file must be escaped if needed. For example, if you have an Issuer with ``/`` in the URL, then you need to escape it to ``%2F`` by applying a URL escape in the file name. The content of these files must be a JSON like ``accounts.google.com.client``: .. code-block:: json { ""client_id"":""<openid_client_id>"", ""client_secret"":""<openid_client_secret>"" } The ``.client`` file handles the SP credentials in the Issuer. ``accounts.google.com.conf``: This file will be a JSON that overrides some of OIDC options. The options that are able to be overrided are listed in the `OpenID Connect Apache2 plugin documentation`_. .. _`OpenID Connect Apache2 plugin documentation`: https://github.com/zmartzone/mod_auth_openidc/wiki/Multiple-Providers#opclient-configuration If you do not want to override the config values, you can leave this file as an empty JSON like ``{}``. ``accounts.google.com.provider``: This file will contain all specifications about the IdentityProvider. To simplify, you can just use the JSON returned in the ``.well-known`` endpoint: .. code-block:: json { ""issuer"": ""https://accounts.google.com"", ""authorization_endpoint"": ""https://accounts.google.com/o/oauth2/v2/auth"", ""token_endpoint"": ""https://oauth2.googleapis.com/token"", ""userinfo_endpoint"": ""https://openidconnect.googleapis.com/v1/userinfo"", ""revocation_endpoint"": ""https://oauth2.googleapis.com/revoke"", ""jwks_uri"": ""https://www.googleapis.com/oauth2/v3/certs"", ""response_types_supported"": [ ""code"", ""token"", ""id_token"", ""code token"", ""code id_token"", ""token id_token"", ""code token id_token"", ""none"" ], ""subject_types_supported"": [ ""public"" ], ""id_token_signing_alg_values_supported"": [ ""RS256"" ], ""scopes_supported"": [ ""openid"", ""email"", ""profile"" ], ""token_endpoint_auth_methods_supported"": [ ""client_secret_post"", ""client_secret_basic"" ], ""claims_supported"": [ ""aud"", ""email"", ""email_verified"", ""exp"", ""family_name"", ""given_name"", ""iat"", ""iss"", ""locale"", ""name"", ""picture"", ""sub"" ], ""code_challenge_methods_supported"": [ ""plain"", ""S256"" ] } ",the Identity Provider's metadata. ``OIDCRedirectURI`` is a vanity URL that must,138,1
openstack%2Fmistral~master~I3bc7f9bb6b76953c7030303791a23aae08daf45e,openstack/mistral,master,I3bc7f9bb6b76953c7030303791a23aae08daf45e,remove inspect utils it was moved to mistral-lib,ABANDONED,2020-01-26 13:03:18.000000000,2020-01-29 15:33:46.000000000,,"[{'_account_id': 19134}, {'_account_id': 22348}, {'_account_id': 30755}]","[{'number': 1, 'created': '2020-01-26 13:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/a2dc38a4467c796c81d60bd35aa6950db5b8f093', 'message': 'remove inspect utils it was moved to mistral-lib\n\nDepends-On: https://review.opendev.org/#/c/703295/\nChange-Id: I3bc7f9bb6b76953c7030303791a23aae08daf45e\n'}, {'number': 2, 'created': '2020-01-26 14:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/99d57deafc5d05b9abda8b21ec2b1e3121668466', 'message': 'remove inspect utils it was moved to mistral-lib\n\nDepends-On: https://review.opendev.org/#/c/703295/\nChange-Id: I3bc7f9bb6b76953c7030303791a23aae08daf45e\n'}, {'number': 3, 'created': '2020-01-27 07:54:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ad796c49979f52bc18b40a6fe21cf711b14755d8', 'message': 'remove inspect utils it was moved to mistral-lib\n\nDepends-On: https://review.opendev.org/#/c/703295/\nChange-Id: I3bc7f9bb6b76953c7030303791a23aae08daf45e\n'}, {'number': 4, 'created': '2020-01-27 09:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/b1790ae64c917c522bd8d93deca5b6188f682cf0', 'message': 'remove inspect utils it was moved to mistral-lib\n\nDepends-On: https://review.opendev.org/#/c/703295/\nDepends-On: https://review.opendev.org/#/c/704280/\nChange-Id: I3bc7f9bb6b76953c7030303791a23aae08daf45e\n'}, {'number': 5, 'created': '2020-01-29 06:37:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/af68441381083498758e4d53c768dc949060dbb4', 'message': 'remove inspect utils it was moved to mistral-lib\n\nDepends-On: https://review.opendev.org/#/c/703295/\nDepends-On: https://review.opendev.org/#/c/704280/\nChange-Id: I3bc7f9bb6b76953c7030303791a23aae08daf45e\n'}, {'number': 6, 'created': '2020-01-29 07:22:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/54a13413b13fd6ec166b3fd824c096d142cc593f', 'message': 'remove inspect utils it was moved to mistral-lib\n\nDepends-On: https://review.opendev.org/#/c/704280/\nChange-Id: I3bc7f9bb6b76953c7030303791a23aae08daf45e\n'}, {'number': 7, 'created': '2020-01-29 10:15:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/76f34a9b6a1b1ed1095652010b43c3a325b47429', 'message': 'remove inspect utils it was moved to mistral-lib\n\nDepends-On: https://review.opendev.org/#/c/704280/\nChange-Id: I3bc7f9bb6b76953c7030303791a23aae08daf45e\n'}, {'number': 8, 'created': '2020-01-29 12:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/c408e9bf0445ce2cd9785bd2409620f3383404da', 'message': 'remove inspect utils it was moved to mistral-lib\n\nDepends-On: https://review.opendev.org/#/c/704280/\nChange-Id: I3bc7f9bb6b76953c7030303791a23aae08daf45e\n'}, {'number': 9, 'created': '2020-01-29 14:17:37.000000000', 'files': ['mistral/utils/inspect_utils.py', 'mistral/services/action_manager.py', 'test-requirements.txt', 'mistral/tests/unit/test_exception_base.py', '.zuul.yaml', 'mistral/engine/base.py', 'mistral/tests/unit/base.py', 'lower-constraints.txt', 'mistral/tests/unit/api/v2/test_action_executions.py', 'mistral/tests/unit/utils/test_inspect_utils.py', 'devstack/settings', 'mistral/workflow/data_flow.py', 'requirements.txt', 'tools/get_action_list.py', 'mistral/executors/default_executor.py', 'doc/requirements.txt', 'mistral/tests/unit/api/v2/test_executions.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/b50a4394a638180f02d2a2f839ad2e6b182d638a', 'message': 'remove inspect utils it was moved to mistral-lib\n\nDepends-On: https://review.opendev.org/#/c/704280/\nChange-Id: I3bc7f9bb6b76953c7030303791a23aae08daf45e\n'}]",0,704249,b50a4394a638180f02d2a2f839ad2e6b182d638a,22,3,9,19134,,,0,"remove inspect utils it was moved to mistral-lib

Depends-On: https://review.opendev.org/#/c/704280/
Change-Id: I3bc7f9bb6b76953c7030303791a23aae08daf45e
",git fetch https://review.opendev.org/openstack/mistral refs/changes/49/704249/8 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/utils/inspect_utils.py', 'mistral/workflow/data_flow.py', 'mistral/services/action_manager.py', 'mistral/executors/default_executor.py', 'mistral/tests/unit/test_exception_base.py', 'mistral/engine/base.py', 'mistral/tests/unit/base.py', 'mistral/tests/unit/utils/test_inspect_utils.py']",8,a2dc38a4467c796c81d60bd35aa6950db5b8f093,inspect,,"# Copyright 2014 - Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import time from mistral.actions import std_actions from mistral.tests.unit import base from mistral.utils import inspect_utils as i_u from mistral.workflow import commands class ClassWithProperties(object): a = 1 @property def prop(self): pass class InspectUtilsTest(base.BaseTest): def test_get_parameters_str(self): action_class = std_actions.HTTPAction parameters_str = i_u.get_arg_list_as_str(action_class.__init__) http_action_params = ( 'url, method=""GET"", params=null, body=null, ' 'json=null, headers=null, cookies=null, auth=null, ' 'timeout=null, allow_redirects=null, ' 'proxies=null, verify=null' ) self.assertEqual(http_action_params, parameters_str) def test_get_parameters_str_all_mandatory(self): clazz = commands.RunTask parameters_str = i_u.get_arg_list_as_str(clazz.__init__) self.assertEqual( 'wf_ex, wf_spec, task_spec, ctx, triggered_by=null,' ' handles_error=false', parameters_str ) def test_get_parameters_str_with_function_parameter(self): def test_func(foo, bar=None, test_func=time.sleep): pass parameters_str = i_u.get_arg_list_as_str(test_func) self.assertEqual(""foo, bar=null"", parameters_str) def test_get_public_fields(self): attrs = i_u.get_public_fields(ClassWithProperties) self.assertEqual(attrs, {'a': 1}) ",6,169
openstack%2Fpuppet-tripleo~master~I23bab883b23cf33ebd9f59399b265b87e6881ed4,openstack/puppet-tripleo,master,I23bab883b23cf33ebd9f59399b265b87e6881ed4,Remove dracut-config-generic package,ABANDONED,2020-01-28 15:54:23.000000000,2020-01-29 14:55:43.000000000,,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-28 15:54:23.000000000', 'files': ['manifests/profile/base/kernel.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e376b5dd999cd875c2f3061a991d33f826f0cf8d', 'message': ""Remove dracut-config-generic package\n\nIn LP#1830574, we introduce the dracut command to include necessary\nfile into initramfs. However, dracut in RHEL or CentOS doesn't include\nsysctl.conf or other specific module related confs at an installation\nof new kernel if dracut-config-generic package exists on the system.\n\nWe should remove the package to allow creating a host-specific initramfs\nat an installation of new kernel.\n\nCloses-bug: #1857493\n\nChange-Id: I23bab883b23cf33ebd9f59399b265b87e6881ed4\nCo-Authored-By: Keigo Noha <knoha@redhat.com>\n""}]",2,704599,e376b5dd999cd875c2f3061a991d33f826f0cf8d,9,5,1,31245,,,0,"Remove dracut-config-generic package

In LP#1830574, we introduce the dracut command to include necessary
file into initramfs. However, dracut in RHEL or CentOS doesn't include
sysctl.conf or other specific module related confs at an installation
of new kernel if dracut-config-generic package exists on the system.

We should remove the package to allow creating a host-specific initramfs
at an installation of new kernel.

Closes-bug: #1857493

Change-Id: I23bab883b23cf33ebd9f59399b265b87e6881ed4
Co-Authored-By: Keigo Noha <knoha@redhat.com>
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/99/704599/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/kernel.pp'],1,e376b5dd999cd875c2f3061a991d33f826f0cf8d,1857493-remove_dracut_config_generic, # The package doesn't include sysctl.conf or other specific module related # configuration at an install of new kernel if dracut-config-generic package # exists on the system package { 'dracut-config-generic': ensure => absent } ,,7,0
openstack%2Fmanila~stable%2Fstein~I917d3c68fc2014d4bdeefbf7c473ebc2bf6d8979,openstack/manila,stable/stein,I917d3c68fc2014d4bdeefbf7c473ebc2bf6d8979,Fix over-quota exception of snapshot creation,MERGED,2020-01-22 14:05:05.000000000,2020-01-29 14:49:13.000000000,2020-01-28 11:12:30.000000000,"[{'_account_id': 9003}, {'_account_id': 18816}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 25243}, {'_account_id': 30002}]","[{'number': 1, 'created': '2020-01-22 14:05:05.000000000', 'files': ['manila/tests/share/test_api.py', 'manila/share/api.py', 'releasenotes/notes/bug-1859775-snapshot-over-quota-exception-bb6691612af03ddf.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/5f91ab35207fc8e7418fbcb0a62fa1541a51125d', 'message': 'Fix over-quota exception of snapshot creation\n\nReport consumed snapshot gigabytes instead of share gigabytes\n\nChange-Id: I917d3c68fc2014d4bdeefbf7c473ebc2bf6d8979\nCloses-Bug: #1859775\nCo-authored-by: Maurice Escher <maurice.escher@sap.com>\n(cherry picked from commit 5c858bc528bc47929b3519ccc6148c76bde734f0)\n(cherry picked from commit 9c07eb3151584dd89050d6d9e0285727a9da3220)\n'}]",0,703799,5f91ab35207fc8e7418fbcb0a62fa1541a51125d,11,6,1,16643,,,0,"Fix over-quota exception of snapshot creation

Report consumed snapshot gigabytes instead of share gigabytes

Change-Id: I917d3c68fc2014d4bdeefbf7c473ebc2bf6d8979
Closes-Bug: #1859775
Co-authored-by: Maurice Escher <maurice.escher@sap.com>
(cherry picked from commit 5c858bc528bc47929b3519ccc6148c76bde734f0)
(cherry picked from commit 9c07eb3151584dd89050d6d9e0285727a9da3220)
",git fetch https://review.opendev.org/openstack/manila refs/changes/99/703799/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/share/test_api.py', 'manila/share/api.py', 'releasenotes/notes/bug-1859775-snapshot-over-quota-exception-bb6691612af03ddf.yaml']",3,5f91ab35207fc8e7418fbcb0a62fa1541a51125d,bug/1859775-stable/train-stable/stein,--- fixes: - | Fixed Quota exceeded exception for snapshot creation. Consumed gigabytes now reports the snapshot gigabytes instead of share gigabytes usage. ,,11,5
openstack%2Foctavia~master~I053a3519b362f5735042ca8c81da09e290cd3e0f,openstack/octavia,master,I053a3519b362f5735042ca8c81da09e290cd3e0f,Correcting typo in received spelling,ABANDONED,2019-07-30 13:35:57.000000000,2020-01-29 14:47:12.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-07-30 13:35:57.000000000', 'files': ['octavia/cmd/health_manager.py', 'octavia/cmd/house_keeping.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/77d7f84434646c0de3910f1f0fe841180fa44bd3', 'message': 'Correcting typo in received spelling\n\nThere are typographical errors in house_keeping.py and\nhealth_manager.py. Correcting spelling from recieved to received.\n\nChange-Id: I053a3519b362f5735042ca8c81da09e290cd3e0f\n'}]",0,673521,77d7f84434646c0de3910f1f0fe841180fa44bd3,3,1,1,29775,,,0,"Correcting typo in received spelling

There are typographical errors in house_keeping.py and
health_manager.py. Correcting spelling from recieved to received.

Change-Id: I053a3519b362f5735042ca8c81da09e290cd3e0f
",git fetch https://review.opendev.org/openstack/octavia refs/changes/21/673521/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/cmd/health_manager.py', 'octavia/cmd/house_keeping.py']",2,77d7f84434646c0de3910f1f0fe841180fa44bd3,fix-received-spell," LOG.info(""Housekeeping received HUP signal, mutating config."")"," LOG.info(""Housekeeping recieved HUP signal, mutating config."")",2,2
openstack%2Ftripleo-quickstart~master~I572a34d34daed847ae63fd89fb0f1a7123ec873f,openstack/tripleo-quickstart,master,I572a34d34daed847ae63fd89fb0f1a7123ec873f,Correcting typo in environment spelling.,ABANDONED,2019-07-30 01:27:00.000000000,2020-01-29 14:46:04.000000000,,"[{'_account_id': 3153}, {'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-07-30 01:27:00.000000000', 'files': ['config/release/tripleo-ci/RedHat-8/master.yml', 'config/release/tripleo-ci/RedHat-8/promotion-testing-hash-master.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/e22459e6ae7bb12e3f03c171a18b8bf4cfa9ba68', 'message': 'Correcting typo in environment spelling.\n\nThere are typographical errors in master.yml and\npromotion-testing-hash-master.yml. Correcting spelling from enviroment\nto environment.\n\nChange-Id: I572a34d34daed847ae63fd89fb0f1a7123ec873f\n'}]",0,673382,e22459e6ae7bb12e3f03c171a18b8bf4cfa9ba68,5,4,1,29775,,,0,"Correcting typo in environment spelling.

There are typographical errors in master.yml and
promotion-testing-hash-master.yml. Correcting spelling from enviroment
to environment.

Change-Id: I572a34d34daed847ae63fd89fb0f1a7123ec873f
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/82/673382/1 && git format-patch -1 --stdout FETCH_HEAD,"['config/release/tripleo-ci/RedHat-8/master.yml', 'config/release/tripleo-ci/RedHat-8/promotion-testing-hash-master.yml']",2,e22459e6ae7bb12e3f03c171a18b8bf4cfa9ba68,,# limits validation on a specific environment due to restricted access,# limits validation on a specific enviroment due to restricted access,2,2
openstack%2Fbifrost~master~I5aaab91f0590c49972e5eb03d1c70559698b2f39,openstack/bifrost,master,I5aaab91f0590c49972e5eb03d1c70559698b2f39,Check out global requirements when creating test VMs,MERGED,2020-01-28 15:49:54.000000000,2020-01-29 14:45:00.000000000,2020-01-29 14:43:31.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-01-28 15:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/1d3ca0d65a7766aebe575a8d751fa014e9ecf2de', 'message': 'Include bifrost-prep-for-install when creating test VMs\n\nAs part of the test VM preparation, we need to use upper-constraints.\nThis change achieves that (as well as cloning other projects).\n\nChange-Id: I5aaab91f0590c49972e5eb03d1c70559698b2f39\n'}, {'number': 2, 'created': '2020-01-28 16:02:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/c784c3ab81824affc28ee96914d729e54cf11ebe', 'message': 'Check out global requirements when creating test VMs\n\nAs part of the test VM preparation, we need to use upper-constraints.\n\nChange-Id: I5aaab91f0590c49972e5eb03d1c70559698b2f39\n'}, {'number': 3, 'created': '2020-01-28 16:17:48.000000000', 'files': ['playbooks/roles/bifrost-create-vm-nodes/tasks/main.yml', 'playbooks/roles/bifrost-create-vm-nodes/defaults/main.yml', 'scripts/test-bifrost.sh'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/6da10694af43d9902a13b2e7a1c6e4b587a5ce57', 'message': 'Check out global requirements when creating test VMs\n\nAs part of the test VM preparation, we need to use upper-constraints.\n\nChange-Id: I5aaab91f0590c49972e5eb03d1c70559698b2f39\n'}]",0,704598,6da10694af43d9902a13b2e7a1c6e4b587a5ce57,11,3,3,10239,,,0,"Check out global requirements when creating test VMs

As part of the test VM preparation, we need to use upper-constraints.

Change-Id: I5aaab91f0590c49972e5eb03d1c70559698b2f39
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/98/704598/2 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/test-bifrost.sh', 'playbooks/test-bifrost-create-vm.yaml']",2,1d3ca0d65a7766aebe575a8d751fa014e9ecf2de,reqs, - role: bifrost-prep-for-install,,1,7
openstack%2Ftripleo-heat-templates~master~I150212ebac3fed471ffb4e7ed7b6eb6c7af3fad9,openstack/tripleo-heat-templates,master,I150212ebac3fed471ffb4e7ed7b6eb6c7af3fad9,Add DeployIdentifier to extra config containers,MERGED,2020-01-22 18:49:35.000000000,2020-01-29 14:44:14.000000000,2020-01-29 14:44:14.000000000,"[{'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 6926}, {'_account_id': 8655}, {'_account_id': 9592}, {'_account_id': 11082}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23804}]","[{'number': 1, 'created': '2020-01-22 18:49:35.000000000', 'files': ['deployment/ironic/ironic-inspector-container-puppet.yaml', 'deployment/neutron/neutron-mlnx-agent-container-puppet.yaml', 'deployment/experimental/designate/designate-central-container-puppet.yaml', 'deployment/nova/nova-api-container-puppet.yaml', 'deployment/cinder/cinder-api-container-puppet.yaml', 'deployment/glance/glance-api-container-puppet.yaml', 'deployment/zaqar/zaqar-container-puppet.yaml', 'deployment/ironic/ironic-api-container-puppet.yaml', 'deployment/nova/nova-conductor-container-puppet.yaml', 'deployment/octavia/octavia-api-container-puppet.yaml', 'deployment/neutron/neutron-ovs-agent-container-puppet.yaml', 'deployment/ovn/ovn-controller-container-puppet.yaml', 'deployment/gnocchi/gnocchi-api-container-puppet.yaml', 'deployment/keystone/keystone-container-puppet.yaml', 'deployment/mistral/mistral-api-container-puppet.yaml', 'deployment/neutron/neutron-api-container-puppet.yaml', 'deployment/sahara/sahara-api-container-puppet.yaml', 'deployment/heat/heat-engine-container-puppet.yaml', 'deployment/placement/placement-api-container-puppet.yaml', 'deployment/ovn/ovn-metadata-container-puppet.yaml', 'deployment/neutron/neutron-agents-ib-config-container-puppet.yaml', 'deployment/aodh/aodh-api-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/714e1b5d3120b1babfec01c15bf508cc9241ceb2', 'message': 'Add DeployIdentifier to extra config containers\n\nCertain config containers might need to be replaced and re-run\nregardless of whether configuration changes on update and upgrade.\nAdding the DeployIdentifier to the env will ensure that they are.\n\nChange-Id: I150212ebac3fed471ffb4e7ed7b6eb6c7af3fad9\nCloses-Bug: #1860571\n'}]",0,703855,714e1b5d3120b1babfec01c15bf508cc9241ceb2,37,10,1,6681,,,0,"Add DeployIdentifier to extra config containers

Certain config containers might need to be replaced and re-run
regardless of whether configuration changes on update and upgrade.
Adding the DeployIdentifier to the env will ensure that they are.

Change-Id: I150212ebac3fed471ffb4e7ed7b6eb6c7af3fad9
Closes-Bug: #1860571
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/55/703855/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/ironic/ironic-inspector-container-puppet.yaml', 'deployment/neutron/neutron-mlnx-agent-container-puppet.yaml', 'deployment/experimental/designate/designate-central-container-puppet.yaml', 'deployment/nova/nova-api-container-puppet.yaml', 'deployment/cinder/cinder-api-container-puppet.yaml', 'deployment/glance/glance-api-container-puppet.yaml', 'deployment/zaqar/zaqar-container-puppet.yaml', 'deployment/ironic/ironic-api-container-puppet.yaml', 'deployment/nova/nova-conductor-container-puppet.yaml', 'deployment/octavia/octavia-api-container-puppet.yaml', 'deployment/neutron/neutron-ovs-agent-container-puppet.yaml', 'deployment/ovn/ovn-controller-container-puppet.yaml', 'deployment/gnocchi/gnocchi-api-container-puppet.yaml', 'deployment/keystone/keystone-container-puppet.yaml', 'deployment/mistral/mistral-api-container-puppet.yaml', 'deployment/neutron/neutron-api-container-puppet.yaml', 'deployment/sahara/sahara-api-container-puppet.yaml', 'deployment/heat/heat-engine-container-puppet.yaml', 'deployment/placement/placement-api-container-puppet.yaml', 'deployment/ovn/ovn-metadata-container-puppet.yaml', 'deployment/neutron/neutron-agents-ib-config-container-puppet.yaml', 'deployment/aodh/aodh-api-container-puppet.yaml']",22,714e1b5d3120b1babfec01c15bf508cc9241ceb2,, DeployIdentifier: default: '' type: string description: > Setting this to a unique value will re-run any deployment tasks which perform configuration on a Heat stack-update. environment: TRIPLEO_DEPLOY_IDENTIFIER: {get_param: DeployIdentifier},,169,0
openstack%2Ftripleo-common~master~I294910384fc9dd9ca8c7114d08842868909d9e9f,openstack/tripleo-common,master,I294910384fc9dd9ca8c7114d08842868909d9e9f,Raise exception on KeyboardInterrupt,MERGED,2020-01-27 21:53:41.000000000,2020-01-29 14:33:20.000000000,2020-01-29 06:16:03.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-27 21:53:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/46e41de4452db863091a3a1b19f3b6fcc34dec23', 'message': 'Raise exception on KeyboardInterrupt\n\nUsing subprocess with tenacity can lead to issues when a keyboard\ninterrupt occurs because the logic we have will actually trigger a\nretry. This can lead to the inability to stop some of the commands with\na ctrl+c.\n\nChange-Id: I294910384fc9dd9ca8c7114d08842868909d9e9f\nCloses-Bug: #1746724\n'}, {'number': 2, 'created': '2020-01-28 00:26:03.000000000', 'files': ['tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/9003b7ac5be6a54aed0b3cd8172c838c413f17f5', 'message': 'Raise exception on KeyboardInterrupt\n\nUsing subprocess with tenacity can lead to issues when a keyboard\ninterrupt occurs because the logic we have will actually trigger a\nretry. This can lead to the inability to stop some of the commands with\na ctrl+c.\n\nChange-Id: I294910384fc9dd9ca8c7114d08842868909d9e9f\nCloses-Bug: #1746724\n'}]",0,704440,9003b7ac5be6a54aed0b3cd8172c838c413f17f5,13,4,2,14985,,,0,"Raise exception on KeyboardInterrupt

Using subprocess with tenacity can lead to issues when a keyboard
interrupt occurs because the logic we have will actually trigger a
retry. This can lead to the inability to stop some of the commands with
a ctrl+c.

Change-Id: I294910384fc9dd9ca8c7114d08842868909d9e9f
Closes-Bug: #1746724
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/40/704440/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,46e41de4452db863091a3a1b19f3b6fcc34dec23,bug/1746724," try: process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out) if process.returncode != 0: raise ImageUploaderException('Error copying image:\n%s\n%s' % (' '.join(cmd), err)) except KeyboardInterrupt: raise Exception('Action interrupted with ctrl+c') try: process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out.decode('utf-8')) if process.returncode != 0: raise ImageUploaderException('Error deleting image:\n%s\n%s' % (' '.join(cmd), err)) except KeyboardInterrupt: raise Exception('Action interrupted with ctrl+c') try: process = subprocess.Popen( cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True, close_fds=True out, err = process.communicate() if process.returncode != 0: error_msg = ( 'Pulling image failed: cmd ""{}"", stdout ""{}"",' ' stderr ""{}""'.format( ' '.join(cmd), out, err ) ) LOG.error(error_msg) raise ImageUploaderException(error_msg) except KeyboardInterrupt: raise Exception('Action interrupted with ctrl+c') try: p = subprocess.Popen(cmd, stdout=subprocess.PIPE) chunk_size = 2 ** 20 while True: data = p.stdout.read(chunk_size) if not data: break calc_digest.update(data) yield data p.wait() if p.returncode != 0: raise ImageUploaderException('Extracting layer failed') except KeyboardInterrupt: raise Exception('Action interrupted with ctrl+c') try: process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out) if process.returncode != 0: LOG.warning('Error deleting image:\n%s\n%s' % (' '.join(cmd), err)) except KeyboardInterrupt: raise Exception('Action interrupted with ctrl+c')"," process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out) if process.returncode != 0: raise ImageUploaderException('Error copying image:\n%s\n%s' % (' '.join(cmd), err)) process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out.decode('utf-8')) if process.returncode != 0: raise ImageUploaderException('Error deleting image:\n%s\n%s' % (' '.join(cmd), err)) process = subprocess.Popen( cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True, close_fds=True ) out, err = process.communicate() if process.returncode != 0: error_msg = ( 'Pulling image failed: cmd ""{}"", stdout ""{}"",' ' stderr ""{}""'.format( ' '.join(cmd), out, err ) LOG.error(error_msg) raise ImageUploaderException(error_msg) p = subprocess.Popen(cmd, stdout=subprocess.PIPE) chunk_size = 2 ** 20 while True: data = p.stdout.read(chunk_size) if not data: break calc_digest.update(data) yield data p.wait() if p.returncode != 0: raise ImageUploaderException('Extracting layer failed') process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, universal_newlines=True) out, err = process.communicate() LOG.info(out) if process.returncode != 0: LOG.warning('Error deleting image:\n%s\n%s' % (' '.join(cmd), err))",64,49
openstack%2Fkayobe~stable%2Fstein~I074d4b9d444649ecf956d3cd92748862e8c89a5c,openstack/kayobe,stable/stein,I074d4b9d444649ecf956d3cd92748862e8c89a5c,Use {{ openstack_branch }} as version of kolla-ansible in ansible tests,MERGED,2020-01-29 10:29:53.000000000,2020-01-29 14:25:11.000000000,2020-01-29 14:23:12.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 10:29:53.000000000', 'files': ['tools/test-ansible.sh', 'ansible/roles/kolla-ansible/tests/test-requirements.yml', 'ansible/roles/kolla-ansible/tests/test-defaults.yml', 'ansible/roles/kolla-ansible/tests/test-extras.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/f10c8e934254ae8b769b2bf501188e16a5ccd156', 'message': 'Use {{ openstack_branch }} as version of kolla-ansible in ansible tests\n\nInstead of always checking out the master branch, use the kolla-ansible\nbranch with which this Kayobe version is meant to be used.\n\nChange-Id: I074d4b9d444649ecf956d3cd92748862e8c89a5c\n(cherry picked from commit 225130a594e84776b3bfcc852da37cbaeb867c42)\n'}]",0,704771,f10c8e934254ae8b769b2bf501188e16a5ccd156,8,2,1,15197,,,0,"Use {{ openstack_branch }} as version of kolla-ansible in ansible tests

Instead of always checking out the master branch, use the kolla-ansible
branch with which this Kayobe version is meant to be used.

Change-Id: I074d4b9d444649ecf956d3cd92748862e8c89a5c
(cherry picked from commit 225130a594e84776b3bfcc852da37cbaeb867c42)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/71/704771/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/test-ansible.sh', 'ansible/roles/kolla-ansible/tests/test-requirements.yml', 'ansible/roles/kolla-ansible/tests/test-defaults.yml', 'ansible/roles/kolla-ansible/tests/test-extras.yml']",4,f10c8e934254ae8b769b2bf501188e16a5ccd156,," kolla_ansible_source_version: ""{{ openstack_branch }}"""," kolla_ansible_source_version: ""master""",8,4
openstack%2Ftripleo-common~master~Ie77ce22f23c7b8ac23203f790a20a548063d08f9,openstack/tripleo-common,master,Ie77ce22f23c7b8ac23203f790a20a548063d08f9,Remove mistral workflow to return the ssh private key,ABANDONED,2020-01-29 00:13:46.000000000,2020-01-29 14:05:24.000000000,,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-29 00:13:46.000000000', 'files': ['workbooks/deployment.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ccd9ea04894b6101968c94d900c90429bceddbae', 'message': 'Remove mistral workflow to return the ssh private key\n\nThis change uses the local file system to return the ssh private key which is\nknown to be stored in the working directory or in the users home folder.\nAs the method searchs, it attempts to open the key file to ensure that the\ncalling user has access to the key. In the event of a failure, the updated\nmethod will return None, which the calling methods expect.\n\nStory: 2007212\nTask: 38437\n\nChange-Id: Ie77ce22f23c7b8ac23203f790a20a548063d08f9\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}]",0,704713,ccd9ea04894b6101968c94d900c90429bceddbae,7,3,1,7353,,,0,"Remove mistral workflow to return the ssh private key

This change uses the local file system to return the ssh private key which is
known to be stored in the working directory or in the users home folder.
As the method searchs, it attempts to open the key file to ensure that the
calling user has access to the key. In the event of a failure, the updated
method will return None, which the calling methods expect.

Story: 2007212
Task: 38437

Change-Id: Ie77ce22f23c7b8ac23203f790a20a548063d08f9
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/13/704713/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/deployment.yaml'],1,ccd9ea04894b6101968c94d900c90429bceddbae,mistral_to_ansible,, on-success: get_private_key on-error: set_deployment_failed get_private_key: action: tripleo.validations.get_privkey publish: private_key: <% task().result %> publish-on-error: message: <% task().result %>,0,9
openstack%2Ftripleo-quickstart-extras~master~I5c6d418c89fb6ab6d25e5bdbcf098b3fdaf1c87f,openstack/tripleo-quickstart-extras,master,I5c6d418c89fb6ab6d25e5bdbcf098b3fdaf1c87f,Correct logs gzip parameter for centos ci,MERGED,2020-01-29 08:14:15.000000000,2020-01-29 14:04:36.000000000,2020-01-29 14:04:36.000000000,"[{'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2020-01-29 08:14:15.000000000', 'files': ['config/general_config/centosci-logs.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/219d1a3bce821bc08a10bf3f1a3cda7fe5390a48', 'message': 'Correct logs gzip parameter for centos ci\n\nChange-Id: I5c6d418c89fb6ab6d25e5bdbcf098b3fdaf1c87f\n'}]",0,704740,219d1a3bce821bc08a10bf3f1a3cda7fe5390a48,8,5,1,24162,,,0,"Correct logs gzip parameter for centos ci

Change-Id: I5c6d418c89fb6ab6d25e5bdbcf098b3fdaf1c87f
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/40/704740/1 && git format-patch -1 --stdout FETCH_HEAD,['config/general_config/centosci-logs.yml'],1,219d1a3bce821bc08a10bf3f1a3cda7fe5390a48,gzip,artcl_gzip: true,artcl_gzip_only: true,1,1
openstack%2Fcharm-mysql-innodb-cluster~master~I7faf3abc19564d715adb99ea0962c013751cef04,openstack/charm-mysql-innodb-cluster,master,I7faf3abc19564d715adb99ea0962c013751cef04,Rebuild and cleanup,MERGED,2020-01-29 00:18:40.000000000,2020-01-29 14:01:47.000000000,2020-01-29 13:50:17.000000000,"[{'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 00:18:40.000000000', 'files': ['wheelhouse-overrides.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/40e41ad1528880937402014dd099ad5fe31d2f9d', 'message': 'Rebuild and cleanup\n\nRebiuld for charmhelpers.\nRemove wheelhouse overrides in tox.\n\nPlease review and land charm-helpers:\nhttps://github.com/juju/charm-helpers/pull/424\n\nChange-Id: I7faf3abc19564d715adb99ea0962c013751cef04\nPartial-Bug: #1861234\n'}]",0,704715,40e41ad1528880937402014dd099ad5fe31d2f9d,8,3,1,20805,,,0,"Rebuild and cleanup

Rebiuld for charmhelpers.
Remove wheelhouse overrides in tox.

Please review and land charm-helpers:
https://github.com/juju/charm-helpers/pull/424

Change-Id: I7faf3abc19564d715adb99ea0962c013751cef04
Partial-Bug: #1861234
",git fetch https://review.opendev.org/openstack/charm-mysql-innodb-cluster refs/changes/15/704715/1 && git format-patch -1 --stdout FETCH_HEAD,"['wheelhouse-overrides.txt', 'tox.ini']",2,40e41ad1528880937402014dd099ad5fe31d2f9d,bug/1861234, charm-build --log-level DEBUG -o {toxinidir}/build src {posargs}, charm-build --log-level DEBUG --wheelhouse-overrides wheelhouse-overrides.txt -o {toxinidir}/build src {posargs},1,2
openstack%2Ftripleo-heat-templates~stable%2Frocky~I9f8ef2e75acd3184c01ebba3ce7e5d4a71ce2577,openstack/tripleo-heat-templates,stable/rocky,I9f8ef2e75acd3184c01ebba3ce7e5d4a71ce2577,DNM - testing rocky branch change,ABANDONED,2019-03-12 13:40:35.000000000,2020-01-29 13:59:41.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-03-12 13:40:35.000000000', 'files': ['ci/environments/README.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b4e422af46c316f7c8234bfe4013cbc4d24825e4', 'message': 'DNM - testing rocky branch change\n\nChange-Id: I9f8ef2e75acd3184c01ebba3ce7e5d4a71ce2577\n'}]",0,642751,b4e422af46c316f7c8234bfe4013cbc4d24825e4,3,1,1,9976,,,0,"DNM - testing rocky branch change

Change-Id: I9f8ef2e75acd3184c01ebba3ce7e5d4a71ce2577
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/51/642751/1 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/README.rst'],1,b4e422af46c316f7c8234bfe4013cbc4d24825e4,test-rocky, # temp change,,2,0
openstack%2Ftripleo-ci~master~Idba4d373c4da6f1d5af4afd17aa0c1620d281e12,openstack/tripleo-ci,master,Idba4d373c4da6f1d5af4afd17aa0c1620d281e12,DNM - Temp change periodic switch to rely on zuul.job,ABANDONED,2018-12-14 14:48:30.000000000,2020-01-29 13:59:02.000000000,,"[{'_account_id': 10022}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-12-14 14:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/77bf50885565ad1050f7ec454bbe93112adfbca1', 'message': 'DNM - Temp change periodic switch to rely on zuul.job\n\nThis is a temp change to allow testing of periodic\njobs within testproject.\n\nChange-Id: Idba4d373c4da6f1d5af4afd17aa0c1620d281e12\n'}, {'number': 2, 'created': '2018-12-17 13:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/da57e5d57e38249760651736b2f16deaa479fbf9', 'message': 'DNM - Temp change periodic switch to rely on zuul.job\n\nThis is a temp change to allow testing of periodic\njobs within testproject.\n\nChange-Id: Idba4d373c4da6f1d5af4afd17aa0c1620d281e12\n'}, {'number': 3, 'created': '2018-12-19 18:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e83886d9dff6a6109827d723617b240f91681b34', 'message': 'DNM - Temp change periodic switch to rely on zuul.job\n\nThis is a temp change to allow testing of periodic\njobs within testproject.\n\nChange-Id: Idba4d373c4da6f1d5af4afd17aa0c1620d281e12\n'}, {'number': 4, 'created': '2019-01-02 21:55:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9db57f78e6e023ccbe85a3d7d7f23c3dc0176968', 'message': 'DNM - Temp change periodic switch to rely on zuul.job\n\nThis is a temp change to allow testing of periodic\njobs within testproject.\n\nChange-Id: Idba4d373c4da6f1d5af4afd17aa0c1620d281e12\n'}, {'number': 5, 'created': '2019-01-03 15:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/97e68eb76070a64a6d674095b1be83d09642b6dc', 'message': 'DNM - Temp change periodic switch to rely on zuul.job\n\nThis is a temp change to allow testing of periodic\njobs within testproject.\n\nChange-Id: Idba4d373c4da6f1d5af4afd17aa0c1620d281e12\n'}, {'number': 6, 'created': '2019-01-04 14:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/35493e265dabee74a05c0c61a3bdf87748e2d015', 'message': 'DNM - Temp change periodic switch to rely on zuul.job\n\nThis is a temp change to allow testing of periodic\njobs within testproject.\n\nChange-Id: Idba4d373c4da6f1d5af4afd17aa0c1620d281e12\n'}, {'number': 7, 'created': '2019-01-06 18:46:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1121f3aabc3ab59482a9c65474e6396d24ee3cef', 'message': 'DNM - Temp change periodic switch to rely on zuul.job\n\nThis is a temp change to allow testing of periodic\njobs within testproject.\n\nChange-Id: Idba4d373c4da6f1d5af4afd17aa0c1620d281e12\n'}, {'number': 8, 'created': '2019-01-08 13:38:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5f18c028ab3d8a19237f1befd2ba6f63f0245cb2', 'message': 'DNM - Temp change periodic switch to rely on zuul.job\n\nThis is a temp change to allow testing of periodic\njobs within testproject.\n\nChange-Id: Idba4d373c4da6f1d5af4afd17aa0c1620d281e12\n'}, {'number': 9, 'created': '2019-01-11 13:48:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3aa43f4b6bffd7edf5aa20de58587909b0cebb4b', 'message': 'DNM - Temp change periodic switch to rely on zuul.job\n\nThis is a temp change to allow testing of periodic\njobs within testproject.\n\nChange-Id: Idba4d373c4da6f1d5af4afd17aa0c1620d281e12\n'}, {'number': 10, 'created': '2019-01-23 14:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5f928ee2265dadc4b74ead8fca23154256fcf1b2', 'message': 'DNM - Temp change periodic switch to rely on zuul.job\n\nThis is a temp change to allow testing of periodic\njobs within testproject.\n\nChange-Id: Idba4d373c4da6f1d5af4afd17aa0c1620d281e12\n'}, {'number': 11, 'created': '2019-02-22 17:01:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/25e2be0a413e6bf6a2da650125296fd0cc0e3c5f', 'message': 'DNM - Temp change periodic switch to rely on zuul.job\n\nThis is a temp change to allow testing of periodic\njobs within testproject.\n\nChange-Id: Idba4d373c4da6f1d5af4afd17aa0c1620d281e12\n'}, {'number': 12, 'created': '2019-03-04 14:53:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d1b125bd72fc711d305391f287084223fbe963e7', 'message': 'DNM - Temp change periodic switch to rely on zuul.job\n\nThis is a temp change to allow testing of periodic\njobs within testproject.\n\nChange-Id: Idba4d373c4da6f1d5af4afd17aa0c1620d281e12\n'}, {'number': 13, 'created': '2019-05-13 14:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/044c5615d97ea4955321bcd3c2d0676e6e4f6600', 'message': 'DNM - Temp change periodic switch to rely on zuul.job\n\nThis is a temp change to allow testing of periodic\njobs within testproject.\n\nChange-Id: Idba4d373c4da6f1d5af4afd17aa0c1620d281e12\n'}, {'number': 14, 'created': '2019-05-22 16:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/964b5087f03a6dd02f0564d881ae52fa04f281d4', 'message': 'DNM - Temp change periodic switch to rely on zuul.job\n\nThis is a temp change to allow testing of periodic\njobs within testproject.\n\nChange-Id: Idba4d373c4da6f1d5af4afd17aa0c1620d281e12\n'}, {'number': 15, 'created': '2019-06-07 13:37:57.000000000', 'files': ['roles/common/vars/main.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2eaf5e89e25b98c2202618d134acfa82cb1472c3', 'message': 'DNM - Temp change periodic switch to rely on zuul.job\n\nThis is a temp change to allow testing of periodic\njobs within testproject.\n\nChange-Id: Idba4d373c4da6f1d5af4afd17aa0c1620d281e12\n'}]",0,625271,2eaf5e89e25b98c2202618d134acfa82cb1472c3,46,3,15,9976,,,0,"DNM - Temp change periodic switch to rely on zuul.job

This is a temp change to allow testing of periodic
jobs within testproject.

Change-Id: Idba4d373c4da6f1d5af4afd17aa0c1620d281e12
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/71/625271/15 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/tripleo-ci/vars/common.yaml'],1,77bf50885565ad1050f7ec454bbe93112adfbca1,temp-trigger-periodic-check, {% if 'periodic' in zuul.job -%}, {% if 'periodic' in zuul.pipeline -%},1,1
openstack%2Fcharm-cinder~master~I00fa695edb7651098d9c7afdd4df823d66a01aef,openstack/charm-cinder,master,I00fa695edb7651098d9c7afdd4df823d66a01aef,"When resuming, exclude haproxy",MERGED,2020-01-23 16:39:38.000000000,2020-01-29 13:58:31.000000000,2020-01-29 13:58:31.000000000,"[{'_account_id': 12549}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 16:39:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/1a9582470460ec7b7278ebd29319401a696e2f75', 'message': 'When resuming, exclude haproxy\n\nWhen resuming services exclude those managed by hacluster, in\nthis case haproxy. If pacemaker lacks quorum it may shut haproxy\ndown which will cause this charm to error.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: I00fa695edb7651098d9c7afdd4df823d66a01aef\n'}, {'number': 2, 'created': '2020-01-25 07:46:18.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'unit_tests/test_cinder_utils.py', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/hardening/audits/apt.py', 'hooks/cinder_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/605352cfe06d51c553fbbd853c14d4b37a0a8469', 'message': 'When resuming, exclude haproxy\n\nWhen resuming services exclude those managed by hacluster, in\nthis case haproxy. If pacemaker lacks quorum it may shut haproxy\ndown which will cause this charm to error.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: I00fa695edb7651098d9c7afdd4df823d66a01aef\n'}]",0,704030,605352cfe06d51c553fbbd853c14d4b37a0a8469,15,4,2,12549,,,0,"When resuming, exclude haproxy

When resuming services exclude those managed by hacluster, in
this case haproxy. If pacemaker lacks quorum it may shut haproxy
down which will cause this charm to error.

Charmhelper sync included to bring in required
get_managed_services_and_ports method.

Change-Id: I00fa695edb7651098d9c7afdd4df823d66a01aef
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/30/704030/2 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'unit_tests/test_cinder_utils.py', 'charmhelpers/contrib/openstack/amulet/deployment.py', 'charmhelpers/contrib/openstack/audits/openstack_security_guide.py', 'charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/hardening/audits/apt.py', 'charmhelpers/contrib/openstack/policyd.py', 'charmhelpers/contrib/openstack/context.py', 'hooks/cinder_utils.py', 'charmhelpers/contrib/charmsupport/nrpe.py']",13,1a9582470460ec7b7278ebd29319401a696e2f75,exclude-haproxy-from-status," def remove_deprecated_check(nrpe, deprecated_services): """""" Remove checks fro deprecated services in list :param nrpe: NRPE object to remove check from :type nrpe: NRPE :param deprecated_services: List of deprecated services that are removed :type deprecated_services: list """""" for dep_svc in deprecated_services: log('Deprecated service: {}'.format(dep_svc)) nrpe.remove_check(shortname=dep_svc)",,265,18
openstack%2Frpm-packaging~master~I72fbd842c5acccdb9e5349d3763f6df7374b0d7b,openstack/rpm-packaging,master,I72fbd842c5acccdb9e5349d3763f6df7374b0d7b,neutron: Fix build,MERGED,2020-01-24 09:35:32.000000000,2020-01-29 13:47:24.000000000,2020-01-29 13:47:24.000000000,"[{'_account_id': 7102}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-24 09:35:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/cd13f5fe78abe289663ffce4fbd4c9788490a0bb', 'message': 'neutron: Add missing BuildRequires\n\nChange-Id: I72fbd842c5acccdb9e5349d3763f6df7374b0d7b\n'}, {'number': 2, 'created': '2020-01-24 10:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/de0a8932e513457688236fefa1cb6fd82b4b7881', 'message': 'neutron: Fix build\n\nChange-Id: I72fbd842c5acccdb9e5349d3763f6df7374b0d7b\n'}, {'number': 3, 'created': '2020-01-29 11:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/6adb6163714deac6961de9635564082dbdfe5aab', 'message': 'neutron: Fix build\n\n- Add ovn-metadata-agent\n\nChange-Id: I72fbd842c5acccdb9e5349d3763f6df7374b0d7b\n'}, {'number': 4, 'created': '2020-01-29 12:08:20.000000000', 'files': ['openstack/neutron/openstack-neutron-ovn-metadata-agent.service', 'openstack/neutron/neutron.spec.j2', 'openstack/neutron/0001-Use-sys.executable-instead-of-python.patch'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/c2eb4377001bdf4dca217693da1d5553a06c183a', 'message': 'neutron: Fix build\n\n- Add ovn-metadata-agent\n\nChange-Id: I72fbd842c5acccdb9e5349d3763f6df7374b0d7b\n'}]",2,704116,c2eb4377001bdf4dca217693da1d5553a06c183a,23,6,4,7102,,,0,"neutron: Fix build

- Add ovn-metadata-agent

Change-Id: I72fbd842c5acccdb9e5349d3763f6df7374b0d7b
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/16/704116/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/neutron/neutron.spec.j2'],1,cd13f5fe78abe289663ffce4fbd4c9788490a0bb,,BuildRequires: {{ py3('sphinx-feature-classification') }},,1,0
openstack%2Fcharms.openstack~master~Ie57321888f377c10fcc58a3c8441ddd65e92e382,openstack/charms.openstack,master,Ie57321888f377c10fcc58a3c8441ddd65e92e382,"When resuming, exclude haproxy",MERGED,2020-01-24 09:48:58.000000000,2020-01-29 13:35:50.000000000,2020-01-29 13:35:50.000000000,"[{'_account_id': 12549}, {'_account_id': 20634}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-24 09:48:58.000000000', 'files': ['charms_openstack/charm/classes.py', 'charms_openstack/charm/core.py', 'unit_tests/charms_openstack/charm/test_core.py', 'unit_tests/charms_openstack/charm/test_classes.py'], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/4fc4b0f249c6eac8fc9ef84b07f97e367d8fe2dc', 'message': 'When resuming, exclude haproxy\n\nWhen resuming services exclude those managed by hacluster, in\nthis case haproxy. If pacemaker lacks quorum it may shut haproxy\ndown which will cause this charm to error.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: Ie57321888f377c10fcc58a3c8441ddd65e92e382\n'}]",0,704121,4fc4b0f249c6eac8fc9ef84b07f97e367d8fe2dc,8,3,1,12549,,,0,"When resuming, exclude haproxy

When resuming services exclude those managed by hacluster, in
this case haproxy. If pacemaker lacks quorum it may shut haproxy
down which will cause this charm to error.

Charmhelper sync included to bring in required
get_managed_services_and_ports method.

Change-Id: Ie57321888f377c10fcc58a3c8441ddd65e92e382
",git fetch https://review.opendev.org/openstack/charms.openstack refs/changes/21/704121/1 && git format-patch -1 --stdout FETCH_HEAD,"['charms_openstack/charm/classes.py', 'charms_openstack/charm/core.py', 'unit_tests/charms_openstack/charm/test_core.py', 'unit_tests/charms_openstack/charm/test_classes.py']",4,4fc4b0f249c6eac8fc9ef84b07f97e367d8fe2dc,exclude-haproxy-from-status," def test_run_pause_or_resume(self): self.patch_object(chm.os_utils, 'resume_unit') self.patch_target('assess_status') self.patch_object( chm.ch_cluster, 'get_managed_services_and_ports', return_value=(['s1'], [])) self.target.run_pause_or_resume('resume') self.resume_unit.assert_called_once_with( self.assess_status, services=['s1']) ",,33,5
openstack%2Fcharm-swift-proxy~master~I85c380a2cffcd18031a32b6e3eb422aa5ff14994,openstack/charm-swift-proxy,master,I85c380a2cffcd18031a32b6e3eb422aa5ff14994,"When resuming, exclude haproxy",MERGED,2020-01-23 16:39:25.000000000,2020-01-29 13:34:19.000000000,2020-01-29 13:34:19.000000000,"[{'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 16:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/487c5f524c9eb2446a8c0c37581eb3166be8bf5c', 'message': 'When resuming, exclude haproxy\n\nWhen resuming services exclude those managed by hacluster, in\nthis case haproxy. If pacemaker lacks quorum it may shut haproxy\ndown which will cause this charm to error.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: I85c380a2cffcd18031a32b6e3eb422aa5ff14994\n'}, {'number': 2, 'created': '2020-01-27 19:19:32.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'actions/actions.py', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'lib/swift_utils.py', 'charmhelpers/contrib/hardening/audits/apt.py', 'unit_tests/test_actions.py', 'unit_tests/test_swift_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/ab8b60a21cfe775b1914182427d76fb44ea5f113', 'message': 'When resuming, exclude haproxy\n\nWhen resuming services exclude those managed by hacluster, in\nthis case haproxy. If pacemaker lacks quorum it may shut haproxy\ndown which will cause this charm to error.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: I85c380a2cffcd18031a32b6e3eb422aa5ff14994\n'}]",0,704024,ab8b60a21cfe775b1914182427d76fb44ea5f113,10,3,2,12549,,,0,"When resuming, exclude haproxy

When resuming services exclude those managed by hacluster, in
this case haproxy. If pacemaker lacks quorum it may shut haproxy
down which will cause this charm to error.

Charmhelper sync included to bring in required
get_managed_services_and_ports method.

Change-Id: I85c380a2cffcd18031a32b6e3eb422aa5ff14994
",git fetch https://review.opendev.org/openstack/charm-swift-proxy refs/changes/24/704024/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/amulet/deployment.py', 'lib/swift_utils.py', 'charmhelpers/contrib/openstack/audits/openstack_security_guide.py', 'charmhelpers/core/hookenv.py', 'charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/ha/utils.py', 'charmhelpers/contrib/openstack/templates/section-placement', 'actions/actions.py', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/hardening/audits/apt.py', 'charmhelpers/contrib/openstack/vaultlocker.py', 'charmhelpers/contrib/openstack/policyd.py', 'unit_tests/test_actions.py', 'unit_tests/test_swift_utils.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/charmsupport/nrpe.py']",19,487c5f524c9eb2446a8c0c37581eb3166be8bf5c,exclude-haproxy-from-status," def remove_deprecated_check(nrpe, deprecated_services): """""" Remove checks fro deprecated services in list :param nrpe: NRPE object to remove check from :type nrpe: NRPE :param deprecated_services: List of deprecated services that are removed :type deprecated_services: list """""" for dep_svc in deprecated_services: log('Deprecated service: {}'.format(dep_svc)) nrpe.remove_check(shortname=dep_svc)",,596,126
openstack%2Fcharm-nova-cloud-controller~master~I063c168595bee05c924cb23469f8dc866a43982b,openstack/charm-nova-cloud-controller,master,I063c168595bee05c924cb23469f8dc866a43982b,"When resuming, exclude haproxy",MERGED,2020-01-23 16:39:32.000000000,2020-01-29 13:33:39.000000000,2020-01-29 13:33:39.000000000,"[{'_account_id': 12549}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 16:39:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/a17378fdab053f8362448cd0e57ecc1ec35a3c6f', 'message': 'When resuming, exclude haproxy\n\nWhen resuming services exclude those managed by hacluster, in\nthis case haproxy. If pacemaker lacks quorum it may shut haproxy\ndown which will cause this charm to error.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: I063c168595bee05c924cb23469f8dc866a43982b\n'}, {'number': 2, 'created': '2020-01-25 07:48:24.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/hardening/audits/apt.py', 'unit_tests/test_nova_cc_utils.py', 'hooks/nova_cc_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/0a300b919e06841fa292b8b7e9804a542a3c1338', 'message': 'When resuming, exclude haproxy\n\nWhen resuming services exclude those managed by hacluster, in\nthis case haproxy. If pacemaker lacks quorum it may shut haproxy\ndown which will cause this charm to error.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: I063c168595bee05c924cb23469f8dc866a43982b\n'}]",0,704026,0a300b919e06841fa292b8b7e9804a542a3c1338,15,4,2,12549,,,0,"When resuming, exclude haproxy

When resuming services exclude those managed by hacluster, in
this case haproxy. If pacemaker lacks quorum it may shut haproxy
down which will cause this charm to error.

Charmhelper sync included to bring in required
get_managed_services_and_ports method.

Change-Id: I063c168595bee05c924cb23469f8dc866a43982b
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/26/704026/2 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/amulet/deployment.py', 'charmhelpers/contrib/openstack/audits/openstack_security_guide.py', 'charmhelpers/core/hookenv.py', 'charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/ha/utils.py', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/hardening/audits/apt.py', 'charmhelpers/contrib/openstack/vaultlocker.py', 'charmhelpers/contrib/openstack/policyd.py', 'unit_tests/test_nova_cc_utils.py', 'charmhelpers/contrib/openstack/context.py', 'hooks/nova_cc_utils.py', 'charmhelpers/contrib/charmsupport/nrpe.py']",16,a17378fdab053f8362448cd0e57ecc1ec35a3c6f,exclude-haproxy-from-status," def remove_deprecated_check(nrpe, deprecated_services): """""" Remove checks fro deprecated services in list :param nrpe: NRPE object to remove check from :type nrpe: NRPE :param deprecated_services: List of deprecated services that are removed :type deprecated_services: list """""" for dep_svc in deprecated_services: log('Deprecated service: {}'.format(dep_svc)) nrpe.remove_check(shortname=dep_svc)",,570,127
openstack%2Fcharm-openstack-dashboard~master~I6f997df31922b6090e5b4b1daeec342a044be5c3,openstack/charm-openstack-dashboard,master,I6f997df31922b6090e5b4b1daeec342a044be5c3,"When resuming, exclude haproxy",MERGED,2020-01-23 16:39:30.000000000,2020-01-29 13:33:09.000000000,2020-01-29 13:33:09.000000000,"[{'_account_id': 12549}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 16:39:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/18608222a27e0eeeaf5f9315aaf556bafdb00ed3', 'message': 'When resuming, exclude haproxy\n\nWhen resuming services exclude those managed by hacluster, in\nthis case haproxy. If pacemaker lacks quorum it may shut haproxy\ndown which will cause this charm to error.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: I6f997df31922b6090e5b4b1daeec342a044be5c3\n'}, {'number': 2, 'created': '2020-01-25 07:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/2f08ba0644f9d8591c6f11d344c22945c878ea0a', 'message': 'When resuming, exclude haproxy\n\nWhen resuming services exclude those managed by hacluster, in\nthis case haproxy. If pacemaker lacks quorum it may shut haproxy\ndown which will cause this charm to error.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: I6f997df31922b6090e5b4b1daeec342a044be5c3\n'}, {'number': 3, 'created': '2020-01-25 14:04:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/8ff3a86c4e501f2796e4e5216b0bbdc7dfa712ff', 'message': 'When resuming, exclude haproxy\n\nWhen resuming services exclude those managed by hacluster, in\nthis case haproxy. If pacemaker lacks quorum it may shut haproxy\ndown which will cause this charm to error.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: I6f997df31922b6090e5b4b1daeec342a044be5c3\n'}, {'number': 4, 'created': '2020-01-26 07:47:07.000000000', 'files': ['tests/tests.yaml', 'charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/hardening/audits/apt.py', 'hooks/horizon_utils.py', 'unit_tests/test_horizon_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/de4e9ec33854f1679e565cb1c7072afcd261c138', 'message': 'When resuming, exclude haproxy\n\nWhen resuming services exclude those managed by hacluster, in\nthis case haproxy. If pacemaker lacks quorum it may shut haproxy\ndown which will cause this charm to error.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: I6f997df31922b6090e5b4b1daeec342a044be5c3\n'}]",0,704025,de4e9ec33854f1679e565cb1c7072afcd261c138,25,4,4,12549,,,0,"When resuming, exclude haproxy

When resuming services exclude those managed by hacluster, in
this case haproxy. If pacemaker lacks quorum it may shut haproxy
down which will cause this charm to error.

Charmhelper sync included to bring in required
get_managed_services_and_ports method.

Change-Id: I6f997df31922b6090e5b4b1daeec342a044be5c3
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/25/704025/2 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/amulet/deployment.py', 'charmhelpers/contrib/openstack/audits/openstack_security_guide.py', 'charmhelpers/core/hookenv.py', 'charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/ha/utils.py', 'charmhelpers/contrib/openstack/templates/section-placement', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/hardening/audits/apt.py', 'charmhelpers/contrib/openstack/vaultlocker.py', 'charmhelpers/contrib/openstack/policyd.py', 'hooks/horizon_utils.py', 'charmhelpers/contrib/openstack/context.py', 'unit_tests/test_horizon_utils.py', 'charmhelpers/contrib/charmsupport/nrpe.py']",17,18608222a27e0eeeaf5f9315aaf556bafdb00ed3,exclude-haproxy-from-status," def remove_deprecated_check(nrpe, deprecated_services): """""" Remove checks fro deprecated services in list :param nrpe: NRPE object to remove check from :type nrpe: NRPE :param deprecated_services: List of deprecated services that are removed :type deprecated_services: list """""" for dep_svc in deprecated_services: log('Deprecated service: {}'.format(dep_svc)) nrpe.remove_check(shortname=dep_svc)",,428,49
openstack%2Fcharm-heat~master~Ie9aca5cec8505ca63d5bdcafb4f49b00010a4254,openstack/charm-heat,master,Ie9aca5cec8505ca63d5bdcafb4f49b00010a4254,"When resuming, exclude haproxy",MERGED,2020-01-23 16:39:37.000000000,2020-01-29 13:32:14.000000000,2020-01-29 13:32:14.000000000,"[{'_account_id': 12549}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 16:39:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-heat/commit/9cfb7e96fb47fe64fa388029074e4724b944a8ca', 'message': 'When resuming, exclude haproxy\n\nWhen resuming services exclude those managed by hacluster, in\nthis case haproxy. If pacemaker lacks quorum it may shut haproxy\ndown which will cause this charm to error.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: Ie9aca5cec8505ca63d5bdcafb4f49b00010a4254\n'}, {'number': 2, 'created': '2020-01-29 04:40:51.000000000', 'files': ['hooks/charmhelpers/contrib/hahelpers/cluster.py', 'hooks/heat_utils.py', 'hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/fetch/ubuntu_apt_pkg.py', 'hooks/charmhelpers/contrib/hardening/audits/apt.py'], 'web_link': 'https://opendev.org/openstack/charm-heat/commit/d3e2fbfb3766ceacb4bae43850327ebb608f6a20', 'message': 'When resuming, exclude haproxy\n\nWhen resuming services exclude those managed by hacluster, in\nthis case haproxy. If pacemaker lacks quorum it may shut haproxy\ndown which will cause this charm to error.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: Ie9aca5cec8505ca63d5bdcafb4f49b00010a4254\n'}]",0,704029,d3e2fbfb3766ceacb4bae43850327ebb608f6a20,19,4,2,12549,,,0,"When resuming, exclude haproxy

When resuming services exclude those managed by hacluster, in
this case haproxy. If pacemaker lacks quorum it may shut haproxy
down which will cause this charm to error.

Charmhelper sync included to bring in required
get_managed_services_and_ports method.

Change-Id: Ie9aca5cec8505ca63d5bdcafb4f49b00010a4254
",git fetch https://review.opendev.org/openstack/charm-heat refs/changes/29/704029/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/charmhelpers/contrib/openstack/policyd.py', 'hooks/charmhelpers/contrib/hahelpers/cluster.py', 'hooks/charmhelpers/contrib/openstack/amulet/deployment.py', 'hooks/heat_utils.py', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/charmhelpers/contrib/hardening/audits/apt.py', 'hooks/charmhelpers/fetch/ubuntu.py', 'hooks/charmhelpers/contrib/openstack/vaultlocker.py', 'hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/fetch/ubuntu_apt_pkg.py', 'hooks/charmhelpers/contrib/openstack/audits/openstack_security_guide.py', 'hooks/charmhelpers/core/hookenv.py', 'hooks/charmhelpers/contrib/openstack/amulet/utils.py']",13,9cfb7e96fb47fe64fa388029074e4724b944a8ca,exclude-haproxy-from-status," 'bionic_ussuri', 'focal_ussuri',",,542,119
openstack%2Fcharm-glance~master~I9ede7d45e1d4da457d2228caf0367bf374bd51ea,openstack/charm-glance,master,I9ede7d45e1d4da457d2228caf0367bf374bd51ea,"When resuming, exclude haproxy",MERGED,2020-01-23 16:39:49.000000000,2020-01-29 13:27:57.000000000,2020-01-29 13:27:57.000000000,"[{'_account_id': 12549}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 16:39:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/8a0da1e29865e0e8ffac6084f294dc09d27c7813', 'message': 'When resuming, exclude haproxy\n\nWhen resuming services exclude those managed by hacluster, in\nthis case haproxy. If pacemaker lacks quorum it may shut haproxy\ndown which will cause this charm to error.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: I9ede7d45e1d4da457d2228caf0367bf374bd51ea\n'}, {'number': 2, 'created': '2020-01-25 07:42:37.000000000', 'files': ['hooks/glance_utils.py', 'charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/hardening/audits/apt.py', 'unit_tests/test_glance_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/9d60f159e7b6022ebe98521950d0ce7df802b9cf', 'message': 'When resuming, exclude haproxy\n\nWhen resuming services exclude those managed by hacluster, in\nthis case haproxy. If pacemaker lacks quorum it may shut haproxy\ndown which will cause this charm to error.\n\nCharmhelper sync included to bring in required\nget_managed_services_and_ports method.\n\nChange-Id: I9ede7d45e1d4da457d2228caf0367bf374bd51ea\n'}]",0,704031,9d60f159e7b6022ebe98521950d0ce7df802b9cf,16,4,2,12549,,,0,"When resuming, exclude haproxy

When resuming services exclude those managed by hacluster, in
this case haproxy. If pacemaker lacks quorum it may shut haproxy
down which will cause this charm to error.

Charmhelper sync included to bring in required
get_managed_services_and_ports method.

Change-Id: I9ede7d45e1d4da457d2228caf0367bf374bd51ea
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/31/704031/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/glance_utils.py', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/amulet/deployment.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/hardening/audits/apt.py', 'charmhelpers/contrib/openstack/amulet/utils.py', 'charmhelpers/fetch/ubuntu.py', 'unit_tests/test_glance_utils.py']",9,8a0da1e29865e0e8ffac6084f294dc09d27c7813,exclude-haproxy-from-status," @patch.object(utils, 'get_managed_services_and_ports') get_optional_interfaces, get_managed_services_and_ports): get_managed_services_and_ports.return_value = (['s1'], []) services=['s1'], ports=None) @patch.object(utils, 'get_managed_services_and_ports') def test_pause_resume_helper(self, services, get_managed_services_and_ports): services.return_value = ['s1'] get_managed_services_and_ports.return_value = (['s1'], []) f.assert_called_once_with('assessor', services=['s1'], ports=None)"," get_optional_interfaces): services='s1', ports=None) def test_pause_resume_helper(self, services): services.return_value = 's1' f.assert_called_once_with('assessor', services='s1', ports=None)",155,9
openstack%2Fpython-tripleoclient~master~I8179884a9d444dc693e2be32dc6ea5d0f800f57c,openstack/python-tripleoclient,master,I8179884a9d444dc693e2be32dc6ea5d0f800f57c,Remove the openstack overcloud plan commands,ABANDONED,2020-01-28 14:20:20.000000000,2020-01-29 13:26:40.000000000,,"[{'_account_id': 9712}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2020-01-28 14:20:20.000000000', 'files': ['tripleoclient/tests/v1/test_overcloud_plan.py', 'setup.cfg', 'tripleoclient/v1/overcloud_plan.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/3004075f81d6143014bcbbaa3721105f98352ca2', 'message': 'Remove the openstack overcloud plan commands\n\nWith the removal of the TripleO UI the dedicated CLI commands for plan\nmanagement make less sense. These can help users manage the plans in\nSwift, however, the deploy command empties the container and repopulates\nit from the local files making any of these changes redundant.\n\nstory: 2007212\ntask: 38419\ntask: 38420\ntask: 38421\ntask: 38424\nChange-Id: I8179884a9d444dc693e2be32dc6ea5d0f800f57c\n'}]",3,704581,3004075f81d6143014bcbbaa3721105f98352ca2,8,5,1,9712,,,0,"Remove the openstack overcloud plan commands

With the removal of the TripleO UI the dedicated CLI commands for plan
management make less sense. These can help users manage the plans in
Swift, however, the deploy command empties the container and repopulates
it from the local files making any of these changes redundant.

story: 2007212
task: 38419
task: 38420
task: 38421
task: 38424
Change-Id: I8179884a9d444dc693e2be32dc6ea5d0f800f57c
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/81/704581/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/v1/test_overcloud_plan.py', 'setup.cfg', 'tripleoclient/v1/overcloud_plan.py']",3,3004075f81d6143014bcbbaa3721105f98352ca2,,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from __future__ import print_function import logging import os.path from osc_lib.i18n import _ from six.moves.urllib import request from tripleoclient import command from tripleoclient import constants from tripleoclient import exceptions from tripleoclient import utils from tripleoclient.workflows import deployment from tripleoclient.workflows import plan_management class ListPlans(command.Lister): """"""List overcloud deployment plans."""""" log = logging.getLogger(__name__ + "".ListPlans"") def take_action(self, parsed_args): self.log.debug(""take_action(%s)"" % parsed_args) clients = self.app.client_manager plans = plan_management.list_deployment_plans(clients) result = [] for r in plans: result.append((r,)) return ((""Plan Name"",), result) class DeletePlan(command.Command): """"""Delete an overcloud deployment plan. The plan will not be deleted if a stack exists with the same name. """""" log = logging.getLogger(__name__ + "".DeletePlan"") def get_parser(self, prog_name): parser = super(DeletePlan, self).get_parser(prog_name) parser.add_argument('plans', metavar='<name>', nargs=""+"", help=_('Name of the plan(s) to delete')) return parser def take_action(self, parsed_args): self.log.debug(""take_action(%s)"" % parsed_args) clients = self.app.client_manager for plan in parsed_args.plans: print(""Deleting plan %s..."" % plan) plan_management.delete_deployment_plan(clients, container=plan) class CreatePlan(command.Command): """"""Create a deployment plan"""""" log = logging.getLogger(__name__ + "".CreatePlan"") def get_parser(self, prog_name): parser = super(CreatePlan, self).get_parser(prog_name) source_group = parser.add_mutually_exclusive_group() parser.add_argument( 'name', help=_('The name of the plan, which is used for the object ' 'storage container, workflow environment and orchestration ' 'stack names.')) source_group.add_argument( '--templates', help=_('The directory containing the Heat templates to deploy. ' 'If this or --source_url isn\'t provided, the templates ' 'packaged on the Undercloud will be used.'), ) parser.add_argument( '--plan-environment-file', '-p', help=_('Plan Environment file, overrides the default %s in the ' '--templates directory') % constants.PLAN_ENVIRONMENT ) parser.add_argument( '--disable-password-generation', action='store_true', default=False, help=_('Disable password generation.') ) source_group.add_argument( '--source-url', help=_('The url of a git repository containing the Heat templates ' 'to deploy. If this or --templates isn\'t provided, the ' 'templates packaged on the Undercloud will be used.') ) return parser def take_action(self, parsed_args): self.log.debug(""take_action(%s)"" % parsed_args) clients = self.app.client_manager name = parsed_args.name use_default_templates = False generate_passwords = not parsed_args.disable_password_generation source_url = parsed_args.source_url # if the templates and source_url params are not used, then # use the default templates if not parsed_args.templates and not parsed_args.source_url: use_default_templates = True if parsed_args.templates: plan_management.create_plan_from_templates( clients, name, parsed_args.templates, generate_passwords=generate_passwords, plan_env_file=parsed_args.plan_environment_file, validate_stack=False) else: plan_management.create_deployment_plan( clients, container=name, generate_passwords=generate_passwords, source_url=source_url, use_default_templates=use_default_templates) class DeployPlan(command.Command): """"""Deploy a deployment plan"""""" log = logging.getLogger(__name__ + "".DeployPlan"") def get_parser(self, prog_name): parser = super(DeployPlan, self).get_parser(prog_name) parser.add_argument('name', help=_('The name of the plan to deploy.')) parser.add_argument('--timeout', '-t', metavar='<TIMEOUT>', type=int, help=_('Deployment timeout in minutes.')) parser.add_argument('--run-validations', action='store_true', default=False, help=_('Run the pre-deployment validations. These ' 'external validations are from the TripleO ' 'Validations project.')) return parser def take_action(self, parsed_args): self.log.debug(""take_action(%s)"" % parsed_args) clients = self.app.client_manager orchestration_client = clients.orchestration stack = utils.get_stack(orchestration_client, parsed_args.name) print(""Starting to deploy plan: {}"".format(parsed_args.name)) deployment.deploy_and_wait(self.log, clients, stack, parsed_args.name, self.app_args.verbose_level, timeout=parsed_args.timeout, run_validations=parsed_args.run_validations) class ExportPlan(command.Command): """"""Export a deployment plan"""""" log = logging.getLogger(__name__ + "".ExportPlan"") def get_parser(self, prog_name): parser = super(ExportPlan, self).get_parser(prog_name) parser.add_argument('plan', metavar='<name>', help=_('Name of the plan to export.')) parser.add_argument('--output-file', '-o', metavar='<output file>', help=_('Name of the output file for export. ' 'It will default to ""<name>.tar.gz"".')) parser.add_argument('--force-overwrite', '-f', action='store_true', default=False, help=_('Overwrite output file if it exists.')) return parser def take_action(self, parsed_args): self.log.debug(""take_action(%s)"" % parsed_args) plan = parsed_args.plan outfile = parsed_args.output_file or '%s.tar.gz' % plan if os.path.exists(outfile) and not parsed_args.force_overwrite: raise exceptions.PlanExportError( ""File '%s' already exists, not exporting."" % outfile) print(""Exporting plan %s..."" % plan) tempurl = plan_management.export_deployment_plan( self.app.client_manager, plan=plan ) f = request.urlopen(tempurl) tarball_contents = f.read() f.close() with open(outfile, 'wb') as f: f.write(tarball_contents) ",0,711
openstack%2Fmanila~master~I4bd02918ff08711dfadbd129b70b79d843ef7634,openstack/manila,master,I4bd02918ff08711dfadbd129b70b79d843ef7634,[WIP] Fix unlimited share replica per share,NEW,2019-11-26 17:12:29.000000000,2020-01-29 13:11:42.000000000,,"[{'_account_id': 12016}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22348}, {'_account_id': 29632}]","[{'number': 1, 'created': '2019-11-26 17:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/1faf9727ecf9746cdb63368167ba36d2708d887f', 'message': '[WIP] Fix unlimited share replica per share\n\nThis patch fixes a bug that makes the user able to create unlimited\nshare replicas from a given share. Now, we have some validations\nin the share type and the administrator is able to specify how many\nshare replicas a given share type is able to support.\n\nChange-Id: I4bd02918ff08711dfadbd129b70b79d843ef7634\nCloses-Bug: #1850545\n'}, {'number': 2, 'created': '2019-12-06 20:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a05dc20741b0f0c9246ab9b39c7af2eb2140aa90', 'message': '[WIP] Fix unlimited share replica per share\n\nThis patch fixes a bug that makes the user able to create unlimited\nshare replicas from a given share. Now, we have some validations\nin the share type and the administrator is able to specify how many\nshare replicas a given share type is able to support.\n\nChange-Id: I4bd02918ff08711dfadbd129b70b79d843ef7634\nCloses-Bug: #1850545\n'}, {'number': 3, 'created': '2019-12-13 13:09:08.000000000', 'files': ['manila/scheduler/utils.py', 'manila/share/share_types.py', 'manila/db/migrations/alembic/versions/f80875efcff0_add_max_replica_limit_to_share_type_.py', 'manila/tests/api/v2/test_share_types.py', 'manila/tests/db/migrations/alembic/migrations_data_checks.py', 'manila/api/v2/share_types.py', 'manila/common/constants.py', 'manila/api/v2/share_replicas.py', 'manila/tests/api/v1/test_share_types_extra_specs.py', 'manila/tests/api/v2/test_share_replicas.py', 'manila/tests/share/test_share_types.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/b55f214921b9db874befe1f2ded119e10dc1e0c9', 'message': '[WIP] Fix unlimited share replica per share\n\nThis patch fixes a bug that makes the user able to create unlimited\nshare replicas from a given share. Now, we have some validations\nin the share type and the administrator is able to specify how many\nshare replicas a given share type is able to support.\n\nChange-Id: I4bd02918ff08711dfadbd129b70b79d843ef7634\nDepends-On: I2c690b8740d3888c3737c880704c6d28bd7df47f\nCloses-Bug:~#1850545\n'}]",0,696136,b55f214921b9db874befe1f2ded119e10dc1e0c9,33,7,3,29632,,,0,"[WIP] Fix unlimited share replica per share

This patch fixes a bug that makes the user able to create unlimited
share replicas from a given share. Now, we have some validations
in the share type and the administrator is able to specify how many
share replicas a given share type is able to support.

Change-Id: I4bd02918ff08711dfadbd129b70b79d843ef7634
Depends-On: I2c690b8740d3888c3737c880704c6d28bd7df47f
Closes-Bug:~#1850545
",git fetch https://review.opendev.org/openstack/manila refs/changes/36/696136/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/scheduler/utils.py', 'manila/db/migrations/alembic/versions/f80875efcff0_add_max_replica_limit_to_share_type_.py', 'manila/tests/db/migrations/alembic/migrations_data_checks.py', 'manila/api/v2/share_replicas.py', 'manila/tests/api/v2/test_share_replicas.py']",5,1faf9727ecf9746cdb63368167ba36d2708d887f,limit-share-replicas-per-share," share_id = 'FAKE_SHAREID' 'share_id': share_id, self.mock_object( self.controller, '_get_allowed_replica_amount', mock.Mock(return_value=2)) self.mock_object(share_replicas.db, 'share_replicas_get_all_by_share', mock.Mock(return_value=[fake_replica])) self.controller._get_allowed_replica_amount.assert_called_once_with( self.member_context, fake_replica ) (share_replicas.db.share_replicas_get_all_by_share .assert_called_once_with(self.member_context, share_id)) share_id = 'FAKE_SHAREID' 'share_id': share_id, self.mock_object( self.controller, '_get_allowed_replica_amount', mock.Mock(return_value=2)) self.mock_object(share_replicas.db, 'share_replicas_get_all_by_share', mock.Mock(return_value=[fake_replica])) self.controller._get_allowed_replica_amount.assert_called_once_with( req_context, fake_replica ) (share_replicas.db.share_replicas_get_all_by_share .assert_called_once_with(req_context, share_id)) def test_create_max_replicas_reached(self): share_id = 'FAKE_SHAREID' fake_share = {'id': share_id} fake_replica, _ = self._get_fake_replica( replication_type='writable') body = { 'share_replica': { 'share_id': share_id, 'availability_zone': 'FAKE_AZ' } } self.mock_object(share_replicas.db, 'share_get', mock.Mock(return_value=fake_share)) self.mock_object(share_replicas.db, 'share_replicas_get_available_active_replica', mock.Mock(return_value=[{'id': 'active1'}])) self.mock_object( self.controller, '_get_allowed_replica_amount', mock.Mock(return_value=1)) self.mock_object(share_replicas.db, 'share_replicas_get_all_by_share', mock.Mock(return_value=[fake_replica])) self.assertRaises(exc.HTTPBadRequest, self.controller.create, self.replicas_req, body) share_replicas.db.share_get.assert_called_once_with( self.member_context, share_id) self.controller._get_allowed_replica_amount( self.member_context, fake_share) (share_replicas.db.share_replicas_get_all_by_share .assert_called_once_with(self.member_context, share_id))"," 'share_id': 'FAKE_SHAREID', 'share_id': 'FAKE_SHAREID',",180,2
openstack%2Fmanila-tempest-plugin~master~I2c690b8740d3888c3737c880704c6d28bd7df47f,openstack/manila-tempest-plugin,master,I2c690b8740d3888c3737c880704c6d28bd7df47f,[WIP] Fit share types tests to max_replica_per_share,NEW,2019-12-13 13:07:45.000000000,2020-01-29 13:11:30.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-12-13 13:07:45.000000000', 'files': ['manila_tempest_tests/tests/api/base.py', 'manila_tempest_tests/tests/api/admin/test_share_types_extra_specs_negative.py'], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/d543f93d667492e6e54ce4e36a55695bd06916a3', 'message': '[WIP] Fit share types tests to max_replica_per_share\n\nThis change fits the existent share types functional tests in order\nto make it accomplish with the `max_replica_per_share` validations.\n\nChange-Id: I2c690b8740d3888c3737c880704c6d28bd7df47f\n'}]",0,698904,d543f93d667492e6e54ce4e36a55695bd06916a3,3,1,1,29632,,,0,"[WIP] Fit share types tests to max_replica_per_share

This change fits the existent share types functional tests in order
to make it accomplish with the `max_replica_per_share` validations.

Change-Id: I2c690b8740d3888c3737c880704c6d28bd7df47f
",git fetch https://review.opendev.org/openstack/manila-tempest-plugin refs/changes/04/698904/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila_tempest_tests/tests/api/base.py', 'manila_tempest_tests/tests/api/admin/test_share_types_extra_specs_negative.py']",2,d543f93d667492e6e54ce4e36a55695bd06916a3,limit-share-replicas-per-share," if utils.is_microversion_ge(CONF.share.max_api_microversion, '2.51'): expected_keys.append('max_replica_per_share')",,3,0
openstack%2Fmanila-tempest-plugin~master~I34832d395afc0e009a19ecaec26a3f586f45db38,openstack/manila-tempest-plugin,master,I34832d395afc0e009a19ecaec26a3f586f45db38,[WIP] Add new test for share types replica limit,NEW,2019-11-26 17:16:13.000000000,2020-01-29 13:10:54.000000000,,"[{'_account_id': 22348}, {'_account_id': 29632}]","[{'number': 1, 'created': '2019-11-26 17:16:13.000000000', 'files': ['manila_tempest_tests/tests/api/test_replication_negative.py'], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/7f330a85e9e0108616eb91a5732ebb8c46139461', 'message': '[WIP] Add new test for share types replica limit\n\nThis patch adds a new test in order to validate the provided fix\nfor creating unlimited share replicas.\n\nChange-Id: I34832d395afc0e009a19ecaec26a3f586f45db38\nDepends-On: I4bd02918ff08711dfadbd129b70b79d843ef7634\n'}]",0,696138,7f330a85e9e0108616eb91a5732ebb8c46139461,5,2,1,29632,,,0,"[WIP] Add new test for share types replica limit

This patch adds a new test in order to validate the provided fix
for creating unlimited share replicas.

Change-Id: I34832d395afc0e009a19ecaec26a3f586f45db38
Depends-On: I4bd02918ff08711dfadbd129b70b79d843ef7634
",git fetch https://review.opendev.org/openstack/manila-tempest-plugin refs/changes/38/696138/1 && git format-patch -1 --stdout FETCH_HEAD,['manila_tempest_tests/tests/api/test_replication_negative.py'],1,7f330a85e9e0108616eb91a5732ebb8c46139461,limit-share-replicas-per-share," @tc.attr(base.TAG_NEGATIVE, base.TAG_API_WITH_BACKEND) def test_try_create_replica_limit_of_allowed_replicas_reached(self): # Update the share type extra spec to have a max replica number self.admin_shares_v2_client.update_share_type_extra_spec( self.share_type['id'], 'max_replica_per_share', '2') # Create the first replica self.create_share_replica(self.share1[""id""], self.replica_zone, cleanup_in_class=False) self.addCleanup( self.admin_shares_v2_client.delete_share_type_extra_spec, self.share_type['id'], 'max_replica_per_share') # Assert that the API will not allow more replicas than the max number # specified self.assertRaises(lib_exc.BadRequest, self.create_share_replica, self.share1['id'], self.replica_zone) ",,20,0
openstack%2Fneutron~master~If0adb7ca4e254f5b19375b471679bcc18e0c7790,openstack/neutron,master,If0adb7ca4e254f5b19375b471679bcc18e0c7790,Remove one of iptables_hybrid jobs,MERGED,2019-11-13 11:16:43.000000000,2020-01-29 13:08:59.000000000,2019-11-15 08:43:36.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 15554}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-11-13 11:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c05c0aaaec5fd8a56b7d82182fe1076c704c830f', 'message': 'Remove one of iptables_hybrid jobs\n\nIn check queue there were 2 iptables_hybrid jobs. One was run on Ubuntu\nand one on Fedora.\nDuring the Shanghai PTG we agreed to remove one of those jobs and left\nonly one of them to be run in both check and gate queues.\n\nThis commit removes iptables_hybrid job based on Ubuntu image. Now only\njob based on latest Fedora will be run in Neutron CI.\n\nChange-Id: If0adb7ca4e254f5b19375b471679bcc18e0c7790\n'}, {'number': 2, 'created': '2019-11-14 11:25:20.000000000', 'files': ['.zuul.yaml', 'doc/source/contributor/testing/ci_scenario_jobs.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a2fdf8aa72859be748918d56c819736b9ae048c2', 'message': 'Remove one of iptables_hybrid jobs\n\nIn check queue there were 2 iptables_hybrid jobs. One was run on Ubuntu\nand one on Fedora.\nDuring the Shanghai PTG we agreed to remove one of those jobs and left\nonly one of them to be run in both check and gate queues.\n\nThis commit removes iptables_hybrid job based on Fedora image.\n\nChange-Id: If0adb7ca4e254f5b19375b471679bcc18e0c7790\n'}]",2,694045,a2fdf8aa72859be748918d56c819736b9ae048c2,18,10,2,11975,,,0,"Remove one of iptables_hybrid jobs

In check queue there were 2 iptables_hybrid jobs. One was run on Ubuntu
and one on Fedora.
During the Shanghai PTG we agreed to remove one of those jobs and left
only one of them to be run in both check and gate queues.

This commit removes iptables_hybrid job based on Fedora image.

Change-Id: If0adb7ca4e254f5b19375b471679bcc18e0c7790
",git fetch https://review.opendev.org/openstack/neutron refs/changes/45/694045/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,c05c0aaaec5fd8a56b7d82182fe1076c704c830f,remove-iptables-hybrid-job, - neutron-tempest-iptables_hybrid-fedora name: neutron-tempest-iptables_hybrid-fedora nodeset: devstack-single-node-fedora-latest, - neutron-tempest-iptables_hybrid - neutron-tempest-iptables_hybrid name: neutron-tempest-iptables_hybrid name: neutron-tempest-iptables_hybrid-fedora parent: neutron-tempest-iptables_hybrid nodeset: devstack-single-node-fedora-latest irrelevant-files: *tempest-irrelevant-files - job:,3,9
openstack%2Fproject-config~master~I774cf28fe93e7b0337368e32884c3d7a2477ae54,openstack/project-config,master,I774cf28fe93e7b0337368e32884c3d7a2477ae54,Remove publishing job for transparency-policy,MERGED,2020-01-29 07:47:26.000000000,2020-01-29 12:46:47.000000000,2020-01-29 12:46:47.000000000,"[{'_account_id': 1004}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 07:47:26.000000000', 'files': ['zuul.d/projects.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/d648673787024f15458414022da991d7943fe5bd', 'message': 'Remove publishing job for transparency-policy\n\nTransparency-policy repo is dead and the content lives on\nwww.openstack.org, remove the publishing. We can add it back if the repo\ngets active again and publishes elsewhere.\n\nChange-Id: I774cf28fe93e7b0337368e32884c3d7a2477ae54\n'}]",0,704737,d648673787024f15458414022da991d7943fe5bd,8,3,1,6547,,,0,"Remove publishing job for transparency-policy

Transparency-policy repo is dead and the content lives on
www.openstack.org, remove the publishing. We can add it back if the repo
gets active again and publishes elsewhere.

Change-Id: I774cf28fe93e7b0337368e32884c3d7a2477ae54
",git fetch https://review.opendev.org/openstack/project-config refs/changes/37/704737/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/projects.yaml', 'zuul.d/jobs.yaml']",2,d648673787024f15458414022da991d7943fe5bd,static-services,, - openstack/transparency-policy,0,4
openstack%2Fneutron~master~I5e9b6b70b502caf9dd6ec78f293f9d4b5b45e360,openstack/neutron,master,I5e9b6b70b502caf9dd6ec78f293f9d4b5b45e360,Fix OVN agent devstack script to support IPv6,MERGED,2020-01-21 20:02:47.000000000,2020-01-29 12:14:34.000000000,2020-01-29 12:12:06.000000000,"[{'_account_id': 1131}, {'_account_id': 5756}, {'_account_id': 6773}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 24791}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-21 20:02:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/71f132d2a9133f7aa2fa968ff4418c463e04ca0e', 'message': 'Un-quote metadata address if it is IPv6\n\nIn the devstack lib/neutron-legacy code, the Nova metadata\nhost address is un-quoted if it is IPv6, i.e. 2001:db8::1,\nnot [2001:db8::1].  We should be doing the same here.\n\nChange-Id: I5e9b6b70b502caf9dd6ec78f293f9d4b5b45e360\n'}, {'number': 2, 'created': '2020-01-22 22:22:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ea12bee5f07134dc02b2790fe9309fb12a54c8ae', 'message': 'Fix OVN agent devstack script to support IPv6\n\nThere are variables in devstack that should be used\nfor services listening endpoints which change depending\non what SERVICE_IP_VERSION is set to, 4 or 6. Use them\nin the ovn_agent script to support IPv6.\n\nChange ovsdb-server to listen on $SERVICE_LOCAL_HOST\ninstead of 127.0.0.1.\n\nChange ovn-northd to listen on 0.0.0.0 instead of\n$SERVICE_HOST.\n\nUn-quote the metadata host address if it is IPv6, i.e.\n2001:db8::1, not [2001:db8::1].\n\nCloses-bug: #1860612\nChange-Id: I5e9b6b70b502caf9dd6ec78f293f9d4b5b45e360\n'}, {'number': 3, 'created': '2020-01-23 18:56:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d9f340a465d2ef5ae91030c112aafbc19ac328e', 'message': 'Fix OVN agent devstack script to support IPv6\n\nThere are variables in devstack that should be used\nfor services listening endpoints which change depending\non what SERVICE_IP_VERSION is set to, 4 or 6. Use them\nin the ovn_agent script to support IPv6.\n\nChange ovsdb-server to listen on $SERVICE_LOCAL_HOST\ninstead of 127.0.0.1.\n\nChange ovn-northd to listen on 0.0.0.0 instead of\n$SERVICE_LISTEN_ADDRESS.\n\nUn-quote the metadata host address if it is IPv6, i.e.\n2001:db8::1, not [2001:db8::1].\n\nCloses-bug: #1860612\nChange-Id: I5e9b6b70b502caf9dd6ec78f293f9d4b5b45e360\n'}, {'number': 4, 'created': '2020-01-28 23:28:14.000000000', 'files': ['devstack/lib/ovn_agent'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7fa564ba2cc9e894c742f18efdce8715de4f1088', 'message': 'Fix OVN agent devstack script to support IPv6\n\nThere are variables in devstack that should be used\nfor services listening endpoints which change depending\non what SERVICE_IP_VERSION is set to, 4 or 6. Use them\nin the ovn_agent script to support IPv6.\n\nChange ovsdb-server to listen on [$SERVICE_LOCAL_HOST]\nif IPv6, else 127.0.0.1 if IPv4.\n\nChange ovn-northd to listen on 0.0.0.0 instead of\n$SERVICE_LISTEN_ADDRESS.\n\nUn-quote the metadata host address if it is IPv6, i.e.\n2001:db8::1, not [2001:db8::1].\n\nCloses-bug: #1860612\nChange-Id: I5e9b6b70b502caf9dd6ec78f293f9d4b5b45e360\n'}]",4,703685,7fa564ba2cc9e894c742f18efdce8715de4f1088,40,8,4,1131,,,0,"Fix OVN agent devstack script to support IPv6

There are variables in devstack that should be used
for services listening endpoints which change depending
on what SERVICE_IP_VERSION is set to, 4 or 6. Use them
in the ovn_agent script to support IPv6.

Change ovsdb-server to listen on [$SERVICE_LOCAL_HOST]
if IPv6, else 127.0.0.1 if IPv4.

Change ovn-northd to listen on 0.0.0.0 instead of
$SERVICE_LISTEN_ADDRESS.

Un-quote the metadata host address if it is IPv6, i.e.
2001:db8::1, not [2001:db8::1].

Closes-bug: #1860612
Change-Id: I5e9b6b70b502caf9dd6ec78f293f9d4b5b45e360
",git fetch https://review.opendev.org/openstack/neutron refs/changes/85/703685/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/ovn_agent'],1,71f132d2a9133f7aa2fa968ff4418c463e04ca0e,unqoute-ipv6-metadata,OVN_META_DATA_HOST=${OVN_META_DATA_HOST:-$(ipv6_unquote $SERVICE_HOST)} iniset $OVN_META_CONF DEFAULT nova_metadata_host $OVN_META_DATA_HOST, iniset $OVN_META_CONF DEFAULT nova_metadata_host $SERVICE_HOST,2,1
openstack%2Fplacement~master~Ied6223a7922566593d51a61790e693efd4588d14,openstack/placement,master,Ied6223a7922566593d51a61790e693efd4588d14,Provide more accurate links in doc/source/user/provider-tree.rst,MERGED,2020-01-29 09:51:24.000000000,2020-01-29 12:13:34.000000000,2020-01-29 12:12:08.000000000,"[{'_account_id': 11564}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-29 09:51:24.000000000', 'files': ['doc/source/user/provider-tree.rst'], 'web_link': 'https://opendev.org/openstack/placement/commit/971c7aa76e1a3455acf8cf2210b3b7af29846696', 'message': 'Provide more accurate links in doc/source/user/provider-tree.rst\n\nChange-Id: Ied6223a7922566593d51a61790e693efd4588d14\nStory: #2007231\nTask: #38507\n'}]",0,704761,971c7aa76e1a3455acf8cf2210b3b7af29846696,7,2,1,23950,,,0,"Provide more accurate links in doc/source/user/provider-tree.rst

Change-Id: Ied6223a7922566593d51a61790e693efd4588d14
Story: #2007231
Task: #38507
",git fetch https://review.opendev.org/openstack/placement refs/changes/61/704761/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/provider-tree.rst'],1,971c7aa76e1a3455acf8cf2210b3b7af29846696,fix-improper-doc,.. _`POST /resource_providers`: https://docs.openstack.org/api-ref/placement/#create-resource-provider .. _`PUT /resource_providers/{uuid}`: https://docs.openstack.org/api-ref/placement/#update-resource-provider .. _`GET /allocation_candidates`: https://docs.openstack.org/api-ref/placement/#list-allocation-candidates,.. _`POST /resource_providers`: https://docs.openstack.org/api-ref/placement/ .. _`PUT /resource_providers/{uuid}`: https://docs.openstack.org/api-ref/placement/ .. _`GET /allocation_candidates`: https://docs.openstack.org/api-ref/placement/,3,3
openstack%2Fneutron-tempest-plugin~master~Ib0a4e8bb6baf596f441539c6fb93ab2ebc4f98af,openstack/neutron-tempest-plugin,master,Ib0a4e8bb6baf596f441539c6fb93ab2ebc4f98af,Fix how netcat is called when started as server,MERGED,2020-01-16 14:51:58.000000000,2020-01-29 12:12:13.000000000,2020-01-29 12:12:13.000000000,"[{'_account_id': 4694}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 14:51:58.000000000', 'files': ['neutron_tempest_plugin/scenario/base.py'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/bc200b575ba7caced2b8fafe718847c1cfe624be', 'message': 'Fix how netcat is called when started as server\n\nNetcat started as server was started with ""-e"" option which,\naccording to documentation in [1] should be used to pass filename\nof script which will be executed after connect.\nIn scenario tests we are not using any additional script,\nbut we are passing simple shell command which should be executed\n(""echo $msg""). That should be passed with ""-c"" option instead of\n""-e"" and this patch is changing exactly that.\n\n[1] https://manpages.debian.org/testing/netcat-traditional/nc.1.en.html\n\nChange-Id: Ib0a4e8bb6baf596f441539c6fb93ab2ebc4f98af\n'}]",0,702882,bc200b575ba7caced2b8fafe718847c1cfe624be,16,5,1,11975,,,0,"Fix how netcat is called when started as server

Netcat started as server was started with ""-e"" option which,
according to documentation in [1] should be used to pass filename
of script which will be executed after connect.
In scenario tests we are not using any additional script,
but we are passing simple shell command which should be executed
(""echo $msg""). That should be passed with ""-c"" option instead of
""-e"" and this patch is changing exactly that.

[1] https://manpages.debian.org/testing/netcat-traditional/nc.1.en.html

Change-Id: Ib0a4e8bb6baf596f441539c6fb93ab2ebc4f98af
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/82/702882/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_tempest_plugin/scenario/base.py'],1,bc200b575ba7caced2b8fafe718847c1cfe624be,fix-nc-server-args," cmd = ""sudo nc %(udp)s -p %(port)s -lk -c echo %(msg)s &"" % {"," cmd = ""sudo nc %(udp)s -p %(port)s -lk -e echo %(msg)s &"" % {",1,1
openstack%2Frpm-packaging~stable%2Frocky~Ia578fa24c6f3c3af789ea54bfae3adb0c604262c,openstack/rpm-packaging,stable/rocky,Ia578fa24c6f3c3af789ea54bfae3adb0c604262c,add freezegun requirement,MERGED,2020-01-29 03:46:19.000000000,2020-01-29 12:02:01.000000000,2020-01-29 12:02:01.000000000,"[{'_account_id': 2062}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-29 03:46:19.000000000', 'files': ['openstack/monasca-agent/monasca-agent.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/ef1449b447d6bfe0986dcc405399d26f9d2ea082', 'message': 'add freezegun requirement\n\nNeed to add freezegun requirement per\nhttps://review.opendev.org/#/c/702896\n\nChange-Id: Ia578fa24c6f3c3af789ea54bfae3adb0c604262c\n'}]",0,704722,ef1449b447d6bfe0986dcc405399d26f9d2ea082,9,5,1,1916,,,0,"add freezegun requirement

Need to add freezegun requirement per
https://review.opendev.org/#/c/702896

Change-Id: Ia578fa24c6f3c3af789ea54bfae3adb0c604262c
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/22/704722/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/monasca-agent/monasca-agent.spec.j2'],1,ef1449b447d6bfe0986dcc405399d26f9d2ea082,add_freezegun_req,BuildRequires: {{ py2pkg('freezegun') }},,1,0
openstack%2Fkolla~master~I18fba8a5c2f99b700990cbf41c76077a1ec2408a,openstack/kolla,master,I18fba8a5c2f99b700990cbf41c76077a1ec2408a,CentOS 8: base and openstack-base images,MERGED,2019-12-17 13:44:17.000000000,2020-01-29 11:57:51.000000000,2020-01-29 11:55:19.000000000,"[{'_account_id': 9592}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23181}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-12-17 13:44:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/cf5d7d4000cc27f524a176a44ebcc76b38493394', 'message': 'CentOS 8: base and openstack-base images\n\nAdds support to the base and openstack-base images for CentOS 8.\n\nChange-Id: I18fba8a5c2f99b700990cbf41c76077a1ec2408a\nPartially-Implements: blueprint centos-rhel-8\n'}, {'number': 2, 'created': '2019-12-21 14:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/e5f1e70b834a060aaf4eb0be6f43430b7297b2de', 'message': 'CentOS 8: base and openstack-base images\n\nAdds support to the base and openstack-base images for CentOS 8.\n\nChange-Id: I18fba8a5c2f99b700990cbf41c76077a1ec2408a\nPartially-Implements: blueprint centos-rhel-8\n'}, {'number': 3, 'created': '2020-01-07 09:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/3c1f5a2c665c5704088ccc28322d4654003998b1', 'message': 'CentOS 8: base and openstack-base images\n\nAdds support to the base and openstack-base images for CentOS 8.\n\nChange-Id: I18fba8a5c2f99b700990cbf41c76077a1ec2408a\nPartially-Implements: blueprint centos-rhel-8\n'}, {'number': 4, 'created': '2020-01-07 12:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/5f7552162c0eeaec32a5a2e983c823fee7281ac3', 'message': 'CentOS 8: base and openstack-base images\n\nAdds support to the base and openstack-base images for CentOS 8.\n\nChange-Id: I18fba8a5c2f99b700990cbf41c76077a1ec2408a\nPartially-Implements: blueprint centos-rhel-8\n'}, {'number': 5, 'created': '2020-01-08 09:38:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/94eee5234b09323a3546a3bfd20df4687bdaca6b', 'message': 'CentOS 8: base and openstack-base images\n\nAdds support to the base and openstack-base images for CentOS 8.\n\nChange-Id: I18fba8a5c2f99b700990cbf41c76077a1ec2408a\nPartially-Implements: blueprint centos-rhel-8\n'}, {'number': 6, 'created': '2020-01-09 15:00:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/a0b676337409bbe99cabdfc0e8a38e8133316547', 'message': 'CentOS 8: base and openstack-base images\n\nAdds support to the base and openstack-base images for CentOS 8.\nThese images have been removed from the list of unbuildable images, and\nreplaced with all dependent images.\n\nChange-Id: I18fba8a5c2f99b700990cbf41c76077a1ec2408a\nPartially-Implements: blueprint centos-rhel-8\n'}, {'number': 7, 'created': '2020-01-09 15:46:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/58ad6284bf263e0cda8a8d326f92582e80fc9922', 'message': 'CentOS 8: base and openstack-base images\n\nAdds support to the base and openstack-base images for CentOS 8.\nThese images have been removed from the list of unbuildable images, and\nreplaced with all dependent images.\n\nChange-Id: I18fba8a5c2f99b700990cbf41c76077a1ec2408a\nPartially-Implements: blueprint centos-rhel-8\n'}, {'number': 8, 'created': '2020-01-09 15:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/46d1500a981d92f6fe6826e1602a94729ca3ec12', 'message': 'CentOS 8: base and openstack-base images\n\nAdds support to the base and openstack-base images for CentOS 8.\nThese images have been removed from the list of unbuildable images, and\nreplaced with all dependent images.\n\nChange-Id: I18fba8a5c2f99b700990cbf41c76077a1ec2408a\nPartially-Implements: blueprint centos-rhel-8\n'}, {'number': 9, 'created': '2020-01-09 16:55:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/7c6f700f7a2c86f95aed55752dde6c7557e80bf6', 'message': 'CentOS 8: base and openstack-base images\n\nAdds support to the base and openstack-base images for CentOS 8.\nThese images have been removed from the list of unbuildable images, and\nreplaced with all dependent images.\n\nChange-Id: I18fba8a5c2f99b700990cbf41c76077a1ec2408a\nPartially-Implements: blueprint centos-rhel-8\n'}, {'number': 10, 'created': '2020-01-09 18:02:44.000000000', 'files': ['kolla/image/build.py', 'docker/openstack-base/Dockerfile.j2', 'docker/macros.j2', 'docker/base/Dockerfile.j2', 'tests/templates/template_overrides.j2', 'docker/base/rabbitmq_rabbitmq-server.repo', 'kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/3c618a1f6f0beca723e031fbe323b159400ad08f', 'message': 'CentOS 8: base and openstack-base images\n\nAdds support to the base and openstack-base images for CentOS 8.\nThese images have been removed from the list of unbuildable images, and\nreplaced with all dependent images.\n\nChange-Id: I18fba8a5c2f99b700990cbf41c76077a1ec2408a\nPartially-Implements: blueprint centos-rhel-8\n'}]",8,699413,3c618a1f6f0beca723e031fbe323b159400ad08f,60,7,10,14826,,,0,"CentOS 8: base and openstack-base images

Adds support to the base and openstack-base images for CentOS 8.
These images have been removed from the list of unbuildable images, and
replaced with all dependent images.

Change-Id: I18fba8a5c2f99b700990cbf41c76077a1ec2408a
Partially-Implements: blueprint centos-rhel-8
",git fetch https://review.opendev.org/openstack/kolla refs/changes/13/699413/8 && git format-patch -1 --stdout FETCH_HEAD,"['docker/openstack-base/Dockerfile.j2', 'docker/base/Dockerfile.j2', 'docker/macros.j2', 'docker/base/rabbitmq_rabbitmq-server.repo']",4,cf5d7d4000cc27f524a176a44ebcc76b38493394,bp/centos-rhel-8,baseurl=https://packagecloud.io/rabbitmq/rabbitmq-server/el/$releasever/$basearch,baseurl=https://packagecloud.io/rabbitmq/rabbitmq-server/el/7/$basearch,58,10
openstack%2Fnova-specs~master~I468abe984d81c264a588f23d4b3804106339a597,openstack/nova-specs,master,I468abe984d81c264a588f23d4b3804106339a597,Additional upgrade clarifications for cpu-resources,MERGED,2019-06-18 15:52:34.000000000,2020-01-29 11:51:28.000000000,2020-01-29 11:49:34.000000000,"[{'_account_id': 5754}, {'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 14070}, {'_account_id': 15334}, {'_account_id': 21672}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-06-18 15:52:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/484b15a140a269d6073e3f1f67d5a42d51b0ba66', 'message': 'Additional upgrade clarifications for cpu-resources\n\nBased on feedback from the mailing list.\n\nChange-Id: I468abe984d81c264a588f23d4b3804106339a597\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nBlueprint: cpu-resources\n'}, {'number': 2, 'created': '2019-06-19 16:02:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/0fc90beec57d5f0001ef2c85b4c414b4c41b28c9', 'message': ""Additional upgrade clarifications for cpu-resources\n\nBased on feedback from the mailing list [1]. Key changes:\n\n- We don't require an operator set both 'cpu_shared_set' and\n  'cpu_dedicated_set'. Clarify why this is the case.\n\n- Add an upgrade summary and summaries to each upgrade step, since this\n  is by far the hairiest part of the whole exercise.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2019-June/thread.html#7084\n\nChange-Id: I468abe984d81c264a588f23d4b3804106339a597\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nBlueprint: cpu-resources\n""}, {'number': 3, 'created': '2020-01-27 11:17:20.000000000', 'files': ['specs/train/approved/cpu-resources.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4b506d0e9f75200940aa41de419cc626b7dfbbbf', 'message': ""Additional upgrade clarifications for cpu-resources\n\nBased on feedback from the mailing list [1] and changes during\nimplementation. Key changes:\n\n- We don't require an operator set both 'cpu_shared_set' and\n  'cpu_dedicated_set'. Clarify why this is the case.\n\n- Add an upgrade summary and summaries to each upgrade step, since this\n  is by far the hairiest part of the whole exercise.\n\n- Replace references to an optional prefilter with the scheduler\n  aliasing with optional fallback functionality actually used\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2019-June/thread.html#7084\n\nChange-Id: I468abe984d81c264a588f23d4b3804106339a597\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nBlueprint: cpu-resources\n""}]",29,666032,4b506d0e9f75200940aa41de419cc626b7dfbbbf,28,8,3,15334,,,0,"Additional upgrade clarifications for cpu-resources

Based on feedback from the mailing list [1] and changes during
implementation. Key changes:

- We don't require an operator set both 'cpu_shared_set' and
  'cpu_dedicated_set'. Clarify why this is the case.

- Add an upgrade summary and summaries to each upgrade step, since this
  is by far the hairiest part of the whole exercise.

- Replace references to an optional prefilter with the scheduler
  aliasing with optional fallback functionality actually used

[1] http://lists.openstack.org/pipermail/openstack-discuss/2019-June/thread.html#7084

Change-Id: I468abe984d81c264a588f23d4b3804106339a597
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
Blueprint: cpu-resources
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/32/666032/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/train/approved/cpu-resources.rst'],1,484b15a140a269d6073e3f1f67d5a42d51b0ba66,bp/cpu-resources,"A key point here is that the new behavior must be opt-in during Stein. We recognize that operators may need time to upgrade a critical number of compute nodes so that they are reporting ``PCPU`` classes. This is reflected at numerous points below. :Summary: A user must unset the ``vcpu_pin_set`` and ``reserved_host_cpus`` config options and set one or both of the existing ``[compute] cpu_shared_set`` and new ``[compute] cpu_dedicated_set`` options. cpu_dedicated_set`` instead. For this same reason, we will only use ``[compute] cpu_shared_set`` to determine the number of ``VCPU`` resources if ``vcpu_pin_set`` is unset. If ``vcpu_pin_set`` is set, a warning will be raised and ``vcpu_pin_set`` will continue to be used to calculate the number of ``VCPU`` resource available while ``[compute] cpu_shared_set`` will continue to be used only for emulator threads.:Summary: We will add a prefilter that we will rewrite legacy flavor extra specs and image metadata properties. This should be enabled once a critical mass of hosts have been updated and start reporting ``PCPU`` resources. We will provide a prefilter to alias the legacy ``hw:cpu_policy`` and ``hw:cpu_thread_policy`` flavor extra specs and their ``hw_cpu_policy`` and ``hw_cpu_thread_policy`` image metadata counterparts to placement requests. The ``hw:cpu_policy`` flavor extra spec and ``hw_cpu_policy`` image metadata option will be aliased to ``resources=(V|P)CPU:${flavor.vcpus}``. For flavors/images using the ``shared`` policy, the prefilter will replace this with the ``resources=VCPU:${flavor.vcpus}`` extra spec, and for flavors/images using the ``dedicated`` policy, we will replace this with the ``resources=PCPU:${flavor.vcpus}`` extra spec. Note that this is similar, though not identical, to how we currently translate ``Flavour.vcpus`` into a placement request for ``VCPU`` resources during scheduling. The ``hw:cpu_thread_policy`` flavor extra spec and ``hw_cpu_thread_policy`` image metadata option will be aliased to ``trait:HW_CPU_HYPERTHREADING``. For flavors/images using the ``isolate`` policy, we will replace this with:Summary: We will provide a way to reshape inventory of existing instances using pinned CPUs to use inventory of the ``PCPU`` resource class instead of ``VCPU``. This will be a manual step that should be run once a critical mass of hosts have been updated and start reporting ``PCPU`` resources. ","cpu_dedicated_set`` instead.We will alias the ``hw:cpu_policy`` flavor extra spec and ``hw_cpu_policy`` image metadata option to ``resources=(V|P)CPU:${flavor.vcpus}`` using a scheduler prefilter. For flavors/images using the ``shared`` policy, we will replace this with the ``resources=VCPU:${flavor.vcpus}`` extra spec, and for flavors/images using the ``dedicated`` policy, we will replace this with the ``resources=PCPU:${flavor.vcpus}`` extra spec. Note that this is similar, though not identical, to how we currently translate ``Flavour.vcpus`` into a placement request for ``VCPU`` resources during scheduling. In addition, we will alias the ``hw:cpu_thread_policy`` flavor extra spec and ``hw_cpu_thread_policy`` image metadata option to ``trait:HW_CPU_HYPERTHREADING`` using a scheduler prefilter. For flavors/images using the ``isolate`` policy, we will replace this with",41,13
openstack%2Fnova~master~If117929305590a111a470640ef5bab4b9f3bbb94,openstack/nova,master,If117929305590a111a470640ef5bab4b9f3bbb94,tests: Cleanup of '_test_resize' helper test,ABANDONED,2019-06-10 11:04:23.000000000,2020-01-29 11:49:07.000000000,,"[{'_account_id': 9008}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-06-10 11:04:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b1ac9fa90a2efc937c9178a09e4fa8efe74e8df9', 'message': ""tests: Cleanup of '_test_resize' helper test\n\nThis is way too complicated for it's own good so clean things up:\n\n- Remove the 'test_migrate_request_spec_not_found' which was checking\n  the behavior of the 'RequestSpec.get_by_instance_uuid' function when a\n  'RequestSpec' isn't found. This might be useful if we were attempting\n  to handle this exception but we're not\n- Remove a useless 'if' statement that was already covered by internal\n  'if' statements\n- Rename the 'flavor_id_passed' parameter to 'is_resize' to better\n  describe what it's doing to the test\n- Remove a mock for the 'Migration' object that was never going to get\n  called\n\nChange-Id: If117929305590a111a470640ef5bab4b9f3bbb94\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2019-06-11 09:33:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e5000429ebc9bbf806e9c67332f3a4b2f8466adb', 'message': ""tests: Cleanup of '_test_resize' helper test\n\nThis is way too complicated for its own good so clean things up:\n\n- Remove the 'test_migrate_request_spec_not_found' which was checking\n  the behavior of the 'RequestSpec.get_by_instance_uuid' function when a\n  'RequestSpec' isn't found. This might be useful if we were attempting\n  to handle this exception but we're not\n- Remove a useless 'if' statement that was already covered by internal\n  'if' statements\n- Rename the 'flavor_id_passed' parameter to 'is_resize' to better\n  describe what it's doing to the test\n- Remove a mock for the 'Migration' object that was never going to get\n  called\n\nChange-Id: If117929305590a111a470640ef5bab4b9f3bbb94\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 3, 'created': '2019-06-12 10:05:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c864b576f3a28ae06555556352787483c30dc303', 'message': ""tests: Cleanup of '_test_resize' helper test\n\nThis is way too complicated for its own good so clean things up:\n\n- Remove the 'test_migrate_request_spec_not_found' which was checking\n  the behavior of the 'RequestSpec.get_by_instance_uuid' function when a\n  'RequestSpec' isn't found. This might be useful if we were attempting\n  to handle this exception but we're not\n- Remove a useless 'if' statement that was already covered by internal\n  'if' statements\n- Rename the 'flavor_id_passed' parameter to 'is_resize' to better\n  describe what it's doing to the test\n- Remove a mock for the 'Migration' object that was never going to get\n  called\n\nChange-Id: If117929305590a111a470640ef5bab4b9f3bbb94\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 4, 'created': '2019-06-13 14:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/95d087c5bb9af5a51353b7aea329ebc56505db6f', 'message': ""tests: Cleanup of '_test_resize' helper test\n\nThis is way too complicated for its own good so clean things up:\n\n- Remove the 'test_migrate_request_spec_not_found' which was checking\n  the behavior of the 'RequestSpec.get_by_instance_uuid' function when a\n  'RequestSpec' isn't found. This might be useful if we were attempting\n  to handle this exception but we're not\n- Remove a useless 'if' statement that was already covered by internal\n  'if' statements\n- Rename the 'flavor_id_passed' parameter to 'is_resize' to better\n  describe what it's doing to the test\n- Remove a mock for the 'Migration' object that was never going to get\n  called\n\nChange-Id: If117929305590a111a470640ef5bab4b9f3bbb94\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 5, 'created': '2019-06-18 13:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f632633277372881a62a0a47fad6bb5d4a57fd46', 'message': ""tests: Cleanup of '_test_resize' helper test\n\nThis is way too complicated for its own good so clean things up:\n\n- Remove the 'test_migrate_request_spec_not_found' which was checking\n  the behavior of the 'RequestSpec.get_by_instance_uuid' function when a\n  'RequestSpec' isn't found. This might be useful if we were attempting\n  to handle this exception but we're not\n- Remove a useless 'if' statement that was already covered by internal\n  'if' statements\n- Rename the 'flavor_id_passed' parameter to 'is_resize' to better\n  describe what it's doing to the test\n- Remove a mock for the 'Migration' object that was never going to get\n  called\n\nChange-Id: If117929305590a111a470640ef5bab4b9f3bbb94\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 6, 'created': '2019-08-16 13:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e326525edc3bb45a3304891d2b8b5414d99a40d1', 'message': ""tests: Cleanup of '_test_resize' helper test\n\nThis is way too complicated for its own good so clean things up:\n\n- Remove the 'test_migrate_request_spec_not_found' which was checking\n  the behavior of the 'RequestSpec.get_by_instance_uuid' function when a\n  'RequestSpec' isn't found. This might be useful if we were attempting\n  to handle this exception but we're not\n- Remove a useless 'if' statement that was already covered by internal\n  'if' statements\n- Rename the 'flavor_id_passed' parameter to 'is_resize' to better\n  describe what it's doing to the test\n- Remove a mock for the 'Migration' object that was never going to get\n  called\n\nChange-Id: If117929305590a111a470640ef5bab4b9f3bbb94\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 7, 'created': '2019-08-22 10:50:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bea08fe1d279616914a5f27dc02ae73ecef175ed', 'message': ""tests: Cleanup of '_test_resize' helper test\n\nThis is way too complicated for its own good so clean things up:\n\n- Remove the 'test_migrate_request_spec_not_found' which was checking\n  the behavior of the 'RequestSpec.get_by_instance_uuid' function when a\n  'RequestSpec' isn't found. This might be useful if we were attempting\n  to handle this exception but we're not\n- Remove a useless 'if' statement that was already covered by internal\n  'if' statements\n- Rename the 'flavor_id_passed' parameter to 'is_resize' to better\n  describe what it's doing to the test\n- Remove a mock for the 'Migration' object that was never going to get\n  called\n\nChange-Id: If117929305590a111a470640ef5bab4b9f3bbb94\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 8, 'created': '2019-08-22 13:33:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7fe164141f481184412a77ef2659700d6c1d1023', 'message': ""tests: Cleanup of '_test_resize' helper test\n\nThis is way too complicated for its own good so clean things up:\n\n- Remove the 'test_migrate_request_spec_not_found' which was checking\n  the behavior of the 'RequestSpec.get_by_instance_uuid' function when a\n  'RequestSpec' isn't found. This might be useful if we were attempting\n  to handle this exception but we're not\n- Remove a useless 'if' statement that was already covered by internal\n  'if' statements\n- Rename the 'flavor_id_passed' parameter to 'is_resize' to better\n  describe what it's doing to the test\n- Remove a mock for the 'Migration' object that was never going to get\n  called\n\nChange-Id: If117929305590a111a470640ef5bab4b9f3bbb94\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 9, 'created': '2019-09-23 13:20:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6918338c2c4b6333a7c92131bc3b87786cbf2b53', 'message': ""tests: Cleanup of '_test_resize' helper test\n\nThis is way too complicated for its own good so clean things up:\n\n- Remove the 'test_migrate_request_spec_not_found' which was checking\n  the behavior of the 'RequestSpec.get_by_instance_uuid' function when a\n  'RequestSpec' isn't found. This might be useful if we were attempting\n  to handle this exception but we're not\n- Remove a useless 'if' statement that was already covered by internal\n  'if' statements\n- Rename the 'flavor_id_passed' parameter to 'is_resize' to better\n  describe what it's doing to the test\n- Remove a mock for the 'Migration' object that was never going to get\n  called\n\nChange-Id: If117929305590a111a470640ef5bab4b9f3bbb94\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 10, 'created': '2020-01-22 18:31:49.000000000', 'files': ['nova/tests/unit/compute/test_compute_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ba2864dbc00766504b68b9658912b3a025f17c99', 'message': ""tests: Cleanup of '_test_resize' helper test\n\nThis is way too complicated for its own good so clean things up:\n\n- Remove the 'test_migrate_request_spec_not_found' which was checking\n  the behavior of the 'RequestSpec.get_by_instance_uuid' function when a\n  'RequestSpec' isn't found. This might be useful if we were attempting\n  to handle this exception but we're not\n- Remove a useless 'if' statement that was already covered by internal\n  'if' statements\n- Rename the 'flavor_id_passed' parameter to 'is_resize' to better\n  describe what it's doing to the test\n- Remove a mock for the 'Migration' object that was never going to get\n  called\n\nChange-Id: If117929305590a111a470640ef5bab4b9f3bbb94\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",8,664245,ba2864dbc00766504b68b9658912b3a025f17c99,70,12,10,15334,,,0,"tests: Cleanup of '_test_resize' helper test

This is way too complicated for its own good so clean things up:

- Remove the 'test_migrate_request_spec_not_found' which was checking
  the behavior of the 'RequestSpec.get_by_instance_uuid' function when a
  'RequestSpec' isn't found. This might be useful if we were attempting
  to handle this exception but we're not
- Remove a useless 'if' statement that was already covered by internal
  'if' statements
- Rename the 'flavor_id_passed' parameter to 'is_resize' to better
  describe what it's doing to the test
- Remove a mock for the 'Migration' object that was never going to get
  called

Change-Id: If117929305590a111a470640ef5bab4b9f3bbb94
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/45/664245/10 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/compute/test_compute_api.py'],1,b1ac9fa90a2efc937c9178a09e4fa8efe74e8df9,bug/1805767," def _test_resize_and_migrate(self, mock_get_all_by_host, mock_get_by_instance_uuid, mock_get_flavor, mock_upsize, mock_inst_save, mock_count, mock_limit, mock_record, mock_validate, mock_is_vol_backed, mock_get_numa, is_resize, same_host=False, allow_same_host=False, project_id=None, extra_kwargs=None, same_flavor=False, clean_shutdown=True, host_name=None, requested_destination=False): if is_resize: if not (is_resize and same_flavor): if is_resize: fake_spec = objects.RequestSpec() if requested_destination: cell1 = objects.CellMapping(uuid=uuids.cell1, name='cell1') fake_spec.requested_destination = objects.Destination( host='dummy_host', node='dummy_node', cell=cell1) mock_get_by_instance_uuid.return_value = fake_spec if is_resize: self.compute_api.resize(self.context, fake_inst, clean_shutdown=clean_shutdown, host_name=host_name, **extra_kwargs) if allow_same_host: self.assertEqual([], fake_spec.ignore_hosts) else: self.assertEqual([fake_inst['host']], fake_spec.ignore_hosts) if host_name is None: self.assertIsNone(fake_spec.requested_destination) else: self.assertIn('host', fake_spec.requested_destination) self.assertEqual(host_name, fake_spec.requested_destination.host) self.assertIn('node', fake_spec.requested_destination) self.assertEqual('hypervisor_host', fake_spec.requested_destination.node) if is_resize and not same_flavor: mock_get_numa.assert_called_once_with(new_flavor, mock.ANY) else: mock_get_numa.assert_not_called() if is_resize: mock_upsize.assert_called_once_with( test.MatchType(objects.Flavor), test.MatchType(objects.Flavor)) image_meta = utils.get_image_from_system_metadata( fake_inst.system_metadata) if not same_flavor: mock_validate.assert_called_once_with( self.context, image_meta, new_flavor, root_bdm=None, validate_pci=True) else: # mock.ANY might be 'instances', 'cores', or 'ram' # depending on how the deltas dict is iterated in check_deltas mock_count.assert_called_once_with( self.context, mock.ANY, project_id, user_id=user_id) # The current and new flavor have the same cores/ram req_cores = current_flavor.vcpus req_ram = current_flavor.memory_mb values = {'cores': req_cores, 'ram': req_ram} mock_limit.assert_called_once_with( self.context, user_values=values, project_values=values, project_id=project_id, user_id=user_id) mock_inst_save.assert_called_once_with( expected_task_state=[None]) else: # This is a migration mock_validate.assert_not_called() mock_get_by_instance_uuid.assert_called_once_with(self.context, fake_inst.uuid) if is_resize: mock_record.assert_called_once_with(self.context, fake_inst, 'resize') else: mock_record.assert_called_once_with(self.context, fake_inst, 'migrate') mock_resize.assert_called_once_with( self.context, fake_inst, extra_kwargs, scheduler_hint=scheduler_hint, flavor=test.MatchType(objects.Flavor), clean_shutdown=clean_shutdown, request_spec=fake_spec) def _test_resize(self, *args, **kwargs): self._test_resize_and_migrate(*args, is_resize=True, **kwargs) self._test_resize_and_migrate(*args, is_resize=False, **kwargs)"," @mock.patch('nova.objects.Migration') def _test_resize(self, mock_get_all_by_host, mock_get_by_instance_uuid, mock_get_flavor, mock_upsize, mock_inst_save, mock_count, mock_limit, mock_record, mock_migration, mock_validate, mock_is_vol_backed, mock_get_numa, flavor_id_passed=True, same_host=False, allow_same_host=False, project_id=None, extra_kwargs=None, same_flavor=False, clean_shutdown=True, host_name=None, request_spec=True, requested_destination=False): if flavor_id_passed: if not (flavor_id_passed and same_flavor): if flavor_id_passed: if request_spec: fake_spec = objects.RequestSpec() if requested_destination: cell1 = objects.CellMapping(uuid=uuids.cell1, name='cell1') fake_spec.requested_destination = objects.Destination( host='dummy_host', node='dummy_node', cell=cell1) mock_get_by_instance_uuid.return_value = fake_spec else: mock_get_by_instance_uuid.side_effect = ( exception.RequestSpecNotFound(instance_uuid=fake_inst.id)) fake_spec = None if flavor_id_passed: if request_spec: self.compute_api.resize(self.context, fake_inst, clean_shutdown=clean_shutdown, host_name=host_name, **extra_kwargs) else: self.assertRaises(exception.RequestSpecNotFound, self.compute_api.resize, self.context, fake_inst, clean_shutdown=clean_shutdown, host_name=host_name, **extra_kwargs) if request_spec: if allow_same_host: self.assertEqual([], fake_spec.ignore_hosts) else: self.assertEqual([fake_inst['host']], fake_spec.ignore_hosts) if host_name is None: self.assertIsNone(fake_spec.requested_destination) else: self.assertIn('host', fake_spec.requested_destination) self.assertEqual(host_name, fake_spec.requested_destination.host) self.assertIn('node', fake_spec.requested_destination) self.assertEqual('hypervisor_host', fake_spec.requested_destination.node) if flavor_id_passed and not same_flavor: mock_get_numa.assert_called_once_with(new_flavor, mock.ANY) else: mock_get_numa.assert_not_called() if flavor_id_passed: if not (flavor_id_passed and same_flavor): if flavor_id_passed: mock_upsize.assert_called_once_with( test.MatchType(objects.Flavor), test.MatchType(objects.Flavor)) image_meta = utils.get_image_from_system_metadata( fake_inst.system_metadata) if not same_flavor: mock_validate.assert_called_once_with( self.context, image_meta, new_flavor, root_bdm=None, validate_pci=True) # mock.ANY might be 'instances', 'cores', or 'ram' # depending on how the deltas dict is iterated in check_deltas mock_count.assert_called_once_with( self.context, mock.ANY, project_id, user_id=user_id) # The current and new flavor have the same cores/ram req_cores = current_flavor.vcpus req_ram = current_flavor.memory_mb values = {'cores': req_cores, 'ram': req_ram} mock_limit.assert_called_once_with( self.context, user_values=values, project_values=values, project_id=project_id, user_id=user_id) mock_inst_save.assert_called_once_with( expected_task_state=[None]) else: # This is a migration mock_migration.assert_not_called() mock_get_by_instance_uuid.assert_called_once_with(self.context, fake_inst.uuid) if flavor_id_passed: mock_record.assert_called_once_with(self.context, fake_inst, 'resize') else: if request_spec: mock_record.assert_called_once_with( self.context, fake_inst, 'migrate') else: mock_record.assert_not_called() if request_spec: mock_resize.assert_called_once_with( self.context, fake_inst, extra_kwargs, scheduler_hint=scheduler_hint, flavor=test.MatchType(objects.Flavor), clean_shutdown=clean_shutdown, request_spec=fake_spec) else: mock_resize.assert_not_called() self._test_resize(*args, flavor_id_passed=False, **kwargs) def test_migrate_request_spec_not_found(self): self._test_migrate(request_spec=False) ",82,112
openstack%2Fansible-role-collect-logs~master~I5db914db44c354c908d0e12726bebf93af239443,openstack/ansible-role-collect-logs,master,I5db914db44c354c908d0e12726bebf93af239443,Create infrared plugin,MERGED,2019-09-13 13:02:52.000000000,2020-01-29 11:43:28.000000000,2020-01-29 11:43:28.000000000,"[{'_account_id': 5803}, {'_account_id': 6683}, {'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 16615}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 30742}]","[{'number': 1, 'created': '2019-09-13 13:02:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/4f2f3ec7e9248645e1366d4176d8c47bb17f60e3', 'message': 'WIP: Create infrared plugin\n\nWORK IN PROGRESS\n\nhttps://tree.taiga.io/project/tripleo-ci-board/task/1276\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\n'}, {'number': 2, 'created': '2019-10-07 13:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/e93d4918f0c366eed4ead585255d1b69d1619a02', 'message': 'WIP: Create infrared plugin\n\nWORK IN PROGRESS\n\nhttps://tree.taiga.io/project/tripleo-ci-board/task/1276\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\n'}, {'number': 3, 'created': '2019-11-29 09:54:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/eec25b31ad36c56bda60ecfef77bfd302c7bfe2c', 'message': 'Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\nhttps://tree.taiga.io/project/tripleo-ci-board/task/1276\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\n'}, {'number': 4, 'created': '2019-11-29 13:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/7950698f7711bfb33ed27efba4fe32db464fa661', 'message': 'Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\nhttps://tree.taiga.io/project/tripleo-ci-board/task/1276\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\n'}, {'number': 5, 'created': '2019-12-03 11:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/3824eca67be82297c7bea4133af187971e614d0c', 'message': 'Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\nhttps://tree.taiga.io/project/tripleo-ci-board/task/1276\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\n'}, {'number': 6, 'created': '2019-12-20 13:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/ba1593fc18a24b71d4c3cea4d76730d18b95e112', 'message': 'Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\nhttps://tree.taiga.io/project/tripleo-ci-board/task/1276\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\n'}, {'number': 7, 'created': '2019-12-23 10:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/f9fc9678b52652e988073b3db4734bccd8f04350', 'message': 'Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\nhttps://tree.taiga.io/project/tripleo-ci-board/task/1276\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\n'}, {'number': 8, 'created': '2019-12-23 11:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/c2c5987e51c52c993f3a9d68d98aabb9ef78671c', 'message': 'WIP: Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\nhttps://tree.taiga.io/project/tripleo-ci-board/task/1276\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\n'}, {'number': 9, 'created': '2020-01-02 09:56:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/1b23d45dfa578dbf895250b83a6aaf0c3cd39070', 'message': 'WIP: Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\nhttps://tree.taiga.io/project/tripleo-ci-board/task/1276\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\n'}, {'number': 10, 'created': '2020-01-02 10:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/b2eae631929312be3657ac74d02e4d1890e2ed61', 'message': 'WIP: Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\nhttps://tree.taiga.io/project/tripleo-ci-board/task/1276\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\n'}, {'number': 11, 'created': '2020-01-08 16:09:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/f44e2f922456bc360fad4ca384a2e0b79f474825', 'message': 'WIP: Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\nhttps://tree.taiga.io/project/tripleo-ci-board/task/1276\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\n'}, {'number': 12, 'created': '2020-01-08 16:26:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/35ccdfad207fb4269f8c4e44fdd85a383b93d656', 'message': 'WIP: Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\nhttps://tree.taiga.io/project/tripleo-ci-board/task/1276\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\n'}, {'number': 13, 'created': '2020-01-10 07:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/3c161cd8a04c8e65a2a0084c18d68184cc76508d', 'message': 'WIP: Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\nhttps://tree.taiga.io/project/tripleo-ci-board/task/1276\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\n'}, {'number': 14, 'created': '2020-01-10 10:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/e6f30911ba9a717765f46c9679834fea14f635cf', 'message': 'WIP: Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\nIncludes missing html report generation from tox molecule.\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1276\n'}, {'number': 15, 'created': '2020-01-10 10:25:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/71cdf585915463332a6f2192a523c77533542564', 'message': 'Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\nIncludes missing html report generation from tox molecule.\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1276\n'}, {'number': 16, 'created': '2020-01-10 10:45:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/7f47e3b52bdc0310071f999615834baeb218fdc2', 'message': ""Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\n- adds 'infrared' molecule scenario (run with pytest -k infrared)\n- fix missing html report generation from tox molecule\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1276\n""}, {'number': 17, 'created': '2020-01-13 13:30:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/9b4da8bc999685058c755b53a70bb2cc6948e27e', 'message': ""Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\n- adds 'infrared' molecule scenario (run with pytest -k infrared)\n- fix missing html report generation from tox molecule\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1276\n""}, {'number': 18, 'created': '2020-01-14 12:21:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/a2125883a751d41bbcb1385ef40e6b76409e695c', 'message': ""Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\n- adds 'infrared' molecule scenario (run with pytest -k infrared)\n- fix missing html report generation from tox molecule\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1276\n""}, {'number': 19, 'created': '2020-01-16 10:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/543594d61b115c499fa12b4bc14be4c523453b5f', 'message': ""Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\n- adds 'infrared' molecule scenario (run with pytest -k infrared)\n- fix missing html report generation from tox molecule\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1276\n""}, {'number': 20, 'created': '2020-01-22 09:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/547e7f22d655eee2bbbd69b5b621f31f5ced25fb', 'message': ""Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\n- adds 'infrared' molecule scenario (run with pytest -k infrared)\n- fix missing html report generation from tox molecule\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1276\n""}, {'number': 21, 'created': '2020-01-26 23:30:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/dd2a83eea3f5c355f861b917142a701eff49afeb', 'message': ""Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\n- adds 'infrared' molecule scenario (run with pytest -k infrared)\n- fix missing html report generation from tox molecule\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1276\n""}, {'number': 22, 'created': '2020-01-27 12:31:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/7ddd07111e98a0ed17fa4751d6d3fdda1421c267', 'message': ""Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\n- adds 'infrared' molecule scenario (run with pytest -k infrared)\n- fix missing html report generation from tox molecule\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1276\n""}, {'number': 23, 'created': '2020-01-28 16:39:17.000000000', 'files': ['molecule/infrared/molecule.yml', '.gitignore', 'molecule/infrared/playbook.yml', 'molecule/sova/molecule.yml', 'molecule/infrared/verify.yml', 'README.rst', 'infrared_plugin/plugin.spec', 'infrared_plugin/main.yml', 'tox.ini', 'molecule/infrared/cleanup.yml', 'tasks/publish.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/25d62887fe6ca915df59ff5fafb096efb5e5de33', 'message': ""Create infrared plugin\n\nThe review adds required files (infrared_plugin/ folder) by Infrared\nin order to make the role an infrared plugin.\n\n- adds 'infrared' molecule scenario (run with pytest -k infrared)\n- fix missing html report generation from tox molecule\n\nChange-Id: I5db914db44c354c908d0e12726bebf93af239443\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1276\n""}]",34,682042,25d62887fe6ca915df59ff5fafb096efb5e5de33,96,13,23,22873,,,0,"Create infrared plugin

The review adds required files (infrared_plugin/ folder) by Infrared
in order to make the role an infrared plugin.

- adds 'infrared' molecule scenario (run with pytest -k infrared)
- fix missing html report generation from tox molecule

Change-Id: I5db914db44c354c908d0e12726bebf93af239443
Task: https://tree.taiga.io/project/tripleo-ci-board/task/1276
",git fetch https://review.opendev.org/openstack/ansible-role-collect-logs refs/changes/42/682042/16 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'README.rst', 'infrared_plugin/plugin.spec', 'infrared_plugin/main.yml']",4,4f2f3ec7e9248645e1366d4176d8c47bb17f60e3,682042,"--- # This file and plugin.spec are required by Infrared project - hosts: ""{{ other.openstack_nodes }}"" remote_user: stack become: true roles: - ansible-role-collect-logs pre_tasks: - name: Remap infrared parameters to role variables set_fact: ""{{ item.key }}"": ""{{ item.value }}"" with_dict: ""{{ other }}"" ",,168,5
openstack%2Ftripleo-ci~master~I2e2ef8ef87ae1a330c268942b419cbf43e982a13,openstack/tripleo-ci,master,I2e2ef8ef87ae1a330c268942b419cbf43e982a13,add tripleo-ci-centos-8-scenario000-standalone job,ABANDONED,2019-10-24 12:51:20.000000000,2020-01-29 11:15:59.000000000,,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2019-10-24 12:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/de44660152af10c9d5d2dc6a477531ce269c3c54', 'message': 'add tripleo-ci-centos-7-scenario000-standalone job\n\nChange-Id: I2e2ef8ef87ae1a330c268942b419cbf43e982a13\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1350\n'}, {'number': 2, 'created': '2019-10-24 12:56:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f9482d81018764f2a04067e3f947140816b5ab0c', 'message': 'Add tripleo-ci-centos-7-scenario000-standalone job\n\nChange-Id: I2e2ef8ef87ae1a330c268942b419cbf43e982a13\nDepends-On: https://review.opendev.org/690960\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1350\n'}, {'number': 3, 'created': '2019-10-24 12:56:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/57a11c53ce34b5bca8df532b29cb2ef51c0067ff', 'message': 'Add tripleo-ci-centos-7-scenario000-standalone job\n\nChange-Id: I2e2ef8ef87ae1a330c268942b419cbf43e982a13\nDepends-On: https://review.opendev.org/690960\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1350\n'}, {'number': 4, 'created': '2019-10-28 13:20:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5729b8875a02809fb3948bf734340f10b94f2f47', 'message': 'add tripleo-ci-centos-7-scenario000-standalone job\n\nChange-Id: I2e2ef8ef87ae1a330c268942b419cbf43e982a13\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1350\n'}, {'number': 5, 'created': '2019-10-28 13:28:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6dbaca44851738e6ce8272340a21dba60488e8a2', 'message': 'add tripleo-ci-centos-7-scenario000-standalone job\n\nChange-Id: I2e2ef8ef87ae1a330c268942b419cbf43e982a13\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1350\n'}, {'number': 6, 'created': '2019-10-29 11:03:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/8654aa3f80e99444014b4ee28fc603db953f9007', 'message': 'add scenario000-standalone jobs\n\nChange-Id: I2e2ef8ef87ae1a330c268942b419cbf43e982a13\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1350\n'}, {'number': 7, 'created': '2019-10-29 11:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fbd6b5aa9821f3d9a277ed67b78e4ad023782656', 'message': 'add scenario000-standalone jobs\n\nChange-Id: I2e2ef8ef87ae1a330c268942b419cbf43e982a13\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1350\nDepends-On: https://review.rdoproject.org/r/23505\n'}, {'number': 8, 'created': '2019-10-29 11:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/0dac2be1ecbbcf62f7ddae6fea49cf0bf2a77a95', 'message': 'add scenario000-standalone jobs\n\nChange-Id: I2e2ef8ef87ae1a330c268942b419cbf43e982a13\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1350\nDepends-On: https://review.rdoproject.org/r/23505\n'}, {'number': 9, 'created': '2019-10-29 15:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6d04336aef230385a07f92c25e23d77d7ba644b4', 'message': 'add scenario000-standalone job for centos-8\n\nChange-Id: I2e2ef8ef87ae1a330c268942b419cbf43e982a13\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1350\nDepends-On: https://review.rdoproject.org/r/23505 (merged)\nDepends-On: https://review.opendev.org/#/c/690960/ (tht)\n'}, {'number': 10, 'created': '2019-10-30 09:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2532f3db5b0e3fb5ba186a900087782e0803a476', 'message': 'add tripleo-ci-centos-8-scenario000-standalone job\n\nChange-Id: I2e2ef8ef87ae1a330c268942b419cbf43e982a13\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1350\nDepends-On: https://review.rdoproject.org/r/23505\n'}, {'number': 11, 'created': '2019-11-11 10:43:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1a6df829b630c5a2637ad1008acb8f694716bc2d', 'message': 'add tripleo-ci-centos-8-scenario000-standalone job\n\nChange-Id: I2e2ef8ef87ae1a330c268942b419cbf43e982a13\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1350\nDepends-On: https://review.rdoproject.org/r/23505\n'}, {'number': 12, 'created': '2019-11-11 16:54:56.000000000', 'files': ['zuul.d/standalone-jobs.yaml', 'zuul.d/nodesets.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7a792fe42b33afce41c42ad3ad7ffb1804324108', 'message': 'add tripleo-ci-centos-8-scenario000-standalone job\n\nChange-Id: I2e2ef8ef87ae1a330c268942b419cbf43e982a13\nTask: https://tree.taiga.io/project/tripleo-ci-board/task/1350\nDepends-On: https://review.rdoproject.org/r/23505\n'}]",3,690961,7a792fe42b33afce41c42ad3ad7ffb1804324108,33,5,12,24162,,,0,"add tripleo-ci-centos-8-scenario000-standalone job

Change-Id: I2e2ef8ef87ae1a330c268942b419cbf43e982a13
Task: https://tree.taiga.io/project/tripleo-ci-board/task/1350
Depends-On: https://review.rdoproject.org/r/23505
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/61/690961/8 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/standalone-jobs.yaml'],1,de44660152af10c9d5d2dc6a477531ce269c3c54,centos8, name: tripleo-ci-centos-7-scenario000-standalone voting: true parent: tripleo-ci-base-standalone nodeset: single-centos-7-node branches: ^(?!stable/(newton|ocata|pike|queens|rocky)).*$ vars: featureset: '052' standalone_ceph: true featureset_override: run_tempest: false standalone_environment_files: - 'environments/low-memory-usage.yaml' - 'ci/environments/scenario000-standalone.yaml' - job:,,15,0
openstack%2Fkeystone~stable%2Frocky~I6c950d054f18ed0bca92a32e921d2e9d387bcdbd,openstack/keystone,stable/rocky,I6c950d054f18ed0bca92a32e921d2e9d387bcdbd,Use pycodestyle in place of pep8,ABANDONED,2020-01-07 00:53:32.000000000,2020-01-29 11:01:50.000000000,,"[{'_account_id': 4146}, {'_account_id': 8482}, {'_account_id': 22348}, {'_account_id': 23950}]","[{'number': 1, 'created': '2020-01-07 00:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6eda270461a647891eb56f270e23628da38243b8', 'message': 'Use pycodestyle in place of pep8\n\nThe lower version of pycodestyle lib (aliased to pep8) doesn\'t work\nfor py36 env. This commit unblocks the py36 gate by adding a\ndependency on pycodestyle and using that for style checks.\n\nBump the ""hacking"" lib version to v1.1.0 which depends\non a higher verion of pycodestyle.\n\nChange-Id: I6c950d054f18ed0bca92a32e921d2e9d387bcdbd\nCloses-Bug: #1858410\n'}, {'number': 2, 'created': '2020-01-07 04:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6b768335c21fd005c0375f3cc7193f0fc27feeb9', 'message': 'Use pycodestyle in place of pep8\n\nThe lower version of pycodestyle lib (aliased to pep8) doesn\'t work\nfor py36 env. This commit unblocks the py36 gate by adding a\ndependency on pycodestyle and using that for style checks.\n\nBump the ""hacking"" lib version to v1.1.0 which depends\non a higher verion of pycodestyle.\n\nChange-Id: I6c950d054f18ed0bca92a32e921d2e9d387bcdbd\nCloses-Bug: #1858410\n'}, {'number': 3, 'created': '2020-01-07 05:57:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9148e891243930bfd6d62bffe9d60c43e8f84b96', 'message': 'Use pycodestyle in place of pep8\n\nThe lower version of pycodestyle lib (aliased to pep8) doesn\'t work\nfor py36 env. This commit unblocks the py36 gate by adding a\ndependency on pycodestyle and using that for style checks.\n\nBump the ""hacking"" lib version to v1.1.0 which depends\non a higher verion of pycodestyle.\n\nChange-Id: I6c950d054f18ed0bca92a32e921d2e9d387bcdbd\nCloses-Bug: #1858410\n'}, {'number': 4, 'created': '2020-01-07 13:44:15.000000000', 'files': ['keystone/identity/core.py', 'test-requirements.txt', 'keystone/cmd/cli.py', 'keystone/tests/unit/test_hacking_checks.py', 'lower-constraints.txt', 'doc/requirements.txt', 'keystone/tests/unit/backend/core_ldap.py', 'tox.ini', 'keystone/tests/hacking/checks.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/c916eefae2c570fcb838379c39a265280d45ea22', 'message': 'Use pycodestyle in place of pep8\n\nThe lower version of pycodestyle lib (aliased to pep8) doesn\'t work\nfor py36 env. This commit unblocks the py36 gate by adding a\ndependency on pycodestyle and using that for style checks.\n\nBump the ""hacking"" lib version to v1.1.0 which depends\non a higher verion of pycodestyle.\n\nChange-Id: I6c950d054f18ed0bca92a32e921d2e9d387bcdbd\nCloses-Bug: #1858410\n'}]",0,701303,c916eefae2c570fcb838379c39a265280d45ea22,17,4,4,23950,,,0,"Use pycodestyle in place of pep8

The lower version of pycodestyle lib (aliased to pep8) doesn't work
for py36 env. This commit unblocks the py36 gate by adding a
dependency on pycodestyle and using that for style checks.

Bump the ""hacking"" lib version to v1.1.0 which depends
on a higher verion of pycodestyle.

Change-Id: I6c950d054f18ed0bca92a32e921d2e9d387bcdbd
Closes-Bug: #1858410
",git fetch https://review.opendev.org/openstack/keystone refs/changes/03/701303/4 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/identity/core.py', 'test-requirements.txt', 'keystone/cmd/cli.py', 'keystone/tests/unit/test_hacking_checks.py', 'lower-constraints.txt', 'keystone/tests/unit/backend/core_ldap.py', 'tox.ini', 'keystone/tests/hacking/checks.py']",8,6eda270461a647891eb56f270e23628da38243b8,bug_1858410,by pycodestyle. The second type is a class that parses AST trees. For more info please see pycodestyle.py.,by pep8. The second type is a class that parses AST trees. For more info please see pep8.py.,43,44
openstack%2Fkayobe~stable%2Frocky~I074d4b9d444649ecf956d3cd92748862e8c89a5c,openstack/kayobe,stable/rocky,I074d4b9d444649ecf956d3cd92748862e8c89a5c,Use {{ openstack_branch }} as version of kolla-ansible in ansible tests,ABANDONED,2020-01-29 10:30:48.000000000,2020-01-29 10:47:39.000000000,,[{'_account_id': 14826}],"[{'number': 1, 'created': '2020-01-29 10:30:48.000000000', 'files': ['tools/test-ansible.sh', 'ansible/roles/kolla-ansible/tests/test-requirements.yml', 'ansible/roles/kolla-ansible/tests/test-defaults.yml', 'ansible/roles/kolla-ansible/tests/test-extras.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/6dff5adff83747f6462af7c3a389c94f06594a65', 'message': 'Use {{ openstack_branch }} as version of kolla-ansible in ansible tests\n\nInstead of always checking out the master branch, use the kolla-ansible\nbranch with which this Kayobe version is meant to be used.\n\nChange-Id: I074d4b9d444649ecf956d3cd92748862e8c89a5c\n(cherry picked from commit 225130a594e84776b3bfcc852da37cbaeb867c42)\n'}]",0,704772,6dff5adff83747f6462af7c3a389c94f06594a65,3,1,1,15197,,,0,"Use {{ openstack_branch }} as version of kolla-ansible in ansible tests

Instead of always checking out the master branch, use the kolla-ansible
branch with which this Kayobe version is meant to be used.

Change-Id: I074d4b9d444649ecf956d3cd92748862e8c89a5c
(cherry picked from commit 225130a594e84776b3bfcc852da37cbaeb867c42)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/72/704772/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/test-ansible.sh', 'ansible/roles/kolla-ansible/tests/test-requirements.yml', 'ansible/roles/kolla-ansible/tests/test-defaults.yml', 'ansible/roles/kolla-ansible/tests/test-extras.yml']",4,6dff5adff83747f6462af7c3a389c94f06594a65,," kolla_ansible_source_version: ""{{ openstack_branch }}"""," kolla_ansible_source_version: ""master""",8,4
openstack%2Fansible-role-container-registry~master~I8aeefeaa3bd5fe5a6407c2959b3320c5559d6480,openstack/ansible-role-container-registry,master,I8aeefeaa3bd5fe5a6407c2959b3320c5559d6480,WIP: Adopt standardized openstack-tox-molecule,ABANDONED,2019-07-30 15:15:09.000000000,2020-01-29 10:41:30.000000000,,"[{'_account_id': 7353}, {'_account_id': 9592}, {'_account_id': 10022}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2019-07-30 15:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-container-registry/commit/c2ebec5c58dae403a214513eb89a6f5164f0ce93', 'message': 'WIP: Enable functional testing with molecule\n\nDetects and runs all molecule testing scenarios in current repository.\n\nChange-Id: I8aeefeaa3bd5fe5a6407c2959b3320c5559d6480\n'}, {'number': 2, 'created': '2019-07-31 15:28:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-container-registry/commit/edef678b0d27d57d41bfdd3b41834ec019af5186', 'message': 'WIP: Adopt standardized openstack-tox-molecule\n\nDetects and runs all molecule testing scenarios in current repository.\n\nThe purpose of this change is to enable the testing job as non-voting,\nnot to make it pass. Making job pass and later voting should be done\nin follow-ups.\n\nChange-Id: I8aeefeaa3bd5fe5a6407c2959b3320c5559d6480\n'}, {'number': 3, 'created': '2019-08-06 09:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-container-registry/commit/3ab4c2ba78326020bbae5e4243963be36ddac4c7', 'message': 'WIP: Adopt standardized openstack-tox-molecule\n\nDetects and runs all molecule testing scenarios in current repository.\n\nThe purpose of this change is to enable the testing job as non-voting,\nnot to make it pass. Making job pass and later voting should be done\nin follow-ups.\n\nChange-Id: I8aeefeaa3bd5fe5a6407c2959b3320c5559d6480\nDepends-On: https://review.rdoproject.org/r/#/c/21728/\n'}, {'number': 4, 'created': '2019-08-06 16:01:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-container-registry/commit/28aefa6db4469845d46af177a675ecc8bea665de', 'message': 'WIP: Adopt standardized openstack-tox-molecule\n\nDetects and runs all molecule testing scenarios in current repository.\n\nThe purpose of this change is to enable the testing job as non-voting,\nnot to make it pass. Making job pass and later voting should be done\nin follow-ups.\n\nChange-Id: I8aeefeaa3bd5fe5a6407c2959b3320c5559d6480\nDepends-On: https://review.rdoproject.org/r/#/c/21728/\n'}, {'number': 5, 'created': '2019-08-06 17:21:12.000000000', 'files': ['.gitignore', 'zuul.d/layout.yaml', 'tox.ini', 'meta/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-container-registry/commit/0529db86200bbdc7982c26693025222296aa3673', 'message': 'WIP: Adopt standardized openstack-tox-molecule\n\nDetects and runs all molecule testing scenarios in current repository.\n\nThe purpose of this change is to enable the testing job as non-voting,\nnot to make it pass. Making job pass and later voting should be done\nin follow-ups.\n\nChange-Id: I8aeefeaa3bd5fe5a6407c2959b3320c5559d6480\nDepends-On: https://review.rdoproject.org/r/#/c/21728/\n'}]",0,673554,0529db86200bbdc7982c26693025222296aa3673,18,6,5,24162,,,0,"WIP: Adopt standardized openstack-tox-molecule

Detects and runs all molecule testing scenarios in current repository.

The purpose of this change is to enable the testing job as non-voting,
not to make it pass. Making job pass and later voting should be done
in follow-ups.

Change-Id: I8aeefeaa3bd5fe5a6407c2959b3320c5559d6480
Depends-On: https://review.rdoproject.org/r/#/c/21728/
",git fetch https://review.opendev.org/openstack/ansible-role-container-registry refs/changes/54/673554/5 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/layout.yaml', 'tox.ini']",2,c2ebec5c58dae403a214513eb89a6f5164f0ce93,molecule,minversion = 3.4.0 envlist = docs linters molecule skipsdist = Truesetenv = ANSIBLE_FORCE_COLOR=1 ANSIBLE_INVENTORY={toxinidir}/test/hosts.ini ANSIBLE_NOCOWS=1 ANSIBLE_RETRY_FILES_ENABLED=0 ANSIBLE_STDOUT_CALLBACK=debug PY_COLORS=1 VIRTUAL_ENV={envdir} # Avoid 2020-01-01 warnings: https://github.com/pypa/pip/issues/6207 PYTHONWARNINGS=ignore:DEPRECATION::pip._internal.cli.base_command PIP_DISABLE_PIP_VERSION_CHECK=1 passenv = ANSIBLE_* DOCKER_* MOLECULE_* SSH_AUTH_SOCK TERM [testenv:molecule] deps = ansi2html # GPL (soft-dependency of pytest-html) docker>=3.7 # Apache molecule>=2.22rc1 # MIT paramiko>=2.5.0 # LGPL (soft-dependency of docker that enables ssh protocol) pytest # MIT pytest-cov # MIT pytest-html # MPL 2.0 pytest-molecule # MIT pytest-xdist # MIT commands = python -m pytest -ra --html={envlogdir}/reports.html --self-contained-html {tty:-s} {posargs:-k molecule} roles,"minversion = 2.0 envlist = docs, linters skipdist = Truesetenv = VIRTUAL_ENV={envdir}",39,4
openstack%2Ftenks~master~Idcda5c1f172f67bad22b5aa7d1b6e4f33e22ef0c,openstack/tenks,master,Idcda5c1f172f67bad22b5aa7d1b6e4f33e22ef0c,DNM: test https://github.com/stackhpc/ansible-role-libvirt-vm/pull/32,ABANDONED,2019-10-16 16:44:01.000000000,2020-01-29 10:28:31.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-10-16 16:44:01.000000000', 'files': ['requirements.yml'], 'web_link': 'https://opendev.org/openstack/tenks/commit/d05ddf03d6f3cb8b22afecc8f2892ec06eb4da0d', 'message': 'DNM: test https://github.com/stackhpc/ansible-role-libvirt-vm/pull/32\n\nDepends-On: https://github.com/stackhpc/ansible-role-libvirt-vm/pull/32\nChange-Id: Idcda5c1f172f67bad22b5aa7d1b6e4f33e22ef0c\n'}]",0,688975,d05ddf03d6f3cb8b22afecc8f2892ec06eb4da0d,3,1,1,28048,,,0,"DNM: test https://github.com/stackhpc/ansible-role-libvirt-vm/pull/32

Depends-On: https://github.com/stackhpc/ansible-role-libvirt-vm/pull/32
Change-Id: Idcda5c1f172f67bad22b5aa7d1b6e4f33e22ef0c
",git fetch https://review.opendev.org/openstack/tenks refs/changes/75/688975/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.yml'],1,d05ddf03d6f3cb8b22afecc8f2892ec06eb4da0d,try-pr,- src: https://github.com/stackhpc/ansible-role-libvirt-vm version: cpu_mode name: stackhpc.libvirt-vm,- src: stackhpc.libvirt-vm,3,1
openstack%2Fopenstack-ansible-os_tempest~master~I05651bff4eb85fda37eddb80074c23ac48b71201,openstack/openstack-ansible-os_tempest,master,I05651bff4eb85fda37eddb80074c23ac48b71201,Improve loading of operating system specific vars,ABANDONED,2019-08-09 13:32:07.000000000,2020-01-29 10:19:16.000000000,,"[{'_account_id': 7353}, {'_account_id': 8367}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 25877}, {'_account_id': 27379}]","[{'number': 1, 'created': '2019-08-09 13:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/ae4ee0c69e2e15c8de7e7783743c63cb90165e55', 'message': 'Improve loading of operating system specific vars\n\nImproves the overlayed var loading pattern by addressing two problems\nwith current implementation:\n\n* Avoid confusion between os_family and distribution\n* Loads all files, allowing to define variable in less places\n\nThat newer pattern is already used in few other repositories.\n\nMore details on https://docs.sbarnea.com/ansible/ansible-disto-vars\n\nChange-Id: I05651bff4eb85fda37eddb80074c23ac48b71201\n'}, {'number': 2, 'created': '2019-08-09 16:24:34.000000000', 'files': ['tasks/main.yml', 'vars/family-debian.yml', 'vars/family-gentoo.yml', 'vars/family-suse.yml', 'vars/family-redhat-8.yml', 'vars/family-redhat-7.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/d04b658e63bc839be1431bba273db064ac896a14', 'message': 'Improve loading of operating system specific vars\n\nImproves the overlayed var loading pattern by addressing two problems\nwith current implementation:\n\n* Avoid confusion between os_family and distribution\n* Loads all files, allowing to define variable in less places\n\nThat newer pattern is already used in few other repositories.\n\nMore details on https://docs.sbarnea.com/ansible/ansible-disto-vars\n\nChange-Id: I05651bff4eb85fda37eddb80074c23ac48b71201\n'}]",0,675624,d04b658e63bc839be1431bba273db064ac896a14,7,8,2,24162,,,0,"Improve loading of operating system specific vars

Improves the overlayed var loading pattern by addressing two problems
with current implementation:

* Avoid confusion between os_family and distribution
* Loads all files, allowing to define variable in less places

That newer pattern is already used in few other repositories.

More details on https://docs.sbarnea.com/ansible/ansible-disto-vars

Change-Id: I05651bff4eb85fda37eddb80074c23ac48b71201
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/24/675624/2 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'vars/family-debian.yml']",2,ae4ee0c69e2e15c8de7e7783743c63cb90165e55,fix/os-spec-vars,,,9,8
openstack%2Ftripleo-ci~master~I814196d8ce32a3872aa545bc15aac2b94c2bf9fd,openstack/tripleo-ci,master,I814196d8ce32a3872aa545bc15aac2b94c2bf9fd,DNM: run jobs w/o paunch,ABANDONED,2019-11-14 19:46:52.000000000,2020-01-29 10:16:26.000000000,,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-11-14 19:46:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/451832fd9c5c847ef38b40c79e1feeb26953e0aa', 'message': 'DNM: run jobs w/o paunch\n\nChange-Id: I814196d8ce32a3872aa545bc15aac2b94c2bf9fd\n'}, {'number': 2, 'created': '2019-11-27 18:20:16.000000000', 'files': ['zuul.d/undercloud-jobs.yaml', 'zuul.d/standalone-jobs.yaml', 'zuul.d/multinode-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b8987838f9fb88f697899e6b90b22f180cadc6c7', 'message': 'DNM: run jobs w/o paunch\n\nChange-Id: I814196d8ce32a3872aa545bc15aac2b94c2bf9fd\n'}]",0,694393,b8987838f9fb88f697899e6b90b22f180cadc6c7,9,3,2,10969,,,0,"DNM: run jobs w/o paunch

Change-Id: I814196d8ce32a3872aa545bc15aac2b94c2bf9fd
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/93/694393/2 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/undercloud-jobs.yaml', 'zuul.d/standalone-jobs.yaml', 'zuul.d/multinode-jobs.yaml']",3,451832fd9c5c847ef38b40c79e1feeb26953e0aa,nopaunch, featureset_override: undercloud_enable_paunch: false,,7,0
openstack%2Ftripleo-heat-templates~master~I5765eed237b7c53f83ed08c2f3457e4df079c833,openstack/tripleo-heat-templates,master,I5765eed237b7c53f83ed08c2f3457e4df079c833,DNM: test sc012 job,ABANDONED,2019-09-23 05:57:06.000000000,2020-01-29 10:13:47.000000000,,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-09-23 05:57:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/153947e2745a637429a122ee70feeea47d463032', 'message': 'DNM: test sc012 job\n\nChange-Id: I5765eed237b7c53f83ed08c2f3457e4df079c833\n'}, {'number': 2, 'created': '2019-10-27 09:46:43.000000000', 'files': ['ci/environments/scenario012-standalone.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d13dc658888e5e885d00a7843ac89b78d70b7100', 'message': 'DNM: test sc012 job\n\nChange-Id: I5765eed237b7c53f83ed08c2f3457e4df079c833\n'}]",0,683848,d13dc658888e5e885d00a7843ac89b78d70b7100,10,3,2,10969,,,0,"DNM: test sc012 job

Change-Id: I5765eed237b7c53f83ed08c2f3457e4df079c833
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/48/683848/2 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/scenario012-standalone.yaml'],1,153947e2745a637429a122ee70feeea47d463032,,# test,,1,0
openstack%2Ftripleo-quickstart~master~I9b3275a372be508d05d7db15871e01a29eb1f6b2,openstack/tripleo-quickstart,master,I9b3275a372be508d05d7db15871e01a29eb1f6b2,DNM: centos8 repos as copy of centos7,ABANDONED,2019-10-25 12:53:01.000000000,2020-01-29 10:13:27.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-25 12:53:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/a6871ddce08b80c7f92d7f96d0d2ef0f731a47ad', 'message': 'DNM: centos8 repos as copy of centos7\n\nChange-Id: I9b3275a372be508d05d7db15871e01a29eb1f6b2\n'}, {'number': 2, 'created': '2019-10-25 15:47:02.000000000', 'files': ['config/release/tripleo-ci/CentOS-8/promotion-testing-hash-pike.yml', 'config/release/tripleo-ci/CentOS-8/consistent-ocata.yml', 'config/release/tripleo-ci/CentOS-8/newton.yml', 'config/release/tripleo-ci/CentOS-8/pike.yml', 'config/release/tripleo-ci/CentOS-8/promotion-testing-hash-queens.yml', 'config/release/tripleo-ci/CentOS-8/promotion-testing-hash-ocata.yml', 'config/release/tripleo-ci/CentOS-8/promotion-testing-hash-stein.yml', 'config/release/tripleo-ci/CentOS-8/consistent-rocky.yml', 'config/release/tripleo-ci/CentOS-8/ocata.yml', 'config/release/tripleo-ci/CentOS-8/queens.yml', 'config/release/tripleo-ci/CentOS-8/promotion-testing-hash-rocky.yml', 'config/release/tripleo-ci/CentOS-8/consistent-newton.yml', 'config/release/tripleo-ci/CentOS-8/master.yml', 'config/release/tripleo-ci/CentOS-8/stein.yml', 'config/release/tripleo-ci/CentOS-8/promotion-testing-hash-master.yml', 'config/release/tripleo-ci/CentOS-8/rocky.yml', 'config/release/tripleo-ci/CentOS-8/train.yml', 'config/release/tripleo-ci/CentOS-8/consistent-pike.yml', 'config/release/tripleo-ci/CentOS-8/consistent-queens.yml', 'config/release/tripleo-ci/CentOS-8/promotion-testing-hash-newton.yml', 'config/release/tripleo-ci/CentOS-8/consistent-master.yml', 'config/release/tripleo-ci/CentOS-8/promotion-testing-hash-train.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/c297dddc5698e48864ee57c157d19e1e772c3d4b', 'message': 'DNM: centos8 repos as copy of centos7\n\nChange-Id: I9b3275a372be508d05d7db15871e01a29eb1f6b2\n'}]",0,691298,c297dddc5698e48864ee57c157d19e1e772c3d4b,6,2,2,10969,,,0,"DNM: centos8 repos as copy of centos7

Change-Id: I9b3275a372be508d05d7db15871e01a29eb1f6b2
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/98/691298/1 && git format-patch -1 --stdout FETCH_HEAD,"['config/release/tripleo-ci/CentOS-8/promotion-testing-hash-pike.yml', 'config/release/tripleo-ci/CentOS-8/consistent-ocata.yml', 'config/release/tripleo-ci/CentOS-8/newton.yml', 'config/release/tripleo-ci/CentOS-8/pike.yml', 'config/release/tripleo-ci/CentOS-8/promotion-testing-hash-queens.yml', 'config/release/tripleo-ci/CentOS-8/promotion-testing-hash-ocata.yml', 'config/release/tripleo-ci/CentOS-8/promotion-testing-hash-stein.yml', 'config/release/tripleo-ci/CentOS-8/consistent-rocky.yml', 'config/release/tripleo-ci/CentOS-8/ocata.yml', 'config/release/tripleo-ci/CentOS-8/queens.yml', 'config/release/tripleo-ci/CentOS-8/promotion-testing-hash-rocky.yml', 'config/release/tripleo-ci/CentOS-8/consistent-newton.yml', 'config/release/tripleo-ci/CentOS-8/master.yml', 'config/release/tripleo-ci/CentOS-8/stein.yml', 'config/release/tripleo-ci/CentOS-8/promotion-testing-hash-master.yml', 'config/release/tripleo-ci/CentOS-8/rocky.yml', 'config/release/tripleo-ci/CentOS-8/train.yml', 'config/release/tripleo-ci/CentOS-8/consistent-pike.yml', 'config/release/tripleo-ci/CentOS-8/consistent-queens.yml', 'config/release/tripleo-ci/CentOS-8/promotion-testing-hash-newton.yml', 'config/release/tripleo-ci/CentOS-8/consistent-master.yml', 'config/release/tripleo-ci/CentOS-8/promotion-testing-hash-train.yml']",22,a6871ddce08b80c7f92d7f96d0d2ef0f731a47ad,centos8,"devmode: true overcloud_as_undercloud: true use_specific_hash: true docker_registry_host: trunk.registry.rdoproject.org docker_registry_namespace: ""tripleo{{ release }}"" delorean_hash_label: &promotion-testing-tag ""{{ dlrn_hash|default(dlrn_hash_tag) }}"" docker_image_tag: *promotion-testing-tag dlrn_hash_tag_newest: current validate_on: rdo images: - name: overcloud-full url: ""{{ overcloud_image_url }}"" type: tar - name: ipa_images url: ""{{ ipa_image_url }}"" type: tar inject_images: - ""ironic-python-agent.initramfs"" - ""ironic-python-agent.kernel"" - ""overcloud-full.qcow2"" - ""overcloud-full.initrd"" - ""overcloud-full.vmlinuz"" release: train dlrn_hash_tag: tripleo-ci-testing overcloud_image_url: ""https://images.rdoproject.org/{{ release }}/rdo_trunk/current-tripleo/overcloud-full.tar"" ipa_image_url: ""https://images.rdoproject.org/{{ release }}/rdo_trunk/current-tripleo/ironic-python-agent.tar"" repo_cmd_before: | sudo rm -rf /etc/yum.repos.d/delorean*; sudo rm -rf /etc/yum.repos.d/*.rpmsave; sudo yum clean all; sudo yum-config-manager --disable ""*"" if [ -e /etc/ci/mirror_info.sh ]; then source /etc/ci/mirror_info.sh else # Otherwise, fallback to official mirrors provided by CentOS. export NODEPOOL_CENTOS_MIRROR={{ lookup('env','NODEPOOL_CENTOS_MIRROR')|default('http://mirror.centos.org/centos', true) }} export NODEPOOL_RDO_PROXY=https://trunk.rdoproject.org fi rdo_dlrn=`curl --silent ${NODEPOOL_RDO_PROXY}/centos7-{{ release }}/{{ dlrn_hash_path|default(dlrn_hash_tag, true) }}/delorean.repo -S 2>>~/dlrn_repo_curl_errors.log | grep baseurl | cut -d= -f2` if [[ -z ""$rdo_dlrn"" ]]; then echo ""Failed to parse dlrn hash"" exit 1 fi export RDO_DLRN_REPO=${rdo_dlrn/https:\/\/trunk.rdoproject.org/$NODEPOOL_RDO_PROXY} repos: - type: generic reponame: delorean filename: delorean.repo priority: 20 baseurl: $RDO_DLRN_REPO - type: generic reponame: ""delorean-{{ release }}-deps"" filename: ""delorean-{{ release }}-deps.repo"" baseurl: ""${NODEPOOL_RDO_PROXY}/centos7-{{ release }}/deps/latest/"" - type: generic reponame: ""delorean-{{ release }}-build-deps"" filename: ""delorean-{{ release }}-build-deps.repo"" baseurl: ""${NODEPOOL_RDO_PROXY}/centos7-{{ release }}/build-deps/latest/"" enabled: 0 # CentOS related repos - type: generic reponame: quickstart-centos-base filename: quickstart-centos-base.repo baseurl: ${NODEPOOL_CENTOS_MIRROR}/7/os/x86_64/ - type: generic reponame: quickstart-centos-updates filename: quickstart-centos-updates.repo baseurl: ${NODEPOOL_CENTOS_MIRROR}/7/updates/x86_64/ - type: generic reponame: quickstart-centos-extras filename: quickstart-centos-extras.repo baseurl: ${NODEPOOL_CENTOS_MIRROR}/7/extras/x86_64/ - type: generic reponame: quickstart-centos-qemu filename: quickstart-centos-qemu.repo baseurl: ${NODEPOOL_CENTOS_MIRROR}/7/virt/x86_64/kvm-common/ - type: generic reponame: quickstart-centos-ceph-nautilus filename: quickstart-centos-ceph-nautilus.repo baseurl: ${NODEPOOL_CENTOS_MIRROR}/7/storage/x86_64/ceph-nautilus/ - type: generic reponame: quickstart-centos-opstools filename: quickstart-centos-opstools.repo baseurl: ${NODEPOOL_CENTOS_MIRROR}/7/opstools/x86_64/ - type: generic reponame: quickstart-centos-cr filename: quickstart-centos-cr.repo baseurl: ${NODEPOOL_CENTOS_MIRROR}/7/cr/x86_64/ enabled: 0 - type: generic reponame: quickstart-centos7-rt filename: quickstart-centos7-rt.repo baseurl: ${NODEPOOL_CENTOS_MIRROR}/7/rt/x86_64/ enabled: 0 repo_cmd_after: | sudo yum install -y yum-plugin-priorities; {% if not enable_opstools_repo|default(false)|bool %}sudo yum-config-manager --save --setopt quickstart-centos-opstools.enabled=0; {%endif %} {% if enable_centos_cr_repo|default(false)|bool %} yum-config-manager --enable quickstart-centos-cr {% endif %} sudo yum-config-manager --disable rdo-qemu-ev; sudo rpm -e epel-release || true; sudo yum remove -y rdo-release centos-release-ceph-* centos-release-openstack-* centos-release-qemu-ev || true; sudo rm -rf /etc/yum.repos.d/CentOS-OpenStack-*.repo /etc/yum.repos.d/CentOS-Ceph-*.repo /etc/yum.repos.d/CentOS-QEMU-EV.repo; sudo rm -rf /etc/yum.repos.d/*.rpmsave; sudo yum repolist; sudo yum clean metadata {% if repo_setup_run_update|default(true)|bool %} sudo yum update -y {% endif %} undercloud_rpm_dependencies: >- python-tripleoclient ceph-ansible # baseos settings baseos_undercloud_image_url: https://cloud.centos.org/centos/7/images/CentOS-7-x86_64-GenericCloud-1901.qcow2 baseos_image: centos baseos_image_type: qcow2 baseos_md5sum: ""26c52282b53e6fe746fbfd5542421675 CentOS-7-x86_64-GenericCloud-1901.qcow2"" ",,2829,0
openstack%2Ftripleo-ci~master~I15c93ff494902741dbf1056be5508c0ce0a5ad58,openstack/tripleo-ci,master,I15c93ff494902741dbf1056be5508c0ce0a5ad58,DNM: scenario006 job,ABANDONED,2019-09-15 12:01:43.000000000,2020-01-29 10:12:18.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-09-15 12:01:43.000000000', 'files': ['zuul.d/standalone-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3de071d89369f3d264cf01027fc7434cbbd0bfa1', 'message': 'DNM: scenario006 job\n\nDepends-On: https://review.opendev.org/682237\nChange-Id: I15c93ff494902741dbf1056be5508c0ce0a5ad58\n'}]",0,682244,3de071d89369f3d264cf01027fc7434cbbd0bfa1,4,2,1,10969,,,0,"DNM: scenario006 job

Depends-On: https://review.opendev.org/682237
Change-Id: I15c93ff494902741dbf1056be5508c0ce0a5ad58
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/44/682244/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/standalone-jobs.yaml'],1,3de071d89369f3d264cf01027fc7434cbbd0bfa1,s006, - tripleo-ci-centos-7-scenario006-standalone: files: - ci/environments/scenario006-standalone.yaml - job: name: tripleo-ci-centos-7-scenario006-standalone voting: false parent: tripleo-ci-base-standalone nodeset: single-centos-7-node branches: ^(?!stable/(newton|ocata|pike|queens|rocky|stein)).*$ vars: featureset: '052' featureset_override: run_tempest: false standalone_environment_files: - 'environments/low-memory-usage.yaml' - 'ci/environments/scenario006-standalone.yaml' tempest_services: - neutron tempest_test_whitelist: - 'tempest.scenario.test_network_basic_ops.TestNetworkBasicOps.test_network_basic_ops' tempest_private_net_provider_type: 'vxlan' use_os_tempest: true,,23,0
openstack%2Ftripleo-heat-templates~master~Ib5f781a22bdc55e0dcf44b92ccd0d7d174e2810b,openstack/tripleo-heat-templates,master,Ib5f781a22bdc55e0dcf44b92ccd0d7d174e2810b,DNM: scenario006 standalone,ABANDONED,2019-09-15 05:59:08.000000000,2020-01-29 10:12:14.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-09-15 05:59:08.000000000', 'files': ['ci/environments/scenario006-standalone.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c11efa526c14c149799b2f5a8791ec1df9df5f52', 'message': 'DNM: scenario006 standalone\n\nChange-Id: Ib5f781a22bdc55e0dcf44b92ccd0d7d174e2810b\n'}]",0,682237,c11efa526c14c149799b2f5a8791ec1df9df5f52,4,2,1,10969,,,0,"DNM: scenario006 standalone

Change-Id: Ib5f781a22bdc55e0dcf44b92ccd0d7d174e2810b
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/37/682237/1 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/scenario006-standalone.yaml'],1,c11efa526c14c149799b2f5a8791ec1df9df5f52,s006,resource_registry: OS::TripleO::Services::CACerts: ../../deployment/certs/ca-certs-baremetal-puppet.yaml OS::TripleO::Services::Chrony: ../../deployment/timesync/chrony-baremetal-ansible.yaml OS::TripleO::Services::ContainerImagePrepare: ../../deployment/container-image-prepare/container-image-prepare-baremetal-ansible.yaml OS::TripleO::Services::Docker: ../../deployment/deprecated/docker/docker-baremetal-ansible.yaml OS::TripleO::Services::Kernel: ../../deployment/kernel/kernel-baremetal-ansible.yaml OS::TripleO::Services::Snmp: ../../deployment/snmp/snmp-baremetal-puppet.yaml OS::TripleO::Services::Timesync: OS::TripleO::Services::Chrony OS::TripleO::Services::Timezone: ../../deployment/time/timezone-baremetal-ansible.yaml OS::TripleO::Services::TripleoPackages: ../../deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml OS::TripleO::Services::TripleoFirewall: ../../deployment/tripleo-firewall/tripleo-firewall-baremetal-puppet.yaml OS::TripleO::Services::Sshd: ../../deployment/sshd/sshd-baremetal-puppet.yaml OS::TripleO::Services::Kubernetes::Master: ../../deployment/kubernetes/kubernetes-master-baremetal-ansible.yaml OS::TripleO::Services::Kubernetes::Worker: ../../deployment/kubernetes/kubernetes-worker-baremetal-ansible.yaml # Some infra instances don't pass the ping test but are otherwise working. # Since the OVB jobs also test this functionality we can shut it off here. OS::TripleO::AllNodes::Validation: ../common/all-nodes-validation-disabled.yaml # Disabled OS::TripleO::Services::SwiftProxy: OS::Heat::None OS::TripleO::Services::SwiftStorage: OS::Heat::None OS::TripleO::Services::SwiftRingBuilder: OS::Heat::None OS::TripleO::Services::Keystone: OS::Heat::None OS::TripleO::Services::GlanceApi: OS::Heat::None OS::TripleO::Services::MySQL: OS::Heat::None OS::TripleO::Services::MySQLClient: OS::Heat::None OS::TripleO::Services::NeutronBgpVpnApi: OS::Heat::None OS::TripleO::Services::NeutronDhcpAgent: OS::Heat::None OS::TripleO::Services::NeutronL3Agent: OS::Heat::None OS::TripleO::Services::NeutronMetadataAgent: OS::Heat::None OS::TripleO::Services::NeutronServer: OS::Heat::None OS::TripleO::Services::NeutronCorePlugin: OS::Heat::None OS::TripleO::Services::NeutronOvsAgent: OS::Heat::None OS::TripleO::Services::RabbitMQ: OS::Heat::None OS::TripleO::Services::HAproxy: OS::Heat::None OS::TripleO::Services::Keepalived: OS::Heat::None OS::TripleO::Services::Memcached: OS::Heat::None OS::TripleO::Services::NovaConductor: OS::Heat::None OS::TripleO::Services::NovaApi: OS::Heat::None OS::TripleO::Services::PlacementApi: OS::Heat::None OS::TripleO::Services::NovaMetadata: OS::Heat::None OS::TripleO::Services::NovaScheduler: OS::Heat::None OS::TripleO::Services::NovaCompute: OS::Heat::None OS::TripleO::Services::NovaLibvirt: OS::Heat::None parameter_defaults: Debug: true KubesprayIgnoreAssertErrors: true ,,47,0
openstack%2Ftripleo-quickstart-extras~master~I594dc1b9ed105dff699d1b82364f4752baf5a77a,openstack/tripleo-quickstart-extras,master,I594dc1b9ed105dff699d1b82364f4752baf5a77a,WIP: build images for rhel8,ABANDONED,2019-08-02 14:40:07.000000000,2020-01-29 10:11:56.000000000,,"[{'_account_id': 10969}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-08-02 14:40:07.000000000', 'files': ['roles/build-images/templates/overcloud-image-build.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/bfddec235fde9f2183217c0978816c7a1fa1dedf', 'message': 'WIP: build images for rhel8\n\nChange-Id: I594dc1b9ed105dff699d1b82364f4752baf5a77a\n'}]",0,674322,bfddec235fde9f2183217c0978816c7a1fa1dedf,8,4,1,10969,,,0,"WIP: build images for rhel8

Change-Id: I594dc1b9ed105dff699d1b82364f4752baf5a77a
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/22/674322/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/build-images/templates/overcloud-image-build.sh.j2'],1,bfddec235fde9f2183217c0978816c7a1fa1dedf,build8,sudo $(command -v dnf || command -v yum) install -y python{% if ansible_python.version.major == 3 %}3{% endif %}-tripleoclient,sudo yum -y install python-tripleoclient,1,1
openstack%2Ftripleo-ci~master~If116bf69f55727e3e1054f639d24b111b08b3d2a,openstack/tripleo-ci,master,If116bf69f55727e3e1054f639d24b111b08b3d2a,DNM: test job failure,ABANDONED,2019-08-26 22:14:34.000000000,2020-01-29 10:05:32.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-08-26 22:14:34.000000000', 'files': ['roles/run-test/templates/toci_quickstart.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/46efa5a700113034133b7e88af0a52439a8b1b21', 'message': 'DNM: test job failure\n\nChange-Id: If116bf69f55727e3e1054f639d24b111b08b3d2a\n'}]",0,678694,46efa5a700113034133b7e88af0a52439a8b1b21,4,2,1,10969,,,0,"DNM: test job failure

Change-Id: If116bf69f55727e3e1054f639d24b111b08b3d2a
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/94/678694/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/run-test/templates/toci_quickstart.sh.j2'],1,46efa5a700113034133b7e88af0a52439a8b1b21,fail,exit 1,exit $exit_value,1,1
openstack%2Ftripleo-heat-templates~master~Ifcc2faa3a0da716003e88dc6732618183336df5c,openstack/tripleo-heat-templates,master,Ifcc2faa3a0da716003e88dc6732618183336df5c,DNM: try 004 with podman,ABANDONED,2019-08-29 08:32:55.000000000,2020-01-29 10:05:25.000000000,,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-08-29 08:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/49b682e383b886e7c28a1dea0fed8bf312619a18', 'message': 'DNM: try 004 with podman\n\nChange-Id: Ifcc2faa3a0da716003e88dc6732618183336df5c\n'}, {'number': 2, 'created': '2019-10-27 09:49:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/732265bc2669d47095db84d02c7e874a4c4b23ea', 'message': 'DNM: try 004 with podman\n\nChange-Id: Ifcc2faa3a0da716003e88dc6732618183336df5c\n'}, {'number': 3, 'created': '2019-11-09 11:02:49.000000000', 'files': ['ci/environments/scenario004-standalone.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/004f753a88f35889cf795a019267144253fc106f', 'message': 'DNM: try 004 with podman\n\nChange-Id: Ifcc2faa3a0da716003e88dc6732618183336df5c\n'}]",0,679199,004f753a88f35889cf795a019267144253fc106f,13,3,3,10969,,,0,"DNM: try 004 with podman

Change-Id: Ifcc2faa3a0da716003e88dc6732618183336df5c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/99/679199/1 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/scenario004-standalone.yaml'],1,49b682e383b886e7c28a1dea0fed8bf312619a18,, ContainerCli: podman, ContainerCli: docker,1,1
openstack%2Ftripleo-quickstart~master~I38fa628ff355c32d67660e8f06185f1a353aeebf,openstack/tripleo-quickstart,master,I38fa628ff355c32d67660e8f06185f1a353aeebf,Add release note link in README,ABANDONED,2018-06-28 06:04:53.000000000,2020-01-29 09:58:09.000000000,,"[{'_account_id': 8449}, {'_account_id': 10969}, {'_account_id': 18846}, {'_account_id': 21691}, {'_account_id': 22348}, {'_account_id': 24162}, {'_account_id': 24752}, {'_account_id': 26285}, {'_account_id': 28614}, {'_account_id': 29222}]","[{'number': 1, 'created': '2018-06-28 06:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/54ba988e7bbc2ee93c650d5ecc1240ae9b79d7a4', 'message': 'Add release note link in README\n\nChange-Id: I38fa628ff355c32d67660e8f06185f1a353aeebf\n'}, {'number': 2, 'created': '2019-09-11 11:51:38.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/0faa86573bfd3c4f7dce0e1c6f9842bb80419ff9', 'message': 'Add release note link in README\n\nChange-Id: I38fa628ff355c32d67660e8f06185f1a353aeebf\n'}]",0,578687,0faa86573bfd3c4f7dce0e1c6f9842bb80419ff9,18,10,2,27336,,,0,"Add release note link in README

Change-Id: I38fa628ff355c32d67660e8f06185f1a353aeebf
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/87/578687/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,54ba988e7bbc2ee93c650d5ecc1240ae9b79d7a4,,.. _Release notes: https://docs.openstack.org/releasenotes/tripleo-quickstart/,,1,0
openstack%2Ftripleo-quickstart-extras~master~Ib78f66723209abe9b4b94630926ab0a776d559d1,openstack/tripleo-quickstart-extras,master,Ib78f66723209abe9b4b94630926ab0a776d559d1,Update min tox version to 2.0,ABANDONED,2018-11-02 04:24:43.000000000,2020-01-29 09:57:29.000000000,,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 24162}]","[{'number': 1, 'created': '2018-11-02 04:24:43.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/cb23fbb753e3ebcf80c17d8b549e2eaa0853e679', 'message': 'Update min tox version to 2.0\n\nThe commands used by constraints need at least tox 2.0.\nUpdate to reflect reality, which should help with local running of\nconstraints targets.\n\nChange-Id: Ib78f66723209abe9b4b94630926ab0a776d559d1\n'}]",0,614967,cb23fbb753e3ebcf80c17d8b549e2eaa0853e679,7,7,1,28956,,,0,"Update min tox version to 2.0

The commands used by constraints need at least tox 2.0.
Update to reflect reality, which should help with local running of
constraints targets.

Change-Id: Ib78f66723209abe9b4b94630926ab0a776d559d1
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/67/614967/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,cb23fbb753e3ebcf80c17d8b549e2eaa0853e679,min-tox-version,minversion = 2.0,minversion = 1.6,1,1
openstack%2Ftripleo-quickstart~master~Icb9ab30ba0ba782962f665c8ff8b8776f9b87de6,openstack/tripleo-quickstart,master,Icb9ab30ba0ba782962f665c8ff8b8776f9b87de6,Add proxy support for curl and yum repo,ABANDONED,2019-03-21 08:05:36.000000000,2020-01-29 09:56:51.000000000,,"[{'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2019-03-21 08:05:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/d287eae67cad3da8cb9ba25ef14a029e727a7db4', 'message': 'Add proxy support for curl and yum repo\n\nChange-Id: Icb9ab30ba0ba782962f665c8ff8b8776f9b87de6\n'}, {'number': 2, 'created': '2019-03-21 08:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/e891111666d102e95a5f2dce7909a7a79779a647', 'message': 'Add proxy support for curl and yum repo\n\nChange-Id: Icb9ab30ba0ba782962f665c8ff8b8776f9b87de6\n'}, {'number': 3, 'created': '2019-03-21 08:37:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/2b352e32acbfcd3557d8796fe6568d13679a63f0', 'message': 'Add proxy support for curl and yum repo\n\nCloses-Bug: #1821145\nChange-Id: Icb9ab30ba0ba782962f665c8ff8b8776f9b87de6\n'}, {'number': 4, 'created': '2019-04-11 18:21:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/74a7b288de8db57feacf7492762772ade9f790ff', 'message': 'Add proxy support for curl and yum repo\n\nmodify the ipa for correct overcloud images and config download way\n\nCloses-Bug: #1821145\nChange-Id: Icb9ab30ba0ba782962f665c8ff8b8776f9b87de6\n'}, {'number': 5, 'created': '2019-04-16 13:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/1b926320fe1511e2700d973a7a7fdd53cccc1967', 'message': 'Add proxy support for curl and yum repo\n\nmodify the ipa for correct overcloud images and config download way\n\nCloses-Bug: #1821145\nChange-Id: Icb9ab30ba0ba782962f665c8ff8b8776f9b87de6\n'}, {'number': 6, 'created': '2019-06-03 14:34:23.000000000', 'files': ['roles/fetch-images/defaults/main.yml', 'roles/repo-setup/templates/repo_setup.sh.j2', 'README.rst', 'roles/fetch-images/tasks/fetch.yml', 'roles/repo-setup/defaults/main.yml', 'config/general_config/ipa.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/834e5e86864c61477743530d501e46610002a93b', 'message': 'Add proxy support for curl and yum repo\n\nmodify the ipa for correct overcloud images and config download way\n\nCloses-Bug: #1821145\nChange-Id: Icb9ab30ba0ba782962f665c8ff8b8776f9b87de6\n'}]",5,645069,834e5e86864c61477743530d501e46610002a93b,24,4,6,2874,,,0,"Add proxy support for curl and yum repo

modify the ipa for correct overcloud images and config download way

Closes-Bug: #1821145
Change-Id: Icb9ab30ba0ba782962f665c8ff8b8776f9b87de6
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/69/645069/6 && git format-patch -1 --stdout FETCH_HEAD,"['roles/fetch-images/defaults/main.yml', 'roles/repo-setup/templates/repo_setup.sh.j2', 'README.rst', 'roles/fetch-images/tasks/fetch.yml', 'roles/repo-setup/defaults/main.yml', 'config/general_config/ipa.yml']",6,d287eae67cad3da8cb9ba25ef14a029e727a7db4,bug/1821145,"container_args: >- {% if release in ['pike', 'queens', 'rocky'] %} -e {{ overcloud_templates_path }}/environments/docker.yaml {% endif %} {% if enable_pacemaker|bool or osp_release is defined%} -e {{ overcloud_templates_path }}/environments/docker-ha.yaml {% endif %} -e {{ working_dir }}/containers-default-parameters.yaml",,21,1
openstack%2Ftripleo-quickstart-extras~master~Iaa126f63a1f85e12aefdf766c756bb6f9a48b284,openstack/tripleo-quickstart-extras,master,Iaa126f63a1f85e12aefdf766c756bb6f9a48b284,manage-stack: add env variables in info gathering,ABANDONED,2018-07-19 10:40:50.000000000,2020-01-29 09:55:36.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2018-07-19 10:40:50.000000000', 'files': ['roles/ovb-manage-stack/tasks/ovb-create-stack.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/eeb65f9486b9d6537de201bcb98058619016b69e', 'message': 'manage-stack: add env variables in info gathering\n\nThe task to gt stack failure informations was missing the exporting of\nenvironment variables needed for the command to work properly\n\nChange-Id: Iaa126f63a1f85e12aefdf766c756bb6f9a48b284\n'}]",0,583916,eeb65f9486b9d6537de201bcb98058619016b69e,5,3,1,10022,,,0,"manage-stack: add env variables in info gathering

The task to gt stack failure informations was missing the exporting of
environment variables needed for the command to work properly

Change-Id: Iaa126f63a1f85e12aefdf766c756bb6f9a48b284
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/16/583916/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/ovb-manage-stack/tasks/ovb-create-stack.yml'],1,eeb65f9486b9d6537de201bcb98058619016b69e,status-info-fix," shell: > export OS_USERNAME=""{{ os_username }}""; export OS_PASSWORD=""{{ os_password }}""; export OS_TENANT_NAME=""{{ os_tenant_name }}""; export OS_AUTH_URL=""{{ os_auth_url }}""; openstack stack show ""{{ stack_name }}"""," shell: openstack stack show ""{{ stack_name }}""",6,1
openstack%2Ftripleo-quickstart~master~I099babc55cd8cc7781a5b419b2ae567ee64e02b7,openstack/tripleo-quickstart,master,I099babc55cd8cc7781a5b419b2ae567ee64e02b7,"[Trivial Fix] Correct spelling error of ""cloud""",ABANDONED,2018-11-02 02:47:33.000000000,2020-01-29 09:54:41.000000000,,"[{'_account_id': 10969}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 28956}]","[{'number': 1, 'created': '2018-11-02 02:47:33.000000000', 'files': ['roles/environment/setup/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/afb9174448b6fb27b7e763d5e14ce59ccd97ac05', 'message': '[Trivial Fix] Correct spelling error of ""cloud""\n\nSmall modification to correct spelling mistake.\n\nChange-Id: I099babc55cd8cc7781a5b419b2ae567ee64e02b7\n'}]",0,614928,afb9174448b6fb27b7e763d5e14ce59ccd97ac05,14,6,1,28956,,,0,"[Trivial Fix] Correct spelling error of ""cloud""

Small modification to correct spelling mistake.

Change-Id: I099babc55cd8cc7781a5b419b2ae567ee64e02b7
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/28/614928/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/environment/setup/tasks/main.yml'],1,afb9174448b6fb27b7e763d5e14ce59ccd97ac05,fix-typo,# attach the undercloud and overcloud virtual machines.,# attach the undercoud and overcloud virtual machines.,1,1
openstack%2Ftripleo-quickstart~master~I5a3e0f4c352947cab3417186f89e96d5995de2a3,openstack/tripleo-quickstart,master,I5a3e0f4c352947cab3417186f89e96d5995de2a3,[Configuration] Increasing the ssh timeout.,ABANDONED,2018-11-13 14:10:14.000000000,2020-01-29 09:53:04.000000000,,"[{'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 24162}, {'_account_id': 29222}]","[{'number': 1, 'created': '2018-11-13 14:10:14.000000000', 'files': ['ansible.cfg'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/f3478b2b41696cb67206cd44c424ec554dac4bf4', 'message': '[Configuration] Increasing the ssh timeout.\n\nTo be more resilient to ssh connectivity issues.\n\nChange-Id: I5a3e0f4c352947cab3417186f89e96d5995de2a3\nCloses-Bug: #1714014\n'}]",0,617663,f3478b2b41696cb67206cd44c424ec554dac4bf4,6,4,1,29222,,,0,"[Configuration] Increasing the ssh timeout.

To be more resilient to ssh connectivity issues.

Change-Id: I5a3e0f4c352947cab3417186f89e96d5995de2a3
Closes-Bug: #1714014
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/63/617663/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible.cfg'],1,f3478b2b41696cb67206cd44c424ec554dac4bf4,bug/1714014,timeout = 20,,1,0
openstack%2Ftripleo-quickstart-extras~master~I113e72cac334c77c3b901f281c1850af865d64d5,openstack/tripleo-quickstart-extras,master,I113e72cac334c77c3b901f281c1850af865d64d5,Amend the spelling error of a word,ABANDONED,2018-06-07 01:41:29.000000000,2020-01-29 09:52:12.000000000,,"[{'_account_id': 10969}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 24752}]","[{'number': 1, 'created': '2018-06-07 01:41:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/afedb19bfc662fb7c2cfa80deb6884cb301b8882', 'message': 'Amend the spelling error of a word\n\nChange-Id: I113e72cac334c77c3b901f281c1850af865d64d5\n'}, {'number': 2, 'created': '2018-11-15 00:20:15.000000000', 'files': ['playbooks/to-build-or-not-to-build.yml', 'releasenotes/notes/root-device-hints-a8a6e41ec851ec12.yaml', 'roles/validate-tempest/files/tempestmail/template/template.html', 'roles/tripleo-validations/templates/run-preintro-validations-negative-tests.sh.j2', 'roles/validate-tempest/files/tempestmail/tests/fixtures/template.html', 'roles/overcloud-deploy/tasks/pre-deploy.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/93f5a51a55a3b2e62b070a6e85f0a91a51b33615', 'message': 'Amend the spelling error of a word\n\nChange-Id: I113e72cac334c77c3b901f281c1850af865d64d5\n'}]",2,573058,93f5a51a55a3b2e62b070a6e85f0a91a51b33615,13,6,2,27549,,,0,"Amend the spelling error of a word

Change-Id: I113e72cac334c77c3b901f281c1850af865d64d5
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/58/573058/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/to-build-or-not-to-build.yml', 'releasenotes/notes/root-device-hints-a8a6e41ec851ec12.yaml', 'roles/validate-tempest/files/tempestmail/template/template.html', 'roles/tripleo-validations/templates/run-preintro-validations-negative-tests.sh.j2', 'roles/validate-tempest/files/tempestmail/tests/fixtures/template.html', 'roles/overcloud-deploy/tasks/pre-deploy.yml']",6,afedb19bfc662fb7c2cfa80deb6884cb301b8882,,"# tripleo-heat-templates directory, no public-bond specific","# tripleo-heat-templates directory, no public-bond specfic",13,13
openstack%2Ftripleo-quickstart-extras~master~Ibf1a0018fd6db65440d6a00acde2c8de92f441fc,openstack/tripleo-quickstart-extras,master,Ibf1a0018fd6db65440d6a00acde2c8de92f441fc,Add ability to update containers,ABANDONED,2018-05-08 12:49:57.000000000,2020-01-29 09:51:54.000000000,,"[{'_account_id': 8871}, {'_account_id': 9592}, {'_account_id': 12715}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 24752}]","[{'number': 1, 'created': '2018-05-08 12:49:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/92fb0f07080a030eb515adefb16647c5db252d9c', 'message': 'WIP Add ability to update containers\n\nChange-Id: Ibf1a0018fd6db65440d6a00acde2c8de92f441fc\n'}, {'number': 2, 'created': '2018-05-23 00:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/ce64272f7665965dfbe301fab767397a35ba6124', 'message': 'Add ability to update containers\n\nWe need to run the prep-containers role a second time to prepare\nthe containers we will use in an update. This commit adds that second\nrun.\n\nDepends-On: I658f09b531e9659c192eeede6cdebf392c4d8281\nChange-Id: Ibf1a0018fd6db65440d6a00acde2c8de92f441fc\n'}, {'number': 3, 'created': '2018-06-07 23:27:15.000000000', 'files': ['playbooks/multinode-overcloud-update.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/b22f149859ffd0383b2aaea8a875d5574bd34ac2', 'message': 'Add ability to update containers\n\nWe need to run the prep-containers role a second time to prepare\nthe containers we will use in an update. This commit adds that second\nrun.\n\nDepends-On: I658f09b531e9659c192eeede6cdebf392c4d8281\nChange-Id: Ibf1a0018fd6db65440d6a00acde2c8de92f441fc\n'}]",0,566877,b22f149859ffd0383b2aaea8a875d5574bd34ac2,20,8,3,12715,,,0,"Add ability to update containers

We need to run the prep-containers role a second time to prepare
the containers we will use in an update. This commit adds that second
run.

Depends-On: I658f09b531e9659c192eeede6cdebf392c4d8281
Change-Id: Ibf1a0018fd6db65440d6a00acde2c8de92f441fc
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/77/566877/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/multinode-overcloud-update.yml'],1,92fb0f07080a030eb515adefb16647c5db252d9c,sprint13,"- name: Prepare containers for Upgrade hosts: undercloud gather_facts: no tags: - overcloud-prep-containers roles: - role: overcloud-prep-containers # This need the new repo in place. update_containers: true containerized_overcloud: true # Do not overwrite the deployment log if any. overcloud_prep_containers_log: ""update_overcloud_prep_containers.log"" overcloud_prep_containers_script: ""update_overcloud_prep_containers.sh"" ",,14,0
openstack%2Ftripleo-quickstart-extras~master~I65590c1ee1b1c7546d151e7a3eb59b95cdb465e1,openstack/tripleo-quickstart-extras,master,I65590c1ee1b1c7546d151e7a3eb59b95cdb465e1,Place the value of EXTRA_VARS into env_vars_to_source_file,ABANDONED,2018-07-10 15:33:51.000000000,2020-01-29 09:51:30.000000000,,"[{'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 24752}]","[{'number': 1, 'created': '2018-07-10 15:33:51.000000000', 'files': ['roles/create-reproducer-script/templates/reproducer-quickstart.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/ad9c393ca40d273716509d2873cb1cf74b57b7cf', 'message': ""Place the value of EXTRA_VARS into env_vars_to_source_file\n\nWe need the value of this so that dlrn_hash_tag_newest is included.\nAlso keep the literal '$EXTRA_VARS' so that it will be included if\nset when the env_vars_to_source_file script is sourced.\n\nChange-Id: I65590c1ee1b1c7546d151e7a3eb59b95cdb465e1\n""}]",0,581404,ad9c393ca40d273716509d2873cb1cf74b57b7cf,7,5,1,1926,,,0,"Place the value of EXTRA_VARS into env_vars_to_source_file

We need the value of this so that dlrn_hash_tag_newest is included.
Also keep the literal '$EXTRA_VARS' so that it will be included if
set when the env_vars_to_source_file script is sourced.

Change-Id: I65590c1ee1b1c7546d151e7a3eb59b95cdb465e1
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/04/581404/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/create-reproducer-script/templates/reproducer-quickstart.sh.j2'],1,ad9c393ca40d273716509d2873cb1cf74b57b7cf,,"export EXTRA_VARS=""\$EXTRA_VARS $EXTRA_VARS {% if dlrn_hash is defined or ('undercloud' in hostvars and 'dlrn_hash' in hostvars['undercloud']) %}--extra-vars dlrn_hash_tag={{ hostvars['undercloud'].dlrn_hash }}{% endif %} ""","export EXTRA_VARS=""\$EXTRA_VARS {% if dlrn_hash is defined or ('undercloud' in hostvars and 'dlrn_hash' in hostvars['undercloud']) %}--extra-vars dlrn_hash_tag={{ hostvars['undercloud'].dlrn_hash }}{% endif %} """,1,1
openstack%2Ftripleo-quickstart~master~I74d39bca2a8d58570d2a037ce4a2432c9c641ad5,openstack/tripleo-quickstart,master,I74d39bca2a8d58570d2a037ce4a2432c9c641ad5,Update value of VERBOSITY option,ABANDONED,2018-10-23 03:12:46.000000000,2020-01-29 09:47:56.000000000,,"[{'_account_id': 9592}, {'_account_id': 10022}, {'_account_id': 12393}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2018-10-23 03:12:46.000000000', 'files': ['quickstart.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/13203a14bd89aa0bf08c7af12c8e64ddd7c313ea', 'message': 'Update value of VERBOSITY option\n\nThis change will update option value for VERBOSITY option to match with officially ansible-playbook CLI.\nhttps://docs.ansible.com/ansible/latest/cli/ansible-playbook.html\n\nChange-Id: I74d39bca2a8d58570d2a037ce4a2432c9c641ad5\nSigned-off-by: Nguyen Quang Huy <huynq@vn.fujitsu.com>\n'}]",0,612554,13203a14bd89aa0bf08c7af12c8e64ddd7c313ea,6,7,1,28846,,,0,"Update value of VERBOSITY option

This change will update option value for VERBOSITY option to match with officially ansible-playbook CLI.
https://docs.ansible.com/ansible/latest/cli/ansible-playbook.html

Change-Id: I74d39bca2a8d58570d2a037ce4a2432c9c641ad5
Signed-off-by: Nguyen Quang Huy <huynq@vn.fujitsu.com>
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/54/612554/1 && git format-patch -1 --stdout FETCH_HEAD,['quickstart.sh'],1,13203a14bd89aa0bf08c7af12c8e64ddd7c313ea,update_verbose_value, VERBOSITY=vvv, VERBOSITY=vv,1,1
openstack%2Ftripleo-quickstart~master~Id937dd2b2857f67b6669bd992046dccb937df6ee,openstack/tripleo-quickstart,master,Id937dd2b2857f67b6669bd992046dccb937df6ee,Correct word in document,ABANDONED,2018-10-24 07:52:54.000000000,2020-01-29 09:47:20.000000000,,"[{'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 24162}]","[{'number': 1, 'created': '2018-10-24 07:52:54.000000000', 'files': ['doc/source/accessing-undercloud.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/eb852dda43207e69c0dd669d81371864b931eb68', 'message': 'Correct word in document\n\nChange incorrect word to correct word\n\nChange-Id: Id937dd2b2857f67b6669bd992046dccb937df6ee\nSigned-off-by: Nguyen Quang Huy <huynq@vn.fujitsu.com>\n'}]",2,612938,eb852dda43207e69c0dd669d81371864b931eb68,5,3,1,28846,,,0,"Correct word in document

Change incorrect word to correct word

Change-Id: Id937dd2b2857f67b6669bd992046dccb937df6ee
Signed-off-by: Nguyen Quang Huy <huynq@vn.fujitsu.com>
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/38/612938/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/accessing-undercloud.rst'],1,eb852dda43207e69c0dd669d81371864b931eb68,update_doc_accessing_undercloud,an insecure connections change the default variable,an insucure connections change the default variable,1,1
openstack%2Ftripleo-quickstart~master~If4e212bf8bdd08de0eca887ad0f81eed913449a3,openstack/tripleo-quickstart,master,If4e212bf8bdd08de0eca887ad0f81eed913449a3,For stock centos/rhel images add repo and stack user,ABANDONED,2017-08-10 09:35:45.000000000,2020-01-29 09:47:03.000000000,,"[{'_account_id': 3}, {'_account_id': 10034}, {'_account_id': 10969}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 24752}]","[{'number': 1, 'created': '2017-08-10 09:35:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/41cc04ab681565a6d93997b21a32a0187a49e200', 'message': 'For stock centos/rhel images add repo and stack user\n\nThis patch would make the undercloud_install work for libvirt based\ndeployments with stock centos and rhel image. The problem is\ndescribed in more detail on the bug:1697007\n\nChange-Id: If4e212bf8bdd08de0eca887ad0f81eed913449a3\nRelated-Bug: 1697007\n'}, {'number': 2, 'created': '2017-08-10 09:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/35da86912526c720f7489d29568e03fe9d8177ba', 'message': 'For stock centos/rhel images add repo and stack user\n\nThis patch would make the undercloud_install work for libvirt based\ndeployments with stock centos and rhel image. The problem is\ndescribed in more detail on the bug:1709833\n\nChange-Id: If4e212bf8bdd08de0eca887ad0f81eed913449a3\nRelated-Bug: 1709833\n'}, {'number': 3, 'created': '2017-08-10 10:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/b626f2d4db505f8ea8e5bdf5f8e257800b6d14cc', 'message': 'For stock centos/rhel images add repo and stack user\n\nThis patch would make the undercloud_install work for libvirt based\ndeployments with stock centos and rhel image. The problem is\ndescribed in more detail on the bug:1709833\n\nChange-Id: If4e212bf8bdd08de0eca887ad0f81eed913449a3\nRelated-Bug: 1709833\n'}, {'number': 4, 'created': '2017-09-06 10:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/7c5b440a1787d4c4dc3b27c21ef5b1fddb47aa11', 'message': 'For stock centos/rhel images add repo and stack user\n\nThis patch would make the undercloud_install work for libvirt based\ndeployments with stock centos and rhel image. The problem is\ndescribed in more detail on the bug:1709833\n\nChange-Id: If4e212bf8bdd08de0eca887ad0f81eed913449a3\nRelated-Bug: 1709833\n'}, {'number': 5, 'created': '2018-05-09 10:42:26.000000000', 'files': ['roles/libvirt/setup/undercloud/tasks/main.yml', 'roles/libvirt/setup/undercloud/tasks/stockos-repo-setup.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/79f380e1cc6d2382c486f71e17e95f6ab07ac562', 'message': 'For stock centos/rhel images add repo and stack user\n\nThis patch would make the undercloud_install work for libvirt based\ndeployments with stock centos and rhel image. The problem is\ndescribed in more detail on the bug:1709833\n\nChange-Id: If4e212bf8bdd08de0eca887ad0f81eed913449a3\nRelated-Bug: 1709833\n'}]",0,492453,79f380e1cc6d2382c486f71e17e95f6ab07ac562,36,8,5,10034,,,0,"For stock centos/rhel images add repo and stack user

This patch would make the undercloud_install work for libvirt based
deployments with stock centos and rhel image. The problem is
described in more detail on the bug:1709833

Change-Id: If4e212bf8bdd08de0eca887ad0f81eed913449a3
Related-Bug: 1709833
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/53/492453/5 && git format-patch -1 --stdout FETCH_HEAD,"['roles/libvirt/setup/undercloud/tasks/main.yml', 'roles/libvirt/setup/undercloud/tasks/stockos-repo-setup.yml']",2,41cc04ab681565a6d93997b21a32a0187a49e200,bug/1709833,--- - name: run the repo-setup role for custom setting of repo include_role: repo-setup ,,11,0
openstack%2Fkolla~master~I5f55c892b1ae9eba9b6af8a45ef7dfad515c7b05,openstack/kolla,master,I5f55c892b1ae9eba9b6af8a45ef7dfad515c7b05,Add cinderlib RPM to cinder-volume,MERGED,2020-01-17 13:20:45.000000000,2020-01-29 09:46:20.000000000,2020-01-29 09:42:12.000000000,"[{'_account_id': 9535}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23181}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-17 13:20:45.000000000', 'files': ['docker/cinder/cinder-volume/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/a1b74b76977f8300938c6a6a9adf67af6cd50086', 'message': 'Add cinderlib RPM to cinder-volume\n\nFinding the root cause of attach/detach operation on volumes can be very\ncomplicated.\n\nThis patch adds the cinderlib RPM to the cinder-volume container, which\ncan, in many scenarios, really help debug these issues on live nodes\n(controller and compute) without affecting our running services.\n\nChange-Id: I5f55c892b1ae9eba9b6af8a45ef7dfad515c7b05\n'}]",0,703075,a1b74b76977f8300938c6a6a9adf67af6cd50086,17,5,1,9535,,,0,"Add cinderlib RPM to cinder-volume

Finding the root cause of attach/detach operation on volumes can be very
complicated.

This patch adds the cinderlib RPM to the cinder-volume container, which
can, in many scenarios, really help debug these issues on live nodes
(controller and compute) without affecting our running services.

Change-Id: I5f55c892b1ae9eba9b6af8a45ef7dfad515c7b05
",git fetch https://review.opendev.org/openstack/kolla refs/changes/75/703075/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/cinder/cinder-volume/Dockerfile.j2'],1,a1b74b76977f8300938c6a6a9adf67af6cd50086,add-cinderlib," 'python3-cinderlib', 'python2-cinderlib',",,2,0
openstack%2Fkolla~master~I73bbfd31586012e1fd64d30f9ce1d7eb2256d210,openstack/kolla,master,I73bbfd31586012e1fd64d30f9ce1d7eb2256d210,Add error message when merge fails,MERGED,2020-01-24 17:30:09.000000000,2020-01-29 09:44:32.000000000,2020-01-29 09:42:11.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23181}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-24 17:30:09.000000000', 'files': ['docker/base/set_configs.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/2207afc9b9306c19785238f8f02642187f807785', 'message': ""Add error message when merge fails\n\nIf the source cfg directory contains a path (e.g.\n/etc/pki/ca-trust/extracted/) which is also bind mounted into the\ncontainer as read-only, when it attempts to merge the paths together\nthe resulting exception doesn't really indicate what happened.\n\nChange-Id: I73bbfd31586012e1fd64d30f9ce1d7eb2256d210\nRelated-Bug: #1860607\n""}]",0,704178,2207afc9b9306c19785238f8f02642187f807785,10,4,1,14985,,,0,"Add error message when merge fails

If the source cfg directory contains a path (e.g.
/etc/pki/ca-trust/extracted/) which is also bind mounted into the
container as read-only, when it attempts to merge the paths together
the resulting exception doesn't really indicate what happened.

Change-Id: I73bbfd31586012e1fd64d30f9ce1d7eb2256d210
Related-Bug: #1860607
",git fetch https://review.opendev.org/openstack/kolla refs/changes/78/704178/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/base/set_configs.py'],1,2207afc9b9306c19785238f8f02642187f807785,bug/1860607," try: self._merge_directories(source, dest) except OSError: # If a source is tried to merge with a read-only mount, it # may throw an OSError. Because we don't print the source or # dest anywhere, let's catch the exception and log a better # message to help with tracking down the issue. LOG.error('Unable to merge %s with %s', source, dest) raise"," self._merge_directories(source, dest)",9,1
openstack%2Fkolla-ansible~stable%2Ftrain~I988d3c9d0564483440ae17203ad88a8049abbea4,openstack/kolla-ansible,stable/train,I988d3c9d0564483440ae17203ad88a8049abbea4,Enable Glance to use Cinder iSCSI backend,MERGED,2020-01-28 16:11:12.000000000,2020-01-29 09:41:09.000000000,2020-01-29 09:36:49.000000000,"[{'_account_id': 19779}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-28 16:11:12.000000000', 'files': ['ansible/roles/glance/handlers/main.yml', 'ansible/roles/glance/tasks/check-containers.yml', 'releasenotes/notes/glance-fix-iscsi-backend-784aca2c2456333c.yaml', 'ansible/roles/glance/tasks/rolling_upgrade.yml', 'ansible/roles/glance/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/7c60631e0b46b20ea9462912f23a02a78688aa1b', 'message': 'Enable Glance to use Cinder iSCSI backend\n\nTo use an iSCSI Cinder backend as its store, glance_api must run\nprivileged and have /dev and /etc/iscsi properly mounted\n\nCo-authored-by: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\nChange-Id: I988d3c9d0564483440ae17203ad88a8049abbea4\nCloses-Bug: #1855695\n(cherry picked from commit fa49b2692de1b38bfdf47e1468296770d5dfff89)\n'}]",0,704607,7c60631e0b46b20ea9462912f23a02a78688aa1b,8,4,1,14826,,,0,"Enable Glance to use Cinder iSCSI backend

To use an iSCSI Cinder backend as its store, glance_api must run
privileged and have /dev and /etc/iscsi properly mounted

Co-authored-by: Radosaw Piliszek <radoslaw.piliszek@gmail.com>
Change-Id: I988d3c9d0564483440ae17203ad88a8049abbea4
Closes-Bug: #1855695
(cherry picked from commit fa49b2692de1b38bfdf47e1468296770d5dfff89)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/07/704607/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/glance/handlers/main.yml', 'ansible/roles/glance/tasks/check-containers.yml', 'releasenotes/notes/glance-fix-iscsi-backend-784aca2c2456333c.yaml', 'ansible/roles/glance/tasks/rolling_upgrade.yml', 'ansible/roles/glance/defaults/main.yml']",5,7c60631e0b46b20ea9462912f23a02a78688aa1b,bug/1855695-stable/train," privileged: ""{{ enable_cinder | bool and enable_cinder_backend_iscsi | bool }}"" # NOTE(yoctozepto): below to support Cinder iSCSI backends - ""{% if enable_cinder | bool and enable_cinder_backend_iscsi | bool %}iscsi_info:/etc/iscsi{% endif %}"" - ""{% if enable_cinder | bool and enable_cinder_backend_iscsi | bool %}/dev:/dev{% endif %}""",,15,3
openstack%2Fkolla-ansible~stable%2Ftrain~Idef21dc5f7e9ff512bc8920630a3de61a1e69eee,openstack/kolla-ansible,stable/train,Idef21dc5f7e9ff512bc8920630a3de61a1e69eee,External Ceph: copy also cinder keyring to nova services,MERGED,2020-01-28 16:10:44.000000000,2020-01-29 09:39:17.000000000,2020-01-29 09:36:47.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-28 16:10:44.000000000', 'files': ['releasenotes/notes/bug-1859408-external-ceph-cinder-keyring-7df624ac556c100b.yaml', 'ansible/roles/nova-cell/tasks/external_ceph.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a9fecc41a31749c97e89ba6b66c9c46714fa6da8', 'message': 'External Ceph: copy also cinder keyring to nova services\n\nSince [1] nova-compute uses rbd python library instead of libvirt to cleanup\nvolumes and get pool info - so it requires cinder keyring on filesystem.\n\nIn external ceph case it is often that nova key does not exist (is simply a copied\ncinder key) and the rbd user is set to cinder - therefore the earlier mentioned\noperations will fail due to a missing keyring on the filesystem.\n\n[1]: https://review.opendev.org/#/c/668564/\n\nChange-Id: Idef21dc5f7e9ff512bc8920630a3de61a1e69eee\nBackport: train\nCloses-Bug: #1859408\n(cherry picked from commit 71d4c697cdb982d7d8e6cbd95ad870eb08f6914e)\n'}]",0,704606,a9fecc41a31749c97e89ba6b66c9c46714fa6da8,8,3,1,14826,,,0,"External Ceph: copy also cinder keyring to nova services

Since [1] nova-compute uses rbd python library instead of libvirt to cleanup
volumes and get pool info - so it requires cinder keyring on filesystem.

In external ceph case it is often that nova key does not exist (is simply a copied
cinder key) and the rbd user is set to cinder - therefore the earlier mentioned
operations will fail due to a missing keyring on the filesystem.

[1]: https://review.opendev.org/#/c/668564/

Change-Id: Idef21dc5f7e9ff512bc8920630a3de61a1e69eee
Backport: train
Closes-Bug: #1859408
(cherry picked from commit 71d4c697cdb982d7d8e6cbd95ad870eb08f6914e)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/06/704606/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1859408-external-ceph-cinder-keyring-7df624ac556c100b.yaml', 'ansible/roles/nova-cell/tasks/external_ceph.yml']",2,a9fecc41a31749c97e89ba6b66c9c46714fa6da8,bug/1859408-stable/train,"- name: Copy over ceph cinder keyring file copy: src: ""{{ cinder_cephx_keyring_file.stat.path }}"" dest: ""{{ node_config_directory }}/{{ item }}/"" mode: ""0660"" become: true with_items: # NOTE: nova-libvirt does not need it - nova-compute when: - inventory_hostname in groups[nova_cell_compute_group] - nova_backend == ""rbd"" - external_ceph_cephx_enabled | bool notify: - Restart {{ item }} container ",# NOTE: nova-compute and nova-libvirt only need ceph.client.nova.keyring.,22,1
openstack%2Fkolla~master~I8d25ef0fa5f3e5180e89264a371de0efdbd0a819,openstack/kolla,master,I8d25ef0fa5f3e5180e89264a371de0efdbd0a819,"Docs: extend release management with ""static links to docs"" step",MERGED,2020-01-21 19:14:33.000000000,2020-01-29 09:39:12.000000000,2020-01-29 09:36:51.000000000,"[{'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2020-01-21 19:14:33.000000000', 'files': ['doc/source/contributor/release-management.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/0024e3e1641fbadaf55c6a4dff992f18897cfb00', 'message': 'Docs: extend release management with ""static links to docs"" step\n\nChange-Id: I8d25ef0fa5f3e5180e89264a371de0efdbd0a819\n'}]",0,703675,0024e3e1641fbadaf55c6a4dff992f18897cfb00,8,3,1,30491,,,0,"Docs: extend release management with ""static links to docs"" step

Change-Id: I8d25ef0fa5f3e5180e89264a371de0efdbd0a819
",git fetch https://review.opendev.org/openstack/kolla refs/changes/75/703675/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/release-management.rst'],1,0024e3e1641fbadaf55c6a4dff992f18897cfb00,rel-mgmt,* ensure static links to documentation are enabled * https://opendev.org/openstack/openstack-manuals/src/branch/master/www/project-data * example for Train: https://review.opendev.org/#/c/702666/2/www/project-data/train.yaml ,,6,0
openstack%2Fkolla-ansible~stable%2Fstein~I988d3c9d0564483440ae17203ad88a8049abbea4,openstack/kolla-ansible,stable/stein,I988d3c9d0564483440ae17203ad88a8049abbea4,Enable Glance to use Cinder iSCSI backend,MERGED,2020-01-28 16:13:49.000000000,2020-01-29 09:38:40.000000000,2020-01-29 09:36:48.000000000,"[{'_account_id': 19779}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-28 16:13:49.000000000', 'files': ['ansible/roles/glance/handlers/main.yml', 'ansible/roles/glance/tasks/check-containers.yml', 'releasenotes/notes/glance-fix-iscsi-backend-784aca2c2456333c.yaml', 'ansible/roles/glance/tasks/rolling_upgrade.yml', 'ansible/roles/glance/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/be4daa5b4ee968f23083023f4840ac9838391993', 'message': 'Enable Glance to use Cinder iSCSI backend\n\nTo use an iSCSI Cinder backend as its store, glance_api must run\nprivileged and have /dev and /etc/iscsi properly mounted\n\nCo-authored-by: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\nChange-Id: I988d3c9d0564483440ae17203ad88a8049abbea4\nCloses-Bug: #1855695\n(cherry picked from commit fa49b2692de1b38bfdf47e1468296770d5dfff89)\n'}]",0,704608,be4daa5b4ee968f23083023f4840ac9838391993,8,4,1,14826,,,0,"Enable Glance to use Cinder iSCSI backend

To use an iSCSI Cinder backend as its store, glance_api must run
privileged and have /dev and /etc/iscsi properly mounted

Co-authored-by: Radosaw Piliszek <radoslaw.piliszek@gmail.com>
Change-Id: I988d3c9d0564483440ae17203ad88a8049abbea4
Closes-Bug: #1855695
(cherry picked from commit fa49b2692de1b38bfdf47e1468296770d5dfff89)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/08/704608/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/glance/handlers/main.yml', 'ansible/roles/glance/tasks/check-containers.yml', 'releasenotes/notes/glance-fix-iscsi-backend-784aca2c2456333c.yaml', 'ansible/roles/glance/tasks/rolling_upgrade.yml', 'ansible/roles/glance/defaults/main.yml']",5,be4daa5b4ee968f23083023f4840ac9838391993,bug/1855695," privileged: ""{{ enable_cinder | bool and enable_cinder_backend_iscsi | bool }}"" # NOTE(yoctozepto): below to support Cinder iSCSI backends - ""{% if enable_cinder | bool and enable_cinder_backend_iscsi | bool %}iscsi_info:/etc/iscsi{% endif %}"" - ""{% if enable_cinder | bool and enable_cinder_backend_iscsi | bool %}/dev:/dev{% endif %}""",,32,3
openstack%2Ftripleo-quickstart~master~I29835f60eceba5551bafade3e522898f3f7eae31,openstack/tripleo-quickstart,master,I29835f60eceba5551bafade3e522898f3f7eae31,Update min tox version to 2.0,ABANDONED,2018-11-02 04:21:04.000000000,2020-01-29 09:33:19.000000000,,"[{'_account_id': 8367}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 24162}]","[{'number': 1, 'created': '2018-11-02 04:21:04.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/a6af8117718412dae53626e93b1e5e048db4e573', 'message': 'Update min tox version to 2.0\n\nThe commands used by constraints need at least tox 2.0.\nUpdate to reflect reality, which should help with local running of\nconstraints targets.\n\nChange-Id: I29835f60eceba5551bafade3e522898f3f7eae31\n'}]",0,614965,a6af8117718412dae53626e93b1e5e048db4e573,6,4,1,28956,,,0,"Update min tox version to 2.0

The commands used by constraints need at least tox 2.0.
Update to reflect reality, which should help with local running of
constraints targets.

Change-Id: I29835f60eceba5551bafade3e522898f3f7eae31
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/65/614965/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a6af8117718412dae53626e93b1e5e048db4e573,update-tox-version,minversion = 2.0,minversion = 1.6,1,1
openstack%2Ftripleo-quickstart-extras~master~I47a37020d21cfff248f908136ee0d6a43ad8b205,openstack/tripleo-quickstart-extras,master,I47a37020d21cfff248f908136ee0d6a43ad8b205,Fix stackviz installation,ABANDONED,2018-07-05 12:15:03.000000000,2020-01-29 09:32:56.000000000,,"[{'_account_id': 4162}, {'_account_id': 8175}, {'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10459}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 12715}, {'_account_id': 18846}, {'_account_id': 21686}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 24752}, {'_account_id': 27898}]","[{'number': 1, 'created': '2018-07-05 12:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/dcdfb8921f03965e66c8063eb327c8729955f623', 'message': 'Fix stackviz installation\n\nRequirements from stackviz installation via pip are broken, running the\nsetup.py install script seems to work.\n\nChange-Id: I47a37020d21cfff248f908136ee0d6a43ad8b205\nCloses-Bug: 1779562\n'}, {'number': 2, 'created': '2018-07-05 15:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f31c91eadd8f92650cf56f3b866151ef5ba85672', 'message': 'Fix stackviz installation\n\nRequirements from stackviz installation via pip are broken, running the\nsetup.py install script seems to work.\n\nChange-Id: I47a37020d21cfff248f908136ee0d6a43ad8b205\nCloses-Bug: 1779562\n'}, {'number': 3, 'created': '2018-07-05 22:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e26f701860ac1ca6d4a082a589bbae47b9d9ca06', 'message': 'Fix stackviz installation\n\nRequirements from stackviz installation via pip are broken, running the\nsetup.py install script seems to work.\n\nChange-Id: I47a37020d21cfff248f908136ee0d6a43ad8b205\nCloses-Bug: 1779562\n'}, {'number': 4, 'created': '2018-07-10 15:11:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/9a8b3bf833408c84dfc27c5ddfd3a6984b5a9d41', 'message': 'Fix stackviz installation\n\nRequirements from stackviz installation via pip are broken, running the\nsetup.py install script seems to work.\n\nChange-Id: I47a37020d21cfff248f908136ee0d6a43ad8b205\nCloses-Bug: 1779562\n'}, {'number': 5, 'created': '2018-07-11 08:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/27b040bcdd5e59f8459e8d44016a01b666dde10d', 'message': 'Fix stackviz installation\n\nRequirements from stackviz installation via pip are broken, running the\nsetup.py install script seems to work.\n\nChange-Id: I47a37020d21cfff248f908136ee0d6a43ad8b205\nCloses-Bug: 1779562\n'}, {'number': 6, 'created': '2018-07-11 12:12:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/95182e93a1dbc18e012cb0b70bbe853f665b11cc', 'message': 'Fix stackviz installation\n\nInstall stackviz with pip without a venv fails due requirements\nconstraints. This patch install and run stackviz from venv in order to\nfix this.\n\nChange-Id: I47a37020d21cfff248f908136ee0d6a43ad8b205\nCloses-Bug: 1779562\n'}, {'number': 7, 'created': '2018-07-11 15:16:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/7d6ebe1fcb10c452c3c6d31c2da6813f4a9b5791', 'message': 'Fix stackviz installation\n\nInstall stackviz with pip without a venv fails due requirements\nconstraints. This patch install and run stackviz from venv in order to\nfix this.\n\nChange-Id: I47a37020d21cfff248f908136ee0d6a43ad8b205\nCloses-Bug: 1779562\n'}, {'number': 8, 'created': '2018-07-12 08:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/1bbc7b00f91899c9eff122c086b33082de4da29a', 'message': 'Fix stackviz installation\n\nInstall stackviz with pip without a venv fails due requirements\nconstraints. This patch install and run stackviz from venv in order to\nfix this.\n\nChange-Id: I47a37020d21cfff248f908136ee0d6a43ad8b205\nCloses-Bug: 1779562\n'}, {'number': 9, 'created': '2018-07-12 11:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f0bfc5dfe13d540762ee93b11158ca8eb97fd8b3', 'message': 'Fix stackviz installation\n\nInstall stackviz with pip without a venv fails due requirements\nconstraints. This patch install and run stackviz from venv in order to\nfix this.\n\nChange-Id: I47a37020d21cfff248f908136ee0d6a43ad8b205\nCloses-Bug: 1779562\n'}, {'number': 10, 'created': '2018-07-12 18:42:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f1a24b054b6601b849207344f17efb45ddc9c9f4', 'message': 'Fix stackviz installation\n\nInstall stackviz with pip without a venv fails due requirements\nconstraints. This patch install and run stackviz from venv in order to\nfix this.\n\nChange-Id: I47a37020d21cfff248f908136ee0d6a43ad8b205\nCloses-Bug: 1779562\n'}, {'number': 11, 'created': '2018-07-13 09:00:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/7873c27ea061a41b743e8a886d3f76db0b706035', 'message': 'Fix stackviz installation\n\nInstall stackviz with pip without a venv fails due requirements\nconstraints. This patch install and run stackviz from venv in order to\nfix this.\n\nDepends-On: https://review.openstack.org/#/c/582468/\nChange-Id: I47a37020d21cfff248f908136ee0d6a43ad8b205\nCloses-Bug: 1779562\n'}, {'number': 12, 'created': '2018-07-30 10:40:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/9219a6860388b1b08160e24c120b773adf3b8b43', 'message': 'Fix stackviz installation\n\nInstall stackviz with pip without a venv fails due requirements\nconstraints. This patch install and run stackviz from venv in order to\nfix this.\n\nDepends-On: https://review.openstack.org/#/c/582468/\nChange-Id: I47a37020d21cfff248f908136ee0d6a43ad8b205\nCloses-Bug: 1779562\n'}, {'number': 13, 'created': '2018-08-07 17:44:59.000000000', 'files': ['roles/validate-tempest/tasks/pre-tempest.yml', 'roles/validate-tempest/tasks/stackviz.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/6d9e16fb223274339ccf6dc6ca0e9c404a5649a7', 'message': 'Fix stackviz installation\n\nInstall stackviz with pip without a venv fails due requirements\nconstraints. This patch install and run stackviz from venv in order to\nfix this.\n\nDepends-On: https://review.openstack.org/#/c/582468/\nChange-Id: I47a37020d21cfff248f908136ee0d6a43ad8b205\nCloses-Bug: 1779562\n'}]",3,580361,6d9e16fb223274339ccf6dc6ca0e9c404a5649a7,92,18,13,8367,,,0,"Fix stackviz installation

Install stackviz with pip without a venv fails due requirements
constraints. This patch install and run stackviz from venv in order to
fix this.

Depends-On: https://review.openstack.org/#/c/582468/
Change-Id: I47a37020d21cfff248f908136ee0d6a43ad8b205
Closes-Bug: 1779562
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/61/580361/11 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/tasks/stackviz.yml'],1,dcdfb8921f03965e66c8063eb327c8729955f623,bug/1779562," command: ""python setup.py install"" args:","- name: Install pip easy_install: name: pip state: present become: true pip: name: "".""",2,8
openstack%2Ftempest~master~If3ff71dbe636ef98072b15f6599e6e641c222f30,openstack/tempest,master,If3ff71dbe636ef98072b15f6599e6e641c222f30,Define python3 as basepython for Tempest tox env,MERGED,2020-01-17 03:55:31.000000000,2020-01-29 09:31:15.000000000,2020-01-28 05:09:12.000000000,"[{'_account_id': 1131}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 8367}, {'_account_id': 8556}, {'_account_id': 16688}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 23186}, {'_account_id': 30491}, {'_account_id': 31239}]","[{'number': 1, 'created': '2020-01-17 03:55:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9f24bd0a63b11cd6250ec94c9473167442ae6b9e', 'message': 'Install Tempest & plugins always on py3\n\nChange-Id: If3ff71dbe636ef98072b15f6599e6e641c222f30\n'}, {'number': 2, 'created': '2020-01-20 18:00:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4bfc78f410707e9e78c51b6a3327ce0fc90e2534', 'message': ""Define python3 as basepython for Tempest tox env\n\nWhile OpenStack is in transition to drop py2, many\nlib or dependency of Tempest or its plugins cannot\nbe installed on python 2.7.\n\nTo install Tempest on py3 evnv, let's change the basepython\nas python 3 for tox env.\n\nDefining venv-tempest basepython as 3.6 where dependency\nneeds py3.6 or above requirement like stable branch testing\nwith master Tempest & plugins.\n\nCloses-Bug: 1860033\nChange-Id: If3ff71dbe636ef98072b15f6599e6e641c222f30\n""}, {'number': 3, 'created': '2020-01-20 18:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e3e9fcef0335b46dbb2e1a6a63d69589511accc0', 'message': ""Define python3 as basepython for Tempest tox env\n\nWhile OpenStack is in transition to drop py2, many\nlib or dependency of Tempest or its plugins cannot\nbe installed on python 2.7.\n\nTo install Tempest on py3 evnv, let's change the basepython\nas python 3 for tox env.\n\nDefining venv-tempest basepython as 3.6 where dependency\nneeds py3.6 or above requirement like stable branch testing\nwith master Tempest & plugins.\n\nCloses-Bug: 1860033\nChange-Id: If3ff71dbe636ef98072b15f6599e6e641c222f30\n""}, {'number': 4, 'created': '2020-01-21 15:29:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/073504221d250b2b79dad3b84ea63c36ccbda1ab', 'message': ""Define python3 as basepython for Tempest tox env\n\nWhile OpenStack is in transition to drop py2, many\nlib or dependency of Tempest or its plugins cannot\nbe installed on python 2.7.\n\nTo install Tempest on py3 evnv, let's change the basepython\nas python 3 for tox env.\n\nDefining venv-tempest basepython as 3.6 where dependency\nneeds py3.6 or above requirement like stable branch testing\nwith master Tempest & plugins.\n\nDepends-On: https://review.opendev.org/#/c/703476/\nCloses-Bug: 1860033\nChange-Id: If3ff71dbe636ef98072b15f6599e6e641c222f30\n""}, {'number': 5, 'created': '2020-01-21 23:39:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/39e51f64c8470bb1c3eb0df1ffeaa27aae221aae', 'message': ""Define python3 as basepython for Tempest tox env\n\nWhile OpenStack is in transition to drop py2, many\nlib or dependency of Tempest or its plugins cannot\nbe installed on python 2.7.\n\nTo install Tempest on py3 evnv, let's change the basepython\nas python 3 for tox env.\n\nDefining venv-tempest basepython as 3.6 where dependency\nneeds py3.6 or above requirement like stable branch testing\nwith master Tempest & plugins.\n\nDepends-On: https://review.opendev.org/#/c/703476/\nDepends-On: https://review.opendev.org/#/c/703679/\n\nCloses-Bug: 1860033\nChange-Id: If3ff71dbe636ef98072b15f6599e6e641c222f30\n""}, {'number': 6, 'created': '2020-01-23 20:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/dce39bdef1d1c2949acd480c49b6efd4ba373343', 'message': ""Define python3 as basepython for Tempest tox env\n\nWhile OpenStack is in transition to drop py2, many\nlib or dependency of Tempest or its plugins cannot\nbe installed on python 2.7.\n\nTo install Tempest on py3 evnv, let's change the basepython\nas python 3 for tox env.\n\nDefining basepython as python3.6 for all venv using\n.tox/tempest.\n\nDepends-On: https://review.opendev.org/#/c/703476/\nDepends-On: https://review.opendev.org/#/c/703679/\n\nCloses-Bug: 1860033\nChange-Id: If3ff71dbe636ef98072b15f6599e6e641c222f30\n""}, {'number': 7, 'created': '2020-01-23 20:49:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/51a4a6be65d3f53919bdce51b613b00868632491', 'message': ""Define python3 as basepython for Tempest tox env\n\nWhile OpenStack is in transition to drop py2, many\nlib or dependency of Tempest or its plugins cannot\nbe installed on python 2.7.\n\nTo install Tempest on py3 evnv, let's change the basepython\nas python 3 for tox env.\n\nDefining basepython as python3.6 for all venv using\n.tox/tempest.\n\nDepends-On: https://review.opendev.org/#/c/703476/\nDepends-On: https://review.opendev.org/#/c/703679/\n\nCloses-Bug: 1860033\nChange-Id: If3ff71dbe636ef98072b15f6599e6e641c222f30\n""}, {'number': 8, 'created': '2020-01-24 08:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/363b78e0d20f86fc72ac0b870e86b89c5c9a9278', 'message': ""Define python3 as basepython for Tempest tox env\n\nWhile OpenStack is in transition to drop py2, many\nlib or dependency of Tempest or its plugins cannot\nbe installed on python 2.7.\n\nTo install Tempest in py3 venv, let's change the basepython\nto python 3 for tox env.\n\nDefining basepython as python3.6 for all venv using\n.tox/tempest.\n\nDepends-On: https://review.opendev.org/#/c/703476/\nDepends-On: https://review.opendev.org/#/c/703679/\n\nCloses-Bug: 1860033\nChange-Id: If3ff71dbe636ef98072b15f6599e6e641c222f30\n""}, {'number': 9, 'created': '2020-01-24 14:34:10.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1c680fdb728c24a4c9a1507ad8319f0a505cef9c', 'message': ""Define python3 as basepython for Tempest tox env\n\nWhile OpenStack is in transition to drop py2, many\nlib or dependency of Tempest or its plugins cannot\nbe installed on python 2.7.\n\nTo install Tempest on py3 evnv, let's change the basepython\nas python 3 for tox env.\n\nDefining basepython as python3.6 for all venv using\n.tox/tempest.\n\nDepends-On: https://review.opendev.org/#/c/703476/\nDepends-On: https://review.opendev.org/#/c/703679/\n\nCloses-Bug: 1860033\nChange-Id: If3ff71dbe636ef98072b15f6599e6e641c222f30\n""}]",12,703011,1c680fdb728c24a4c9a1507ad8319f0a505cef9c,70,11,9,8556,,,0,"Define python3 as basepython for Tempest tox env

While OpenStack is in transition to drop py2, many
lib or dependency of Tempest or its plugins cannot
be installed on python 2.7.

To install Tempest on py3 evnv, let's change the basepython
as python 3 for tox env.

Defining basepython as python3.6 for all venv using
.tox/tempest.

Depends-On: https://review.opendev.org/#/c/703476/
Depends-On: https://review.opendev.org/#/c/703679/

Closes-Bug: 1860033
Change-Id: If3ff71dbe636ef98072b15f6599e6e641c222f30
",git fetch https://review.opendev.org/openstack/tempest refs/changes/11/703011/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,9f24bd0a63b11cd6250ec94c9473167442ae6b9e,bug/1860033,basepython = python3,,1,0
openstack%2Fnova-specs~master~Ib125c9de60ac614b4b8cb3ad0f03a4141efd0d2a,openstack/nova-specs,master,Ib125c9de60ac614b4b8cb3ad0f03a4141efd0d2a,Re-proposes multiple vGPU types in libvirt,MERGED,2020-01-16 18:01:59.000000000,2020-01-29 09:30:37.000000000,2020-01-27 14:11:44.000000000,"[{'_account_id': 9708}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 18:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7cae268c6b4c4531004ab3b53d8b161be100314a', 'message': 'Re-proposes multiple vGPU types in libvirt\n\nThis spec is for telling libvirt how to manage multiple vGPU types.\nThe only modification to the approved spec in Stein is to mention\nanother alternative and no longer mention upgrades since GPUs are\nalready modeled as children RPs.\n\nChange-Id: Ib125c9de60ac614b4b8cb3ad0f03a4141efd0d2a\nPartially-Implements: bp/vgpu-multiple-types\nPreviously-Approved: Stein\n'}, {'number': 2, 'created': '2020-01-27 10:38:48.000000000', 'files': ['specs/ussuri/approved/vgpu-multiple-types.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/dee2ff3afd344cbab9689b95e79324f3bd69f152', 'message': 'Re-proposes multiple vGPU types in libvirt\n\nThis spec is for telling libvirt how to manage multiple vGPU types.\nThe only modification to the approved spec in Stein is to mention\nanother alternative and no longer mention upgrades since GPUs are\nalready modeled as children RPs.\n\nChange-Id: Ib125c9de60ac614b4b8cb3ad0f03a4141efd0d2a\nPartially-Implements: bp/vgpu-multiple-types\nPreviously-Approved: Stein\n'}]",20,702943,dee2ff3afd344cbab9689b95e79324f3bd69f152,12,3,2,7166,,,0,"Re-proposes multiple vGPU types in libvirt

This spec is for telling libvirt how to manage multiple vGPU types.
The only modification to the approved spec in Stein is to mention
another alternative and no longer mention upgrades since GPUs are
already modeled as children RPs.

Change-Id: Ib125c9de60ac614b4b8cb3ad0f03a4141efd0d2a
Partially-Implements: bp/vgpu-multiple-types
Previously-Approved: Stein
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/43/702943/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/ussuri/approved/vgpu-multiple-types.rst'],1,7cae268c6b4c4531004ab3b53d8b161be100314a,bp/vgpu-multiple-types,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================================= libvirt: Supporting multiple vGPU types for a single pGPU ========================================================= https://blueprints.launchpad.net/nova/+spec/vgpu-multiple-types `Virtual GPUs in Nova`_ was implemented in Queens but only with one supported GPU type per compute node. Now that GPUs are created as `Nested Resource Providers`_ this spec is only targeting about how to expose some operator choice for telling which GPU type should be set per GPU. .. note:: As Xen provides a specific feature where physical GPUs supporting same vGPU type are within a single pGPU group, that virt driver doesn't need to know which exact pGPUs need to support a specific type, hence this spec only targets the libvirt driver. .. _`Virtual GPUs in Nova`: https://specs.openstack.org/openstack/nova-specs/specs/queens/implemented/add-support-for-vgpu.html .. _`Nested Resource Providers`: https://specs.openstack.org/openstack/nova-specs/specs/queens/approved/nested-resource-providers.html Problem description =================== Hardware vendors tell us that a physical GPU device can support multiple types. That said, Intel (to be confirmed) and NVidia vendor drivers only accept one type for all the virtual devices *per graphical processing unit*. For example, NVidia GRID physical cards can accept a list of different GPU types, but the driver can only support `one type per physical GPU`_. .. figure:: http://docs.nvidia.com/grid/5.0/grid-vgpu-user-guide/graphics/sample-vgpu-configurations-grid-2gpus-on-card.png .. _`one type per physical GPU`: http://docs.nvidia.com/grid/5.0/grid-vgpu-user-guide/index.html#homogeneous-grid-vgpus Consequently, we require a way to instruct the libvirt driver which vGPU types an NVIDIA or Intel physical GPU is configured to accept. Use Cases --------- An operator needs a way to inform the libvirt driver which vGPU types an NVIDIA or Intel physical GPU is configured to accept. Proposed change =============== We already have ``[devices]/enabled_vgpu_types`` that define which types the Nova compute node can use: .. code:: [devices] enabled_vgpu_types = [str_vgpu_type_1, str_vgpu_type_2, ...] Now we propose that libvirt will accept configuration sections that are related to the [devices]/enabled_vgpu_types and specifies which exact pGPUs are related to the enabled vGPU types and will have a ``device_addresses`` option defined like this: .. code:: cfg.ListOpt('device_addresses', default=[], help="""""" List of physical PCI addresses to associate with a specific GPU type. The particular physical GPU device address needs to be mapped to the vendor vGPU type which that physical GPU is configured to accept. In order to provide this mapping, there will be a CONF section with a name corresponding to the following template: ""vgpu_type_%(vgpu_type_name)s The vGPU type to associate with the PCI devices has to be the section name prefixed by ``vgpu_``. For example, for 'nvidia-11', you would declare ``[vgpu_nvidia-11]/device_addresses``. Each vGPU type also has to be declared in ``[devices]/enabled_vgpu_types``. Related options: * ``[devices]/enabled_vgpu_types`` """"""), For example, it would be set in nova.conf: .. code:: [devices] enabled_vgpu_types = nvidia-35,nvidia-36 [vgpu_nvidia-35] device_addresses = 0000:84:00.0,0000:85:00.0 [vgpu_nvidia-36] device_addresses = 0000:86:00.0 In that case, the ``nvidia-35`` vGPU type would be supported by the physical GPUs that are in the PCI addresses ``0000:84:00.0`` and ``0000:85:00.0``, while ``nvidia-36`` vGPU would only be supported by ``0000:86:00.0``. If some operator messes up and provides two types for the same pGPU, an InvalidLibvirtGPUConfig exception will be raised. If the operator forgets to provide a type for a specific pGPU, then the first type given in ``enabled_vgpu_types`` will be supported, like the existing situation. If the operator fat-fingers the PCI IDs, then when creating the inventory, it will return an exception. As one single compute could now support multiple vGPU types, asking operators to provide host aggregates for grouping computes having the same vGPU type becomes irrelevant. Instead, we need to ask operators to amend their flavors for specific GPU capabilities if they care of such things, or Placement will just randomly pick one of the available vGPU types. For this, we propose to standardize GPU capabilities that are unfortunately very vendor specific (eg. a CUDA library version support) by having a nova.virt.vgpu_capabilities module that would translate a vendor-specific vGPU type into a set of os-traits traits. If operators want vendor-specific traits, it's their responsibility to provide custom traits on the resource providers or ask the community to find a standard trait that would fit their needs. Alternatives ------------ We could ask the operators to provide those details into a `Provider Configuration File`_ by adding some additional information that would be libvirt-specific and telling which GPU type to use for a specific Resource Provider. That said, this would imply us to amend the YAML schema by allowing some extra random parameter to be available which would be libvirt-specific and would defeat the purpose of the Provider Configuration File to be as much generic as possible. It's also worth saying that a GPU type is *not* a trait, as it defines quantitative amount of virtual resources to allocate for a matching physical GPU. .. _`Provider Configuration File`: https://specs.openstack.org/openstack/nova-specs/specs/ussuri/approved/provider-config-file.html Data model impact ----------------- None REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ None. Other deployer impact --------------------- Operators need to either look at the sysfs (for libvirt) for knowing the existing pGPUs and which types are supported. Developer impact ---------------- None. Upgrade impact -------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: bauzas Other contributors: None Feature Liaison --------------- None Work Items ---------- * Create the config option * Modify the libvirt virt driver code to make use of that option for creating the nested Resource Provider inventories. Dependencies ============ None. Testing ======= Classic unittests and functional tests. Documentation Impact ==================== A release note will be added with a 'feature' section, and the `Virtual GPU`_ documentation will be modified to explain the new feature. .. _`Virtual GPU`: https://docs.openstack.org/nova/latest/admin/virtual-gpu.html References ========== None. History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Rocky - Approved * - Stein - Reproposed * - Ussuri - Reproposed ",,250,0
openstack%2Ftripleo-quickstart~master~I0ea3adb80212793e49474a8c49f8b9b055395379,openstack/tripleo-quickstart,master,I0ea3adb80212793e49474a8c49f8b9b055395379,iptables and queens,ABANDONED,2019-10-30 17:25:36.000000000,2020-01-29 09:28:19.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-30 17:25:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/e84271d99bacd1658c8950d642213f1c9a3cbd04', 'message': 'WIP: iptables and queens\n\nChange-Id: I0ea3adb80212793e49474a8c49f8b9b055395379\n'}, {'number': 2, 'created': '2019-10-30 17:56:57.000000000', 'files': ['config/release/tripleo-ci/CentOS-7/queens.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/55fddee326cfdd6e97c5377f1aafe4386e864e25', 'message': 'iptables and queens\n\ndisable docker iptables for queens.\nIn CI the docker login in zuul playbooks\nbreaks the overcloud deployment\nhttps://bugs.launchpad.net/tripleo/+bug/1845166/\n\nCustomers should not hit this issue.\n\nCloses-Bug: #1845166\nChange-Id: I0ea3adb80212793e49474a8c49f8b9b055395379\n'}]",0,692196,55fddee326cfdd6e97c5377f1aafe4386e864e25,6,2,2,24162,,,0,"iptables and queens

disable docker iptables for queens.
In CI the docker login in zuul playbooks
breaks the overcloud deployment
https://bugs.launchpad.net/tripleo/+bug/1845166/

Customers should not hit this issue.

Closes-Bug: #1845166
Change-Id: I0ea3adb80212793e49474a8c49f8b9b055395379
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/96/692196/1 && git format-patch -1 --stdout FETCH_HEAD,['config/release/tripleo-ci/CentOS-7/queens.yml'],1,e84271d99bacd1658c8950d642213f1c9a3cbd04,queens-docker-iptables,# Workaround regression cause by initial fix of: # https://bugs.launchpad.net/tripleo/+bug/1845166/ container_registry_docker_disable_iptables: true ,,4,0
openstack%2Ftripleo-puppet-elements~master~I56f2965d02bd12c146d501f211fff3508f9689dd,openstack/tripleo-puppet-elements,master,I56f2965d02bd12c146d501f211fff3508f9689dd,"Revert ""Remove libvirt package""",ABANDONED,2020-01-29 08:56:14.000000000,2020-01-29 09:28:07.000000000,,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 30133}]","[{'number': 1, 'created': '2020-01-29 08:56:14.000000000', 'files': ['elements/overcloud-compute/post-install.d/51-remove-libvirt-default-net', 'elements/overcloud-compute/pkg-map', 'elements/overcloud-controller/post-install.d/51-disable-libvirtd-service', 'elements/overcloud-compute/install.d/package-installs-overcloud-compute', 'releasenotes/notes/remove-libvirt-deps-8994d3d325af0765.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/ee12b62d7b86c93e996392f40b8e88d2f455828e', 'message': 'Revert ""Remove libvirt package""\n\nThis reverts commit 359bc74c7602b27a803039557c9c5767e2bf0df6.\n\nChange-Id: I56f2965d02bd12c146d501f211fff3508f9689dd\nRelated-Bug: #1860971\n'}]",0,704748,ee12b62d7b86c93e996392f40b8e88d2f455828e,4,8,1,12393,,,0,"Revert ""Remove libvirt package""

This reverts commit 359bc74c7602b27a803039557c9c5767e2bf0df6.

Change-Id: I56f2965d02bd12c146d501f211fff3508f9689dd
Related-Bug: #1860971
",git fetch https://review.opendev.org/openstack/tripleo-puppet-elements refs/changes/48/704748/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/overcloud-compute/post-install.d/51-remove-libvirt-default-net', 'elements/overcloud-compute/pkg-map', 'elements/overcloud-controller/post-install.d/51-disable-libvirtd-service', 'elements/overcloud-compute/install.d/package-installs-overcloud-compute', 'releasenotes/notes/remove-libvirt-deps-8994d3d325af0765.yaml']",5,ee12b62d7b86c93e996392f40b8e88d2f455828e,remove-libvirt-deps,,--- other: - | Nova services are now running in the containers but we have still a lot of libvirt packages installed on Overcloud systems. This change remove unnecessary libvirt packages. ,15,6
openstack%2Ftripleo-ci~master~Iadb2c6af4754e400cb2a85c9652db267484711a2,openstack/tripleo-ci,master,Iadb2c6af4754e400cb2a85c9652db267484711a2,Make tripleo-tox-molecule use centos-8 nodes,ABANDONED,2019-10-11 11:24:47.000000000,2020-01-29 09:27:56.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2019-10-11 11:24:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/349586989f494788981d809e0a9184613ec84883', 'message': 'POC: Forces molecule to use centos-8 nodes\n\nExperiment for testing if we can use molecule jobs with centos-8 based\nnodes.\n\nChange-Id: Iadb2c6af4754e400cb2a85c9652db267484711a2\n'}, {'number': 2, 'created': '2019-10-11 13:02:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2e0dca21ced8026a6662ddc86b753e265c3eb3b5', 'message': 'POC: Forces molecule to use centos-8 nodes\n\nExperiment for testing if we can use molecule jobs with centos-8 based\nnodes.\n\nChange-Id: Iadb2c6af4754e400cb2a85c9652db267484711a2\nDepends-On: https://review.opendev.org/#/c/688118/\n'}, {'number': 3, 'created': '2019-10-17 11:06:42.000000000', 'files': ['zuul.d/base.yaml', 'zuul.d/nodesets.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/4c515613805d7e0d2e19d2aad8050d91b12bc8f7', 'message': 'Make tripleo-tox-molecule use centos-8 nodes\n\nUse molecule jobs with centos-8 based nodes as these do have newer\ndocker versions.\n\nChange-Id: Iadb2c6af4754e400cb2a85c9652db267484711a2\n'}]",0,688106,4c515613805d7e0d2e19d2aad8050d91b12bc8f7,12,3,3,24162,,,0,"Make tripleo-tox-molecule use centos-8 nodes

Use molecule jobs with centos-8 based nodes as these do have newer
docker versions.

Change-Id: Iadb2c6af4754e400cb2a85c9652db267484711a2
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/06/688106/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/base.yaml', 'zuul.d/nodesets.yaml']",2,349586989f494788981d809e0a9184613ec84883,, name: single-centos-8-node nodes: - name: primary label: centos-8 groups: - name: switch nodes: - primary - name: peers nodes: [] - nodeset:,,13,0
openstack%2Ftripleo-common~master~I854b7b5adda8486fddf389c4e2cfb67d521f06ad,openstack/tripleo-common,master,I854b7b5adda8486fddf389c4e2cfb67d521f06ad,DNM: test bleading edge molecule dependencies,ABANDONED,2019-07-03 09:38:28.000000000,2020-01-29 09:27:19.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-07-03 09:38:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7847b58287048527b9505cd0a15625d7631764ae', 'message': 'DNM: test bleading edge molecule dependencies\n\nThis change is used to verify that the unreleased code of molecule and\nits major dependencies does not break our jobs.\n\nThis is not supposed to be merged, only to be used for testing upcoming\nreleases of these packages.\n\nChange-Id: I854b7b5adda8486fddf389c4e2cfb67d521f06ad\n'}, {'number': 2, 'created': '2019-08-12 15:00:52.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/89dc3ed3aa43d8a0df443a4a9618cfae524ea0d9', 'message': 'DNM: test bleading edge molecule dependencies\n\nThis change is used to verify that the unreleased code of molecule and\nits major dependencies does not break our jobs.\n\nThis is not supposed to be merged, only to be used for testing upcoming\nreleases of these packages.\n\nChange-Id: I854b7b5adda8486fddf389c4e2cfb67d521f06ad\n'}]",0,668847,89dc3ed3aa43d8a0df443a4a9618cfae524ea0d9,5,1,2,24162,,,0,"DNM: test bleading edge molecule dependencies

This change is used to verify that the unreleased code of molecule and
its major dependencies does not break our jobs.

This is not supposed to be merged, only to be used for testing upcoming
releases of these packages.

Change-Id: I854b7b5adda8486fddf389c4e2cfb67d521f06ad
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/47/668847/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,7847b58287048527b9505cd0a15625d7631764ae,fix/molecule-risk," -e git://github.com/docker/docker-py.git#egg=docker[tls,ssh] -e git://github.com/pycontribs/selinux.git#egg=selinux -e git://github.com/ansible/molecule.git#egg=molecule -e git://github.com/pycontribs/pytest-molecule.git#egg=pytest-molecule", docker>=3.7 molecule>=2.22rc3 pytest-molecule>=1.0rc1 selinux,5,4
openstack%2Fdiskimage-builder~master~I4e088dd91ff7644c083e6c96ac28c201e00ecb0d,openstack/diskimage-builder,master,I4e088dd91ff7644c083e6c96ac28c201e00ecb0d,Bypass pip-and-virtualenv for later redhat distros,ABANDONED,2019-05-01 14:34:26.000000000,2020-01-29 09:26:57.000000000,,"[{'_account_id': 4146}, {'_account_id': 4162}, {'_account_id': 7118}, {'_account_id': 9311}, {'_account_id': 10118}, {'_account_id': 13294}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 28743}]","[{'number': 1, 'created': '2019-05-01 14:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f33ebc42701344821346a035d1ba51bc593794c9', 'message': 'Bypass pip-and-virtualenv for later redhat distros\n\nWe just use the packaged versions and avoid overriding any rpms.\n\nThis ensures that the builder images are not tainted in a way that would\nmake them considered unsupported.\n\nAllows us to use them for testing real-life use-scenarios.\n\nChange-Id: I4e088dd91ff7644c083e6c96ac28c201e00ecb0d\nFixes-Bug: https://bugs.launchpad.net/tripleo/+bug/1826452\n'}, {'number': 2, 'created': '2019-05-06 12:48:13.000000000', 'files': ['diskimage_builder/elements/pip-and-virtualenv/install.d/pip-and-virtualenv-source-install/04-install-pip'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ff0b8bcc4c04bf3603a5b142d25af11bb6e94a6c', 'message': 'Bypass pip-and-virtualenv for later redhat distros\n\nWe just use the packaged versions and avoid overriding any rpms.\n\nThis ensures that the builder images are not tainted in a way that would\nmake them considered unsupported.\n\nAllows us to use them for testing real-life use-scenarios.\n\nChange-Id: I4e088dd91ff7644c083e6c96ac28c201e00ecb0d\nFixes-Bug: https://bugs.launchpad.net/tripleo/+bug/1826452\n'}]",0,656636,ff0b8bcc4c04bf3603a5b142d25af11bb6e94a6c,18,10,2,24162,,,0,"Bypass pip-and-virtualenv for later redhat distros

We just use the packaged versions and avoid overriding any rpms.

This ensures that the builder images are not tainted in a way that would
make them considered unsupported.

Allows us to use them for testing real-life use-scenarios.

Change-Id: I4e088dd91ff7644c083e6c96ac28c201e00ecb0d
Fixes-Bug: https://bugs.launchpad.net/tripleo/+bug/1826452
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/36/656636/1 && git format-patch -1 --stdout FETCH_HEAD,['diskimage_builder/elements/pip-and-virtualenv/install.d/pip-and-virtualenv-source-install/04-install-pip'],1,f33ebc42701344821346a035d1ba51bc593794c9,fix/virtualenv-redhat," # Shortcut for later distros; just use inbuilt packages without doing any # extra operation. This assures that testing is done using a supported # operating system setup instead of tainted one. Remarcable facts: # fedora-28: python2-virtualenv -> /usr/bin/virtualenv # python3-virtualenv -> /usr/bin/virtualenv-3 # fedora-29: python3-virtualenv -> /usr/vin/virtualenv if [[ $DISTRO_NAME =~ (fedora|rhel) ]]; then # validate virtualenv availability if [[ $_do_py3 -eq 1 ]]; then venv_cmd=$(command -v virtualenv-3 virtualenv | head -n1) if [ ""$(python3 -m virtualenv --version)"" != ""$($venv_cmd --version)"" ]; then die ""virtualenv under python3 is broken"" fi fi exit 0 fi ",,17,0
openstack%2Fdevstack~master~Ic4e8cb2569b3dd3562c737fa166fc8d521db1bfa,openstack/devstack,master,Ic4e8cb2569b3dd3562c737fa166fc8d521db1bfa,tempest: Install python36 on Fedora,ABANDONED,2020-01-29 09:11:44.000000000,2020-01-29 09:23:22.000000000,,[],"[{'number': 1, 'created': '2020-01-29 09:11:44.000000000', 'files': ['files/rpms/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/83aff07486e8d2f35f1493787dc37ab9e5f1b1cf', 'message': 'tempest: Install python36 on Fedora\n\nIf3ff71dbe636ef98072b15f6599e6e641c222f30 has switched the basepython\nversion of tempestenv to python3.6. This breaks the installation of\nTempest on Fedora where only python3.7 is provided by default. To\nworkaround this for now we can install the python36 package alongside\npython37, this should obviously be removed when Tempest moves past\npython3.6.\n\nCloses-Bug: #1861263\nChange-Id: Ic4e8cb2569b3dd3562c737fa166fc8d521db1bfa\n'}]",0,704753,83aff07486e8d2f35f1493787dc37ab9e5f1b1cf,2,0,1,10135,,,0,"tempest: Install python36 on Fedora

If3ff71dbe636ef98072b15f6599e6e641c222f30 has switched the basepython
version of tempestenv to python3.6. This breaks the installation of
Tempest on Fedora where only python3.7 is provided by default. To
workaround this for now we can install the python36 package alongside
python37, this should obviously be removed when Tempest moves past
python3.6.

Closes-Bug: #1861263
Change-Id: Ic4e8cb2569b3dd3562c737fa166fc8d521db1bfa
",git fetch https://review.opendev.org/openstack/devstack refs/changes/53/704753/1 && git format-patch -1 --stdout FETCH_HEAD,['files/rpms/tempest'],1,83aff07486e8d2f35f1493787dc37ab9e5f1b1cf,,"python36 # dist:f29,f30,f31 ",,1,0
openstack%2Fnova~stable%2Frocky~I5a0e805fe04c00c5e7cf316f0ea8d432b940e560,openstack/nova,stable/rocky,I5a0e805fe04c00c5e7cf316f0ea8d432b940e560,Add support for osprofiler in placement wsgi,ABANDONED,2019-06-27 09:48:57.000000000,2020-01-29 09:22:48.000000000,,"[{'_account_id': 6873}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-06-27 09:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3949ee947dd0c188889e8f4208add962243ff20b', 'message': 'Add support for osprofiler in placement wsgi\n\nThis patch is backport of the placement fix [1] from stein (and master).\n\n[1] https://review.opendev.org/#/c/667647\n\nCloses-Bug: #1834450\n\nChange-Id: I5a0e805fe04c00c5e7cf316f0ea8d432b940e560\n'}, {'number': 2, 'created': '2019-07-09 08:59:40.000000000', 'files': ['nova/api/openstack/placement/wsgi.py', 'releasenotes/notes/fix-osprofiler-support-78b34a92c32fd30f.yaml', 'nova/api/openstack/placement/deploy.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/04bc27f9575bdbb43347ebab135269126e5ac8ee', 'message': 'Add support for osprofiler in placement wsgi\n\nThis patch is backport of the placement fix [1] from stein (and master).\n\n[1] https://review.opendev.org/#/c/667647\n\nCloses-Bug: #1834450\n\nChange-Id: I5a0e805fe04c00c5e7cf316f0ea8d432b940e560\n'}]",6,667832,04bc27f9575bdbb43347ebab135269126e5ac8ee,31,9,2,9708,,,0,"Add support for osprofiler in placement wsgi

This patch is backport of the placement fix [1] from stein (and master).

[1] https://review.opendev.org/#/c/667647

Closes-Bug: #1834450

Change-Id: I5a0e805fe04c00c5e7cf316f0ea8d432b940e560
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/667832/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/placement/wsgi.py', 'nova/api/openstack/placement/deploy.py']",2,3949ee947dd0c188889e8f4208add962243ff20b,bug/1834450,"from oslo_utils import importutilsos_profiler = importutils.try_import('osprofiler.profiler') os_profiler_web = importutils.try_import('osprofiler.web') if os_profiler_web and 'profiler' in conf and conf.profiler.enabled: osprofiler_middleware = os_profiler_web.WsgiMiddleware.factory( {}, **conf.profiler) else: osprofiler_middleware = None osprofiler_middleware",,25,0
openstack%2Fkolla-ansible~stable%2Ftrain~I501d02cfd40fbacea32d551c3912640c5661d821,openstack/kolla-ansible,stable/train,I501d02cfd40fbacea32d551c3912640c5661d821,Allow ironic_ipxe to serve instance images,MERGED,2020-01-28 16:06:49.000000000,2020-01-29 09:21:39.000000000,2020-01-29 09:17:44.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-28 16:06:49.000000000', 'files': ['releasenotes/notes/ironic-ipxe-instance-image-47fb3c9f0edef5f5.yaml', 'ansible/roles/ironic/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/07031e38f5971c5e012dd11be8dc7c9c574c5f97', 'message': 'Allow ironic_ipxe to serve instance images\n\nIronic provides a feature to allow instance images to be served from a\nlocal HTTP server [1]. This is the same server used for PXE images with\niPXE. This does not work currently because the ironic_ipxe container\ndoes not have access to /var/lib/ironic/images (ironic docker volume),\nwhere the images are cached. Note that to make use of this feature, the\nfollowing is required in ironic.conf:\n\n[agent]\nimage_download_source = http\n\nThis change fixes the issue by giving ironic_ipxe container access to\nthe ironic volume.\n\n[1] https://docs.openstack.org/ironic/latest/admin/interfaces/deploy.html#deploy-with-custom-http-servers\n\nChange-Id: I501d02cfd40fbacea32d551c3912640c5661d821\nCloses-Bug: #1856194\n(cherry picked from commit 2b662cfb127c9abc4930c498d7f9957a8065f5ce)\n'}]",0,704605,07031e38f5971c5e012dd11be8dc7c9c574c5f97,8,3,1,14826,,,0,"Allow ironic_ipxe to serve instance images

Ironic provides a feature to allow instance images to be served from a
local HTTP server [1]. This is the same server used for PXE images with
iPXE. This does not work currently because the ironic_ipxe container
does not have access to /var/lib/ironic/images (ironic docker volume),
where the images are cached. Note that to make use of this feature, the
following is required in ironic.conf:

[agent]
image_download_source = http

This change fixes the issue by giving ironic_ipxe container access to
the ironic volume.

[1] https://docs.openstack.org/ironic/latest/admin/interfaces/deploy.html#deploy-with-custom-http-servers

Change-Id: I501d02cfd40fbacea32d551c3912640c5661d821
Closes-Bug: #1856194
(cherry picked from commit 2b662cfb127c9abc4930c498d7f9957a8065f5ce)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/05/704605/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/ironic-ipxe-instance-image-47fb3c9f0edef5f5.yaml', 'ansible/roles/ironic/defaults/main.yml']",2,07031e38f5971c5e012dd11be8dc7c9c574c5f97,bug/1856194-stable/train," - ""ironic:/var/lib/ironic:ro""",,7,0
openstack%2Fkolla-ansible~stable%2Ftrain~Ia02f83dfaaba53f95e373b2b2be3f74cfb7ae578,openstack/kolla-ansible,stable/train,Ia02f83dfaaba53f95e373b2b2be3f74cfb7ae578,Add also_notifies to Infoblox backend for Designate,MERGED,2020-01-28 16:03:28.000000000,2020-01-29 09:19:44.000000000,2020-01-29 09:17:43.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 29543}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-28 16:03:28.000000000', 'files': ['releasenotes/notes/designate-infoblox-backend-also-notifies-0214cc1e51b838b8.yaml', 'ansible/roles/designate/templates/pools.yaml.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c21a891a23eebe653a925182290b80a29264e265', 'message': 'Add also_notifies to Infoblox backend for Designate\n\nChange-Id: Ia02f83dfaaba53f95e373b2b2be3f74cfb7ae578\nCloses-Bug: #1855085\n(cherry picked from commit 68b92244255934dcc58195f664b825353d54c8d3)\n'}]",0,704602,c21a891a23eebe653a925182290b80a29264e265,8,4,1,14826,,,0,"Add also_notifies to Infoblox backend for Designate

Change-Id: Ia02f83dfaaba53f95e373b2b2be3f74cfb7ae578
Closes-Bug: #1855085
(cherry picked from commit 68b92244255934dcc58195f664b825353d54c8d3)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/02/704602/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/designate/templates/pools.yaml.j2', 'releasenotes/notes/designate-infoblox-backend-also-notifies-0214cc1e51b838b8.yaml']",2,c21a891a23eebe653a925182290b80a29264e265,bug/1855085-stable/train,--- fixes: - | Adds configuration to set `also_notifies` within the pools.yaml file when using the Infoblox backend for Designate. Pushing a DNS NOTIFY packet to the master does not cause the DNS update to be propagated onto other nodes within the cluster. This means each node needs a DNS NOTIFY packet otherwise users may be given a stale DNS record if they query any worker node. For details please see `bug 1855085 <https://bugs.launchpad.net/kolla-ansible/+bug/1855085>`__ ,,16,0
openstack%2Fkolla-ansible~stable%2Fstein~Ia02f83dfaaba53f95e373b2b2be3f74cfb7ae578,openstack/kolla-ansible,stable/stein,Ia02f83dfaaba53f95e373b2b2be3f74cfb7ae578,Add also_notifies to Infoblox backend for Designate,MERGED,2020-01-28 16:03:35.000000000,2020-01-29 09:19:29.000000000,2020-01-29 09:17:42.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 29543}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-28 16:03:35.000000000', 'files': ['releasenotes/notes/designate-infoblox-backend-also-notifies-0214cc1e51b838b8.yaml', 'ansible/roles/designate/templates/pools.yaml.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a86b4744fc2672b0b474e0f5e6a2b3552fca68de', 'message': 'Add also_notifies to Infoblox backend for Designate\n\nChange-Id: Ia02f83dfaaba53f95e373b2b2be3f74cfb7ae578\nCloses-Bug: #1855085\n(cherry picked from commit 68b92244255934dcc58195f664b825353d54c8d3)\n'}]",0,704603,a86b4744fc2672b0b474e0f5e6a2b3552fca68de,8,4,1,14826,,,0,"Add also_notifies to Infoblox backend for Designate

Change-Id: Ia02f83dfaaba53f95e373b2b2be3f74cfb7ae578
Closes-Bug: #1855085
(cherry picked from commit 68b92244255934dcc58195f664b825353d54c8d3)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/03/704603/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/designate/templates/pools.yaml.j2', 'releasenotes/notes/designate-infoblox-backend-also-notifies-0214cc1e51b838b8.yaml']",2,a86b4744fc2672b0b474e0f5e6a2b3552fca68de,bug/1855085-stable/stein,--- fixes: - | Adds configuration to set `also_notifies` within the pools.yaml file when using the Infoblox backend for Designate. Pushing a DNS NOTIFY packet to the master does not cause the DNS update to be propagated onto other nodes within the cluster. This means each node needs a DNS NOTIFY packet otherwise users may be given a stale DNS record if they query any worker node. For details please see `bug 1855085 <https://bugs.launchpad.net/kolla-ansible/+bug/1855085>`__ ,,16,0
openstack%2Fneutron~master~I17904c996e1357f7292d25aab4d448edb052f44c,openstack/neutron,master,I17904c996e1357f7292d25aab4d448edb052f44c,[OVN] scripts for networking-ovn code migration,MERGED,2020-01-08 23:36:49.000000000,2020-01-29 09:16:31.000000000,2020-01-29 09:14:20.000000000,"[{'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 9531}, {'_account_id': 11952}, {'_account_id': 11975}, {'_account_id': 22348}, {'_account_id': 24791}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-08 23:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cf4b3f2d490b49fa8ddf3eea8532bd4a43e1b896', 'message': 'tools: Adding scripts to help with networking-ovn migration\n\nIn an effort to help on migrating changes on netowking-ovn to neutron,\nthese 3 scripts are being introduced.\n\n1) files_in_patch.py ==> show files that are changed in a patch_file\n\n$ # make a patch to use as example\n$ git show > /tmp/commit.patch\n\n$ ./tools/files_in_patch.py /tmp/commit.patch\ntools/download_gerrit_change.py\ntools/files_in_patch.py\ntools/migrate_names.py\ntools/migrate_names.txt\n$\n\n2) download_gerrit_change.py ==> given a gerrit change id, download latest\n   patchset as a patch_file\n\n$ ./tools/download_gerrit_change.py -h\nusage: download_gerrit_change.py [-h] gerritChange [output] [url]\n\nGet patch file for a gerrit\n\npositional arguments:\n  gerritChange  the gerrit change id\n  output        file containing the gerrit change\n  url           the url to Gerrit server\n\noptional arguments:\n  -h, --help    show this help message and exit\n$ ./tools/download_gerrit_change.py 698863 /tmp/change.patch\n$ ./tools/files_in_patch.py !$\n./tools/files_in_patch.py /tmp/change.patch\nnetworking_ovn/ml2/mech_driver.py\nnetworking_ovn/ml2/trunk_driver.py\nnetworking_ovn/tests/unit/ml2/test_mech_driver.py\nnetworking_ovn/tests/unit/ml2/test_trunk_driver.py\n\n3) ./tools/migrate_names.py ==> given a gerrit change id or a patch_file, use mapfile\n   to rename files in patch\n\n$ ./tools/migrate_names.py --help\nUsage: migrate_names.py [OPTIONS]\n\nOptions:\n  -i, --input_patch TEXT    input_patch patch file or gerrit change\n  -o, --output TEXT         Output patch file. Default: stdout\n  -m, --mapfile PATH        Data file that specifies mapping to be applied to\n                            input\n  --reverse / --no-reverse  Map filenames from neutron to networking-ovn repo\n  --help                    Show this message and exit.\n$ ./tools/migrate_names.py -i /tmp/change.patch -o /tmp/neutron_change.patch\n$ ./tools/migrate_names.py -o /tmp/change.patch.2 -i /tmp/neutron_change.patch --reverse\n$ diff /tmp/change.patch /tmp/change.patch\n$ diff /tmp/change.patch /tmp/neutron_change.patch\n38,39c38,39\n< --- a/networking_ovn/ml2/mech_driver.py\n< +++ b/networking_ovn/ml2/mech_driver.py\n---\n> --- a/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n> +++ b/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n84,85c84,85\n<%-%- snip %-%->\n\n$ ./tools/files_in_patch.py /tmp/neutron_change.patch\nneutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\nneutron/services/trunk/drivers/ovn/trunk_driver.py\nneutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\nneutron/tests/unit/services/trunk/drivers/ovn/test_trunk_driver.py\n\nChange-Id: I17904c996e1357f7292d25aab4d448edb052f44c\n'}, {'number': 2, 'created': '2020-01-09 01:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/03355ca7f9de4eb02d0e12f85e12432ec5ab3f4e', 'message': 'tools: Adding scripts to help with networking-ovn migration\n\nIn an effort to help on migrating changes on netowking-ovn to neutron,\nthese 3 scripts are being introduced.\n\n1) files_in_patch.py ==> show files that are changed in a patch_file\n\n$ # make a patch to use as example\n$ git show > /tmp/commit.patch\n\n$ ./tools/files_in_patch.py /tmp/commit.patch\ntools/download_gerrit_change.py\ntools/files_in_patch.py\ntools/migrate_names.py\ntools/migrate_names.txt\n$\n\n2) download_gerrit_change.py ==> given a gerrit change id, download latest\n   patchset as a patch_file\n\n$ ./tools/download_gerrit_change.py -h\nusage: download_gerrit_change.py [-h] gerritChange [output] [url]\n\nGet patch file for a gerrit\n\npositional arguments:\n  gerritChange  the gerrit change id\n  output        file containing the gerrit change\n  url           the url to Gerrit server\n\noptional arguments:\n  -h, --help    show this help message and exit\n$ ./tools/download_gerrit_change.py 698863 /tmp/change.patch\n$ ./tools/files_in_patch.py !$\n./tools/files_in_patch.py /tmp/change.patch\nnetworking_ovn/ml2/mech_driver.py\nnetworking_ovn/ml2/trunk_driver.py\nnetworking_ovn/tests/unit/ml2/test_mech_driver.py\nnetworking_ovn/tests/unit/ml2/test_trunk_driver.py\n\n3) ./tools/migrate_names.py ==> given a gerrit change id or a patch_file, use mapfile\n   to rename files in patch\n\n$ ./tools/migrate_names.py --help\nUsage: migrate_names.py [OPTIONS]\n\nOptions:\n  -i, --input_patch TEXT    input_patch patch file or gerrit change\n  -o, --output TEXT         Output patch file. Default: stdout\n  -m, --mapfile PATH        Data file that specifies mapping to be applied to\n                            input\n  --reverse / --no-reverse  Map filenames from neutron to networking-ovn repo\n  --help                    Show this message and exit.\n$ ./tools/migrate_names.py -i /tmp/change.patch -o /tmp/neutron_change.patch\n$ ./tools/migrate_names.py -o /tmp/change.patch.2 -i /tmp/neutron_change.patch --reverse\n$ diff /tmp/change.patch /tmp/change.patch\n$ diff /tmp/change.patch /tmp/neutron_change.patch\n38,39c38,39\n< --- a/networking_ovn/ml2/mech_driver.py\n< +++ b/networking_ovn/ml2/mech_driver.py\n---\n> --- a/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n> +++ b/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n84,85c84,85\n<%-%- snip %-%->\n\n$ ./tools/files_in_patch.py /tmp/neutron_change.patch\nneutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\nneutron/services/trunk/drivers/ovn/trunk_driver.py\nneutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\nneutron/tests/unit/services/trunk/drivers/ovn/test_trunk_driver.py\n\nChange-Id: I17904c996e1357f7292d25aab4d448edb052f44c\n'}, {'number': 3, 'created': '2020-01-09 01:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4dddc0bf3365ccaa3422399f9df11dae1b4a9be7', 'message': 'tools: Adding scripts to help with networking-ovn migration\n\nIn an effort to help on migrating changes on netowking-ovn to neutron,\nthese 3 scripts are being introduced.\n\n1) files_in_patch.py ==> show files that are changed in a patch_file\n\n$ # make a patch to use as example\n$ git show > /tmp/commit.patch\n\n$ ./tools/files_in_patch.py /tmp/commit.patch\ntools/download_gerrit_change.py\ntools/files_in_patch.py\ntools/migrate_names.py\ntools/migrate_names.txt\n$\n\n2) download_gerrit_change.py ==> given a gerrit change id, download latest\n   patchset as a patch_file\n\n$ ./tools/download_gerrit_change.py -h\nusage: download_gerrit_change.py [-h] gerritChange [output] [url]\n\nGet patch file for a gerrit\n\npositional arguments:\n  gerritChange  the gerrit change id\n  output        file containing the gerrit change\n  url           the url to Gerrit server\n\noptional arguments:\n  -h, --help    show this help message and exit\n$ ./tools/download_gerrit_change.py 698863 /tmp/change.patch\n$ ./tools/files_in_patch.py !$\n./tools/files_in_patch.py /tmp/change.patch\nnetworking_ovn/ml2/mech_driver.py\nnetworking_ovn/ml2/trunk_driver.py\nnetworking_ovn/tests/unit/ml2/test_mech_driver.py\nnetworking_ovn/tests/unit/ml2/test_trunk_driver.py\n\n3) ./tools/migrate_names.py ==> given a gerrit change id or a patch_file, use mapfile\n   to rename files in patch\n\n$ ./tools/migrate_names.py --help\nUsage: migrate_names.py [OPTIONS]\n\nOptions:\n  -i, --input_patch TEXT    input_patch patch file or gerrit change\n  -o, --output TEXT         Output patch file. Default: stdout\n  -m, --mapfile PATH        Data file that specifies mapping to be applied to\n                            input\n  --reverse / --no-reverse  Map filenames from neutron to networking-ovn repo\n  --help                    Show this message and exit.\n$ ./tools/migrate_names.py -i /tmp/change.patch -o /tmp/neutron_change.patch\n$ ./tools/migrate_names.py -o /tmp/change.patch.2 -i /tmp/neutron_change.patch --reverse\n$ diff /tmp/change.patch /tmp/change.patch\n$ diff /tmp/change.patch /tmp/neutron_change.patch\n38,39c38,39\n< --- a/networking_ovn/ml2/mech_driver.py\n< +++ b/networking_ovn/ml2/mech_driver.py\n---\n> --- a/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n> +++ b/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n84,85c84,85\n<%-%- snip %-%->\n\n$ ./tools/files_in_patch.py /tmp/neutron_change.patch\nneutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\nneutron/services/trunk/drivers/ovn/trunk_driver.py\nneutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\nneutron/tests/unit/services/trunk/drivers/ovn/test_trunk_driver.py\n\nChange-Id: I17904c996e1357f7292d25aab4d448edb052f44c\nRelated-Blueprint: neutron-ovn-merge\n'}, {'number': 4, 'created': '2020-01-09 20:39:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/321931666a2f9ed7db5aa7b36aea4b5ad7e14ae4', 'message': 'tools: Adding scripts to help with networking-ovn migration\n\nIn an effort to help on migrating changes on netowking-ovn to neutron,\nthese 3 scripts are being introduced.\n\n1) files_in_patch.py ==> show files that are changed in a patch_file\n\n$ # make a patch to use as example\n$ git show > /tmp/commit.patch\n\n$ ./tools/files_in_patch.py /tmp/commit.patch\ntools/download_gerrit_change.py\ntools/files_in_patch.py\ntools/migrate_names.py\ntools/migrate_names.txt\n$\n\n2) download_gerrit_change.py ==> given a gerrit change id, download latest\n   patchset as a patch_file\n\n$ ./tools/download_gerrit_change.py -h\nusage: download_gerrit_change.py [-h] gerritChange [output] [url]\n\nGet patch file for a gerrit\n\npositional arguments:\n  gerritChange  the gerrit change id\n  output        file containing the gerrit change\n  url           the url to Gerrit server\n\noptional arguments:\n  -h, --help    show this help message and exit\n$ ./tools/download_gerrit_change.py 698863 /tmp/change.patch\n$ ./tools/files_in_patch.py !$\n./tools/files_in_patch.py /tmp/change.patch\nnetworking_ovn/ml2/mech_driver.py\nnetworking_ovn/ml2/trunk_driver.py\nnetworking_ovn/tests/unit/ml2/test_mech_driver.py\nnetworking_ovn/tests/unit/ml2/test_trunk_driver.py\n\n3) ./tools/migrate_names.py ==> given a gerrit change id or a patch_file, use mapfile\n   to rename files in patch\n\n$ ./tools/migrate_names.py --help\nUsage: migrate_names.py [OPTIONS]\n\nOptions:\n  -i, --input_patch TEXT    input_patch patch file or gerrit change\n  -o, --output TEXT         Output patch file. Default: stdout\n  -m, --mapfile PATH        Data file that specifies mapping to be applied to\n                            input\n  --reverse / --no-reverse  Map filenames from neutron to networking-ovn repo\n  --help                    Show this message and exit.\n$ ./tools/migrate_names.py -i /tmp/change.patch -o /tmp/neutron_change.patch\n$ ./tools/migrate_names.py -o /tmp/change.patch.2 -i /tmp/neutron_change.patch --reverse\n$ diff /tmp/change.patch /tmp/change.patch\n$ diff /tmp/change.patch /tmp/neutron_change.patch\n38,39c38,39\n< --- a/networking_ovn/ml2/mech_driver.py\n< +++ b/networking_ovn/ml2/mech_driver.py\n---\n> --- a/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n> +++ b/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n84,85c84,85\n<%-%- snip %-%->\n\n$ ./tools/files_in_patch.py /tmp/neutron_change.patch\nneutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\nneutron/services/trunk/drivers/ovn/trunk_driver.py\nneutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\nneutron/tests/unit/services/trunk/drivers/ovn/test_trunk_driver.py\n\nChange-Id: I17904c996e1357f7292d25aab4d448edb052f44c\nRelated-Blueprint: neutron-ovn-merge\n'}, {'number': 5, 'created': '2020-01-13 23:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ea74a21c3841ca27d616ed1210ca7cffafd920ec', 'message': '[OVN] scripts for networking-ovn code migration\n\nIn an effort to help on migrating changes from neutron to networking-ovn,\nthese 3 scripts are being introduced under tools.\n\nAlso adding documentation about these under OVN folder.\n\n1) files_in_patch.py\nUse this to show files that are changed in a patch file.\n\n   $ # Make a patch to use as example\n   $ git show > /tmp/commit.patch\n\n   $ ./tools/files_in_patch.py /tmp/commit.patch | grep .py\n   tools/download_gerrit_change.py\n   tools/files_in_patch.py\n   tools/migrate_names.py\n\n2) download_gerrit_change.py\nGiven a gerrit change id, it will fetch the latest patchset of the change\nfrom review.opendev.org as a patch file.\n\n   $ ./tools/download_gerrit_change.py -h\n   usage: download_gerrit_change.py [-h] gerritChange [output] [url]\n\n   Get patch file for a gerrit\n\n   positional arguments:\n     gerritChange  the gerrit change id\n     output        file containing the gerrit change\n     url           the url to Gerrit server\n\n   $ ./tools/download_gerrit_change.py 698863 /tmp/change.patch\n   $ ./tools/files_in_patch.py !$\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\n3) ./tools/migrate_names.py\nUse this tool to modify the name of the files in a patchfile so it can\nbe converted to/from the legacy networking-ovn and neutron repositories.\n\n   $ ./tools/migrate_names.py --help\n   Usage: migrate_names.py [OPTIONS]\n\n   Options:\n     -i, --input_patch TEXT    input_patch patch file or gerrit change\n     -o, --output TEXT         Output patch file. Default: stdout\n     -m, --mapfile PATH        Data file that specifies mapping to be applied to\n                               input  [default: ./tools/migrate_names.txt]\n     --reverse / --no-reverse  Map filenames from networking-ovn to neutron repo\n\n   $ ./tools/migrate_names.py -i 701646 > /tmp/ovn_change.patch\n   $ ./tools/migrate_names.py -o /tmp/change.patch.reverse -i /tmp/ovn_change.patch --reverse\n   $ diff /tmp/change.patch.reverse /tmp/ovn_change.patch\n   40,41c40,41\n   < --- a/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   < +++ b/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   ---\n   > --- a/networking_ovn/ml2/mech_driver.py\n   > +++ b/networking_ovn/ml2/mech_driver.py\n   <... snip ...>\n\n   $ ./tools/files_in_patch.py /tmp/ovn_change.patch\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\nChange-Id: I17904c996e1357f7292d25aab4d448edb052f44c\nRelated-Blueprint: neutron-ovn-merge\n'}, {'number': 6, 'created': '2020-01-13 23:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/29e236d1d9716b87a9ce2126abf62da3b83267d8', 'message': '[OVN] scripts for networking-ovn code migration\n\nIn an effort to help on migrating changes from neutron to networking-ovn,\nthese 3 scripts are being introduced under tools.\n\nAlso adding documentation about these under OVN folder.\n\n1) files_in_patch.py\nUse this to show files that are changed in a patch file.\n\n   $ # Make a patch to use as example\n   $ git show > /tmp/commit.patch\n\n   $ ./tools/files_in_patch.py /tmp/commit.patch | grep .py\n   tools/download_gerrit_change.py\n   tools/files_in_patch.py\n   tools/migrate_names.py\n\n2) download_gerrit_change.py\nGiven a gerrit change id, it will fetch the latest patchset of the change\nfrom review.opendev.org as a patch file.\n\n   $ ./tools/download_gerrit_change.py -h\n   usage: download_gerrit_change.py [-h] gerritChange [output] [url]\n\n   Get patch file for a gerrit\n\n   positional arguments:\n     gerritChange  the gerrit change id\n     output        file containing the gerrit change\n     url           the url to Gerrit server\n\n   $ ./tools/download_gerrit_change.py 698863 /tmp/change.patch\n   $ ./tools/files_in_patch.py !$\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\n3) ./tools/migrate_names.py\nUse this tool to modify the name of the files in a patchfile so it can\nbe converted to/from the legacy networking-ovn and neutron repositories.\n\n   $ ./tools/migrate_names.py --help\n   Usage: migrate_names.py [OPTIONS]\n\n   Options:\n     -i, --input_patch TEXT    input_patch patch file or gerrit change\n     -o, --output TEXT         Output patch file. Default: stdout\n     -m, --mapfile PATH        Data file that specifies mapping to be applied to\n                               input  [default: ./tools/migrate_names.txt]\n     --reverse / --no-reverse  Map filenames from networking-ovn to neutron repo\n\n   $ ./tools/migrate_names.py -i 701646 > /tmp/ovn_change.patch\n   $ ./tools/migrate_names.py -o /tmp/change.patch.reverse -i /tmp/ovn_change.patch --reverse\n   $ diff /tmp/change.patch.reverse /tmp/ovn_change.patch\n   40,41c40,41\n   < --- a/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   < +++ b/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   ---\n   > --- a/networking_ovn/ml2/mech_driver.py\n   > +++ b/networking_ovn/ml2/mech_driver.py\n   <... snip ...>\n\n   $ ./tools/files_in_patch.py /tmp/ovn_change.patch\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\nChange-Id: I17904c996e1357f7292d25aab4d448edb052f44c\nRelated-Blueprint: neutron-ovn-merge\n'}, {'number': 7, 'created': '2020-01-14 11:39:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/019cbd883516a32105af139269f3877a06c9437b', 'message': '[OVN] scripts for networking-ovn code migration\n\nIn an effort to help on migrating changes from neutron to networking-ovn,\nthese 3 scripts are being introduced under tools.\n\nAlso adding documentation about these under OVN folder.\n\n1) files_in_patch.py\nUse this to show files that are changed in a patch file.\n\n   $ # Make a patch to use as example\n   $ git show > /tmp/commit.patch\n\n   $ ./tools/files_in_patch.py /tmp/commit.patch | grep .py\n   tools/download_gerrit_change.py\n   tools/files_in_patch.py\n   tools/migrate_names.py\n\n2) download_gerrit_change.py\nGiven a gerrit change id, it will fetch the latest patchset of the change\nfrom review.opendev.org as a patch file.\n\n   $ ./tools/download_gerrit_change.py -h\n   usage: download_gerrit_change.py [-h] gerritChange [output] [url]\n\n   Get patch file for a gerrit\n\n   positional arguments:\n     gerritChange  the gerrit change id\n     output        file containing the gerrit change\n     url           the url to Gerrit server\n\n   $ ./tools/download_gerrit_change.py 698863 /tmp/change.patch\n   $ ./tools/files_in_patch.py !$\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\n3) ./tools/migrate_names.py\nUse this tool to modify the name of the files in a patchfile so it can\nbe converted to/from the legacy networking-ovn and neutron repositories.\n\n   $ ./tools/migrate_names.py --help\n   Usage: migrate_names.py [OPTIONS]\n\n   Options:\n     -i, --input_patch TEXT    input_patch patch file or gerrit change\n     -o, --output TEXT         Output patch file. Default: stdout\n     -m, --mapfile PATH        Data file that specifies mapping to be applied to\n                               input  [default: ./tools/migrate_names.txt]\n     --reverse / --no-reverse  Map filenames from networking-ovn to neutron repo\n\n   $ ./tools/migrate_names.py -i 701646 > /tmp/ovn_change.patch\n   $ ./tools/migrate_names.py -o /tmp/change.patch.reverse -i /tmp/ovn_change.patch --reverse\n   $ diff /tmp/change.patch.reverse /tmp/ovn_change.patch\n   40,41c40,41\n   < --- a/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   < +++ b/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   ---\n   > --- a/networking_ovn/ml2/mech_driver.py\n   > +++ b/networking_ovn/ml2/mech_driver.py\n   <... snip ...>\n\n   $ ./tools/files_in_patch.py /tmp/ovn_change.patch\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\nChange-Id: I17904c996e1357f7292d25aab4d448edb052f44c\nRelated-Blueprint: neutron-ovn-merge\n'}, {'number': 8, 'created': '2020-01-14 14:40:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/765bf0034df65297ff043cc644203f97527a861f', 'message': '[OVN] scripts for networking-ovn code migration\n\nIn an effort to help on migrating changes from neutron to networking-ovn,\nthese 3 scripts are being introduced under tools.\n\nAlso adding documentation about these under OVN folder.\n\n1) files_in_patch.py\nUse this to show files that are changed in a patch file.\n\n   $ # Make a patch to use as example\n   $ git show > /tmp/commit.patch\n\n   $ ./tools/files_in_patch.py /tmp/commit.patch | grep .py\n   tools/download_gerrit_change.py\n   tools/files_in_patch.py\n   tools/migrate_names.py\n\n2) download_gerrit_change.py\nGiven a gerrit change id, it will fetch the latest patchset of the change\nfrom review.opendev.org as a patch file.\n\n   $ ./tools/download_gerrit_change.py -h\n   usage: download_gerrit_change.py [-h] gerritChange [output] [url]\n\n   Get patch file for a gerrit\n\n   positional arguments:\n     gerritChange  the gerrit change id\n     output        file containing the gerrit change\n     url           the url to Gerrit server\n\n   $ ./tools/download_gerrit_change.py 698863 /tmp/change.patch\n   $ ./tools/files_in_patch.py !$\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\n3) ./tools/migrate_names.py\nUse this tool to modify the name of the files in a patchfile so it can\nbe converted to/from the legacy networking-ovn and neutron repositories.\n\n   $ ./tools/migrate_names.py --help\n   Usage: migrate_names.py [OPTIONS]\n\n   Options:\n     -i, --input_patch TEXT    input_patch patch file or gerrit change\n     -o, --output TEXT         Output patch file. Default: stdout\n     -m, --mapfile PATH        Data file that specifies mapping to be applied to\n                               input  [default: ./tools/migrate_names.txt]\n     --reverse / --no-reverse  Map filenames from networking-ovn to neutron repo\n\n   $ ./tools/migrate_names.py -i 701646 > /tmp/ovn_change.patch\n   $ ./tools/migrate_names.py -o /tmp/change.patch.reverse -i /tmp/ovn_change.patch --reverse\n   $ diff /tmp/change.patch.reverse /tmp/ovn_change.patch\n   40,41c40,41\n   < --- a/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   < +++ b/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   ---\n   > --- a/networking_ovn/ml2/mech_driver.py\n   > +++ b/networking_ovn/ml2/mech_driver.py\n   <... snip ...>\n\n   $ ./tools/files_in_patch.py /tmp/ovn_change.patch\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\nChange-Id: I17904c996e1357f7292d25aab4d448edb052f44c\nRelated-Blueprint: neutron-ovn-merge\n'}, {'number': 9, 'created': '2020-01-16 19:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cbfd994e9dee86e2129c3399e190118231179198', 'message': '[OVN] scripts for networking-ovn code migration\n\nIn an effort to help on migrating changes from neutron to networking-ovn,\nthese 3 scripts are being introduced under tools.\n\nAlso adding documentation about these under OVN folder.\n\n1) files_in_patch.py\nUse this to show files that are changed in a patch file.\n\n   $ # Make a patch to use as example\n   $ git show > /tmp/commit.patch\n\n   $ ./tools/files_in_patch.py /tmp/commit.patch | grep .py\n   tools/download_gerrit_change.py\n   tools/files_in_patch.py\n   tools/migrate_names.py\n\n2) download_gerrit_change.py\nGiven a gerrit change id, it will fetch the latest patchset of the change\nfrom review.opendev.org as a patch file.\n\n   $ ./tools/download_gerrit_change.py -h\n   usage: download_gerrit_change.py [-h] gerritChange [output] [url]\n\n   Get patch file for a gerrit\n\n   positional arguments:\n     gerritChange  the gerrit change id\n     output        file containing the gerrit change\n     url           the url to Gerrit server\n\n   $ ./tools/download_gerrit_change.py 698863 /tmp/change.patch\n   $ ./tools/files_in_patch.py !$\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\n3) ./tools/migrate_names.py\nUse this tool to modify the name of the files in a patchfile so it can\nbe converted to/from the legacy networking-ovn and neutron repositories.\n\n   $ ./tools/migrate_names.py --help\n   Usage: migrate_names.py [OPTIONS]\n\n   Options:\n     -i, --input_patch TEXT    input_patch patch file or gerrit change\n     -o, --output TEXT         Output patch file. Default: stdout\n     -m, --mapfile PATH        Data file that specifies mapping to be applied to\n                               input  [default: ./tools/migrate_names.txt]\n     --reverse / --no-reverse  Map filenames from networking-ovn to neutron repo\n\n   $ ./tools/migrate_names.py -i 701646 > /tmp/ovn_change.patch\n   $ ./tools/migrate_names.py -o /tmp/change.patch.reverse -i /tmp/ovn_change.patch --reverse\n   $ diff /tmp/change.patch.reverse /tmp/ovn_change.patch | grep .py\n   < --- a/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   < +++ b/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   > --- a/networking_ovn/ml2/mech_driver.py\n   > +++ b/networking_ovn/ml2/mech_driver.py\n   <... snip ...>\n\n   $ ./tools/files_in_patch.py /tmp/ovn_change.patch\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\nChange-Id: I17904c996e1357f7292d25aab4d448edb052f44c\nRelated-Blueprint: neutron-ovn-merge\n'}, {'number': 10, 'created': '2020-01-16 19:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6a3752e57163923653a9208da71d602b31b59034', 'message': '[OVN] scripts for networking-ovn code migration\n\nIn an effort to help on migrating changes from neutron to networking-ovn,\nthese 3 scripts are being introduced under tools.\n\nAlso adding documentation about these under OVN folder.\n\n1) files_in_patch.py\nUse this to show files that are changed in a patch file.\n\n   $ # Make a patch to use as example\n   $ git show > /tmp/commit.patch\n\n   $ ./tools/files_in_patch.py /tmp/commit.patch | grep .py\n   tools/download_gerrit_change.py\n   tools/files_in_patch.py\n   tools/migrate_names.py\n\n2) download_gerrit_change.py\nGiven a gerrit change id, it will fetch the latest patchset of the change\nfrom review.opendev.org as a patch file.\n\n   $ ./tools/download_gerrit_change.py -h\n   usage: download_gerrit_change.py [-h] gerritChange [output] [url]\n\n   Get patch file for a gerrit\n\n   positional arguments:\n     gerritChange  the gerrit change id\n     output        file containing the gerrit change\n     url           the url to Gerrit server\n\n   $ ./tools/download_gerrit_change.py 698863 /tmp/change.patch\n   $ ./tools/files_in_patch.py !$\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\n3) ./tools/migrate_names.py\nUse this tool to modify the name of the files in a patchfile so it can\nbe converted to/from the legacy networking-ovn and neutron repositories.\n\n   $ ./tools/migrate_names.py --help\n   Usage: migrate_names.py [OPTIONS]\n\n   Options:\n     -i, --input_patch TEXT    input_patch patch file or gerrit change\n     -o, --output TEXT         Output patch file. Default: stdout\n     -m, --mapfile PATH        Data file that specifies mapping to be applied to\n                               input  [default: ./tools/migrate_names.txt]\n     --reverse / --no-reverse  Map filenames from networking-ovn to neutron repo\n\n   $ ./tools/migrate_names.py -i 701646 > /tmp/ovn_change.patch\n   $ ./tools/migrate_names.py -o /tmp/change.patch.reverse -i /tmp/ovn_change.patch --reverse\n   $ diff /tmp/change.patch.reverse /tmp/ovn_change.patch | grep .py\n   < --- a/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   < +++ b/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   > --- a/networking_ovn/ml2/mech_driver.py\n   > +++ b/networking_ovn/ml2/mech_driver.py\n   <... snip ...>\n\n   $ ./tools/files_in_patch.py /tmp/ovn_change.patch\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\nChange-Id: I17904c996e1357f7292d25aab4d448edb052f44c\nRelated-Blueprint: neutron-ovn-merge\n'}, {'number': 11, 'created': '2020-01-16 20:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/995f3dc251b92443efd8cb25731d01f622596b69', 'message': '[OVN] scripts for networking-ovn code migration\n\nIn an effort to help on migrating changes from neutron to networking-ovn,\nthese 3 scripts are being introduced under tools.\n\nAlso adding documentation about these under OVN folder.\n\n1) files_in_patch.py\nUse this to show files that are changed in a patch file.\n\n   $ # Make a patch to use as example\n   $ git show > /tmp/commit.patch\n\n   $ ./tools/files_in_patch.py /tmp/commit.patch | grep .py\n   tools/download_gerrit_change.py\n   tools/files_in_patch.py\n   tools/migrate_names.py\n\n2) download_gerrit_change.py\nGiven a gerrit change id, it will fetch the latest patchset of the change\nfrom review.opendev.org as a patch file.\n\n   $ ./tools/download_gerrit_change.py -h\n   usage: download_gerrit_change.py [-h] gerritChange [output] [url]\n\n   Get patch file for a gerrit\n\n   positional arguments:\n     gerritChange  the gerrit change id\n     output        file containing the gerrit change\n     url           the url to Gerrit server\n\n   $ ./tools/download_gerrit_change.py 698863 /tmp/change.patch\n   $ ./tools/files_in_patch.py !$\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\n3) ./tools/migrate_names.py\nUse this tool to modify the name of the files in a patchfile so it can\nbe converted to/from the legacy networking-ovn and neutron repositories.\n\n   $ ./tools/migrate_names.py --help\n   Usage: migrate_names.py [OPTIONS]\n\n   Options:\n     -i, --input_patch TEXT    input_patch patch file or gerrit change\n     -o, --output TEXT         Output patch file. Default: stdout\n     -m, --mapfile PATH        Data file that specifies mapping to be applied to\n                               input  [default: ./tools/migrate_names.txt]\n     --reverse / --no-reverse  Map filenames from networking-ovn to neutron repo\n\n   $ ./tools/migrate_names.py -i 701646 > /tmp/ovn_change.patch\n   $ ./tools/migrate_names.py -o /tmp/change.patch.reverse -i /tmp/ovn_change.patch --reverse\n   $ diff /tmp/change.patch.reverse /tmp/ovn_change.patch | grep .py\n   < --- a/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   < +++ b/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   > --- a/networking_ovn/ml2/mech_driver.py\n   > +++ b/networking_ovn/ml2/mech_driver.py\n   <... snip ...>\n\n   $ ./tools/files_in_patch.py /tmp/ovn_change.patch\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\nChange-Id: I17904c996e1357f7292d25aab4d448edb052f44c\nRelated-Blueprint: neutron-ovn-merge\n'}, {'number': 12, 'created': '2020-01-17 19:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d4b5f8d5c27834372ce4f2fe123d1be6dd4099aa', 'message': '[OVN] scripts for networking-ovn code migration\n\nIn an effort to help on migrating changes from neutron to networking-ovn,\nthese 3 scripts are being introduced under tools.\n\nAlso adding documentation about these under OVN folder.\n\n1) files_in_patch.py\nUse this to show files that are changed in a patch file.\n\n   $ # Make a patch to use as example\n   $ git show > /tmp/commit.patch\n\n   $ ./tools/files_in_patch.py /tmp/commit.patch | grep .py\n   tools/download_gerrit_change.py\n   tools/files_in_patch.py\n   tools/migrate_names.py\n\n2) download_gerrit_change.py\nGiven a gerrit change id, it will fetch the latest patchset of the change\nfrom review.opendev.org as a patch file.\n\n   $ ./tools/download_gerrit_change.py --help\n   Usage: download_gerrit_change.py [OPTIONS] GERRIT_CHANGE\n\n   Options:\n     -o, --output_patch TEXT  Output patch file  [default: stdout]\n     -g, --gerrit_url TEXT    The url to Gerrit server  [default:\n                              https://review.opendev.org/]\n     -t, --timeout INTEGER    Timeout, in seconds  [default: 10]\n     --help                   Show this message and exit.\n\n   $ ./tools/download_gerrit_change.py 698863 -o /tmp/change.patch\n   $ ./tools/files_in_patch.py /tmp/change.patch\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\n3) migrate_names.py\nUse this tool to modify the name of the files in a patchfile so it can\nbe converted to/from the legacy networking-ovn and neutron repositories.\n\n   $ ./tools/migrate_names.py --help\n   Usage: migrate_names.py [OPTIONS]\n\n   Options:\n     -i, --input_patch TEXT    input_patch patch file or gerrit change\n     -o, --output_patch TEXT   Output patch file. Default: stdout\n     -m, --mapfile PATH        Data file that specifies mapping to be applied to\n                               input  [default: /Users/gute/work/openstack/neutro\n                               n.git/tools/migrate_names.txt]\n     --reverse / --no-reverse  Map filenames from networking-ovn to Neutron repo\n     --help                    Show this message and exit.\n   $ ./tools/migrate_names.py -i 701646 > /tmp/ovn_change.patch\n   $ ./tools/migrate_names.py -o /tmp/reverse.patch -i /tmp/ovn_change.patch --reverse\n   $ diff /tmp/reverse.patch /tmp/ovn_change.patch | grep .py\n   < --- a/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   < +++ b/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   > --- a/networking_ovn/ml2/mech_driver.py\n   > +++ b/networking_ovn/ml2/mech_driver.py\n   <... snip ...>\n\n   $ ./tools/files_in_patch.py /tmp/ovn_change.patch\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\nChange-Id: I17904c996e1357f7292d25aab4d448edb052f44c\nRelated-Blueprint: neutron-ovn-merge\n'}, {'number': 13, 'created': '2020-01-17 19:08:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b3ea1bb7a9216de95d28cebd2a35c7c85b71273b', 'message': '[OVN] scripts for networking-ovn code migration\n\nIn an effort to help on migrating changes from neutron to networking-ovn,\nthese 3 scripts are being introduced under tools.\n\nAlso adding documentation about these under OVN folder.\n\n1) files_in_patch.py\nUse this to show files that are changed in a patch file.\n\n   $ # Make a patch to use as example\n   $ git show > /tmp/commit.patch\n\n   $ ./tools/files_in_patch.py /tmp/commit.patch | grep .py\n   tools/download_gerrit_change.py\n   tools/files_in_patch.py\n   tools/migrate_names.py\n\n2) download_gerrit_change.py\nGiven a gerrit change id, it will fetch the latest patchset of the change\nfrom review.opendev.org as a patch file.\n\n   $ ./tools/download_gerrit_change.py --help\n   Usage: download_gerrit_change.py [OPTIONS] GERRIT_CHANGE\n\n   Options:\n     -o, --output_patch TEXT  Output patch file  [default: stdout]\n     -g, --gerrit_url TEXT    The url to Gerrit server  [default:\n                              https://review.opendev.org/]\n     -t, --timeout INTEGER    Timeout, in seconds  [default: 10]\n     --help                   Show this message and exit.\n\n   $ ./tools/download_gerrit_change.py 698863 -o /tmp/change.patch\n   $ ./tools/files_in_patch.py /tmp/change.patch\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\n3) migrate_names.py\nUse this tool to modify the name of the files in a patchfile so it can\nbe converted to/from the legacy networking-ovn and neutron repositories.\n\n   $ ./tools/migrate_names.py --help\n   Usage: migrate_names.py [OPTIONS]\n\n   Options:\n     -i, --input_patch TEXT    input_patch patch file or gerrit change\n     -o, --output_patch TEXT   Output patch file. Default: stdout\n     -m, --mapfile PATH        Data file that specifies mapping to be applied to\n                               input  [default: /Users/gute/work/openstack/neutro\n                               n.git/tools/migrate_names.txt]\n     --reverse / --no-reverse  Map filenames from networking-ovn to Neutron repo\n     --help                    Show this message and exit.\n   $ ./tools/migrate_names.py -i 701646 > /tmp/ovn_change.patch\n   $ ./tools/migrate_names.py -o /tmp/reverse.patch -i /tmp/ovn_change.patch --reverse\n   $ diff /tmp/reverse.patch /tmp/ovn_change.patch | grep .py\n   < --- a/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   < +++ b/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   > --- a/networking_ovn/ml2/mech_driver.py\n   > +++ b/networking_ovn/ml2/mech_driver.py\n   <... snip ...>\n\n   $ ./tools/files_in_patch.py /tmp/ovn_change.patch\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\nChange-Id: I17904c996e1357f7292d25aab4d448edb052f44c\nRelated-Blueprint: neutron-ovn-merge\n'}, {'number': 14, 'created': '2020-01-18 12:30:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/411fb39557ab47b1bbb132f9e2a91bc06cd44c53', 'message': '[OVN] scripts for networking-ovn code migration\n\nIn an effort to help on migrating changes from neutron to networking-ovn,\nthese 3 scripts are being introduced under tools.\n\nAlso adding documentation about these under OVN folder.\n\n1) files_in_patch.py\nUse this to show files that are changed in a patch file.\n\n   $ # Make a patch to use as example\n   $ git show > /tmp/commit.patch\n\n   $ ./tools/files_in_patch.py /tmp/commit.patch | grep .py\n   tools/download_gerrit_change.py\n   tools/files_in_patch.py\n   tools/migrate_names.py\n\n2) download_gerrit_change.py\nGiven a gerrit change id, it will fetch the latest patchset of the change\nfrom review.opendev.org as a patch file.\n\n   $ ./tools/download_gerrit_change.py --help\n   Usage: download_gerrit_change.py [OPTIONS] GERRIT_CHANGE\n\n   Options:\n     -o, --output_patch TEXT  Output patch file  [default: stdout]\n     -g, --gerrit_url TEXT    The url to Gerrit server  [default:\n                              https://review.opendev.org/]\n     -t, --timeout INTEGER    Timeout, in seconds  [default: 10]\n     --help                   Show this message and exit.\n\n   $ ./tools/download_gerrit_change.py 698863 -o /tmp/change.patch\n   $ ./tools/files_in_patch.py /tmp/change.patch\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\n3) migrate_names.py\nUse this tool to modify the name of the files in a patchfile so it can\nbe converted to/from the legacy networking-ovn and neutron repositories.\n\n   $ ./tools/migrate_names.py --help\n   Usage: migrate_names.py [OPTIONS]\n\n   Options:\n     -i, --input_patch TEXT    input_patch patch file or gerrit change\n     -o, --output_patch TEXT   Output patch file. Default: stdout\n     -m, --mapfile PATH        Data file that specifies mapping to be applied to\n                               input  [default: /Users/gute/work/openstack/neutro\n                               n.git/tools/migrate_names.txt]\n     --reverse / --no-reverse  Map filenames from networking-ovn to Neutron repo\n     --help                    Show this message and exit.\n   $ ./tools/migrate_names.py -i 701646 > /tmp/ovn_change.patch\n   $ ./tools/migrate_names.py -o /tmp/reverse.patch -i /tmp/ovn_change.patch --reverse\n   $ diff /tmp/reverse.patch /tmp/ovn_change.patch | grep .py\n   < --- a/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   < +++ b/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   > --- a/networking_ovn/ml2/mech_driver.py\n   > +++ b/networking_ovn/ml2/mech_driver.py\n   <... snip ...>\n\n   $ ./tools/files_in_patch.py /tmp/ovn_change.patch\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\nChange-Id: I17904c996e1357f7292d25aab4d448edb052f44c\nRelated-Blueprint: neutron-ovn-merge\n'}, {'number': 15, 'created': '2020-01-22 11:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/92e2476620df2f368c1759351cfc8070e151cc4c', 'message': '[OVN] scripts for networking-ovn code migration\n\nIn an effort to help on migrating changes from neutron to networking-ovn,\nthese 3 scripts are being introduced under tools.\n\nAlso adding documentation about these under OVN folder.\n\n1) files_in_patch.py\nUse this to show files that are changed in a patch file.\n\n   $ # Make a patch to use as example\n   $ git show > /tmp/commit.patch\n\n   $ ./tools/files_in_patch.py /tmp/commit.patch | grep .py\n   tools/download_gerrit_change.py\n   tools/files_in_patch.py\n   tools/migrate_names.py\n\n2) download_gerrit_change.py\nGiven a gerrit change id, it will fetch the latest patchset of the change\nfrom review.opendev.org as a patch file.\n\n   $ ./tools/download_gerrit_change.py --help\n   Usage: download_gerrit_change.py [OPTIONS] GERRIT_CHANGE\n\n   Options:\n     -o, --output_patch TEXT  Output patch file  [default: stdout]\n     -g, --gerrit_url TEXT    The url to Gerrit server  [default:\n                              https://review.opendev.org/]\n     -t, --timeout INTEGER    Timeout, in seconds  [default: 10]\n     --help                   Show this message and exit.\n\n   $ ./tools/download_gerrit_change.py 698863 -o /tmp/change.patch\n   $ ./tools/files_in_patch.py /tmp/change.patch\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\n3) migrate_names.py\nUse this tool to modify the name of the files in a patchfile so it can\nbe converted to/from the legacy networking-ovn and neutron repositories.\n\n   $ ./tools/migrate_names.py --help\n   Usage: migrate_names.py [OPTIONS]\n\n   Options:\n     -i, --input_patch TEXT    input_patch patch file or gerrit change\n     -o, --output_patch TEXT   Output patch file. Default: stdout\n     -m, --mapfile PATH        Data file that specifies mapping to be applied to\n                               input  [default: /home/user/openstack/neutron.git\n                               /tools/migrate_names.txt]\n     --reverse / --no-reverse  Map filenames from networking-ovn to Neutron repo\n     --help                    Show this message and exit.\n   $ ./tools/migrate_names.py -i 701646 > /tmp/ovn_change.patch\n   $ ./tools/migrate_names.py -o /tmp/reverse.patch -i /tmp/ovn_change.patch --reverse\n   $ diff /tmp/reverse.patch /tmp/ovn_change.patch | grep .py\n   < --- a/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   < +++ b/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   > --- a/networking_ovn/ml2/mech_driver.py\n   > +++ b/networking_ovn/ml2/mech_driver.py\n   <... snip ...>\n\n   $ ./tools/files_in_patch.py /tmp/ovn_change.patch\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\nChange-Id: I17904c996e1357f7292d25aab4d448edb052f44c\nRelated-Blueprint: neutron-ovn-merge\n'}, {'number': 16, 'created': '2020-01-26 20:19:43.000000000', 'files': ['doc/source/contributor/ovn/index.rst', 'doc/source/contributor/index.rst', 'tools/migrate_names.py', 'doc/source/contributor/ovn/tools.rst', 'tools/requirements.txt', 'tools/download_gerrit_change.py', 'tools/migrate_names.txt', 'tools/files_in_patch.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/303937f3aec1e53d7ba49078ff399186c8cbabd0', 'message': '[OVN] scripts for networking-ovn code migration\n\nIn an effort to help on migrating changes from neutron to networking-ovn,\nthese 3 scripts are being introduced under tools.\n\nAlso adding documentation about these under OVN folder.\n\n1) files_in_patch.py\nUse this to show files that are changed in a patch file.\n\n   $ # Make a patch to use as example\n   $ git show > /tmp/commit.patch\n\n   $ ./tools/files_in_patch.py /tmp/commit.patch | grep .py\n   tools/download_gerrit_change.py\n   tools/files_in_patch.py\n   tools/migrate_names.py\n\n2) download_gerrit_change.py\nGiven a gerrit change id, it will fetch the latest patchset of the change\nfrom review.opendev.org as a patch file.\n\n   $ ./tools/download_gerrit_change.py --help\n   Usage: download_gerrit_change.py [OPTIONS] GERRIT_CHANGE\n\n   Options:\n     -o, --output_patch TEXT  Output patch file  [default: stdout]\n     -g, --gerrit_url TEXT    The url to Gerrit server  [default:\n                              https://review.opendev.org/]\n     -t, --timeout INTEGER    Timeout, in seconds  [default: 10]\n     --help                   Show this message and exit.\n\n   $ ./tools/download_gerrit_change.py 698863 -o /tmp/change.patch\n   $ ./tools/files_in_patch.py /tmp/change.patch\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\n3) migrate_names.py\nUse this tool to modify the name of the files in a patchfile so it can\nbe converted to/from the legacy networking-ovn and neutron repositories.\n\n   $ ./tools/migrate_names.py --help\n   Usage: migrate_names.py [OPTIONS]\n\n   Options:\n     -i, --input_patch TEXT    input_patch patch file or gerrit change\n     -o, --output_patch TEXT   Output patch file. Default: stdout\n     -m, --mapfile PATH        Data file that specifies mapping to be applied to\n                               input  [default: /home/user/openstack/neutron.git\n                               /tools/migrate_names.txt]\n     --reverse / --no-reverse  Map filenames from networking-ovn to Neutron repo\n     --help                    Show this message and exit.\n   $ ./tools/migrate_names.py -i 701646 > /tmp/ovn_change.patch\n   $ ./tools/migrate_names.py -o /tmp/reverse.patch -i /tmp/ovn_change.patch --reverse\n   $ diff /tmp/reverse.patch /tmp/ovn_change.patch | grep .py\n   < --- a/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   < +++ b/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n   > --- a/networking_ovn/ml2/mech_driver.py\n   > +++ b/networking_ovn/ml2/mech_driver.py\n   <... snip ...>\n\n   $ ./tools/files_in_patch.py /tmp/ovn_change.patch\n   networking_ovn/ml2/mech_driver.py\n   networking_ovn/ml2/trunk_driver.py\n   networking_ovn/tests/unit/ml2/test_mech_driver.py\n   networking_ovn/tests/unit/ml2/test_trunk_driver.py\n\nChange-Id: I17904c996e1357f7292d25aab4d448edb052f44c\nRelated-Blueprint: neutron-ovn-merge\n'}]",41,701637,303937f3aec1e53d7ba49078ff399186c8cbabd0,65,8,16,11952,,,0,"[OVN] scripts for networking-ovn code migration

In an effort to help on migrating changes from neutron to networking-ovn,
these 3 scripts are being introduced under tools.

Also adding documentation about these under OVN folder.

1) files_in_patch.py
Use this to show files that are changed in a patch file.

   $ # Make a patch to use as example
   $ git show > /tmp/commit.patch

   $ ./tools/files_in_patch.py /tmp/commit.patch | grep .py
   tools/download_gerrit_change.py
   tools/files_in_patch.py
   tools/migrate_names.py

2) download_gerrit_change.py
Given a gerrit change id, it will fetch the latest patchset of the change
from review.opendev.org as a patch file.

   $ ./tools/download_gerrit_change.py --help
   Usage: download_gerrit_change.py [OPTIONS] GERRIT_CHANGE

   Options:
     -o, --output_patch TEXT  Output patch file  [default: stdout]
     -g, --gerrit_url TEXT    The url to Gerrit server  [default:
                              https://review.opendev.org/]
     -t, --timeout INTEGER    Timeout, in seconds  [default: 10]
     --help                   Show this message and exit.

   $ ./tools/download_gerrit_change.py 698863 -o /tmp/change.patch
   $ ./tools/files_in_patch.py /tmp/change.patch
   networking_ovn/ml2/mech_driver.py
   networking_ovn/ml2/trunk_driver.py
   networking_ovn/tests/unit/ml2/test_mech_driver.py
   networking_ovn/tests/unit/ml2/test_trunk_driver.py

3) migrate_names.py
Use this tool to modify the name of the files in a patchfile so it can
be converted to/from the legacy networking-ovn and neutron repositories.

   $ ./tools/migrate_names.py --help
   Usage: migrate_names.py [OPTIONS]

   Options:
     -i, --input_patch TEXT    input_patch patch file or gerrit change
     -o, --output_patch TEXT   Output patch file. Default: stdout
     -m, --mapfile PATH        Data file that specifies mapping to be applied to
                               input  [default: /home/user/openstack/neutron.git
                               /tools/migrate_names.txt]
     --reverse / --no-reverse  Map filenames from networking-ovn to Neutron repo
     --help                    Show this message and exit.
   $ ./tools/migrate_names.py -i 701646 > /tmp/ovn_change.patch
   $ ./tools/migrate_names.py -o /tmp/reverse.patch -i /tmp/ovn_change.patch --reverse
   $ diff /tmp/reverse.patch /tmp/ovn_change.patch | grep .py
   < --- a/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py
   < +++ b/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py
   > --- a/networking_ovn/ml2/mech_driver.py
   > +++ b/networking_ovn/ml2/mech_driver.py
   <... snip ...>

   $ ./tools/files_in_patch.py /tmp/ovn_change.patch
   networking_ovn/ml2/mech_driver.py
   networking_ovn/ml2/trunk_driver.py
   networking_ovn/tests/unit/ml2/test_mech_driver.py
   networking_ovn/tests/unit/ml2/test_trunk_driver.py

Change-Id: I17904c996e1357f7292d25aab4d448edb052f44c
Related-Blueprint: neutron-ovn-merge
",git fetch https://review.opendev.org/openstack/neutron refs/changes/37/701637/16 && git format-patch -1 --stdout FETCH_HEAD,"['tools/migrate_names.py', 'tools/download_gerrit_change.py', 'tools/migrate_names.txt', 'tools/files_in_patch.py']",4,cf4b3f2d490b49fa8ddf3eea8532bd4a43e1b896,bp/neutron-ovn-merge,"#!/usr/bin/env python3 # Copyright 2020 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import sys import re # Initialize defaults debug = 0 file_names = {} # ====================================================================== def print_error(msg): sys.stderr.write(msg) # ====================================================================== def parse_input(input_file): global debug, file_names while 1: line_buffer = input_file.readline() if not line_buffer: break # print line_buffer, line_match = re.search(r""^\s*---\s+([^\s@]+)[\s@]+"", line_buffer) if not line_match: line_match = re.search(r""^\s*\+\+\+\s+([^\s@]+)[\s@]+"", line_buffer) if line_match: curr_file_name = line_match.group(1) # trim off 'a/' and 'b/' that you will normally see in git output # if len(curr_file_name) > 2 and curr_file_name[1] == '/' and ( curr_file_name[0] == 'a' or curr_file_name[0] == 'b'): curr_file_name = curr_file_name[2:] # ignore funny files that git can produce # if curr_file_name == '/dev/null': continue if curr_file_name not in file_names: # print curr_file_name file_names[curr_file_name] = 1 else: file_names[curr_file_name] += 1 # ====================================================================== def prune_unwanted_names(): global debug, file_names names = file_names.keys() unwanted_names = [] for currName in names: # ignore files that end in '.orig' as long as non-.orig exists line_match = re.search(r""^(.+)\.[oO][Rr][iI][gG]$"", currName) if line_match and line_match.group(1) in file_names: unwanted_names.append(currName) for currName in unwanted_names: del file_names[currName] if debug: print(""unwanted name: {}"".format(currName)) # ====================================================================== def print_file_names(): global debug, file_names names = list(file_names.keys()) names.sort() if debug: for currName in names: print(""{} ==> {}"".format(currName, file_names[currName])) else: for currName in names: print(currName) # ====================================================================== if __name__ == '__main__': if len(sys.argv) == 1: parse_input(sys.stdin) else: for currInputName in sys.argv[1:]: try: # print currInputName currInputFile = open(currInputName, 'r') parse_input(currInputFile) currInputFile.close() except IOError as eStr: print_error(""Cannot open %s: %s\n"" % (currInputName, eStr)) sys.exit(255) prune_unwanted_names() print_file_names() sys.exit(0) # ====================================================================== ",,345,0
openstack%2Fkolla-ansible~stable%2Ftrain~Idbe1e52dd3693a6f168d475f9230a253dae64480,openstack/kolla-ansible,stable/train,Idbe1e52dd3693a6f168d475f9230a253dae64480,Fix Prometheus template generation,MERGED,2020-01-28 16:02:12.000000000,2020-01-29 09:14:07.000000000,2020-01-29 09:11:56.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 29543}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-28 16:02:12.000000000', 'files': ['releasenotes/notes/prometheus-config-when-alertmanager-disabled-0090c1570ff4e632.yaml', 'ansible/roles/prometheus/templates/prometheus.yml.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8f7af8764431236f5103286edfc7a6d90cfed6ad', 'message': 'Fix Prometheus template generation\n\nIn a deployment where Prometheus is enabled and\nAlertmanager is disabled the task ""Copying over\nprometheus config file"" in\n\'ansible/roles/prometheus/tasks/config.yml\' will\nfail to template the Prometheus configuration file\n\'ansible/roles/prometheus/templates/prometheus.yml.j2\'\nas the variable \'prometheus_alert_rules\' does not\ncontain the key \'files\'. This commit fixes this bug.\n\nChange-Id: Idbe1e52dd3693a6f168d475f9230a253dae64480\nCloses-Bug: #1854540\n(cherry picked from commit 991bdc5f558467403cc3d993ba5c53b5f89272f9)\n'}]",0,704600,8f7af8764431236f5103286edfc7a6d90cfed6ad,8,4,1,14826,,,0,"Fix Prometheus template generation

In a deployment where Prometheus is enabled and
Alertmanager is disabled the task ""Copying over
prometheus config file"" in
'ansible/roles/prometheus/tasks/config.yml' will
fail to template the Prometheus configuration file
'ansible/roles/prometheus/templates/prometheus.yml.j2'
as the variable 'prometheus_alert_rules' does not
contain the key 'files'. This commit fixes this bug.

Change-Id: Idbe1e52dd3693a6f168d475f9230a253dae64480
Closes-Bug: #1854540
(cherry picked from commit 991bdc5f558467403cc3d993ba5c53b5f89272f9)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/00/704600/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/prometheus-config-when-alertmanager-disabled-0090c1570ff4e632.yaml', 'ansible/roles/prometheus/templates/prometheus.yml.j2']",2,8f7af8764431236f5103286edfc7a6d90cfed6ad,bug/1854540-stable/train,{% if prometheus_alert_rules.files is defined and prometheus_alert_rules.files | length > 0 %},{% if prometheus_alert_rules is defined and prometheus_alert_rules.files | length > 0 %},9,1
openstack%2Fcontributor-guide~master~I5813e5c792d0eb3bf5d919d1012b8d11269e61c0,openstack/contributor-guide,master,I5813e5c792d0eb3bf5d919d1012b8d11269e61c0,Imported Translations from Zanata,MERGED,2020-01-27 08:21:47.000000000,2020-01-29 08:56:46.000000000,2020-01-29 08:54:52.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-27 08:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/contributor-guide/commit/f0bca9971c5881947317bcce6732ef144f4988ae', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I5813e5c792d0eb3bf5d919d1012b8d11269e61c0\n'}, {'number': 2, 'created': '2020-01-28 08:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/contributor-guide/commit/e4ea622b3e5f7cac0fd0a2fc1b3bb2dabf5fc6d9', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I5813e5c792d0eb3bf5d919d1012b8d11269e61c0\n'}, {'number': 3, 'created': '2020-01-29 08:13:23.000000000', 'files': ['doc/source/locale/de/LC_MESSAGES/doc-common.po', 'doc/source/locale/id/LC_MESSAGES/doc-contributing.po', 'doc/source/locale/de/LC_MESSAGES/doc-contributing.po'], 'web_link': 'https://opendev.org/openstack/contributor-guide/commit/7c8f5c4b1b6972cd18f3452f20652d5ad7726a8b', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I5813e5c792d0eb3bf5d919d1012b8d11269e61c0\n'}]",0,704278,7c8f5c4b1b6972cd18f3452f20652d5ad7726a8b,13,2,3,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I5813e5c792d0eb3bf5d919d1012b8d11269e61c0
",git fetch https://review.opendev.org/openstack/contributor-guide refs/changes/78/704278/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/locale/en_GB/LC_MESSAGES/doc-contributing.po'],1,f0bca9971c5881947317bcce6732ef144f4988ae,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2020. #zanata""POT-Creation-Date: 2020-01-23 09:16+0000\n""""PO-Revision-Date: 2020-01-26 11:18+0000\n""msgid ""Bulding the guide"" msgstr ""Bulding the guide"" ","""POT-Creation-Date: 2019-12-11 10:54+0000\n""""PO-Revision-Date: 2019-12-14 04:47+0000\n""",6,2
openstack%2Fkolla-ansible~stable%2Fstein~Idbe1e52dd3693a6f168d475f9230a253dae64480,openstack/kolla-ansible,stable/stein,Idbe1e52dd3693a6f168d475f9230a253dae64480,Fix Prometheus template generation,MERGED,2020-01-28 16:02:19.000000000,2020-01-29 08:56:31.000000000,2020-01-29 08:54:21.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 29543}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-28 16:02:19.000000000', 'files': ['releasenotes/notes/prometheus-config-when-alertmanager-disabled-0090c1570ff4e632.yaml', 'ansible/roles/prometheus/templates/prometheus.yml.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/15c233c52cf9b69f6ed842bcf725b5b48a8ad3cc', 'message': 'Fix Prometheus template generation\n\nIn a deployment where Prometheus is enabled and\nAlertmanager is disabled the task ""Copying over\nprometheus config file"" in\n\'ansible/roles/prometheus/tasks/config.yml\' will\nfail to template the Prometheus configuration file\n\'ansible/roles/prometheus/templates/prometheus.yml.j2\'\nas the variable \'prometheus_alert_rules\' does not\ncontain the key \'files\'. This commit fixes this bug.\n\nChange-Id: Idbe1e52dd3693a6f168d475f9230a253dae64480\nCloses-Bug: #1854540\n(cherry picked from commit 991bdc5f558467403cc3d993ba5c53b5f89272f9)\n'}]",0,704601,15c233c52cf9b69f6ed842bcf725b5b48a8ad3cc,9,5,1,14826,,,0,"Fix Prometheus template generation

In a deployment where Prometheus is enabled and
Alertmanager is disabled the task ""Copying over
prometheus config file"" in
'ansible/roles/prometheus/tasks/config.yml' will
fail to template the Prometheus configuration file
'ansible/roles/prometheus/templates/prometheus.yml.j2'
as the variable 'prometheus_alert_rules' does not
contain the key 'files'. This commit fixes this bug.

Change-Id: Idbe1e52dd3693a6f168d475f9230a253dae64480
Closes-Bug: #1854540
(cherry picked from commit 991bdc5f558467403cc3d993ba5c53b5f89272f9)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/01/704601/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/prometheus-config-when-alertmanager-disabled-0090c1570ff4e632.yaml', 'ansible/roles/prometheus/templates/prometheus.yml.j2']",2,15c233c52cf9b69f6ed842bcf725b5b48a8ad3cc,bug/1854540-stable/stein,{% if prometheus_alert_rules.files is defined and prometheus_alert_rules.files | length > 0 %},{% if prometheus_alert_rules is defined and prometheus_alert_rules.files | length > 0 %},9,1
openstack%2Ftripleo-puppet-elements~master~I1220eda28cb8d21098c26aa548305004567e6e03,openstack/tripleo-puppet-elements,master,I1220eda28cb8d21098c26aa548305004567e6e03,Remove libvirt package,MERGED,2019-09-15 22:21:05.000000000,2020-01-29 08:56:14.000000000,2020-01-08 18:28:34.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 30133}]","[{'number': 1, 'created': '2019-09-15 22:21:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/601ca2971812990c5ade3d5af5764d99be947873', 'message': 'Remove libvirt package\n\nNova services are now running in the containers but we still have\nlibvirt packages installed on Overcloud systems. This change removes\nlibvirt packages that are not needed any more.\n\nDepends-On: https://review.opendev.org/682055\nChange-Id: I1220eda28cb8d21098c26aa548305004567e6e03\nCloses-Bug: 1842932\n'}, {'number': 2, 'created': '2019-10-28 16:21:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/04c31a8caec4c15fcb517bdb3505fc3d9c33cd9b', 'message': 'Remove libvirt package\n\nNova services are now running in the containers but we still have\nlibvirt packages installed on Overcloud systems. This change removes\nlibvirt packages that are not needed any more.\n\nDepends-On: https://review.opendev.org/681092\nChange-Id: I1220eda28cb8d21098c26aa548305004567e6e03\nCloses-Bug: 1842932\n'}, {'number': 3, 'created': '2019-10-31 19:05:12.000000000', 'files': ['elements/overcloud-compute/post-install.d/51-remove-libvirt-default-net', 'elements/overcloud-compute/pkg-map', 'elements/overcloud-controller/post-install.d/51-disable-libvirtd-service', 'elements/overcloud-compute/install.d/package-installs-overcloud-compute', 'releasenotes/notes/remove-libvirt-deps-8994d3d325af0765.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/359bc74c7602b27a803039557c9c5767e2bf0df6', 'message': 'Remove libvirt package\n\nNova services are now running in the containers but we still have\nlibvirt packages installed on Overcloud systems. This change removes\nlibvirt packages that are not needed any more.\n\nDepends-On: https://review.opendev.org/681092\nChange-Id: I1220eda28cb8d21098c26aa548305004567e6e03\nCloses-Bug: 1842932\n'}]",0,682255,359bc74c7602b27a803039557c9c5767e2bf0df6,29,8,3,30133,,,0,"Remove libvirt package

Nova services are now running in the containers but we still have
libvirt packages installed on Overcloud systems. This change removes
libvirt packages that are not needed any more.

Depends-On: https://review.opendev.org/681092
Change-Id: I1220eda28cb8d21098c26aa548305004567e6e03
Closes-Bug: 1842932
",git fetch https://review.opendev.org/openstack/tripleo-puppet-elements refs/changes/55/682255/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/overcloud-compute/pkg-map', 'elements/overcloud-compute/install.d/package-installs-overcloud-compute', 'releasenotes/notes/remove-libvirt-deps-8994d3d325af0765.yaml']",3,601ca2971812990c5ade3d5af5764d99be947873,remove-libvirt-deps,--- other: - | Nova services are now running in the containers but we have still a lot of libvirt packages installed on Overcloud systems. This change remove unnecessary libvirt packages. ,,6,2
openstack%2Foctavia~master~I8e03858e32b6c220ce08fe418a613a6c32fe064c,openstack/octavia,master,I8e03858e32b6c220ce08fe418a613a6c32fe064c,Increase sleep in health_check in case of DBConnectionError,ABANDONED,2020-01-22 11:06:38.000000000,2020-01-29 08:43:04.000000000,,"[{'_account_id': 1131}, {'_account_id': 6469}, {'_account_id': 7249}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-22 11:06:38.000000000', 'files': ['octavia/controller/healthmanager/health_manager.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/4797e2d17f2d5c45d4e12ebc1fb54e23da1a5c3e', 'message': 'Increase sleep in health_check in case of DBConnectionError\n\nTo avoid false failover of amphorae by healthmanager during db\noutage increase time of sleep.\n\nStory: 2007197\nTask: 38360\n\nChange-Id: I8e03858e32b6c220ce08fe418a613a6c32fe064c\n'}]",1,703769,4797e2d17f2d5c45d4e12ebc1fb54e23da1a5c3e,5,4,1,7249,,,0,"Increase sleep in health_check in case of DBConnectionError

To avoid false failover of amphorae by healthmanager during db
outage increase time of sleep.

Story: 2007197
Task: 38360

Change-Id: I8e03858e32b6c220ce08fe418a613a6c32fe064c
",git fetch https://review.opendev.org/openstack/octavia refs/changes/69/703769/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia/controller/healthmanager/health_manager.py'],1,4797e2d17f2d5c45d4e12ebc1fb54e23da1a5c3e,," # online. Sleeping off the full ""heartbeat_timeout"" * 2 time.sleep(CONF.health_manager.heartbeat_timeout * 2)"," # online. Sleeping off the full ""heartbeat_timeout"" time.sleep(CONF.health_manager.heartbeat_timeout)",2,2
openstack%2Fhorizon~master~Ia940b6666327dd908a7c5f2fea0f3fe8d74cc6f9,openstack/horizon,master,Ia940b6666327dd908a7c5f2fea0f3fe8d74cc6f9,Add neutron error message when security group rule creation fails,ABANDONED,2020-01-27 11:56:58.000000000,2020-01-29 08:40:30.000000000,,"[{'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-01-27 11:56:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d1dd4778942f14501637e7b876e9615e9a2d16ea', 'message': 'Add neutron error message when security group rule creation fails\n\nChange-Id: Ia940b6666327dd908a7c5f2fea0f3fe8d74cc6f9\n'}, {'number': 2, 'created': '2020-01-27 12:08:21.000000000', 'files': ['openstack_dashboard/dashboards/project/security_groups/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b4bce1858c50be0135cc5e2b31e1609dde77ede5', 'message': 'Add neutron error message when security group rule creation fails\n\nChange-Id: Ia940b6666327dd908a7c5f2fea0f3fe8d74cc6f9\n'}]",0,704312,b4bce1858c50be0135cc5e2b31e1609dde77ede5,5,2,2,20363,,,0,"Add neutron error message when security group rule creation fails

Change-Id: Ia940b6666327dd908a7c5f2fea0f3fe8d74cc6f9
",git fetch https://review.opendev.org/openstack/horizon refs/changes/12/704312/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/security_groups/forms.py'],1,d1dd4778942f14501637e7b876e9615e9a2d16ea,sg_error," except Exception as e: if (hasattr(e, 'status_code') and e.status_code == 400 and hasattr(e, 'message') and e.message): msg = e.message else: msg = _('Unable to add rule to security group.') exceptions.handle(request, msg, redirect=redirect)"," except Exception: exceptions.handle(request, _('Unable to add rule to security group.'), redirect=redirect)",7,4
openstack%2Ftripleo-ci~master~I9854fe11e55f5cbaf92c6046a32cec7d80a48827,openstack/tripleo-ci,master,I9854fe11e55f5cbaf92c6046a32cec7d80a48827,ensure rdo-ovb logs are gzipped,MERGED,2020-01-28 21:42:27.000000000,2020-01-29 08:27:41.000000000,2020-01-29 08:27:41.000000000,"[{'_account_id': 9592}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-28 21:42:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ee61ccbfca8bacad46c676f29269a17de24c5b7c', 'message': 'ensure rdo-ovb logs are gzipped\n\nRelated-To: https://review.opendev.org/#/c/702883/\nChange-Id: I9854fe11e55f5cbaf92c6046a32cec7d80a48827\n'}, {'number': 2, 'created': '2020-01-29 02:12:17.000000000', 'files': ['toci-quickstart/config/testenv/ovb-rdocloud.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ba0db9b849c1c0f485800e408990804fec9716e0', 'message': 'ensure rdo-ovb logs are gzipped\n\nRelated-To: https://review.opendev.org/#/c/702883/\nChange-Id: I9854fe11e55f5cbaf92c6046a32cec7d80a48827\n'}]",0,704689,ba0db9b849c1c0f485800e408990804fec9716e0,12,3,2,9592,,,0,"ensure rdo-ovb logs are gzipped

Related-To: https://review.opendev.org/#/c/702883/
Change-Id: I9854fe11e55f5cbaf92c6046a32cec7d80a48827
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/89/704689/2 && git format-patch -1 --stdout FETCH_HEAD,['toci-quickstart/config/testenv/ovb-rdocloud.yml'],1,ee61ccbfca8bacad46c676f29269a17de24c5b7c,gzip, # Ensure logs are gzipped artcl_gzip: true ,,4,0
openstack%2Fproject-config~master~I6fdda4de11a04cb1a88be8c33390b2a9e2958b8b,openstack/project-config,master,I6fdda4de11a04cb1a88be8c33390b2a9e2958b8b,Fix description for promote-tox-docs-infra,MERGED,2020-01-27 17:01:40.000000000,2020-01-29 08:26:02.000000000,2020-01-29 08:26:01.000000000,"[{'_account_id': 5263}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-27 17:01:40.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/6339a68e2d3ca1ff1c6a5fc2d24a42aa909e0c7b', 'message': 'Fix description for promote-tox-docs-infra\n\nUpdate description for promote-tox-docs-infra to match implementation.\n\nChange-Id: I6fdda4de11a04cb1a88be8c33390b2a9e2958b8b\n'}]",0,704359,6339a68e2d3ca1ff1c6a5fc2d24a42aa909e0c7b,7,3,1,6547,,,0,"Fix description for promote-tox-docs-infra

Update description for promote-tox-docs-infra to match implementation.

Change-Id: I6fdda4de11a04cb1a88be8c33390b2a9e2958b8b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/59/704359/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,6339a68e2d3ca1ff1c6a5fc2d24a42aa909e0c7b,fix-description, This is a promote job for ``opendev-tox-docs``., This is a promote job for ``tox-docs``.,1,1
openstack%2Ftripleo-ci~master~I956db84602964f5d64707e27d3e5a340c7a6bc17,openstack/tripleo-ci,master,I956db84602964f5d64707e27d3e5a340c7a6bc17,WIP: Enable commpression for collect logs in testenvs,ABANDONED,2020-01-23 17:30:01.000000000,2020-01-29 08:15:50.000000000,,"[{'_account_id': 8175}, {'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2020-01-23 17:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d4fdfef57dccbb7b5411e560bb7bcbc8482176ce', 'message': 'Enabled commpression for collect logs in testenvs\n\nChange-Id: I956db84602964f5d64707e27d3e5a340c7a6bc17\nNeeded-By: https://review.opendev.org/#/c/704020/\n'}, {'number': 2, 'created': '2020-01-27 13:20:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/0e6b726c4532edd82f9a9d14d9f50e8f559f4ebb', 'message': 'WIP: Enable commpression for collect logs in testenvs\n\nGoals is to:\n\n* remove the call of collect_logs.sh script and calling the\nrole directory\n* assure that all functionality from collect_logs.sh is done by the role\n\nChange-Id: I956db84602964f5d64707e27d3e5a340c7a6bc17\nNeeded-By: https://review.opendev.org/#/c/704020/\n'}, {'number': 3, 'created': '2020-01-27 13:54:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f005e2eb16b8472a7b7d8b4c3644d0031f735f31', 'message': 'WIP: Enable commpression for collect logs in testenvs\n\nGoals is to:\n\n* remove the call of collect_logs.sh script and calling the\nrole directory\n* assure that all functionality from collect_logs.sh is done by the role\n\nChange-Id: I956db84602964f5d64707e27d3e5a340c7a6bc17\nNeeded-By: https://review.opendev.org/#/c/704020/\n'}, {'number': 4, 'created': '2020-01-27 14:17:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/65c022bb210238eb1b1a0eb3249b36463337f3d6', 'message': 'WIP: Enable commpression for collect logs in testenvs\n\nGoals is to:\n\n* remove the call of collect_logs.sh script and calling the\nrole directory\n* assure that all functionality from collect_logs.sh is done by the role\n\nChange-Id: I956db84602964f5d64707e27d3e5a340c7a6bc17\nNeeded-By: https://review.opendev.org/#/c/704020/\n'}, {'number': 5, 'created': '2020-01-27 14:23:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9ba9e2080f41e0bc9562157d30da040f033e042b', 'message': 'WIP: Enable commpression for collect logs in testenvs\n\nGoals is to:\n\n* remove the call of collect_logs.sh script and calling the\nrole directory\n* assure that all functionality from collect_logs.sh is done by the role\n\nChange-Id: I956db84602964f5d64707e27d3e5a340c7a6bc17\nRequired-By: https://review.opendev.org/#/c/704020/\nStory: https://tree.taiga.io/project/tripleo-ci-board/task/1507\n'}, {'number': 6, 'created': '2020-01-27 14:26:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1893763e2660914924a830eb3f1e2a91fe55f305', 'message': 'WIP: Enable commpression for collect logs in testenvs\n\nGoals is to:\n\n* remove the call of collect_logs.sh script and calling the\nrole directory\n* assure that all functionality from collect_logs.sh is done by the role\n\nChange-Id: I956db84602964f5d64707e27d3e5a340c7a6bc17\nDepends-On: https://review.opendev.org/#/c/704020/\nStory: https://tree.taiga.io/project/tripleo-ci-board/task/1507\n'}, {'number': 7, 'created': '2020-01-27 17:37:23.000000000', 'files': ['toci-quickstart/config/testenv/ovb-rdocloud.yml', 'zuul.d/base.yaml', 'zuul.d/layout.yaml', 'toci-quickstart/config/testenv/multinode-rdocloud.yml', 'playbooks/tripleo-ci/post.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f026ed0246daa1302038eb94f2baeed2c56ee9b9', 'message': 'WIP: Enable commpression for collect logs in testenvs\n\nGoals is to:\n\n* remove the call of collect_logs.sh script and calling the\nrole directory\n* assure that all functionality from collect_logs.sh is done by the role\n\nChange-Id: I956db84602964f5d64707e27d3e5a340c7a6bc17\nDepends-On: https://review.opendev.org/#/c/704020/\nStory: https://tree.taiga.io/project/tripleo-ci-board/task/1507\n'}]",0,704044,f026ed0246daa1302038eb94f2baeed2c56ee9b9,21,8,7,24162,,,0,"WIP: Enable commpression for collect logs in testenvs

Goals is to:

* remove the call of collect_logs.sh script and calling the
role directory
* assure that all functionality from collect_logs.sh is done by the role

Change-Id: I956db84602964f5d64707e27d3e5a340c7a6bc17
Depends-On: https://review.opendev.org/#/c/704020/
Story: https://tree.taiga.io/project/tripleo-ci-board/task/1507
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/44/704044/7 && git format-patch -1 --stdout FETCH_HEAD,"['toci-quickstart/config/testenv/ovb-rdocloud.yml', 'toci-quickstart/config/testenv/multinode-rdocloud.yml']",2,d4fdfef57dccbb7b5411e560bb7bcbc8482176ce,gzip,# compress log files artcl_gzip: true ,,6,0
openstack%2Fneutron-vpnaas~stable%2Frocky~I38ffc08e9a03d93e9072ac718ad2865db4f8fcab,openstack/neutron-vpnaas,stable/rocky,I38ffc08e9a03d93e9072ac718ad2865db4f8fcab,Ensure python versions,ABANDONED,2020-01-28 22:01:24.000000000,2020-01-29 07:55:35.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-01-28 22:01:24.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/33af38d3f86c6d746e8ce5e07f89c9ca345fd851', 'message': 'Ensure python versions\n\nIt looks like better to specify basepython for all tox envs.\nAs of the rocky release, we use python 2.7 by default.\n\nhttp://lists.openstack.org/pipermail/openstack-discuss/2019-November/010957.html\n\nChange-Id: I38ffc08e9a03d93e9072ac718ad2865db4f8fcab\n'}]",0,704695,33af38d3f86c6d746e8ce5e07f89c9ca345fd851,3,1,1,841,,,0,"Ensure python versions

It looks like better to specify basepython for all tox envs.
As of the rocky release, we use python 2.7 by default.

http://lists.openstack.org/pipermail/openstack-discuss/2019-November/010957.html

Change-Id: I38ffc08e9a03d93e9072ac718ad2865db4f8fcab
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/95/704695/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,33af38d3f86c6d746e8ce5e07f89c9ca345fd851,rocky-gate,basepython = python2.7basepython = python2.7basepython = python2.7basepython = python2.7basepython = python2.7basepython = python2.7basepython = python2.7basepython = python2.7,,8,0
openstack%2Fcharm-nova-cloud-controller~master~Icdf47ea80267d421ca14f131f2d1f7cbdeb73641,openstack/charm-nova-cloud-controller,master,Icdf47ea80267d421ca14f131f2d1f7cbdeb73641,Trigger nova-compute restart when amqp has changed,MERGED,2020-01-28 12:13:09.000000000,2020-01-29 07:34:29.000000000,2020-01-29 07:34:29.000000000,"[{'_account_id': 12549}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-28 12:13:09.000000000', 'files': ['unit_tests/test_nova_cc_hooks.py', 'hooks/nova_cc_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/a0a98862d5633be9060874a687aca699b0a88701', 'message': 'Trigger nova-compute restart when amqp has changed\n\nIf nova-compute is contected to the message broker before\nthe nova-conducter then it times out after a minute and shutsdown.\nThe nova-cloud-controller needs to inform the nova-compute charm\nto restart nova-compute when it is connected to the message broker.\nThe restart is limited to the leader to stop multiple restart\nrequests.\n\nChange-Id: Icdf47ea80267d421ca14f131f2d1f7cbdeb73641\nCloses-Bug: #1861094\n'}]",0,704545,a0a98862d5633be9060874a687aca699b0a88701,9,4,1,12549,,,0,"Trigger nova-compute restart when amqp has changed

If nova-compute is contected to the message broker before
the nova-conducter then it times out after a minute and shutsdown.
The nova-cloud-controller needs to inform the nova-compute charm
to restart nova-compute when it is connected to the message broker.
The restart is limited to the leader to stop multiple restart
requests.

Change-Id: Icdf47ea80267d421ca14f131f2d1f7cbdeb73641
Closes-Bug: #1861094
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/45/704545/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_nova_cc_hooks.py', 'hooks/nova_cc_hooks.py']",2,a0a98862d5633be9060874a687aca699b0a88701,bug/1861094, if hookenv.is_leader(): # NOTE: trigger restart on nova-api-metadata on # neutron-gateway units once nova-cc has working # amqp connection (avoiding service down on n-gateway) # Also trigger restart of nova-compute Bug #1861094 update_nova_relation(remote_restart=True)," # NOTE: trigger restart on nova-api-metadata on # neutron-gateway units once nova-cc has working # amqp connection (avoiding service down on n-gateway) for rid in hookenv.relation_ids('quantum-network-service'): quantum_joined(rid=rid, remote_restart=True)",12,16
openstack%2Fopenstacksdk~stable%2Fstein~Ie0cffc402747d070c1eae1d9b423a046936d917d,openstack/openstacksdk,stable/stein,Ie0cffc402747d070c1eae1d9b423a046936d917d,Keep connection backrefs with weakref.proxy,MERGED,2019-11-27 01:57:34.000000000,2020-01-29 06:30:33.000000000,2020-01-29 06:27:55.000000000,"[{'_account_id': 2}, {'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2019-11-27 01:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/7d3c98a2aad4ea1d20562c9f7da7d29285d27e1d', 'message': ""Keep connection backrefs with weakref.proxy\n\nWe're storing references to the connection object on\nproxy objects and the senlin folks are seeing memory\nleaks. Storing them in weakrefs.\n\nChange-Id: Ie0cffc402747d070c1eae1d9b423a046936d917d\n(cherry picked from commit 0e8e36163716a53b4c1c2931408ced72951513be)\n""}, {'number': 2, 'created': '2020-01-02 14:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e2b45236cbd2bee6bca3cc6a98f6d0fc9ffe6f91', 'message': ""Keep connection backrefs with weakref.proxy\n\nWe're storing references to the connection object on\nproxy objects and the senlin folks are seeing memory\nleaks. Storing them in weakrefs.\n\nChange-Id: Ie0cffc402747d070c1eae1d9b423a046936d917d\n(cherry picked from commit 0e8e36163716a53b4c1c2931408ced72951513be)\n""}, {'number': 3, 'created': '2020-01-03 18:28:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/668fddcc8100fa414da30e4155b1b8cf998c67c7', 'message': ""Keep connection backrefs with weakref.proxy\n\nWe're storing references to the connection object on\nproxy objects and the senlin folks are seeing memory\nleaks. Storing them in weakrefs.\n\nChange-Id: Ie0cffc402747d070c1eae1d9b423a046936d917d\n(cherry picked from commit 0e8e36163716a53b4c1c2931408ced72951513be)\n""}, {'number': 4, 'created': '2020-01-27 01:47:09.000000000', 'files': ['openstack/connection.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/5f4ad7ea1d3f05fd04780f9a2aceccd7d30bcc05', 'message': ""Keep connection backrefs with weakref.proxy\n\nWe're storing references to the connection object on\nproxy objects and the senlin folks are seeing memory\nleaks. Storing them in weakrefs.\n\nChange-Id: Ie0cffc402747d070c1eae1d9b423a046936d917d\n(cherry picked from commit 0e8e36163716a53b4c1c2931408ced72951513be)\n""}]",0,696220,5f4ad7ea1d3f05fd04780f9a2aceccd7d30bcc05,22,4,4,22623,,,0,"Keep connection backrefs with weakref.proxy

We're storing references to the connection object on
proxy objects and the senlin folks are seeing memory
leaks. Storing them in weakrefs.

Change-Id: Ie0cffc402747d070c1eae1d9b423a046936d917d
(cherry picked from commit 0e8e36163716a53b4c1c2931408ced72951513be)
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/20/696220/4 && git format-patch -1 --stdout FETCH_HEAD,['openstack/connection.py'],1,7d3c98a2aad4ea1d20562c9f7da7d29285d27e1d,,import weakref self.session._sdk_connection = weakref.proxy(self), self.session._sdk_connection = self,2,1
openstack%2Fhorizon~stable%2Ftrain~I32c1e75e4d71d88b98599c6fb0647fc3ac3d6736,openstack/horizon,stable/train,I32c1e75e4d71d88b98599c6fb0647fc3ac3d6736,Allow to evacuate without specifying a target host,ABANDONED,2020-01-28 07:50:06.000000000,2020-01-29 05:11:26.000000000,,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-01-28 07:50:06.000000000', 'files': ['openstack_dashboard/dashboards/admin/hypervisors/compute/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/2cae3882c0785d64c80bedd1e968fe61fb02524e', 'message': 'Allow to evacuate without specifying a target host\n\nWhen the evacuate is run without specifying a target host, horizon\nsets an empty string for target host. But the evacuate api doesn\'t\nallow an empty string. As a result, nova returns ""HTTP 400 Bad\nrequest"".\n\nSo this patch sets None as the target host when it isn\'t specified.\n\nCloses-Bug: 1793694\nChange-Id: I32c1e75e4d71d88b98599c6fb0647fc3ac3d6736\n(cherry picked from commit f9e0f8a976b82088ef095a69cd1fa892cddde3ba)\n'}]",1,704503,2cae3882c0785d64c80bedd1e968fe61fb02524e,13,5,1,8988,,,0,"Allow to evacuate without specifying a target host

When the evacuate is run without specifying a target host, horizon
sets an empty string for target host. But the evacuate api doesn't
allow an empty string. As a result, nova returns ""HTTP 400 Bad
request"".

So this patch sets None as the target host when it isn't specified.

Closes-Bug: 1793694
Change-Id: I32c1e75e4d71d88b98599c6fb0647fc3ac3d6736
(cherry picked from commit f9e0f8a976b82088ef095a69cd1fa892cddde3ba)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/03/704503/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/admin/hypervisors/compute/forms.py'],1,2cae3882c0785d64c80bedd1e968fe61fb02524e,bug/1793694, # The target_host value will be an empty string when the target # host wasn't specified. But the evacuate api doesn't allow # an empty string. So set None as the target_host value. if not target_host: target_host = None,,5,0
openstack%2Fhorizon~stable%2Fstein~I8ef390d90c85c571e600adf8584416e3c9920488,openstack/horizon,stable/stein,I8ef390d90c85c571e600adf8584416e3c9920488,Allow to evacuate without specifying a target host,ABANDONED,2020-01-28 07:52:30.000000000,2020-01-29 05:09:21.000000000,,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 8988}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-01-28 07:52:30.000000000', 'files': ['openstack_dashboard/dashboards/admin/hypervisors/compute/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/4fe43b63c0dad90db71ce499b07a44ad78445b4c', 'message': 'Allow to evacuate without specifying a target host\n\nWhen the evacuate is run without specifying a target host, horizon\nsets an empty string for target host. But the evacuate api doesn\'t\nallow an empty string. As a result, nova returns ""HTTP 400 Bad\nrequest"".\n\nSo this patch sets None as the target host when it isn\'t specified.\n\nChange-Id: I8ef390d90c85c571e600adf8584416e3c9920488\nCloses-Bug: 1793694\n(cherry picked from commit f9e0f8a976b82088ef095a69cd1fa892cddde3ba)\n'}]",1,704505,4fe43b63c0dad90db71ce499b07a44ad78445b4c,7,6,1,8988,,,0,"Allow to evacuate without specifying a target host

When the evacuate is run without specifying a target host, horizon
sets an empty string for target host. But the evacuate api doesn't
allow an empty string. As a result, nova returns ""HTTP 400 Bad
request"".

So this patch sets None as the target host when it isn't specified.

Change-Id: I8ef390d90c85c571e600adf8584416e3c9920488
Closes-Bug: 1793694
(cherry picked from commit f9e0f8a976b82088ef095a69cd1fa892cddde3ba)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/05/704505/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/admin/hypervisors/compute/forms.py'],1,4fe43b63c0dad90db71ce499b07a44ad78445b4c,bug/1793694, # The target_host value will be an empty string when the target # host wasn't specified. But the evacuate api doesn't allow # an empty string. So set None as the target_host value. if not target_host: target_host = None,,5,0
openstack%2Ftripleo-quickstart-extras~master~I2a7ce46755c535e0aaac69de3f28a45aa40f88dd,openstack/tripleo-quickstart-extras,master,I2a7ce46755c535e0aaac69de3f28a45aa40f88dd,Rename tripleo-operator-ansible roles,MERGED,2020-01-20 15:47:01.000000000,2020-01-29 04:58:07.000000000,2020-01-29 04:58:07.000000000,"[{'_account_id': 3153}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2020-01-20 15:47:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/ca883a713eea066240688d33f1bce82bf39de75b', 'message': 'Rename tripleo-operator-ansible roles\n\nhttps://docs.ansible.com/ansible/devel/dev_guide/developing_collections.html#roles-directory\n\nChange-Id: I2a7ce46755c535e0aaac69de3f28a45aa40f88dd\nDepends-On: https://review.opendev.org/#/c/703419/\n'}, {'number': 2, 'created': '2020-01-28 18:36:44.000000000', 'files': ['roles/undercloud-deploy/tasks/main.yml', 'roles/undercloud-minion-deploy/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d5b59cb1cede890b3dc9e26f0b35cb304909d589', 'message': 'Rename tripleo-operator-ansible roles\n\nhttps://docs.ansible.com/ansible/devel/dev_guide/developing_collections.html#roles-directory\n\nChange-Id: I2a7ce46755c535e0aaac69de3f28a45aa40f88dd\nDepends-On: https://review.opendev.org/#/c/703419/\n'}]",0,703432,d5b59cb1cede890b3dc9e26f0b35cb304909d589,30,6,2,14985,,,0,"Rename tripleo-operator-ansible roles

https://docs.ansible.com/ansible/devel/dev_guide/developing_collections.html#roles-directory

Change-Id: I2a7ce46755c535e0aaac69de3f28a45aa40f88dd
Depends-On: https://review.opendev.org/#/c/703419/
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/32/703432/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/undercloud-deploy/tasks/main.yml', 'roles/undercloud-minion-deploy/tasks/main.yml']",2,ca883a713eea066240688d33f1bce82bf39de75b,rename-roles, name: tripleo_undercloud_minion_install, name: tripleo-undercloud-minion-install,2,2
openstack%2Fdevstack~master~I5c3e1b7b632fd73310c462530990cdb0e0c0ceea,openstack/devstack,master,I5c3e1b7b632fd73310c462530990cdb0e0c0ceea,libvirt: Support the use of the virt-preview repo when using Fedora,MERGED,2020-01-06 13:50:44.000000000,2020-01-29 04:52:57.000000000,2020-01-29 04:51:39.000000000,"[{'_account_id': 4146}, {'_account_id': 7118}, {'_account_id': 10135}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-06 13:50:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6bbd48e6ba44b7f68e0eb24cf66dbd524f7b86c8', 'message': 'nova: Support the use of the virt-preview repo when using Fedora\n\nThe virt-preview repo provides the latest rawhide versions of QEMU,\nLibvirt and other virt tools for older releases of Fedora. This repo is\nextremely useful when testing features in OpenStack that rely on these\nlatest builds well in advance of them landing in full Fedora, CentOS or\nRHEL releases.\n\nThis change adds a ``NOVA_ENABLE_FEDORA_VIRT_PREVIEW_REPO`` configurable\nto control when this repo is enabled and used when deploying on Fedora.\n\nChange-Id: I5c3e1b7b632fd73310c462530990cdb0e0c0ceea\n'}, {'number': 2, 'created': '2020-01-06 17:12:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/317a5daca5b724971cf9e8b0180a9bd451d09a00', 'message': 'nova: Support the use of the virt-preview repo when using Fedora\n\nThe virt-preview repo provides the latest rawhide versions of QEMU,\nLibvirt and other virt tools for older releases of Fedora. This repo is\nextremely useful when testing features in OpenStack that rely on these\nlatest builds well in advance of them landing in full Fedora, CentOS or\nRHEL releases.\n\nThis change adds a ``NOVA_ENABLE_FEDORA_VIRT_PREVIEW_REPO`` configurable\nto control when this repo is enabled and used when deploying on Fedora.\n\nChange-Id: I5c3e1b7b632fd73310c462530990cdb0e0c0ceea\n'}, {'number': 3, 'created': '2020-01-06 17:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/0d5a36bebd9a37bfbeef6ac985f65a40d295eed2', 'message': 'nova: Support the use of the virt-preview repo when using Fedora\n\nThe virt-preview repo provides the latest rawhide versions of QEMU,\nLibvirt and other virt tools for older releases of Fedora. This repo is\nextremely useful when testing features in OpenStack that rely on these\nlatest builds well in advance of them landing in full Fedora, CentOS or\nRHEL releases.\n\nThis change adds a ``NOVA_ENABLE_FEDORA_VIRT_PREVIEW_REPO`` configurable\nto control when this repo is enabled and used when deploying on Fedora.\n\nChange-Id: I5c3e1b7b632fd73310c462530990cdb0e0c0ceea\n'}, {'number': 4, 'created': '2020-01-27 17:45:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/cfdd9241eb706becf72122c5da8621de5ccf8b4e', 'message': 'libvirt: Support the use of the virt-preview repo when using Fedora\n\nThe virt-preview repo provides the latest rawhide versions of QEMU,\nLibvirt and other virt tools for older releases of Fedora. This repo is\nextremely useful when testing features in OpenStack that rely on these\nlatest builds well in advance of them landing in full Fedora, CentOS or\nRHEL releases.\n\nThis change adds a ``ENABLE_FEDORA_VIRT_PREVIEW_REPO`` configurable\nto control when this repo is enabled and used when deploying on Fedora.\n\nChange-Id: I5c3e1b7b632fd73310c462530990cdb0e0c0ceea\n'}, {'number': 5, 'created': '2020-01-27 18:02:50.000000000', 'files': ['lib/nova_plugins/functions-libvirt'], 'web_link': 'https://opendev.org/openstack/devstack/commit/169f5dee475f49ca18cd5f803287797a6c1ee5c0', 'message': 'libvirt: Support the use of the virt-preview repo when using Fedora\n\nThe virt-preview repo provides the latest rawhide versions of QEMU,\nLibvirt and other virt tools for older releases of Fedora. This repo is\nextremely useful when testing features in OpenStack that rely on these\nlatest builds well in advance of them landing in full Fedora, CentOS or\nRHEL releases.\n\nThis change adds a ``ENABLE_FEDORA_VIRT_PREVIEW_REPO`` configurable\nto control when this repo is enabled and used when deploying on Fedora.\n\nChange-Id: I5c3e1b7b632fd73310c462530990cdb0e0c0ceea\n'}]",9,701226,169f5dee475f49ca18cd5f803287797a6c1ee5c0,37,6,5,10135,,,0,"libvirt: Support the use of the virt-preview repo when using Fedora

The virt-preview repo provides the latest rawhide versions of QEMU,
Libvirt and other virt tools for older releases of Fedora. This repo is
extremely useful when testing features in OpenStack that rely on these
latest builds well in advance of them landing in full Fedora, CentOS or
RHEL releases.

This change adds a ``ENABLE_FEDORA_VIRT_PREVIEW_REPO`` configurable
to control when this repo is enabled and used when deploying on Fedora.

Change-Id: I5c3e1b7b632fd73310c462530990cdb0e0c0ceea
",git fetch https://review.opendev.org/openstack/devstack refs/changes/26/701226/5 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova'],1,6bbd48e6ba44b7f68e0eb24cf66dbd524f7b86c8,fedora-virt-preview,"# Enable the Fedora Virtualization Preview Copr repo that provides the latest # rawhide builds of QEMU, Libvirt and other virt tools for earlier releases. NOVA_ENABLE_FEDORA_VIRT_PREVIEW_REPO=$(trueorfalse False NOVA_ENABLE_FEDORA_VIRT_PREVIEW_REPO) if is_fedora && [[ $DISTRO =~ f[0-9][0-9] ]] && [[""$NOVA_ENABLE_FEDORA_VIRT_PREVIEW_REPO"" == ""True"" ]]; then # https://copr.fedorainfracloud.org/coprs/g/virtmaint-sig/virt-preview/ sudo dnf copr enable @virtmaint-sig/virt-preview sudo dnf update -y # Ensure the updated version of libvirtd is being used. sudo systemctl restart libvirtd fi ",,12,0
openstack%2Fswift~master~Ib537065a88ba3b7d97235d74cf8bcae465ccf055,openstack/swift,master,Ib537065a88ba3b7d97235d74cf8bcae465ccf055,Add ability to undelete an account.,NEW,2017-09-27 09:47:33.000000000,2020-01-29 04:50:56.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 860}, {'_account_id': 1179}, {'_account_id': 7233}, {'_account_id': 7847}, {'_account_id': 13052}, {'_account_id': 13852}, {'_account_id': 15343}, {'_account_id': 22348}, {'_account_id': 26690}]","[{'number': 1, 'created': '2017-09-27 09:47:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c31f1f7a82f22d18c3278d5871a308d5fa80ad4e', 'message': ""Implemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nTo undelete the account, the following cURL command would\nbe invoked to undelete the account.\ncurl -X PUT -H 'X-account-meta-undelete: true' -H 'X-Auth-Token:\n<admin_authentication_token>' http://<ip_address>:8080/v1/<name_of_deleted_account>\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n""}, {'number': 2, 'created': '2017-09-28 08:53:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d0466992ae16c8478f86866dc7a6935df2dc6949', 'message': 'Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nTo undelete the account, the following cURL command would\nbe invoked to undelete the account.\ncurl -v -X PUT -H \'X-account-meta-undelete: true\' -H \'X-Auth-Token:\n<admin_authentication_token>\' http://<ip_address>:8080/v1/<name_of_deleted_account>\n\nUpdated the ""Revive a deleted account"" procedure in procedures.rst file for\nend-users point of view.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n'}, {'number': 3, 'created': '2017-09-28 10:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7a56381b02de207e0efb9e37bcd9e22f9f50dcb9', 'message': 'Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nTo undelete the account, the following cURL command would\nbe invoked to undelete the account.\ncurl -v -X PUT -H \'X-account-meta-undelete: true\' -H \'X-Auth-Token:\n<admin_authentication_token>\' http://<ip_address>:8080/v1/<name_of_deleted_account>\n\nUpdated the ""Revive a deleted account"" procedure in procedures.rst file for\nend-users point of view.\n\nUpdated the code indentation pep8 issues.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n'}, {'number': 4, 'created': '2017-10-03 09:13:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ad7beb636ee0fa58aa3e02c902a83a0a913cb8d3', 'message': 'Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nTo undelete the account, the following cURL command would\nbe invoked to undelete the account.\ncurl -v -X PUT -H \'X-account-meta-undelete: true\' -H \'X-Auth-Token:\n<admin_authentication_token>\' http://<ip_address>:8080/v1/<name_of_deleted_account>\n\nUpdated the ""Revive a deleted account"" procedure in procedures.rst file for\nend-users point of view.\n\nUpdated the Jenkins issues.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n'}, {'number': 5, 'created': '2017-10-11 10:43:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7bb90382ce046982072c22a21b51195cb7ef921b', 'message': ""Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nTo undelete the account, the following cURL command would\nbe invoked to undelete the account.\ncurl -v -X PUT -H 'X-account-meta-undelete: true' -H 'X-Auth-Token:\n<admin_authentication_token>' http://<ip_address>:8080/v1/<name_of_deleted_account>\n\nUpdated for the reviews received on Patch Set 4.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n""}, {'number': 6, 'created': '2017-10-16 08:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a4618131f4cf4b8b07b3e869fef3b8772dfe96d4', 'message': ""Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nTo undelete the account, the following cURL command would\nbe invoked to undelete the account.\ncurl -v -X PUT -H 'X-account-meta-undelete: true' -H 'X-Auth-Token:\n<admin_authentication_token>' http://<ip_address>:8080/v1/<name_of_deleted_account>\n\nUpdated for the reviews received on Patch Set 4.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n""}, {'number': 7, 'created': '2017-10-17 09:42:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bcc01e7165b6c53f0141734a8b537900312d54ff', 'message': ""Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nTo undelete the account, the following cURL command would\nbe invoked to undelete the account.\ncurl -v -X PUT -H 'X-account-meta-undelete: true' -H 'X-Auth-Token:\n<admin_authentication_token>' http://<ip_address>:8080/v1/<name_of_deleted_account>\n\nUpdated for the reviews received on Patch Set 5.\nUpdated the conf file and documentation for delay_reaping.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n""}, {'number': 8, 'created': '2017-10-23 10:36:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/835a534c23ef970bfb6b11f93d981fb28188c226', 'message': ""Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nTo undelete the account, the following cURL command would\nbe invoked to undelete the account.\ncurl -v -X PUT -H 'X-account-meta-undelete: true' -H 'X-Auth-Token:\n<admin_authentication_token>' http://<ip_address>:8080/v1/<name_of_deleted_account>\n\nUpdated for the reviews received till Patch Set 7.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n""}, {'number': 9, 'created': '2017-10-24 16:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f3c0717aef96220327dd140c266c2d9265f83aa8', 'message': ""Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nTo undelete the account, the following cURL command would\nbe invoked to undelete the account.\ncurl -v -X PUT -H 'X-account-meta-undelete: true' -H 'X-Auth-Token:\n<admin_authentication_token>' http://<ip_address>:8080/v1/<name_of_deleted_account>\n\nUpdated for the reviews received till Patch Set 7.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n""}, {'number': 10, 'created': '2017-10-25 05:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cb2e02505394ca2cbff143144856043e3c6b0fd3', 'message': ""Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nTo undelete the account, the following cURL command would\nbe invoked to undelete the account.\ncurl -v -X PUT -H 'X-account-meta-undelete: true' -H 'X-Auth-Token:\n<admin_authentication_token>' http://<ip_address>:8080/v1/<name_of_deleted_account>\n\nUpdated for the reviews received till Patch Set 7.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n""}, {'number': 11, 'created': '2017-10-25 07:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0090e8dadb9b32e1c0d750ae629cb4004b2f6eb3', 'message': ""Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nTo undelete the account, the following cURL command would\nbe invoked to undelete the account.\ncurl -v -X PUT -H 'X-account-meta-undelete: true' -H 'X-Auth-Token:\n<admin_authentication_token>' http://<ip_address>:8080/v1/<name_of_deleted_account>\n\nUpdated for the reviews received till Patch Set 7.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n""}, {'number': 12, 'created': '2017-11-03 10:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b634f35b12f093656ae62c51b4c3ce1442840159', 'message': ""Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nTo undelete the account, the following cURL command would\nbe invoked to undelete the account.\ncurl -v -X PUT -H 'X-account-meta-undelete: true' -H 'X-Auth-Token:\n<admin_authentication_token>' http://<ip_address>:8080/v1/<name_of_deleted_account>\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n""}, {'number': 13, 'created': '2017-11-24 08:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/26dcececc82dd1a7c6511ed9d1da602a806da8b9', 'message': 'Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n'}, {'number': 14, 'created': '2018-02-20 08:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f4e3cdfe021623517542db9ceb2294ceb2a5c247', 'message': 'Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n'}, {'number': 15, 'created': '2018-07-06 05:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0bd36d6c2d655de705658846063a93d15d46bc77', 'message': 'Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n'}, {'number': 16, 'created': '2018-07-09 05:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/62ed723a48a1e1a4d8d093ff0df449d24d1b56f9', 'message': 'Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n'}, {'number': 17, 'created': '2018-07-31 06:32:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/82505316bba1483f934cb5571c1bb9ad7abbc979', 'message': 'Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n'}, {'number': 18, 'created': '2018-08-02 06:55:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f70a6b2157a97c77bcb011e0907177774017552e', 'message': 'Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n'}, {'number': 19, 'created': '2018-08-08 10:18:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/541b9d4dd80a5beb7be28daca30f74fb52a629c1', 'message': 'Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n'}, {'number': 20, 'created': '2019-06-26 05:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/22e0ffdd26b79d44c401862db05b42a227119db2', 'message': 'Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n'}, {'number': 21, 'created': '2019-07-03 09:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a974e134d2b1c51e30d9eda1ec33c3066a8b6b2d', 'message': 'Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n'}, {'number': 22, 'created': '2019-07-04 08:04:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b613c75164d7ba11c2fb0240e64a1f07926057e3', 'message': 'Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n'}, {'number': 23, 'created': '2019-07-09 06:52:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/10bc63ceef01018cca52443a87ac28fe42e5d10f', 'message': 'Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n'}, {'number': 24, 'created': '2019-07-10 06:56:58.000000000', 'files': ['doc/source/deployment_guide.rst', 'swift/account/backend.py', 'test/unit/account/test_reaper.py', 'test/unit/account/test_server.py', 'test/unit/proxy/controllers/test_account.py', 'test/unit/common/test_db.py', 'swift/account/server.py', 'test/unit/account/test_backend.py', 'swift/common/db.py', 'test/probe/test_account_reaper.py', 'swift/account/reaper.py', 'swift/proxy/controllers/account.py', 'etc/account-server.conf-sample', 'swift/container/backend.py', 'doc/manpages/account-server.conf.5', 'doc/source/ops_runbook/procedures.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/ac74dc38668b965bbab7d777ad67c525fb358bd1', 'message': 'Add ability to undelete an account.\n\nImplemented the fix to support the feature of undeleting the\naccount which was marked for deletion for the reaper.\n\nChange-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055\nCloses-Bug: #1521351\n'}]",174,507808,ac74dc38668b965bbab7d777ad67c525fb358bd1,147,11,24,26690,,,0,"Add ability to undelete an account.

Implemented the fix to support the feature of undeleting the
account which was marked for deletion for the reaper.

Change-Id: Ib537065a88ba3b7d97235d74cf8bcae465ccf055
Closes-Bug: #1521351
",git fetch https://review.opendev.org/openstack/swift refs/changes/08/507808/14 && git format-patch -1 --stdout FETCH_HEAD,"['swift/account/backend.py', 'swift/common/db.py', 'test/unit/common/test_db.py', 'swift/account/server.py', 'test/unit/account/test_backend.py', 'swift/container/backend.py']",6,c31f1f7a82f22d18c3278d5871a308d5fa80ad4e,bug/1521351," def _undelete_db(self, conn, timestamp): """""" Mark the DB as un-deleted. This will reset the status back to empty, the default value for the account. :param conn: DB connection object :param timestamp: timestamp to mark status changed """""" conn.execute("""""" UPDATE container_stat SET delete_timestamp = '0', put_timestamp = ?, status = '', status_changed_at = ? """""", (timestamp,timestamp,)) ",,114,33
openstack%2Frequirements~master~I5762673966187239ccbdc021215f158faa9efdf1,openstack/requirements,master,I5762673966187239ccbdc021215f158faa9efdf1,"Revert ""confluent-kafka 1.3.0 fails to install""",MERGED,2020-01-28 10:08:30.000000000,2020-01-29 04:48:48.000000000,2020-01-29 04:47:18.000000000,"[{'_account_id': 11904}, {'_account_id': 12404}, {'_account_id': 14288}, {'_account_id': 16222}, {'_account_id': 19134}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-28 10:08:30.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/0b399014bac6cba76738b84181f08c12f3a93c56', 'message': 'Revert ""confluent-kafka 1.3.0 fails to install""\n\nThe missing wheels have been published on Jan 8, 2020.\n\nhttps://pypi.org/project/confluent-kafka/#files\n\nThis reverts commit 9987b849df85bf40e5698dc52e29bd3f21d5464a.\n\nChange-Id: I5762673966187239ccbdc021215f158faa9efdf1\n'}]",0,704525,0b399014bac6cba76738b84181f08c12f3a93c56,16,7,1,16222,,,0,"Revert ""confluent-kafka 1.3.0 fails to install""

The missing wheels have been published on Jan 8, 2020.

https://pypi.org/project/confluent-kafka/#files

This reverts commit 9987b849df85bf40e5698dc52e29bd3f21d5464a.

Change-Id: I5762673966187239ccbdc021215f158faa9efdf1
",git fetch https://review.opendev.org/openstack/requirements refs/changes/25/704525/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,0b399014bac6cba76738b84181f08c12f3a93c56,kafka,confluent-kafka===1.3.0,confluent-kafka===1.2.0,2,2
openstack%2Fstorlets~master~I62239e865d2938f0fc7dc2755156206b29095524,openstack/storlets,master,I62239e865d2938f0fc7dc2755156206b29095524,[ussuri][goal] Drop python 2.7 support and testing,MERGED,2019-10-31 07:01:08.000000000,2020-01-29 04:29:37.000000000,2020-01-29 04:27:49.000000000,"[{'_account_id': 4608}, {'_account_id': 8556}, {'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-31 07:01:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/fc4ede9568205947cdd61a59a4a46874b450ac80', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nstorlets is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I62239e865d2938f0fc7dc2755156206b29095524\n'}, {'number': 2, 'created': '2019-11-16 15:06:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/3ffe2befc0b9074c80b4fa890b6e33913e9680e0', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nstorlets is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\nDepends-On: https://review.opendev.org/#/c/693631/\n\nChange-Id: I62239e865d2938f0fc7dc2755156206b29095524\n'}, {'number': 3, 'created': '2019-12-24 06:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/c4f2085028d471d4ef8f4c7f775ac22fd4c27272', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nstorlets is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\nDepends-On: https://review.opendev.org/#/c/693631/\n\nChange-Id: I62239e865d2938f0fc7dc2755156206b29095524\n'}, {'number': 4, 'created': '2020-01-16 09:33:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/26a88e37881d0ce09c01390c3132f73694489aa1', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nstorlets is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\nDepends-On: https://review.opendev.org/#/c/693631/\n\nChange-Id: I62239e865d2938f0fc7dc2755156206b29095524\n'}, {'number': 5, 'created': '2020-01-22 02:12:38.000000000', 'files': ['test-requirements.txt', '.zuul.yaml', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/storlets/commit/2f5d0300cc5c9ca5ffc8599baa3f9f86d3b8f746', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nstorlets is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\nDepends-On: https://review.opendev.org/#/c/693631/\n\nChange-Id: I62239e865d2938f0fc7dc2755156206b29095524\n'}]",2,692277,2f5d0300cc5c9ca5ffc8599baa3f9f86d3b8f746,23,4,5,8556,,,0,"[ussuri][goal] Drop python 2.7 support and testing

OpenStack is dropping the py2.7 support in ussuri cycle.

storlets is ready with python 3 and ok to drop the
python 2.7 support.

Complete discussion & schedule can be found in
- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html
- https://etherpad.openstack.org/p/drop-python2-support

Ussuri Communtiy-wide goal:
https://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html
Depends-On: https://review.opendev.org/#/c/693631/

Change-Id: I62239e865d2938f0fc7dc2755156206b29095524
",git fetch https://review.opendev.org/openstack/storlets refs/changes/77/692277/3 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/drop-py-2-7-e5652825c4b63b32.yaml', '.zuul.yaml', 'setup.cfg', 'tox.ini']",4,fc4ede9568205947cdd61a59a4a46874b450ac80,drop-py27-support,"envlist = py37,pep8commands = {toxinidir}/.functests jenkins","envlist = py27,py37,pep8[testenv:func] basepython = python2.7 deps = -r{toxinidir}/test-requirements.txt git+git://github.com/openstack/swift.git setenv = VIRTUAL_ENV={envdir} STORLET_SAMPLE_PATH={toxinidir}/StorletSamples CLUSTER_CONF_DIR={toxinidir} commands = {toxinidir}/.functests jenkins commands = {[testenv:func]commands}",9,29
openstack%2Fnova~master~I6333deb2f6e85eba3c92128dab4e4b4d35355603,openstack/nova,master,I6333deb2f6e85eba3c92128dab4e4b4d35355603,doc: define boot from volume in the glossary,MERGED,2019-12-13 19:54:59.000000000,2020-01-29 03:56:43.000000000,2020-01-29 03:52:49.000000000,"[{'_account_id': 4690}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-13 19:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f841f397bdd468e6dbb3cd984fc49aa3c0a1fc33', 'message': 'doc: define boot from volume in the glossary\n\nDefine it and also link to the term in a few different docs.\n\nChange-Id: I6333deb2f6e85eba3c92128dab4e4b4d35355603\n'}, {'number': 2, 'created': '2020-01-08 17:41:12.000000000', 'files': ['doc/source/user/cellsv2-layout.rst', 'doc/source/admin/manage-volumes.rst', 'doc/source/user/certificate-validation.rst', 'doc/source/user/block-device-mapping.rst', 'doc/source/admin/configuration/hypervisor-powervm.rst', 'doc/source/reference/glossary.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/33c79966242c248c771c6cd7d00aeba2a9d69114', 'message': 'doc: define boot from volume in the glossary\n\nDefine it and also link to the term in a few different docs.\n\nChange-Id: I6333deb2f6e85eba3c92128dab4e4b4d35355603\n'}]",0,699009,33c79966242c248c771c6cd7d00aeba2a9d69114,20,8,2,6873,,,0,"doc: define boot from volume in the glossary

Define it and also link to the term in a few different docs.

Change-Id: I6333deb2f6e85eba3c92128dab4e4b4d35355603
",git fetch https://review.opendev.org/openstack/nova refs/changes/09/699009/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/user/cellsv2-layout.rst', 'doc/source/admin/manage-volumes.rst', 'doc/source/user/certificate-validation.rst', 'doc/source/user/block-device-mapping.rst', 'doc/source/admin/configuration/hypervisor-powervm.rst', 'doc/source/reference/glossary.rst']",6,f841f397bdd468e6dbb3cd984fc49aa3c0a1fc33,glossary-bfv," Boot From Volume A server that is created with a :doc:`Block Device Mapping </user/block-device-mapping>` with ``boot_index=0`` and ``destination_type=volume``. The root volume can already exist when the server is created or be created by the compute service as part of the server creation. Note that a server can have volumes attached and not be boot-from-volume. A boot from volume server has an empty ("""") ``image`` parameter in ``GET /servers/{server_id}`` responses. ",,27,15
openstack%2Fkeystone~stable%2Ftrain~Icfce3b14abb55c6fef3de1b314cee22fc8b1d08c,openstack/keystone,stable/train,Icfce3b14abb55c6fef3de1b314cee22fc8b1d08c,Fix role_assignments role.id filter,MERGED,2020-01-27 22:44:48.000000000,2020-01-29 03:56:33.000000000,2020-01-29 03:52:59.000000000,"[{'_account_id': 1955}, {'_account_id': 5046}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-27 22:44:48.000000000', 'files': ['keystone/tests/unit/test_v3_assignment.py', 'keystone/tests/protection/v3/test_assignment.py', 'keystone/tests/unit/test_v3.py', 'keystone/assignment/core.py', 'releasenotes/notes/bug-1858012-584267ada7e33f2c.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/4d413f1eba2d1e6b16ecd57fa27de528dd0f67cb', 'message': ""Fix role_assignments role.id filter\n\nWithout this patch, if there are multiple role assignments on the system\nand they are not all the same role, querying for role assignments with\n/v3/role_assignments?role.id={role_id} may leak some role assignments\nthat don't match the role_id, making the returned results incorrect.\nThis patch fixes the issue by using a list comprehension instead of a\nfor loop over a list that was being modified within the loop.\n\nChange-Id: Icfce3b14abb55c6fef3de1b314cee22fc8b1d08c\nCloses-bug: #1858012\n(cherry picked from commit c2d88306621f890a857acd6831ea8bf073f55537)\n""}]",0,704453,4d413f1eba2d1e6b16ecd57fa27de528dd0f67cb,9,4,1,8482,,,0,"Fix role_assignments role.id filter

Without this patch, if there are multiple role assignments on the system
and they are not all the same role, querying for role assignments with
/v3/role_assignments?role.id={role_id} may leak some role assignments
that don't match the role_id, making the returned results incorrect.
This patch fixes the issue by using a list comprehension instead of a
for loop over a list that was being modified within the loop.

Change-Id: Icfce3b14abb55c6fef3de1b314cee22fc8b1d08c
Closes-bug: #1858012
(cherry picked from commit c2d88306621f890a857acd6831ea8bf073f55537)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/53/704453/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/test_v3_assignment.py', 'keystone/tests/protection/v3/test_assignment.py', 'keystone/tests/unit/test_v3.py', 'keystone/assignment/core.py', 'releasenotes/notes/bug-1858012-584267ada7e33f2c.yaml']",5,4d413f1eba2d1e6b16ecd57fa27de528dd0f67cb,assignment-role-filtering-stable/train,--- fixes: - | [`bug 1858012 <https://bugs.launchpad.net/keystone/+bug/1858012>`_] Fixes a bug in the /v3/role_assignments filtering where the `role.id` query parameter didn't properly filter role assignments by role in cases where there were multiple system role assignments. ,,51,7
openstack%2Fswift~master~I8296681b61996e073b3ba12ad46f99042dc15c37,openstack/swift,master,I8296681b61996e073b3ba12ad46f99042dc15c37,s3api: Implement object versioning API,MERGED,2019-07-30 20:36:01.000000000,2020-01-29 03:55:31.000000000,2020-01-29 03:52:57.000000000,"[{'_account_id': 1179}, {'_account_id': 9625}, {'_account_id': 15343}, {'_account_id': 22348}, {'_account_id': 23861}]","[{'number': 1, 'created': '2019-07-30 20:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7ef93077691e6c58395028651208822e49432e09', 'message': 's3api: Implement versioning status API\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nStore version id when copying object to archive\n\nWhen the current object is deleted and the versioning mode is set to\n""stack"", an older object from the archive container is restored as the\ncurrent object.  The ""version id"" is only part of the object name when\nit is in the archive container, which means that when it becomes the\ncurrent object, the ""version id"" is lost.  swift3 needs to know the\nversion id even after it is restored, but right now there is no way to\nget the version id.\n\nThis change stores the version id as metadata\n""X-Object-Sysmeta-Version-Id"" when an object is copied to the archive\ncontainer and given a version id.\n\ns3api: Modify obj GETorHEAD to support versions\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\ns3api: Listing of versioned objects\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nAdd X-Backend-Versioning-Mode-Override\n\nswift3 needs both the stack mode delete and history mode delete.  When\nan object without specifying a ""versionId"" is deleted, swift3 uses the\nhistory mode delete, which means the object is marked as deleted and\nreturns 404.  When an object with a specific ""versionId"" is deleted and\nthat object is the current object, swift3 uses the stack mode delete,\nwhich means the most recent non-deleted object in the versioning\ncontainer becomes the current object.  Right now, swift only supports\nsetting the mode once and using it to determine the behavior of the\ndeletion.\n\nAdding X-Backend-Versioning-Mode-Override allows swift3 to override the\nstored versioning mode for one request.  This means that even if the\nversioning mode is set to ""history"", if the request has the header\n""X-Backend-Versioning-Mode-Override: stack"", swift will use ""stack"" as\nthe versioning mode.\n\ns3api: Delete versioned objects\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\n'}, {'number': 2, 'created': '2019-08-27 16:58:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b3f4e0e13d5e855db4f46a1741da388360734af9', 'message': 's3api: Implement versioning status API\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nStore version id when copying object to archive\n\nWhen the current object is deleted and the versioning mode is set to\n""stack"", an older object from the archive container is restored as the\ncurrent object.  The ""version id"" is only part of the object name when\nit is in the archive container, which means that when it becomes the\ncurrent object, the ""version id"" is lost.  swift3 needs to know the\nversion id even after it is restored, but right now there is no way to\nget the version id.\n\nThis change stores the version id as metadata\n""X-Object-Sysmeta-Version-Id"" when an object is copied to the archive\ncontainer and given a version id.\n\ns3api: Modify obj GETorHEAD to support versions\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\ns3api: Listing of versioned objects\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nAdd X-Backend-Versioning-Mode-Override\n\nswift3 needs both the stack mode delete and history mode delete.  When\nan object without specifying a ""versionId"" is deleted, swift3 uses the\nhistory mode delete, which means the object is marked as deleted and\nreturns 404.  When an object with a specific ""versionId"" is deleted and\nthat object is the current object, swift3 uses the stack mode delete,\nwhich means the most recent non-deleted object in the versioning\ncontainer becomes the current object.  Right now, swift only supports\nsetting the mode once and using it to determine the behavior of the\ndeletion.\n\nAdding X-Backend-Versioning-Mode-Override allows swift3 to override the\nstored versioning mode for one request.  This means that even if the\nversioning mode is set to ""history"", if the request has the header\n""X-Backend-Versioning-Mode-Override: stack"", swift will use ""stack"" as\nthe versioning mode.\n\ns3api: Delete versioned objects\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\n'}, {'number': 3, 'created': '2019-09-11 05:09:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d781e25e900578d625099554f917fe804045dd99', 'message': 's3api: Implement versioning status API\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\ns3api: Modify obj GETorHEAD to support versions\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\ns3api: Listing of versioned objects\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\ns3api: Delete versioned objects\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 4, 'created': '2019-10-17 00:14:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1d84ded1d5ad98abd3193dc513abe37934d4edde', 'message': 's3api: Implement versioning status API\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\ns3api: Modify obj GETorHEAD to support versions\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\ns3api: Listing of versioned objects\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\ns3api: Delete versioned objects\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 5, 'created': '2019-10-19 02:19:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/545c817de0a4bd3208b93d4a0568f8a3aa24e562', 'message': 's3api: Implement versioning status API\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\ns3api: Modify obj GETorHEAD to support versions\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\ns3api: Listing of versioned objects\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\ns3api: Delete versioned objects\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 6, 'created': '2019-10-19 05:16:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f07a89fbc8a1df49217f65a08314910cd68a893e', 'message': 's3api: Implement versioning status API\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\ns3api: Modify obj GETorHEAD to support versions\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\ns3api: Listing of versioned objects\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\ns3api: Delete versioned objects\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 7, 'created': '2019-10-24 20:35:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/163c75d225649ec2dfaf90a9ed282b939c174045', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 8, 'created': '2019-10-28 22:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ddf994dabfe65cd7e8f55c9201002bf9aaed815e', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 9, 'created': '2019-11-14 23:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1e9113ca347cd73b80c6cfabab666c7104faf33c', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 10, 'created': '2019-11-15 00:03:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5f5f7a8dc3b2bcee3590ef1e8174def60848388c', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 11, 'created': '2019-11-15 07:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b499aebfed53bbc46eba7d3b8b356300c81bc1fe', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 12, 'created': '2019-11-19 18:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/71abf38df832c406ea684a77cd03aece67aa9aac', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 13, 'created': '2019-11-19 18:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c9c02daf3ff24979c2cc18003f67b8e2ec9ef7cf', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 14, 'created': '2019-11-19 20:30:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ece155a09d6b2fe7024c5377e4891a174aacd2e3', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 15, 'created': '2019-11-19 21:57:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/149dec2b1463572585017989c84c0b74c8b0c2d0', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 16, 'created': '2019-11-19 23:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/94d98b1b8d110fb3ecef242c1b047903032434e7', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 17, 'created': '2019-11-20 20:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4de259a85e8acf5fa162b689aaca86c007f72863', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 18, 'created': '2019-11-21 00:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f4873edbf03a4823bc8e041480200dcd00af904c', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 19, 'created': '2019-11-21 07:04:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3b88eca490d80e18ecef09db55fe69621007c0c2', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 20, 'created': '2019-11-21 07:52:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7c548721dac59fab7afa9da520e9ca52c13f4258', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 21, 'created': '2019-11-21 20:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a777f409430f51a9ee7e33037382c9a7ef31dc6c', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 22, 'created': '2019-11-21 21:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d71a627343eb06fe528e8c2a4004a69f5e96c9ea', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 23, 'created': '2019-11-22 00:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2cc62341ff0dd601076eb7524c62cd059b207ed1', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 24, 'created': '2019-11-22 02:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6efef26745700f00cd4629b4d42d14ae36fdba26', 'message': 'WIP: s3api: Implement object versioning API\n\n * Status API\n * Modify obj GETorHEAD to support versions\n * Listing of versioned objects\n * Delete versioned objects\n\nSet up versioning for a container and return the status of versioning.\n\nWhen deleting buckets, also try to delete the +versioning bucket.\n\nIf a versionId is given, if it is ""null"", it must be the current object.\nIf the versionId is not null, it might be in the versioning container,\nor it might be the current object that had that version id that was\nrestored after an object has been deleted.\n\nWhen processing GET requests for buckets with ""?versions"", in addition\nto listing what is currently in the bucket, also return the objects that\nare in the versioning container.\n\nWhen deleting an object with a specified version, and it is in the\nversioning container, it is deleted permanently.  If it is the current\nversion, then the object is deleted and the next available object in the\nversioning container becomes the current object.\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 25, 'created': '2019-11-22 20:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b30120fac78cf614d8425e1caf714ec4ab0fcdf9', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 26, 'created': '2019-11-25 18:26:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/adf769b2317cb45ce725165eaad683e69ed9a6b5', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 27, 'created': '2019-11-26 14:14:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/727e1b196d7404c226fc47a992453a92845c6d77', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 28, 'created': '2019-11-27 18:27:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/eefd4aada4dba21f8b3a1d7306277d718bef6805', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 29, 'created': '2019-12-06 19:13:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a2c23dbfedf0987c127ea715628aacce3a4b90a5', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 30, 'created': '2019-12-11 18:53:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/48c8e1aca3b50f10b1d3375c572ce23fe73688ec', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 31, 'created': '2019-12-17 17:24:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cfff8dee0bd973d724daee7f9a69d064ed0af1db', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 32, 'created': '2019-12-24 01:51:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/81f17531aa23502605188a8ed23789351745aa81', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 33, 'created': '2019-12-24 08:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f78f21ae695a98036b35dc933c36c8d70f745e0f', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 34, 'created': '2019-12-26 06:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a2f6a50106829ef11b46b71642f8b3065308940f', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 35, 'created': '2019-12-26 07:14:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/44c1d04eeb767ad5fcdc9c024d50307ddad65ed4', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 36, 'created': '2019-12-26 21:20:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/46a6f60b9ba029966a7bffcd1330ead3148f34fd', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 37, 'created': '2019-12-27 01:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a8d4916e2953eb97466778f1c91e230eb28114f9', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 38, 'created': '2019-12-27 05:09:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/964d7613346d70e5c4dea7f3c0d0efb696e7f6ed', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 39, 'created': '2019-12-28 06:22:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d3b630e06ac778037e3a64ab254d2270afcb3066', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 40, 'created': '2020-01-06 07:37:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/944a97601d626603f2ea70e755b1b4b75bab43b6', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 41, 'created': '2020-01-06 22:34:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9844c52bc0096177706129821c21213bbc203530', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 42, 'created': '2020-01-07 21:01:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b6d93555d9051bdf01fc9d738905aaa1906ee937', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 43, 'created': '2020-01-07 22:59:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/17a2d30d61a68fe3fb730d52f1f6cfb891fd8990', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 44, 'created': '2020-01-08 03:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4d9827d95dd988caa180c754c8fa07d8ee6b67e9', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 45, 'created': '2020-01-17 18:45:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f64e3452f5b27d9a628755af272647801894220e', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 46, 'created': '2020-01-23 05:36:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/021a81ea6aaa4b0dede315f66b1b52dcef75b699', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 47, 'created': '2020-01-24 03:02:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d256eb9e55bd14c6c00a16a9b368822670fc8d7b', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 48, 'created': '2020-01-24 07:29:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7b536acc31c73438cae38312dd4b345a440cdeca', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 49, 'created': '2020-01-25 01:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7b43ef84064ef572061eae7988f32230c7229f49', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 50, 'created': '2020-01-25 01:40:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7fb9b494d33a4f6fcab5208284bcbf12110d184b', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 51, 'created': '2020-01-27 02:08:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f035a727d7f47184612efcba92ead64db72f219f', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}, {'number': 52, 'created': '2020-01-28 22:00:22.000000000', 'files': ['swift/common/middleware/s3api/controllers/obj.py', 'test/unit/common/middleware/s3api/test_obj.py', 'doc/s3api/conf/ceph-known-failures-tempauth.yaml', 'test/functional/s3api/s3_test_client.py', 'test/unit/common/middleware/s3api/test_bucket.py', 'swift/common/middleware/s3api/controllers/multi_upload.py', 'swift/common/middleware/s3api/controllers/versioning.py', 'test/functional/s3api/test_multi_upload.py', 'test/functional/s3api/test_versioning.py', 'test/unit/common/middleware/s3api/test_multi_upload.py', 'swift/common/middleware/s3api/acl_handlers.py', 'swift/common/middleware/s3api/s3request.py', 'test/unit/common/middleware/s3api/helpers.py', 'test/unit/common/middleware/s3api/test_multi_delete.py', 'doc/source/s3_compat.rst', 'test/unit/common/middleware/s3api/test_versioning.py', 'swift/common/middleware/s3api/s3response.py', 'test/s3api/__init__.py', 'test/s3api/test_versioning.py', 'swift/common/middleware/s3api/controllers/bucket.py', 'swift/common/middleware/s3api/controllers/multi_delete.py', 'doc/s3api/conf/ceph-known-failures-keystone.yaml', 'test/unit/common/middleware/s3api/__init__.py', 'test/functional/__init__.py', 'swift/common/middleware/s3api/utils.py', 'test/functional/s3api/test_object.py', 'test/s3api/test_service.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/6097660f0c350e12c026d62fd2fbd437140b917b', 'message': 's3api: Implement object versioning API\n\nTranslate AWS S3 Object Versioning API requests to native Swift Object\nVersioning API, speficially:\n\n * bucket versioning status\n * bucket versioned objects listing params\n * object GETorHEAD & DELETE versionId\n * multi_delete versionId\n\nChange-Id: I8296681b61996e073b3ba12ad46f99042dc15c37\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n'}]",52,673682,6097660f0c350e12c026d62fd2fbd437140b917b,138,5,52,1179,,,0,"s3api: Implement object versioning API

Translate AWS S3 Object Versioning API requests to native Swift Object
Versioning API, speficially:

 * bucket versioning status
 * bucket versioned objects listing params
 * object GETorHEAD & DELETE versionId
 * multi_delete versionId

Change-Id: I8296681b61996e073b3ba12ad46f99042dc15c37
Co-Authored-By: Tim Burke <tim.burke@gmail.com>
Co-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>
",git fetch https://review.opendev.org/openstack/swift refs/changes/82/673682/4 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/versioned_writes.py', 'swift/common/middleware/s3api/controllers/obj.py', 'test/unit/common/middleware/s3api/test_obj.py', 'doc/s3api/conf/ceph-known-failures-tempauth.yaml', 'test/unit/common/middleware/s3api/test_bucket.py', 'test/unit/common/middleware/s3api/test_utils.py', 'swift/common/middleware/s3api/controllers/versioning.py', 'test/functional/s3api/test_versioning.py', 'swift/common/middleware/s3api/acl_handlers.py', 'swift/common/middleware/s3api/s3request.py', 'test/unit/common/middleware/s3api/test_multi_delete.py', 'test/unit/common/middleware/s3api/test_versioning.py', 'swift/common/middleware/s3api/s3response.py', 'test/s3api/__init__.py', 'test/s3api/test_versioning.py', 'swift/common/middleware/s3api/controllers/bucket.py', 'swift/common/middleware/s3api/controllers/multi_delete.py', 'doc/s3api/conf/ceph-known-failures-keystone.yaml', 'test/unit/common/middleware/test_versioned_writes.py', 'test/unit/common/middleware/s3api/__init__.py', 'test/functional/__init__.py', 'swift/common/middleware/s3api/utils.py', 'test/functional/s3api/test_object.py', 'test/s3api/test_service.py', 'swift/proxy/controllers/base.py']",25,7ef93077691e6c58395028651208822e49432e09,more_tests," 'transient_sysmeta': transient_sysmeta, 'x-timestamp': headers.get('x-timestamp'),", 'transient_sysmeta': transient_sysmeta,1905,243
openstack%2Fnova~master~Ia54b5adf0a125ae1f9b86887a07dd1d79821dd54,openstack/nova,master,Ia54b5adf0a125ae1f9b86887a07dd1d79821dd54,Handle cell failures in get_compute_nodes_by_host_or_node,MERGED,2019-12-20 15:06:59.000000000,2020-01-29 03:55:10.000000000,2020-01-29 03:52:43.000000000,"[{'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 28988}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-20 15:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/890c809b884f4f55fd2480d5e0d5f91c4a71916f', 'message': 'Handle cell failures in get_compute_nodes_by_host_or_node\n\nget_compute_nodes_by_host_or_node uses the scatter_gather_cells\nfunction but was not handling the case that a failure result\nwas returned, which could be the called function raising some\nexception or the cell timing out. This causes issues when the\ncaller of get_compute_nodes_by_host_or_node expects to get a\nComputeNodeList back and can do something like len(nodes) on it\nwhich fails when the result is not iterable.\n\nTo be clear, if a cell is down there are going to be problems\nwhich likely result in a NoValidHost error during scheduling, but\nthis avoids an ugly TypeError traceback in the scheduler logs.\n\nChange-Id: Ia54b5adf0a125ae1f9b86887a07dd1d79821dd54\nCloses-Bug: #1857139\n'}, {'number': 2, 'created': '2019-12-30 12:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0fd6b1bd48e35c95bc09e5af0d2f22ff03b41e4d', 'message': 'Handle cell failures in get_compute_nodes_by_host_or_node\n\nget_compute_nodes_by_host_or_node uses the scatter_gather_cells\nfunction but was not handling the case that a failure result\nwas returned, which could be the called function raising some\nexception or the cell timing out. This causes issues when the\ncaller of get_compute_nodes_by_host_or_node expects to get a\nComputeNodeList back and can do something like len(nodes) on it\nwhich fails when the result is not iterable.\n\nTo be clear, if a cell is down there are going to be problems\nwhich likely result in a NoValidHost error during scheduling, but\nthis avoids an ugly TypeError traceback in the scheduler logs.\n\nChange-Id: Ia54b5adf0a125ae1f9b86887a07dd1d79821dd54\nCloses-Bug: #1857139\n'}, {'number': 3, 'created': '2019-12-30 14:45:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4196fc494c6ab70bb6095c1f810f204f72f75ee4', 'message': 'Handle cell failures in get_compute_nodes_by_host_or_node\n\nget_compute_nodes_by_host_or_node uses the scatter_gather_cells\nfunction but was not handling the case that a failure result\nwas returned, which could be the called function raising some\nexception or the cell timing out. This causes issues when the\ncaller of get_compute_nodes_by_host_or_node expects to get a\nComputeNodeList back and can do something like len(nodes) on it\nwhich fails when the result is not iterable.\n\nTo be clear, if a cell is down there are going to be problems\nwhich likely result in a NoValidHost error during scheduling, but\nthis avoids an ugly TypeError traceback in the scheduler logs.\n\nChange-Id: Ia54b5adf0a125ae1f9b86887a07dd1d79821dd54\nCloses-Bug: #1857139\n'}, {'number': 4, 'created': '2019-12-30 15:56:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/42bc0f9ff42d3273686b817af86f5c2a41dfc0b9', 'message': 'Handle cell failures in get_compute_nodes_by_host_or_node\n\nget_compute_nodes_by_host_or_node uses the scatter_gather_cells\nfunction but was not handling the case that a failure result\nwas returned, which could be the called function raising some\nexception or the cell timing out. This causes issues when the\ncaller of get_compute_nodes_by_host_or_node expects to get a\nComputeNodeList back and can do something like len(nodes) on it\nwhich fails when the result is not iterable.\n\nTo be clear, if a cell is down there are going to be problems\nwhich likely result in a NoValidHost error during scheduling, but\nthis avoids an ugly TypeError traceback in the scheduler logs.\n\nChange-Id: Ia54b5adf0a125ae1f9b86887a07dd1d79821dd54\nCloses-Bug: #1857139\n'}, {'number': 5, 'created': '2019-12-30 16:01:53.000000000', 'files': ['nova/tests/unit/scheduler/test_host_manager.py', 'nova/scheduler/host_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0d9622f581e830e7b7bc9763aaa09ba02e99b8bb', 'message': 'Handle cell failures in get_compute_nodes_by_host_or_node\n\nget_compute_nodes_by_host_or_node uses the scatter_gather_cells\nfunction but was not handling the case that a failure result\nwas returned, which could be the called function raising some\nexception or the cell timing out. This causes issues when the\ncaller of get_compute_nodes_by_host_or_node expects to get a\nComputeNodeList back and can do something like len(nodes) on it\nwhich fails when the result is not iterable.\n\nTo be clear, if a cell is down there are going to be problems\nwhich likely result in a NoValidHost error during scheduling, but\nthis avoids an ugly TypeError traceback in the scheduler logs.\n\nChange-Id: Ia54b5adf0a125ae1f9b86887a07dd1d79821dd54\nCloses-Bug: #1857139\n'}]",4,700186,0d9622f581e830e7b7bc9763aaa09ba02e99b8bb,39,14,5,6873,,,0,"Handle cell failures in get_compute_nodes_by_host_or_node

get_compute_nodes_by_host_or_node uses the scatter_gather_cells
function but was not handling the case that a failure result
was returned, which could be the called function raising some
exception or the cell timing out. This causes issues when the
caller of get_compute_nodes_by_host_or_node expects to get a
ComputeNodeList back and can do something like len(nodes) on it
which fails when the result is not iterable.

To be clear, if a cell is down there are going to be problems
which likely result in a NoValidHost error during scheduling, but
this avoids an ugly TypeError traceback in the scheduler logs.

Change-Id: Ia54b5adf0a125ae1f9b86887a07dd1d79821dd54
Closes-Bug: #1857139
",git fetch https://review.opendev.org/openstack/nova refs/changes/86/700186/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/scheduler/test_host_manager.py', 'nova/scheduler/host_manager.py']",2,890c809b884f4f55fd2480d5e0d5f91c4a71916f,bug/1857139," # has a value; be sure to filter out cell failures. (nodes for nodes in nodes_by_cell.values() if nodes and not context_module.is_cell_failure_sentinel(nodes)),"," # has a value (nodes for nodes in nodes_by_cell.values() if nodes),",21,2
openstack%2Fkeystone~stable%2Ftrain~Iddc364d8c934b6e54d1e8c75b8b159faadbf865d,openstack/keystone,stable/train,Iddc364d8c934b6e54d1e8c75b8b159faadbf865d,Ensure bootstrap handles multiple roles with the same name,MERGED,2019-12-18 18:19:47.000000000,2020-01-29 03:55:05.000000000,2020-01-29 03:52:55.000000000,"[{'_account_id': 1955}, {'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 8866}, {'_account_id': 9954}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-18 18:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/23f6dbb21295eeb0a4e6e7cf3a40996bcf47cddd', 'message': ""Ensure bootstrap handles multiple roles with the same name\n\nThe bootstrap logic doesn't take into consideration multiple roles\nwith the same name. If bootstrap is unable to determine which role to\nuse and accidentally uses a domain-specific role with the same name\nas a default role, bootstrap will fail in unexpected ways.\n\nCloses-Bug: 1856881\nChange-Id: Iddc364d8c934b6e54d1e8c75b8b159faadbf865d\n(cherry picked from commit 0552bf9804adea7ab9b9b8b9485fd6cbff598260)\n""}, {'number': 2, 'created': '2020-01-09 13:51:54.000000000', 'files': ['releasenotes/notes/bug-1856881-277103af343187f1.yaml', 'keystone/cmd/bootstrap.py', 'keystone/tests/unit/test_cli.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/51ff7be731450c183b3e3eb6d34493e986cc2635', 'message': ""Ensure bootstrap handles multiple roles with the same name\n\nThe bootstrap logic doesn't take into consideration multiple roles\nwith the same name. If bootstrap is unable to determine which role to\nuse and accidentally uses a domain-specific role with the same name\nas a default role, bootstrap will fail in unexpected ways.\n\nCloses-Bug: 1856881\nChange-Id: Iddc364d8c934b6e54d1e8c75b8b159faadbf865d\n(cherry picked from commit 25cf359e5fb914b855922121f20e23bd14626b8e)\n""}]",0,699751,51ff7be731450c183b3e3eb6d34493e986cc2635,13,7,2,5046,,,0,"Ensure bootstrap handles multiple roles with the same name

The bootstrap logic doesn't take into consideration multiple roles
with the same name. If bootstrap is unable to determine which role to
use and accidentally uses a domain-specific role with the same name
as a default role, bootstrap will fail in unexpected ways.

Closes-Bug: 1856881
Change-Id: Iddc364d8c934b6e54d1e8c75b8b159faadbf865d
(cherry picked from commit 25cf359e5fb914b855922121f20e23bd14626b8e)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/51/699751/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/cmd/bootstrap.py', 'keystone/tests/unit/test_cli.py']",2,23f6dbb21295eeb0a4e6e7cf3a40996bcf47cddd,," def test_bootstrap_with_ambiguous_role_names(self): # bootstrap system to create the default admin role self._do_test_bootstrap(self.bootstrap) # create a domain-specific roles that share the same names as the # default roles created by keystone-manage bootstrap domain = {'id': uuid.uuid4().hex, 'name': uuid.uuid4().hex} domain = PROVIDERS.resource_api.create_domain(domain['id'], domain) domain_roles = {} for name in ['admin', 'member', 'reader']: domain_role = { 'domain_id': domain['id'], 'id': uuid.uuid4().hex, 'name': name } domain_roles[name] = PROVIDERS.role_api.create_role( domain_role['id'], domain_role ) # ensure subsequent bootstrap attempts don't fail because of # ambiguity self._do_test_bootstrap(self.bootstrap) # clean up the role so we don't hit it again on the next run PROVIDERS.role_api.delete_role(domain_role['id'])",,33,1
openstack%2Fneutron~stable%2Fstein~I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f,openstack/neutron,stable/stein,I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f,DVR: Ignore DHCP port during DVR host query,MERGED,2020-01-02 23:52:07.000000000,2020-01-29 03:54:36.000000000,2020-01-29 03:52:38.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 9531}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 29071}]","[{'number': 1, 'created': '2020-01-02 23:52:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8f6efd0b7c34264276a438e0215758c2dddfa3a4', 'message': ""DVR: Ignore DHCP port during DVR host query\n\nFor large scale deployment, the dvr router will be installed to\nthe scheduled DHCP host. This will definitely increase the l3\nagent service pressure, especially in large number of concurrent\nupdates, creation, or agent restart.\n\nThis patch adds a config ``host_dvr_for_dhcp`` for the DHCP port\ndevice_owner filter during DVR host query. Then if we set\n``host_dvr_for_dhcp = False``, L3-agent will not host the DVR router\nnamespace in its connected networks' DHCP agent hosts.\n\nCloses-Bug: #1609217\nChange-Id: I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f\n(cherry picked from commit 8f057fb49ac637bd0dbf60ca07b89f0e4a59c7b7)\n""}, {'number': 2, 'created': '2020-01-04 00:21:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0c5d47830a70d768904fbff022f80df8562799db', 'message': ""DVR: Ignore DHCP port during DVR host query\n\nFor large scale deployment, the dvr router will be installed to\nthe scheduled DHCP host. This will definitely increase the l3\nagent service pressure, especially in large number of concurrent\nupdates, creation, or agent restart.\n\nThis patch adds a config ``host_dvr_for_dhcp`` for the DHCP port\ndevice_owner filter during DVR host query. Then if we set\n``host_dvr_for_dhcp = False``, L3-agent will not host the DVR router\nnamespace in its connected networks' DHCP agent hosts.\n\nCloses-Bug: #1609217\nChange-Id: I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f\n(cherry picked from commit 8f057fb49ac637bd0dbf60ca07b89f0e4a59c7b7)\n""}, {'number': 4, 'created': '2020-01-21 00:36:48.000000000', 'files': ['neutron/db/l3_dvrscheduler_db.py', 'neutron/db/dvr_mac_db.py', 'releasenotes/notes/config-host_dvr_for_dhcp-f949aca5bd666e24.yaml', 'doc/source/admin/deploy-ovs-ha-dvr.rst', 'neutron/common/utils.py', 'neutron/conf/db/l3_dvr_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/50fdc6505f22758e6d0d4ccf01b3c13ca2a93153', 'message': ""DVR: Ignore DHCP port during DVR host query\n\nFor large scale deployment, the dvr router will be installed to\nthe scheduled DHCP host. This will definitely increase the l3\nagent service pressure, especially in large number of concurrent\nupdates, creation, or agent restart.\n\nThis patch adds a config ``host_dvr_for_dhcp`` for the DHCP port\ndevice_owner filter during DVR host query. Then if we set\n``host_dvr_for_dhcp = False``, L3-agent will not host the DVR router\nnamespace in its connected networks' DHCP agent hosts.\n\nCloses-Bug: #1609217\nChange-Id: I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f\n(cherry picked from commit 8f057fb49ac637bd0dbf60ca07b89f0e4a59c7b7)\n""}]",0,700955,50fdc6505f22758e6d0d4ccf01b3c13ca2a93153,53,7,3,29071,,,0,"DVR: Ignore DHCP port during DVR host query

For large scale deployment, the dvr router will be installed to
the scheduled DHCP host. This will definitely increase the l3
agent service pressure, especially in large number of concurrent
updates, creation, or agent restart.

This patch adds a config ``host_dvr_for_dhcp`` for the DHCP port
device_owner filter during DVR host query. Then if we set
``host_dvr_for_dhcp = False``, L3-agent will not host the DVR router
namespace in its connected networks' DHCP agent hosts.

Closes-Bug: #1609217
Change-Id: I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f
(cherry picked from commit 8f057fb49ac637bd0dbf60ca07b89f0e4a59c7b7)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/55/700955/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_dvrscheduler_db.py', 'neutron/db/dvr_mac_db.py', 'releasenotes/notes/config-host_dvr_for_dhcp-f949aca5bd666e24.yaml', 'doc/source/admin/deploy-ovs-ha-dvr.rst', 'neutron/common/utils.py', 'neutron/conf/db/l3_dvr_db.py']",6,8f6efd0b7c34264276a438e0215758c2dddfa3a4,bug/1609217-stable/stein," cfg.BoolOpt('host_dvr_for_dhcp', default=True, help=_(""Flag to determine if hosting a DVR local router to "" ""the DHCP agent is desired. If False, any L3 function "" ""supported by the DHCP agent instance will not be "" ""possible, for instance: DNS."")),",,40,9
openstack%2Fswift~master~If23592855db5f5bb0ec1e7c679de15769fd86871,openstack/swift,master,If23592855db5f5bb0ec1e7c679de15769fd86871,Add a note to the part power increase documentation,MERGED,2020-01-28 18:52:37.000000000,2020-01-29 03:54:27.000000000,2020-01-29 03:52:40.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-28 18:52:37.000000000', 'files': ['doc/source/ring_partpower.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/ebaf154fc4d7f91ff704ca2367556c137ed52137', 'message': 'Add a note to the part power increase documentation\n\nSpecify that the relink command must be run as the same user than the\ndaemon processes to avoid creating files that are not manipulable by the\nserver/replicator/...\n\nChange-Id: If23592855db5f5bb0ec1e7c679de15769fd86871\n'}]",0,704662,ebaf154fc4d7f91ff704ca2367556c137ed52137,7,2,1,13852,,,0,"Add a note to the part power increase documentation

Specify that the relink command must be run as the same user than the
daemon processes to avoid creating files that are not manipulable by the
server/replicator/...

Change-Id: If23592855db5f5bb0ec1e7c679de15769fd86871
",git fetch https://review.opendev.org/openstack/swift refs/changes/62/704662/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/ring_partpower.rst'],1,ebaf154fc4d7f91ff704ca2367556c137ed52137,docRelinker,".. note:: The relinking command must run as the same user as the daemon processes (usually swift). It will create files and directories that must be manipulable by the daemon processes (server, auditor, replicator, ...). ",,6,0
openstack%2Fneutron~stable%2Fqueens~I72dc4a06a806731ec5124fa11c9f69c7dd6cbbb0,openstack/neutron,stable/queens,I72dc4a06a806731ec5124fa11c9f69c7dd6cbbb0,[L3] Switch order of processing added and removed router ports,MERGED,2020-01-10 08:11:27.000000000,2020-01-29 03:53:02.000000000,2020-01-29 03:53:02.000000000,"[{'_account_id': 4694}, {'_account_id': 8556}, {'_account_id': 9732}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-10 08:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/839eb1a290aff9e3e5b76528ccd3fbf12d25c611', 'message': ""[L3] Switch order of processing added and removed router ports\n\nIt may happend that one router's port is going to be\nremoved and another one (same IP but new subnet) is going to be added\nto the router in short time.\nThat can lead to the problem that IP which is allocated to the new\nport is not added to keepalived's vips list because same IP address\nis already in this list (this exising IP address belongs to old port).\nBut few seconds later old port is removed and finally router ends\nup with new port configured without IP address.\n\nTo avoid such case, this patch switches order of processing new\nand deleted ports in _process_internal_ports() method in RouterInfo\nclass.\nSo now first old ports will be removed and than new ports will be\nconfigured so there will be no case when IP address is already added\nto VIPs list when it is going to be removed in few seconds.\n\nChange-Id: I72dc4a06a806731ec5124fa11c9f69c7dd6cbbb0\nCloses-Bug: #1857021\n(cherry picked from commit 3faba7cae0c5f0b8ac93c025ca057e2f533445cf)\n""}, {'number': 2, 'created': '2020-01-16 14:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/74899bd37447e1082d14ac0e73185b7a5d234b81', 'message': ""[L3] Switch order of processing added and removed router ports\n\nIt may happend that one router's port is going to be\nremoved and another one (same IP but new subnet) is going to be added\nto the router in short time.\nThat can lead to the problem that IP which is allocated to the new\nport is not added to keepalived's vips list because same IP address\nis already in this list (this exising IP address belongs to old port).\nBut few seconds later old port is removed and finally router ends\nup with new port configured without IP address.\n\nTo avoid such case, this patch switches order of processing new\nand deleted ports in _process_internal_ports() method in RouterInfo\nclass.\nSo now first old ports will be removed and than new ports will be\nconfigured so there will be no case when IP address is already added\nto VIPs list when it is going to be removed in few seconds.\n\nDepends-On: https://review.opendev.org/702868\nChange-Id: I72dc4a06a806731ec5124fa11c9f69c7dd6cbbb0\nCloses-Bug: #1857021\n(cherry picked from commit 3faba7cae0c5f0b8ac93c025ca057e2f533445cf)\n""}, {'number': 3, 'created': '2020-01-26 11:47:30.000000000', 'files': ['neutron/agent/l3/router_info.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a9b491a5ed58f4ec22f9e93e7d921c8e92406544', 'message': ""[L3] Switch order of processing added and removed router ports\n\nIt may happend that one router's port is going to be\nremoved and another one (same IP but new subnet) is going to be added\nto the router in short time.\nThat can lead to the problem that IP which is allocated to the new\nport is not added to keepalived's vips list because same IP address\nis already in this list (this exising IP address belongs to old port).\nBut few seconds later old port is removed and finally router ends\nup with new port configured without IP address.\n\nTo avoid such case, this patch switches order of processing new\nand deleted ports in _process_internal_ports() method in RouterInfo\nclass.\nSo now first old ports will be removed and than new ports will be\nconfigured so there will be no case when IP address is already added\nto VIPs list when it is going to be removed in few seconds.\n\nChange-Id: I72dc4a06a806731ec5124fa11c9f69c7dd6cbbb0\nCloses-Bug: #1857021\n(cherry picked from commit 3faba7cae0c5f0b8ac93c025ca057e2f533445cf)\n""}]",0,701900,a9b491a5ed58f4ec22f9e93e7d921c8e92406544,49,7,3,11975,,,0,"[L3] Switch order of processing added and removed router ports

It may happend that one router's port is going to be
removed and another one (same IP but new subnet) is going to be added
to the router in short time.
That can lead to the problem that IP which is allocated to the new
port is not added to keepalived's vips list because same IP address
is already in this list (this exising IP address belongs to old port).
But few seconds later old port is removed and finally router ends
up with new port configured without IP address.

To avoid such case, this patch switches order of processing new
and deleted ports in _process_internal_ports() method in RouterInfo
class.
So now first old ports will be removed and than new ports will be
configured so there will be no case when IP address is already added
to VIPs list when it is going to be removed in few seconds.

Change-Id: I72dc4a06a806731ec5124fa11c9f69c7dd6cbbb0
Closes-Bug: #1857021
(cherry picked from commit 3faba7cae0c5f0b8ac93c025ca057e2f533445cf)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/00/701900/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3/router_info.py'],1,839eb1a290aff9e3e5b76528ccd3fbf12d25c611,bug/1857021-stable/queens," for p in old_ports: self.internal_network_removed(p) LOG.debug(""removing port %s from internal_ports cache"", p) self.internal_ports.remove(p) enable_ra = enable_ra or self._port_has_ipv6_subnet(p) for subnet in p['subnets']: if ipv6_utils.is_ipv6_pd_enabled(subnet): self.agent.pd.disable_subnet(self.router_id, subnet['id']) del self.pd_subnets[subnet['id']] "," for p in old_ports: self.internal_network_removed(p) LOG.debug(""removing port %s from internal_ports cache"", p) self.internal_ports.remove(p) enable_ra = enable_ra or self._port_has_ipv6_subnet(p) for subnet in p['subnets']: if ipv6_utils.is_ipv6_pd_enabled(subnet): self.agent.pd.disable_subnet(self.router_id, subnet['id']) del self.pd_subnets[subnet['id']] ",10,10
openstack%2Ftripleo-operator-ansible~master~I2066ef542acc0b339f8eb9c3477f68989e44f4c9,openstack/tripleo-operator-ansible,master,I2066ef542acc0b339f8eb9c3477f68989e44f4c9,Add overcloud export role,MERGED,2020-01-21 22:30:13.000000000,2020-01-29 03:28:00.000000000,2020-01-29 03:27:59.000000000,"[{'_account_id': 3153}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-21 22:30:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/cf33866a5fe6ac0209f9779ee2a653352b6bbcf6', 'message': 'Add overcloud export role\n\nAdds tripleo_overcloud_export role to run the overcloud export action.\n\nChange-Id: I2066ef542acc0b339f8eb9c3477f68989e44f4c9\n'}, {'number': 2, 'created': '2020-01-21 22:57:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/1f7e4ebf5871d6618654a40575c325dfb48dc4a5', 'message': 'Add overcloud export role\n\nAdds tripleo_overcloud_export role to run the overcloud export action.\n\nChange-Id: I2066ef542acc0b339f8eb9c3477f68989e44f4c9\n'}, {'number': 3, 'created': '2020-01-28 18:34:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/e613c7871e5ef2224f5dfe7cea0b5c64205eae2b', 'message': 'Add overcloud export role\n\nAdds tripleo_overcloud_export role to run the overcloud export action.\n\nChange-Id: I2066ef542acc0b339f8eb9c3477f68989e44f4c9\n'}, {'number': 4, 'created': '2020-01-28 19:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/27bc5ff3c33be34ee723a8264ad6c4e06f2bb987', 'message': 'Add overcloud export role\n\nAdds tripleo_overcloud_export role to run the overcloud export action.\n\nChange-Id: I2066ef542acc0b339f8eb9c3477f68989e44f4c9\n'}, {'number': 5, 'created': '2020-01-28 19:54:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/7bbe546aaafcb8e394e6a4a7346cf80ffbf901e5', 'message': 'Add overcloud export role\n\nAdds tripleo_overcloud_export role to run the overcloud export action.\n\nChange-Id: I2066ef542acc0b339f8eb9c3477f68989e44f4c9\n'}, {'number': 6, 'created': '2020-01-28 19:55:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/205f49ded2388a129fe90e6e5b1d16d155a22184', 'message': 'Add overcloud export role\n\nAdds tripleo_overcloud_export role to run the overcloud export action.\n\nChange-Id: I2066ef542acc0b339f8eb9c3477f68989e44f4c9\n'}, {'number': 7, 'created': '2020-01-28 20:15:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/9cce32f463aee3e86b70333b9a827ff1b8ac1f0e', 'message': 'Add overcloud export role\n\nAdds tripleo_overcloud_export role to run the overcloud export action.\n\nChange-Id: I2066ef542acc0b339f8eb9c3477f68989e44f4c9\n'}, {'number': 8, 'created': '2020-01-28 20:36:22.000000000', 'files': ['roles/tripleo_overcloud_export/defaults/main.yml', 'roles/tripleo_overcloud_export/tests/inventory', 'zuul.d/molecule.yaml', 'roles/tripleo_overcloud_export/molecule/default/molecule.yml', 'roles/tripleo_overcloud_export/tasks/main.yml', 'roles/tripleo_overcloud_export/tests/test.yml', 'roles/tripleo_overcloud_export/README.md', 'roles/tripleo_overcloud_export/meta/main.yml', 'roles/tripleo_overcloud_export/molecule/default/playbook.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/110e58deb8483b807681cb5bb5a660cd7a02bc32', 'message': 'Add overcloud export role\n\nAdds tripleo_overcloud_export role to run the overcloud export action.\n\nChange-Id: I2066ef542acc0b339f8eb9c3477f68989e44f4c9\n'}]",0,703704,110e58deb8483b807681cb5bb5a660cd7a02bc32,22,4,8,14985,,,0,"Add overcloud export role

Adds tripleo_overcloud_export role to run the overcloud export action.

Change-Id: I2066ef542acc0b339f8eb9c3477f68989e44f4c9
",git fetch https://review.opendev.org/openstack/tripleo-operator-ansible refs/changes/04/703704/8 && git format-patch -1 --stdout FETCH_HEAD,"['roles/tripleo_overcloud_export/defaults/main.yml', 'roles/tripleo_overcloud_export/tests/inventory', 'roles/tripleo_overcloud_export/tasks/main.yml', 'roles/tripleo_overcloud_export/tests/test.yml', 'roles/tripleo_overcloud_export/README.md', 'roles/tripleo_overcloud_export/meta/main.yml']",6,cf33866a5fe6ac0209f9779ee2a653352b6bbcf6,tripleo-overcloud-export,"--- # Copyright 2019 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. galaxy_info: author: OpenStack description: TripleO Operator Role -- tripleo_overcloud_export company: Red Hat license: Apache-2.0 min_ansible_version: 2.8 # # Provide a list of supported platforms, and for each platform a list of versions. # If you don't wish to enumerate all versions for a particular platform, use 'all'. # To view available platforms and versions (or releases), visit: # https://galaxy.ansible.com/api/v1/platforms/ # platforms: - name: CentOS versions: - 7 - 8 galaxy_tags: - tripleo # List your role dependencies here, one per line. Be sure to remove the '[]' above, # if you add dependencies to this list. dependencies: [] ",,140,0
openstack%2Fpython-tripleoclient~stable%2Ftrain~Ia4d064d7b039ef3afcee38de8ad1aa47f035a263,openstack/python-tripleoclient,stable/train,Ia4d064d7b039ef3afcee38de8ad1aa47f035a263,Complete overcloud deploy --baremetal-deployment,MERGED,2020-01-07 21:55:12.000000000,2020-01-29 03:15:01.000000000,2020-01-29 03:12:42.000000000,"[{'_account_id': 3153}, {'_account_id': 4571}, {'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-07 21:55:12.000000000', 'files': ['tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'tripleoclient/v1/overcloud_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6acea63122a13118af4c64a106ac03cded875cd7', 'message': 'Complete overcloud deploy --baremetal-deployment\n\nThe overcloud deploy --baremetal-deployment argument is an alternative\nto calling the provision and unprovision commands separately, giving\nusers the option of only needing to call overcloud deploy to also\nmanage baremetal.\n\nThis change does the following:\n- adds the missing plan argument to deploy_roles to support\n  multi-overcloud\n- calls undeploy_roles after the heat stack operation, to unprovision\n  any nodes that are flagged as provisioned:false\n\nThis is a medium-risk backport because overcloud deploy is frequently\nrun, but the code-path is only used when the --baremetal-deployment\nargument is passed (which is not documented in stable/train)\n\nBlueprint: nova-less-deploy\nChange-Id: Ia4d064d7b039ef3afcee38de8ad1aa47f035a263\n(cherry picked from commit 69aad030d3e1808826ddda37ab47290d1925b6fe)\n'}]",0,701463,6acea63122a13118af4c64a106ac03cded875cd7,19,5,1,4571,,,0,"Complete overcloud deploy --baremetal-deployment

The overcloud deploy --baremetal-deployment argument is an alternative
to calling the provision and unprovision commands separately, giving
users the option of only needing to call overcloud deploy to also
manage baremetal.

This change does the following:
- adds the missing plan argument to deploy_roles to support
  multi-overcloud
- calls undeploy_roles after the heat stack operation, to unprovision
  any nodes that are flagged as provisioned:false

This is a medium-risk backport because overcloud deploy is frequently
run, but the code-path is only used when the --baremetal-deployment
argument is passed (which is not documented in stable/train)

Blueprint: nova-less-deploy
Change-Id: Ia4d064d7b039ef3afcee38de8ad1aa47f035a263
(cherry picked from commit 69aad030d3e1808826ddda37ab47290d1925b6fe)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/63/701463/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'tripleoclient/v1/overcloud_deploy.py']",2,6acea63122a13118af4c64a106ac03cded875cd7,train-bp/nova-less-deploy," self._unprovision_baremetal(parsed_args) plan=parsed_args.stack, def _unprovision_baremetal(self, parsed_args): if not parsed_args.baremetal_deployment: return with open(parsed_args.baremetal_deployment, 'r') as fp: roles = yaml.safe_load(fp) baremetal.undeploy_roles( self.app.client_manager, plan=parsed_args.stack, roles=roles ) ",,28,1
openstack%2Fpython-tripleoclient~stable%2Ftrain~I25c5311ec3599e0de9bd87038366ed8c7d7896a2,openstack/python-tripleoclient,stable/train,I25c5311ec3599e0de9bd87038366ed8c7d7896a2,Improvements to unprovision command,MERGED,2020-01-07 21:55:12.000000000,2020-01-29 03:14:02.000000000,2020-01-29 03:12:41.000000000,"[{'_account_id': 3153}, {'_account_id': 4571}, {'_account_id': 9592}, {'_account_id': 10239}, {'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-07 21:55:12.000000000', 'files': ['tripleoclient/workflows/baremetal.py', 'tripleoclient/tests/v1/overcloud_node/test_overcloud_node.py', 'tripleoclient/v1/overcloud_node.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f15890bdffc2a0283030a773062605acd4de086d', 'message': 'Improvements to unprovision command\n\n- print a table of baremetal nodes which are about to be unprovisioned\n- prompt user to confirm unprovision, overridable with --yes argument\n- add an -all argument which will unprovision all nodes in the yaml,\n  instead of just the provisioned:false nodes.\n- add the missing plan argument to the provision deploy_roles to\n  support multiple overcloud stacks\n\nThis is a low-risk backport as the unprovision command is unused in\nstable/train.\n\nBlueprint: nova-less-undercloud\n\nChange-Id: I25c5311ec3599e0de9bd87038366ed8c7d7896a2\n(cherry picked from commit 4a568fd7ea36907911452bc8ed3c094c5274d98e)\n'}]",0,701462,f15890bdffc2a0283030a773062605acd4de086d,21,7,1,4571,,,0,"Improvements to unprovision command

- print a table of baremetal nodes which are about to be unprovisioned
- prompt user to confirm unprovision, overridable with --yes argument
- add an -all argument which will unprovision all nodes in the yaml,
  instead of just the provisioned:false nodes.
- add the missing plan argument to the provision deploy_roles to
  support multiple overcloud stacks

This is a low-risk backport as the unprovision command is unused in
stable/train.

Blueprint: nova-less-undercloud

Change-Id: I25c5311ec3599e0de9bd87038366ed8c7d7896a2
(cherry picked from commit 4a568fd7ea36907911452bc8ed3c094c5274d98e)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/62/701462/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/workflows/baremetal.py', 'tripleoclient/tests/v1/overcloud_node/test_overcloud_node.py', 'tripleoclient/v1/overcloud_node.py']",3,f15890bdffc2a0283030a773062605acd4de086d,train-bp/nova-less-deploy,"import collectionsimport sys from cliff.formatters import table plan=parsed_args.stack, parser.add_argument('--stack', dest='stack', help=_('Name or ID of heat stack ' '(default=Env: OVERCLOUD_STACK_NAME)'), default=utils.env('OVERCLOUD_STACK_NAME', default='overcloud')) parser.add_argument('--all', help=_('Unprovision every instance in the ' 'deployment'), default=False, action=""store_true"") parser.add_argument('-y', '--yes', help=_('Skip yes/no prompt (assume yes)'), default=False, action=""store_true"") nodes = [] expanded = baremetal.expand_roles( self.app.client_manager, roles=roles, stackname=parsed_args.stack, provisioned=False) nodes.extend(expanded.get('instances', [])) if parsed_args.all: expanded = baremetal.expand_roles( self.app.client_manager, roles=roles, stackname=parsed_args.stack, provisioned=True) nodes.extend(expanded.get('instances', [])) if not nodes: print('No nodes to unprovision') return self._print_nodes(nodes) if not parsed_args.yes: confirm = oooutils.prompt_user_for_confirmation( message=_(""Are you sure you want to unprovision these %s "" ""nodes [y/N]? "") % parsed_args.stack, logger=self.log) if not confirm: raise oscexc.CommandError(""Action not confirmed, exiting."") unprovision_role = self._build_unprovision_role(nodes) print('Unprovisioning %d nodes' % len(nodes)) roles=unprovision_role, plan=parsed_args.stack) def _build_unprovision_role(self, nodes): # build a fake role called Unprovisioned which has an instance # entry for every node to be unprovisioned instances = [{'hostname': n['hostname'], 'provisioned': False} for n in nodes if 'hostname' in n] return [{ 'name': 'Unprovisioned', 'count': 0, 'instances': instances }] def _print_nodes(self, nodes): TableArgs = collections.namedtuple( 'TableArgs', 'print_empty max_width fit_width') args = TableArgs(print_empty=True, max_width=80, fit_width=True) nodes_data = [(i.get('hostname', ''), i.get('name', '')) for i in nodes] formatter = table.TableFormatter() formatter.emit_list( column_names=['hostname', 'name'], data=nodes_data, stdout=sys.stdout, parsed_args=args )", # TODO(sbaker) call ExpandRolesAction to get a list of # instances being unprovisioned to prompt for confirmation roles=roles),164,7
openstack%2Fansible-role-collect-logs~master~If5cb792f24e6151998a56ef1cd649b863b75a3d2,openstack/ansible-role-collect-logs,master,If5cb792f24e6151998a56ef1cd649b863b75a3d2,Assure we respect artcl_gzip parameter,MERGED,2020-01-28 18:11:33.000000000,2020-01-29 02:26:47.000000000,2020-01-29 02:26:47.000000000,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2020-01-28 18:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/97dd81901a3787cd126313454bf8cdaa8def4e6a', 'message': 'Assure we respect artcl_gzip parameter\n\nFollow-up on previous change which ignored artcl_gzip value.\n\nChange-Id: If5cb792f24e6151998a56ef1cd649b863b75a3d2\n'}, {'number': 2, 'created': '2020-01-28 20:50:18.000000000', 'files': ['tasks/collect.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/f68cf6aa7833bb83a8a970c5a9e77de22c9a954c', 'message': 'Assure we respect artcl_gzip parameter\n\nFollow-up on previous change which ignored artcl_gzip value.\n\nChange-Id: If5cb792f24e6151998a56ef1cd649b863b75a3d2\n'}]",2,704649,f68cf6aa7833bb83a8a970c5a9e77de22c9a954c,12,8,2,24162,,,0,"Assure we respect artcl_gzip parameter

Follow-up on previous change which ignored artcl_gzip value.

Change-Id: If5cb792f24e6151998a56ef1cd649b863b75a3d2
",git fetch https://review.opendev.org/openstack/ansible-role-collect-logs refs/changes/49/704649/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/collect.yml'],1,97dd81901a3787cd126313454bf8cdaa8def4e6a,gzip, when: artcl_gzip,,1,0
openstack%2Ftempest~master~Idc76e07efdd3710a59c773c564ca532419989ed5,openstack/tempest,master,Idc76e07efdd3710a59c773c564ca532419989ed5,Add doc for supported OpenStack release & py version,MERGED,2019-10-09 03:08:24.000000000,2020-01-29 02:10:23.000000000,2020-01-26 00:26:50.000000000,"[{'_account_id': 5689}, {'_account_id': 8556}, {'_account_id': 17130}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 23186}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-09 03:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/05d63e6d54009e6e44680661f5b37d22ee92ecf3', 'message': 'Add doc for supported OpenStack release & py version\n\nTempest is branchless and support many OpenStack stable branches\nand python versions. Users of Tempest should have a clear doc about\nwhat all openstack releases and python versions are supported.\n\nChange-Id: Idc76e07efdd3710a59c773c564ca532419989ed5\n'}, {'number': 2, 'created': '2019-10-09 03:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/aadd041ba865dbac40e1d58b225acd82bb7105eb', 'message': 'Add doc for supported OpenStack release & py version\n\nTempest is branchless and support many OpenStack stable branches\nand python versions. Users of Tempest should have a clear doc about\nwhat all openstack releases and python versions are supported.\n\nChange-Id: Idc76e07efdd3710a59c773c564ca532419989ed5\n'}, {'number': 3, 'created': '2019-10-09 03:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/96d485ba947200052aed32f1610b7b9b699124ad', 'message': 'Add doc for supported OpenStack release & py version\n\nTempest is branchless and support many OpenStack stable branches\nand python versions. Users of Tempest should have a clear doc about\nwhat all openstack releases and python versions are supported.\n\nChange-Id: Idc76e07efdd3710a59c773c564ca532419989ed5\n'}, {'number': 4, 'created': '2019-10-09 03:29:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1a531fb252e9d1c38941644b2684a256794a6ad5', 'message': 'Add doc for supported OpenStack release & py version\n\nTempest is branchless and support many OpenStack stable branches\nand python versions. Users of Tempest should have a clear doc about\nwhat all openstack releases and python versions are supported.\n\nChange-Id: Idc76e07efdd3710a59c773c564ca532419989ed5\n'}, {'number': 5, 'created': '2020-01-23 00:57:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/587308795a9de6b5de2510d6cf28e89dd9e16eaf', 'message': 'Add doc for supported OpenStack release & py version\n\nTempest is branchless and support many OpenStack stable branches\nand python versions. Users of Tempest should have a clear doc about\nwhat all openstack releases and python versions are supported.\n\nChange-Id: Idc76e07efdd3710a59c773c564ca532419989ed5\n'}, {'number': 6, 'created': '2020-01-23 14:39:40.000000000', 'files': ['doc/source/index.rst', 'doc/source/supported_version.rst'], 'web_link': 'https://opendev.org/openstack/tempest/commit/68600b18faf6c24614e22f1f0081ba0b8d38a0be', 'message': 'Add doc for supported OpenStack release & py version\n\nTempest is branchless and support many OpenStack stable branches\nand python versions. Users of Tempest should have a clear doc about\nwhat all openstack releases and python versions are supported.\n\nChange-Id: Idc76e07efdd3710a59c773c564ca532419989ed5\n'}]",28,687448,68600b18faf6c24614e22f1f0081ba0b8d38a0be,26,7,6,8556,,,0,"Add doc for supported OpenStack release & py version

Tempest is branchless and support many OpenStack stable branches
and python versions. Users of Tempest should have a clear doc about
what all openstack releases and python versions are supported.

Change-Id: Idc76e07efdd3710a59c773c564ca532419989ed5
",git fetch https://review.opendev.org/openstack/tempest refs/changes/48/687448/6 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/supported_version.rst']",2,05d63e6d54009e6e44680661f5b37d22ee92ecf3,,"Compatible OpenStack Release ============================ Tempest master supports the below OpenStack Releases: * Train * Stein * Rocky * Queens For older OpenStack Release: For any older OpenStack Release than the listed above, Tempest master might work. But if Tempest master start failing then, you can use the respective Tempest tag listed in OpenStack release page. For example: OpenStack Stein: Tempest 20.0.0 https://releases.openstack.org/stein/index.html#stein-tempest Supported Python Version ======================== Tempest master support the below python version: * Python 2.7 * Python 3.5 * Python 3.6 * Python 3.7 ",,38,1
openstack%2Ftripleo-operator-ansible~master~I34b19ce71f88901d87c602f98ca6f274b61d1f82,openstack/tripleo-operator-ansible,master,I34b19ce71f88901d87c602f98ca6f274b61d1f82,Enabled markdownlint,MERGED,2020-01-27 20:51:59.000000000,2020-01-29 02:07:58.000000000,2020-01-29 02:07:58.000000000,"[{'_account_id': 3153}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-27 20:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/35f54d08a80a1c7c2727b5d638704114a01e47b4', 'message': 'Enabled markdownlint\n\nChange-Id: I34b19ce71f88901d87c602f98ca6f274b61d1f82\n'}, {'number': 2, 'created': '2020-01-28 11:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/e54e061475f04809cac7ab941027e032d458e569', 'message': 'Enabled markdownlint\n\nChange-Id: I34b19ce71f88901d87c602f98ca6f274b61d1f82\n'}, {'number': 3, 'created': '2020-01-28 12:55:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/ba751d4edab636cf655a4b1aacf899ad7da768c3', 'message': 'Enabled markdownlint\n\nChange-Id: I34b19ce71f88901d87c602f98ca6f274b61d1f82\n'}, {'number': 4, 'created': '2020-01-28 13:11:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/bb4d04b6aea2134e9fb319960bede8fc4b66f6ea', 'message': 'Enabled markdownlint\n\nChange-Id: I34b19ce71f88901d87c602f98ca6f274b61d1f82\n'}, {'number': 5, 'created': '2020-01-28 13:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/4d44fd4ad5e4b7ad56eef6158d0f9983cbc47d21', 'message': 'Enabled markdownlint\n\nChange-Id: I34b19ce71f88901d87c602f98ca6f274b61d1f82\n'}, {'number': 6, 'created': '2020-01-28 13:27:43.000000000', 'files': ['roles/tripleo_container_image_prepare/README.md', 'roles/tripleo_repos/README.md', 'roles/tripleo_container_image_delete/README.md', 'roles/tripleo_container_image_list/README.md', 'roles/tripleo_undercloud_install/README.md', 'roles/tripleo_container_image_show/README.md', 'roles/README.md', 'roles/tripleo_undercloud_upgrade/README.md', 'roles/tripleo_container_image_push/README.md', '.pre-commit-config.yaml', 'README.md', 'bindep.txt', 'roles/tripleo_overcloud_node_introspect/README.md', '.mdlrc', 'roles/tripleo_undercloud_minion_upgrade/README.md', 'roles/tripleo_undercloud_minion_install/README.md', 'roles/tripleo_container_image_prepare_default/README.md', 'roles/tripleo_undercloud_backup/README.md', 'roles/tripleo_config_generate_ansible/README.md'], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/f2467db214b9029185b30075fbc7edb2e2cd046f', 'message': 'Enabled markdownlint\n\nChange-Id: I34b19ce71f88901d87c602f98ca6f274b61d1f82\n'}]",0,704423,f2467db214b9029185b30075fbc7edb2e2cd046f,20,4,6,24162,,,0,"Enabled markdownlint

Change-Id: I34b19ce71f88901d87c602f98ca6f274b61d1f82
",git fetch https://review.opendev.org/openstack/tripleo-operator-ansible refs/changes/23/704423/6 && git format-patch -1 --stdout FETCH_HEAD,"['roles/tripleo_container_image_prepare/README.md', 'roles/tripleo_repos/README.md', 'roles/tripleo_container_image_delete/README.md', 'roles/tripleo_container_image_list/README.md', 'roles/tripleo_undercloud_install/README.md', 'roles/tripleo_container_image_show/README.md', 'roles/README.md', 'roles/tripleo_undercloud_upgrade/README.md', 'roles/tripleo_container_image_push/README.md', '.pre-commit-config.yaml', 'README.md', '.mdlrc', 'roles/tripleo_undercloud_minion_upgrade/README.md', 'roles/tripleo_undercloud_minion_install/README.md', 'roles/tripleo_container_image_prepare_default/README.md', 'roles/tripleo_undercloud_backup/README.md', 'roles/tripleo_config_generate_ansible/README.md']",17,35f54d08a80a1c7c2727b5d638704114a01e47b4,,```yaml - hosts: undercloud gather_facts: true tasks: - name: Generate default ansible config import_role: name: tripleo_config_generate_ansible ```, - hosts: undercloud gather_facts: true tasks: - name: Generate default ansible config import_role: name: tripleo_config_generate_ansible,203,175
openstack%2Fpython-tripleoclient~master~I054a805e820087a30bd8d27a0b460b6e519849ac,openstack/python-tripleoclient,master,I054a805e820087a30bd8d27a0b460b6e519849ac,Move undercloud backup from mistral to ansible,MERGED,2019-06-17 14:31:23.000000000,2020-01-29 01:55:25.000000000,2020-01-29 01:54:03.000000000,"[{'_account_id': 4571}, {'_account_id': 7144}, {'_account_id': 7353}, {'_account_id': 9712}, {'_account_id': 11491}, {'_account_id': 14985}, {'_account_id': 15895}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-06-17 14:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/9ad7202d5a44345fd86a62e5742c682db86602ba', 'message': 'Move undercloud backup from ansible to mistral\n\nDepends-on: Ie09fda68b631725c3667961d271ae627d1f89038\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\n'}, {'number': 2, 'created': '2019-06-20 09:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/7e75856d73993da427f5d6955b6b491459c9cee1', 'message': 'Move undercloud backup from ansible to mistral\n\nDepends-on: Ie09fda68b631725c3667961d271ae627d1f89038\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\n'}, {'number': 3, 'created': '2019-08-02 17:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/8646958322905f9281e0d6f69694182d9d460084', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name.\nIt adds the functionality discussed on this external bug\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem\n\nDepends-on: Icf964c23745941dd596f65e2b0bfa81e515508d0\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\n'}, {'number': 4, 'created': '2019-08-05 08:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b5672d714457b7ee743dcebab2fc61c50e1976be', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name.\nIt adds the functionality discussed on this external bug\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem\n\nDepends-on: Icf964c23745941dd596f65e2b0bfa81e515508d0\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\n'}, {'number': 5, 'created': '2019-11-04 12:12:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/705755b7550bf6a8cdbcca8e843c034c4c7421a9', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name.\nIt adds the functionality discussed on this external bug\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem\n\nDepends-on: Icf964c23745941dd596f65e2b0bfa81e515508d0\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\n'}, {'number': 6, 'created': '2019-11-21 21:34:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/50e4df7146e06ad4007fa91398aa609c1f109611', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name and adds functionality discussed on this external\nbug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem.\n\nRelated-Bug: RHBZ:1659888\nDepends-on: Ia82ddeeae53b2c61a914e14ac8bae4adcee90c76\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 7, 'created': '2019-11-21 23:45:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ab15456f582641fef582f95dec52e7492cb376b3', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name and adds functionality discussed on this external\nbug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem.\n\nRelated-Bug: RHBZ:1659888\nDepends-on: Ia82ddeeae53b2c61a914e14ac8bae4adcee90c76\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 8, 'created': '2019-11-22 02:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/e3749bac733d2590aad9dfd474f49752c267a1b0', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name and adds functionality discussed on this external\nbug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem.\n\nRelated-Bug: RHBZ:1659888\nDepends-on: Ia82ddeeae53b2c61a914e14ac8bae4adcee90c76\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 9, 'created': '2019-11-22 22:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f41523e820d51f622f9fc1d32fa00d4a7283d277', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name and adds functionality discussed on this external\nbug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem.\n\nRelated-Bug: rhbz#1659888\nDepends-on: Ia82ddeeae53b2c61a914e14ac8bae4adcee90c76\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 10, 'created': '2019-11-25 15:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b68e5a5e8b9b2ca6eaa98057927dd0395d4dc997', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name and adds functionality discussed on this external\nbug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem.\n\nRelated-Bug: rhbz#1659888\nDepends-on: Ia82ddeeae53b2c61a914e14ac8bae4adcee90c76\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 11, 'created': '2019-11-25 15:13:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/98c6e7fa8a93981917256bfcf6bb05af6f2eacb1', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name and adds functionality discussed on this external\nbug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem.\n\nRelated-Bug: rhbz#1659888\nDepends-on: Ia82ddeeae53b2c61a914e14ac8bae4adcee90c76\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 12, 'created': '2019-11-25 15:16:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/a29ad5c551bb342da8961725fa98393d4da9b42d', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name and adds functionality discussed on this external\nbug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem.\n\nRelated-Bug: rhbz#1659888\nDepends-on: Ia82ddeeae53b2c61a914e14ac8bae4adcee90c76\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 13, 'created': '2020-01-21 13:54:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/773de79c5e65682698223d7768de089fd7eb55a8', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name and adds functionality discussed on this external\nbug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem.\n\nRelated-Bug: rhbz#1659888\nDepends-on: Ia82ddeeae53b2c61a914e14ac8bae4adcee90c76\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 14, 'created': '2020-01-21 15:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/92a14ab6bdcc12811d73ecbfa419f7b223a3e0b1', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name and adds functionality discussed on this external\nbug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem.\n\nRelated-Bug: rhbz#1659888\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 15, 'created': '2020-01-21 15:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/967be318441bb6b86200d6e24792b5d4f366cd91', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name and adds functionality discussed on this external\nbug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem.\n\nRelated-Bug: rhbz#1659888\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 16, 'created': '2020-01-21 15:30:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/aac6f4e59ef39c0e62092ec7d231efd626794827', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name and adds functionality discussed on this external\nbug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem.\n\nRelated-Bug: rhbz#1659888\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 17, 'created': '2020-01-21 15:31:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/25e535e86391c8e3585b7de2b83bca24baab4699', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name and adds functionality discussed on this external\nbug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem.\n\nRelated-Bug: rhbz#1659888\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 18, 'created': '2020-01-21 15:50:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/755d80fb0eeb6d4689f8bf8ce0286f7d67413974', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name and adds functionality discussed on this external\nbug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem.\n\nDepends-On: I309d52eb424a73bd04af167a2a7411ba3bf35674\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 19, 'created': '2020-01-22 13:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/0a37e4be2b94a7318823d5002c3636bb45a464db', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name and adds functionality discussed on this external\nbug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem.\n\nDepends-On: I309d52eb424a73bd04af167a2a7411ba3bf35674\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 20, 'created': '2020-01-23 13:55:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/9c5bc75df75b7688343684e345bc09c225f31698', 'message': 'Move undercloud backup from ansible to mistral\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name and adds functionality discussed on this external\nbug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem.\n\nDepends-On: I309d52eb424a73bd04af167a2a7411ba3bf35674\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 21, 'created': '2020-01-24 09:59:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/4b3245c23fab6646ced155888edf29455f9e50a2', 'message': 'Move undercloud backup from mistral to ansible\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name and adds functionality discussed on this external\nbug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem.\n\nDepends-On: I309d52eb424a73bd04af167a2a7411ba3bf35674\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 22, 'created': '2020-01-27 17:12:33.000000000', 'files': ['tripleoclient/constants.py', 'tripleoclient/tests/v2/undercloud/__init__.py', 'releasenotes/notes/add_save_swift_parameter_to_undercloud_backup-894e0bb4b3562a78.yaml', 'tripleoclient/tests/v2/undercloud/test_backup.py', 'tripleoclient/tests/v1/undercloud/test_backup.py', 'tripleoclient/v2/undercloud_backup.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/8bc80382d3a940cc34f4f4377cf53a80364959f4', 'message': 'Move undercloud backup from mistral to ansible\n\nThis playbook reflects the same behaviour as the mistral workbook\nof the same name and adds functionality discussed on this external\nbug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888\n\nThis also adds a --save-swift parameter (default false)\nthat makes the backup be saved on swift otherwise it will\nbe saved on the filesystem.\n\nDepends-On: I309d52eb424a73bd04af167a2a7411ba3bf35674\nChange-Id: I054a805e820087a30bd8d27a0b460b6e519849ac\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}]",7,665690,8bc80382d3a940cc34f4f4377cf53a80364959f4,86,9,22,15895,,,0,"Move undercloud backup from mistral to ansible

This playbook reflects the same behaviour as the mistral workbook
of the same name and adds functionality discussed on this external
bug: https://bugzilla.redhat.com/show_bug.cgi?id=1659888

This also adds a --save-swift parameter (default false)
that makes the backup be saved on swift otherwise it will
be saved on the filesystem.

Depends-On: I309d52eb424a73bd04af167a2a7411ba3bf35674
Change-Id: I054a805e820087a30bd8d27a0b460b6e519849ac
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/90/665690/19 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/constants.py', 'tripleoclient/v1/undercloud_backup.py']",2,9ad7202d5a44345fd86a62e5742c682db86602ba,mistral_to_ansible,"from tripleoclient import utils from tripleoclient import constants try: utils.run_ansible_playbook( LOG.info, constants.ANSIBLE_TRIPLEO_PLAYBOOKS, 'undercloud_backup.yaml', 'undercloud,' retries=False )"," try: output = undercloud_backup.backup(clients, workflow_input) LOG.info(output)",13,2
openstack%2Ftacker-horizon~master~Icfa76c6d916af4548059a44704972877ad457e2f,openstack/tacker-horizon,master,Icfa76c6d916af4548059a44704972877ad457e2f,Drop Django 1.11 support,MERGED,2020-01-06 01:53:43.000000000,2020-01-29 01:34:33.000000000,2020-01-29 01:33:06.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 18955}, {'_account_id': 22348}, {'_account_id': 26588}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-01-06 01:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-horizon/commit/e22391a42d3a971c6888a3fe8ba6b601a9665d4c', 'message': 'Drop Django 1.11 support\n\nDjango 1.11 ends its extended support in April 2020 (which is before\nUssuri release), so horizon drops Django 1.11 support in Ussuri.\n\ntox envs for non-primary Django versions are no longer needed in tox.ini\nas testing environments for non-primary Django versions are setup in\nthe zuul jobs now.\n\nhorizon>=17.1.0 is required to use Django 2.2. requirements.txt and\nlower-constraints.txt are updated accordingly. for more info. please\nrefer [1].\nDepends-On: https://review.opendev.org/#/c/700733/\n[1] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin\n\nChange-Id: Icfa76c6d916af4548059a44704972877ad457e2f\n'}, {'number': 2, 'created': '2020-01-06 02:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-horizon/commit/fd14de1e9eaa22f13a674eb0153cf47ad722409a', 'message': 'Drop Django 1.11 support\n\nDjango 1.11 ends its extended support in April 2020 (which is before\nUssuri release), so horizon drops Django 1.11 support in Ussuri.\n\ntox envs for non-primary Django versions are no longer needed in tox.ini\nas testing environments for non-primary Django versions are setup in\nthe zuul jobs now.\n\nhorizon>=17.1.0 is required to use Django 2.2. requirements.txt and\nlower-constraints.txt are updated accordingly. for more info. please\nrefer [1].\nDepends-On: https://review.opendev.org/#/c/700733/\n[1] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin\n\nChange-Id: Icfa76c6d916af4548059a44704972877ad457e2f\n'}, {'number': 3, 'created': '2020-01-06 02:28:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-horizon/commit/1a0cbac4e8a65a5d45caabc4b345a6d696e8b240', 'message': 'Drop Django 1.11 support\n\nDjango 1.11 ends its extended support in April 2020 (which is before\nUssuri release), so horizon drops Django 1.11 support in Ussuri.\n\ntox envs for non-primary Django versions are no longer needed in tox.ini\nas testing environments for non-primary Django versions are setup in\nthe zuul jobs now.\n\nhorizon>=17.1.0 is required to use Django 2.2. requirements.txt and\nlower-constraints.txt are updated accordingly. for more info. please\nrefer [1].\nDepends-On: https://review.opendev.org/#/c/700733/\n[1] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin\n\nChange-Id: Icfa76c6d916af4548059a44704972877ad457e2f\n'}, {'number': 4, 'created': '2020-01-07 02:47:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-horizon/commit/bd1cb47e15ca1f5aea3e8169728c25891b807b97', 'message': 'Drop Django 1.11 support\n\nDjango 1.11 ends its extended support in April 2020 (which is before\nUssuri release), so horizon drops Django 1.11 support in Ussuri.\n\ntox envs for non-primary Django versions are no longer needed in tox.ini\nas testing environments for non-primary Django versions are setup in\nthe zuul jobs now.\n\nhorizon>=17.1.0 is required to use Django 2.2. requirements.txt and\nlower-constraints.txt are updated accordingly. for more info. please\nrefer [1].\nDepends-On: https://review.opendev.org/#/c/700733/\n[1] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin\n\nChange-Id: Icfa76c6d916af4548059a44704972877ad457e2f\n'}, {'number': 5, 'created': '2020-01-07 05:40:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-horizon/commit/95db5eedfe33eee8edc7e66a72d89854a4febbd5', 'message': 'Drop Django 1.11 support\n\nDjango 1.11 ends its extended support in April 2020 (which is before\nUssuri release), so horizon drops Django 1.11 support in Ussuri.\n\ntox envs for non-primary Django versions are no longer needed in tox.ini\nas testing environments for non-primary Django versions are setup in\nthe zuul jobs now.\n\nhorizon>=17.1.0 is required to use Django 2.2. requirements.txt and\nlower-constraints.txt are updated accordingly. for more info. please\nrefer [1].\nDepends-On: https://review.opendev.org/#/c/700733/\n[1] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin\n\nChange-Id: Icfa76c6d916af4548059a44704972877ad457e2f\n'}, {'number': 6, 'created': '2020-01-07 06:17:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-horizon/commit/031a3f95dec53dbcee4749e72e95bcf7509061cd', 'message': 'Drop Django 1.11 support\n\nDjango 1.11 ends its extended support in April 2020 (which is before\nUssuri release), so horizon drops Django 1.11 support in Ussuri.\n\ntox envs for non-primary Django versions are no longer needed in tox.ini\nas testing environments for non-primary Django versions are setup in\nthe zuul jobs now.\n\nhorizon>=17.1.0 is required to use Django 2.2. requirements.txt and\nlower-constraints.txt are updated accordingly. for more info. please\nrefer [1].\nDepends-On: https://review.opendev.org/#/c/700733/\n[1] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin\n\nChange-Id: Icfa76c6d916af4548059a44704972877ad457e2f\n'}, {'number': 7, 'created': '2020-01-08 00:33:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-horizon/commit/7af201140006f7cb0951ebf4a1a2b2e3f37d4542', 'message': 'Drop Django 1.11 support\n\nDjango 1.11 ends its extended support in April 2020 (which is before\nUssuri release), so horizon drops Django 1.11 support in Ussuri.\n\ntox envs for non-primary Django versions are no longer needed in tox.ini\nas testing environments for non-primary Django versions are setup in\nthe zuul jobs now.\n\nhorizon>=17.1.0 is required to use Django 2.2. requirements.txt and\nlower-constraints.txt are updated accordingly. for more info. please\nrefer [1].\nDepends-On: https://review.opendev.org/#/c/700733/\n[1] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin\n\nChange-Id: Icfa76c6d916af4548059a44704972877ad457e2f\n'}, {'number': 8, 'created': '2020-01-08 00:57:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-horizon/commit/1c186e3b3ba84823e36c174f6a2b73eb6422e132', 'message': 'Drop Django 1.11 support\n\nDjango 1.11 ends its extended support in April 2020 (which is before\nUssuri release), so horizon drops Django 1.11 support in Ussuri.\n\ntox envs for non-primary Django versions are no longer needed in tox.ini\nas testing environments for non-primary Django versions are setup in\nthe zuul jobs now.\n\nhorizon>=17.1.0 is required to use Django 2.2. requirements.txt and\nlower-constraints.txt are updated accordingly. for more info. please\nrefer [1] [2].\n[1] https://review.opendev.org/#/c/700733/\n[2] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin\n\nChange-Id: Icfa76c6d916af4548059a44704972877ad457e2f\n'}, {'number': 9, 'created': '2020-01-08 01:48:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-horizon/commit/7ede588312a2765fe805ef047d857f4aa99c22ae', 'message': 'Drop Django 1.11 support\n\nDjango 1.11 ends its extended support in April 2020 (which is before\nUssuri release), so horizon drops Django 1.11 support in Ussuri.\n\ntox envs for non-primary Django versions are no longer needed in tox.ini\nas testing environments for non-primary Django versions are setup in\nthe zuul jobs now.\n\nhorizon>=17.1.0 is required to use Django 2.2. requirements.txt and\nlower-constraints.txt are updated accordingly. for more info. please\nrefer [1] [2].\n[1] https://review.opendev.org/#/c/700733/\n[2] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin\n\nChange-Id: Icfa76c6d916af4548059a44704972877ad457e2f\n'}, {'number': 10, 'created': '2020-01-08 01:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-horizon/commit/6c3fdb6f3765dbc3c04087f4a68196ea9a43c4d9', 'message': 'Drop Django 1.11 support\n\nDjango 1.11 ends its extended support in April 2020 (which is before\nUssuri release), so horizon drops Django 1.11 support in Ussuri.\n\ntox envs for non-primary Django versions are no longer needed in tox.ini\nas testing environments for non-primary Django versions are setup in\nthe zuul jobs now.\n\nhorizon>=17.1.0 is required to use Django 2.2. requirements.txt and\nlower-constraints.txt are updated accordingly. for more info. please\nrefer [1] [2].\n[1] https://review.opendev.org/#/c/700733/\n[2] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin\n\nChange-Id: Icfa76c6d916af4548059a44704972877ad457e2f\n'}, {'number': 11, 'created': '2020-01-08 02:07:55.000000000', 'files': ['requirements.txt', 'lower-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tacker-horizon/commit/17798fadc58b48f3f2d754d0a129b5c3031c2f76', 'message': 'Drop Django 1.11 support\n\nDjango 1.11 ends its extended support in April 2020 (which is before\nUssuri release), so horizon drops Django 1.11 support in Ussuri.\n\ntox envs for non-primary Django versions are no longer needed in tox.ini\nas testing environments for non-primary Django versions are setup in\nthe zuul jobs now.\n\nhorizon>=17.1.0 is required to use Django 2.2. requirements.txt and\nlower-constraints.txt are updated accordingly. for more info. please\nrefer [1] [2].\n[1] https://review.opendev.org/#/c/700733/\n[2] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin\n\nChange-Id: Icfa76c6d916af4548059a44704972877ad457e2f\n'}]",0,701124,17798fadc58b48f3f2d754d0a129b5c3031c2f76,32,6,11,29313,,,0,"Drop Django 1.11 support

Django 1.11 ends its extended support in April 2020 (which is before
Ussuri release), so horizon drops Django 1.11 support in Ussuri.

tox envs for non-primary Django versions are no longer needed in tox.ini
as testing environments for non-primary Django versions are setup in
the zuul jobs now.

horizon>=17.1.0 is required to use Django 2.2. requirements.txt and
lower-constraints.txt are updated accordingly. for more info. please
refer [1] [2].
[1] https://review.opendev.org/#/c/700733/
[2] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin

Change-Id: Icfa76c6d916af4548059a44704972877ad457e2f
",git fetch https://review.opendev.org/openstack/tacker-horizon refs/changes/24/701124/3 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'lower-constraints.txt', 'tox.ini']",3,e22391a42d3a971c6888a3fe8ba6b601a9665d4c,drop-django111-support,"envlist = py37,pep8,docs","envlist = py37,py3-{dj111,dj22},pep8,docs dj111: pip install django>=1.11,<2 dj22: pip install django>=2.2,<2.3",5,6
openstack%2Fkuryr-kubernetes~master~I766024502b23f46c42b985d00616cdd0bb442123,openstack/kuryr-kubernetes,master,I766024502b23f46c42b985d00616cdd0bb442123,Remove _get_trunks method for openstacksdk client.,MERGED,2020-01-28 09:27:36.000000000,2020-01-29 00:35:41.000000000,2020-01-29 00:33:36.000000000,"[{'_account_id': 11600}, {'_account_id': 13692}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2020-01-28 09:27:36.000000000', 'files': ['kuryr_kubernetes/clients.py', 'kuryr_kubernetes/controller/drivers/vif_pool.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/6cc473ba50932a4ae1314b3526c265ef6bf8d208', 'message': 'Remove _get_trunks method for openstacksdk client.\n\nWe already bumped version of openstacksdk, so now we can get all trunk\nports without any hacks. This patch is fixing it.\n\nChange-Id: I766024502b23f46c42b985d00616cdd0bb442123\n'}]",3,704511,6cc473ba50932a4ae1314b3526c265ef6bf8d208,21,4,1,13692,,,0,"Remove _get_trunks method for openstacksdk client.

We already bumped version of openstacksdk, so now we can get all trunk
ports without any hacks. This patch is fixing it.

Change-Id: I766024502b23f46c42b985d00616cdd0bb442123
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/11/704511/1 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_kubernetes/clients.py', 'kuryr_kubernetes/controller/drivers/vif_pool.py']",2,6cc473ba50932a4ae1314b3526c265ef6bf8d208,trunks, tags = [] tags = config.CONF.neutron_defaults.resource_tags trunks = os_net.trunks(tags=tags), args = {} args['tags'] = config.CONF.neutron_defaults.resource_tags trunks = os_net.get_trunks(args),3,15
openstack%2Fpuppet-openstack_spec_helper~stable%2Frocky~If625beff7cbcc2d7261e881e43dcd43b6e4d9cba,openstack/puppet-openstack_spec_helper,stable/rocky,If625beff7cbcc2d7261e881e43dcd43b6e4d9cba,Pin gettext < 3.3.0,MERGED,2020-01-09 17:44:08.000000000,2020-01-29 00:05:12.000000000,2020-01-29 00:05:12.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-09 17:44:08.000000000', 'files': ['puppet-openstack_spec_helper.gemspec'], 'web_link': 'https://opendev.org/openstack/puppet-openstack_spec_helper/commit/23b1fa3221bbce4c68d8d839b6a24c551fa000b1', 'message': 'Pin gettext < 3.3.0\n\nWe need this here since r10k is the ultimate cause\nof the issue.\n\nDependency chain is:\nr10k -> puppet_forge -> gettext-setup -> locale -> gettext\n\nChange-Id: If625beff7cbcc2d7261e881e43dcd43b6e4d9cba\n(cherry picked from commit 57785448ce4e0d2ffece98022c268c9e773d3912)\n'}]",0,701783,23b1fa3221bbce4c68d8d839b6a24c551fa000b1,10,3,1,16312,,,0,"Pin gettext < 3.3.0

We need this here since r10k is the ultimate cause
of the issue.

Dependency chain is:
r10k -> puppet_forge -> gettext-setup -> locale -> gettext

Change-Id: If625beff7cbcc2d7261e881e43dcd43b6e4d9cba
(cherry picked from commit 57785448ce4e0d2ffece98022c268c9e773d3912)
",git fetch https://review.opendev.org/openstack/puppet-openstack_spec_helper refs/changes/83/701783/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet-openstack_spec_helper.gemspec'],1,23b1fa3221bbce4c68d8d839b6a24c551fa000b1,," spec.add_dependency 'gettext', ['< 3.3.0']",,1,0
openstack%2Fpuppet-openstack_spec_helper~stable%2Fstein~If625beff7cbcc2d7261e881e43dcd43b6e4d9cba,openstack/puppet-openstack_spec_helper,stable/stein,If625beff7cbcc2d7261e881e43dcd43b6e4d9cba,Pin gettext < 3.3.0,MERGED,2020-01-09 17:43:43.000000000,2020-01-29 00:05:11.000000000,2020-01-29 00:05:11.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-09 17:43:43.000000000', 'files': ['puppet-openstack_spec_helper.gemspec'], 'web_link': 'https://opendev.org/openstack/puppet-openstack_spec_helper/commit/b86a48aaf74351f730a99071c105711dabf8f35a', 'message': 'Pin gettext < 3.3.0\n\nWe need this here since r10k is the ultimate cause\nof the issue.\n\nDependency chain is:\nr10k -> puppet_forge -> gettext-setup -> locale -> gettext\n\nChange-Id: If625beff7cbcc2d7261e881e43dcd43b6e4d9cba\n(cherry picked from commit 57785448ce4e0d2ffece98022c268c9e773d3912)\n'}]",0,701782,b86a48aaf74351f730a99071c105711dabf8f35a,10,3,1,16312,,,0,"Pin gettext < 3.3.0

We need this here since r10k is the ultimate cause
of the issue.

Dependency chain is:
r10k -> puppet_forge -> gettext-setup -> locale -> gettext

Change-Id: If625beff7cbcc2d7261e881e43dcd43b6e4d9cba
(cherry picked from commit 57785448ce4e0d2ffece98022c268c9e773d3912)
",git fetch https://review.opendev.org/openstack/puppet-openstack_spec_helper refs/changes/82/701782/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet-openstack_spec_helper.gemspec'],1,b86a48aaf74351f730a99071c105711dabf8f35a,," spec.add_dependency 'gettext', ['< 3.3.0']",,1,0
openstack%2Felection~master~If666499149c80e2194c33dfd17d115f39f2280bf,openstack/election,master,If666499149c80e2194c33dfd17d115f39f2280bf,Add promote-governance-election job,MERGED,2020-01-28 22:23:56.000000000,2020-01-28 23:24:56.000000000,2020-01-28 23:21:13.000000000,"[{'_account_id': 5263}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-28 22:23:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/db9f56c2e32dbcb6f6551dae5bbc7c9747559f8f', 'message': 'Add promote-governance-election job\n\nThis job publishes the election site under the\ngovernance.openstack.org AFS volume.  This is our ""next generation""\npublishing as it doesn\'t rely on storing things on a single static\nserver.  The current job, promote-tox-docs-static, will be removed\nafter we transition to serving the site from AFS.\n\nChange-Id: If666499149c80e2194c33dfd17d115f39f2280bf\n'}, {'number': 2, 'created': '2020-01-28 22:24:19.000000000', 'files': ['.zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/election/commit/75b2cec7d3158c7e348d3c6d1f22f55f5bcde07f', 'message': 'Add promote-governance-election job\n\nThis job publishes the election site under the\ngovernance.openstack.org AFS volume.  This is our ""next generation""\npublishing as it doesn\'t rely on storing things on a single static\nserver.  The current job, promote-tox-docs-static, will be removed\nafter we transition to serving the site from AFS.\n\nDepends-On: https://review.opendev.org/704702\nChange-Id: If666499149c80e2194c33dfd17d115f39f2280bf\n'}]",1,704703,75b2cec7d3158c7e348d3c6d1f22f55f5bcde07f,12,3,2,7118,,,0,"Add promote-governance-election job

This job publishes the election site under the
governance.openstack.org AFS volume.  This is our ""next generation""
publishing as it doesn't rely on storing things on a single static
server.  The current job, promote-tox-docs-static, will be removed
after we transition to serving the site from AFS.

Depends-On: https://review.opendev.org/704702
Change-Id: If666499149c80e2194c33dfd17d115f39f2280bf
",git fetch https://review.opendev.org/openstack/election refs/changes/03/704703/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/project.yaml'],1,db9f56c2e32dbcb6f6551dae5bbc7c9747559f8f,publish-afs, - promote-governance-election,,1,0
openstack%2Fopenstack-helm-infra~master~Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831,openstack/openstack-helm-infra,master,Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831,Add audit database user for audit purposes,MERGED,2019-09-04 16:30:19.000000000,2020-01-28 23:05:36.000000000,2020-01-28 23:03:45.000000000,"[{'_account_id': 14029}, {'_account_id': 17966}, {'_account_id': 18236}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 23928}, {'_account_id': 24780}, {'_account_id': 28718}, {'_account_id': 30746}, {'_account_id': 30777}]","[{'number': 1, 'created': '2019-09-04 16:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b270bd3ea859d3c0b3311d4c60651fe7b4bac287', 'message': 'Add audit database user for audit purposes\n\n  * Add audit user to postgresql using helm-toolkit db-init method\n  * Add a job to create the audit user with SELECT only permission\n  * Add secret for the audit user\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 2, 'created': '2019-09-04 16:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c4119a6f4b1ab35321811460c7d9e3ff7cfc9165', 'message': 'Add audit database user for audit purposes\n\n  * Add audit user to postgresql using helm-toolkit db-init method\n  * Add a job to create the audit user with SELECT only permission\n  * Add secret for the audit user\n\nDepends-On: https://review.opendev.org/679280/6\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 3, 'created': '2019-12-10 18:08:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/10da1d1594867399b64c504399edb9a2d418d6d0', 'message': 'Add audit database user for audit purposes\n\n  * Add audit user to postgresql using helm-toolkit db-init method\n  * Add a job to create the audit user with SELECT only permission\n  * Add secret for the audit user\n\nDepends-On: https://review.opendev.org/679280/6\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 4, 'created': '2019-12-12 16:46:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a9d60951cf4d19f1553c6d2f06c88e5f5aae574a', 'message': 'Add audit database user for audit purposes\n\n  * Add audit user to postgresql using helm-toolkit db-init method\n  * Add a job to create the audit user with SELECT only permission\n  * Add secret for the audit user\n\nDepends-On: https://review.opendev.org/679280/6\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 5, 'created': '2019-12-18 15:56:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/19d3bdc83094b489b957ecb9cc7ce6d49ad2ad52', 'message': 'Add audit database user for audit purposes\n\n  * Add audit user to postgresql using helm-toolkit db-init method\n  * Add a job to create the audit user with SELECT only permission\n  * Add secret for the audit user\n\nDepends-On: https://review.opendev.org/#/c/679280/\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 6, 'created': '2019-12-18 17:31:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/25af849b0c44e0bacb1fcc77627bef583f5dfb38', 'message': 'Add audit database user for audit purposes\n\n  * Add audit user to postgresql using helm-toolkit db-init method\n  * Add a job to create the audit user with SELECT only permission\n  * Add secret for the audit user\n\nDepends-On: https://review.opendev.org/#/c/679280/\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 7, 'created': '2019-12-19 20:37:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/d20817ddd6a13e318a8011196061ed2497c1e393', 'message': 'Add audit database user for audit purposes\n\n  * Add audit user to postgresql using helm-toolkit db-init method\n  * Add a job to create the audit user with SELECT only permission\n  * Add secret for the audit user\n\nDepends-On: https://review.opendev.org/#/c/679280/\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 8, 'created': '2020-01-08 16:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/39283a218983582ea66fc35ccc224aa084540457', 'message': 'Add audit database user for audit purposes\n\n  * Add audit user to postgresql using helm-toolkit db-init method\n  * Add a job to create the audit user with SELECT only permission\n  * Add secret for the audit user\n\nDepends-On: https://review.opendev.org/#/c/679280/\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 9, 'created': '2020-01-16 23:40:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/0d4e2a9cd3dd49445a19259440b95c53c8dcaa06', 'message': 'Add audit database user for audit purposes\n\n  * Add audit user to postgresql using helm-toolkit db-init method\n  * Add a job to create the audit user with SELECT only permission\n  * Add secret for the audit user\n\nDepends-On: https://review.opendev.org/#/c/679280/\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 10, 'created': '2020-01-24 15:44:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/fed447c694fd3966c40a0872e61b78d21448560b', 'message': 'Add audit database user for audit purposes\n\n  * Add audit user to postgresql using helm-toolkit db-init method\n  * Add a job to create the audit user with SELECT only permission\n  * Add secret for the audit user\n\nDepends-On: https://review.opendev.org/#/c/679280/\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 11, 'created': '2020-01-26 22:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c7f97009e0e4bc7bfcaa7fc54805a7d356af8b4d', 'message': 'Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 12, 'created': '2020-01-26 22:54:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/69b5ceb862cda999d3397809595d717f886e6813', 'message': 'Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 13, 'created': '2020-01-26 22:55:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3ff3951aa28d96bd07a34d0268cc263f185d9ccd', 'message': 'Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 14, 'created': '2020-01-26 22:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/d71bd3e52d758bb308a0292cf9622d1229728b7a', 'message': '[WIP] Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 15, 'created': '2020-01-26 23:17:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/af3d353221611a5d3cc563f2d1920ad68f71f859', 'message': '[WIP] Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 16, 'created': '2020-01-27 00:36:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c63e1d30c8999c5d1a16d8ca4585603208ed8fd3', 'message': '[WIP] Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 17, 'created': '2020-01-27 01:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8170a52da552e9fb2bfb2dd5db75492f3d6b9c92', 'message': '[WIP] Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 18, 'created': '2020-01-27 02:53:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/787bd75a1b4406018067338c844a3a1324175df4', 'message': '[WIP] Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 19, 'created': '2020-01-27 03:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9ddf27244fbe9765fd57e3e79780bee501bac77b', 'message': 'Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 20, 'created': '2020-01-27 03:48:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8f29200261151b3af149b1bd86eafcee86583e84', 'message': 'Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 21, 'created': '2020-01-27 15:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a82ccae250f8442a6e2cb3009b98ed4a4d2233d3', 'message': 'Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 22, 'created': '2020-01-27 15:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ef2e2c7281957043d7e769e396d92469490882ce', 'message': '[WIP] Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 23, 'created': '2020-01-27 15:25:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8df25eb374ebbb5834c81e75b9003cf82d14bb11', 'message': '[WIP] Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 24, 'created': '2020-01-27 19:38:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3d6af130e0402a1f164511ecd79cb122047296b1', 'message': '[WIP] Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 25, 'created': '2020-01-27 20:39:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/35b4cb5140db9e870057bbd050ef21c1d548dbb9', 'message': '[WIP] Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 26, 'created': '2020-01-27 21:47:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5f2d7c5ebc20c03c35d478b5bd7fa88b94f13773', 'message': '[WIP] Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 27, 'created': '2020-01-27 22:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c964d0029d22b552077992c95f7266c0844bf03c', 'message': '[WIP] Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 28, 'created': '2020-01-27 23:28:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e3c696d18c75f943ad1d69b61fa55d42b598c30a', 'message': '[WIP] Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 29, 'created': '2020-01-28 03:18:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/0b3c7c9d331446ebba191665ec61e6a62a05d8b2', 'message': '[WIP] Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql user table.\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 30, 'created': '2020-01-28 04:43:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1dd7d150b673ae009b2da7dcb10e8e3c515a9fc9', 'message': 'Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql database tables.\nThis is accomplished by setting up audit user creation parameters\nin the Patroni bootstrap environment settings, according to (1).\n\n(1) https://patroni.readthedocs.io/en/latest/ENVIRONMENT.html\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 31, 'created': '2020-01-28 15:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3048a0c36672836520ca9932dc21ce912e1343e2', 'message': 'Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql database tables.\nThis is accomplished by setting up audit user creation parameters\nin the Patroni bootstrap environment settings, according to (1).\n\n(1) https://patroni.readthedocs.io/en/latest/ENVIRONMENT.html\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}, {'number': 32, 'created': '2020-01-28 16:48:50.000000000', 'files': ['postgresql/templates/secret-audit.yaml', 'postgresql/templates/statefulset.yaml', 'postgresql/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/914ea2bd6037ae67c315a57083f20b12ae51a179', 'message': 'Add audit database user for audit purposes\n\nThis commit adds an audit user to the postgresql database which\nwill have only SELECT privileges on the postgresql database tables.\nThis is accomplished by setting up audit user creation parameters\nin the Patroni bootstrap environment settings, according to (1).\n\n(1) https://patroni.readthedocs.io/en/latest/ENVIRONMENT.html\n\nChange-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831\n'}]",14,680081,914ea2bd6037ae67c315a57083f20b12ae51a179,87,12,32,28875,,,0,"Add audit database user for audit purposes

This commit adds an audit user to the postgresql database which
will have only SELECT privileges on the postgresql database tables.
This is accomplished by setting up audit user creation parameters
in the Patroni bootstrap environment settings, according to (1).

(1) https://patroni.readthedocs.io/en/latest/ENVIRONMENT.html

Change-Id: Idf1cd90b5d093f12fa4a3c5c794d4b5bbc6c8831
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/81/680081/32 && git format-patch -1 --stdout FETCH_HEAD,"['postgresql/templates/configmap-bin.yaml', 'postgresql/templates/secret-user.yaml', 'postgresql/templates/job-db-init.yaml', 'postgresql/values.yaml']",4,b270bd3ea859d3c0b3311d4c60651fe7b4bac287,," db_init: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" db_init: ""docker.io/postgres:9.5"" db_init: services: - service: postgresql endpoint: internal audit: postgresql-audit audit: username: audit password: password database: postgres permission: SELECT table: pg_user job_db_init: true",,164,0
openstack%2Fproject-config~master~I6db3cd87c368b132af16695b1533aa7033d2ce15,openstack/project-config,master,I6db3cd87c368b132af16695b1533aa7033d2ce15,Add openstack/election AFS promotion job,MERGED,2020-01-28 22:18:15.000000000,2020-01-28 22:48:12.000000000,2020-01-28 22:48:12.000000000,"[{'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-28 22:18:15.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c098f033c95594f88b3489ca5f5d04a4a52e1859', 'message': 'Add openstack/election AFS promotion job\n\nThis job publishes the election site under the governance.o.o AFS\nvolume.\n\nChange-Id: I6db3cd87c368b132af16695b1533aa7033d2ce15\n'}]",0,704702,c098f033c95594f88b3489ca5f5d04a4a52e1859,7,2,1,7118,,,0,"Add openstack/election AFS promotion job

This job publishes the election site under the governance.o.o AFS
volume.

Change-Id: I6db3cd87c368b132af16695b1533aa7033d2ce15
",git fetch https://review.opendev.org/openstack/project-config refs/changes/02/704702/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,c098f033c95594f88b3489ca5f5d04a4a52e1859,publish-elections," name: promote-governance-election parent: promote-tox-docs-site-base description: Promote content to governance.openstack.org/election. final: true allowed-projects: - openstack/election vars: publish_site: ""governance.openstack.org/election"" - job:",,11,0
openstack%2Ftripleo-heat-templates~stable%2Frocky~Idd22c7b4403bb63c06d2ba714d851a976e830108,openstack/tripleo-heat-templates,stable/rocky,Idd22c7b4403bb63c06d2ba714d851a976e830108,Run update without yum update to apply hotfixes.,MERGED,2020-01-15 14:30:38.000000000,2020-01-28 22:46:46.000000000,2020-01-28 22:46:45.000000000,"[{'_account_id': 6816}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}, {'_account_id': 26343}, {'_account_id': 28522}, {'_account_id': 31245}]","[{'number': 1, 'created': '2020-01-15 14:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dff10e6a5b318af6d17ec15e60feb388b27a2a42', 'message': 'Run update without yum update to apply hotfixes.\n\nAdd a new option to skip the yum update of all packages.\n\nChange-Id: Idd22c7b4403bb63c06d2ba714d851a976e830108\n(cherry picked from commit 4cc2b1196e2ac13de521b2fae0d1436a6f7d0d66)\n(cherry picked from commit e5e6b95bb29f3a06a9db1121dc50fb2dbb6e16a6)\n(cherry picked from commit f0dd6b3a6cf6bfdf37faa54116ae62ecb97c5130)\n'}, {'number': 2, 'created': '2020-01-15 14:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5539df1977fb4bfc00091f1a9976412ea9d34f3b', 'message': 'Run update without yum update to apply hotfixes.\n\nAdd a new option to skip the yum update of all packages.\n\nChange-Id: Idd22c7b4403bb63c06d2ba714d851a976e830108\n(cherry picked from commit 4cc2b1196e2ac13de521b2fae0d1436a6f7d0d66)\n(cherry picked from commit e5e6b95bb29f3a06a9db1121dc50fb2dbb6e16a6)\n(cherry picked from commit f0dd6b3a6cf6bfdf37faa54116ae62ecb97c5130)\n'}, {'number': 3, 'created': '2020-01-23 10:17:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/04cd9571d4a2e7fd2edcc0259d1c962cb544e365', 'message': 'Run update without yum update to apply hotfixes.\n\nAdd a new option to skip the yum update of all packages.\n\nChange-Id: Idd22c7b4403bb63c06d2ba714d851a976e830108\n(cherry picked from commit 4cc2b1196e2ac13de521b2fae0d1436a6f7d0d66)\n(cherry picked from commit e5e6b95bb29f3a06a9db1121dc50fb2dbb6e16a6)\n(cherry picked from commit f0dd6b3a6cf6bfdf37faa54116ae62ecb97c5130)\n'}, {'number': 4, 'created': '2020-01-23 10:31:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3fe91ded043596886f1a03f443cbc75642f7a000', 'message': 'Run update without yum update to apply hotfixes.\n\nAdd a new option to skip the yum update of all packages.\n\nChange-Id: Idd22c7b4403bb63c06d2ba714d851a976e830108\n(cherry picked from commit 4cc2b1196e2ac13de521b2fae0d1436a6f7d0d66)\n(cherry picked from commit e5e6b95bb29f3a06a9db1121dc50fb2dbb6e16a6)\n(cherry picked from commit f0dd6b3a6cf6bfdf37faa54116ae62ecb97c5130)\n'}, {'number': 5, 'created': '2020-01-24 11:59:38.000000000', 'files': ['puppet/services/tripleo-packages.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/da3bf441aa49608698a4eb6c64793d8689e52a48', 'message': 'Run update without yum update to apply hotfixes.\n\nAdd a new option to skip the yum update of all packages.\n\nChange-Id: Idd22c7b4403bb63c06d2ba714d851a976e830108\n(cherry picked from commit 4cc2b1196e2ac13de521b2fae0d1436a6f7d0d66)\n(cherry picked from commit e5e6b95bb29f3a06a9db1121dc50fb2dbb6e16a6)\n(cherry picked from commit f0dd6b3a6cf6bfdf37faa54116ae62ecb97c5130)\n'}]",1,702671,da3bf441aa49608698a4eb6c64793d8689e52a48,49,8,5,31245,,,0,"Run update without yum update to apply hotfixes.

Add a new option to skip the yum update of all packages.

Change-Id: Idd22c7b4403bb63c06d2ba714d851a976e830108
(cherry picked from commit 4cc2b1196e2ac13de521b2fae0d1436a6f7d0d66)
(cherry picked from commit e5e6b95bb29f3a06a9db1121dc50fb2dbb6e16a6)
(cherry picked from commit f0dd6b3a6cf6bfdf37faa54116ae62ecb97c5130)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/71/702671/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/tripleo-packages.yaml'],1,dff10e6a5b318af6d17ec15e60feb388b27a2a42,rocky, SkipPackageUpdate: default: 'false' description: Set to true to skip the update all packages type: boolean - name: Set boolean skip_package_update set_fact: skip_package_update: {get_param: SkipPackageUpdate} # Exclude ansible until https://github.com/ansible/ansible/issues/56636 # is available when: - step|int == 3 - not skip_package_update|bool yum: name: '*' state: latest exclude: ansible external_upgrade_tasks: - name: Clean up upgrade artifacts when: step|int == 1 tags: - never - system_upgrade_cleanup block: - name: cleanup tripleo_persist include_role: name: tripleo-persist tasks_from: cleanup.yml - name: cleanup tripleo_transfer include_role: name: tripleo-transfer tasks_from: cleanup.yml - name: Set boolean skip_package_update set_fact: skip_package_update: {get_param: SkipPackageUpdate} # Exclude ansible until https://github.com/ansible/ansible/issues/56636 # is available when: - step|int == 3 - not skip_package_update|bool yum: name: '*' state: latest exclude: ansible," when: step|int == 3 package: name=* state=latest package: name=* state=latest when: step == ""3""",44,4
openstack%2Fswift~master~I36f0954fd9949d7d1404a0c381b917d1cfb17ec5,openstack/swift,master,I36f0954fd9949d7d1404a0c381b917d1cfb17ec5,s3api: Better handle 498/429 responses,MERGED,2019-12-05 17:54:02.000000000,2020-01-28 22:32:55.000000000,2020-01-28 22:29:27.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-05 17:54:02.000000000', 'files': ['swift/common/middleware/s3api/s3request.py', 'swift/common/http.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/f33c061ae92f33ea467c58749d3f15d2b1cc942c', 'message': ""s3api: Better handle 498/429 responses\n\nCurrently, they just 500 as an unexpected response status. Much better\nwould be S3's '503 Slow Down' response.\n\nOf course, that's all dependent on where you place ratelimit in your\npipeline -- and we haven't really given clear guidance on that. I'm not\nactually sure you *want* ratelimit to be after s3api and auth... but if\nyou *do*, let's at least handle it gracefully.\n\nChange-Id: I36f0954fd9949d7d1404a0c381b917d1cfb17ec5\nRelated-Bug: 1669888\n""}]",0,697535,f33c061ae92f33ea467c58749d3f15d2b1cc942c,7,2,1,15343,,,0,"s3api: Better handle 498/429 responses

Currently, they just 500 as an unexpected response status. Much better
would be S3's '503 Slow Down' response.

Of course, that's all dependent on where you place ratelimit in your
pipeline -- and we haven't really given clear guidance on that. I'm not
actually sure you *want* ratelimit to be after s3api and auth... but if
you *do*, let's at least handle it gracefully.

Change-Id: I36f0954fd9949d7d1404a0c381b917d1cfb17ec5
Related-Bug: 1669888
",git fetch https://review.opendev.org/openstack/swift refs/changes/35/697535/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/s3api/s3request.py', 'swift/common/http.py']",2,f33c061ae92f33ea467c58749d3f15d2b1cc942c,bug/1669888,HTTP_RATE_LIMITED = 498,,5,2
openstack%2Fnetworking-ovn~stable%2Ftrain~Ic850665bde77c6891691e831317a0ec320ed197b,openstack/networking-ovn,stable/train,Ic850665bde77c6891691e831317a0ec320ed197b,Agent liveness - allow time to propagate checks,MERGED,2020-01-24 09:11:20.000000000,2020-01-28 22:24:41.000000000,2020-01-28 22:22:36.000000000,"[{'_account_id': 6773}, {'_account_id': 8655}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 24791}]","[{'number': 1, 'created': '2020-01-24 09:11:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/025cb07da2914d0bdcf9deecb8827651995e6cc2', 'message': 'Agent liveness - allow time to propagate checks\n\nRight now neutron-server bumps the nb_cfg parameter in NB_Global\ntable which needs to be propagated by northd to SB_Global,\nprocessed by agents, and write it back into SB_Global.\nThis requires processing by neutron-server but unfortunatelly\nthe server checks straight away and many times the value read\nis behind the expected value.\n\nAll this results in frequent false positives showing dead agents\nwhen they are not.\n\nThis patch is relaxing the checks by allowing a difference of 1\nbetween the read and expected values.\n\nChange-Id: Ic850665bde77c6891691e831317a0ec320ed197b\nBackported-From: https://review.opendev.org/#/c/703612/\nCloses-Bug: 1860436\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}, {'number': 2, 'created': '2020-01-24 09:32:05.000000000', 'files': ['networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ml2/mech_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/b9958774f1f0952c03ad6e34f804a00ae5f00bfd', 'message': 'Agent liveness - allow time to propagate checks\n\nRight now neutron-server bumps the nb_cfg parameter in NB_Global\ntable which needs to be propagated by northd to SB_Global,\nprocessed by agents, and write it back into SB_Global.\nThis requires processing by neutron-server but unfortunatelly\nthe server checks straight away and many times the value read\nis behind the expected value.\n\nAll this results in frequent false positives showing dead agents\nwhen they are not.\n\nThis patch is relaxing the checks by allowing a difference of 1\nbetween the read and expected values.\n\nChange-Id: Ic850665bde77c6891691e831317a0ec320ed197b\nBackported-From: https://review.opendev.org/#/c/703612/\nCloses-Bug: 1860436\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}]",2,704112,b9958774f1f0952c03ad6e34f804a00ae5f00bfd,19,5,2,23804,,,0,"Agent liveness - allow time to propagate checks

Right now neutron-server bumps the nb_cfg parameter in NB_Global
table which needs to be propagated by northd to SB_Global,
processed by agents, and write it back into SB_Global.
This requires processing by neutron-server but unfortunatelly
the server checks straight away and many times the value read
is behind the expected value.

All this results in frequent false positives showing dead agents
when they are not.

This patch is relaxing the checks by allowing a difference of 1
between the read and expected values.

Change-Id: Ic850665bde77c6891691e831317a0ec320ed197b
Backported-From: https://review.opendev.org/#/c/703612/
Closes-Bug: 1860436
Signed-off-by: Daniel Alvarez <dalvarez@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/12/704112/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ml2/mech_driver.py']",2,025cb07da2914d0bdcf9deecb8827651995e6cc2,bug/1860436, # Allow a maximum of 1 difference between expected and read values # to avoid false positives. if self._nb_ovn.nb_global.nb_cfg - nb_cfg <= 1:, if self._nb_ovn.nb_global.nb_cfg == nb_cfg:,16,3
openstack%2Ftripleo-heat-templates~master~I3fd9b8f8ee131c5b2118d922b7756a7572c09108,openstack/tripleo-heat-templates,master,I3fd9b8f8ee131c5b2118d922b7756a7572c09108,container-puppet: create containers sequentially to avoid race,ABANDONED,2019-12-18 18:40:32.000000000,2020-01-28 22:12:29.000000000,,"[{'_account_id': 14985}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-18 18:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/81336cbe464b97519cdf726ef236ce82b25f276a', 'message': 'container-puppet: create containers sequentially to avoid race\n\nDue to a race in podman 1.6.3, when containers are created in\nparallel under high disk IO, their associated overlayFS mount point\nmight become invalid, and container-puppet would fail to run.\n\nIn order to avoid the bug, create the docker-puppet containers\nsequentially to prevent any race, and make then run in detached\nmode, concurrently. This way, we keep honouring the concurrency\nsetting for image download and puppet run, so we do not degrade\nrun time overall.\n\nChange-Id: I3fd9b8f8ee131c5b2118d922b7756a7572c09108\nCloses-Bug: #1856324\n'}, {'number': 2, 'created': '2019-12-19 10:32:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ff229cab0d95342eb18df994c8379c44abba521f', 'message': 'container-puppet: create containers sequentially to avoid race\n\nDue to a race in podman 1.6.3, when containers are created in\nparallel under high disk IO, their associated overlayFS mount point\nmight become invalid, and container-puppet would fail to run.\n\nIn order to avoid the bug, create the docker-puppet containers\nsequentially to prevent any race, and make then run in detached\nmode, concurrently. This way, we keep honouring the concurrency\nsetting for image download and puppet run, so we do not degrade\nrun time overall.\n\nChange-Id: I3fd9b8f8ee131c5b2118d922b7756a7572c09108\nCloses-Bug: #1856324\n'}, {'number': 3, 'created': '2019-12-19 20:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/200e911758d3d576e041759ea923170171382765', 'message': 'container-puppet: create containers sequentially to avoid race\n\nDue to a race in podman 1.6.3, when containers are created in\nparallel under high disk IO, their associated overlayFS mount point\nmight become invalid, and container-puppet would fail to run.\n\nIn order to avoid the bug, create the docker-puppet containers\nsequentially to prevent any race, and make then run in detached\nmode, concurrently. This way, we keep honouring the concurrency\nsetting for image download and puppet run, so we do not degrade\nrun time overall.\n\nChange-Id: I3fd9b8f8ee131c5b2118d922b7756a7572c09108\nCloses-Bug: #1856324\n'}, {'number': 4, 'created': '2019-12-20 08:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d41a7610ab5ffbc5439e99ec0bf046d31ccfd8d5', 'message': 'container-puppet: create containers sequentially to avoid race\n\nDue to a race in podman 1.6.3, when containers are created in\nparallel under high disk IO, their associated overlayFS mount point\nmight become invalid, and container-puppet would fail to run.\n\nIn order to avoid the bug, create the docker-puppet containers\nsequentially to prevent any race, and make then run in detached\nmode, concurrently. This way, we keep honouring the concurrency\nsetting for image download and puppet run, so we do not degrade\nrun time overall.\n\nChange-Id: I3fd9b8f8ee131c5b2118d922b7756a7572c09108\nCloses-Bug: #1856324\n'}, {'number': 5, 'created': '2019-12-20 14:11:27.000000000', 'files': ['common/container-puppet.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0b9cf92a3829a0178600665a931ba6637cc34bb4', 'message': 'container-puppet: create containers sequentially to avoid race\n\nDue to a race in podman 1.6.3, when containers are created in\nparallel under high disk IO, their associated overlayFS mount point\nmight become invalid, and container-puppet would fail to run.\n\nIn order to avoid the bug, create the docker-puppet containers\nsequentially to prevent any race, and make then run in detached\nmode, concurrently. This way, we keep honouring the concurrency\nsetting for image download and puppet run, so we do not degrade\nrun time overall.\n\nChange-Id: I3fd9b8f8ee131c5b2118d922b7756a7572c09108\nCloses-Bug: #1856324\n'}]",0,699803,0b9cf92a3829a0178600665a931ba6637cc34bb4,22,4,5,20778,,,0,"container-puppet: create containers sequentially to avoid race

Due to a race in podman 1.6.3, when containers are created in
parallel under high disk IO, their associated overlayFS mount point
might become invalid, and container-puppet would fail to run.

In order to avoid the bug, create the docker-puppet containers
sequentially to prevent any race, and make then run in detached
mode, concurrently. This way, we keep honouring the concurrency
setting for image download and puppet run, so we do not degrade
run time overall.

Change-Id: I3fd9b8f8ee131c5b2118d922b7756a7572c09108
Closes-Bug: #1856324
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/03/699803/3 && git format-patch -1 --stdout FETCH_HEAD,['common/container-puppet.py'],1,81336cbe464b97519cdf726ef236ce82b25f276a,bug/1856324-puppet-detached," return 0 return retvaldef pull_container_image(*args): ( config_volume, puppet_tags, manifest, config_image, volumes, privileged, check_mode, keep_container ) = args[0] retval = pull_image(config_image) return retval def start_container(*args): '--detach=true', stdout, stderr, retval = local_subprocess_call( cmd=common_dcmd, env=ENV if stdout: LOG.debug('%s started: %s' % (uname, stdout)) if stderr: LOG.warning(stderr) return (uname, retval) def wait_container(*args): uname = args[0] common_dcmd = [ CLI_CMD, 'wait', uname ] LOG.info('Waiting for %s to finish' % uname) stdout, stderr, retval = local_subprocess_call( cmd=common_dcmd, env=ENV ) if retval == 0: # stdout holds the container return code return int(stdout) else: LOG.warning(stderr)def container_logs(uname): logs_dcmd = [ CLI_CMD, 'logs', uname ] stdout, stderr, retval = local_subprocess_call( cmd=logs_dcmd, env=ENV ) if retval != 0: LOG.warning('Could not retrieve logs of %s: err=%d %s' % (uname, retval)) if stderr: LOG.warning(stderr) return stdout # Download all container images concurrently RETURNCODES = list(p.map(pull_container_image, PROCESS_MAP)) if any(RETURNCODES): LOG.error('Not all images could be pulled. Aborting') raise SystemExit(1) count = 3 while len(PROCESS_MAP) > 0 and count > 0: # https://bugzilla.redhat.com/show_bug.cgi?id=1757845 # To prevent a race in podman that could mess up overlayfs mount # points, create the containers sequentially, to create their # overlayfs mount points without concurrency. Containers then # run in parallel (detached), so we honour the PROCESS_COUNT. UNAME_MAP = [] for proc in PROCESS_MAP: uname, c_ret = start_container(proc) UNAME_MAP.append(uname) RETURNCODES = list(p.map(wait_container, UNAME_MAP)) # scan result and extract failed container runs retry_list = [] for returncode, uname, process in zip(RETURNCODES, UNAME_MAP, PROCESS_MAP): logs = container_logs(uname) config_volume = process[0] if returncode not in [0, 2]: LOG.error('ERROR configuring %s: %s' % (config_volume, logs)) retry_list.append(process) else: LOG.debug('%s config succeeded: %s' % (config_volume, logs)) rm_container(uname) PROCESS_MAP = retry_list if len(retry_list) > 0: LOG.warning('%d puppet configuration(s) failed.' % len(retry_list)) count -= 1 if count > 0: LOG.warning('Retrying running puppet. %d attempt(s) left' % count) SUCCESS = len(PROCESS_MAP) != 0"," returndef mp_puppet_config(*args): pull_image(config_image) # Remove container by default after the run # This should mitigate the ""ghost container"" issue described here # https://bugzilla.redhat.com/show_bug.cgi?id=1747885 # https://bugs.launchpad.net/tripleo/+bug/1840691 if not keep_container: common_dcmd.append('--rm') # https://github.com/containers/libpod/issues/1844 # This block will run ""CONTAINER_CLI"" run 5 times before to fail. retval = -1 count = 0 LOG.debug( 'Running %s command: %s' % ( CONTAINER_CLI, ' '.join(common_dcmd) ) while count < 3: count += 1 stdout, stderr, retval = local_subprocess_call( cmd=common_dcmd, env=ENV ) # puppet with --detailed-exitcodes will return 0 for success and # no changes and 2 for success and resource changes. Other # numbers are failures if retval in [0, 2]: if stdout: LOG.debug('%s run succeeded: %s' % (common_dcmd, stdout)) if stderr: LOG.warning(stderr) # only delete successful runs, for debugging rm_container(uname) break time.sleep(3) LOG.error( '%s run failed after %s attempt(s): %s' % ( common_dcmd, stderr, count ) ) rm_container(uname) LOG.warning('Retrying running container: %s' % config_volume) else: if stdout: LOG.debug(stdout) if stderr: LOG.debug(stderr) LOG.error('Failed running container for %s' % config_volume) LOG.info( 'Finished processing puppet configs for %s' % ( config_volume ) ) RETURNCODES = list(PROCESS.map(mp_puppet_config, PROCESS_MAP)) CONFIG_VOLUMES = [pm[0] for pm in PROCESS_MAP] SUCCESS = True for returncode, config_volume in zip(RETURNCODES, CONFIG_VOLUMES): if returncode not in [0, 2]: LOG.error('ERROR configuring %s' % config_volume) SUCCESS = False",104,64
openstack%2Fneutron~master~I7ed1a742849dfce9e65b8eb36566112501fb0e39,openstack/neutron,master,I7ed1a742849dfce9e65b8eb36566112501fb0e39,Ensure driver error preventing trunk port deletion is logged,MERGED,2020-01-09 22:20:45.000000000,2020-01-28 21:55:52.000000000,2020-01-26 12:16:17.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 8313}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 15554}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 24042}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-09 22:20:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/862bd25dc45c85bec6328b5ea5e2cf043ec52fe6', 'message': 'Ensure driver error preventing trunk port deletion is logged\n\nWhen trunk port deletion is attempted but fails because the driver does\nnot permit it, the logs do not contain the driver error message that\nspecifies the precise rationale for preventing the trunk port deletion.\nLog it explicitly.\n\nChange-Id: I7ed1a742849dfce9e65b8eb36566112501fb0e39\n'}, {'number': 2, 'created': '2020-01-10 17:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3527b0921ba56cd3c4c7b81b99a99df8f35b4bb3', 'message': 'Ensure driver error preventing trunk port deletion is logged\n\nWhen trunk port deletion is attempted but fails because the driver does\nnot permit it, the logs do not contain the driver error message that\nspecifies the precise rationale for preventing the trunk port deletion.\nLog it explicitly.\n\nChange-Id: I7ed1a742849dfce9e65b8eb36566112501fb0e39\n'}, {'number': 3, 'created': '2020-01-22 15:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d5154e8f336440b91714fd66d9f47e48fc2c132', 'message': 'Ensure driver error preventing trunk port deletion is logged\n\nWhen trunk port deletion is attempted but fails because the driver does\nnot permit it, the logs do not contain the driver error message that\nspecifies the precise rationale for preventing the trunk port deletion.\nLog it explicitly.\n\nChange-Id: I7ed1a742849dfce9e65b8eb36566112501fb0e39\n'}, {'number': 4, 'created': '2020-01-22 16:09:29.000000000', 'files': ['neutron/services/trunk/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3b56299e1fa0b48bd4d674e57be2e289c4c28547', 'message': 'Ensure driver error preventing trunk port deletion is logged\n\nWhen trunk port deletion is attempted but fails because the driver does\nnot permit it, the logs do not contain the driver error message that\nspecifies the precise rationale for preventing the trunk port deletion.\nLog it explicitly.\n\nChange-Id: I7ed1a742849dfce9e65b8eb36566112501fb0e39\n'}]",7,701853,3b56299e1fa0b48bd4d674e57be2e289c4c28547,55,13,4,13995,,,0,"Ensure driver error preventing trunk port deletion is logged

When trunk port deletion is attempted but fails because the driver does
not permit it, the logs do not contain the driver error message that
specifies the precise rationale for preventing the trunk port deletion.
Log it explicitly.

Change-Id: I7ed1a742849dfce9e65b8eb36566112501fb0e39
",git fetch https://review.opendev.org/openstack/neutron refs/changes/53/701853/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/trunk/plugin.py'],1,862bd25dc45c85bec6328b5ea5e2cf043ec52fe6,report_trunk_port_deletion,"from oslo_utils import excutils try: trunk.delete() payload = callbacks.TrunkPayload(context, trunk_id, original_trunk=trunk) registry.notify(resources.TRUNK, events.PRECOMMIT_DELETE, self, payload=payload) except Exception as e: with excutils.save_and_reraise_exception(): LOG.info('Trunk driver raised exception when deleting ' 'trunk port %s: %s', trunk_id, str(e)) else: LOG.info('Trunk driver does not consider trunk %s ' 'untrunkable', trunk_id)"," trunk.delete() payload = callbacks.TrunkPayload(context, trunk_id, original_trunk=trunk) registry.notify(resources.TRUNK, events.PRECOMMIT_DELETE, self, payload=payload) else:",14,5
openstack%2Fkeystonemiddleware~stable%2Fqueens~I73bde68be53afff4e8dff12d756b8381f34b2adb,openstack/keystonemiddleware,stable/queens,I73bde68be53afff4e8dff12d756b8381f34b2adb,Make tests pass in 2022,MERGED,2020-01-07 19:21:25.000000000,2020-01-28 21:45:44.000000000,2020-01-28 21:45:44.000000000,"[{'_account_id': 1446}, {'_account_id': 1916}, {'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 11904}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-07 19:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/9c39b36e560a487ba7c4489f43fb3dfdf6674bab', 'message': 'Make tests pass in 2022\n\nBackground:\nAs part of my work on reproducible builds for openSUSE, I check that software still gives identical build results in the future.\nThe usual offset is +15 years, because that is how long I expect some software will be used in some places.\nThis showed up failing tests in our package build.\nSee https://reproducible-builds.org/ for why this matters.\n\nThis makes it expire 1 year in the future to model realistic tokens.\n\nChange-Id: I73bde68be53afff4e8dff12d756b8381f34b2adb\n(cherry picked from commit 4a4c96ce9b28ed54f93a21ca405c5b34ef3c3429)\n'}, {'number': 2, 'created': '2020-01-07 23:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/0d4d8bab7db962e56030d47f758c49e0efcf88ef', 'message': ""Make tests pass in 2022\n\nBackground:\nAs part of my work on reproducible builds for openSUSE, I check that software still gives identical build results in the future.\nThe usual offset is +15 years, because that is how long I expect some software will be used in some places.\nThis showed up failing tests in our package build.\nSee https://reproducible-builds.org/ for why this matters.\n\nThis makes it expire 1 year in the future to model realistic tokens.\n\nNOTE: there's an additional token expiration hardcoded date fix that is\nnot part of the original backport. We are piggybacking it onto this patch\nto avoid circular dependencies.\n\nChange-Id: I73bde68be53afff4e8dff12d756b8381f34b2adb\n(cherry picked from commit 4a4c96ce9b28ed54f93a21ca405c5b34ef3c3429)\n""}, {'number': 3, 'created': '2020-01-08 19:18:00.000000000', 'files': ['keystonemiddleware/tests/unit/auth_token/test_auth_token_middleware.py', 'keystonemiddleware/auth_token/_request.py', 'keystonemiddleware/tests/unit/client_fixtures.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/8b5202e730b5294b3420b7b64a62100f5309cc3e', 'message': ""Make tests pass in 2022\n\nBackground:\nAs part of my work on reproducible builds for openSUSE, I check that software still gives identical build results in the future.\nThe usual offset is +15 years, because that is how long I expect some software will be used in some places.\nThis showed up failing tests in our package build.\nSee https://reproducible-builds.org/ for why this matters.\n\nThis makes it expire 1 year in the future to model realistic tokens.\n\nNOTE: in addition to the orginal backport, this patch adds the following\nchanges. The changes has to be combined into a single patch in order to\navoid circular dependencies.\n\n1. fixed the hadcoded token expiration date in\nkeystonemiddleware/tests/unit/client_fixtures.py. This is using the same\ntechnique in the original backport.\n\n2. fixed bandit complains in keystonemiddleware/auth_token/_request.py.\nThe request environment variable names are not tokens. We'll need to\nmark them as false positives so bandit can stop chirping.\n\nChange-Id: I73bde68be53afff4e8dff12d756b8381f34b2adb\n(cherry picked from commit 4a4c96ce9b28ed54f93a21ca405c5b34ef3c3429)\n""}]",0,701438,8b5202e730b5294b3420b7b64a62100f5309cc3e,18,7,3,1916,,,0,"Make tests pass in 2022

Background:
As part of my work on reproducible builds for openSUSE, I check that software still gives identical build results in the future.
The usual offset is +15 years, because that is how long I expect some software will be used in some places.
This showed up failing tests in our package build.
See https://reproducible-builds.org/ for why this matters.

This makes it expire 1 year in the future to model realistic tokens.

NOTE: in addition to the orginal backport, this patch adds the following
changes. The changes has to be combined into a single patch in order to
avoid circular dependencies.

1. fixed the hadcoded token expiration date in
keystonemiddleware/tests/unit/client_fixtures.py. This is using the same
technique in the original backport.

2. fixed bandit complains in keystonemiddleware/auth_token/_request.py.
The request environment variable names are not tokens. We'll need to
mark them as false positives so bandit can stop chirping.

Change-Id: I73bde68be53afff4e8dff12d756b8381f34b2adb
(cherry picked from commit 4a4c96ce9b28ed54f93a21ca405c5b34ef3c3429)
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/38/701438/1 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/tests/unit/auth_token/test_auth_token_middleware.py'],1,9c39b36e560a487ba7c4489f43fb3dfdf6674bab,FTBFS2020-stable/stein-stable/rocky-stable/queens, 'expires': '%i-10-03T16:58:01Z' % (1 + time.gmtime().tm_year)}}}), 'expires': '2022-10-03T16:58:01Z'}}}),2,1
openstack%2Fkeystone~master~Icb0b7cbcb830a55910942b36a111562b83554f3d,openstack/keystone,master,Icb0b7cbcb830a55910942b36a111562b83554f3d,Cleanup doc/requirements.txt,MERGED,2020-01-14 09:18:04.000000000,2020-01-28 21:32:38.000000000,2020-01-28 21:29:50.000000000,"[{'_account_id': 8482}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2020-01-14 09:18:04.000000000', 'files': ['doc/requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/6dbf3a68b460a5aa7fb2bf7a9f9433f5b10a9ca2', 'message': 'Cleanup doc/requirements.txt\n\nChange-Id: Icb0b7cbcb830a55910942b36a111562b83554f3d\n'}]",0,702374,6dbf3a68b460a5aa7fb2bf7a9f9433f5b10a9ca2,12,4,1,27621,,,0,"Cleanup doc/requirements.txt

Change-Id: Icb0b7cbcb830a55910942b36a111562b83554f3d
",git fetch https://review.opendev.org/openstack/keystone refs/changes/74/702374/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/requirements.txt'],1,6dbf3a68b460a5aa7fb2bf7a9f9433f5b10a9ca2,,"sphinx!=1.6.6,!=1.6.7,!=2.1.0,>=1.6.2 # BSD","sphinx!=1.6.6,!=1.6.7,!=2.1.0,>=1.6.2;python_version>='3.4' # BSD",1,1
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I2ae2f498c70d2c6d90c6f760d7d4a09a36403722,openstack/tripleo-heat-templates,stable/train,I2ae2f498c70d2c6d90c6f760d7d4a09a36403722,Fix hieradata for Heat API timeout,MERGED,2020-01-28 15:33:15.000000000,2020-01-28 21:21:47.000000000,2020-01-28 21:21:47.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-28 15:33:15.000000000', 'files': ['deployment/heat/heat-api-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d7b13a24d2c92ff0001344856d7211872de93f70', 'message': ""Fix hieradata for Heat API timeout\n\npuppet-tripleo uses heat::wsgi::apache_api and not heat::wsgi::apache so\nwe need to update the hieradata. Also let's move it to the heat-api\nservice and not in base.\n\nDepends-On: I7da55899b9108daced7adb8f82bdb58fcf97aa09\nChange-Id: I2ae2f498c70d2c6d90c6f760d7d4a09a36403722\n(cherry picked from commit d2db2292e59fe56fc969c93a60a985178bf89f09)\n""}]",0,704592,d7b13a24d2c92ff0001344856d7211872de93f70,7,3,1,14985,,,0,"Fix hieradata for Heat API timeout

puppet-tripleo uses heat::wsgi::apache_api and not heat::wsgi::apache so
we need to update the hieradata. Also let's move it to the heat-api
service and not in base.

Depends-On: I7da55899b9108daced7adb8f82bdb58fcf97aa09
Change-Id: I2ae2f498c70d2c6d90c6f760d7d4a09a36403722
(cherry picked from commit d2db2292e59fe56fc969c93a60a985178bf89f09)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/92/704592/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/heat/heat-api-container-puppet.yaml'],1,d7b13a24d2c92ff0001344856d7211872de93f70,bug/1860475, heat::wsgi::apache_api::vhost_custom_fragment: 'Timeout 600',,1,0
openstack%2Fopenstack-helm-infra~master~I4d217882db700c1aa7fb6a3a0df9859918af03a1,openstack/openstack-helm-infra,master,I4d217882db700c1aa7fb6a3a0df9859918af03a1,This fixes App-armor Zuul gate jobs.,ABANDONED,2020-01-28 18:01:45.000000000,2020-01-28 21:12:53.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-01-28 18:01:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f26f2fdfc428a0d423a9a0fe4ac9211a5b9dcf5a', 'message': 'This fixes App-armor Zuul gate jobs.\n\nChange-Id: I4d217882db700c1aa7fb6a3a0df9859918af03a1\nSigned-off-by: diwakar thyagaraj <diwakar.chitoor.thyagaraj@att.com>'}]",0,704647,f26f2fdfc428a0d423a9a0fe4ac9211a5b9dcf5a,3,1,1,29131,,,0,"This fixes App-armor Zuul gate jobs.

Change-Id: I4d217882db700c1aa7fb6a3a0df9859918af03a1
Signed-off-by: diwakar thyagaraj <diwakar.chitoor.thyagaraj@att.com>",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/47/704647/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,f26f2fdfc428a0d423a9a0fe4ac9211a5b9dcf5a,apparmor,,,0,0
openstack%2Fopenstack-helm~master~Icec98c5166611a8c538f93e6326cf7d20b545ecd,openstack/openstack-helm,master,Icec98c5166611a8c538f93e6326cf7d20b545ecd,Make sure requested mtu is set,MERGED,2020-01-28 18:34:48.000000000,2020-01-28 20:54:44.000000000,2020-01-28 20:53:03.000000000,"[{'_account_id': 8898}, {'_account_id': 11934}, {'_account_id': 16881}, {'_account_id': 18250}, {'_account_id': 20466}, {'_account_id': 20469}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 23928}]","[{'number': 1, 'created': '2020-01-28 18:34:48.000000000', 'files': ['neutron/templates/bin/_neutron-openvswitch-agent-init.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/f00777e57d4da05d65a292b2a797f99d853a43e1', 'message': ""Make sure requested mtu is set\n\nThe 'options' keyword for setting mtu in 'set interface' does not\nset mtu and it seems to ignore/fail the request silently.\n\nChange-Id: Icec98c5166611a8c538f93e6326cf7d20b545ecd\n""}]",0,704657,f00777e57d4da05d65a292b2a797f99d853a43e1,13,10,1,18256,,,0,"Make sure requested mtu is set

The 'options' keyword for setting mtu in 'set interface' does not
set mtu and it seems to ignore/fail the request silently.

Change-Id: Icec98c5166611a8c538f93e6326cf7d20b545ecd
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/57/704657/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/templates/bin/_neutron-openvswitch-agent-init.sh.tpl'],1,f00777e57d4da05d65a292b2a797f99d853a43e1,," dpdk_options+='mtu_request=${mtu} ' dev_args_str+="" -- set Interface ""${nic_name}"" mtu_request=${mtu}"""," dpdk_options+='options:mtu_request=${mtu} ' dev_args_str+="" -- set Interface ""${nic_name}"" options:mtu_request=${mtu}""",2,2
openstack%2Fneutron~master~Ia05df925eccf3c9d397748f282e995203a058de9,openstack/neutron,master,Ia05df925eccf3c9d397748f282e995203a058de9,objects: automatically detect whether engine facade is used,MERGED,2018-03-15 21:39:47.000000000,2020-01-28 20:50:32.000000000,2018-05-02 13:06:53.000000000,"[{'_account_id': 4694}, {'_account_id': 7249}, {'_account_id': 9656}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 11816}, {'_account_id': 11975}, {'_account_id': 15752}, {'_account_id': 15905}, {'_account_id': 16376}, {'_account_id': 17491}, {'_account_id': 22348}, {'_account_id': 25903}, {'_account_id': 27654}]","[{'number': 1, 'created': '2018-03-15 21:39:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1c5e7205ea9868301969c39be561d94176995015', 'message': ""WIP objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 2, 'created': '2018-03-16 10:53:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/990db6f03c130ec4205f641c62f73177c829b15a', 'message': ""WIP objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 3, 'created': '2018-03-19 08:11:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d706f293b057a206fa0403976a18804a2ecdb4ae', 'message': ""WIP objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 4, 'created': '2018-03-21 00:46:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f436125455abf1667e8012c4be928ce5de49ef0f', 'message': ""WIP objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 5, 'created': '2018-03-21 23:02:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/915d4591362a0ed975a8c35008731bbc207f2a28', 'message': ""objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 6, 'created': '2018-03-21 23:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e6c83a16db1b76504126855e8e810fca4d8d8496', 'message': ""objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 7, 'created': '2018-04-10 20:43:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a9e226b8c1943941bdb87d1a23ed3fc269b2b422', 'message': ""objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 8, 'created': '2018-04-11 17:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb506b6f8929bbc38be4e8ae6e5bd2abb382b14a', 'message': ""objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 9, 'created': '2018-04-11 18:33:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/63190396527b5d1870638aa65006ec97475ecb0c', 'message': ""objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 10, 'created': '2018-04-11 18:37:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/88674ea20cade384d73e3396cef8bf4f37c7b5b6', 'message': ""objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 11, 'created': '2018-04-11 20:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a94facd6f9a73e554d844054961a7871230ebf98', 'message': ""objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 12, 'created': '2018-04-12 19:32:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d927bd0a9e00f3040b4c66502f65c92ac2e50a83', 'message': ""objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 13, 'created': '2018-04-12 19:35:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/85792ae33c71e502562c98648b141a5e289ec445', 'message': ""objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 14, 'created': '2018-04-12 22:23:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bf6f465d4fcf8d32738479466e23b5e132ea92ca', 'message': ""objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 15, 'created': '2018-04-13 09:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/add3379fc066cccf1a2ac6c43c53aeda34c43719', 'message': ""objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 16, 'created': '2018-04-16 21:11:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2d30384ae5cebdac4b2e003db564ce92f642e1b5', 'message': ""objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 17, 'created': '2018-04-17 18:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e63e2826d57401bf2c8ba7a85fa751bd89a2deab', 'message': ""objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 18, 'created': '2018-04-23 18:27:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/975ec39b6536193b8ac27d92b032cc148b3a4a7e', 'message': ""objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 19, 'created': '2018-04-23 19:18:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b7505489b918d83503e20807c9207708362a1e74', 'message': ""objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 20, 'created': '2018-04-27 21:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/37c733ad09d153798fc2b63ceac597d77e8b8369', 'message': ""objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}, {'number': 21, 'created': '2018-04-27 21:50:23.000000000', 'files': ['neutron/tests/unit/plugins/ml2/test_plugin.py', 'doc/source/contributor/internals/objects_usage.rst', 'neutron/objects/base.py', 'neutron/tests/unit/objects/test_base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/92b95815318806f90eca987145ad453782dd7041', 'message': ""objects: automatically detect whether engine facade is used\n\nWhile we added new_facade object attribute to framework and it has its\nniche and used in some stadium subprojects, it's not ideal because it's\nglobal to an object. Meaning that if you mark an object for new_facade =\nTrue, *all* business logic using the object must also switch to new\nfacade in the same step, which is a pain and sometimes close to\nimpossible to do without changing thousands loosely related lines of\ncode in multiple modules. It would be nice to instead use objects as\nusual in different contexts - some using engine facade and some still\nusing session.begin(...) - and allow the OVO framework to pick the right\nway to nest subtransactions.\n\nThis patch does exactly that. We call an internal function from oslo.db\nand check whether it raises an exception. If it does, it means that the\nengine facade is not used; otherwise, we use the new style of nested\ntransactions management.\n\nBy default, if session is not active when OVO action is called, we stick\nto the old facade. Once we are done with switching the rest of the\nplugin code / OVO objects to the new facade, we will rip off the\ntransitionary logic.\n\nChange-Id: Ia05df925eccf3c9d397748f282e995203a058de9\nPartially-Implements: blueprint enginefacade-switch\nPartially-Implements: blueprint adopt-oslo-versioned-objects-for-db\n""}]",10,553617,92b95815318806f90eca987145ad453782dd7041,151,15,21,9656,,,0,"objects: automatically detect whether engine facade is used

While we added new_facade object attribute to framework and it has its
niche and used in some stadium subprojects, it's not ideal because it's
global to an object. Meaning that if you mark an object for new_facade =
True, *all* business logic using the object must also switch to new
facade in the same step, which is a pain and sometimes close to
impossible to do without changing thousands loosely related lines of
code in multiple modules. It would be nice to instead use objects as
usual in different contexts - some using engine facade and some still
using session.begin(...) - and allow the OVO framework to pick the right
way to nest subtransactions.

This patch does exactly that. We call an internal function from oslo.db
and check whether it raises an exception. If it does, it means that the
engine facade is not used; otherwise, we use the new style of nested
transactions management.

By default, if session is not active when OVO action is called, we stick
to the old facade. Once we are done with switching the rest of the
plugin code / OVO objects to the new facade, we will rip off the
transitionary logic.

Change-Id: Ia05df925eccf3c9d397748f282e995203a058de9
Partially-Implements: blueprint enginefacade-switch
Partially-Implements: blueprint adopt-oslo-versioned-objects-for-db
",git fetch https://review.opendev.org/openstack/neutron refs/changes/17/553617/13 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributor/internals/objects_usage.rst', 'neutron/objects/base.py', 'neutron/tests/unit/objects/test_base.py']",3,1c5e7205ea9868301969c39be561d94176995015,bp/adopt-oslo-versioned-objects-for-db,"from neutron.db import api as db_api # for engine facade, we didn't have distinction between r/o and r/w # transactions and so we always call commit even for getters when no # facade is used if self._test_class._use_db_facade else SQLALCHEMY_COMMIT) with db_api.autonested_transaction(self.context.session): self._test_class.get_objects(self.context) self.assertEqual(1, mock_exit.call_count) def test_get_objects_single_transaction_enginefacade(self): with mock.patch(self._get_ro_txn_exit_func_name()) as mock_exit: with db_api.context_manager.reader.using(self.context): self._test_class.get_objects(self.context) with db_api.autonested_transaction(self.context.session): obj = self._test_class.get_object(self.context, **obj._get_composite_keys()) self.assertEqual(1, mock_exit.call_count) def test_get_object_single_transaction_enginefacade(self): obj = self._make_object(self.obj_fields[0]) obj.create() with mock.patch(self._get_ro_txn_exit_func_name()) as mock_exit: with db_api.context_manager.reader.using(self.context): obj = self._test_class.get_object(self.context, **obj._get_composite_keys())"," # for old engine facade, we didn't have distinction between r/o and r/w # transactions and so we always call commit even for getters when the # old facade is used if self._test_class.new_facade else SQLALCHEMY_COMMIT) self._test_class.get_objects(self.context) obj = self._test_class.get_object(self.context, **obj._get_composite_keys())",41,9
openstack%2Fneutron~stable%2Fstein~I10e3619d5f3600ea97ed695321bb691dece3181f,openstack/neutron,stable/stein,I10e3619d5f3600ea97ed695321bb691dece3181f,Add retries to update trunk port,MERGED,2020-01-14 08:16:13.000000000,2020-01-28 20:48:26.000000000,2020-01-28 20:46:32.000000000,"[{'_account_id': 1131}, {'_account_id': 9732}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-14 08:16:13.000000000', 'files': ['neutron/services/trunk/rpc/server.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7a8b59624c87b6b74f28e98a1cff1d6a40edc65f', 'message': 'Add retries to update trunk port\n\nIn [1] retry of trunk update was added to avoid StaleDataError\nexceptions to fail to set trunk port or subports to ACTIVE state.\nBut it was only partial fix for the issue descibed in related bug\nand from [2] we know that it still can happen on high load systems\nfrom time to time.\nSo I was checking this issue and reported bug again and I found out\nthat retry was added only in _process_trunk_subport_bindings()\nmethod. But StaleDataError can be raised also in other cases where\nthe same trunk is updated, e.g. in update_trunk_status() method.\n\nSo this commit adds same retry mechanism to all trunk.update() actions\nin services.trunk.rpc.server module.\n\n[1] https://review.opendev.org/#/c/662236/\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=1733197\n\nConflicts:\n    neutron/services/trunk/rpc/server.py\n\nChange-Id: I10e3619d5f3600ea97ed695321bb691dece3181f\nPartial-Bug: #1828375\n(cherry picked from commit ade35a233edb5c9489cc3a68ae00672fb328f63d)\n'}]",0,702364,7a8b59624c87b6b74f28e98a1cff1d6a40edc65f,32,6,1,11975,,,0,"Add retries to update trunk port

In [1] retry of trunk update was added to avoid StaleDataError
exceptions to fail to set trunk port or subports to ACTIVE state.
But it was only partial fix for the issue descibed in related bug
and from [2] we know that it still can happen on high load systems
from time to time.
So I was checking this issue and reported bug again and I found out
that retry was added only in _process_trunk_subport_bindings()
method. But StaleDataError can be raised also in other cases where
the same trunk is updated, e.g. in update_trunk_status() method.

So this commit adds same retry mechanism to all trunk.update() actions
in services.trunk.rpc.server module.

[1] https://review.opendev.org/#/c/662236/
[2] https://bugzilla.redhat.com/show_bug.cgi?id=1733197

Conflicts:
    neutron/services/trunk/rpc/server.py

Change-Id: I10e3619d5f3600ea97ed695321bb691dece3181f
Partial-Bug: #1828375
(cherry picked from commit ade35a233edb5c9489cc3a68ae00672fb328f63d)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/64/702364/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/trunk/rpc/server.py'],1,7a8b59624c87b6b74f28e98a1cff1d6a40edc65f,bug/1828375," def _safe_update_trunk(self, trunk, **kwargs): trunk.update(**kwargs) def update_trunk_status(self, context, trunk_id, status): """"""Update the trunk status to reflect outcome of data plane wiring."""""" with db_api.autonested_transaction(context.session): trunk = trunk_objects.Trunk.get_object(context, id=trunk_id) if trunk: self._safe_update_trunk(trunk, status=status) def _process_trunk_subport_bindings(self, context, trunk, port_ids): """"""Process port bindings for subports on the given trunk."""""" updated_ports = [] trunk_port_id = trunk.port_id trunk_port = self.core_plugin.get_port(context, trunk_port_id) trunk_host = trunk_port.get(portbindings.HOST_ID) # NOTE(status_police) Set the trunk in BUILD state before # processing subport bindings. The trunk will stay in BUILD # state until an attempt has been made to bind all subports # passed here and the agent acknowledges the operation was # successful. self._safe_update_trunk( trunk, status=trunk_consts.BUILD_STATUS) self._safe_update_trunk( trunk, status=trunk_consts.ERROR_STATUS) self._safe_update_trunk( trunk, status=trunk_consts.DEGRADED_STATUS)"," def update_trunk_status(self, context, trunk_id, status): """"""Update the trunk status to reflect outcome of data plane wiring."""""" with db_api.autonested_transaction(context.session): trunk = trunk_objects.Trunk.get_object(context, id=trunk_id) if trunk: trunk.update(status=status) def _process_trunk_subport_bindings(self, context, trunk, port_ids): """"""Process port bindings for subports on the given trunk."""""" updated_ports = [] trunk_port_id = trunk.port_id trunk_port = self.core_plugin.get_port(context, trunk_port_id) trunk_host = trunk_port.get(portbindings.HOST_ID) # NOTE(status_police) Set the trunk in BUILD state before # processing subport bindings. The trunk will stay in BUILD # state until an attempt has been made to bind all subports # passed here and the agent acknowledges the operation was # successful. trunk.update(status=trunk_consts.BUILD_STATUS) trunk.update(status=trunk_consts.ERROR_STATUS) trunk.update(status=trunk_consts.DEGRADED_STATUS)",28,22
openstack%2Fopenstack-helm-infra~master~I399d120a2d884da1d8530cf0fb20721c5b7259e6,openstack/openstack-helm-infra,master,I399d120a2d884da1d8530cf0fb20721c5b7259e6,tools: Allow custom base images for kubeadm AIO,ABANDONED,2019-10-21 16:46:20.000000000,2020-01-28 20:45:27.000000000,,"[{'_account_id': 7769}, {'_account_id': 8898}, {'_account_id': 12281}, {'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23928}, {'_account_id': 28618}, {'_account_id': 30777}]","[{'number': 1, 'created': '2019-10-21 16:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2f35b5fbf4f1d719e9569301f99a6f9e8a23a33f', 'message': 'tools: Allow custom base images for kubeadm AIO\n\nThis change adds support for modifying the kubeadm AIO base image using\nAnsible playbook vars. Using a custom base image allows users behind a\ncorporate proxy server to download custom-hosted images behind their\nfirewall, enabling quicker setup times.\n\nChange-Id: I399d120a2d884da1d8530cf0fb20721c5b7259e6\nSigned-off-by: Drew Walters <andrew.walters@att.com>\n'}, {'number': 2, 'created': '2019-10-22 16:22:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/65cb4a019258df54b280bf5c900af614adbfa8a1', 'message': 'tools: Allow custom base images for kubeadm AIO\n\nThis change adds support for modifying the kubeadm AIO base image using\nAnsible playbook vars. Using a custom base image allows users behind a\ncorporate proxy server to download custom-hosted images behind their\nfirewall, enabling quicker setup times.\n\nChange-Id: I399d120a2d884da1d8530cf0fb20721c5b7259e6\nSigned-off-by: Drew Walters <andrew.walters@att.com>\n'}, {'number': 3, 'created': '2019-10-29 21:08:53.000000000', 'files': ['tools/images/kubeadm-aio/Dockerfile', 'roles/build-images/defaults/main.yml', 'roles/build-images/tasks/kubeadm-aio.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/14a4af79f24aed18cf3f29c33ae19037b9d42f3b', 'message': 'tools: Allow custom base images for kubeadm AIO\n\nThis change adds support for modifying the kubeadm AIO base image using\nAnsible playbook vars. Using a custom base image allows users behind a\ncorporate proxy server to download custom-hosted images behind their\nfirewall, enabling quicker setup times.\n\nChange-Id: I399d120a2d884da1d8530cf0fb20721c5b7259e6\nSigned-off-by: Drew Walters <andrew.walters@att.com>\n'}]",0,689840,14a4af79f24aed18cf3f29c33ae19037b9d42f3b,22,11,3,28618,,,0,"tools: Allow custom base images for kubeadm AIO

This change adds support for modifying the kubeadm AIO base image using
Ansible playbook vars. Using a custom base image allows users behind a
corporate proxy server to download custom-hosted images behind their
firewall, enabling quicker setup times.

Change-Id: I399d120a2d884da1d8530cf0fb20721c5b7259e6
Signed-off-by: Drew Walters <andrew.walters@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/40/689840/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/images/kubeadm-aio/Dockerfile', 'roles/build-images/defaults/main.yml', 'roles/build-images/tasks/kubeadm-aio.yaml']",3,2f35b5fbf4f1d719e9569301f99a6f9e8a23a33f,," --build-arg FROM=""{{ images.ubuntu.ubuntu_base_image }}"" \ --build-arg FROM=""{{ images.ubuntu.ubuntu_base_image }}"" \",,7,1
openstack%2Fopenstack-helm-addons~master~Ifec1113b35576ec0a641eae87d89591950dda463,openstack/openstack-helm-addons,master,Ifec1113b35576ec0a641eae87d89591950dda463,mini-mirror: Add deployment gate job,ABANDONED,2019-11-25 17:08:05.000000000,2020-01-28 20:44:59.000000000,,"[{'_account_id': 7769}, {'_account_id': 8898}, {'_account_id': 12281}, {'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23928}, {'_account_id': 28618}]","[{'number': 1, 'created': '2019-11-25 17:08:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/6e3f14b9ad609ad8edb7d821fad9bbff4e6162f8', 'message': 'mini-mirror: Add deployment gate job\n\nThis change adds a gate job that deploys the mini-mirror chart.\n\nChange-Id: Ifec1113b35576ec0a641eae87d89591950dda463\nSigned-off-by: Drew Walters <andrew.walters@att.com>\n'}, {'number': 2, 'created': '2019-11-25 17:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/c3648632a1d64bfcd5493640bfa18846f39b0355', 'message': 'mini-mirror: Add deployment gate job\n\nThis change adds a gate job that deploys the mini-mirror chart.\n\nChange-Id: Ifec1113b35576ec0a641eae87d89591950dda463\nSigned-off-by: Drew Walters <andrew.walters@att.com>\n'}, {'number': 3, 'created': '2019-11-25 19:27:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/323873dd7bbd8959109d7d0b7a72be3157b424af', 'message': 'mini-mirror: Add deployment gate job\n\nThis change adds a gate job that deploys the mini-mirror chart.\n\nChange-Id: Ifec1113b35576ec0a641eae87d89591950dda463\nSigned-off-by: Drew Walters <andrew.walters@att.com>\n'}, {'number': 4, 'created': '2019-12-05 17:01:27.000000000', 'files': ['tools/gate/scripts/mini-mirror.sh', 'tools/gate/playbooks/osh-addons-mini-mirror.yaml', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/6be4650739b83c2d5acd8d75343bf8c8be4bc336', 'message': 'mini-mirror: Add deployment gate job\n\nThis change adds a gate job that deploys the mini-mirror chart.\n\nChange-Id: Ifec1113b35576ec0a641eae87d89591950dda463\nSigned-off-by: Drew Walters <andrew.walters@att.com>\n'}]",0,695946,6be4650739b83c2d5acd8d75343bf8c8be4bc336,14,9,4,28618,,,0,"mini-mirror: Add deployment gate job

This change adds a gate job that deploys the mini-mirror chart.

Change-Id: Ifec1113b35576ec0a641eae87d89591950dda463
Signed-off-by: Drew Walters <andrew.walters@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-addons refs/changes/46/695946/3 && git format-patch -1 --stdout FETCH_HEAD,"['tools/gate/scripts/mini-mirror.sh', 'tools/gate/playbooks/osh-addons-mini-mirror.yaml', '.zuul.yaml']",3,6e3f14b9ad609ad8edb7d821fad9bbff4e6162f8,, - openstack-helm-addons-mini-mirror - openstack-helm-addons-mini-mirror - job: name: openstack-helm-addons-mini-mirror required-projects: - openstack/openstack-helm-infra - openstack/openstack-helm roles: - zuul: openstack/openstack-helm-infra timeout: 7200 vars: osh_openstack_release: newton zuul_osh_infra_relative_path: ../openstack-helm-infra/ zuul_osh_relative_path: ../openstack-helm/ nodeset: openstack-helm-ubuntu pre-run: - tools/gate/playbooks/osh-infra-upgrade-host.yaml - tools/gate/playbooks/osh-infra-deploy-docker.yaml - tools/gate/playbooks/osh-infra-build.yaml - tools/gate/playbooks/osh-infra-deploy-k8s.yaml run: tools/gate/playbooks/osh-addons-mini-mirror.yaml post-run: tools/gate/playbooks/osh-infra-collect-logs.yaml files: - ^mini-mirror/.*$,,75,0
openstack%2Fkeystonemiddleware~stable%2Frocky~Ib9a62a4cd0b7b9ffb9fa2d6440e8072d45ee0fee,openstack/keystonemiddleware,stable/rocky,Ib9a62a4cd0b7b9ffb9fa2d6440e8072d45ee0fee,Make sure audit middleware use own context,MERGED,2019-04-29 02:47:24.000000000,2020-01-28 20:42:06.000000000,2020-01-28 20:39:31.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-04-29 02:47:24.000000000', 'files': ['keystonemiddleware/tests/unit/audit/test_audit_api.py', 'keystonemiddleware/tests/unit/audit/test_audit_middleware.py', 'keystonemiddleware/audit/__init__.py', 'releasenotes/notes/bug-1809101-6b5088443d5970ba.yaml'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/47294755ab90b2c24a67836fb9321adc52b26bff', 'message': ""Make sure audit middleware use own context\n\nKeystone audit middleware requires to iterate req.context as dict,\nbut Glance requires to access req.context.read_only.\nWhen glance enabled audit, they are conflict with each other.\nThis patch fix this issue by store audit context in\nreq.environ['audit.context']\n\nChange-Id: Ib9a62a4cd0b7b9ffb9fa2d6440e8072d45ee0fee\nCloses-Bug: #1809101\nSigned-off-by: Leehom Li <feli5@cisco.com>\n(cherry picked from commit 82707e15a5bce8de2d33b1c865c96844c9770580)\n""}]",0,656230,47294755ab90b2c24a67836fb9321adc52b26bff,11,5,1,19156,,,0,"Make sure audit middleware use own context

Keystone audit middleware requires to iterate req.context as dict,
but Glance requires to access req.context.read_only.
When glance enabled audit, they are conflict with each other.
This patch fix this issue by store audit context in
req.environ['audit.context']

Change-Id: Ib9a62a4cd0b7b9ffb9fa2d6440e8072d45ee0fee
Closes-Bug: #1809101
Signed-off-by: Leehom Li <feli5@cisco.com>
(cherry picked from commit 82707e15a5bce8de2d33b1c865c96844c9770580)
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/30/656230/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystonemiddleware/tests/unit/audit/test_audit_api.py', 'keystonemiddleware/tests/unit/audit/test_audit_middleware.py', 'keystonemiddleware/audit/__init__.py', 'releasenotes/notes/bug-1809101-6b5088443d5970ba.yaml']",4,47294755ab90b2c24a67836fb9321adc52b26bff,bug/1809101-stable/rocky,--- fixes: - | [`bug 1809101 <https://bugs.launchpad.net/keystonemiddleware/+bug/1809101>`_] Fix req.context of Keystone audit middleware and Glance conflict with each other issue. The audit middleware now stores the admin context to req.environ['audit.context']. ,,18,10
openstack%2Fossa~master~Ie93e5717981a938c465e42d8c207bd92bbd870c1,openstack/ossa,master,Ie93e5717981a938c465e42d8c207bd92bbd870c1,A fond farewell to Morgan Fainberg,MERGED,2020-01-28 17:34:22.000000000,2020-01-28 20:39:39.000000000,2020-01-28 20:36:20.000000000,"[{'_account_id': 2903}, {'_account_id': 14288}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-28 17:34:22.000000000', 'files': ['doc/source/index.rst', 'doc/source/_static/0x0d1a8c8423cf3c86bf420f7bb9a83cefa07c6d8a.txt'], 'web_link': 'https://opendev.org/openstack/ossa/commit/23af4fc5e828a6eb86f7e5f3a705f22fff60c2f4', 'message': ""A fond farewell to Morgan Fainberg\n\nMorgan Fainberg has acknowledged that he no longer has sufficient\nopportunity to serve as a vulnerability manager for OpenStack.\nThanks so much, Morgan, for all your assistance over the years.\nHopefully we'll still see you around from time to time!\n\nChange-Id: Ie93e5717981a938c465e42d8c207bd92bbd870c1\n""}]",0,704640,23af4fc5e828a6eb86f7e5f3a705f22fff60c2f4,9,4,1,5263,,,0,"A fond farewell to Morgan Fainberg

Morgan Fainberg has acknowledged that he no longer has sufficient
opportunity to serve as a vulnerability manager for OpenStack.
Thanks so much, Morgan, for all your assistance over the years.
Hopefully we'll still see you around from time to time!

Change-Id: Ie93e5717981a938c465e42d8c207bd92bbd870c1
",git fetch https://review.opendev.org/openstack/ossa refs/changes/40/704640/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/_static/0x0d1a8c8423cf3c86bf420f7bb9a83cefa07c6d8a.txt']",2,23af4fc5e828a6eb86f7e5f3a705f22fff60c2f4,farewell-morgan,,pub 4096R/0xB9A83CEFA07C6D8A 2016-04-19 Key fingerprint = 0D1A 8C84 23CF 3C86 BF42 0F7B B9A8 3CEF A07C 6D8A uid [ unknown] Morgan Fainberg <morgan.fainberg@gmail.com> uid [ unknown] Morgan Fainberg <notmorgan@redhat.com> uid [ unknown] Morgan Fainberg <morgan@tempusfrang.it> uid [ unknown] Morgan Fainberg <morgan@modernsteam.net> uid [ unknown] Morgan Fainberg <morgan.fainberg@tempusfrang.it> uid [ unknown] Morgan Fainberg <morgan.fainberg@modernsteam.net> uid [ unknown] Morgan Fainberg <morgan.fainberg@tempusfrangit.org> uid [ unknown] [jpeg image of size 14556] sub 4096R/0x07E5A46A1474DDE5 2016-04-19 sub 4096R/0xC82B7A3F9227005D 2016-05-17 -----BEGIN PGP PUBLIC KEY BLOCK----- Version: GnuPG v2 mQINBFcWftcBEAC8fQ3r/ut0lAqmccksY1SkLvTuxzEyGgiqNbhDV3bKxTjNPV4t l/Q9zIJ6Jq6tq2NpvC75IOQUpfJiSo2XisOK6l/W2tvqf2wesCQH+LKji6t/hTRu xA7sNKbmfdN40sri878ve5hB+66Asbs0soq/3AXO1W28Aj831IBwAOIDkRPSmrJ9 v7nHD9VTSF5rBexVYc/op4qYuaV/93D5YSG+1gLgValLJoNIZjssl5kBSRsAm5pU sQM4Zy1cX2qQiT2mTlnFoNkDP/bJCwGh8qOsD10+rjrSoeLhuZa/y4ZSWsTl2cTJ S1nLZ0Rag25F6afn1niefQwqiC0J61b/xSzz3IERhk8OB9IgTiKoOFFbWg5+mv73 oi6M21X6ygTZ44CCVkzUeAdn4Wc2dWTZsa1AN6RAgl82uoziKPsabDeXaEnmT+40 84wzycXYqNe+992V/peqFcQ2sTMpNoDwImO0/6wJne86GguuwRkndE+Kp7S8sx9u Bkaz6iFRtdBWRNBWrdCJ11KEO1qmkDhc9BGUp64G8dz/GqWLSaDYbyBXaJHTxGUM 3nXlpAu9hrsWe7aov5ap5QmtVzMIJeBTjnfwSg6QB90b+R9ROnXFCkVToMEUpapr PFOxwrkI3+x0NrLFs4tCWtNbFMyTNKumaChGS9sDx6o96CSlztgVsu4VVQARAQAB tCZNb3JnYW4gRmFpbmJlcmcgPG5vdG1vcmdhbkByZWRoYXQuY29tPokCNwQTAQoA IQIbAwULCQgHAwUVCgkICwUWAgMBAAIeAQIXgAUCV0H+NgAKCRC5qDzvoHxtiqd2 D/4xG3NPLrTDUhKwrO7WxopI0nZk6L2ZQKy+ZR/kVLBezEtlx9G7BIJ1gHmM/MYy Jb1lYGPO7eRy6owyzTPSVuNqdKVw1Ov+aGnZ8eviAv83vMPpg4YuBAkH9Tv1pV1s Iqz1sALxiEsB4gs0NjRhA4X0d/hjI7o6neF2rpgAJ7N/rxYOgZiLFO/DqI7ey0E7 m+LFPgAJ6RFDZqUFYnX/txgRwGN1HDBaBkVvi4ln8pprVB2yp5BMtRp53/ICb+Ec kTIcv3kkBoZYizokyrZL2bVg3bAU7giBxv1OvB5qiXWMHVXT8//i6UH9AcVfnICQ A5jd2jnao14zJKBANn9tZdUqs8FJIyEVN7Rk8jshYrUwhNm59efl983T1JRuSHuR 03jk3Zq3V2LcrvI4oz6E0Yd7LU4zx0guvpAixMl0RFklh/RI/toPSYMAYV0xuTmO 7wNMX08ztcGKWE7K2VXHwewXxMK09m9hTwRWVIoiTNLX6TTqO8+JWpZAVAQ/MbOv 7uyS75mfIKL1oMCLpqjCVKK2XaSPaYIMQWWxoQS5WvavRZGS7APpTdnaKdSTteXz SSrZ36QP1meGv95zntBGk1XFNXvCjh6kgNQ8HYgo9WxUju/bDfMLhrlzDC0iVERY 1+36LTng14pKUivSlZs6yNzf++K0khrq5NNavozHhjRSKbQnTW9yZ2FuIEZhaW5i ZXJnIDxtb3JnYW5AdGVtcHVzZnJhbmcuaXQ+iQI3BBMBCgAhAhsDBQsJCAcDBRUK CQgLBRYCAwEAAh4BAheABQJXQf45AAoJELmoPO+gfG2Kw2kP/i0FIgIQQE5mkUgf N2+FHrGzleXDEQBWMKN6SeRR5/yja+HLdb4vgqP3uTsp4xMSRcOkCnsGJ0rCXXMe ijmRUQ0En0HTsOqXoCbnxd90UTGsenu1z4mIXiZBB49W5X0t9DnqNkN3k6DuEtwz KktoLu2Y0ACCST2fRi+3My3FHVC7nRsI2wCRj+JcHkclbPALa0hS3I+/ZVSMQjRF VSN64KKaduZcZ7nvaJk3wz8KePGnsp+7AWZHpC6070rT/MBFXfObE2Xxls9A1tTQ gAfMXLoC8vni+ms6k3pyQEThqwbVgt0Yl2r30Flim806MPAkKFceJXLJqjKXeb63 aK/d2Cs57HkdpqPxqNqDtJzdSNU4GJEvf1Fl+ssw7WOScjU50ftsmQIJrmXQeCpJ XNyur608HMNhOSpDRkJDigOLTgbMfGLpY8FNKK/WVI5ga5AnDdZ0yKoP2yRMH7CS 85D1Hdo0E6b2kw7drxxQNopkCOtrCnb3blTaRXkHzSHQMhtNWmdSOcSwGXtVL1Up jqDzWM8Ob2ujZrrcxRaHQE12pkLmrKBNDKoebhVVXC7MBjBkYYoFaYbVI7BAPQDB fN05ddWi8FAj+8TAqCY29UwUNm2sT7cx/OupwJxCUysTB2iTT4ixWkWyqNmNOz45 sh5pXLY0EpZGNg2u8mdSfoxsvBbutChNb3JnYW4gRmFpbmJlcmcgPG1vcmdhbkBt b2Rlcm5zdGVhbS5uZXQ+iQI3BBMBCgAhAhsDBQsJCAcDBRUKCQgLBRYCAwEAAh4B AheABQJXQf46AAoJELmoPO+gfG2KwxgP/0EtRWEBylNDUO4Fi77FUmB0+TCvNP/R zzc0bbq59KYOF0XU+1eX5/hrArud1+oSmnPgbId9fs1BpciSQZ9MeL/GjG9g2yS0 cekJS1aT2TEUgvM96NFKwHS5/0LN5oWzwT7YZTIOECEPGruask01TqErDDoDmEuf ANmfDKcyXq9yKCfuYKYbQIi/mizLqrawuwKX85CC04Uvx6LBC1+ng9lCQS/l336Z oWCAVrl3cvRATjgChydpPziwEwAtQQswdrZeSzYw7fbgmEOZIYoLotaf+N/6X51l JY9pkgs72xrrkMxBsDZMoMW3939B+1COxegHsH9ZZluThpqgNQ1fk/9+4uOukTCj mdvP+xbSBhgAqQQN1D1PFJrrsMwyhJQwEpNpdyFGHovAj40MsieUHIUxem/Rvaye 8iWvP5pje3TPwP1TG6vpsnUOm05p64Y1xNYIdf4BOIg5NlAjFnb44GLfJdORuVLk CZO3mIvGtTpU+EnoOf8jXYviKbKISH1PjFBghhUNTFCrSQUTRAED+VFVpjf7Lflc gtBhblklL+wiHx+o+PgeK1UrMiZim7nDdtx+J7QfFNGeSaGbwqiO25CVZbp7NEsW g+8BIbfKQixmc8nwIPADiHcYaMIqJnhxsmQ0329GgsAF1FdArHjPJj7krlHSlrrw IKArQBEAdzgutCtNb3JnYW4gRmFpbmJlcmcgPG1vcmdhbi5mYWluYmVyZ0BnbWFp bC5jb20+iQI6BBMBCgAkAhsDBQsJCAcDBRUKCQgLBRYCAwEAAh4BAheAAhkBBQJX Qf41AAoJELmoPO+gfG2KFHAP+wdnv6akDWC0mjM8xbH/RgZyO0F49291rZV+OmtY 0TDqC6Bu+94862LlQpeCQQwksFuRgwuAuXOcAP5pyd/A8wFROG6oyGvJR12QhmyB pkb1lnP7sJzj3CL87z57gb8EhrVrP4PJlXen1IHzmEpvB7voc3y3UmirN9d2vweN Nu6e4CSlGps+IRsqO/8IpaNlbmSC+g1cIodJfLpENT0vZkdJF7NwchwIYKC8DQ1F RmNVraFIEcqpJaJdN78/Q2OTErTcmPOGvVuWQxhwwt2osuMpDbgfJQft+xKuOJr7 9QckXnECvmeXK4hKu3KQDALRprmbHVxXHB982guJIKIBOIX8dU43qEMjcXYPkos1 VaGVHfxfx/+0XOD+2S37Uff3QCXEnWRh0VhWBU+49bAgfFUw17DucMzig31DtXO7 hIy6mCxuIzA/EsttOb8RBXGnMistTeitUpYOWrx4E/R+NOf1MfiY0z2RaBD+tvBk g+TwiIQQZwAww40vbMh5X2iIMyd8Xx5idE0ZnBXt7ipkcbO3lTSEEeqyOcL6b10a MjINlnQ7VK1mZL4sPebaTJGE/0cq0B+jon5vMfRPnYWveR9J3KapVKf7ZvGHVh4+ c5L45Z6FG2S/aj/fOJcXsOWo/G+H/+5SNqLxbGRP22qT3SGYtebByR1zFZby2zOk BJ2ytDBNb3JnYW4gRmFpbmJlcmcgPG1vcmdhbi5mYWluYmVyZ0B0ZW1wdXNmcmFu Zy5pdD6JAjcEEwEKACECGwMFCwkIBwMFFQoJCAsFFgIDAQACHgECF4AFAldB/jcA CgkQuag876B8bYppOQ//f7Usud+WC+YkeoedQ2viaToq75m/b5D6h2Ge8w2LG+8O YPu9AB35Z0aPhx7AFya4FTcyiwOHVBXwr5kQdueHoJ7z5urbF555D8FlisjwH4Fy Rp/6+5NNNJ+RvvAS35MzLV/eMyTqI6rlHfHbLSyC+hp2ADYjJrq37ixaPsc0eD80 SdhPrFZtM3avbU+Obla3LJG7XkyJ6WbSud93vKhCHnHhDQ6maRwKOvCcu3cugJuk qFLeP61f6jnm27vOez5vtOc80zUgVudQnWop5IB5eHmQrPyCk5aGARCmk005sXi7 29YFcFyubTOtOQEhsHIUXOpN0FHOgmlgGb2mefYOGcd32DFf4o0HvsycjE4V7RwP H0eVeGUnLVCTnp9nvUfNPC0qS4i9U96cVe5/8flMcSYkcDScn+ZQhBqvxfytKwdq StYtjDHfic+He5uVYEnjGbLQJ/hZVcebA9NZB8tcSHAXngy/KWAeIriRfZfaOPHy RiTDZMtm50v48pYY9XBd0wJadb2u2EHs0dsYHnRaQOW6GXq8aLntBVmL6aweTQ6t lnQ8dMe2j2Znecr1cRVb6us21R5o6CFwdL39pz3EMvVIPLB59CVlw8oyeJ+4igGY BrpL2zRgy7Hrm3JYOz4wbt6IWXVJOgiot8iGCQWcHnvubfYrXIPPK9si68x0Sbq0 MU1vcmdhbiBGYWluYmVyZyA8bW9yZ2FuLmZhaW5iZXJnQG1vZGVybnN0ZWFtLm5l dD6JAjcEEwEKACECGwMFCwkIBwMFFQoJCAsFFgIDAQACHgECF4AFAldB/jgACgkQ uag876B8bYot0A/5AWI7mbzuJgZQcK4GbJBDuZ7pajH3ByyE9Twjl0tQ656wja2W fcnH0NXxrK12+fPCdQSTg43sgGbw7jDc2qs8DSCrifbkfDw0hpS/4uwK4qZAHAnJ w7guxqdr9cjEfGUzhaMR8PMjSTASAs7AVHxMJBcJciQhFlKbGepbmkW1rpmNsau1 Cmi4mUNYgsXMcZKx/A6a9EDGLLulGLYW1cJlhS7P5Y53uS4WH9vtMaUEbwlMv78z 7LhY+7BQfQ2Hkj6mCXA3I0td2TsnVop25HTqOk0y/wL34Z0aIE3TFBnQLFh4mnBB 8bSaZNbJymtqGWVLRC8xNXtfJ5w1A2RVwGlzqdDQ3q6RoYaODwjFOrIEkAJf0b9q GwFuUJgFj5fd9u0RO3gw1wuRQxYp44Bf/+Wkn7p6XwaZfWq0CpJAMqh2gWLoPh4d FcbvCgULuwYOJGWm8M7TK8e3NrqPgg4Cq5gJf2JcFVqhH1lwHVnFW4Dz6l2BxPx6 1TEmYvt89kR5TtR0B3uhVJe5lOxnR2h3tj9PDTDTOSW6sRq+kGXmRNgSbuu2ub7Q Ha/sZI7TzDtejDpDQP71v/fOvkIl2GnFoOVqhErzBxXcHjZX09a1XuBTnVbhkGu4 AmgQATdkePIWiJWh2ufgyUVsbsMynt8HUtOZQMMtUQLgppW/oq619ChKmxO0M01v cmdhbiBGYWluYmVyZyA8bW9yZ2FuLmZhaW5iZXJnQHRlbXB1c2ZyYW5naXQub3Jn PokCNwQTAQoAIQIbAwULCQgHAwUVCgkICwUWAgMBAAIeAQIXgAUCV0H+OQAKCRC5 qDzvoHxtijmQD/9QFGwTcTy1JZ5HJLte6xHTI77UpUeYnkjf5ij1AKoQyHBJIxht DdLBGDH3cgpc5bSL/Qmdn5GM5GeRymRcTeoTVXRe+LK3nwSkGveZlAJR6/87KvRE 1iZ0z4baTfbxcxwlsvMRDGIYGwG59Re/WCT2ftaK3pwpoq8xu9NuRqS//IDUzGv9 TfPeu3sEG71xCadry8KcQ/8y2a8BS/o8EKb4WrppkCX6nGMfsOgGSHnlBSqfFnqz WF38avPI6oTp+mU+kntV7bvoSQzFgwCTeJQfB65758hQ/+yQ7um6lcNn26Kzyy6n 837ohftfIOu2hQLBJa8PFkmNr4h0/+lYMe1YpTcQobNZyiYB4KQskhdzIQQvdWX/ aVO2c/yL98+j6IALbWM4CDZuASOgLZNl/cNAIVX9XkWaBzOiw5pxiVuiykSsK2Z0 JhIr+sQ5G35zmR+BvlB1DyRTiGV/kzxLXpuH88jmEGBOSJ7zLoXwVem5Os01q+Gg Hv4DZrgKAjzyUqiLa+bstf1mErL14On3QBMcdBDz4UAonWLUwvg/DSIs7lwj3OB8 uFXeVS5LNCkbNB7jR/ezkieltSZmd0TPcwjm1iVyH1/sC64j1jDUhEYsjQF7LdOy JR9KXlzDfIZyG8R75Ys0aObtlYQpqLgbATYwixQs53Rb7pyZWVkPasP5fNH/AAA4 8v8AADjtARAAAQEAAAAAAAAAAAAAAAD/2P/gABBKRklGAAEBAABIAEgAAP/hAIBF eGlmAABNTQAqAAAACAAFARIAAwAAAAEAAQAAARoABQAAAAEAAABKARsABQAAAAEA AABSASgAAwAAAAEAAgAAh2kABAAAAAEAAABaAAAAAAAAAEgAAAABAAAASAAAAAEA AqACAAQAAAABAAAA+qADAAQAAAABAAAA+gAAAAD/4QoJaHR0cDovL25zLmFkb2Jl LmNvbS94YXAvMS4wLwA8P3hwYWNrZXQgYmVnaW49Iu+7vyIgaWQ9Ilc1TTBNcENl aGlIenJlU3pOVGN6a2M5ZCI/PiA8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5z Om1ldGEvIiB4OnhtcHRrPSJYTVAgQ29yZSA1LjQuMCI+IDxyZGY6UkRGIHhtbG5z OnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5z IyI+IDxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSIiIHhtbG5zOnBob3Rvc2hv cD0iaHR0cDovL25zLmFkb2JlLmNvbS9waG90b3Nob3AvMS4wLyIgcGhvdG9zaG9w OlRyYW5zbWlzc2lvblJlZmVyZW5jZT0iemdkNGlTeUJpbllxXzl3OVRwa0UiIHBo b3Rvc2hvcDpJbnN0cnVjdGlvbnM9IkZCTUQwMTAwMGFjMDAzMDAwMGY2MTMwMDAw ZDkyMjAwMDAyODI2MDAwMGM3MjgwMDAwMGYzMDAwMDBmNjQ3MDAwMDJlNGMwMDAw Mjk1MTAwMDA2ZDU1MDAwMGUxODQwMDAwIi8+IDwvcmRmOlJERj4gPC94OnhtcG1l dGE+ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgPD94cGFja2V0IGVu ZD0idyI/PgD/7QDIUGhvdG9zaG9wIDMuMAA4QklNBAQAAAAAAI8cAVoAAxslRxwC AAACAAIcAmcAFHpnZDRpU3lCaW5ZcV85dzlUcGtFHAIoAGJGQk1EMDEwMDBhYzAw MzAwMDBmNjEzMDAwMGQ5MjIwMDAwMjgyNjAwMDBjNzI4MDAwMDBmMzAwMDAwZjY0 NzAwMDAyZTRjMDAwMDI5NTEwMDAwNmQ1NTAwMDBlMTg0MDAwMAA4QklNBCUAAAAA ABBz8+hXviaiMb7xlQB7AFc8/+ICHElDQ19QUk9GSUxFAAEBAAACDGxjbXMCEAAA bW50clJHQiBYWVogB9wAAQAZAAMAKQA5YWNzcEFQUEwAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAPbWAAEAAAAA0y1sY21zAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKZGVzYwAAAPwAAABeY3BydAAAAVwAAAAL d3RwdAAAAWgAAAAUYmtwdAAAAXwAAAAUclhZWgAAAZAAAAAUZ1hZWgAAAaQAAAAU YlhZWgAAAbgAAAAUclRSQwAAAcwAAABAZ1RSQwAAAcwAAABAYlRSQwAAAcwAAABA ZGVzYwAAAAAAAAADYzIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA dGV4dAAAAABGQgAAWFlaIAAAAAAAAPbWAAEAAAAA0y1YWVogAAAAAAAAAxYAAAMz AAACpFhZWiAAAAAAAABvogAAOPUAAAOQWFlaIAAAAAAAAGKZAAC3hQAAGNpYWVog AAAAAAAAJKAAAA+EAAC2z2N1cnYAAAAAAAAAGgAAAMsByQNjBZIIawv2ED8VURs0 IfEpkDIYO5JGBVF3Xe1rcHoFibGafKxpv33Tw+kw////wgARCAD6APoDARIAAhEB AxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAwIEAQUABgcICQoL/8QAwxAAAQMDAgQD BAYEBwYECAZzAQIAAxEEEiEFMRMiEAZBUTIUYXEjB4EgkUIVoVIzsSRiMBbBctFD kjSCCOFTQCVjFzXwk3OiUESyg/EmVDZklHTCYNKEoxhw4idFN2WzVXWklcOF8tNG doDjR1ZmtAkKGRooKSo4OTpISUpXWFlaZ2hpand4eXqGh4iJipCWl5iZmqClpqeo qaqwtba3uLm6wMTFxsfIycrQ1NXW19jZ2uDk5ebn6Onq8/T19vf4+fr/xAAfAQAD AQEBAQEBAQEBAAAAAAABAgADBAUGBwgJCgv/xADDEQACAgEDAwMCAwUCBQIEBIcB AAIRAxASIQQgMUETBTAiMlEUQAYzI2FCFXFSNIFQJJGhQ7EWB2I1U/DRJWDBROFy 8ReCYzZwJkVUkiei0ggJChgZGigpKjc4OTpGR0hJSlVWV1hZWmRlZmdoaWpzdHV2 d3h5eoCDhIWGh4iJipCTlJWWl5iZmqCjpKWmp6ipqrCys7S1tre4ubrAwsPExcbH yMnK0NPU1dbX2Nna4OLj5OXm5+jp6vLz9PX29/j5+v/bAEMACQYHCAcGCQgICAoK CQsOFw8ODQ0OHBQVERciHiMjIR4gICUqNS0lJzIoICAuPy8yNzk8PDwkLUJGQTpG NTs8Of/bAEMBCgoKDgwOGw8PGzkmICY5OTk5OTk5OTk5OTk5OTk5OTk5OTk5OTk5 OTk5OTk5OTk5OTk5OTk5OTk5OTk5OTk5Of/aAAwDAQACEQMRAAAB41W+Uatq2rat qcrTLRWmtNDVQEu8xShxKISjgrFSXUQvFLIjLmhjIlI3pw3pwGBgxOIA8hYmo1aa jU2U7oVSdHatqiacrTMa6GShmoZKCWdq4M1ckJTG2qEZJHXIimag4gO4NHVNHtM3 UBvFZvYhqdw+aFhRqpJKlQYcENM+ik1OhlQiaiRFMqDVSUGKCJ29TiYVSoAyqiaQ uhyWGSJXKQSiI6z2qXGmLVbJDpXBZrpWqfNMSpJFCoJJFBKrdo06ExWVUKFOgYAB b3LaquA1FYtnVXYen6xHoOxz15vpkfmukrlulYcl0rLyl6+dSZkp07YHbQM3MUcz hsKwrwbWqDWtVRBPm7agPgiLhKIGqtqZ0J1HStLoFgtlc2GW1ruXrhyGRbIUOAEm IGWAzUItBLTRyGq301VYG5a91y4e56eTnza5BPET1ZhbTVNpVW4ZW0mjVtSk04bi jEzMFRUTCxDm8BZenqefoelXS9LzdJynOVMumGkjTBK6GShqBEsM1lXAqateMvGv Oviqe4VuUnTIwAzutpknbLY21RMY1RMdoKiC0AzBBEiVEHhctegnl77qcY8ukywm YZRXSbRDV66KMCJxANdF3VENKvfHXAayb4b159cKkuiVAd8B5htW1bVExjVtU6to aamANibFrm3UtuXu6YGGliNs3DA1hXEWQIOEFcOlUkXjhWqbks0fgCLTB3CldjSp etEWF5Zl2cbHbZbVGratq2rao0dqnQVME6O1OEKtg2TTrqvl7uhnJ3tM+d9zJrVI NS31wqOmdHTfDovG6O7QVWiEyZu8poZHryrpWtNsuaD3cCMyxo7VE1GratqjR01p hMAbE6QCwFiCXis9eonk7XznJ1Syzqa6KZp6soxcLoIkDt2Vw2o7cE4BLMRSvQ3m hvS84OK7Exq2qNW1bVGjOgqIbR2pbhQEkArpeB6jn8Ovua7m6rhUiXLKDKwm66Wl ayPIggtNzghdENsGPLITFGY014CfQ8xsV1bkiKYxidqiajVtW1bVtRVKqliEuEKq ChmksLWqTX0+m4u66yzU4doaKcZyZsZUyyKh5dBGUziqwkMRLtzt5tlyN1ty0b7T Gsl0CuZGJ2rao1bVtUxRRgPEoCtS5QyziqVGQWnbVH9E4vm6/QarPSykFmdNGriK 4KHakHFRJhkRBXxW8DBcA1zqNa5deRH3eWOXzAWYJIjUZGjtW1bVOEbBUqhCoQSO NEMyyipTS4BuK3Pftud5+rrqrLW1ACfFSwyKBENcHmwokraaSuqSm6eWoV1cUzEa oImomm+bTatq01JAs4LOpUUfB1JiKDnGNpEpQYqQ9kxz16tXJ3tnlN3IAntMncVK CkHCdGRlannurlDtsRLOeiKcVRNJxDfHXap1EkJOhGBmIKijpjKamIKwIlkQmnEL oqKuK1Nu4bcXY6KCFyQ3KCAgOWRkFeap+zkIllGooLMicRCYTqhdf//aAAgBAQAB BQL73lTSjGhdXV5PLsopMhxxTPIlapVLVkMcjTIPIPIPJ1HY/wA1pTR6PR6M8e+H 0alaW0SJDL9IqSLlqYGnYBqFCj2mfuU7DT7p496J5dC6OEddzIJEPmEIJq6OlT2o 0aNNvItSPuU/mDi9K6Ogej0ZKXVLUxVqq1JKSAS0Uw0eALIqwA0rCWLnTzdO1e4N PueZ49q6VFC6PEPGroWXoOwBBfJHK4dgCplJSaMd6On3hx86sn7wL1B4vgcVKVKa ygMEYXFA6OP2lCrUMXV1dQ8nkO/l2T7WVCKrPKNFCjowktFutTTYv3INVrobUv2W M4Y0qo61eWLFVqKgGlaAxcjK5xMeTDqy8PuUaQSzoQKuGFMaVpq/dlMQOG1xYTR4 vFlDXG1RBTWhUYU6/wAwDRhQ+8CFLSadrZIK8aD2XFDm0RpS6Ojo6OjKWpDUiouY GtBSe2n3wSHzfuIUULkXHLMutduj1UvSGNjvT7lGQ6ORFRcQ6KS4ysMKmUcJ3gpz Uy++mnaOcItlKSsQ0RbwqMkkY0AY++Qy1O4RVEiKMKxdWlbroTU/e8u0cORUkoWj NLtEUcYY/mVEM6tVGIVzSi0QLfEpNHKaJ/mDQdkKKCaqNuMjA0MfeOjXJrRReDUn F3F9GGnOOa1lzjvABclz+1/OWjh9pH3i5AqQxxJQ1rSgLuJVlVjLO7m2Nqu1iItL E9W4wYyNZqr+aPa2LgNXGdGPu8H7xzFSIUpaIVUSHeQieG2Cvd1KMUt3VdtMv6L+ dRobZThOudGqbFpkWogsFyyJiQjK9eADHdThDuY6iH6S1uRy/wCeQ4V4riWwCtoQ lLJAc15BG17okOe4kuDYTJkt+9QGQqR0o1vnpt3cqzm/mvLsGEu3XkOYiKNV3JI+ VLKqO2jQndLZMYs7CHk+6e7yRypU8kvUsIZZcgd+Polan+aPccC4VLCra1RQoykS AkO5TnFZH6FQZAJCce9XVqDuUZRfz1NHb8LOXJPeY9MAx7Kf5cnk6vWvlINJtJf5 kdwGT2jqFwDFaVa8xIfWt4hLGhrorUrY1fsupaRo5PZkAMlP5zikh0aEZGC5XE7Z QmShCQyyWpbQtjUUAFHgGepY7XBpGf5zHQ8O1D22+flyoNQos6vFp4gEsJp2kU0h jiS59Xcw0U6M/wAyfZoKU+4DrYz8yOmQwZTiUL6sg6sqq8ewajoOprTVywZM2q6F n+YUX+UcCoOp72kxgXBIFJ4tTUlgNIfBlXeZWKLUfRrDKWtPVcJCZWf5kq+9b3Co Db3ccoBqyO1ewPZRdyqojTiijKXL0olVlIy6On3RxUfuAfcGjhvZEOG4TKOPYCrC Qy5iHCM5u1HuSgm3PFn7449wOx7jtZ9UcUxDC2kuuil4uRZmcUXLT3vZufL5/wAw PuJZ4dx2sWKKCwpDTcCnOUp8lcgjjShnsHuVxQHh/OpavuB+Ua+XKmihRpIdQ6sH vNIIYyStav5kfdDPY9gX5Euyn5ZAeL5bxY7B7hPzZGf54M9z2Q1cQ7L/ABYdix2k /dpZZ+9//9oACAEDEQE/Afp1pQaD40q9DrTtaDSRX1603NtoLu7b0t3PD9qT2cfS r6QS7LRjjTPHtaYwTh/JqvOlBpoNDvAY4bfZfZk/p5I6U+qOmi+zD8n2Yfk+xFPT RTgPomFDTns3PuSZS3NB26F2jsGuKFnQDS223c227m9J4hJniMdadjt+mL0hkoU4 gSbKUnuvS0aSFpx2ftCOmNeXl3FM/q4hZYJ7xH82wHc7nfL8mWWbjgfxI/q5By0n 6sJ045Wlouwux2taeUB4dzbV+WPApITyzkfH14TMSwyCSS3btaLklki+1OXJLCxw WtbRJBQ5CYiwylZv9gxsREix2UyHCC3ptdrtaRJPIpkKP1TrH+jDNFBsJptAaTjf DbbvCE6y8tt/TrWtMeQweJCwig7g3abdxeS7SxoJNpQEOTAJMumkPCcch6aX9Cn0 bb0ttjklHwxzxl+J4PhHCJN6bWq18aXoachBlxpbf0L129gRlkHFPeL0pLygF8dl ubLxQ+lfZFJ7BphybDSOe06ks8hl4ZNfQPaE9o5SwmYoN6bm9SWUzLQ93//aAAgB AhEBPwH61NoSQG0U0001pTX7Fbb5dtacaW2222ku6Tf16a+gS227ixN6GVIn9Wgn IPR9x3h90JzhPUF96T70n3ijMUZQiVvl2tabXY+2GMKaaa0vsI1yyp5SaTLSmmmm mtLY5SGOS9C27neg3212mvLTKFm2ZrxpTXbXbE0idDl98aUiH1chZfQtq3a7XbH8 2GOHozmPwsw4zxTbH6shbOOlttu5vSq8tt62QeGfm2MvQo+0sIg8/WLIWyhTSAdO HHGBfcjHgMqPI7KaSNIAS8sRQr9gmzMgewN8ta22220xNFBsfVvUssRTGtK13PnS nadBoPKPH7FOAkkGPCeynhtN6kvhhlpGUO8fUprslES8ssJH4Xkee3c3eoFsuTpb EsOBz9a+044lnDaWtA8NtJPp2Ysdcn9lyR3BLbw223qBbDHX7KdJQEmQo91MYCP0 P//aAAgBAQAGPwL7w/mvoQtAPqWNDXzeSVkKZUs5KPEl5RlSD6VdMj/qEdvN8fvJ X+VWjxH2lqzNKCrRbxIACdK+p9S1pzSoj9nsf9TKJyzroPJ8Ow4cfNqkQMQvj/K7 Y+Va9vl90mtFD2aMgU01Ov8APcO/m/N+b83p2pSjoXo/8p6B8HU8e2iE0HqGa28J r/J4MmlPl9/h/qA9ik9ssur0pp3oHr/PcP5qrxA6jwDURwdWBVj176/zg7UA7ant w7a9qPpP2F0UCktZT+ZOIV6d9C9e1cnrw9WFp/m6dh5kugDqaPp6i6q4/eosfayn ig/6hGZVj8Gr4j07VOtHVXH0dTqXVT0H8zwdP5/IcQ8xFy0+ifV1pSryLy9eDyP8 3Rnt0ulP1P2UPqTH+D0A/mNRXty/PMK+bFScqOnmQ/gn+f8Ah9wn+aSnJNVcACyl QoRxDTpQEafz6gDRIL5dOLKTxTp2+f8AMilfj2CkmhDqTUn+b0fp2qTQOg1+TXRR KSK19WCeLVTz17U/nVH+Z4v4uqiAHjbx1/lK0D+nuT8kjR4rNY1cFUac+JH6mtBa Jhw9k9if50/zVIhkPNXkz06vqUeykH7GkE6jRhQ+1n8WSP8AUfA98lmgeaqpt/JP 7XzYpoB5D7qj5E9gFFiP9n+er6PVj7nUsB9CSXVZ+z0aacU6Efd9E9ylXn7LWf5+ pLp5h5KUAPi/oI9P2laB0kWVfLQB0wT+DEqBQcFBpVIkLUR5vmQcPNL9C+L0DqdT 9yv7OrP+oPo+PmXnKeZJ8fJ1V9j07KHwaR6dtUuoH3lD/UMiPMgH8GD9zEe0XT+Z LXT1/wBQBVeHmwU+z5/Dv+yHp9/0+4r5/wA6O5dBqPRg1L0H3KfzBev86Pu4ngfu augfHvj9yjqP9RjvXi+rvp909qfgyUFMlONOP+oa/lPFgg1H83X17jXiyB/qHT2f R6HX0/mQgcSWB3yqAAdWo+p/mqfzGjGWv8wVeQ+5j+1p/qXjqC6L0+7gjzdPuVHs J4f6lWnz4uhemqXqCyEJfWp6fc5KTqeP+pkrYUnge2oen3Ss+TKlcT/qfBXsn9X8 xgD0p/h/1Sj7yvl/M//EADMQAQADAAICAgICAwEBAAACCwERACExQVFhcYGRobHB 8NEQ4fEgMEBQYHCAkKCwwNDg/9oACAEBAAE/If8A8X8FA18qPwXqu/8Aj4X43uWs fEXX81ck2Sc9RfgVX+q3T5AqPQN1k9P+7swMSHri7Sqvluv/ABh27RmP+cv/AMHX /wCLsc1g8tny/wCCPL/8AUZhUXnDcun7PBZlcTxHavgu1KggHzHxRkY+w158f8h/ 4jZApmoWjbt274/4iqXE/wD4HkvJ/wBKThiiOHa2cWUHNl4vsQHwzf6qC8heFPXs qI7RQwKT3Uw8eKKFDOVFAatn3ee78iqItRwfuhG4SRgvN+P/AMBL/k1f/wAHdWM2 yuT834v5o+7Y8aY8/tely832UJexQ8J881NnJPHu4A+mbKwmCX4vg7y8RFCUgPpo Jg/mm+WhPF5McGzZfDSbMMVLoQFDOG46v1Q+P+7MOd0JsbSlcv8A3MfdJnmqaDzS HlolktYjl+qpYebEBJ8R1eNosEjtSDjmsSVxjD7rK2912GWxQ0EXm/Fix6s/DZ// AIhmgTIqPCy9XbpTaidWajy1ZGnxXErTLLDSZriHuifJIH0RUdWP9HJU4o2SzcH1 YqGRsmHi9/di3Tuw/wCh/wAD/wAM/JYu83AB5aFKLIgB8FYMRWMFD6MXs01AiKpl nq8uRKTxR4bjZYhiO7w4s+O1m7PV5PNwzbAchVwDSYGjyU/KrJvpZMWH/Dj/AILn iaqxGe6J+wxZEfzZi73EXwF37oj+xdo+T0URANGICL8K3nZS81PFPU8Qohec82QR Of8A4pYSWHr/AInCu5q8XP8Ap+qM6Ox0PVKEmEDkt5bARGg8tFDM/wDBWOy8BXf6 aPmU8/8A8Fbmul5iyzAny9WRDnj/AKSHTLnn/wDFwjZeP+/FEcxNlP4VJ+Xq8kOQ ggT1ZFxf6sqG8BQXlfdIFCh/xH/Ir/wtiyLGXfTYtPuyL98sUFfYs/P32P8AizvB IB0R/wDkIT0M2IfP/HsOsfD31cKrwyfdlQngNdz4i4P+QpY//Bv/AAFG8Wej7LMc ma2I5UhCUe6lT0X3Y/8A5A4aEi+KvWHMM9SdFeM+E6usqXl3da8u3Mo/4f8AYsVi sXyLgJ8UwZpyIJamiYQr3TmGKrSxD/8AkOiwBpHPz6/4lB0idNbHIlXlsiRSSHqj P+D/AKf8QNo4RTpVGN5pFH5LM8Oo/wCoAXhqcaH5rx0livPgf/l9UbHbqLxXhSh/ +BRTgQPF1OfJvuNTVSY/5PdQmb1CFz5jB/TzRjwHroWPotitzlj/ABUvux//ABn/ AOIAD3cT3ZqP+h/4lwzXZgYD+FLlPSWQsBBjw2Htby1Orw3hF6Hrhj4XYnBRCGpB /wDllaWYpQsMKjFkQElmERVOSyVoU+2wSUPjff09XCjwqENjbM0/5KPULr90MqMJ VSs//lj/AIXlIE8uKxS580JTWfVJ42jXBe8TZ2d94XavwOKyEB6iUpFfmoZWqSz+ 5vUZe03AFnMDuoryv/5yZxfu1ko+uxfnJWEFVn8Z22fX+HO/uwGHmOVGPNA/TWyU zyD4qt2XbSdfINS5FnrvbSH/AIAf8uH5QPjuqV5f/wAvAf8ARSvql8BXSJd8fgXw IGPFggvc0E9GtD0j/hnBfNDAoyF+/wDiDZC+0xvz/wDklK/8CyqKp6CPcpi+7j/n 1erq3xihAdF5KI2m6naUbnqqaVSvvigBwH/+aTM5rv1RsQQlPpe+RkHb/VJ515Lv ihwnseaHTS8ry0bUGiuCCtjGhhFI9mvi/wCJ1cqsXvXxrn/5YS/BTXiprAGIJo4n tdfFHMTyTeJT3VBYy6O3CCzZpJSCdo3qCwNWnRXXiynuKHXlO1MmpUj/APJFrq4O n/ItGpYr/wBOiCXrrlYjqkyb7sEYpvzWDa2iPn/tZVRKZD51LJxWfFGf/kqCVQ8y F480IeLJH1/yAJyU0z6+GtnKo1C9s4+KZx2TUxzVx+d52P8AqObDBj/mEYO/CF7p +lk8fVU0ZP8A+RIAU9qJDTdTfqsNiylvA/uyoDhogpvgqjxQgoleOm3gpqrfdzW4 /wDI+tCAMvEsXqiH/wDGc3z4qODlD/gf8Bb3Z2v71FyUTY+OKMf8yrZnizBYCr4j KAFZFgvOSAnxfZI0Morc/wD8PBZP5WP/AMAl+K1qlInZUwo+e65R05LlOG/8BKM4 sCz5owemxz/0i7OF1XX/AOQUC875sULO0PNUv/eVTGngQyG4fLz00HZwpxM2NGGa iJ7NIxz215pzeBXCyqdHv7sVF5sf/iE//g410/8AeVI2vegw+LhMlkYPi7uJIfXF Z4Pt4vQQnBQc/dX/AF0YZZ0eLmisR/x//CE0P/wcKsqP/fPquyrk7HJ5LPidhKuM oHKaGf8AQWl4LR+WtNLy3nYr/wAf/wABR/8AiPbNE1sViTFd8bQlf7n/AAS2FYFF iigE7mjunCi9VuVMyw/9Kf8A4nOlOP8Avv8A8OlSos5/+A705rhzGV3Hxel4Fa/8 P+f/2gAMAwEAAhEDEQAAEMBgBv2aIVTmmKQMcVT3J7cdsZt6q15tmz//AK6jO0Zq PDjZFzbf3JM9UF6/8nfOzVMtyer7r6IKsYTC1Y6zcvGs7cqfQ+px+iPolQqHjAjF CswNrKxBTsX/AHvx9wEb9VhaGeyrdPKG/NAiasm3ZczVjJCc/C2pDY5/NHgUy5QM zVUcUcwQH+IKp2K+d6wBwIzMGJ8PfIw9jpZKRMMfxwwMzMXYAAJ6RsjegD5cPrx/ QIwZnd31sqzl8P6I896CVOAAERSTzrWSCIGeYHy431lKIREd6DtInd2rcCXPbYz5 yO5czDMumFxCVIzyQ3STSyGtzEEaM6iUm+DXYWsPlz2ENv/EADMRAQEBAAMAAQIF BQEBAAEBCQEAESExEEFRYSBx8JGBobHRweHxMEBQYHCAkKCwwNDg/9oACAEDEQE/ EN/ExlxP28Blh7WPKXYUzHB5tbzb8y5xtlsSUFgEvm22lrC3fvxZ5ngLhxbt/S5d nRG/N9olw1s2nsP1Qn5ierPMgx3aeJs2228X28FYwRxa2tqX3tCHYa5AHGOyTn5t nDCYVxb6+egWgx9Sx9b7t9/xs+ZsmwZBrxJzi0eCEmdoPfMH4T9GacEbt+8/Vjcj OvmDOm3e7YR1AfMI5Ja+yB+YHo+YHmeHiSbZ6uAtDiwJj+DdxAtww1yhDAfNl6bV snht9QbPN5t80MJU7uEmTSVh4rPm2+R2PAYBzO5HYcoA582TcOJ/8MnnzXeJVh0b gZOZZZZYGNNV1jmG/Fr6z8EK4mTxDmy4yYaDicktfxvrBNps0dtpjR8y5R3CHduO LglHxa6lNk5AEOpuyGEyIaOf/i+Lznug2gOoDjuxn6kLvP3sPpEfGWCRLCUSN13I k8VvmhGX/wAW2PFye44j9/MG4Tz3d8WEx8WEFLdcmbg2Q2wYbL5tAt/+KfgcSknd gu+IdjqQtLxI20uSPjAGb9S6alvb5jg2attR9du//HdlZtjBIDh8X+0MjRzBR8DZ HU/AS0fJDm7fF0ueJc30wHyu2goxr/4GIekZOp3b6s6oThjHy9k9r6Mudbn22Zuw LZOuPAxHLOEceH1wbT8L1bnjYF6j6ptu5I6Qfd0Cz6WrfxOnxAi07+fwNJ7tnu/g 3J+n8Pi4/AbcLkHTIGyWNn2sYMHghrcJwLhweF4z8TL8KlzbdyW5cEk4sTLFtuWo TLbYGyGTCeJbfMv/2gAIAQIRAT8Q/Es8+c2wXFhYkdQkYCanEuhZsWLMgWGcH/02 220ttd219LUmMY2hsXNhOHPc80eiQ4C5FtxbO/Hvf4F4tts9Orb+ZUuYZ5sDbkbc J3fpfRykg0vqw7yXNra2tz+FcuywOY3EE337CP1J6n6kfUgfm+qkd2j6wAsWfmTj Dix8yGZ098WJqo4tfg4OLdOSHYRlyYO0r1cseGPOJgpDJiOCMslln7fvY+L6D8GF j1PDvUDsbsEQyPLEIHmWPhJCTxVASpZzLRNJNswYf/AM8Qe4M6sOCcdxZZBZkpPx LXa+y2xpzEGrYbo3Lk06tdHmIMP/AK96ykyBHmCA2b1fkJHwQ7ICNqLYBIXayGOv /sNhGPkEuZC+Jz5bfnsnh3Ksbfp+9z8+bCnw9M7kAh/9Vti/JZBbWPE7s7jqRPmz zmbznZJsWQ2//TtkJbZzGb1zbcYLAaymXzxCJYkLwe8gT1DcXEFtv/y1W3G0ttd8 N57ndWk4sfANg/WAdWDqSsyPQkb3C8DD/wDHAk5trALPTsF2zZOATjJnghaJUy3L uPUoOLUzwdwR+Xm/jeoM93xtniF2BHgMs8x8+EMNebix16Gzqurbfx76zBZ4zZLo dwxyPrlXxY+C3a+ZfFWEXN7i30/+SWTbDJcICM5uGssk9NOQHHhH4Nv/2gAIAQEA AT8Q/wDwtMD1rBWGnqaiT5FT7VBRFmK5tPRSJw/NGYikikx3dphN4A7HXPM85VRi CNROB1BTkiTLDYiXhxBpxWujwJGZ6M64rAKELCYnJEdcrMAdkgfQeLIlTnRbFIn8 VYQmX1QzZlrzY0VX1XhsCMzBFiCkeLB4qEfNiw2P+JUItIExVB4/V/8AnFFKSiOy +Jz8Xk+bA5U2jaXV2OlsT5TSKb1DTkHR0H7pQsAEET64Iw1cqhCyAxxeJ6f3lbrc AGCGj41PkphkfDxZUWIMnt8UQxZrB7euarCMMSM1giGBavCAPmsSw9UByFTlE2ay O6sqSI9GyLYIm91YPgv71cat2+rx59ru489BQqcZQcFQ7fikuCirhiw+nH3dmrPK ejgA5Oq6BCOlMMBB2CN+qBgeAg/FbBoFGRPFDCu4NVouOFR3Cj/9Lz50EJVFl1Dk VGfmYGWV9w2QhQbeaSPdga1gUsPNCLJYLrnVjJcxSSGG6zA+KJ8/XRTA+BaB/sKu EPpRHTylx+Kuf1F1uBO+q1IoGDiDmJyyH6OuvNZSEBkAz7rBkPtwOWyQUoQUkMZz M/VACPhiSiUgHwKnRiBcOCOqEgP4pS6wCT5e6rcUGABxHl7sfO/rQVJzI8QWUNXE NZ6piFPoK8uP/DUpKI6e7I2sIUbRJ+Sy+6xglmCw8plQTMdK3e9imaJj1C0wEvRR gHSksoKojFGaQEkbUC8+6ougbPikVCYeYw/DcSOszaWT7D5oPZ+KWkh8UkTZaE64 soYnE8NGWGWgImIXNMT/ADVPCvaU9/7/AOFJgb/NObIHlimin5ohgY7vjCwzhiom 80K1N7cLAcJshExN2rbnbRPI0Uk1uyTh7smAOB0qhfOmqP8ATPqn+AR3Ev2NdcV4 PFQ3fhBsTtCyHVCAJEsN2QxEWG1UlR1mcDXSCYR8VECLF5MYoYC/q+39f8GVz7XS ztgVLIT0gYsWfidGD3SCbGwux0x1NKDT2R/7SdNOp7+LxJ+FimtlHTj48FghmPuw 0JPNlBRZ1w+qWfHhDSUm3wpDj8UiJKCWZ0eTCKjgIMJ6vGlI4K0PuPAaQK9lXqr8 o8cFTFc2/wCqAET0z7KBShBJEbnpH6WYSQfDSGLb2HLF8s/n/gajYNsA4MC8NECi EqDJifdZZJST1UGQT3wK7cCuj2+AvllPhLqPVXmJMFk+qaQexH/0auVDh8+acFAg ys6V6JskIPdD/R1REyPnPuxEeiiIefn3Yd2RA0+aKlC5Dv8A4KCCw8/8j/gZQaWW L5j/AIhKSrDIex7sjDib7P8AwmI8WPKPlTBBoDE6ccx+6lqugkRA+B7TulAIxg/R Po5pRojlEePl5fquUPWQerBNB3pFEegpqvagjDL8by4y9OUQyVJZI90YRnqgU1cY Pp8WYCOT+q837swTRMLz8VZcPzfsr/yP+On4KQEmf+ArFBWKdWBj+9+JPuzaLSh6 JgJTKHjLJDhg6wkeGLEZ8HqNT+f4sDmSVn3cGepTYHcvuzXOlQ65seq8LMNPaT0U gD4aihHJ+BPP8WENPQjhLG92DB/mmHfABQ0/UFeGDxRnIoci2P8Ar/w5phNQcJZp 4HtHjj/mkrSTEACDpBjMxYR4gSTkqJ4nNM5s1sJyAeJ+bwbDLCZjj6pQRcOJaIcU XtlD1YqMSBNBa5ebuwJJvZTXQpksfRTCpB17fNXAoaY7+arV7LxGnma9EQm9QSP/ AOBP+FYhmzzNMpJkZOtUCIEsv8eatidM55hcnE81sJYyUcnioRgBqHxPlrEcOo8S 0DzWA6CgNx1e8oWEcVMUjl4qRjNeJCeKphLMqo2RFnTQhou/3TiyIpU8tlAnrzDE /ZDULP8AHDPFn/8AEc1DDh/NKAXEEg+Dr52nE3gDn98h7qnILSjyrQVSALKsthUw G+bAWeapNuIpM0KLFnCA91Agl55n4q/THetMiH04pUCcmIuz2t5sd+uN93dtUPZ/ NyfVSFdnwyazpLwe8/qy8llJx+5//GG2er3/AMeNUI6aAQMA2oFJjhuiv1eP/AAo FAKJm6+TelNERnk/FdgHKRXd6hSB9PP0Gp01ov5EzQjJI2Jujp47JeqbAzh2zMnq a8XJRh+y/g81ur8592MZ4Lr8iR8V/wCv/eVSGP8AhzeQeCnNcSABTzRAZwsFfj/w xFJytnx4pMwAavBUfrGQ+FwtBj4jzDufXFQPg0J8VCDAyVo84eg6JUzKcHjOLH8f sXn1VkTj5w2S/wAuRFiM/wCP/wCKZb3edW3lVBXiViC5xSGDLKNrQrGi5sdrdM1q UPml3oz51I+vmrhEAw/J1+7vMqAwsEgPoucSu2iHHFROVQSfjmuVIl+FJoDDE7qt Fm9kZFkrJC+ej9f9f/xF7pxa3lY9hEOPt5+LAJuU6T5OqJ7qH+qJ6XmgwL2Xa7UL qo6Qy1FMjH83z+Ct1gmLE3g8+3aCwSLqfx2WCym/8IdU5ERYQD3x/pLhDAICzEDO z+6iUusFGi9cTfTWzrP/AMD/APhP+GfOnDSuBAoyfNY7sF7WqbJCZdeS5JGUhZg8 A8y+D/BHu4rDngeYZHpaGn0qMZeXlrmSAYJeA63H5pk1RdOwOD55ryAUMkT18fqi cHwG4Mrx3eBAqPR8zwfBYJZ6sydVfPK9HH4rq9jX/wDIKWQPVO6VEcB5m4kEedrc iMjmIxvgH80qipFl/wAZ880eajQYu35okJBFPBT/ABCZO6khv4FZ45sq9QUqDj1Z 1PJZevrVmoPw1mQ/VhFMmaTZJi+rsQITH5/6/wDH/wDC5VK/8mvIgjjmynixZMBn KmfYf00AUiLHluLDQjiSVkXluApIDo7X1Z0KAT5akWbQaja4Eh6eKJmhx6qSk6j4 slAxOWSRybHkpPyKCkUxiIPz/v8A68f8f+lCwBmvNK1guxnNShA4ZVma8lJent9e fVMtMqpm2Tyv1ZQFEpEC9Bq0afTuvgp8dhT9lE+vfxXCD02UyM76KpyBENl+vL80 TbI8FYSjg7y+7ie/dS/wLXUJKT92NZfmhWn/AB//ABYH/DiuFEQc1Ikfui4V9WZv X0Y6pkOlIR4XR6rjfGQh8UEWH5P5vK3kHbCYkj811EDg6oIge45q1Ndd1JjyA7sc wRH7syPEZdguVPFgokKLKyTI8PdV/gsmPFm+q/8AY/5Nn/gpTfc3ALhNm9v5rOTV mKScYy6VEW+eqciRsQS5ai7MO7+qZyMidz6oJsCsiKmkD4LuPs3koJsfQYQdHuxD PVWChxoicLL9Xwzg7syiBOTssReV4j1YRhr/APhL3WqTGRGnFIBOXkrSMiqrkiFZ JlrMESR8N+QgPRyUVO3RptIiwTWqer4oy9mY/lVss5UJIp5oPmowvypGay8q91BA RlwzVGxPxp90XwgP7p8uTzWIbOWHexzHjilDJkUpzrk9n4sCTuzwf/jOSikLjknx QU6O68hJ6q+mKozZtByRj+t7KNM8izfkFxszIJsVUEdXQGh3R9jxZGBE/qlMue66 IxYEgjpVWl0j82OQUnrKwndGkJqyeb1ts+nmhs83E6//AB6B7oMJ4e6LODQipUmx FZjqxpzMo58nhpCEJ0vouERGou1Nt4nm5iNGpDLvF1IZz8129d0Uiv0OYkTGv6oF gBtCB4bHiZriAr8yCsj/AFE5+ovcoLpS6y/D/wBP+GfkKyDwUQpQWvHFOQ67pBwi 7ydotpYkJ93jgcrP/Vja84bTaIoMnHiznUEg/wB0WZ5de2975UQFTrGw7ZpfJX4C bEsc1KaTXTCcPByv4LtjibHBonr/AJH/AE/5MPDNGa+VNaWKkEcbYdwWTTCzH+7M vGUSCt6A4uQCgP3SzTO/0UdWCZeaCTk91AcvhuwE79ZZzSkDg8/DUan8hoJPmufS sMACVei95T/O+38fNJyrAmpwrCz/APhleqYQUYaeblPlux74uSy9Rd7pw+7JBzxR AcQvMIf4uK0IZpqgQofwKsAqgS1ZQIcCMdXm8DaIbEB3nstxjruKsmeIojbFuJib /af4vDMWiFqWosQsF62P/wAEwsBZpzSuDcwbtTyWIdmj7pe1dm8zQ3go8xyf54oA haGxKTipCUZZLAYB4KqZml23pKdrl9A76D810DK+/wDzi9EWHVwbxWDu9Es/9E2A /wCjRkrgI8WYz0UoRJ+KIaijp6rKPvQsjIODBAVfBXF/J8NEhHHxWeKFstFgC7kR dM3SYokkslnF+uLBAzosjP4sxS82ecUqer9f/gcf+P8Awqw//Arm05qrj+bv6Fd0 pErPd5NOLxKCfleSs8QYTEyqDdUKt/spKZLw+r1eTXm//9mJAjcEEwEKACECGwMF CwkIBwMFFQoJCAsFFgIDAQACHgECF4AFAldB/jsACgkQuag876B8bYpcaA/+Le1/ CuXyxt7a3E7SkyNQwmILkRRauig2IHhSiKs7aLWpturNnKyFcNzJBPCfUcuqY/e/ 8XFosYThOPKMVEB7mIPYgDq8Nzsm8+a7xzeo4BTBXxJYRvXsZ3JHGOfxlWGakTOu dCjBI94/kSykczjhZAhEnm97lnki+wqGhnBqjqBLu2L23WIuieljQaakKkmhdStj q4ScUyoKD8UqyKtP9LaoC1ytZaW+muo/OktY7lPD6NJ3qbdDjfWp5lCWiAb5m/Su IqYlWhDaohVgE7C/mf4knXNQhp4Dl0vamjs0ZS9/XgxB17+6y7FdP7MjbMS3D/Gi qNo6r6xGNh3osTBnjvGE4v7f1PAaWf+UWh6zkdhuAkordKUC2mlrQh1QqUxVHg2r taT1XMmZZT/zGXDwXzqijxZM1TFoeXgE0XCVQF8z7Fe5dsp1pCKzO6pKo6QHWEz/ w/UTJv1jTZl614KqwfAl3vh84k0kQuevacKfc6COif6yP7KrscNybaMbffqEuHUz 4OHArG2b3gkT5Eh4Rn4sA1VBAzhGbo428IDfgcwNdbimUXcSQoC5X3QrHKOlXWIX hnAKndDUBQOxcuOk/CHoHe5uf2PD88c96XyYw5Gc6xjpDCii4wf+Bz4TY3RzBjup o5p3qQU2Wsi/XZ2CbSQ9TjSs7bYOsxG6O644uL25Ag0EVxZ+1wEQANll5OQNAZwN FilM+n1SLDMNLSg3u/8V2ZVC2cRZ2wFing8O2t6BsQJLOpWIF97fgByHk29gloy2 twMNL5oQaUnbMtiytP4SxSmql3HxHuDaJ4hWjDTrqRxX2VGuLuvZrCi1u57yrsxX rG6VaOdrPFE+cDoPxZlloUrDLuPpDNgWKk5BHqTWqVUpzPwQ8MiqUjS8g3n3zpl8 18qVBoQadirBiW7kYmI9XWVNUDTJ21rJXiZjPcyShKCbNomBlFRHbgc1vT1BOGJS XO6suHA+QV33MhKYHO7jKkXJpktmLd42s3gNjoMdpJxkgKuziPvOel8A8VdAITpD yiy433g/TUhmXmaC3EMMHubAqLHjqt0w6dBAVggBUgWyfypy6eZiHNeg6Et32XR2 oAXUGuwm0lJjJI+L3SuWy4WG50HtO7RVQ+iF3JyxCYjJ8E2mvz7r1J3ca/Qe/gst XSN+4rK+NLq1JZL7Dn1fbnMkGNIrB070E8NGr+Ho1uavpfoFrSSPgJkutslxay/B fPfmEkYFMzLYdPXXguUJd27M+2oXjh1EWH529J4qjJ9Bm+laPCYJZgTC/TCvFTgj FeqL3y/D6QaB6G7dMp4OU0eisMueS3QaBxUzHJnXVWgAhXc3ERI5M+unPmQ8A4jC lSkws2YanHY+hDjXoKGnooKyg9PZRNQVABEBAAGJAh8EGAEKAAkCGwwFAldB/lkA CgkQuag876B8bYrYhg/+MXQMbNDdSg35uVy4FtiNKlyGUDX6+aFHt/j6Tt+OnxDZ 1+zE0ItRK9Xy47qAIXqNWnroZQfpm2h7wigo+GV6hW4rVsYKC3pMdxjztuTcrQlh n0EpuOpe5+c9xXnZrQdHKulqPzZOnM1dCoNeMVngOYrtfbGdFdoqkmwKiGvwn0zF eSAKeKS53XjUJpFBS6tIRtWdgsA8r4yu169IHB7DQQRx1RvbZGs/yNKdnKOPfD4x 2OUsu8MV1/jK+W8Ktd1NC5LUPO7i81vijXH9PrTA4I9UpFE3yHfU9U/zqbwQbHh/ srKkSnoQ2a4cAjoBFqTjC4vqLQEx7RVHcgekLwRyStbIgqZ4q8uMI6wAHpDsTG+A XeNG5iUnn/Q8c5Yuq4JVkhdvrb77Gy+ZsafBOAk3dYB1lAaV37ngcIIEVl8VRNhW 62xQgaVewo26V7TZ0guDgNsy/iQPG8SpBqnlEoP9VU/YobjKp9LnZ//1hifeyYBB Q7bs9Xj2/uJhAxbkNo7+cE+v/LjEr3S2LilNPspds3o1s/Ta7zocAeRjl2Wcy88H cf64v3p9F8BvPTXJi6PDG63jaZ2nlYbmgad2QXh8sWvjuqWWTeSAnMxJiHV4Zvm3 1Yrb2zCz8wcBvI0yhXTKYUcuMYxGleGWKZVK4ByPMl1NMxIIJBrSvpcvwCOyKUG5 Ag0EVztL4gEQAL2eZfu3CcK7W8/vm20Io3XicFnpgx0K9OAaR8VfvX4LJ1DD52Ti UigCPHkZHXMk39jKQek0yaNRs13c1qYOIaPv9o5x/LAu+bPLXCY1RLos1mzi8+PR qBW7JuvnJp6B6qBVNk+0xgH1JFJNMO0zpwmj59y8pUFSUYUXrLw2VQF2wcz6E9X2 G6MvMHRF0zVgNvna1POLuUK/nihWM/QMzEatWxX6hvZH0Ll/Io3s11ciO+zf+RCN Lb3UNhgh3whAkqppFiUQf9wqZYDyS27geXHwfk0H8CE0/7MPCq1pC3/s/Iev6WTK 4ICdrZy9ymFBKGiFHkIWosAfNc4cLNW+lXIPNtS2RlxhGKvV3PTBFopj/FVwu+YF 6UWdAyjBPJt2oCBzAlbDklSZ9/xbehdk2OV+WT0By35QmLPBRdbqQ6ioXAEQIpaN JQWzXEH4CSdhaSL2yl09Z1nDAhplY0EFDWdhfpYMdyU2+ypRxLpwftE702lJ5zGN otwgvB9jYBVnEWE/qyLZ++JjHFblft3l3Rcz42th12ME3Qbq5KBX6d4HN7jCvV5+ U8XUMhPp+9Xqz2GTcEIvi51n/zlHhacyApaRoIZAxMr94v/OTrgID4J7WhwodeZg qSo3bAMCJbUN5/1WMB9tkSGhnq6Dw4ItpNnw5ueNk0AKksz38R2bHL+5ABEBAAGJ Ah8EGAEKAAkCGyAFAldB/lkACgkQuag876B8bYryZxAAkyqB37+hkuPpAQ88jMJE ulVEqmL1dWqz9e6qh0QiZNxa17E7OT9yvQTIqU5rra2Esf0LWIp1nOkl2DjBfQqi dbJq9P0w1aqgjc4WM7PQKXkye2CWofI6vWCKfI0t9e7r/oY5is8snpFWCbP0dhKi AFb5fZu68Vx06lM8QA89441JE2GdXmS87M95cY6vEwFEUZ/vQiaqoMflYcRD2DeA n//Eiz+Jhjrtv9pfJ0gNbrrNBUW+sKWYc/rLfkTXD8caUDY9Yb4vlNEDW3xLmgLZ ZeHDcBnOH6DsRVj+T9XmpcV1zDY0oRKULCGetWlf4joKLOKpEWBEN1bXdMzWYO8q yFrqvlm91SFaNQfSU0riiaevy2bRCq4A+yCnVFY4gHILX5l0G99ilOfcFmZS0+na S6MILuXL6XTYOOFkrPenSIB/6aVPDGnOXNCYafAoICWo/+t+Hb8XtI7jeTC6c60x O3QZcONXotk4f+ygqeH7GJlPWiMBFu39hZJNaMyfVggASkeWcr87WsakueqgYEAo 3XTCAfQF0/4M1FVrVqUhALKX+vVVN9UBs4J9hHjuurrxeX8NWU7z9Kd+n6EHU5ew A2nfG3TGMh3Azvq/Px838NNrzvzSiVlDAdpDVQJ7K0d/2Zxs6hgt0R4eeJCVSx7W XwBcs8DQ0SUDhqcbWTbFIQg= =/9fe -----END PGP PUBLIC KEY BLOCK----- ,0,484
openstack%2Ftripleo-validations~master~I9cfe5a83cd804f4793d6f4a73821a21ce64f40f6,openstack/tripleo-validations,master,I9cfe5a83cd804f4793d6f4a73821a21ce64f40f6,Fix role-addition.yaml automation playbook,MERGED,2020-01-28 07:50:21.000000000,2020-01-28 20:29:44.000000000,2020-01-28 20:29:44.000000000,"[{'_account_id': 7353}, {'_account_id': 8532}, {'_account_id': 11491}, {'_account_id': 17888}, {'_account_id': 22348}, {'_account_id': 25877}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-28 07:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/17973a58b5838e050fbecb839154f5530172e502', 'message': 'Corrected role-addition.yaml\n\nThe call to ansible-galaxy was wrong:\n- wrong init path (tripleo_validations/roles instead of roles)\n- missing role name\n\nChange-Id: I9cfe5a83cd804f4793d6f4a73821a21ce64f40f6\n'}, {'number': 2, 'created': '2020-01-28 08:11:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/527f0eb2c225fd81217bc5652848aa0020adcee4', 'message': 'Corrected role-addition.yaml\n\nThe call to ansible-galaxy was wrong:\n- wrong init path (tripleo_validations/roles instead of roles)\n- missing role name\n\nChange-Id: I9cfe5a83cd804f4793d6f4a73821a21ce64f40f6\n'}, {'number': 3, 'created': '2020-01-28 11:45:09.000000000', 'files': ['role-addition.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/878224e89de4120434f468de347878d4e282c96a', 'message': 'Fix role-addition.yaml automation playbook\n\nThe call to ansible-galaxy was wrong:\n- wrong init path (tripleo_validations/roles instead of roles)\n- missing role name\n\nThis patch adds a sort method to keep the job lists (check & gate)\nsorted when adding a new role.\n\nChange-Id: I9cfe5a83cd804f4793d6f4a73821a21ce64f40f6\n'}]",1,704504,878224e89de4120434f468de347878d4e282c96a,11,7,3,28223,,,0,"Fix role-addition.yaml automation playbook

The call to ansible-galaxy was wrong:
- wrong init path (tripleo_validations/roles instead of roles)
- missing role name

This patch adds a sort method to keep the job lists (check & gate)
sorted when adding a new role.

Change-Id: I9cfe5a83cd804f4793d6f4a73821a21ce64f40f6
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/04/704504/2 && git format-patch -1 --stdout FETCH_HEAD,['role-addition.yml'],1,17973a58b5838e050fbecb839154f5530172e502,role-addition, --init-path=roles/{{ _role_name }} {{ _role_name }}, --init-path=tripleo_validations/roles/{{ _role_name }},2,1
openstack%2Fnetworking-ovn~stable%2Ftrain~Iea532e2a02b7992305d1b90aa040e064901c340c,openstack/networking-ovn,stable/train,Iea532e2a02b7992305d1b90aa040e064901c340c,[OVN] Delete NAT entry first on any FIP update,MERGED,2020-01-23 08:45:48.000000000,2020-01-28 20:27:17.000000000,2020-01-28 20:24:46.000000000,"[{'_account_id': 6773}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 24791}]","[{'number': 1, 'created': '2020-01-23 08:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/45d4d9c8afcaa562b0ec7f0b8d599f9a159c03ac', 'message': ""[OVN] Delete NAT entry first on any FIP update\n\nFor now while updating FIP  check if port or logical_ip\nhas changed and only then we deleted the NAT entry.\n\nUnfortunately each time when FIP update occurs the\nmethod _create_or_update_floatingip() is used. It first deletes\nLSP pointed by FIP and adds it again along with new NAT entries.\nBased on author comment this actions are required.\n\nSo if we don't update FIP with logical_ip or new port_id,\nlike update a description, the NAT entries gets duplicated.\n\nSince all is wrapped withing a transaction and to not wait for\nproper fix (this code need sa refactor based on commments with NAT\nexternal_id column) I think thats safe just to delete the NAT entry\nin such situation like described above.\n\n(cherry picked from commit 45ae9dfb7d5acacc72fcf9f071a9db1beb0ca972)\n\nChange-Id: Iea532e2a02b7992305d1b90aa040e064901c340c\nRelated-Bug: #1859977\n""}, {'number': 2, 'created': '2020-01-23 11:50:17.000000000', 'files': ['networking_ovn/common/ovn_client.py', 'networking_ovn/tests/unit/l3/test_l3_ovn.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/ba542715de5fa22ae57d8b3263a6ea8c6ae2620f', 'message': ""[OVN] Delete NAT entry first on any FIP update\n\nFor now while updating FIP  check if port or logical_ip\nhas changed and only then we deleted the NAT entry.\n\nUnfortunately each time when FIP update occurs the\nmethod _create_or_update_floatingip() is used. It first deletes\nLSP pointed by FIP and adds it again along with new NAT entries.\nBased on author comment this actions are required.\n\nSo if we don't update FIP with logical_ip or new port_id,\nlike update a description, the NAT entries gets duplicated.\n\nSince all is wrapped withing a transaction and to not wait for\nproper fix (this code need sa refactor based on commments with NAT\nexternal_id column) I think thats safe just to delete the NAT entry\nin such situation like described above.\n\n(cherry picked from commit 45ae9dfb7d5acacc72fcf9f071a9db1beb0ca972)\n\nChange-Id: Iea532e2a02b7992305d1b90aa040e064901c340c\nRelated-Bug: #1859977\n""}]",0,703939,ba542715de5fa22ae57d8b3263a6ea8c6ae2620f,19,4,2,24791,,,0,"[OVN] Delete NAT entry first on any FIP update

For now while updating FIP  check if port or logical_ip
has changed and only then we deleted the NAT entry.

Unfortunately each time when FIP update occurs the
method _create_or_update_floatingip() is used. It first deletes
LSP pointed by FIP and adds it again along with new NAT entries.
Based on author comment this actions are required.

So if we don't update FIP with logical_ip or new port_id,
like update a description, the NAT entries gets duplicated.

Since all is wrapped withing a transaction and to not wait for
proper fix (this code need sa refactor based on commments with NAT
external_id column) I think thats safe just to delete the NAT entry
in such situation like described above.

(cherry picked from commit 45ae9dfb7d5acacc72fcf9f071a9db1beb0ca972)

Change-Id: Iea532e2a02b7992305d1b90aa040e064901c340c
Related-Bug: #1859977
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/39/703939/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/common/ovn_client.py', 'networking_ovn/tests/unit/l3/test_l3_ovn.py']",2,45d4d9c8afcaa562b0ec7f0b8d599f9a159c03ac,bug/1859977," 'update_floatingip') def test_update_floatingip_association_empty_update(self, uf, gf): self.l3_inst._ovn.is_col_present.return_value = True self.l3_inst._ovn.get_floatingip.return_value = ( self.fake_ovn_nat_rule) self.fake_floating_ip.update({'fixed_port_id': 'foo'}) self.fake_floating_ip_new.update({'port_id': 'foo'}) self.l3_inst._ovn.delete_nat_rule_in_lrouter.assert_called_once_with( 'neutron-router-id', type='dnat_and_snat', logical_ip='10.0.0.10', external_ip='192.168.0.10') expected_ext_ids = { ovn_const.OVN_FIP_EXT_ID_KEY: self.fake_floating_ip_new['id'], ovn_const.OVN_REV_NUM_EXT_ID_KEY: '1', ovn_const.OVN_FIP_PORT_EXT_ID_KEY: self.fake_floating_ip_new['port_id'], ovn_const.OVN_ROUTER_NAME_EXT_ID_KEY: utils.ovn_name( self.fake_floating_ip_new['router_id'])} self.l3_inst._ovn.add_nat_rule_in_lrouter.assert_called_once_with( 'neutron-new-router-id', type='dnat_and_snat', logical_ip='10.10.10.10', external_ip='192.168.0.10', external_ids=expected_ext_ids)"," 'update_floatingip') def test_update_floatingip_association_not_changed(self, uf, gf): self.fake_floating_ip.update({'fixed_port_id': None}) self.fake_floating_ip_new.update({'port_id': None}) self.l3_inst._ovn.delete_nat_rule_in_lrouter.assert_not_called() self.l3_inst._ovn.add_nat_rule_in_lrouter.assert_not_called()",26,12
openstack%2Fheat-translator~master~I026a06de41ed390967e9ef137fa633ecd4fe747f,openstack/heat-translator,master,I026a06de41ed390967e9ef137fa633ecd4fe747f,ETSI-NFV SOL 001 translation: BlockStorage,MERGED,2019-11-26 07:37:00.000000000,2020-01-28 20:07:23.000000000,2020-01-28 20:03:24.000000000,"[{'_account_id': 16511}, {'_account_id': 22348}, {'_account_id': 26588}, {'_account_id': 31072}]","[{'number': 1, 'created': '2019-11-26 07:37:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/f17e0f45f7456b90d8c624cfcd6e4e52fdeb3503', 'message': 'ETSI-NFV SOL 001 translation: BlockStorage\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.Vdu.VirtualBlockStorage\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I026a06de41ed390967e9ef137fa633ecd4fe747f\nStory: 2006372\nTask: 37621\n'}, {'number': 2, 'created': '2019-11-26 08:04:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/5d7bcb98a8e692a354ecfd5116124b4e81dcd635', 'message': 'ETSI-NFV SOL 001 translation: BlockStorage\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.Vdu.VirtualBlockStorage\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I026a06de41ed390967e9ef137fa633ecd4fe747f\nStory: 2006372\nTask: 37621\n'}, {'number': 3, 'created': '2019-11-26 08:16:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/594fc24e20e95e623f83a85819e479a0d6a37c46', 'message': 'ETSI-NFV SOL 001 translation: BlockStorage\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.Vdu.VirtualBlockStorage\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I026a06de41ed390967e9ef137fa633ecd4fe747f\nStory: 2006372\nTask: 37621\n'}, {'number': 4, 'created': '2019-11-26 08:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/4174c01178f57e49bd0dd824381f2ba8d87436e0', 'message': 'ETSI-NFV SOL 001 translation: BlockStorage\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.Vdu.VirtualBlockStorage\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I026a06de41ed390967e9ef137fa633ecd4fe747f\nStory: 2006372\nTask: 37621\n'}, {'number': 5, 'created': '2019-11-27 07:43:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/0620a69045d0f031e6953632fa691c3714fdf55d', 'message': 'ETSI-NFV SOL 001 translation: BlockStorage\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.Vdu.VirtualBlockStorage\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I026a06de41ed390967e9ef137fa633ecd4fe747f\nStory: 2006372\nTask: 37621\n'}, {'number': 6, 'created': '2019-11-27 09:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/e2c1a52db994844530e6585eface1fe2337faa2d', 'message': 'ETSI-NFV SOL 001 translation: BlockStorage\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.Vdu.VirtualBlockStorage\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I026a06de41ed390967e9ef137fa633ecd4fe747f\nStory: 2006372\nTask: 37621\n'}, {'number': 7, 'created': '2019-11-28 00:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/667ef0520e2cfbdb02ab1d9ecfc24fb80e8223dc', 'message': 'ETSI-NFV SOL 001 translation: BlockStorage\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.Vdu.VirtualBlockStorage\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I026a06de41ed390967e9ef137fa633ecd4fe747f\nStory: 2006372\nTask: 37621\n'}, {'number': 8, 'created': '2019-12-06 10:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/3bc2ff06d070c02a4a87e1d562967b002dbf591a', 'message': 'ETSI-NFV SOL 001 translation: BlockStorage\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.Vdu.VirtualBlockStorage\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I026a06de41ed390967e9ef137fa633ecd4fe747f\nStory: 2006372\nTask: 37621\n'}, {'number': 9, 'created': '2019-12-09 10:41:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/fcb89f2dee2fd88237c443d47fa4af1e201c6d0e', 'message': 'ETSI-NFV SOL 001 translation: BlockStorage\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.Vdu.VirtualBlockStorage\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I026a06de41ed390967e9ef137fa633ecd4fe747f\nStory: 2006372\nTask: 37621\n'}, {'number': 10, 'created': '2019-12-20 01:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/99e9c66a6b2a377dbd56028af6c56b492143b85f', 'message': 'ETSI-NFV SOL 001 translation: BlockStorage\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.Vdu.VirtualBlockStorage\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I026a06de41ed390967e9ef137fa633ecd4fe747f\nStory: 2006372\nTask: 37621\n'}, {'number': 11, 'created': '2020-01-22 03:36:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/d4c74063b690cf16125f1c667a76ba86e150a4a1', 'message': 'ETSI-NFV SOL 001 translation: BlockStorage\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.Vdu.VirtualBlockStorage\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I026a06de41ed390967e9ef137fa633ecd4fe747f\nStory: 2006372\nTask: 37621\n'}, {'number': 12, 'created': '2020-01-24 04:54:58.000000000', 'files': ['translator/tests/test_translate_node_template.py', 'translator/tests/test_etsi_tosca_hot_translation.py', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_blockstorage.yaml', 'translator/hot/tosca/etsi_nfv/tosca_nfv_vdu_virtualblockstorage.py', 'translator/tests/data/etsi_nfv/tosca_nfv_blockstorage.yaml'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/59c61d71eb6534dddc4b4f83ba75d14bdd8b6e6a', 'message': 'ETSI-NFV SOL 001 translation: BlockStorage\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.Vdu.VirtualBlockStorage\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I026a06de41ed390967e9ef137fa633ecd4fe747f\nStory: 2006372\nTask: 37621\n'}]",0,696026,59c61d71eb6534dddc4b4f83ba75d14bdd8b6e6a,32,4,12,31072,,,0,"ETSI-NFV SOL 001 translation: BlockStorage

Currently heat-translator supports translation of TOSCA Simple Profile
for YAML[1] and TOSCA Simple Profile for NFV[2] only.
This commit enables to translation of the follwoing type defined in
ETSI NFV-SOL 001[3].
- tosca.nodes.nfv.Vdu.VirtualBlockStorage

[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html
[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html
[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf

Change-Id: I026a06de41ed390967e9ef137fa633ecd4fe747f
Story: 2006372
Task: 37621
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/26/696026/12 && git format-patch -1 --stdout FETCH_HEAD,"['translator/tests/test_translate_node_template.py', 'translator/tests/test_etsi_tosca_hot_translation.py', 'translator/tests/data/etsi_nfv/tosca_nfv_vdu_cp_blockstorage.yaml', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_blockstorage.yaml', 'translator/tests/test_etsi_tosca_hot_translation.py.orig', 'translator/hot/tosca/etsi_nfv/tosca_nfv_vdu_virtualblockstorage.py', 'translator/tests/data/etsi_nfv/tosca_nfv_blockstorage.yaml', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_vdu_cp_blockstorage.yaml']",8,f17e0f45f7456b90d8c624cfcd6e4e52fdeb3503,etsi_nfv-sol001,heat_template_version: 2013-05-23 description: > Template for deploying one VDU and one CP and two VirtualStorage. parameters: {} resources: CP1: type: OS::Neutron::Port properties: network: REPLACE_TO_EXTERNAL_VL binding:vnic_type: direct-physical VDU1: type: OS::Nova::Server properties: flavor: { get_resource: VDU1_flavor } name: VDU1 networks: - port: { get_resource: CP1 } block_device_mapping_v2: - volume_id: { get_resource: VirtualStorage1 } - volume_id: { get_resource: VirtualStorage2 } VirtualStorage1: type: OS::Cinder::Volume properties: size: 30 image: REPLACED_IMAGE VirtualStorage2: type: OS::Cinder::Volume properties: size: 60 image: REPLACED_IMAGE VDU1_flavor: type: OS::Nova::Flavor properties: ram: 512 vcpus: 1 disk: 1 outputs: {} ,,416,1
openstack%2Fheat-translator~master~I28b4ff67b74e7d5ad4264acb93cd8c292b91a0d4,openstack/heat-translator,master,I28b4ff67b74e7d5ad4264acb93cd8c292b91a0d4,"ETSI-NFV SOL 001 translation: CP,VL",MERGED,2019-11-26 06:48:02.000000000,2020-01-28 20:05:15.000000000,2020-01-28 20:03:21.000000000,"[{'_account_id': 12404}, {'_account_id': 16511}, {'_account_id': 22348}, {'_account_id': 26588}, {'_account_id': 31072}]","[{'number': 1, 'created': '2019-11-26 06:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/82914e5e9599750efb3be368a02f9c7bbb369392', 'message': 'ETSI-NFV SOL 001 translation: CP,VL\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.VduCp\n- tosca.nodes.nfv.VnfVirtualLink\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I28b4ff67b74e7d5ad4264acb93cd8c292b91a0d4\nStory: 2006372\nTask: 37620\n'}, {'number': 2, 'created': '2019-11-27 10:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/8cfd019e9cff665190e833c468ff3ed2e02aaa52', 'message': 'ETSI-NFV SOL 001 translation: CP,VL\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.VduCp\n- tosca.nodes.nfv.VnfVirtualLink\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I28b4ff67b74e7d5ad4264acb93cd8c292b91a0d4\nStory: 2006372\nTask: 37620\n'}, {'number': 3, 'created': '2019-12-06 10:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/57d6688fd0a5e54a17bd33a380a4938a447cb833', 'message': 'ETSI-NFV SOL 001 translation: CP,VL\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.VduCp\n- tosca.nodes.nfv.VnfVirtualLink\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I28b4ff67b74e7d5ad4264acb93cd8c292b91a0d4\nStory: 2006372\nTask: 37620\n'}, {'number': 4, 'created': '2019-12-09 10:41:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/bba9c926e81f882864a38e08e15427a1303b926c', 'message': 'ETSI-NFV SOL 001 translation: CP,VL\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.VduCp\n- tosca.nodes.nfv.VnfVirtualLink\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I28b4ff67b74e7d5ad4264acb93cd8c292b91a0d4\nStory: 2006372\nTask: 37620\n'}, {'number': 5, 'created': '2019-12-20 01:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/c39b00eeed10fb7c34abd787b5b70274e70d2493', 'message': 'ETSI-NFV SOL 001 translation: CP,VL\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.VduCp\n- tosca.nodes.nfv.VnfVirtualLink\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I28b4ff67b74e7d5ad4264acb93cd8c292b91a0d4\nStory: 2006372\nTask: 37620\n'}, {'number': 6, 'created': '2020-01-22 03:36:27.000000000', 'files': ['translator/tests/test_translate_node_template.py', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_vl.yaml', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_non_leaf_in_vl.yaml', 'translator/tests/data/etsi_nfv/tosca_nfv_vl.yaml', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_check_cp_order.yaml', 'translator/tests/test_etsi_tosca_hot_translation.py', 'translator/tests/data/etsi_nfv/tosca_nfv_vl_with_unsupported_protocol.yaml', 'translator/tests/data/etsi_nfv/tosca_nfv_non_leaf_in_vl.yaml', 'translator/tests/data/etsi_nfv/tosca_nfv_cp_with_extended_vnic_type.yaml', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_cp.yaml', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_vl_with_unsupported_protocol.yaml', 'translator/hot/translate_node_templates.py', 'translator/tests/data/etsi_nfv/tosca_nfv_cp.yaml', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_cp_with_extended_vnic_type.yaml', 'translator/tests/data/etsi_nfv/tosca_nfv_check_cp_order.yaml', 'translator/hot/tosca/etsi_nfv/tosca_nfv_vducp.py', 'translator/hot/tosca/etsi_nfv/tosca_nfv_vnfvirtuallink.py'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/6f94614c71659aec9e8fa6826ba2b06131081913', 'message': 'ETSI-NFV SOL 001 translation: CP,VL\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.VduCp\n- tosca.nodes.nfv.VnfVirtualLink\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nChange-Id: I28b4ff67b74e7d5ad4264acb93cd8c292b91a0d4\nStory: 2006372\nTask: 37620\n'}]",12,696021,6f94614c71659aec9e8fa6826ba2b06131081913,27,5,6,31072,,,0,"ETSI-NFV SOL 001 translation: CP,VL

Currently heat-translator supports translation of TOSCA Simple Profile
for YAML[1] and TOSCA Simple Profile for NFV[2] only.
This commit enables to translation of the follwoing type defined in
ETSI NFV-SOL 001[3].
- tosca.nodes.nfv.VduCp
- tosca.nodes.nfv.VnfVirtualLink

[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html
[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html
[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf

Change-Id: I28b4ff67b74e7d5ad4264acb93cd8c292b91a0d4
Story: 2006372
Task: 37620
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/21/696021/2 && git format-patch -1 --stdout FETCH_HEAD,"['translator/tests/test_translate_node_template.py', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_vl.yaml', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_non_leaf_in_vl.yaml', 'translator/tests/data/etsi_nfv/tosca_nfv_vl.yaml', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_check_cp_order.yaml', 'translator/tests/test_etsi_tosca_hot_translation.py', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_vdu_cp_vl.yaml', 'translator/tests/data/etsi_nfv/tosca_nfv_vl_with_unsupported_protocol.yaml', 'translator/tests/data/etsi_nfv/tosca_nfv_non_leaf_in_vl.yaml', 'translator/tests/data/etsi_nfv/tosca_nfv_cp_with_unsupported_vnic_type.yaml', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_cp.yaml', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_vl_with_unsupported_protocol.yaml', 'translator/tests/data/etsi_nfv/tosca_nfv_vdu_cp_vl.yaml', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_cp_with_unsupported_vnic_type.yaml', 'translator/hot/translate_node_templates.py', 'translator/tests/data/etsi_nfv/tosca_nfv_cp.yaml', 'translator/tests/data/etsi_nfv/tosca_nfv_check_cp_order.yaml', 'translator/hot/tosca/etsi_nfv/tosca_nfv_vducp.py', 'translator/hot/tosca/etsi_nfv/tosca_nfv_vnfvirtuallink.py']",19,82914e5e9599750efb3be368a02f9c7bbb369392,etsi_nfv-sol001,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import logging from translator.common.utils import MemoryUnit from translator.hot.syntax.hot_resource import HotResource log = logging.getLogger('heat-translator') # Name used to dynamically load appropriate map class. TARGET_CLASS_NAME = 'ToscaNfvVnfVirtualLink' class ToscaNfvVnfVirtualLink(HotResource): """"""Translate TOSCA node type tosca.nodes.nfv.VnfVirtualLink."""""" toscatype = 'tosca.nodes.nfv.VnfVirtualLink' SUBNET_SUFFIX = '_subnet' QOSPOLICY_SUFFIX = '_qospolicy' BANDWIDTH_SUFFIX = '_bandwidth' ip_map = { 'ipv4': '4', 'ipv6': '6', } def __init__(self, nodetemplate, csar_dir=None): # Check if it is an IP network tosca_props = {} for prop in nodetemplate.get_properties_objects(): tosca_props[prop.name] = prop.value lp = tosca_props.get('connectivity_type').get('layer_protocols') self.ip_protocol = list(set(self.ip_map.keys()) & set(lp)) # Branch by IP or not if self.ip_protocol: super(ToscaNfvVnfVirtualLink, self).__init__( nodetemplate, type='OS::Neutron::Net', csar_dir=csar_dir ) else: super(ToscaNfvVnfVirtualLink, self).__init__( nodetemplate, csar_dir=csar_dir ) log.warning(('Unsupported layer_protocols:%s') % lp) def handle_properties(self): # Branch by IP or not if self.ip_protocol: tosca_props = self.get_tosca_props() own_props = {} self.is_leaf = False for key, value in tosca_props.items(): if key == 'vl_profile': mbr = value['max_bitrate_requirements'] if 'leaf' in mbr: max_bps = mbr['leaf'] # Convert to KiB self.max_kbps = \ max_bps / MemoryUnit.UNIT_SIZE_DICT['KiB'] self.is_leaf = True else: log.warning('Can not set the required properties ' 'max_kbps on HOT.' 'virtual_link_name:%s' % self.name) if self.is_leaf: own_props['qos_policy'] = '{ get_resource: %s%s }' % ( self.name, self.QOSPOLICY_SUFFIX, ) self.properties = own_props else: pass def handle_expansion(self): hot_resources = [] # Branch by IP or not if self.ip_protocol: tosca_props = self.get_tosca_props() # subnet props subnet_props = {} subnet_props['ip_version'] = self.ip_map.get(self.ip_protocol[0]) subnet_props['network'] = '{ get_resource: %s }' % (self.name) for key, value in tosca_props.items(): if key == 'vl_profile': if 'virtual_link_protocol_data' in value: vlpd = value['virtual_link_protocol_data'] if 'l3_protocol_data' in vlpd[0]: l3pd = vlpd[0]['l3_protocol_data'] subnet_props['cidr'] = l3pd['cidr'] subnet_resource_name = self.name + self.SUBNET_SUFFIX hot_resources.append( HotResource( self.nodetemplate, type='OS::Neutron::Subnet', name=subnet_resource_name, properties=subnet_props, ) ) # qospolicy_props props qospolicy_props = {} qospolicy_resource_name = self.name + self.QOSPOLICY_SUFFIX # bandwidth props bandwidth_props = {} bandwidth_props['policy'] = '{ get_resource: %s%s }' % ( self.name, self.QOSPOLICY_SUFFIX, ) bandwidth_resource_name = self.name + self.BANDWIDTH_SUFFIX # Create QoSPolicy and QoSBandwidthLimitRule resources # only when max_bitrate_requirements has leaf property. if self.is_leaf: hot_resources.append( HotResource( self.nodetemplate, type='OS::Neutron::QoSPolicy', name=qospolicy_resource_name, properties=qospolicy_props, ) ) bandwidth_props['max_kbps'] = self.max_kbps hot_resources.append( HotResource( self.nodetemplate, type='OS::Neutron::QoSBandwidthLimitRule', name=bandwidth_resource_name, properties=bandwidth_props, ) ) else: pass return hot_resources ",,995,4
openstack%2Fheat-translator~master~I69263dce88bab5413a2d6f74f8d0c920dd454bf3,openstack/heat-translator,master,I69263dce88bab5413a2d6f74f8d0c920dd454bf3,"ETSI-NFV SOL 001 translation: VNF, Compute",MERGED,2019-11-15 06:06:14.000000000,2020-01-28 20:03:29.000000000,2020-01-28 20:01:26.000000000,"[{'_account_id': 12404}, {'_account_id': 16511}, {'_account_id': 22348}, {'_account_id': 26588}, {'_account_id': 31072}]","[{'number': 1, 'created': '2019-11-15 06:06:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/c869fc0b1d06fcf64dcef077c6a3744df9309fbb', 'message': '[WIP]ETSI-NFV SOL 001 translation: VNF, Compute\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.VNF\n- tosca.nodes.nfv.Vdu.Compute\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nSroty: 2006372\nTask: 36161\n\nChange-Id: I69263dce88bab5413a2d6f74f8d0c920dd454bf3\n'}, {'number': 2, 'created': '2019-11-15 06:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/2c5f1f34e0c95dd51ce4056ac6a5452d979c057a', 'message': 'ETSI-NFV SOL 001 translation: VNF, Compute\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.VNF\n- tosca.nodes.nfv.Vdu.Compute\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nSroty: 2006372\nTask: 36161\n\nChange-Id: I69263dce88bab5413a2d6f74f8d0c920dd454bf3\n'}, {'number': 3, 'created': '2019-11-18 08:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/5f49de71db3e9fd1d99b1361a691b7de88569d39', 'message': 'ETSI-NFV SOL 001 translation: VNF, Compute\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.VNF\n- tosca.nodes.nfv.Vdu.Compute\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nSroty: 2006372\nTask: 36161\n\nChange-Id: I69263dce88bab5413a2d6f74f8d0c920dd454bf3\n'}, {'number': 4, 'created': '2019-11-19 08:11:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/35e60a6a2c089bac45714d0fc53079213cfb04f0', 'message': 'ETSI-NFV SOL 001 translation: VNF, Compute\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.VNF\n- tosca.nodes.nfv.Vdu.Compute\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nSroty: 2006372\nTask: 36161\n\nChange-Id: I69263dce88bab5413a2d6f74f8d0c920dd454bf3\n'}, {'number': 5, 'created': '2019-11-20 01:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/8b4d6ed08e9a46f538c66c7d29e98c2c7f96010b', 'message': 'ETSI-NFV SOL 001 translation: VNF, Compute\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.VNF\n- tosca.nodes.nfv.Vdu.Compute\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nStory: 2006372\nTask: 36161\n\nChange-Id: I69263dce88bab5413a2d6f74f8d0c920dd454bf3\n'}, {'number': 6, 'created': '2019-11-27 10:22:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/7c477956832e0a6036bec497b3923f3efd40745f', 'message': 'ETSI-NFV SOL 001 translation: VNF, Compute\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.VNF\n- tosca.nodes.nfv.Vdu.Compute\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nStory: 2006372\nTask: 36161\n\nChange-Id: I69263dce88bab5413a2d6f74f8d0c920dd454bf3\n'}, {'number': 7, 'created': '2019-12-20 01:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/01627a9660dfa4716e873385c68367bdc3fe89e8', 'message': 'ETSI-NFV SOL 001 translation: VNF, Compute\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.VNF\n- tosca.nodes.nfv.Vdu.Compute\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nStory: 2006372\nTask: 36161\n\nChange-Id: I69263dce88bab5413a2d6f74f8d0c920dd454bf3\n'}, {'number': 8, 'created': '2020-01-22 03:36:27.000000000', 'files': ['translator/tests/data/hot_output/etsi_nfv/hot_nfv_vdu_with_logical_node.yaml', 'translator/tests/test_translate_node_template.py', 'translator/tests/test_etsi_tosca_hot_translation.py', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_vnf.yaml', 'lower-constraints.txt', 'translator/tests/data/etsi_nfv/tosca_nfv_vdu_with_invalid_compute_requirements.yaml', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_vdu.yaml', 'translator/hot/syntax/hot_resource.py', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_vdu_with_compute_requirements.yaml', 'requirements.txt', 'translator/hot/tosca/etsi_nfv/tosca_nfv_vdu_compute.py', 'translator/tests/data/etsi_nfv/tosca_nfv_vdu_with_unsupported_storage.yaml', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_vdu_with_unsupported_storage.yaml', 'translator/hot/translate_node_templates.py', 'translator/hot/tosca/etsi_nfv/__init__.py', 'translator/tests/data/etsi_nfv/tosca_nfv_vdu_with_compute_requirements.yaml', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_vdu_with_invalid_compute_requirements.yaml', 'translator/tests/data/etsi_nfv/tosca_nfv_vnf.yaml', 'translator/tests/data/etsi_nfv/etsi_nfv_sol001_common_types.yaml', 'translator/tests/data/etsi_nfv/etsi_nfv_sol001_vnfd_types.yaml', 'translator/tests/data/etsi_nfv/tosca_nfv_vdu.yaml', 'translator/hot/tosca/etsi_nfv/tosca_nfv_vnf.py', 'translator/tests/data/etsi_nfv/tosca_nfv_vdu_with_logical_node.yaml'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/4833eb5e9262433f21c651b5835c2974ef8a7bf0', 'message': 'ETSI-NFV SOL 001 translation: VNF, Compute\n\nCurrently heat-translator supports translation of TOSCA Simple Profile\nfor YAML[1] and TOSCA Simple Profile for NFV[2] only.\nThis commit enables to translation of the follwoing type defined in\nETSI NFV-SOL 001[3].\n- tosca.nodes.nfv.VNF\n- tosca.nodes.nfv.Vdu.Compute\n\n[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html\n[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html\n[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf\n\nStory: 2006372\nTask: 36161\n\nChange-Id: I69263dce88bab5413a2d6f74f8d0c920dd454bf3\n'}]",1,694454,4833eb5e9262433f21c651b5835c2974ef8a7bf0,28,5,8,26588,,,0,"ETSI-NFV SOL 001 translation: VNF, Compute

Currently heat-translator supports translation of TOSCA Simple Profile
for YAML[1] and TOSCA Simple Profile for NFV[2] only.
This commit enables to translation of the follwoing type defined in
ETSI NFV-SOL 001[3].
- tosca.nodes.nfv.VNF
- tosca.nodes.nfv.Vdu.Compute

[1] http://docs.oasis-open.org/tosca/tosca-nfv/v1.0/tosca-nfv-v1.0.html
[2] http://docs.oasis-open.org/tosca/TOSCA-Simple-Profile-YAML/v1.0/TOSCA-Simple-Profile-YAML-v1.0.html
[3] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.06.01_60/gs_NFV-SOL001v020601p.pdf

Story: 2006372
Task: 36161

Change-Id: I69263dce88bab5413a2d6f74f8d0c920dd454bf3
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/54/694454/8 && git format-patch -1 --stdout FETCH_HEAD,"['translator/tests/test_translate_node_template.py', 'translator/tests/test_etsi_tosca_hot_translation.py', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_vnf.yaml', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_vdu.yaml', 'translator/hot/syntax/hot_resource.py', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_vdu_with_compute_requirements.yaml', 'translator/hot/tosca/etsi_nfv/tosca_nfv_vdu_compute.py', 'translator/tests/data/etsi_nfv/tosca_nfv_vdu_with_unsupported_storage.yaml', 'translator/tests/data/hot_output/etsi_nfv/hot_nfv_vdu_with_unsupported_storage.yaml', 'translator/hot/translate_node_templates.py', 'translator/hot/tosca/etsi_nfv/__init__.py', 'translator/tests/data/etsi_nfv/tosca_nfv_vdu_with_compute_requirements.yaml', 'translator/tests/data/etsi_nfv/tosca_nfv_vnf.yaml', 'translator/tests/data/etsi_nfv/etsi_nfv_sol001_common_types.yaml', 'translator/tests/data/etsi_nfv/etsi_nfv_sol001_vnfd_types.yaml', 'translator/tests/data/etsi_nfv/tosca_nfv_vdu.yaml', 'translator/hot/tosca/etsi_nfv/tosca_nfv_vnf.py']",17,c869fc0b1d06fcf64dcef077c6a3744df9309fbb,etsi_nfv-sol001,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from translator.hot.syntax.hot_resource import HotResource # Name used to dynamically load appropriate map class. TARGET_CLASS_NAME = 'ToscaNfvVnf' class ToscaNfvVnf(HotResource): """"""Translate TOSCA node type tosca.nodes.nfv.VNF."""""" toscatype = 'tosca.nodes.nfv.VNF' def __init__(self, nodetemplate, csar_dir): super(ToscaNfvVnf, self).__init__( nodetemplate, csar_dir=csar_dir) def handle_properties(self): pass ",,2151,3
